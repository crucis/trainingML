----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 2018435
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 16, 16)    608         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 32, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      18496       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 64, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 4, 4)     73856       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 128, 4, 4)     0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 4, 4)     0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 2, 2)     295168      dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 256, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           262400      flatten_1[0][0]                  
_____________________________________________________________________________________----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 2018435
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 16, 16)    608         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 32, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      18496       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 64, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 4, 4)     73856       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 128, 4, 4)     0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 4, 4)     0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 2, 2)     295168      dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 256, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           262400      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 650785
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5621 ', 'GAN acc 0.7305', 'Discriminator loss 4.8536', 'Discriminator accuracy 0.4863', 'Total loss: 5.4157', 'for batch', 0)
('GAN loss 0.2315 ', 'GAN acc 0.9961', 'Discriminator loss 1.5884', 'Discriminator accuracy 0.4199', 'Total loss: 1.8199', 'for batch', 1)
('GAN loss 0.1613 ', 'GAN acc 0.9961', 'Discriminator loss 1.0101', 'Discriminator accuracy 0.4746', 'Total loss: 1.1714', 'for batch', 2)
('GAN loss 0.1654 ', 'GAN acc 0.9961', 'Discriminator loss 1.1423', 'Discriminator accuracy 0.4824', 'Total loss: 1.3077', 'for batch', 3)
('GAN loss 0.2259 ', 'GAN acc 0.9961', 'Discriminator loss 1.1068', 'Discriminator accuracy 0.4785', 'Total loss: 1.3327', 'for batch', 4)
('GAN loss 0.3600 ', 'GAN acc 0.9492', 'Discriminator loss 0.9685', 'Discriminator accuracy 0.4883', 'Total loss: 1.3286', 'for batch', 5)
('GAN loss 0.4592 ', 'GAN acc 0.8594', 'Discriminator loss 0.7571', 'Discriminator accuracy 0.4961', 'Total loss: 1.2163', 'for batch', 6)
('GAN loss 0.6308 ', 'GAN acc 0.6250', 'Discriminator loss 0.5850', 'Discriminator accuracy 0.5449', 'Total loss: 1.2159', 'for batch', 7)
('GAN loss 0.6617 ', 'GAN acc 0.6055', 'Discriminator loss 0.6738', 'Discriminator accuracy 0.5918', 'Total loss: 1.3355', 'for batch', 8)
('GAN loss 0.5856 ', 'GAN acc 0.7227', 'Discriminator loss 0.7421', 'Discriminator accuracy 0.5430', 'Total loss: 1.3277', 'for batch', 9)
('GAN loss 0.5471 ', 'GAN acc 0.7812', 'Discriminator loss 0.5496', 'Discriminator accuracy 0.5859', 'Total loss: 1.0967', 'for batch', 10)
('GAN loss 0.6259 ', 'GAN acc 0.6875', 'Discriminator loss 0.5656', 'Discriminator accuracy 0.5742', 'Total loss: 1.1915', 'for batch', 11)
('GAN loss 0.7062 ', 'GAN acc 0.5391', 'Discriminator loss 0.5348', 'Discriminator accuracy 0.6055', 'Total loss: 1.2409', 'for batch', 12)
('GAN loss 0.7020 ', 'GAN acc 0.5352', 'Discriminator loss 0.4673', 'Discriminator accuracy 0.6328', 'Total loss: 1.1692', 'for batch', 13)
('GAN loss 0.7057 ', 'GAN acc 0.5039', 'Discriminator loss 0.4875', 'Discriminator accuracy 0.6270', 'Total loss: 1.1932', 'for batch', 14)
('GAN loss 0.6798 ', 'GAN acc 0.5312', 'Discriminator loss 0.4870', 'Discriminator accuracy 0.6152', 'Total loss: 1.1667', 'for batch', 15)
('GAN loss 0.6325 ', 'GAN acc 0.6445', 'Discriminator loss 0.5859', 'Discriminator accuracy 0.5371', 'Total loss: 1.2184', 'for batch', 16)
('GAN loss 0.6682 ', 'GAN acc 0.5898', 'Discriminator loss 0.5483', 'Discriminator accuracy 0.5605', 'Total loss: 1.2165', 'for batch', 17)
('GAN loss 0.7726 ', 'GAN acc 0.3984', 'Discriminator loss 0.5810', 'Discriminator accuracy 0.6211', 'Total loss: 1.3536', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95941079)
('DISCRIMINATOR_Imagem FAKE=', 0.46884528)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.016620')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8260 ', 'GAN acc 0.3555', 'Discriminator loss 0.5646', 'Discriminator accuracy 0.7207', 'Total loss: 1.3905', 'for batch', 0)
('GAN loss 0.8434 ', 'GAN acc 0.3320', 'Discriminator loss 0.4233', 'Discriminator accuracy 0.7266', 'Total loss: 1.2666', 'for batch', 1)
('GAN loss 0.8711 ', 'GAN acc 0.2500', 'Discriminator loss 0.5556', 'Discriminator accuracy 0.7676', 'Total loss: 1.4267', 'for batch', 2)
('GAN loss 0.8919 ', 'GAN acc 0.2383', 'Discriminator loss 0.4091', 'Discriminator accuracy 0.7852', 'Total loss: 1.3010', 'for batch', 3)
('GAN loss 0.8079 ', 'GAN acc 0.3320', 'Discriminator loss 0.4034', 'Discriminator accuracy 0.7676', 'Total loss: 1.2114', 'for batch', 4)
('GAN loss 0.7589 ', 'GAN acc 0.4141', 'Discriminator loss 0.4972', 'Discriminator accuracy 0.7227', 'Total loss: 1.2562', 'for batch', 5)
('GAN loss 0.7229 ', 'GAN acc 0.5273', 'Discriminator loss 0.5269', 'Discriminator accuracy 0.6387', 'Total loss: 1.2498', 'for batch', 6)
('GAN loss 0.7806 ', 'GAN acc 0.3906', 'Discriminator loss 0.4086', 'Discriminator accuracy 0.6973', 'Total loss: 1.1892', 'for batch', 7)
('GAN loss 0.7781 ', 'GAN acc 0.4258', 'Discriminator loss 0.4841', 'Discriminator accuracy 0.7168', 'Total loss: 1.2622', 'for batch', 8)
('GAN loss 0.7515 ', 'GAN acc 0.4219', 'Discriminator loss 0.4206', 'Discriminator accuracy 0.6973', 'Total loss: 1.1721', 'for batch', 9)
('GAN loss 0.8292 ', 'GAN acc 0.2852', 'Discriminator loss 0.3596', 'Discriminator accuracy 0.7363', 'Total loss: 1.1889', 'for batch', 10)
('GAN loss 0.8064 ', 'GAN acc 0.3438', 'Discriminator loss 0.4853', 'Discriminator accuracy 0.7656', 'Total loss: 1.2916', 'for batch', 11)
('GAN loss 0.7911 ', 'GAN acc 0.3008', 'Discriminator loss 0.4509', 'Discriminator accuracy 0.7832', 'Total loss: 1.2420', 'for batch', 12)
('GAN loss 0.8715 ', 'GAN acc 0.2031', 'Discriminator loss 0.3740', 'Discriminator accuracy 0.8066', 'Total loss: 1.2454', 'for batch', 13)
('GAN loss 0.9002 ', 'GAN acc 0.1797', 'Discriminator loss 0.3771', 'Discriminator accuracy 0.8145', 'Total loss: 1.2773', 'for batch', 14)
('GAN loss 0.9148 ', 'GAN acc 0.1602', 'Discriminator loss 0.3915', 'Discriminator accuracy 0.8398', 'Total loss: 1.3062', 'for batch', 15)
('GAN loss 0.9401 ', 'GAN acc 0.1445', 'Discriminator loss 0.3795', 'Discriminator accuracy 0.8574', 'Total loss: 1.3196', 'for batch', 16)
('GAN loss 0.8805 ', 'GAN acc 0.2070', 'Discriminator loss 0.3585', 'Discriminator accuracy 0.8301', 'Total loss: 1.2390', 'for batch', 17)
('GAN loss 0.8079 ', 'GAN acc 0.3359', 'Discriminator loss 0.4668', 'Discriminator accuracy 0.8027', 'Total loss: 1.2747', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96695065)
('DISCRIMINATOR_Imagem FAKE=', 0.45198414)
('Discriminator trained', 2, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.017348')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7986 ', 'GAN acc 0.3203', 'Discriminator loss 0.4265', 'Discriminator accuracy 0.7656', 'Total loss: 1.2251', 'for batch', 0)
('GAN loss 0.8372 ', 'GAN acc 0.2578', 'Discriminator loss 0.3867', 'Discriminator accuracy 0.7754', 'Total loss: 1.2239', 'for batch', 1)
('GAN loss 0.7792 ', 'GAN acc 0.3281', 'Discriminator loss 0.5106', 'Discriminator accuracy 0.7539', 'Total loss: 1.2898', 'for batch', 2)
('GAN loss 0.8179 ', 'GAN acc 0.3320', 'Discriminator loss 0.4182', 'Discriminator accuracy 0.7891', 'Total loss: 1.2361', 'for batch', 3)
('GAN loss 0.8112 ', 'GAN acc 0.3281', 'Discriminator loss 0.3888', 'Discriminator accuracy 0.7559', 'Total loss: 1.2000', 'for batch', 4)
('GAN loss 0.8590 ', 'GAN acc 0.2461', 'Discriminator loss 0.4158', 'Discriminator accuracy 0.7695', 'Total loss: 1.2747', 'for batch', 5)
('GAN loss 0.8829 ', 'GAN acc 0.2031', 'Discriminator loss 0.3757', 'Discriminator accuracy 0.8262', 'Total loss: 1.2586', 'for batch', 6)
('GAN loss 0.9209 ', 'GAN acc 0.1445', 'Discriminator loss 0.3170', 'Discriminator accuracy 0.8457', 'Total loss: 1.2379', 'for batch', 7)
('GAN loss 0.9321 ', 'GAN acc 0.1328', 'Discriminator loss 0.4910', 'Discriminator accuracy 0.8691', 'Total loss: 1.4231', 'for batch', 8)
('GAN loss 0.9144 ', 'GAN acc 0.1133', 'Discriminator loss 0.4512', 'Discriminator accuracy 0.8594', 'Total loss: 1.3656', 'for batch', 9)
('GAN loss 0.9062 ', 'GAN acc 0.1133', 'Discriminator loss 0.3486', 'Discriminator accuracy 0.9023', 'Total loss: 1.2548', 'for batch', 10)
('GAN loss 0.8646 ', 'GAN acc 0.1875', 'Discriminator loss 0.4374', 'Discriminator accuracy 0.8926', 'Total loss: 1.3020', 'for batch', 11)
('GAN loss 0.8776 ', 'GAN acc 0.1406', 'Discriminator loss 0.3601', 'Discriminator accuracy 0.8730', 'Total loss: 1.2377', 'for batch', 12)
('GAN loss 0.8688 ', 'GAN acc 0.1211', 'Discriminator loss 0.4184', 'Discriminator accuracy 0.8867', 'Total loss: 1.2872', 'for batch', 13)
('GAN loss 0.8873 ', 'GAN acc 0.1055', 'Discriminator loss 0.3516', 'Discriminator accuracy 0.8945', 'Total loss: 1.2389', 'for batch', 14)
('GAN loss 0.8867 ', 'GAN acc 0.0820', 'Discriminator loss 0.3908', 'Discriminator accuracy 0.9180', 'Total loss: 1.2775', 'for batch', 15)
('GAN loss 0.8975 ', 'GAN acc 0.1094', 'Discriminator loss 0.3750', 'Discriminator accuracy 0.9082', 'Total loss: 1.2724', 'for batch', 16)
('GAN loss 0.8537 ', 'GAN acc 0.1836', 'Discriminator loss 0.3101', 'Discriminator accuracy 0.9121', 'Total loss: 1.1638', 'for batch', 17)
('GAN loss 0.8328 ', 'GAN acc 0.1602', 'Discriminator loss 0.3563', 'Discriminator accuracy 0.8789', 'Total loss: 1.1891', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9685418)
('DISCRIMINATOR_Imagem FAKE=', 0.43576011)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.680819')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8489 ', 'GAN acc 0.2109', 'Discriminator loss 0.3447', 'Discriminator accuracy 0.8496', 'Total loss: 1.1936', 'for batch', 0)
('GAN loss 0.8683 ', 'GAN acc 0.2188', 'Discriminator loss 0.3557', 'Discriminator accuracy 0.8418', 'Total loss: 1.2240', 'for batch', 1)
('GAN loss 0.9029 ', 'GAN acc 0.2188', 'Discriminator loss 0.3811', 'Discriminator accuracy 0.8828', 'Total loss: 1.2840', 'for batch', 2)
('GAN loss 0.9269 ', 'GAN acc 0.1523', 'Discriminator loss 0.3580', 'Discriminator accuracy 0.8770', 'Total loss: 1.2849', 'for batch', 3)
('GAN loss 1.0088 ', 'GAN acc 0.0664', 'Discriminator loss 0.3664', 'Discriminator accuracy 0.8984', 'Total loss: 1.3752', 'for batch', 4)
('GAN loss 1.0399 ', 'GAN acc 0.0625', 'Discriminator loss 0.3420', 'Discriminator accuracy 0.9395', 'Total loss: 1.3819', 'for batch', 5)
('GAN loss 0.9926 ', 'GAN acc 0.0781', 'Discriminator loss 0.3671', 'Discriminator accuracy 0.9453', 'Total loss: 1.3597', 'for batch', 6)
('GAN loss 1.0284 ', 'GAN acc 0.0586', 'Discriminator loss 0.2659', 'Discriminator accuracy 0.9551', 'Total loss: 1.2943', 'for batch', 7)
('GAN loss 1.0087 ', 'GAN acc 0.0391', 'Discriminator loss 0.4105', 'Discriminator accuracy 0.9434', 'Total loss: 1.4193', 'for batch', 8)
('GAN loss 1.0385 ', 'GAN acc 0.0156', 'Discriminator loss 0.3270', 'Discriminator accuracy 0.9336', 'Total loss: 1.3655', 'for batch', 9)
('GAN loss 1.1048 ', 'GAN acc 0.0273', 'Discriminator loss 0.2482', 'Discriminator accuracy 0.9629', 'Total loss: 1.3529', 'for batch', 10)
('GAN loss 1.0809 ', 'GAN acc 0.0234', 'Discriminator loss 0.3682', 'Discriminator accuracy 0.9570', 'Total loss: 1.4491', 'for batch', 11)
('GAN loss 1.0565 ', 'GAN acc 0.0195', 'Discriminator loss 0.2908', 'Discriminator accuracy 0.9707', 'Total loss: 1.3474', 'for batch', 12)
('GAN loss 1.0684 ', 'GAN acc 0.0156', 'Discriminator loss 0.2577', 'Discriminator accuracy 0.9727', 'Total loss: 1.3261', 'for batch', 13)
('GAN loss 1.0235 ', 'GAN acc 0.0469', 'Discriminator loss 0.2652', 'Discriminator accuracy 0.9570', 'Total loss: 1.2887', 'for batch', 14)
('GAN loss 1.0336 ', 'GAN acc 0.0625', 'Discriminator loss 0.3009', 'Discriminator accuracy 0.9258', 'Total loss: 1.3345', 'for batch', 15)
('GAN loss 1.0817 ', 'GAN acc 0.0391', 'Discriminator loss 0.3192', 'Discriminator accuracy 0.9277', 'Total loss: 1.4009', 'for batch', 16)
('GAN loss 1.1910 ', 'GAN acc 0.0078', 'Discriminator loss 0.2891', 'Discriminator accuracy 0.9492', 'Total loss: 1.4802', 'for batch', 17)
('GAN loss 1.2559 ', 'GAN acc 0.0078', 'Discriminator loss 0.2862', 'Discriminator accuracy 0.9688', 'Total loss: 1.5421', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95941669)
('DISCRIMINATOR_Imagem FAKE=', 0.30201125)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.321348')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2567 ', 'GAN acc 0.0117', 'Discriminator loss 0.2752', 'Discriminator accuracy 0.9570', 'Total loss: 1.5319', 'for batch', 0)
('GAN loss 1.2273 ', 'GAN acc 0.0078', 'Discriminator loss 0.2686', 'Discriminator accuracy 0.9668', 'Total loss: 1.4959', 'for batch', 1)
('GAN loss 1.1681 ', 'GAN acc 0.0117', 'Discriminator loss 0.3373', 'Discriminator accuracy 0.9570', 'Total loss: 1.5054', 'for batch', 2)
('GAN loss 1.0794 ', 'GAN acc 0.0391', 'Discriminator loss 0.2470', 'Discriminator accuracy 0.9551', 'Total loss: 1.3264', 'for batch', 3)
('GAN loss 1.0822 ', 'GAN acc 0.0508', 'Discriminator loss 0.2779', 'Discriminator accuracy 0.9492', 'Total loss: 1.3600', 'for batch', 4)
('GAN loss 1.1565 ', 'GAN acc 0.0508', 'Discriminator loss 0.2431', 'Discriminator accuracy 0.9688', 'Total loss: 1.3997', 'for batch', 5)
('GAN loss 1.1628 ', 'GAN acc 0.0234', 'Discriminator loss 0.3092', 'Discriminator accuracy 0.9531', 'Total loss: 1.4719', 'for batch', 6)
('GAN loss 1.2964 ', 'GAN acc 0.0078', 'Discriminator loss 0.2349', 'Discriminator accuracy 0.9688', 'Total loss: 1.5312', 'for batch', 7)
('GAN loss 1.1816 ', 'GAN acc 0.0430', 'Discriminator loss 0.2760', 'Discriminator accuracy 0.9570', 'Total loss: 1.4575', 'for batch', 8)
('GAN loss 1.2020 ', 'GAN acc 0.0234', 'Discriminator loss 0.2614', 'Discriminator accuracy 0.9453', 'Total loss: 1.4635', 'for batch', 9)
('GAN loss 1.2697 ', 'GAN acc 0.0469', 'Discriminator loss 0.2423', 'Discriminator accuracy 0.9355', 'Total loss: 1.5121', 'for batch', 10)
('GAN loss 1.2963 ', 'GAN acc 0.0430', 'Discriminator loss 0.3492', 'Discriminator accuracy 0.9395', 'Total loss: 1.6455', 'for batch', 11)
('GAN loss 1.2817 ', 'GAN acc 0.0195', 'Discriminator loss 0.3102', 'Discriminator accuracy 0.9414', 'Total loss: 1.5920', 'for batch', 12)
('GAN loss 1.3013 ', 'GAN acc 0.0039', 'Discriminator loss 0.2911', 'Discriminator accuracy 0.9648', 'Total loss: 1.5924', 'for batch', 13)
('GAN loss 1.4114 ', 'GAN acc 0.0117', 'Discriminator loss 0.3070', 'Discriminator accuracy 0.9570', 'Total loss: 1.7184', 'for batch', 14)
('GAN loss 1.4201 ', 'GAN acc 0.0039', 'Discriminator loss 0.2608', 'Discriminator accuracy 0.9473', 'Total loss: 1.6809', 'for batch', 15)
('GAN loss 1.5058 ', 'GAN acc 0.0000', 'Discriminator loss 0.2815', 'Discriminator accuracy 0.9551', 'Total loss: 1.7873', 'for batch', 16)
('GAN loss 1.4366 ', 'GAN acc 0.0078', 'Discriminator loss 0.2461', 'Discriminator accuracy 0.9688', 'Total loss: 1.6827', 'for batch', 17)
('GAN loss 1.3978 ', 'GAN acc 0.0039', 'Discriminator loss 0.2832', 'Discriminator accuracy 0.9707', 'Total loss: 1.6809', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95793992)
('DISCRIMINATOR_Imagem FAKE=', 0.28252721)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.851462')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 1.3797 ', 'GAN acc 0.0000', 'Discriminator loss 0.2547', 'Discriminator accuracy 0.9609', 'Total loss: 1.6344', 'for batch', 0)
('GAN loss 1.4988 ', 'GAN acc 0.0078', 'Discriminator loss 0.2298', 'Discriminator accuracy 0.9707', 'Total loss: 1.7287', 'for batch', 1)
('GAN loss 1.5647 ', 'GAN acc 0.0000', 'Discriminator loss 0.3972', 'Discriminator accuracy 0.9629', 'Total loss: 1.9619', 'for batch', 2)
('GAN loss 1.5736 ', 'GAN acc 0.0000', 'Discriminator loss 0.2427', 'Discriminator accuracy 0.9707', 'Total loss: 1.8163', 'for batch', 3)
('GAN loss 1.6738 ', 'GAN acc 0.0000', 'Discriminator loss 0.2084', 'Discriminator accuracy 0.9668', 'Total loss: 1.8822', 'for batch', 4)
('GAN loss 1.7821 ', 'GAN acc 0.0000', 'Discriminator loss 0.2307', 'Discriminator accuracy 0.9766', 'Total loss: 2.0127', 'for batch', 5)
('GAN loss 1.7350 ', 'GAN acc 0.0039', 'Discriminator loss 0.2159', 'Discriminator accuracy 0.9648', 'Total loss: 1.9509', 'for batch', 6)
('GAN loss 1.7322 ', 'GAN acc 0.0000', 'Discriminator loss 0.1431', 'Discriminator accuracy 0.9785', 'Total loss: 1.8753', 'for batch', 7)
('GAN loss 1.7240 ', 'GAN acc 0.0000', 'Discriminator loss 0.3221', 'Discriminator accuracy 0.9551', 'Total loss: 2.0461', 'for batch', 8)
('GAN loss 1.6640 ', 'GAN acc 0.0000', 'Discriminator loss 0.2918', 'Discriminator accuracy 0.9570', 'Total loss: 1.9559', 'for batch', 9)
('GAN loss 1.5974 ', 'GAN acc 0.0039', 'Discriminator loss 0.1541', 'Discriminator accuracy 0.9844', 'Total loss: 1.7515', 'for batch', 10)
('GAN loss 1.5149 ', 'GAN acc 0.0117', 'Discriminator loss 0.2729', 'Discriminator accuracy 0.9648', 'Total loss: 1.7878', 'for batch', 11)
('GAN loss 1.5164 ', 'GAN acc 0.0078', 'Discriminator loss 0.1976', 'Discriminator accuracy 0.9727', 'Total loss: 1.7140', 'for batch', 12)
('GAN loss 1.4275 ', 'GAN acc 0.0195', 'Discriminator loss 0.2569', 'Discriminator accuracy 0.9707', 'Total loss: 1.6843', 'for batch', 13)
('GAN loss 1.4026 ', 'GAN acc 0.0234', 'Discriminator loss 0.2247', 'Discriminator accuracy 0.9609', 'Total loss: 1.6273', 'for batch', 14)
('GAN loss 1.6510 ', 'GAN acc 0.0039', 'Discriminator loss 0.2520', 'Discriminator accuracy 0.9492', 'Total loss: 1.9030', 'for batch', 15)
('GAN loss 1.7277 ', 'GAN acc 0.0039', 'Discriminator loss 0.2582', 'Discriminator accuracy 0.9590', 'Total loss: 1.9859', 'for batch', 16)
('GAN loss 1.9409 ', 'GAN acc 0.0000', 'Discriminator loss 0.1898', 'Discriminator accuracy 0.9727', 'Total loss: 2.1308', 'for batch', 17)
('GAN loss 2.1741 ', 'GAN acc 0.0000', 'Discriminator loss 0.2350', 'Discriminator accuracy 0.9688', 'Total loss: 2.4091', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95180678)
('DISCRIMINATOR_Imagem FAKE=', 0.12348698)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.408958')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 1.9444 ', 'GAN acc 0.0000', 'Discriminator loss 0.2456', 'Discriminator accuracy 0.9629', 'Total loss: 2.1900', 'for batch', 0)
('GAN loss 1.8185 ', 'GAN acc 0.0000', 'Discriminator loss 0.1986', 'Discriminator accuracy 0.9727', 'Total loss: 2.0172', 'for batch', 1)
('GAN loss 1.5087 ', 'GAN acc 0.0117', 'Discriminator loss 0.2593', 'Discriminator accuracy 0.9648', 'Total loss: 1.7679', 'for batch', 2)
('GAN loss 1.4222 ', 'GAN acc 0.0312', 'Discriminator loss 0.2070', 'Discriminator accuracy 0.9570', 'Total loss: 1.6292', 'for batch', 3)
('GAN loss 1.6776 ', 'GAN acc 0.0039', 'Discriminator loss 0.2167', 'Discriminator accuracy 0.9570', 'Total loss: 1.8943', 'for batch', 4)
('GAN loss 1.9465 ', 'GAN acc 0.0039', 'Discriminator loss 0.1826', 'Discriminator accuracy 0.9727', 'Total loss: 2.1290', 'for batch', 5)
('GAN loss 1.8725 ', 'GAN acc 0.0000', 'Discriminator loss 0.2179', 'Discriminator accuracy 0.9648', 'Total loss: 2.0903', 'for batch', 6)
('GAN loss 2.0128 ', 'GAN acc 0.0000', 'Discriminator loss 0.1200', 'Discriminator accuracy 0.9883', 'Total loss: 2.1329', 'for batch', 7)
('GAN loss 1.8570 ', 'GAN acc 0.0000', 'Discriminator loss 0.2801', 'Discriminator accuracy 0.9551', 'Total loss: 2.1371', 'for batch', 8)
('GAN loss 1.7793 ', 'GAN acc 0.0000', 'Discriminator loss 0.1986', 'Discriminator accuracy 0.9668', 'Total loss: 1.9779', 'for batch', 9)
('GAN loss 1.8932 ', 'GAN acc 0.0000', 'Discriminator loss 0.1587', 'Discriminator accuracy 0.9863', 'Total loss: 2.0519', 'for batch', 10)
('GAN loss 1.8897 ', 'GAN acc 0.0000', 'Discriminator loss 0.2357', 'Discriminator accuracy 0.9668', 'Total loss: 2.1254', 'for batch', 11)
('GAN loss 1.8758 ', 'GAN acc 0.0000', 'Discriminator loss 0.1921', 'Discriminator accuracy 0.9746', 'Total loss: 2.0679', 'for batch', 12)
('GAN loss 1.9022 ', 'GAN acc 0.0000', 'Discriminator loss 0.1635', 'Discriminator accuracy 0.9824', 'Total loss: 2.0657', 'for batch', 13)
('GAN loss 1.9086 ', 'GAN acc 0.0039', 'Discriminator loss 0.1923', 'Discriminator accuracy 0.9688', 'Total loss: 2.1009', 'for batch', 14)
('GAN loss 1.8134 ', 'GAN acc 0.0000', 'Discriminator loss 0.2016', 'Discriminator accuracy 0.9570', 'Total loss: 2.0149', 'for batch', 15)
('GAN loss 1.7326 ', 'GAN acc 0.0234', 'Discriminator loss 0.2288', 'Discriminator accuracy 0.9473', 'Total loss: 1.9615', 'for batch', 16)
('GAN loss 1.9825 ', 'GAN acc 0.0000', 'Discriminator loss 0.1694', 'Discriminator accuracy 0.9648', 'Total loss: 2.1519', 'for batch', 17)
('GAN loss 2.0544 ', 'GAN acc 0.0000', 'Discriminator loss 0.2022', 'Discriminator accuracy 0.9766', 'Total loss: 2.2566', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95542186)
('DISCRIMINATOR_Imagem FAKE=', 0.14125699)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.926655')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 2.1203 ', 'GAN acc 0.0039', 'Discriminator loss 0.1880', 'Discriminator accuracy 0.9688', 'Total loss: 2.3083', 'for batch', 0)
('GAN loss 2.1704 ', 'GAN acc 0.0000', 'Discriminator loss 0.1678', 'Discriminator accuracy 0.9707', 'Total loss: 2.3382', 'for batch', 1)
('GAN loss 2.0008 ', 'GAN acc 0.0000', 'Discriminator loss 0.2426', 'Discriminator accuracy 0.9648', 'Total loss: 2.2434', 'for batch', 2)
('GAN loss 1.7618 ', 'GAN acc 0.0039', 'Discriminator loss 0.1624', 'Discriminator accuracy 0.9746', 'Total loss: 1.9242', 'for batch', 3)
('GAN loss 1.8649 ', 'GAN acc 0.0000', 'Discriminator loss 0.1745', 'Discriminator accuracy 0.9727', 'Total loss: 2.0394', 'for batch', 4)
('GAN loss 2.2112 ', 'GAN acc 0.0000', 'Discriminator loss 0.1358', 'Discriminator accuracy 0.9824', 'Total loss: 2.3469', 'for batch', 5)
('GAN loss 2.3955 ', 'GAN acc 0.0000', 'Discriminator loss 0.1678', 'Discriminator accuracy 0.9707', 'Total loss: 2.5633', 'for batch', 6)
('GAN loss 2.5245 ', 'GAN acc 0.0000', 'Discriminator loss 0.0961', 'Discriminator accuracy 0.9863', 'Total loss: 2.6206', 'for batch', 7)
('GAN loss 2.3358 ', 'GAN acc 0.0000', 'Discriminator loss 0.2149', 'Discriminator accuracy 0.9609', 'Total loss: 2.5507', 'for batch', 8)
('GAN loss 2.2431 ', 'GAN acc 0.0000', 'Discriminator loss 0.1699', 'Discriminator accuracy 0.9668', 'Total loss: 2.4130', 'for batch', 9)
('GAN loss 2.2485 ', 'GAN acc 0.0000', 'Discriminator loss 0.1001', 'Discriminator accuracy 0.9922', 'Total loss: 2.3486', 'for batch', 10)
('GAN loss 2.2004 ', 'GAN acc 0.0000', 'Discriminator loss 0.1911', 'Discriminator accuracy 0.9707', 'Total loss: 2.3916', 'for batch', 11)
('GAN loss 2.0596 ', 'GAN acc 0.0000', 'Discriminator loss 0.1604', 'Discriminator accuracy 0.9805', 'Total loss: 2.2200', 'for batch', 12)
('GAN loss 1.9945 ', 'GAN acc 0.0000', 'Discriminator loss 0.1478', 'Discriminator accuracy 0.9766', 'Total loss: 2.1423', 'for batch', 13)
('GAN loss 2.2266 ', 'GAN acc 0.0000', 'Discriminator loss 0.1638', 'Discriminator accuracy 0.9746', 'Total loss: 2.3904', 'for batch', 14)
('GAN loss 2.3532 ', 'GAN acc 0.0000', 'Discriminator loss 0.1994', 'Discriminator accuracy 0.9609', 'Total loss: 2.5526', 'for batch', 15)
('GAN loss 2.3945 ', 'GAN acc 0.0000', 'Discriminator loss 0.1791', 'Discriminator accuracy 0.9648', 'Total loss: 2.5736', 'for batch', 16)
('GAN loss 2.5945 ', 'GAN acc 0.0039', 'Discriminator loss 0.1200', 'Discriminator accuracy 0.9785', 'Total loss: 2.7145', 'for batch', 17)
('GAN loss 2.7041 ', 'GAN acc 0.0000', 'Discriminator loss 0.1647', 'Discriminator accuracy 0.9746', 'Total loss: 2.8688', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95090377)
('DISCRIMINATOR_Imagem FAKE=', 0.082766727)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.512632')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 2.4856 ', 'GAN acc 0.0039', 'Discriminator loss 0.1682', 'Discriminator accuracy 0.9668', 'Total loss: 2.6538', 'for batch', 0)
('GAN loss 2.3802 ', 'GAN acc 0.0039', 'Discriminator loss 0.1496', 'Discriminator accuracy 0.9707', 'Total loss: 2.5298', 'for batch', 1)
('GAN loss 2.2538 ', 'GAN acc 0.0000', 'Discriminator loss 0.1330', 'Discriminator accuracy 0.9766', 'Total loss: 2.3867', 'for batch', 2)
('GAN loss 1.9270 ', 'GAN acc 0.0000', 'Discriminator loss 0.1552', 'Discriminator accuracy 0.9766', 'Total loss: 2.0823', 'for batch', 3)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 2018435
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 16, 16)    608         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 32, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      18496       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 64, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 4, 4)     73856       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 128, 4, 4)     0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 4, 4)     0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 2, 2)     295168      dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 256, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           262400      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 650785
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5621 ', 'GAN acc 0.7305', 'Discriminator loss 4.8536', 'Discriminator accuracy 0.4863', 'Total loss: 5.4157', 'for batch', 0)
('GAN loss 0.2315 ', 'GAN acc 0.9961', 'Discriminator loss 1.5884', 'Discriminator accuracy 0.4199', 'Total loss: 1.8199', 'for batch', 1)
('GAN loss 0.1613 ', 'GAN acc 0.9961', 'Discriminator loss 1.0101', 'Discriminator accuracy 0.4746', 'Total loss: 1.1714', 'for batch', 2)
('GAN loss 0.1654 ', 'GAN acc 0.9961', 'Discriminator loss 1.1418', 'Discriminator accuracy 0.4824', 'Total loss: 1.3073', 'for batch', 3)
('GAN loss 0.2259 ', 'GAN acc 0.9961', 'Discriminator loss 1.1066', 'Discriminator accuracy 0.4785', 'Total loss: 1.3325', 'for batch', 4)
('GAN loss 0.3628 ', 'GAN acc 0.9375', 'Discriminator loss 0.9726', 'Discriminator accuracy 0.4902', 'Total loss: 1.3354', 'for batch', 5)
('GAN loss 0.4609 ', 'GAN acc 0.8594', 'Discriminator loss 0.7527', 'Discriminator accuracy 0.4941', 'Total loss: 1.2135', 'for batch', 6)
('GAN loss 0.6256 ', 'GAN acc 0.6562', 'Discriminator loss 0.5982', 'Discriminator accuracy 0.5586', 'Total loss: 1.2238', 'for batch', 7)
('GAN loss 0.6405 ', 'GAN acc 0.6562', 'Discriminator loss 0.6756', 'Discriminator accuracy 0.5840', 'Total loss: 1.3161', 'for batch', 8)
('GAN loss 0.5658 ', 'GAN acc 0.7227', 'Discriminator loss 0.7456', 'Discriminator accuracy 0.5293', 'Total loss: 1.3115', 'for batch', 9)
('GAN loss 0.5541 ', 'GAN acc 0.7734', 'Discriminator loss 0.5490', 'Discriminator accuracy 0.5879', 'Total loss: 1.1031', 'for batch', 10)
('GAN loss 0.6144 ', 'GAN acc 0.6641', 'Discriminator loss 0.5806', 'Discriminator accuracy 0.5586', 'Total loss: 1.1950', 'for batch', 11)
('GAN loss 0.7164 ', 'GAN acc 0.5156', 'Discriminator loss 0.5533', 'Discriminator accuracy 0.5957', 'Total loss: 1.2697', 'for batch', 12)
('GAN loss 0.7497 ', 'GAN acc 0.4336', 'Discriminator loss 0.4579', 'Discriminator accuracy 0.6719', 'Total loss: 1.2076', 'for batch', 13)
('GAN loss 0.7914 ', 'GAN acc 0.3555', 'Discriminator loss 0.4650', 'Discriminator accuracy 0.6855', 'Total loss: 1.2564', 'for batch', 14)
('GAN loss 0.8147 ', 'GAN acc 0.3516', 'Discriminator loss 0.4340', 'Discriminator accuracy 0.7070', 'Total loss: 1.2488', 'for batch', 15)
('GAN loss 0.8342 ', 'GAN acc 0.3242', 'Discriminator loss 0.4613', 'Discriminator accuracy 0.7148', 'Total loss: 1.2956', 'for batch', 16)
('GAN loss 0.8367 ', 'GAN acc 0.3633', 'Discriminator loss 0.4328', 'Discriminator accuracy 0.7246', 'Total loss: 1.2695', 'for batch', 17)
('GAN loss 0.8925 ', 'GAN acc 0.2539', 'Discriminator loss 0.4824', 'Discriminator accuracy 0.7500', 'Total loss: 1.3748', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96303821)
('DISCRIMINATOR_Imagem FAKE=', 0.45013487)
('Discriminator trained', 14, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.195994')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8831 ', 'GAN acc 0.2734', 'Discriminator loss 0.4935', 'Discriminator accuracy 0.7715', 'Total loss: 1.3766', 'for batch', 0)
('GAN loss 0.8711 ', 'GAN acc 0.2539', 'Discriminator loss 0.4024', 'Discriminator accuracy 0.7695', 'Total loss: 1.2735', 'for batch', 1)
('GAN loss 0.6756 ', 'GAN acc 0.5859', 'Discriminator loss 0.5862', 'Discriminator accuracy 0.6289', 'Total loss: 1.2618', 'for batch', 2)
('GAN loss 0.7296 ', 'GAN acc 0.4883', 'Discriminator loss 0.5092', 'Discriminator accuracy 0.6328', 'Total loss: 1.2388', 'for batch', 3)
('GAN loss 0.7201 ', 'GAN acc 0.4609', 'Discriminator loss 0.4773', 'Discriminator accuracy 0.6484', 'Total loss: 1.1974', 'for batch', 4)
('GAN loss 0.8296 ', 'GAN acc 0.3594', 'Discriminator loss 0.5053', 'Discriminator accuracy 0.7148', 'Total loss: 1.3349', 'for batch', 5)
('GAN loss 0.9104 ', 'GAN acc 0.2266', 'Discriminator loss 0.4557', 'Discriminator accuracy 0.7695', 'Total loss: 1.3661', 'for batch', 6)
('GAN loss 0.9040 ', 'GAN acc 0.1992', 'Discriminator loss 0.3703', 'Discriminator accuracy 0.7598', 'Total loss: 1.2743', 'for batch', 7)
('GAN loss 0.9386 ', 'GAN acc 0.2305', 'Discriminator loss 0.4408', 'Discriminator accuracy 0.8066', 'Total loss: 1.3794', 'for batch', 8)
('GAN loss 0.8646 ', 'GAN acc 0.2812', 'Discriminator loss 0.3984', 'Discriminator accuracy 0.8086', 'Total loss: 1.2630', 'for batch', 9)
('GAN loss 0.8699 ', 'GAN acc 0.2617', 'Discriminator loss 0.3517', 'Discriminator accuracy 0.7578', 'Total loss: 1.2216', 'for batch', 10)
('GAN loss 0.7066 ', 'GAN acc 0.5312', 'Discriminator loss 0.5005', 'Discriminator accuracy 0.6523', 'Total loss: 1.2071', 'for batch', 11)
('GAN loss 0.6894 ', 'GAN acc 0.5664', 'Discriminator loss 0.5424', 'Discriminator accuracy 0.6582', 'Total loss: 1.2318', 'for batch', 12)
('GAN loss 0.7437 ', 'GAN acc 0.4492', 'Discriminator loss 0.4798', 'Discriminator accuracy 0.6738', 'Total loss: 1.2235', 'for batch', 13)
('GAN loss 0.7263 ', 'GAN acc 0.4648', 'Discriminator loss 0.4673', 'Discriminator accuracy 0.7090', 'Total loss: 1.1935', 'for batch', 14)
('GAN loss 0.7530 ', 'GAN acc 0.4297', 'Discriminator loss 0.5014', 'Discriminator accuracy 0.6992', 'Total loss: 1.2544', 'for batch', 15)
('GAN loss 0.7622 ', 'GAN acc 0.4180', 'Discriminator loss 0.4809', 'Discriminator accuracy 0.7207', 'Total loss: 1.2431', 'for batch', 16)
('GAN loss 0.7812 ', 'GAN acc 0.3828', 'Discriminator loss 0.3983', 'Discriminator accuracy 0.7207', 'Total loss: 1.1795', 'for batch', 17)
('GAN loss 0.8232 ', 'GAN acc 0.2695', 'Discriminator loss 0.4622', 'Discriminator accuracy 0.7754', 'Total loss: 1.2854', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96479052)
('DISCRIMINATOR_Imagem FAKE=', 0.45548728)
('Discriminator trained', 3, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.125284')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8512 ', 'GAN acc 0.2461', 'Discriminator loss 0.4004', 'Discriminator accuracy 0.7305', 'Total loss: 1.2516', 'for batch', 0)
('GAN loss 0.9354 ', 'GAN acc 0.1016', 'Discriminator loss 0.3769', 'Discriminator accuracy 0.8105', 'Total loss: 1.3123', 'for batch', 1)
('GAN loss 0.9735 ', 'GAN acc 0.1133', 'Discriminator loss 0.4644', 'Discriminator accuracy 0.8730', 'Total loss: 1.4379', 'for batch', 2)
('GAN loss 0.9870 ', 'GAN acc 0.0898', 'Discriminator loss 0.3777', 'Discriminator accuracy 0.8887', 'Total loss: 1.3646', 'for batch', 3)
('GAN loss 0.9583 ', 'GAN acc 0.1133', 'Discriminator loss 0.3192', 'Discriminator accuracy 0.9004', 'Total loss: 1.2775', 'for batch', 4)
('GAN loss 0.9609 ', 'GAN acc 0.1211', 'Discriminator loss 0.3918', 'Discriminator accuracy 0.9004', 'Total loss: 1.3527', 'for batch', 5)
('GAN loss 0.8956 ', 'GAN acc 0.1406', 'Discriminator loss 0.3689', 'Discriminator accuracy 0.8848', 'Total loss: 1.2646', 'for batch', 6)
('GAN loss 0.9320 ', 'GAN acc 0.1133', 'Discriminator loss 0.2947', 'Discriminator accuracy 0.9004', 'Total loss: 1.2267', 'for batch', 7)
('GAN loss 0.9493 ', 'GAN acc 0.1289', 'Discriminator loss 0.4612', 'Discriminator accuracy 0.9043', 'Total loss: 1.4105', 'for batch', 8)
('GAN loss 0.9894 ', 'GAN acc 0.0547', 'Discriminator loss 0.3435', 'Discriminator accuracy 0.9004', 'Total loss: 1.3329', 'for batch', 9)
('GAN loss 0.9593 ', 'GAN acc 0.0938', 'Discriminator loss 0.2967', 'Discriminator accuracy 0.9355', 'Total loss: 1.2559', 'for batch', 10)
('GAN loss 0.9493 ', 'GAN acc 0.0625', 'Discriminator loss 0.4089', 'Discriminator accuracy 0.9180', 'Total loss: 1.3583', 'for batch', 11)
('GAN loss 0.9331 ', 'GAN acc 0.0898', 'Discriminator loss 0.3623', 'Discriminator accuracy 0.9238', 'Total loss: 1.2954', 'for batch', 12)
('GAN loss 0.9135 ', 'GAN acc 0.1172', 'Discriminator loss 0.3872', 'Discriminator accuracy 0.9375', 'Total loss: 1.3007', 'for batch', 13)
('GAN loss 0.9347 ', 'GAN acc 0.0938', 'Discriminator loss 0.3444', 'Discriminator accuracy 0.9160', 'Total loss: 1.2790', 'for batch', 14)
('GAN loss 0.9047 ', 'GAN acc 0.1055', 'Discriminator loss 0.4000', 'Discriminator accuracy 0.9004', 'Total loss: 1.3047', 'for batch', 15)
('GAN loss 0.9496 ', 'GAN acc 0.0898', 'Discriminator loss 0.3964', 'Discriminator accuracy 0.8848', 'Total loss: 1.3461', 'for batch', 16)
('GAN loss 0.9230 ', 'GAN acc 0.1328', 'Discriminator loss 0.3353', 'Discriminator accuracy 0.8633', 'Total loss: 1.2584', 'for batch', 17)
('GAN loss 0.9274 ', 'GAN acc 0.0938', 'Discriminator loss 0.3754', 'Discriminator accuracy 0.8906', 'Total loss: 1.3027', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96215969)
('DISCRIMINATOR_Imagem FAKE=', 0.41439703)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.767820')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9307 ', 'GAN acc 0.0977', 'Discriminator loss 0.3505', 'Discriminator accuracy 0.8789', 'Total loss: 1.2812', 'for batch', 0)
('GAN loss 0.9427 ', 'GAN acc 0.0898', 'Discriminator loss 0.3581', 'Discriminator accuracy 0.9141', 'Total loss: 1.3008', 'for batch', 1)
('GAN loss 0.9088 ', 'GAN acc 0.0977', 'Discriminator loss 0.4201', 'Discriminator accuracy 0.9082', 'Total loss: 1.3289', 'for batch', 2)
('GAN loss 0.9145 ', 'GAN acc 0.1211', 'Discriminator loss 0.3549', 'Discriminator accuracy 0.9004', 'Total loss: 1.2695', 'for batch', 3)
('GAN loss 0.9480 ', 'GAN acc 0.1328', 'Discriminator loss 0.3744', 'Discriminator accuracy 0.8965', 'Total loss: 1.3223', 'for batch', 4)
('GAN loss 0.9732 ', 'GAN acc 0.0898', 'Discriminator loss 0.3186', 'Discriminator accuracy 0.9316', 'Total loss: 1.2919', 'for batch', 5)
('GAN loss 1.0029 ', 'GAN acc 0.0430', 'Discriminator loss 0.3791', 'Discriminator accuracy 0.9414', 'Total loss: 1.3820', 'for batch', 6)
('GAN loss 1.0731 ', 'GAN acc 0.0469', 'Discriminator loss 0.2596', 'Discriminator accuracy 0.9629', 'Total loss: 1.3328', 'for batch', 7)
('GAN loss 1.0217 ', 'GAN acc 0.0742', 'Discriminator loss 0.4240', 'Discriminator accuracy 0.9121', 'Total loss: 1.4457', 'for batch', 8)
('GAN loss 1.0230 ', 'GAN acc 0.0469', 'Discriminator loss 0.3207', 'Discriminator accuracy 0.9277', 'Total loss: 1.3437', 'for batch', 9)
('GAN loss 1.0608 ', 'GAN acc 0.0664', 'Discriminator loss 0.2884', 'Discriminator accuracy 0.9141', 'Total loss: 1.3492', 'for batch', 10)
('GAN loss 1.0023 ', 'GAN acc 0.0938', 'Discriminator loss 0.4403', 'Discriminator accuracy 0.9199', 'Total loss: 1.4426', 'for batch', 11)
('GAN loss 0.9502 ', 'GAN acc 0.1211', 'Discriminator loss 0.3309', 'Discriminator accuracy 0.9141', 'Total loss: 1.2811', 'for batch', 12)
('GAN loss 0.9711 ', 'GAN acc 0.1016', 'Discriminator loss 0.3075', 'Discriminator accuracy 0.9160', 'Total loss: 1.2787', 'for batch', 13)
('GAN loss 0.9967 ', 'GAN acc 0.0820', 'Discriminator loss 0.3102', 'Discriminator accuracy 0.9316', 'Total loss: 1.3069', 'for batch', 14)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 2018435
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 16, 16)    608         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 32, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      18496       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 64, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 4, 4)     73856       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 128, 4, 4)     0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 4, 4)     0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 2, 2)     295168      dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 256, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           262400      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 650785
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 2018435
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 32, 16, 16)    608         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 32, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 32, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 64, 8, 8)      18496       dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 64, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 64, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 128, 4, 4)     73856       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 128, 4, 4)     0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 128, 4, 4)     0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 256, 2, 2)     295168      dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 256, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 256, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 1024)          0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           262400      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 650785
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5621 ', 'GAN acc 0.7305', 'Discriminator loss 4.8536', 'Discriminator accuracy 0.4863', 'Total loss: 5.4157', 'for batch', 0)
('GAN loss 0.2315 ', 'GAN acc 0.9961', 'Discriminator loss 1.5884', 'Discriminator accuracy 0.4199', 'Total loss: 1.8199', 'for batch', 1)
('GAN loss 0.1613 ', 'GAN acc 0.9961', 'Discriminator loss 1.0101', 'Discriminator accuracy 0.4746', 'Total loss: 1.1714', 'for batch', 2)
('GAN loss 0.1654 ', 'GAN acc 0.9961', 'Discriminator loss 1.1422', 'Discriminator accuracy 0.4824', 'Total loss: 1.3076', 'for batch', 3)
('GAN loss 0.2258 ', 'GAN acc 0.9961', 'Discriminator loss 1.1068', 'Discriminator accuracy 0.4785', 'Total loss: 1.3326', 'for batch', 4)
('GAN loss 0.3594 ', 'GAN acc 0.9414', 'Discriminator loss 0.9702', 'Discriminator accuracy 0.4883', 'Total loss: 1.3296', 'for batch', 5)
('GAN loss 0.4623 ', 'GAN acc 0.8594', 'Discriminator loss 0.7548', 'Discriminator accuracy 0.4961', 'Total loss: 1.2171', 'for batch', 6)
('GAN loss 0.6234 ', 'GAN acc 0.6562', 'Discriminator loss 0.5962', 'Discriminator accuracy 0.5469', 'Total loss: 1.2197', 'for batch', 7)
('GAN loss 0.6484 ', 'GAN acc 0.6016', 'Discriminator loss 0.6692', 'Discriminator accuracy 0.5840', 'Total loss: 1.3176', 'for batch', 8)
('GAN loss 0.5784 ', 'GAN acc 0.7383', 'Discriminator loss 0.7372', 'Discriminator accuracy 0.5430', 'Total loss: 1.3156', 'for batch', 9)
('GAN loss 0.5556 ', 'GAN acc 0.7617', 'Discriminator loss 0.5407', 'Discriminator accuracy 0.5898', 'Total loss: 1.0962', 'for batch', 10)
('GAN loss 0.6027 ', 'GAN acc 0.7070', 'Discriminator loss 0.5736', 'Discriminator accuracy 0.5645', 'Total loss: 1.1763', 'for batch', 11)
('GAN loss 0.6809 ', 'GAN acc 0.5781', 'Discriminator loss 0.5693', 'Discriminator accuracy 0.5996', 'Total loss: 1.2502', 'for batch', 12)
('GAN loss 0.6934 ', 'GAN acc 0.5469', 'Discriminator loss 0.4926', 'Discriminator accuracy 0.6152', 'Total loss: 1.1860', 'for batch', 13)
('GAN loss 0.7155 ', 'GAN acc 0.5352', 'Discriminator loss 0.5143', 'Discriminator accuracy 0.6211', 'Total loss: 1.2298', 'for batch', 14)
('GAN loss 0.7421 ', 'GAN acc 0.4961', 'Discriminator loss 0.5024', 'Discriminator accuracy 0.6074', 'Total loss: 1.2444', 'for batch', 15)
('GAN loss 0.6979 ', 'GAN acc 0.5742', 'Discriminator loss 0.5726', 'Discriminator accuracy 0.5938', 'Total loss: 1.2705', 'for batch', 16)
('GAN loss 0.7509 ', 'GAN acc 0.4570', 'Discriminator loss 0.4843', 'Discriminator accuracy 0.6582', 'Total loss: 1.2352', 'for batch', 17)
('GAN loss 0.7617 ', 'GAN acc 0.3945', 'Discriminator loss 0.5155', 'Discriminator accuracy 0.6758', 'Total loss: 1.2772', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96253979)
('DISCRIMINATOR_Imagem FAKE=', 0.47909769)
('Discriminator trained', 18, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.212448')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7180 ', 'GAN acc 0.5195', 'Discriminator loss 0.5520', 'Discriminator accuracy 0.6777', 'Total loss: 1.2700', 'for batch', 0)
('GAN loss 0.7115 ', 'GAN acc 0.5156', 'Discriminator loss 0.4729', 'Discriminator accuracy 0.6309', 'Total loss: 1.1844', 'for batch', 1)
('GAN loss 0.7414 ', 'GAN acc 0.4414', 'Discriminator loss 0.5505', 'Discriminator accuracy 0.6680', 'Total loss: 1.2919', 'for batch', 2)
('GAN loss 0.8056 ', 'GAN acc 0.3477', 'Discriminator loss 0.4414', 'Discriminator accuracy 0.7129', 'Total loss: 1.2470', 'for batch', 3)
('GAN loss 0.7560 ', 'GAN acc 0.4375', 'Discriminator loss 0.4348', 'Discriminator accuracy 0.7363', 'Total loss: 1.1908', 'for batch', 4)
('GAN loss 0.8134 ', 'GAN acc 0.3359', 'Discriminator loss 0.4815', 'Discriminator accuracy 0.7500', 'Total loss: 1.2948', 'for batch', 5)
('GAN loss 0.8592 ', 'GAN acc 0.2539', 'Discriminator loss 0.4492', 'Discriminator accuracy 0.7500', 'Total loss: 1.3084', 'for batch', 6)
('GAN loss 0.9237 ', 'GAN acc 0.2070', 'Discriminator loss 0.3487', 'Discriminator accuracy 0.7930', 'Total loss: 1.2724', 'for batch', 7)
('GAN loss 0.9134 ', 'GAN acc 0.2305', 'Discriminator loss 0.4621', 'Discriminator accuracy 0.7734', 'Total loss: 1.3755', 'for batch', 8)
('GAN loss 0.8306 ', 'GAN acc 0.3320', 'Discriminator loss 0.3889', 'Discriminator accuracy 0.7559', 'Total loss: 1.2195', 'for batch', 9)
('GAN loss 0.8260 ', 'GAN acc 0.3008', 'Discriminator loss 0.3684', 'Discriminator accuracy 0.7383', 'Total loss: 1.1945', 'for batch', 10)
('GAN loss 0.7846 ', 'GAN acc 0.3555', 'Discriminator loss 0.5041', 'Discriminator accuracy 0.7207', 'Total loss: 1.2887', 'for batch', 11)
('GAN loss 0.7533 ', 'GAN acc 0.4219', 'Discriminator loss 0.4783', 'Discriminator accuracy 0.7129', 'Total loss: 1.2316', 'for batch', 12)
('GAN loss 0.8514 ', 'GAN acc 0.2891', 'Discriminator loss 0.4193', 'Discriminator accuracy 0.7363', 'Total loss: 1.2706', 'for batch', 13)
('GAN loss 0.8859 ', 'GAN acc 0.1797', 'Discriminator loss 0.4143', 'Discriminator accuracy 0.7812', 'Total loss: 1.3002', 'for batch', 14)
('GAN loss 0.8978 ', 'GAN acc 0.1602', 'Discriminator loss 0.4434', 'Discriminator accuracy 0.8438', 'Total loss: 1.3411', 'for batch', 15)
('GAN loss 0.9073 ', 'GAN acc 0.1562', 'Discriminator loss 0.3997', 'Discriminator accuracy 0.8789', 'Total loss: 1.3070', 'for batch', 16)
('GAN loss 0.8952 ', 'GAN acc 0.1719', 'Discriminator loss 0.3389', 'Discriminator accuracy 0.8672', 'Total loss: 1.2341', 'for batch', 17)
('GAN loss 0.8541 ', 'GAN acc 0.1875', 'Discriminator loss 0.4667', 'Discriminator accuracy 0.8652', 'Total loss: 1.3208', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96611571)
('DISCRIMINATOR_Imagem FAKE=', 0.43501282)
('Discriminator trained', 1, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.199217')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7971 ', 'GAN acc 0.3008', 'Discriminator loss 0.3735', 'Discriminator accuracy 0.8340', 'Total loss: 1.1706', 'for batch', 0)
('GAN loss 0.7597 ', 'GAN acc 0.3750', 'Discriminator loss 0.3909', 'Discriminator accuracy 0.7676', 'Total loss: 1.1506', 'for batch', 1)
('GAN loss 0.6955 ', 'GAN acc 0.4766', 'Discriminator loss 0.5004', 'Discriminator accuracy 0.6992', 'Total loss: 1.1959', 'for batch', 2)
('GAN loss 0.7268 ', 'GAN acc 0.4297', 'Discriminator loss 0.4183', 'Discriminator accuracy 0.6719', 'Total loss: 1.1451', 'for batch', 3)
('GAN loss 0.7193 ', 'GAN acc 0.4648', 'Discriminator loss 0.4153', 'Discriminator accuracy 0.6719', 'Total loss: 1.1347', 'for batch', 4)
('GAN loss 0.7712 ', 'GAN acc 0.3516', 'Discriminator loss 0.4090', 'Discriminator accuracy 0.7227', 'Total loss: 1.1801', 'for batch', 5)
('GAN loss 0.8055 ', 'GAN acc 0.2500', 'Discriminator loss 0.3760', 'Discriminator accuracy 0.7871', 'Total loss: 1.1816', 'for batch', 6)
('GAN loss 0.8896 ', 'GAN acc 0.1602', 'Discriminator loss 0.3314', 'Discriminator accuracy 0.8203', 'Total loss: 1.2210', 'for batch', 7)
('GAN loss 0.8846 ', 'GAN acc 0.1719', 'Discriminator loss 0.4767', 'Discriminator accuracy 0.8730', 'Total loss: 1.3613', 'for batch', 8)
('GAN loss 0.8614 ', 'GAN acc 0.1797', 'Discriminator loss 0.4377', 'Discriminator accuracy 0.8730', 'Total loss: 1.2991', 'for batch', 9)
('GAN loss 0.8547 ', 'GAN acc 0.1836', 'Discriminator loss 0.3461', 'Discriminator accuracy 0.8770', 'Total loss: 1.2007', 'for batch', 10)
('GAN loss 0.8360 ', 'GAN acc 0.2070', 'Discriminator loss 0.4219', 'Discriminator accuracy 0.8730', 'Total loss: 1.2579', 'for batch', 11)
('GAN loss 0.8368 ', 'GAN acc 0.1875', 'Discriminator loss 0.3787', 'Discriminator accuracy 0.8633', 'Total loss: 1.2155', 'for batch', 12)
('GAN loss 0.8465 ', 'GAN acc 0.1914', 'Discriminator loss 0.3956', 'Discriminator accuracy 0.8652', 'Total loss: 1.2421', 'for batch', 13)
('GAN loss 0.9204 ', 'GAN acc 0.1094', 'Discriminator loss 0.3613', 'Discriminator accuracy 0.8594', 'Total loss: 1.2817', 'for batch', 14)
('GAN loss 0.8918 ', 'GAN acc 0.1523', 'Discriminator loss 0.3867', 'Discriminator accuracy 0.8711', 'Total loss: 1.2785', 'for batch', 15)
('GAN loss 0.9064 ', 'GAN acc 0.1250', 'Discriminator loss 0.3932', 'Discriminator accuracy 0.8555', 'Total loss: 1.2996', 'for batch', 16)
('GAN loss 0.8974 ', 'GAN acc 0.1172', 'Discriminator loss 0.3319', 'Discriminator accuracy 0.8906', 'Total loss: 1.2293', 'for batch', 17)
('GAN loss 0.8749 ', 'GAN acc 0.1680', 'Discriminator loss 0.3618', 'Discriminator accuracy 0.8770', 'Total loss: 1.2367', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96416253)
('DISCRIMINATOR_Imagem FAKE=', 0.42767078)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.827253')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9194 ', 'GAN acc 0.1484', 'Discriminator loss 0.3405', 'Discriminator accuracy 0.8613', 'Total loss: 1.2600', 'for batch', 0)
('GAN loss 0.8952 ', 'GAN acc 0.1406', 'Discriminator loss 0.3670', 'Discriminator accuracy 0.8848', 'Total loss: 1.2622', 'for batch', 1)
('GAN loss 0.8966 ', 'GAN acc 0.1562', 'Discriminator loss 0.4191', 'Discriminator accuracy 0.9062', 'Total loss: 1.3157', 'for batch', 2)
('GAN loss 0.8866 ', 'GAN acc 0.1406', 'Discriminator loss 0.3770', 'Discriminator accuracy 0.8828', 'Total loss: 1.2636', 'for batch', 3)
('GAN loss 0.8826 ', 'GAN acc 0.1797', 'Discriminator loss 0.3751', 'Discriminator accuracy 0.8672', 'Total loss: 1.2576', 'for batch', 4)
('GAN loss 0.9014 ', 'GAN acc 0.1758', 'Discriminator loss 0.3415', 'Discriminator accuracy 0.8789', 'Total loss: 1.2429', 'for batch', 5)
('GAN loss 0.8754 ', 'GAN acc 0.1719', 'Discriminator loss 0.4054', 'Discriminator accuracy 0.8594', 'Total loss: 1.2808', 'for batch', 6)
('GAN loss 0.9847 ', 'GAN acc 0.1094', 'Discriminator loss 0.3041', 'Discriminator accuracy 0.8828', 'Total loss: 1.2888', 'for batch', 7)
('GAN loss 1.0535 ', 'GAN acc 0.0469', 'Discriminator loss 0.4146', 'Discriminator accuracy 0.9062', 'Total loss: 1.4681', 'for batch', 8)
('GAN loss 1.0974 ', 'GAN acc 0.0352', 'Discriminator loss 0.3209', 'Discriminator accuracy 0.9238', 'Total loss: 1.4182', 'for batch', 9)
('GAN loss 1.1498 ', 'GAN acc 0.0156', 'Discriminator loss 0.2557', 'Discriminator accuracy 0.9629', 'Total loss: 1.4055', 'for batch', 10)
('GAN loss 1.0576 ', 'GAN acc 0.0430', 'Discriminator loss 0.4588', 'Discriminator accuracy 0.9434', 'Total loss: 1.5165', 'for batch', 11)
('GAN loss 1.0202 ', 'GAN acc 0.0625', 'Discriminator loss 0.2933', 'Discriminator accuracy 0.9570', 'Total loss: 1.3135', 'for batch', 12)
('GAN loss 1.0280 ', 'GAN acc 0.0234', 'Discriminator loss 0.2887', 'Discriminator accuracy 0.9336', 'Total loss: 1.3168', 'for batch', 13)
('GAN loss 1.0328 ', 'GAN acc 0.0430', 'Discriminator loss 0.2941', 'Discriminator accuracy 0.9453', 'Total loss: 1.3269', 'for batch', 14)
('GAN loss 1.0157 ', 'GAN acc 0.0430', 'Discriminator loss 0.3091', 'Discriminator accuracy 0.9219', 'Total loss: 1.3248', 'for batch', 15)
('GAN loss 1.0380 ', 'GAN acc 0.0547', 'Discriminator loss 0.3215', 'Discriminator accuracy 0.9355', 'Total loss: 1.3594', 'for batch', 16)
('GAN loss 1.1008 ', 'GAN acc 0.0469', 'Discriminator loss 0.2962', 'Discriminator accuracy 0.9375', 'Total loss: 1.3969', 'for batch', 17)
('GAN loss 1.1084 ', 'GAN acc 0.0312', 'Discriminator loss 0.3044', 'Discriminator accuracy 0.9570', 'Total loss: 1.4128', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96224803)
('DISCRIMINATOR_Imagem FAKE=', 0.35875669)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.418445')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 1.0960 ', 'GAN acc 0.0273', 'Discriminator loss 0.3103', 'Discriminator accuracy 0.9277', 'Total loss: 1.4063', 'for batch', 0)
('GAN loss 1.1248 ', 'GAN acc 0.0352', 'Discriminator loss 0.2906', 'Discriminator accuracy 0.9414', 'Total loss: 1.4154', 'for batch', 1)
('GAN loss 1.0611 ', 'GAN acc 0.0547', 'Discriminator loss 0.3893', 'Discriminator accuracy 0.9375', 'Total loss: 1.4504', 'for batch', 2)
('GAN loss 1.0358 ', 'GAN acc 0.0430', 'Discriminator loss 0.2797', 'Discriminator accuracy 0.9316', 'Total loss: 1.3154', 'for batch', 3)
('GAN loss 1.0702 ', 'GAN acc 0.0586', 'Discriminator loss 0.2996', 'Discriminator accuracy 0.9082', 'Total loss: 1.3698', 'for batch', 4)
('GAN loss 1.1815 ', 'GAN acc 0.0156', 'Discriminator loss 0.2791', 'Discriminator accuracy 0.9453', 'Total loss: 1.4606', 'for batch', 5)
('GAN loss 1.1940 ', 'GAN acc 0.0273', 'Discriminator loss 0.3359', 'Discriminator accuracy 0.9414', 'Total loss: 1.5298', 'for batch', 6)
('GAN loss 1.3330 ', 'GAN acc 0.0078', 'Discriminator loss 0.2193', 'Discriminator accuracy 0.9785', 'Total loss: 1.5524', 'for batch', 7)
('GAN loss 1.3111 ', 'GAN acc 0.0078', 'Discriminator loss 0.3472', 'Discriminator accuracy 0.9531', 'Total loss: 1.6583', 'for batch', 8)
('GAN loss 1.2853 ', 'GAN acc 0.0000', 'Discriminator loss 0.2636', 'Discriminator accuracy 0.9629', 'Total loss: 1.5489', 'for batch', 9)
('GAN loss 1.3796 ', 'GAN acc 0.0000', 'Discriminator loss 0.1979', 'Discriminator accuracy 0.9863', 'Total loss: 1.5775', 'for batch', 10)
('GAN loss 1.4366 ', 'GAN acc 0.0000', 'Discriminator loss 0.3397', 'Discriminator accuracy 0.9629', 'Total loss: 1.7763', 'for batch', 11)
('GAN loss 1.3761 ', 'GAN acc 0.0000', 'Discriminator loss 0.2668', 'Discriminator accuracy 0.9648', 'Total loss: 1.6430', 'for batch', 12)
('GAN loss 1.2119 ', 'GAN acc 0.0078', 'Discriminator loss 0.2696', 'Discriminator accuracy 0.9688', 'Total loss: 1.4815', 'for batch', 13)
('GAN loss 1.0840 ', 'GAN acc 0.0625', 'Discriminator loss 0.3199', 'Discriminator accuracy 0.9512', 'Total loss: 1.4038', 'for batch', 14)
('GAN loss 1.0457 ', 'GAN acc 0.0820', 'Discriminator loss 0.2769', 'Discriminator accuracy 0.9395', 'Total loss: 1.3226', 'for batch', 15)
('GAN loss 1.1275 ', 'GAN acc 0.0352', 'Discriminator loss 0.3125', 'Discriminator accuracy 0.9297', 'Total loss: 1.4400', 'for batch', 16)
('GAN loss 1.2875 ', 'GAN acc 0.0039', 'Discriminator loss 0.2421', 'Discriminator accuracy 0.9609', 'Total loss: 1.5296', 'for batch', 17)
('GAN loss 1.4362 ', 'GAN acc 0.0039', 'Discriminator loss 0.2808', 'Discriminator accuracy 0.9707', 'Total loss: 1.7171', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95783132)
('DISCRIMINATOR_Imagem FAKE=', 0.255867)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.927952')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 1.5087 ', 'GAN acc 0.0000', 'Discriminator loss 0.2534', 'Discriminator accuracy 0.9648', 'Total loss: 1.7621', 'for batch', 0)
('GAN loss 1.5357 ', 'GAN acc 0.0000', 'Discriminator loss 0.2216', 'Discriminator accuracy 0.9707', 'Total loss: 1.7574', 'for batch', 1)
('GAN loss 1.4658 ', 'GAN acc 0.0000', 'Discriminator loss 0.3962', 'Discriminator accuracy 0.9609', 'Total loss: 1.8620', 'for batch', 2)
('GAN loss 1.4473 ', 'GAN acc 0.0000', 'Discriminator loss 0.2463', 'Discriminator accuracy 0.9727', 'Total loss: 1.6936', 'for batch', 3)
('GAN loss 1.4699 ', 'GAN acc 0.0000', 'Discriminator loss 0.2139', 'Discriminator accuracy 0.9688', 'Total loss: 1.6839', 'for batch', 4)
('GAN loss 1.4630 ', 'GAN acc 0.0000', 'Discriminator loss 0.2215', 'Discriminator accuracy 0.9785', 'Total loss: 1.6844', 'for batch', 5)
('GAN loss 1.4323 ', 'GAN acc 0.0000', 'Discriminator loss 0.2166', 'Discriminator accuracy 0.9746', 'Total loss: 1.6488', 'for batch', 6)
('GAN loss 1.4611 ', 'GAN acc 0.0078', 'Discriminator loss 0.1738', 'Discriminator accuracy 0.9824', 'Total loss: 1.6349', 'for batch', 7)
('GAN loss 1.4666 ', 'GAN acc 0.0078', 'Discriminator loss 0.3332', 'Discriminator accuracy 0.9531', 'Total loss: 1.7998', 'for batch', 8)
('GAN loss 1.4991 ', 'GAN acc 0.0117', 'Discriminator loss 0.2550', 'Discriminator accuracy 0.9629', 'Total loss: 1.7541', 'for batch', 9)
('GAN loss 1.5528 ', 'GAN acc 0.0000', 'Discriminator loss 0.1647', 'Discriminator accuracy 0.9902', 'Total loss: 1.7176', 'for batch', 10)
('GAN loss 1.6972 ', 'GAN acc 0.0000', 'Discriminator loss 0.2663', 'Discriminator accuracy 0.9707', 'Total loss: 1.9635', 'for batch', 11)
('GAN loss 1.6830 ', 'GAN acc 0.0000', 'Discriminator loss 0.1930', 'Discriminator accuracy 0.9746', 'Total loss: 1.8760', 'for batch', 12)
('GAN loss 1.5722 ', 'GAN acc 0.0039', 'Discriminator loss 0.2364', 'Discriminator accuracy 0.9785', 'Total loss: 1.8086', 'for batch', 13)
('GAN loss 1.4295 ', 'GAN acc 0.0000', 'Discriminator loss 0.2061', 'Discriminator accuracy 0.9668', 'Total loss: 1.6356', 'for batch', 14)
('GAN loss 1.4635 ', 'GAN acc 0.0078', 'Discriminator loss 0.2339', 'Discriminator accuracy 0.9629', 'Total loss: 1.6974', 'for batch', 15)
('GAN loss 1.4624 ', 'GAN acc 0.0039', 'Discriminator loss 0.2510', 'Discriminator accuracy 0.9629', 'Total loss: 1.7134', 'for batch', 16)
('GAN loss 1.6189 ', 'GAN acc 0.0000', 'Discriminator loss 0.2063', 'Discriminator accuracy 0.9746', 'Total loss: 1.8252', 'for batch', 17)
('GAN loss 1.8552 ', 'GAN acc 0.0000', 'Discriminator loss 0.2204', 'Discriminator accuracy 0.9727', 'Total loss: 2.0756', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95577699)
('DISCRIMINATOR_Imagem FAKE=', 0.1651772)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.468117')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 1.8931 ', 'GAN acc 0.0000', 'Discriminator loss 0.1935', 'Discriminator accuracy 0.9668', 'Total loss: 2.0866', 'for batch', 0)
('GAN loss 1.8407 ', 'GAN acc 0.0000', 'Discriminator loss 0.1959', 'Discriminator accuracy 0.9727', 'Total loss: 2.0366', 'for batch', 1)
('GAN loss 1.4976 ', 'GAN acc 0.0000', 'Discriminator loss 0.3132', 'Discriminator accuracy 0.9648', 'Total loss: 1.8108', 'for batch', 2)
('GAN loss 1.3962 ', 'GAN acc 0.0156', 'Discriminator loss 0.1956', 'Discriminator accuracy 0.9746', 'Total loss: 1.5917', 'for batch', 3)
('GAN loss 1.5109 ', 'GAN acc 0.0117', 'Discriminator loss 0.2216', 'Discriminator accuracy 0.9668', 'Total loss: 1.7326', 'for batch', 4)
('GAN loss 1.6995 ', 'GAN acc 0.0000', 'Discriminator loss 0.1945', 'Discriminator accuracy 0.9766', 'Total loss: 1.8940', 'for batch', 5)
('GAN loss 1.8609 ', 'GAN acc 0.0000', 'Discriminator loss 0.1969', 'Discriminator accuracy 0.9688', 'Total loss: 2.0578', 'for batch', 6)
('GAN loss 2.1339 ', 'GAN acc 0.0000', 'Discriminator loss 0.1298', 'Discriminator accuracy 0.9863', 'Total loss: 2.2637', 'for batch', 7)
('GAN loss 2.0643 ', 'GAN acc 0.0000', 'Discriminator loss 0.2898', 'Discriminator accuracy 0.9570', 'Total loss: 2.3541', 'for batch', 8)
('GAN loss 1.9879 ', 'GAN acc 0.0000', 'Discriminator loss 0.1895', 'Discriminator accuracy 0.9648', 'Total loss: 2.1775', 'for batch', 9)
('GAN loss 2.0962 ', 'GAN acc 0.0000', 'Discriminator loss 0.1423', 'Discriminator accuracy 0.9863', 'Total loss: 2.2386', 'for batch', 10)
('GAN loss 1.9900 ', 'GAN acc 0.0000', 'Discriminator loss 0.2461', 'Discriminator accuracy 0.9629', 'Total loss: 2.2361', 'for batch', 11)
('GAN loss 1.9354 ', 'GAN acc 0.0000', 'Discriminator loss 0.1987', 'Discriminator accuracy 0.9688', 'Total loss: 2.1341', 'for batch', 12)
('GAN loss 1.7789 ', 'GAN acc 0.0039', 'Discriminator loss 0.1534', 'Discriminator accuracy 0.9785', 'Total loss: 1.9323', 'for batch', 13)
('GAN loss 1.7169 ', 'GAN acc 0.0039', 'Discriminator loss 0.1922', 'Discriminator accuracy 0.9707', 'Total loss: 1.9091', 'for batch', 14)
('GAN loss 1.7222 ', 'GAN acc 0.0000', 'Discriminator loss 0.2083', 'Discriminator accuracy 0.9551', 'Total loss: 1.9305', 'for batch', 15)
('GAN loss 1.7281 ', 'GAN acc 0.0000', 'Discriminator loss 0.2260', 'Discriminator accuracy 0.9609', 'Total loss: 1.9541', 'for batch', 16)
('GAN loss 1.9777 ', 'GAN acc 0.0000', 'Discriminator loss 0.1585', 'Discriminator accuracy 0.9766', 'Total loss: 2.1362', 'for batch', 17)
('GAN loss 2.0338 ', 'GAN acc 0.0000', 'Discriminator loss 0.2311', 'Discriminator accuracy 0.9746', 'Total loss: 2.2650', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95311725)
('DISCRIMINATOR_Imagem FAKE=', 0.12294729)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.020151')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 2.1505 ', 'GAN acc 0.0000', 'Discriminator loss 0.2104', 'Discriminator accuracy 0.9648', 'Total loss: 2.3609', 'for batch', 0)
('GAN loss 2.1089 ', 'GAN acc 0.0000', 'Discriminator loss 0.1927', 'Discriminator accuracy 0.9707', 'Total loss: 2.3016', 'for batch', 1)
('GAN loss 1.8004 ', 'GAN acc 0.0000', 'Discriminator loss 0.2828', 'Discriminator accuracy 0.9609', 'Total loss: 2.0832', 'for batch', 2)
('GAN loss 1.6388 ', 'GAN acc 0.0078', 'Discriminator loss 0.1660', 'Discriminator accuracy 0.9727', 'Total loss: 1.8048', 'for batch', 3)
('GAN loss 1.7251 ', 'GAN acc 0.0039', 'Discriminator loss 0.2009', 'Discriminator accuracy 0.9668', 'Total loss: 1.9260', 'for batch', 4)
('GAN loss 2.1369 ', 'GAN acc 0.0000', 'Discriminator loss 0.1480', 'Discriminator accuracy 0.9844', 'Total loss: 2.2849', 'for batch', 5)
('GAN loss 2.3065 ', 'GAN acc 0.0000', 'Discriminator loss 0.1901', 'Discriminator accuracy 0.9707', 'Total loss: 2.4966', 'for batch', 6)
('GAN loss 2.5661 ', 'GAN acc 0.0000', 'Discriminator loss 0.1014', 'Discriminator accuracy 0.9844', 'Total loss: 2.6676', 'for batch', 7)
('GAN loss 2.3762 ', 'GAN acc 0.0000', 'Discriminator loss 0.2674', 'Discriminator accuracy 0.9590', 'Total loss: 2.6435', 'for batch', 8)
('GAN loss 2.1340 ', 'GAN acc 0.0000', 'Discriminator loss 0.2215', 'Discriminator accuracy 0.9551', 'Total loss: 2.3555', 'for batch', 9)
('GAN loss 2.2117 ', 'GAN acc 0.0078', 'Discriminator loss 0.0980', 'Discriminator accuracy 0.9902', 'Total loss: 2.3096', 'for batch', 10)
('GAN loss 2.0829 ', 'GAN acc 0.0000', 'Discriminator loss 0.2146', 'Discriminator accuracy 0.9688', 'Total loss: 2.2974', 'for batch', 11)
('GAN loss 2.0755 ', 'GAN acc 0.0000', 'Discriminator loss 0.1409', 'Discriminator accuracy 0.9785', 'Total loss: 2.2164', 'for batch', 12)
('GAN loss 1.8010 ', 'GAN acc 0.0000', 'Discriminator loss 0.1980', 'Discriminator accuracy 0.9766', 'Total loss: 1.9990', 'for batch', 13)
('GAN loss 1.9701 ', 'GAN acc 0.0000', 'Discriminator loss 0.1673', 'Discriminator accuracy 0.9746', 'Total loss: 2.1374', 'for batch', 14)
('GAN loss 2.2404 ', 'GAN acc 0.0000', 'Discriminator loss 0.1992', 'Discriminator accuracy 0.9609', 'Total loss: 2.4397', 'for batch', 15)
('GAN loss 2.3027 ', 'GAN acc 0.0000', 'Discriminator loss 0.1887', 'Discriminator accuracy 0.9648', 'Total loss: 2.4914', 'for batch', 16)
('GAN loss 2.3936 ', 'GAN acc 0.0000', 'Discriminator loss 0.1348', 'Discriminator accuracy 0.9785', 'Total loss: 2.5284', 'for batch', 17)
('GAN loss 2.5049 ', 'GAN acc 0.0000', 'Discriminator loss 0.1618', 'Discriminator accuracy 0.9766', 'Total loss: 2.6667', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95359087)
('DISCRIMINATOR_Imagem FAKE=', 0.08702869)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.503110')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 2.3613 ', 'GAN acc 0.0000', 'Discriminator loss 0.1581', 'Discriminator accuracy 0.9668', 'Total loss: 2.5194', 'for batch', 0)
('GAN loss 2.2819 ', 'GAN acc 0.0000', 'Discriminator loss 0.1423', 'Discriminator accuracy 0.9727', 'Total loss: 2.4243', 'for batch', 1)
('GAN loss 1.9388 ', 'GAN acc 0.0000', 'Discriminator loss 0.1406', 'Discriminator accuracy 0.9727', 'Total loss: 2.0794', 'for batch', 2)
('GAN loss 1.7143 ', 'GAN acc 0.0156', 'Discriminator loss 0.1631', 'Discriminator accuracy 0.9766', 'Total loss: 1.8774', 'for batch', 3)
('GAN loss 2.0247 ', 'GAN acc 0.0000', 'Discriminator loss 0.1908', 'Discriminator accuracy 0.9648', 'Total loss: 2.2155', 'for batch', 4)
('GAN loss 2.4127 ', 'GAN acc 0.0000', 'Discriminator loss 0.1428', 'Discriminator accuracy 0.9805', 'Total loss: 2.5554', 'for batch', 5)
('GAN loss 2.2893 ', 'GAN acc 0.0000', 'Discriminator loss 0.1573', 'Discriminator accuracy 0.9707', 'Total loss: 2.4466', 'for batch', 6)
('GAN loss 2.4882 ', 'GAN acc 0.0000', 'Discriminator loss 0.0980', 'Discriminator accuracy 0.9883', 'Total loss: 2.5863', 'for batch', 7)
('GAN loss 2.3425 ', 'GAN acc 0.0000', 'Discriminator loss 0.1924', 'Discriminator accuracy 0.9648', 'Total loss: 2.5349', 'for batch', 8)
('GAN loss 2.5308 ', 'GAN acc 0.0000', 'Discriminator loss 0.1343', 'Discriminator accuracy 0.9727', 'Total loss: 2.6651', 'for batch', 9)
('GAN loss 2.6903 ', 'GAN acc 0.0000', 'Discriminator loss 0.1132', 'Discriminator accuracy 0.9883', 'Total loss: 2.8034', 'for batch', 10)
('GAN loss 2.2539 ', 'GAN acc 0.0000', 'Discriminator loss 0.1865', 'Discriminator accuracy 0.9688', 'Total loss: 2.4404', 'for batch', 11)
('GAN loss 2.2591 ', 'GAN acc 0.0000', 'Discriminator loss 0.1017', 'Discriminator accuracy 0.9844', 'Total loss: 2.3608', 'for batch', 12)
('GAN loss 2.5348 ', 'GAN acc 0.0000', 'Discriminator loss 0.1022', 'Discriminator accuracy 0.9863', 'Total loss: 2.6370', 'for batch', 13)
('GAN loss 2.6418 ', 'GAN acc 0.0000', 'Discriminator loss 0.1467', 'Discriminator accuracy 0.9707', 'Total loss: 2.7884', 'for batch', 14)
('GAN loss 2.6093 ', 'GAN acc 0.0000', 'Discriminator loss 0.1573', 'Discriminator accuracy 0.9648', 'Total loss: 2.7666', 'for batch', 15)
('GAN loss 2.5817 ', 'GAN acc 0.0000', 'Discriminator loss 0.1839', 'Discriminator accuracy 0.9629', 'Total loss: 2.7657', 'for batch', 16)
('GAN loss 2.6956 ', 'GAN acc 0.0000', 'Discriminator loss 0.1053', 'Discriminator accuracy 0.9785', 'Total loss: 2.8009', 'for batch', 17)
('GAN loss 2.3326 ', 'GAN acc 0.0000', 'Discriminator loss 0.1482', 'Discriminator accuracy 0.9746', 'Total loss: 2.4808', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95794219)
('DISCRIMINATOR_Imagem FAKE=', 0.088852257)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.982268')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 2.1524 ', 'GAN acc 0.0039', 'Discriminator loss 0.1689', 'Discriminator accuracy 0.9688', 'Total loss: 2.3213', 'for batch', 0)
('GAN loss 2.1533 ', 'GAN acc 0.0000', 'Discriminator loss 0.1660', 'Discriminator accuracy 0.9727', 'Total loss: 2.3192', 'for batch', 1)
('GAN loss 2.4068 ', 'GAN acc 0.0000', 'Discriminator loss 0.1265', 'Discriminator accuracy 0.9824', 'Total loss: 2.5333', 'for batch', 2)
('GAN loss 2.7520 ', 'GAN acc 0.0000', 'Discriminator loss 0.1503', 'Discriminator accuracy 0.9766', 'Total loss: 2.9023', 'for batch', 3)
('GAN loss 2.9163 ', 'GAN acc 0.0000', 'Discriminator loss 0.1469', 'Discriminator accuracy 0.9707', 'Total loss: 3.0632', 'for batch', 4)
('GAN loss 2.8520 ', 'GAN acc 0.0000', 'Discriminator loss 0.1082', 'Discriminator accuracy 0.9785', 'Total loss: 2.9602', 'for batch', 5)
('GAN loss 2.7611 ', 'GAN acc 0.0000', 'Discriminator loss 0.1268', 'Discriminator accuracy 0.9727', 'Total loss: 2.8879', 'for batch', 6)
('GAN loss 2.8894 ', 'GAN acc 0.0000', 'Discriminator loss 0.0744', 'Discriminator accuracy 0.9883', 'Total loss: 2.9637', 'for batch', 7)
('GAN loss 1.9628 ', 'GAN acc 0.0000', 'Discriminator loss 0.2729', 'Discriminator accuracy 0.9551', 'Total loss: 2.2356', 'for batch', 8)
('GAN loss 1.8368 ', 'GAN acc 0.0039', 'Discriminator loss 0.1610', 'Discriminator accuracy 0.9746', 'Total loss: 1.9978', 'for batch', 9)
('GAN loss 2.3902 ', 'GAN acc 0.0000', 'Discriminator loss 0.1372', 'Discriminator accuracy 0.9863', 'Total loss: 2.5274', 'for batch', 10)
('GAN loss 2.8189 ', 'GAN acc 0.0000', 'Discriminator loss 0.1557', 'Discriminator accuracy 0.9746', 'Total loss: 2.9746', 'for batch', 11)
('GAN loss 2.9833 ', 'GAN acc 0.0000', 'Discriminator loss 0.1234', 'Discriminator accuracy 0.9824', 'Total loss: 3.1067', 'for batch', 12)
('GAN loss 2.6982 ', 'GAN acc 0.0000', 'Discriminator loss 0.0998', 'Discriminator accuracy 0.9824', 'Total loss: 2.7980', 'for batch', 13)
('GAN loss 2.5442 ', 'GAN acc 0.0000', 'Discriminator loss 0.1356', 'Discriminator accuracy 0.9707', 'Total loss: 2.6798', 'for batch', 14)
('GAN loss 2.6477 ', 'GAN acc 0.0000', 'Discriminator loss 0.1370', 'Discriminator accuracy 0.9688', 'Total loss: 2.7847', 'for batch', 15)
('GAN loss 2.6295 ', 'GAN acc 0.0000', 'Discriminator loss 0.1531', 'Discriminator accuracy 0.9648', 'Total loss: 2.7826', 'for batch', 16)
('GAN loss 2.8983 ', 'GAN acc 0.0000', 'Discriminator loss 0.0931', 'Discriminator accuracy 0.9805', 'Total loss: 2.9913', 'for batch', 17)
('GAN loss 2.9138 ', 'GAN acc 0.0000', 'Discriminator loss 0.1182', 'Discriminator accuracy 0.9766', 'Total loss: 3.0320', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95419919)
('DISCRIMINATOR_Imagem FAKE=', 0.047942329)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.484839')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 2.8530 ', 'GAN acc 0.0000', 'Discriminator loss 0.1383', 'Discriminator accuracy 0.9668', 'Total loss: 2.9913', 'for batch', 0)
('GAN loss 2.6640 ', 'GAN acc 0.0000', 'Discriminator loss 0.1078', 'Discriminator accuracy 0.9746', 'Total loss: 2.7718', 'for batch', 1)
('GAN loss 2.5503 ', 'GAN acc 0.0000', 'Discriminator loss 0.1036', 'Discriminator accuracy 0.9805', 'Total loss: 2.6539', 'for batch', 2)
('GAN loss 2.5258 ', 'GAN acc 0.0000', 'Discriminator loss 0.1152', 'Discriminator accuracy 0.9824', 'Total loss: 2.6410', 'for batch', 3)
('GAN loss 2.5477 ', 'GAN acc 0.0000', 'Discriminator loss 0.1416', 'Discriminator accuracy 0.9707', 'Total loss: 2.6893', 'for batch', 4)
('GAN loss 2.7333 ', 'GAN acc 0.0000', 'Discriminator loss 0.0992', 'Discriminator accuracy 0.9844', 'Total loss: 2.8325', 'for batch', 5)
('GAN loss 2.8842 ', 'GAN acc 0.0000', 'Discriminator loss 0.1155', 'Discriminator accuracy 0.9785', 'Total loss: 2.9997', 'for batch', 6)
('GAN loss 3.0962 ', 'GAN acc 0.0000', 'Discriminator loss 0.0729', 'Discriminator accuracy 0.9883', 'Total loss: 3.1690', 'for batch', 7)
('GAN loss 2.2337 ', 'GAN acc 0.0117', 'Discriminator loss 0.1765', 'Discriminator accuracy 0.9629', 'Total loss: 2.4102', 'for batch', 8)
('GAN loss 2.1104 ', 'GAN acc 0.0039', 'Discriminator loss 0.1451', 'Discriminator accuracy 0.9766', 'Total loss: 2.2556', 'for batch', 9)
('GAN loss 2.5291 ', 'GAN acc 0.0000', 'Discriminator loss 0.1166', 'Discriminator accuracy 0.9902', 'Total loss: 2.6457', 'for batch', 10)
('GAN loss 3.1900 ', 'GAN acc 0.0000', 'Discriminator loss 0.1079', 'Discriminator accuracy 0.9785', 'Total loss: 3.2979', 'for batch', 11)
('GAN loss 3.6694 ', 'GAN acc 0.0000', 'Discriminator loss 0.0713', 'Discriminator accuracy 0.9844', 'Total loss: 3.7408', 'for batch', 12)
('GAN loss 3.4580 ', 'GAN acc 0.0000', 'Discriminator loss 0.0838', 'Discriminator accuracy 0.9805', 'Total loss: 3.5418', 'for batch', 13)
('GAN loss 3.1829 ', 'GAN acc 0.0000', 'Discriminator loss 0.1527', 'Discriminator accuracy 0.9707', 'Total loss: 3.3357', 'for batch', 14)
('GAN loss 3.0582 ', 'GAN acc 0.0000', 'Discriminator loss 0.1306', 'Discriminator accuracy 0.9668', 'Total loss: 3.1889', 'for batch', 15)
('GAN loss 2.7273 ', 'GAN acc 0.0000', 'Discriminator loss 0.1395', 'Discriminator accuracy 0.9648', 'Total loss: 2.8669', 'for batch', 16)
('GAN loss 3.0614 ', 'GAN acc 0.0000', 'Discriminator loss 0.0977', 'Discriminator accuracy 0.9805', 'Total loss: 3.1591', 'for batch', 17)
('GAN loss 2.8227 ', 'GAN acc 0.0000', 'Discriminator loss 0.0836', 'Discriminator accuracy 0.9824', 'Total loss: 2.9063', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95760143)
('DISCRIMINATOR_Imagem FAKE=', 0.055949524)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.024590')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 2.8544 ', 'GAN acc 0.0000', 'Discriminator loss 0.1183', 'Discriminator accuracy 0.9727', 'Total loss: 2.9727', 'for batch', 0)
('GAN loss 2.9410 ', 'GAN acc 0.0000', 'Discriminator loss 0.0983', 'Discriminator accuracy 0.9766', 'Total loss: 3.0394', 'for batch', 1)
('GAN loss 2.6999 ', 'GAN acc 0.0039', 'Discriminator loss 0.1036', 'Discriminator accuracy 0.9785', 'Total loss: 2.8035', 'for batch', 2)
('GAN loss 2.8783 ', 'GAN acc 0.0000', 'Discriminator loss 0.1024', 'Discriminator accuracy 0.9805', 'Total loss: 2.9806', 'for batch', 3)
('GAN loss 3.1726 ', 'GAN acc 0.0000', 'Discriminator loss 0.1243', 'Discriminator accuracy 0.9727', 'Total loss: 3.2970', 'for batch', 4)
('GAN loss 3.1312 ', 'GAN acc 0.0000', 'Discriminator loss 0.1008', 'Discriminator accuracy 0.9824', 'Total loss: 3.2320', 'for batch', 5)
('GAN loss 3.0755 ', 'GAN acc 0.0000', 'Discriminator loss 0.1123', 'Discriminator accuracy 0.9746', 'Total loss: 3.1878', 'for batch', 6)
('GAN loss 3.1955 ', 'GAN acc 0.0000', 'Discriminator loss 0.0673', 'Discriminator accuracy 0.9883', 'Total loss: 3.2628', 'for batch', 7)
('GAN loss 2.5075 ', 'GAN acc 0.0039', 'Discriminator loss 0.1303', 'Discriminator accuracy 0.9707', 'Total loss: 2.6378', 'for batch', 8)
('GAN loss 2.5969 ', 'GAN acc 0.0000', 'Discriminator loss 0.1473', 'Discriminator accuracy 0.9688', 'Total loss: 2.7442', 'for batch', 9)
('GAN loss 3.3688 ', 'GAN acc 0.0000', 'Discriminator loss 0.0861', 'Discriminator accuracy 0.9844', 'Total loss: 3.4549', 'for batch', 10)
('GAN loss 3.0672 ', 'GAN acc 0.0000', 'Discriminator loss 0.1149', 'Discriminator accuracy 0.9766', 'Total loss: 3.1820', 'for batch', 11)
('GAN loss 3.3581 ', 'GAN acc 0.0000', 'Discriminator loss 0.0717', 'Discriminator accuracy 0.9863', 'Total loss: 3.4298', 'for batch', 12)
('GAN loss 3.7170 ', 'GAN acc 0.0000', 'Discriminator loss 0.0622', 'Discriminator accuracy 0.9863', 'Total loss: 3.7792', 'for batch', 13)
('GAN loss 3.8242 ', 'GAN acc 0.0000', 'Discriminator loss 0.0997', 'Discriminator accuracy 0.9746', 'Total loss: 3.9238', 'for batch', 14)
('GAN loss 3.8912 ', 'GAN acc 0.0000', 'Discriminator loss 0.1236', 'Discriminator accuracy 0.9668', 'Total loss: 4.0149', 'for batch', 15)
('GAN loss 3.4979 ', 'GAN acc 0.0000', 'Discriminator loss 0.1153', 'Discriminator accuracy 0.9668', 'Total loss: 3.6132', 'for batch', 16)
('GAN loss 3.3945 ', 'GAN acc 0.0000', 'Discriminator loss 0.0765', 'Discriminator accuracy 0.9785', 'Total loss: 3.4710', 'for batch', 17)
('GAN loss 3.3139 ', 'GAN acc 0.0000', 'Discriminator loss 0.0816', 'Discriminator accuracy 0.9844', 'Total loss: 3.3955', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95592201)
('DISCRIMINATOR_Imagem FAKE=', 0.034830678)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.470962')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0835 ', 'GAN acc 0.0000', 'Discriminator loss 0.1111', 'Discriminator accuracy 0.9727', 'Total loss: 3.1946', 'for batch', 0)
('GAN loss 2.9428 ', 'GAN acc 0.0000', 'Discriminator loss 0.0901', 'Discriminator accuracy 0.9766', 'Total loss: 3.0329', 'for batch', 1)
('GAN loss 2.5053 ', 'GAN acc 0.0039', 'Discriminator loss 0.1030', 'Discriminator accuracy 0.9746', 'Total loss: 2.6083', 'for batch', 2)
('GAN loss 2.6704 ', 'GAN acc 0.0000', 'Discriminator loss 0.1129', 'Discriminator accuracy 0.9785', 'Total loss: 2.7833', 'for batch', 3)
('GAN loss 3.2498 ', 'GAN acc 0.0000', 'Discriminator loss 0.1265', 'Discriminator accuracy 0.9707', 'Total loss: 3.3762', 'for batch', 4)
('GAN loss 3.5901 ', 'GAN acc 0.0000', 'Discriminator loss 0.0807', 'Discriminator accuracy 0.9863', 'Total loss: 3.6707', 'for batch', 5)
('GAN loss 3.5555 ', 'GAN acc 0.0000', 'Discriminator loss 0.0892', 'Discriminator accuracy 0.9766', 'Total loss: 3.6447', 'for batch', 6)
('GAN loss 3.5850 ', 'GAN acc 0.0000', 'Discriminator loss 0.0560', 'Discriminator accuracy 0.9883', 'Total loss: 3.6409', 'for batch', 7)
('GAN loss 3.0832 ', 'GAN acc 0.0000', 'Discriminator loss 0.1489', 'Discriminator accuracy 0.9688', 'Total loss: 3.2321', 'for batch', 8)
('GAN loss 2.9002 ', 'GAN acc 0.0000', 'Discriminator loss 0.1068', 'Discriminator accuracy 0.9707', 'Total loss: 3.0070', 'for batch', 9)
('GAN loss 2.8709 ', 'GAN acc 0.0000', 'Discriminator loss 0.0639', 'Discriminator accuracy 0.9902', 'Total loss: 2.9348', 'for batch', 10)
('GAN loss 2.7983 ', 'GAN acc 0.0000', 'Discriminator loss 0.1084', 'Discriminator accuracy 0.9785', 'Total loss: 2.9068', 'for batch', 11)
('GAN loss 3.0415 ', 'GAN acc 0.0000', 'Discriminator loss 0.0833', 'Discriminator accuracy 0.9844', 'Total loss: 3.1247', 'for batch', 12)
('GAN loss 3.4251 ', 'GAN acc 0.0000', 'Discriminator loss 0.0650', 'Discriminator accuracy 0.9883', 'Total loss: 3.4901', 'for batch', 13)
('GAN loss 3.6252 ', 'GAN acc 0.0000', 'Discriminator loss 0.0987', 'Discriminator accuracy 0.9746', 'Total loss: 3.7238', 'for batch', 14)
('GAN loss 3.5758 ', 'GAN acc 0.0000', 'Discriminator loss 0.1233', 'Discriminator accuracy 0.9668', 'Total loss: 3.6991', 'for batch', 15)
('GAN loss 3.2854 ', 'GAN acc 0.0000', 'Discriminator loss 0.1275', 'Discriminator accuracy 0.9668', 'Total loss: 3.4129', 'for batch', 16)
('GAN loss 3.2142 ', 'GAN acc 0.0000', 'Discriminator loss 0.0766', 'Discriminator accuracy 0.9805', 'Total loss: 3.2908', 'for batch', 17)
('GAN loss 3.1220 ', 'GAN acc 0.0000', 'Discriminator loss 0.0690', 'Discriminator accuracy 0.9824', 'Total loss: 3.1909', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95895523)
('DISCRIMINATOR_Imagem FAKE=', 0.043747131)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.010861')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0187 ', 'GAN acc 0.0000', 'Discriminator loss 0.1018', 'Discriminator accuracy 0.9707', 'Total loss: 3.1205', 'for batch', 0)
('GAN loss 3.0055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0873', 'Discriminator accuracy 0.9785', 'Total loss: 3.0927', 'for batch', 1)
('GAN loss 2.9982 ', 'GAN acc 0.0000', 'Discriminator loss 0.0715', 'Discriminator accuracy 0.9863', 'Total loss: 3.0697', 'for batch', 2)
('GAN loss 3.1565 ', 'GAN acc 0.0000', 'Discriminator loss 0.0772', 'Discriminator accuracy 0.9805', 'Total loss: 3.2337', 'for batch', 3)
('GAN loss 3.2537 ', 'GAN acc 0.0000', 'Discriminator loss 0.1039', 'Discriminator accuracy 0.9746', 'Total loss: 3.3576', 'for batch', 4)
('GAN loss 3.3609 ', 'GAN acc 0.0000', 'Discriminator loss 0.0595', 'Discriminator accuracy 0.9883', 'Total loss: 3.4204', 'for batch', 5)
('GAN loss 3.4939 ', 'GAN acc 0.0000', 'Discriminator loss 0.0781', 'Discriminator accuracy 0.9805', 'Total loss: 3.5720', 'for batch', 6)
('GAN loss 3.5495 ', 'GAN acc 0.0000', 'Discriminator loss 0.0539', 'Discriminator accuracy 0.9883', 'Total loss: 3.6034', 'for batch', 7)
('GAN loss 3.5432 ', 'GAN acc 0.0000', 'Discriminator loss 0.0996', 'Discriminator accuracy 0.9727', 'Total loss: 3.6428', 'for batch', 8)
('GAN loss 3.4078 ', 'GAN acc 0.0000', 'Discriminator loss 0.0982', 'Discriminator accuracy 0.9727', 'Total loss: 3.5059', 'for batch', 9)
('GAN loss 3.3896 ', 'GAN acc 0.0000', 'Discriminator loss 0.0440', 'Discriminator accuracy 0.9922', 'Total loss: 3.4337', 'for batch', 10)
('GAN loss 3.3739 ', 'GAN acc 0.0000', 'Discriminator loss 0.0830', 'Discriminator accuracy 0.9785', 'Total loss: 3.4569', 'for batch', 11)
('GAN loss 3.3701 ', 'GAN acc 0.0000', 'Discriminator loss 0.0599', 'Discriminator accuracy 0.9844', 'Total loss: 3.4300', 'for batch', 12)
('GAN loss 3.3166 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.3756', 'for batch', 13)
('GAN loss 3.3008 ', 'GAN acc 0.0000', 'Discriminator loss 0.0980', 'Discriminator accuracy 0.9727', 'Total loss: 3.3988', 'for batch', 14)
('GAN loss 3.0653 ', 'GAN acc 0.0000', 'Discriminator loss 0.1142', 'Discriminator accuracy 0.9688', 'Total loss: 3.1795', 'for batch', 15)
('GAN loss 3.0583 ', 'GAN acc 0.0000', 'Discriminator loss 0.1110', 'Discriminator accuracy 0.9707', 'Total loss: 3.1693', 'for batch', 16)
('GAN loss 3.0436 ', 'GAN acc 0.0000', 'Discriminator loss 0.0908', 'Discriminator accuracy 0.9785', 'Total loss: 3.1344', 'for batch', 17)
('GAN loss 3.0257 ', 'GAN acc 0.0000', 'Discriminator loss 0.0551', 'Discriminator accuracy 0.9922', 'Total loss: 3.0808', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96053296)
('DISCRIMINATOR_Imagem FAKE=', 0.050930969)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.547489')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1228 ', 'GAN acc 0.0000', 'Discriminator loss 0.0935', 'Discriminator accuracy 0.9766', 'Total loss: 3.2163', 'for batch', 0)
('GAN loss 3.0352 ', 'GAN acc 0.0000', 'Discriminator loss 0.0918', 'Discriminator accuracy 0.9766', 'Total loss: 3.1271', 'for batch', 1)
('GAN loss 3.0021 ', 'GAN acc 0.0000', 'Discriminator loss 0.0621', 'Discriminator accuracy 0.9883', 'Total loss: 3.0643', 'for batch', 2)
('GAN loss 2.9926 ', 'GAN acc 0.0000', 'Discriminator loss 0.0783', 'Discriminator accuracy 0.9805', 'Total loss: 3.0709', 'for batch', 3)
('GAN loss 3.0141 ', 'GAN acc 0.0000', 'Discriminator loss 0.1017', 'Discriminator accuracy 0.9766', 'Total loss: 3.1158', 'for batch', 4)
('GAN loss 3.0155 ', 'GAN acc 0.0000', 'Discriminator loss 0.0696', 'Discriminator accuracy 0.9863', 'Total loss: 3.0851', 'for batch', 5)
('GAN loss 3.0032 ', 'GAN acc 0.0000', 'Discriminator loss 0.0850', 'Discriminator accuracy 0.9805', 'Total loss: 3.0882', 'for batch', 6)
('GAN loss 3.0136 ', 'GAN acc 0.0000', 'Discriminator loss 0.0627', 'Discriminator accuracy 0.9883', 'Total loss: 3.0763', 'for batch', 7)
('GAN loss 3.0321 ', 'GAN acc 0.0000', 'Discriminator loss 0.1039', 'Discriminator accuracy 0.9746', 'Total loss: 3.1360', 'for batch', 8)
('GAN loss 3.0025 ', 'GAN acc 0.0000', 'Discriminator loss 0.1030', 'Discriminator accuracy 0.9727', 'Total loss: 3.1055', 'for batch', 9)
('GAN loss 3.0291 ', 'GAN acc 0.0000', 'Discriminator loss 0.0533', 'Discriminator accuracy 0.9922', 'Total loss: 3.0824', 'for batch', 10)
('GAN loss 3.0353 ', 'GAN acc 0.0000', 'Discriminator loss 0.0889', 'Discriminator accuracy 0.9785', 'Total loss: 3.1242', 'for batch', 11)
('GAN loss 3.0514 ', 'GAN acc 0.0000', 'Discriminator loss 0.0675', 'Discriminator accuracy 0.9863', 'Total loss: 3.1189', 'for batch', 12)
('GAN loss 3.1218 ', 'GAN acc 0.0000', 'Discriminator loss 0.0624', 'Discriminator accuracy 0.9883', 'Total loss: 3.1841', 'for batch', 13)
('GAN loss 3.1241 ', 'GAN acc 0.0000', 'Discriminator loss 0.1053', 'Discriminator accuracy 0.9746', 'Total loss: 3.2294', 'for batch', 14)
('GAN loss 3.1064 ', 'GAN acc 0.0000', 'Discriminator loss 0.1291', 'Discriminator accuracy 0.9688', 'Total loss: 3.2355', 'for batch', 15)
('GAN loss 3.0892 ', 'GAN acc 0.0000', 'Discriminator loss 0.1142', 'Discriminator accuracy 0.9707', 'Total loss: 3.2035', 'for batch', 16)
('GAN loss 3.0947 ', 'GAN acc 0.0000', 'Discriminator loss 0.0846', 'Discriminator accuracy 0.9785', 'Total loss: 3.1793', 'for batch', 17)
('GAN loss 3.1216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0515', 'Discriminator accuracy 0.9922', 'Total loss: 3.1732', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96112078)
('DISCRIMINATOR_Imagem FAKE=', 0.053013813)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.983696')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1596 ', 'GAN acc 0.0000', 'Discriminator loss 0.1001', 'Discriminator accuracy 0.9766', 'Total loss: 3.2597', 'for batch', 0)
('GAN loss 3.1685 ', 'GAN acc 0.0000', 'Discriminator loss 0.0888', 'Discriminator accuracy 0.9805', 'Total loss: 3.2573', 'for batch', 1)
('GAN loss 3.1211 ', 'GAN acc 0.0000', 'Discriminator loss 0.0657', 'Discriminator accuracy 0.9844', 'Total loss: 3.1868', 'for batch', 2)
('GAN loss 3.1261 ', 'GAN acc 0.0000', 'Discriminator loss 0.0800', 'Discriminator accuracy 0.9824', 'Total loss: 3.2061', 'for batch', 3)
('GAN loss 3.1542 ', 'GAN acc 0.0000', 'Discriminator loss 0.0981', 'Discriminator accuracy 0.9766', 'Total loss: 3.2523', 'for batch', 4)
('GAN loss 3.1523 ', 'GAN acc 0.0000', 'Discriminator loss 0.0620', 'Discriminator accuracy 0.9883', 'Total loss: 3.2143', 'for batch', 5)
('GAN loss 3.1688 ', 'GAN acc 0.0000', 'Discriminator loss 0.0825', 'Discriminator accuracy 0.9824', 'Total loss: 3.2514', 'for batch', 6)
('GAN loss 3.2114 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9883', 'Total loss: 3.2725', 'for batch', 7)
('GAN loss 3.1701 ', 'GAN acc 0.0000', 'Discriminator loss 0.1085', 'Discriminator accuracy 0.9727', 'Total loss: 3.2786', 'for batch', 8)
('GAN loss 3.2218 ', 'GAN acc 0.0000', 'Discriminator loss 0.1013', 'Discriminator accuracy 0.9766', 'Total loss: 3.3231', 'for batch', 9)
('GAN loss 3.2097 ', 'GAN acc 0.0000', 'Discriminator loss 0.0497', 'Discriminator accuracy 0.9922', 'Total loss: 3.2594', 'for batch', 10)
('GAN loss 3.2504 ', 'GAN acc 0.0000', 'Discriminator loss 0.0844', 'Discriminator accuracy 0.9805', 'Total loss: 3.3348', 'for batch', 11)
('GAN loss 3.2799 ', 'GAN acc 0.0000', 'Discriminator loss 0.0647', 'Discriminator accuracy 0.9863', 'Total loss: 3.3446', 'for batch', 12)
('GAN loss 3.2758 ', 'GAN acc 0.0000', 'Discriminator loss 0.0598', 'Discriminator accuracy 0.9883', 'Total loss: 3.3356', 'for batch', 13)
('GAN loss 3.3103 ', 'GAN acc 0.0000', 'Discriminator loss 0.1072', 'Discriminator accuracy 0.9746', 'Total loss: 3.4175', 'for batch', 14)
('GAN loss 3.2748 ', 'GAN acc 0.0000', 'Discriminator loss 0.1138', 'Discriminator accuracy 0.9707', 'Total loss: 3.3886', 'for batch', 15)
('GAN loss 3.2122 ', 'GAN acc 0.0000', 'Discriminator loss 0.1177', 'Discriminator accuracy 0.9707', 'Total loss: 3.3300', 'for batch', 16)
('GAN loss 3.2564 ', 'GAN acc 0.0000', 'Discriminator loss 0.0852', 'Discriminator accuracy 0.9805', 'Total loss: 3.3417', 'for batch', 17)
('GAN loss 3.2724 ', 'GAN acc 0.0000', 'Discriminator loss 0.0453', 'Discriminator accuracy 0.9922', 'Total loss: 3.3177', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96150804)
('DISCRIMINATOR_Imagem FAKE=', 0.045187876)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.038636')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2516 ', 'GAN acc 0.0000', 'Discriminator loss 0.0975', 'Discriminator accuracy 0.9766', 'Total loss: 3.3491', 'for batch', 0)
('GAN loss 3.2487 ', 'GAN acc 0.0000', 'Discriminator loss 0.0856', 'Discriminator accuracy 0.9805', 'Total loss: 3.3344', 'for batch', 1)
('GAN loss 3.2599 ', 'GAN acc 0.0000', 'Discriminator loss 0.0582', 'Discriminator accuracy 0.9863', 'Total loss: 3.3182', 'for batch', 2)
('GAN loss 3.2649 ', 'GAN acc 0.0000', 'Discriminator loss 0.0704', 'Discriminator accuracy 0.9824', 'Total loss: 3.3353', 'for batch', 3)
('GAN loss 3.3047 ', 'GAN acc 0.0000', 'Discriminator loss 0.1000', 'Discriminator accuracy 0.9766', 'Total loss: 3.4047', 'for batch', 4)
('GAN loss 3.2971 ', 'GAN acc 0.0000', 'Discriminator loss 0.0634', 'Discriminator accuracy 0.9883', 'Total loss: 3.3606', 'for batch', 5)
('GAN loss 3.2953 ', 'GAN acc 0.0000', 'Discriminator loss 0.0808', 'Discriminator accuracy 0.9824', 'Total loss: 3.3761', 'for batch', 6)
('GAN loss 3.3134 ', 'GAN acc 0.0000', 'Discriminator loss 0.0596', 'Discriminator accuracy 0.9883', 'Total loss: 3.3730', 'for batch', 7)
('GAN loss 3.3164 ', 'GAN acc 0.0000', 'Discriminator loss 0.1084', 'Discriminator accuracy 0.9746', 'Total loss: 3.4248', 'for batch', 8)
('GAN loss 3.2823 ', 'GAN acc 0.0000', 'Discriminator loss 0.0996', 'Discriminator accuracy 0.9766', 'Total loss: 3.3818', 'for batch', 9)
('GAN loss 3.3117 ', 'GAN acc 0.0000', 'Discriminator loss 0.0475', 'Discriminator accuracy 0.9922', 'Total loss: 3.3592', 'for batch', 10)
('GAN loss 3.3409 ', 'GAN acc 0.0000', 'Discriminator loss 0.0852', 'Discriminator accuracy 0.9805', 'Total loss: 3.4261', 'for batch', 11)
('GAN loss 3.3216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0655', 'Discriminator accuracy 0.9863', 'Total loss: 3.3871', 'for batch', 12)
('GAN loss 3.3618 ', 'GAN acc 0.0000', 'Discriminator loss 0.0613', 'Discriminator accuracy 0.9883', 'Total loss: 3.4231', 'for batch', 13)
('GAN loss 3.3409 ', 'GAN acc 0.0000', 'Discriminator loss 0.1027', 'Discriminator accuracy 0.9746', 'Total loss: 3.4436', 'for batch', 14)
('GAN loss 3.3260 ', 'GAN acc 0.0000', 'Discriminator loss 0.1105', 'Discriminator accuracy 0.9707', 'Total loss: 3.4365', 'for batch', 15)
('GAN loss 3.2875 ', 'GAN acc 0.0000', 'Discriminator loss 0.1147', 'Discriminator accuracy 0.9707', 'Total loss: 3.4022', 'for batch', 16)
('GAN loss 3.2793 ', 'GAN acc 0.0000', 'Discriminator loss 0.0810', 'Discriminator accuracy 0.9805', 'Total loss: 3.3603', 'for batch', 17)
('GAN loss 3.2868 ', 'GAN acc 0.0000', 'Discriminator loss 0.0466', 'Discriminator accuracy 0.9922', 'Total loss: 3.3333', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96171278)
('DISCRIMINATOR_Imagem FAKE=', 0.042913809)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.561563')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3157 ', 'GAN acc 0.0000', 'Discriminator loss 0.0945', 'Discriminator accuracy 0.9766', 'Total loss: 3.4101', 'for batch', 0)
('GAN loss 3.2952 ', 'GAN acc 0.0000', 'Discriminator loss 0.0860', 'Discriminator accuracy 0.9805', 'Total loss: 3.3813', 'for batch', 1)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5172 ', 'GAN acc 0.7812', 'Discriminator loss 2.4692', 'Discriminator accuracy 0.4824', 'Total loss: 2.9864', 'for batch', 0)
('GAN loss 0.2944 ', 'GAN acc 0.9531', 'Discriminator loss 1.4106', 'Discriminator accuracy 0.4473', 'Total loss: 1.7050', 'for batch', 1)
('GAN loss 0.2052 ', 'GAN acc 0.9805', 'Discriminator loss 1.1744', 'Discriminator accuracy 0.4648', 'Total loss: 1.3797', 'for batch', 2)
('GAN loss 0.2263 ', 'GAN acc 0.9688', 'Discriminator loss 1.1247', 'Discriminator accuracy 0.4727', 'Total loss: 1.3511', 'for batch', 3)
('GAN loss 0.2605 ', 'GAN acc 0.9531', 'Discriminator loss 1.1686', 'Discriminator accuracy 0.4688', 'Total loss: 1.4291', 'for batch', 4)
('GAN loss 0.3225 ', 'GAN acc 0.9258', 'Discriminator loss 1.0147', 'Discriminator accuracy 0.4824', 'Total loss: 1.3372', 'for batch', 5)
('GAN loss 0.3658 ', 'GAN acc 0.8672', 'Discriminator loss 0.9575', 'Discriminator accuracy 0.4961', 'Total loss: 1.3233', 'for batch', 6)
('GAN loss 0.4347 ', 'GAN acc 0.8516', 'Discriminator loss 0.8475', 'Discriminator accuracy 0.5078', 'Total loss: 1.2822', 'for batch', 7)
('GAN loss 0.4678 ', 'GAN acc 0.8320', 'Discriminator loss 0.7430', 'Discriminator accuracy 0.4980', 'Total loss: 1.2108', 'for batch', 8)
('GAN loss 0.4943 ', 'GAN acc 0.7773', 'Discriminator loss 0.7960', 'Discriminator accuracy 0.5195', 'Total loss: 1.2904', 'for batch', 9)
('GAN loss 0.4507 ', 'GAN acc 0.8555', 'Discriminator loss 0.6851', 'Discriminator accuracy 0.5449', 'Total loss: 1.1358', 'for batch', 10)
('GAN loss 0.4391 ', 'GAN acc 0.8633', 'Discriminator loss 0.7610', 'Discriminator accuracy 0.5000', 'Total loss: 1.2000', 'for batch', 11)
('GAN loss 0.4173 ', 'GAN acc 0.8789', 'Discriminator loss 0.7713', 'Discriminator accuracy 0.5137', 'Total loss: 1.1886', 'for batch', 12)
('GAN loss 0.4478 ', 'GAN acc 0.8516', 'Discriminator loss 0.7769', 'Discriminator accuracy 0.4922', 'Total loss: 1.2246', 'for batch', 13)
('GAN loss 0.3963 ', 'GAN acc 0.9023', 'Discriminator loss 0.7556', 'Discriminator accuracy 0.5059', 'Total loss: 1.1519', 'for batch', 14)
('GAN loss 0.4120 ', 'GAN acc 0.8945', 'Discriminator loss 0.8051', 'Discriminator accuracy 0.4844', 'Total loss: 1.2171', 'for batch', 15)
('GAN loss 0.4282 ', 'GAN acc 0.8906', 'Discriminator loss 0.7099', 'Discriminator accuracy 0.4883', 'Total loss: 1.1382', 'for batch', 16)
('GAN loss 0.5163 ', 'GAN acc 0.7969', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.4980', 'Total loss: 1.2207', 'for batch', 17)
('GAN loss 0.5361 ', 'GAN acc 0.8242', 'Discriminator loss 0.6400', 'Discriminator accuracy 0.5312', 'Total loss: 1.1761', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96227282)
('DISCRIMINATOR_Imagem FAKE=', 0.59437466)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:44.718457')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5582 ', 'GAN acc 0.7617', 'Discriminator loss 0.6481', 'Discriminator accuracy 0.5352', 'Total loss: 1.2063', 'for batch', 0)
('GAN loss 0.5986 ', 'GAN acc 0.7148', 'Discriminator loss 0.5678', 'Discriminator accuracy 0.5488', 'Total loss: 1.1664', 'for batch', 1)
('GAN loss 0.5923 ', 'GAN acc 0.7305', 'Discriminator loss 0.5569', 'Discriminator accuracy 0.5859', 'Total loss: 1.1491', 'for batch', 2)
('GAN loss 0.5576 ', 'GAN acc 0.7695', 'Discriminator loss 0.5831', 'Discriminator accuracy 0.5801', 'Total loss: 1.1408', 'for batch', 3)
('GAN loss 0.5909 ', 'GAN acc 0.7266', 'Discriminator loss 0.5002', 'Discriminator accuracy 0.5898', 'Total loss: 1.0911', 'for batch', 4)
('GAN loss 0.6108 ', 'GAN acc 0.6992', 'Discriminator loss 0.5376', 'Discriminator accuracy 0.5898', 'Total loss: 1.1484', 'for batch', 5)
('GAN loss 0.6213 ', 'GAN acc 0.6758', 'Discriminator loss 0.5444', 'Discriminator accuracy 0.5840', 'Total loss: 1.1657', 'for batch', 6)
('GAN loss 0.6043 ', 'GAN acc 0.7031', 'Discriminator loss 0.5533', 'Discriminator accuracy 0.5703', 'Total loss: 1.1576', 'for batch', 7)
('GAN loss 0.6664 ', 'GAN acc 0.6016', 'Discriminator loss 0.6138', 'Discriminator accuracy 0.5898', 'Total loss: 1.2802', 'for batch', 8)
('GAN loss 0.7310 ', 'GAN acc 0.4883', 'Discriminator loss 0.4547', 'Discriminator accuracy 0.6621', 'Total loss: 1.1857', 'for batch', 9)
('GAN loss 0.7097 ', 'GAN acc 0.5234', 'Discriminator loss 0.4251', 'Discriminator accuracy 0.6973', 'Total loss: 1.1348', 'for batch', 10)
('GAN loss 0.6613 ', 'GAN acc 0.6250', 'Discriminator loss 0.5556', 'Discriminator accuracy 0.6367', 'Total loss: 1.2169', 'for batch', 11)
('GAN loss 0.6455 ', 'GAN acc 0.6328', 'Discriminator loss 0.5438', 'Discriminator accuracy 0.6250', 'Total loss: 1.1893', 'for batch', 12)
('GAN loss 0.6721 ', 'GAN acc 0.5742', 'Discriminator loss 0.5981', 'Discriminator accuracy 0.6328', 'Total loss: 1.2703', 'for batch', 13)
('GAN loss 0.6605 ', 'GAN acc 0.6133', 'Discriminator loss 0.4665', 'Discriminator accuracy 0.6387', 'Total loss: 1.1270', 'for batch', 14)
('GAN loss 0.6658 ', 'GAN acc 0.6016', 'Discriminator loss 0.5364', 'Discriminator accuracy 0.6426', 'Total loss: 1.2022', 'for batch', 15)
('GAN loss 0.5972 ', 'GAN acc 0.7422', 'Discriminator loss 0.5031', 'Discriminator accuracy 0.6016', 'Total loss: 1.1003', 'for batch', 16)
('GAN loss 0.6446 ', 'GAN acc 0.6641', 'Discriminator loss 0.4730', 'Discriminator accuracy 0.6113', 'Total loss: 1.1176', 'for batch', 17)
('GAN loss 0.6627 ', 'GAN acc 0.5977', 'Discriminator loss 0.5019', 'Discriminator accuracy 0.6484', 'Total loss: 1.1646', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95585644)
('DISCRIMINATOR_Imagem FAKE=', 0.54559195)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.202699')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6567 ', 'GAN acc 0.6211', 'Discriminator loss 0.5263', 'Discriminator accuracy 0.5762', 'Total loss: 1.1830', 'for batch', 0)
('GAN loss 0.6596 ', 'GAN acc 0.5859', 'Discriminator loss 0.5313', 'Discriminator accuracy 0.6250', 'Total loss: 1.1910', 'for batch', 1)
('GAN loss 0.6395 ', 'GAN acc 0.6328', 'Discriminator loss 0.5789', 'Discriminator accuracy 0.6406', 'Total loss: 1.2184', 'for batch', 2)
('GAN loss 0.6231 ', 'GAN acc 0.6680', 'Discriminator loss 0.5087', 'Discriminator accuracy 0.5996', 'Total loss: 1.1318', 'for batch', 3)
('GAN loss 0.6469 ', 'GAN acc 0.6289', 'Discriminator loss 0.4800', 'Discriminator accuracy 0.6504', 'Total loss: 1.1269', 'for batch', 4)
('GAN loss 0.6405 ', 'GAN acc 0.6680', 'Discriminator loss 0.4832', 'Discriminator accuracy 0.6152', 'Total loss: 1.1238', 'for batch', 5)
('GAN loss 0.6417 ', 'GAN acc 0.6523', 'Discriminator loss 0.4694', 'Discriminator accuracy 0.6113', 'Total loss: 1.1111', 'for batch', 6)
('GAN loss 0.6882 ', 'GAN acc 0.5586', 'Discriminator loss 0.4283', 'Discriminator accuracy 0.6309', 'Total loss: 1.1165', 'for batch', 7)
('GAN loss 0.7267 ', 'GAN acc 0.4844', 'Discriminator loss 0.4751', 'Discriminator accuracy 0.6816', 'Total loss: 1.2018', 'for batch', 8)
('GAN loss 0.7393 ', 'GAN acc 0.4258', 'Discriminator loss 0.4273', 'Discriminator accuracy 0.6992', 'Total loss: 1.1666', 'for batch', 9)
('GAN loss 0.7191 ', 'GAN acc 0.4648', 'Discriminator loss 0.4517', 'Discriminator accuracy 0.7031', 'Total loss: 1.1708', 'for batch', 10)
('GAN loss 0.7263 ', 'GAN acc 0.4844', 'Discriminator loss 0.4650', 'Discriminator accuracy 0.7402', 'Total loss: 1.1913', 'for batch', 11)
('GAN loss 0.7133 ', 'GAN acc 0.4531', 'Discriminator loss 0.4345', 'Discriminator accuracy 0.6855', 'Total loss: 1.1478', 'for batch', 12)
('GAN loss 0.7267 ', 'GAN acc 0.4648', 'Discriminator loss 0.4637', 'Discriminator accuracy 0.7109', 'Total loss: 1.1904', 'for batch', 13)
('GAN loss 0.7004 ', 'GAN acc 0.5156', 'Discriminator loss 0.4266', 'Discriminator accuracy 0.7070', 'Total loss: 1.1269', 'for batch', 14)
('GAN loss 0.7117 ', 'GAN acc 0.4492', 'Discriminator loss 0.4449', 'Discriminator accuracy 0.6582', 'Total loss: 1.1566', 'for batch', 15)
('GAN loss 0.7363 ', 'GAN acc 0.4297', 'Discriminator loss 0.4737', 'Discriminator accuracy 0.6797', 'Total loss: 1.2100', 'for batch', 16)
('GAN loss 0.7617 ', 'GAN acc 0.3867', 'Discriminator loss 0.3907', 'Discriminator accuracy 0.7051', 'Total loss: 1.1525', 'for batch', 17)
('GAN loss 0.7673 ', 'GAN acc 0.3711', 'Discriminator loss 0.4324', 'Discriminator accuracy 0.7891', 'Total loss: 1.1997', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9601903)
('DISCRIMINATOR_Imagem FAKE=', 0.46114776)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.864306')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7802 ', 'GAN acc 0.3477', 'Discriminator loss 0.4030', 'Discriminator accuracy 0.7891', 'Total loss: 1.1833', 'for batch', 0)
('GAN loss 0.8070 ', 'GAN acc 0.2539', 'Discriminator loss 0.3777', 'Discriminator accuracy 0.8027', 'Total loss: 1.1847', 'for batch', 1)
('GAN loss 0.7761 ', 'GAN acc 0.3281', 'Discriminator loss 0.3849', 'Discriminator accuracy 0.8027', 'Total loss: 1.1610', 'for batch', 2)
('GAN loss 0.7821 ', 'GAN acc 0.2930', 'Discriminator loss 0.3716', 'Discriminator accuracy 0.7676', 'Total loss: 1.1536', 'for batch', 3)
('GAN loss 0.7696 ', 'GAN acc 0.3633', 'Discriminator loss 0.3606', 'Discriminator accuracy 0.7930', 'Total loss: 1.1302', 'for batch', 4)
('GAN loss 0.7775 ', 'GAN acc 0.3594', 'Discriminator loss 0.3703', 'Discriminator accuracy 0.7559', 'Total loss: 1.1478', 'for batch', 5)
('GAN loss 0.7730 ', 'GAN acc 0.3047', 'Discriminator loss 0.4080', 'Discriminator accuracy 0.7461', 'Total loss: 1.1810', 'for batch', 6)
('GAN loss 0.7936 ', 'GAN acc 0.3008', 'Discriminator loss 0.3821', 'Discriminator accuracy 0.7578', 'Total loss: 1.1756', 'for batch', 7)
('GAN loss 0.7988 ', 'GAN acc 0.3438', 'Discriminator loss 0.5209', 'Discriminator accuracy 0.7773', 'Total loss: 1.3196', 'for batch', 8)
('GAN loss 0.8052 ', 'GAN acc 0.2734', 'Discriminator loss 0.3755', 'Discriminator accuracy 0.7832', 'Total loss: 1.1806', 'for batch', 9)
('GAN loss 0.8111 ', 'GAN acc 0.2656', 'Discriminator loss 0.3334', 'Discriminator accuracy 0.8359', 'Total loss: 1.1445', 'for batch', 10)
('GAN loss 0.8579 ', 'GAN acc 0.2266', 'Discriminator loss 0.4598', 'Discriminator accuracy 0.8379', 'Total loss: 1.3177', 'for batch', 11)
('GAN loss 0.8663 ', 'GAN acc 0.1953', 'Discriminator loss 0.3960', 'Discriminator accuracy 0.8496', 'Total loss: 1.2623', 'for batch', 12)
('GAN loss 0.8645 ', 'GAN acc 0.2031', 'Discriminator loss 0.3714', 'Discriminator accuracy 0.8516', 'Total loss: 1.2359', 'for batch', 13)
('GAN loss 0.8900 ', 'GAN acc 0.2109', 'Discriminator loss 0.4440', 'Discriminator accuracy 0.8477', 'Total loss: 1.3340', 'for batch', 14)
('GAN loss 0.8918 ', 'GAN acc 0.1562', 'Discriminator loss 0.4106', 'Discriminator accuracy 0.8340', 'Total loss: 1.3024', 'for batch', 15)
('GAN loss 0.8962 ', 'GAN acc 0.1680', 'Discriminator loss 0.3716', 'Discriminator accuracy 0.8398', 'Total loss: 1.2678', 'for batch', 16)
('GAN loss 0.9021 ', 'GAN acc 0.1445', 'Discriminator loss 0.3712', 'Discriminator accuracy 0.8770', 'Total loss: 1.2733', 'for batch', 17)
('GAN loss 0.8888 ', 'GAN acc 0.1797', 'Discriminator loss 0.4190', 'Discriminator accuracy 0.8828', 'Total loss: 1.3079', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95880055)
('DISCRIMINATOR_Imagem FAKE=', 0.40723979)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.464545')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8960 ', 'GAN acc 0.1484', 'Discriminator loss 0.3381', 'Discriminator accuracy 0.8574', 'Total loss: 1.2341', 'for batch', 0)
('GAN loss 0.8916 ', 'GAN acc 0.1484', 'Discriminator loss 0.3984', 'Discriminator accuracy 0.8594', 'Total loss: 1.2899', 'for batch', 1)
('GAN loss 0.8268 ', 'GAN acc 0.2422', 'Discriminator loss 0.4246', 'Discriminator accuracy 0.8613', 'Total loss: 1.2514', 'for batch', 2)
('GAN loss 0.8386 ', 'GAN acc 0.2461', 'Discriminator loss 0.3907', 'Discriminator accuracy 0.8262', 'Total loss: 1.2293', 'for batch', 3)
('GAN loss 0.8856 ', 'GAN acc 0.1680', 'Discriminator loss 0.3532', 'Discriminator accuracy 0.8594', 'Total loss: 1.2388', 'for batch', 4)
('GAN loss 0.9130 ', 'GAN acc 0.1367', 'Discriminator loss 0.3407', 'Discriminator accuracy 0.8594', 'Total loss: 1.2537', 'for batch', 5)
('GAN loss 0.9025 ', 'GAN acc 0.1641', 'Discriminator loss 0.3630', 'Discriminator accuracy 0.8730', 'Total loss: 1.2655', 'for batch', 6)
('GAN loss 0.9525 ', 'GAN acc 0.0742', 'Discriminator loss 0.3026', 'Discriminator accuracy 0.9199', 'Total loss: 1.2551', 'for batch', 7)
('GAN loss 0.9409 ', 'GAN acc 0.0625', 'Discriminator loss 0.4922', 'Discriminator accuracy 0.9004', 'Total loss: 1.4331', 'for batch', 8)
('GAN loss 0.9395 ', 'GAN acc 0.1055', 'Discriminator loss 0.3646', 'Discriminator accuracy 0.9258', 'Total loss: 1.3041', 'for batch', 9)
('GAN loss 0.9973 ', 'GAN acc 0.0547', 'Discriminator loss 0.2681', 'Discriminator accuracy 0.9434', 'Total loss: 1.2655', 'for batch', 10)
('GAN loss 1.0296 ', 'GAN acc 0.0273', 'Discriminator loss 0.3797', 'Discriminator accuracy 0.9375', 'Total loss: 1.4092', 'for batch', 11)
('GAN loss 1.0108 ', 'GAN acc 0.0508', 'Discriminator loss 0.3127', 'Discriminator accuracy 0.9395', 'Total loss: 1.3235', 'for batch', 12)
('GAN loss 0.9919 ', 'GAN acc 0.0469', 'Discriminator loss 0.3513', 'Discriminator accuracy 0.9531', 'Total loss: 1.3432', 'for batch', 13)
('GAN loss 0.9907 ', 'GAN acc 0.0469', 'Discriminator loss 0.2911', 'Discriminator accuracy 0.9453', 'Total loss: 1.2818', 'for batch', 14)
('GAN loss 0.9933 ', 'GAN acc 0.0430', 'Discriminator loss 0.2947', 'Discriminator accuracy 0.9316', 'Total loss: 1.2879', 'for batch', 15)
('GAN loss 0.9914 ', 'GAN acc 0.0664', 'Discriminator loss 0.3188', 'Discriminator accuracy 0.9414', 'Total loss: 1.3102', 'for batch', 16)
('GAN loss 0.9977 ', 'GAN acc 0.0664', 'Discriminator loss 0.3229', 'Discriminator accuracy 0.9473', 'Total loss: 1.3206', 'for batch', 17)
('GAN loss 0.9617 ', 'GAN acc 0.0664', 'Discriminator loss 0.3083', 'Discriminator accuracy 0.9453', 'Total loss: 1.2699', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95888674)
('DISCRIMINATOR_Imagem FAKE=', 0.39139226)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.028867')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9509 ', 'GAN acc 0.0469', 'Discriminator loss 0.3348', 'Discriminator accuracy 0.9355', 'Total loss: 1.2856', 'for batch', 0)
('GAN loss 0.9686 ', 'GAN acc 0.0625', 'Discriminator loss 0.3194', 'Discriminator accuracy 0.9297', 'Total loss: 1.2881', 'for batch', 1)
('GAN loss 0.9664 ', 'GAN acc 0.0312', 'Discriminator loss 0.3148', 'Discriminator accuracy 0.9629', 'Total loss: 1.2812', 'for batch', 2)
('GAN loss 0.9566 ', 'GAN acc 0.0469', 'Discriminator loss 0.2932', 'Discriminator accuracy 0.9492', 'Total loss: 1.2499', 'for batch', 3)
('GAN loss 0.9931 ', 'GAN acc 0.0312', 'Discriminator loss 0.2802', 'Discriminator accuracy 0.9629', 'Total loss: 1.2733', 'for batch', 4)
('GAN loss 0.9956 ', 'GAN acc 0.0234', 'Discriminator loss 0.2845', 'Discriminator accuracy 0.9629', 'Total loss: 1.2801', 'for batch', 5)
('GAN loss 1.0351 ', 'GAN acc 0.0156', 'Discriminator loss 0.2781', 'Discriminator accuracy 0.9609', 'Total loss: 1.3133', 'for batch', 6)
('GAN loss 1.0811 ', 'GAN acc 0.0234', 'Discriminator loss 0.2515', 'Discriminator accuracy 0.9707', 'Total loss: 1.3325', 'for batch', 7)
('GAN loss 1.1082 ', 'GAN acc 0.0078', 'Discriminator loss 0.3245', 'Discriminator accuracy 0.9492', 'Total loss: 1.4327', 'for batch', 8)
('GAN loss 1.1553 ', 'GAN acc 0.0117', 'Discriminator loss 0.2722', 'Discriminator accuracy 0.9590', 'Total loss: 1.4275', 'for batch', 9)
('GAN loss 1.2173 ', 'GAN acc 0.0000', 'Discriminator loss 0.2346', 'Discriminator accuracy 0.9863', 'Total loss: 1.4519', 'for batch', 10)
('GAN loss 1.1895 ', 'GAN acc 0.0039', 'Discriminator loss 0.3370', 'Discriminator accuracy 0.9629', 'Total loss: 1.5265', 'for batch', 11)
('GAN loss 1.1948 ', 'GAN acc 0.0000', 'Discriminator loss 0.2413', 'Discriminator accuracy 0.9707', 'Total loss: 1.4361', 'for batch', 12)
('GAN loss 1.1067 ', 'GAN acc 0.0117', 'Discriminator loss 0.3321', 'Discriminator accuracy 0.9707', 'Total loss: 1.4388', 'for batch', 13)
('GAN loss 1.1032 ', 'GAN acc 0.0078', 'Discriminator loss 0.2495', 'Discriminator accuracy 0.9629', 'Total loss: 1.3527', 'for batch', 14)
('GAN loss 1.1030 ', 'GAN acc 0.0039', 'Discriminator loss 0.2901', 'Discriminator accuracy 0.9648', 'Total loss: 1.3931', 'for batch', 15)
('GAN loss 1.1054 ', 'GAN acc 0.0195', 'Discriminator loss 0.2955', 'Discriminator accuracy 0.9375', 'Total loss: 1.4009', 'for batch', 16)
('GAN loss 1.0972 ', 'GAN acc 0.0078', 'Discriminator loss 0.2753', 'Discriminator accuracy 0.9414', 'Total loss: 1.3725', 'for batch', 17)
('GAN loss 1.0835 ', 'GAN acc 0.0234', 'Discriminator loss 0.3064', 'Discriminator accuracy 0.9473', 'Total loss: 1.3899', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9569912)
('DISCRIMINATOR_Imagem FAKE=', 0.35159773)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.592072')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1303 ', 'GAN acc 0.0312', 'Discriminator loss 0.2864', 'Discriminator accuracy 0.9395', 'Total loss: 1.4167', 'for batch', 0)
('GAN loss 1.1746 ', 'GAN acc 0.0195', 'Discriminator loss 0.2802', 'Discriminator accuracy 0.9551', 'Total loss: 1.4548', 'for batch', 1)
('GAN loss 1.1340 ', 'GAN acc 0.0508', 'Discriminator loss 0.4004', 'Discriminator accuracy 0.9277', 'Total loss: 1.5344', 'for batch', 2)
('GAN loss 1.0738 ', 'GAN acc 0.0625', 'Discriminator loss 0.3071', 'Discriminator accuracy 0.9414', 'Total loss: 1.3809', 'for batch', 3)
('GAN loss 1.1245 ', 'GAN acc 0.0547', 'Discriminator loss 0.2936', 'Discriminator accuracy 0.9258', 'Total loss: 1.4182', 'for batch', 4)
('GAN loss 1.1977 ', 'GAN acc 0.0312', 'Discriminator loss 0.2724', 'Discriminator accuracy 0.9473', 'Total loss: 1.4701', 'for batch', 5)
('GAN loss 1.2069 ', 'GAN acc 0.0273', 'Discriminator loss 0.2520', 'Discriminator accuracy 0.9570', 'Total loss: 1.4588', 'for batch', 6)
('GAN loss 1.3406 ', 'GAN acc 0.0273', 'Discriminator loss 0.2129', 'Discriminator accuracy 0.9688', 'Total loss: 1.5536', 'for batch', 7)
('GAN loss 1.3234 ', 'GAN acc 0.0234', 'Discriminator loss 0.3339', 'Discriminator accuracy 0.9512', 'Total loss: 1.6573', 'for batch', 8)
('GAN loss 1.2683 ', 'GAN acc 0.0234', 'Discriminator loss 0.2617', 'Discriminator accuracy 0.9570', 'Total loss: 1.5300', 'for batch', 9)
('GAN loss 1.3041 ', 'GAN acc 0.0117', 'Discriminator loss 0.2792', 'Discriminator accuracy 0.9707', 'Total loss: 1.5833', 'for batch', 10)
('GAN loss 1.3024 ', 'GAN acc 0.0039', 'Discriminator loss 0.3401', 'Discriminator accuracy 0.9609', 'Total loss: 1.6425', 'for batch', 11)
('GAN loss 1.2986 ', 'GAN acc 0.0117', 'Discriminator loss 0.2549', 'Discriminator accuracy 0.9688', 'Total loss: 1.5536', 'for batch', 12)
('GAN loss 1.3572 ', 'GAN acc 0.0078', 'Discriminator loss 0.2441', 'Discriminator accuracy 0.9746', 'Total loss: 1.6013', 'for batch', 13)
('GAN loss 1.3572 ', 'GAN acc 0.0195', 'Discriminator loss 0.2315', 'Discriminator accuracy 0.9629', 'Total loss: 1.5886', 'for batch', 14)
('GAN loss 1.3768 ', 'GAN acc 0.0039', 'Discriminator loss 0.2982', 'Discriminator accuracy 0.9492', 'Total loss: 1.6750', 'for batch', 15)
('GAN loss 1.3597 ', 'GAN acc 0.0078', 'Discriminator loss 0.2738', 'Discriminator accuracy 0.9512', 'Total loss: 1.6335', 'for batch', 16)
('GAN loss 1.3806 ', 'GAN acc 0.0039', 'Discriminator loss 0.2393', 'Discriminator accuracy 0.9648', 'Total loss: 1.6199', 'for batch', 17)
('GAN loss 1.3503 ', 'GAN acc 0.0000', 'Discriminator loss 0.2638', 'Discriminator accuracy 0.9766', 'Total loss: 1.6141', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95648241)
('DISCRIMINATOR_Imagem FAKE=', 0.27000904)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.091047')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 1.3514 ', 'GAN acc 0.0000', 'Discriminator loss 0.2702', 'Discriminator accuracy 0.9551', 'Total loss: 1.6216', 'for batch', 0)
('GAN loss 1.3725 ', 'GAN acc 0.0078', 'Discriminator loss 0.2549', 'Discriminator accuracy 0.9648', 'Total loss: 1.6274', 'for batch', 1)
('GAN loss 1.3648 ', 'GAN acc 0.0000', 'Discriminator loss 0.3183', 'Discriminator accuracy 0.9707', 'Total loss: 1.6832', 'for batch', 2)
('GAN loss 1.3026 ', 'GAN acc 0.0039', 'Discriminator loss 0.2466', 'Discriminator accuracy 0.9707', 'Total loss: 1.5492', 'for batch', 3)
('GAN loss 1.2807 ', 'GAN acc 0.0078', 'Discriminator loss 0.2210', 'Discriminator accuracy 0.9688', 'Total loss: 1.5017', 'for batch', 4)
('GAN loss 1.2829 ', 'GAN acc 0.0117', 'Discriminator loss 0.2523', 'Discriminator accuracy 0.9785', 'Total loss: 1.5352', 'for batch', 5)
('GAN loss 1.3171 ', 'GAN acc 0.0117', 'Discriminator loss 0.2384', 'Discriminator accuracy 0.9629', 'Total loss: 1.5555', 'for batch', 6)
('GAN loss 1.3567 ', 'GAN acc 0.0000', 'Discriminator loss 0.1969', 'Discriminator accuracy 0.9824', 'Total loss: 1.5536', 'for batch', 7)
('GAN loss 1.3478 ', 'GAN acc 0.0039', 'Discriminator loss 0.3056', 'Discriminator accuracy 0.9590', 'Total loss: 1.6533', 'for batch', 8)
('GAN loss 1.3913 ', 'GAN acc 0.0039', 'Discriminator loss 0.2211', 'Discriminator accuracy 0.9648', 'Total loss: 1.6124', 'for batch', 9)
('GAN loss 1.4456 ', 'GAN acc 0.0039', 'Discriminator loss 0.1678', 'Discriminator accuracy 0.9902', 'Total loss: 1.6133', 'for batch', 10)
('GAN loss 1.4640 ', 'GAN acc 0.0000', 'Discriminator loss 0.2783', 'Discriminator accuracy 0.9648', 'Total loss: 1.7423', 'for batch', 11)
('GAN loss 1.4225 ', 'GAN acc 0.0000', 'Discriminator loss 0.2163', 'Discriminator accuracy 0.9707', 'Total loss: 1.6388', 'for batch', 12)
('GAN loss 1.3651 ', 'GAN acc 0.0000', 'Discriminator loss 0.1871', 'Discriminator accuracy 0.9805', 'Total loss: 1.5522', 'for batch', 13)
('GAN loss 1.3440 ', 'GAN acc 0.0039', 'Discriminator loss 0.2280', 'Discriminator accuracy 0.9707', 'Total loss: 1.5720', 'for batch', 14)
('GAN loss 1.4028 ', 'GAN acc 0.0039', 'Discriminator loss 0.2387', 'Discriminator accuracy 0.9609', 'Total loss: 1.6415', 'for batch', 15)
('GAN loss 1.4799 ', 'GAN acc 0.0039', 'Discriminator loss 0.2309', 'Discriminator accuracy 0.9609', 'Total loss: 1.7108', 'for batch', 16)
('GAN loss 1.5648 ', 'GAN acc 0.0000', 'Discriminator loss 0.1903', 'Discriminator accuracy 0.9766', 'Total loss: 1.7551', 'for batch', 17)
('GAN loss 1.6207 ', 'GAN acc 0.0000', 'Discriminator loss 0.1812', 'Discriminator accuracy 0.9785', 'Total loss: 1.8019', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95434493)
('DISCRIMINATOR_Imagem FAKE=', 0.20609243)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.637730')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 1.6237 ', 'GAN acc 0.0000', 'Discriminator loss 0.2112', 'Discriminator accuracy 0.9707', 'Total loss: 1.8348', 'for batch', 0)
('GAN loss 1.6437 ', 'GAN acc 0.0078', 'Discriminator loss 0.1800', 'Discriminator accuracy 0.9688', 'Total loss: 1.8237', 'for batch', 1)
('GAN loss 1.5683 ', 'GAN acc 0.0039', 'Discriminator loss 0.2645', 'Discriminator accuracy 0.9648', 'Total loss: 1.8328', 'for batch', 2)
('GAN loss 1.4552 ', 'GAN acc 0.0117', 'Discriminator loss 0.2139', 'Discriminator accuracy 0.9727', 'Total loss: 1.6691', 'for batch', 3)
('GAN loss 1.4222 ', 'GAN acc 0.0078', 'Discriminator loss 0.1983', 'Discriminator accuracy 0.9688', 'Total loss: 1.6205', 'for batch', 4)
('GAN loss 1.4451 ', 'GAN acc 0.0039', 'Discriminator loss 0.2060', 'Discriminator accuracy 0.9707', 'Total loss: 1.6511', 'for batch', 5)
('GAN loss 1.5639 ', 'GAN acc 0.0039', 'Discriminator loss 0.2067', 'Discriminator accuracy 0.9727', 'Total loss: 1.7706', 'for batch', 6)
('GAN loss 1.6967 ', 'GAN acc 0.0000', 'Discriminator loss 0.1841', 'Discriminator accuracy 0.9785', 'Total loss: 1.8808', 'for batch', 7)
('GAN loss 1.6575 ', 'GAN acc 0.0000', 'Discriminator loss 0.2777', 'Discriminator accuracy 0.9590', 'Total loss: 1.9352', 'for batch', 8)
('GAN loss 1.7444 ', 'GAN acc 0.0039', 'Discriminator loss 0.2166', 'Discriminator accuracy 0.9629', 'Total loss: 1.9609', 'for batch', 9)
('GAN loss 1.7741 ', 'GAN acc 0.0000', 'Discriminator loss 0.1445', 'Discriminator accuracy 0.9883', 'Total loss: 1.9186', 'for batch', 10)
('GAN loss 1.7223 ', 'GAN acc 0.0000', 'Discriminator loss 0.2714', 'Discriminator accuracy 0.9590', 'Total loss: 1.9938', 'for batch', 11)
('GAN loss 1.6757 ', 'GAN acc 0.0000', 'Discriminator loss 0.1900', 'Discriminator accuracy 0.9746', 'Total loss: 1.8657', 'for batch', 12)
('GAN loss 1.6426 ', 'GAN acc 0.0039', 'Discriminator loss 0.1611', 'Discriminator accuracy 0.9785', 'Total loss: 1.8037', 'for batch', 13)
('GAN loss 1.6926 ', 'GAN acc 0.0000', 'Discriminator loss 0.1901', 'Discriminator accuracy 0.9707', 'Total loss: 1.8827', 'for batch', 14)
('GAN loss 1.7397 ', 'GAN acc 0.0039', 'Discriminator loss 0.2063', 'Discriminator accuracy 0.9629', 'Total loss: 1.9460', 'for batch', 15)
('GAN loss 1.7458 ', 'GAN acc 0.0000', 'Discriminator loss 0.1955', 'Discriminator accuracy 0.9629', 'Total loss: 1.9413', 'for batch', 16)
('GAN loss 1.8567 ', 'GAN acc 0.0039', 'Discriminator loss 0.1922', 'Discriminator accuracy 0.9727', 'Total loss: 2.0489', 'for batch', 17)
('GAN loss 1.7993 ', 'GAN acc 0.0000', 'Discriminator loss 0.1842', 'Discriminator accuracy 0.9746', 'Total loss: 1.9835', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.94875681)
('DISCRIMINATOR_Imagem FAKE=', 0.18027809)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.160057')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 1.7492 ', 'GAN acc 0.0000', 'Discriminator loss 0.2300', 'Discriminator accuracy 0.9648', 'Total loss: 1.9792', 'for batch', 0)
('GAN loss 1.7241 ', 'GAN acc 0.0078', 'Discriminator loss 0.2214', 'Discriminator accuracy 0.9668', 'Total loss: 1.9455', 'for batch', 1)
('GAN loss 1.5823 ', 'GAN acc 0.0000', 'Discriminator loss 0.2454', 'Discriminator accuracy 0.9668', 'Total loss: 1.8278', 'for batch', 2)
('GAN loss 1.6509 ', 'GAN acc 0.0039', 'Discriminator loss 0.1735', 'Discriminator accuracy 0.9727', 'Total loss: 1.8245', 'for batch', 3)
('GAN loss 1.7895 ', 'GAN acc 0.0000', 'Discriminator loss 0.1870', 'Discriminator accuracy 0.9688', 'Total loss: 1.9764', 'for batch', 4)
('GAN loss 1.8910 ', 'GAN acc 0.0000', 'Discriminator loss 0.1509', 'Discriminator accuracy 0.9844', 'Total loss: 2.0419', 'for batch', 5)
('GAN loss 1.9158 ', 'GAN acc 0.0000', 'Discriminator loss 0.1674', 'Discriminator accuracy 0.9688', 'Total loss: 2.0833', 'for batch', 6)
('GAN loss 2.0565 ', 'GAN acc 0.0000', 'Discriminator loss 0.1242', 'Discriminator accuracy 0.9863', 'Total loss: 2.1807', 'for batch', 7)
('GAN loss 2.1165 ', 'GAN acc 0.0000', 'Discriminator loss 0.2509', 'Discriminator accuracy 0.9648', 'Total loss: 2.3674', 'for batch', 8)
('GAN loss 2.1089 ', 'GAN acc 0.0000', 'Discriminator loss 0.1803', 'Discriminator accuracy 0.9668', 'Total loss: 2.2893', 'for batch', 9)
('GAN loss 2.1038 ', 'GAN acc 0.0000', 'Discriminator loss 0.1272', 'Discriminator accuracy 0.9863', 'Total loss: 2.2310', 'for batch', 10)
('GAN loss 2.0215 ', 'GAN acc 0.0000', 'Discriminator loss 0.2881', 'Discriminator accuracy 0.9648', 'Total loss: 2.3096', 'for batch', 11)
('GAN loss 1.8835 ', 'GAN acc 0.0000', 'Discriminator loss 0.1945', 'Discriminator accuracy 0.9727', 'Total loss: 2.0780', 'for batch', 12)
('GAN loss 1.8780 ', 'GAN acc 0.0000', 'Discriminator loss 0.1230', 'Discriminator accuracy 0.9863', 'Total loss: 2.0010', 'for batch', 13)
('GAN loss 1.9550 ', 'GAN acc 0.0000', 'Discriminator loss 0.1670', 'Discriminator accuracy 0.9707', 'Total loss: 2.1220', 'for batch', 14)
('GAN loss 2.0964 ', 'GAN acc 0.0000', 'Discriminator loss 0.1592', 'Discriminator accuracy 0.9648', 'Total loss: 2.2557', 'for batch', 15)
('GAN loss 2.1855 ', 'GAN acc 0.0000', 'Discriminator loss 0.2029', 'Discriminator accuracy 0.9590', 'Total loss: 2.3884', 'for batch', 16)
('GAN loss 2.2031 ', 'GAN acc 0.0000', 'Discriminator loss 0.1314', 'Discriminator accuracy 0.9766', 'Total loss: 2.3345', 'for batch', 17)
('GAN loss 2.0834 ', 'GAN acc 0.0000', 'Discriminator loss 0.1704', 'Discriminator accuracy 0.9707', 'Total loss: 2.2538', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95054013)
('DISCRIMINATOR_Imagem FAKE=', 0.11437222)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.665072')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 2.0153 ', 'GAN acc 0.0000', 'Discriminator loss 0.2032', 'Discriminator accuracy 0.9668', 'Total loss: 2.2185', 'for batch', 0)
('GAN loss 2.0020 ', 'GAN acc 0.0000', 'Discriminator loss 0.1611', 'Discriminator accuracy 0.9688', 'Total loss: 2.1630', 'for batch', 1)
('GAN loss 1.8514 ', 'GAN acc 0.0078', 'Discriminator loss 0.2005', 'Discriminator accuracy 0.9746', 'Total loss: 2.0519', 'for batch', 2)
('GAN loss 1.9386 ', 'GAN acc 0.0000', 'Discriminator loss 0.1771', 'Discriminator accuracy 0.9766', 'Total loss: 2.1157', 'for batch', 3)
('GAN loss 2.0626 ', 'GAN acc 0.0000', 'Discriminator loss 0.1719', 'Discriminator accuracy 0.9688', 'Total loss: 2.2345', 'for batch', 4)
('GAN loss 2.1629 ', 'GAN acc 0.0000', 'Discriminator loss 0.1219', 'Discriminator accuracy 0.9824', 'Total loss: 2.2848', 'for batch', 5)
('GAN loss 2.1461 ', 'GAN acc 0.0000', 'Discriminator loss 0.1508', 'Discriminator accuracy 0.9746', 'Total loss: 2.2969', 'for batch', 6)
('GAN loss 2.3033 ', 'GAN acc 0.0000', 'Discriminator loss 0.1031', 'Discriminator accuracy 0.9844', 'Total loss: 2.4065', 'for batch', 7)
('GAN loss 2.3227 ', 'GAN acc 0.0000', 'Discriminator loss 0.2219', 'Discriminator accuracy 0.9629', 'Total loss: 2.5446', 'for batch', 8)
('GAN loss 2.2504 ', 'GAN acc 0.0000', 'Discriminator loss 0.1667', 'Discriminator accuracy 0.9648', 'Total loss: 2.4172', 'for batch', 9)
('GAN loss 2.2236 ', 'GAN acc 0.0000', 'Discriminator loss 0.1034', 'Discriminator accuracy 0.9902', 'Total loss: 2.3270', 'for batch', 10)
('GAN loss 2.2031 ', 'GAN acc 0.0000', 'Discriminator loss 0.2018', 'Discriminator accuracy 0.9727', 'Total loss: 2.4048', 'for batch', 11)
('GAN loss 2.2469 ', 'GAN acc 0.0000', 'Discriminator loss 0.1232', 'Discriminator accuracy 0.9766', 'Total loss: 2.3701', 'for batch', 12)
('GAN loss 2.1025 ', 'GAN acc 0.0000', 'Discriminator loss 0.1190', 'Discriminator accuracy 0.9824', 'Total loss: 2.2215', 'for batch', 13)
('GAN loss 2.0586 ', 'GAN acc 0.0000', 'Discriminator loss 0.1550', 'Discriminator accuracy 0.9727', 'Total loss: 2.2136', 'for batch', 14)
('GAN loss 2.0959 ', 'GAN acc 0.0039', 'Discriminator loss 0.1650', 'Discriminator accuracy 0.9648', 'Total loss: 2.2609', 'for batch', 15)
('GAN loss 2.1279 ', 'GAN acc 0.0000', 'Discriminator loss 0.1690', 'Discriminator accuracy 0.9668', 'Total loss: 2.2970', 'for batch', 16)
('GAN loss 2.3337 ', 'GAN acc 0.0000', 'Discriminator loss 0.1302', 'Discriminator accuracy 0.9785', 'Total loss: 2.4639', 'for batch', 17)
('GAN loss 2.2730 ', 'GAN acc 0.0000', 'Discriminator loss 0.1358', 'Discriminator accuracy 0.9785', 'Total loss: 2.4088', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95049584)
('DISCRIMINATOR_Imagem FAKE=', 0.08856824)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.173128')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 2.3006 ', 'GAN acc 0.0000', 'Discriminator loss 0.1566', 'Discriminator accuracy 0.9688', 'Total loss: 2.4573', 'for batch', 0)
('GAN loss 2.2888 ', 'GAN acc 0.0000', 'Discriminator loss 0.1535', 'Discriminator accuracy 0.9668', 'Total loss: 2.4423', 'for batch', 1)
('GAN loss 2.0641 ', 'GAN acc 0.0039', 'Discriminator loss 0.1692', 'Discriminator accuracy 0.9727', 'Total loss: 2.2333', 'for batch', 2)
('GAN loss 2.0685 ', 'GAN acc 0.0039', 'Discriminator loss 0.1309', 'Discriminator accuracy 0.9805', 'Total loss: 2.1994', 'for batch', 3)
('GAN loss 2.1899 ', 'GAN acc 0.0000', 'Discriminator loss 0.1611', 'Discriminator accuracy 0.9688', 'Total loss: 2.3510', 'for batch', 4)
('GAN loss 2.2880 ', 'GAN acc 0.0000', 'Discriminator loss 0.1415', 'Discriminator accuracy 0.9824', 'Total loss: 2.4295', 'for batch', 5)
('GAN loss 2.2083 ', 'GAN acc 0.0000', 'Discriminator loss 0.1349', 'Discriminator accuracy 0.9746', 'Total loss: 2.3432', 'for batch', 6)
('GAN loss 2.2803 ', 'GAN acc 0.0039', 'Discriminator loss 0.1179', 'Discriminator accuracy 0.9805', 'Total loss: 2.3982', 'for batch', 7)
('GAN loss 2.1760 ', 'GAN acc 0.0039', 'Discriminator loss 0.2079', 'Discriminator accuracy 0.9688', 'Total loss: 2.3839', 'for batch', 8)
('GAN loss 2.3239 ', 'GAN acc 0.0000', 'Discriminator loss 0.1871', 'Discriminator accuracy 0.9668', 'Total loss: 2.5110', 'for batch', 9)
('GAN loss 2.7259 ', 'GAN acc 0.0000', 'Discriminator loss 0.0969', 'Discriminator accuracy 0.9902', 'Total loss: 2.8227', 'for batch', 10)
('GAN loss 2.6071 ', 'GAN acc 0.0000', 'Discriminator loss 0.2107', 'Discriminator accuracy 0.9688', 'Total loss: 2.8179', 'for batch', 11)
('GAN loss 2.3502 ', 'GAN acc 0.0000', 'Discriminator loss 0.1511', 'Discriminator accuracy 0.9746', 'Total loss: 2.5013', 'for batch', 12)
('GAN loss 2.2487 ', 'GAN acc 0.0000', 'Discriminator loss 0.1215', 'Discriminator accuracy 0.9824', 'Total loss: 2.3702', 'for batch', 13)
('GAN loss 2.2739 ', 'GAN acc 0.0039', 'Discriminator loss 0.1790', 'Discriminator accuracy 0.9668', 'Total loss: 2.4529', 'for batch', 14)
('GAN loss 2.2234 ', 'GAN acc 0.0000', 'Discriminator loss 0.1881', 'Discriminator accuracy 0.9609', 'Total loss: 2.4115', 'for batch', 15)
('GAN loss 2.2262 ', 'GAN acc 0.0039', 'Discriminator loss 0.2001', 'Discriminator accuracy 0.9609', 'Total loss: 2.4263', 'for batch', 16)
('GAN loss 2.4534 ', 'GAN acc 0.0000', 'Discriminator loss 0.1358', 'Discriminator accuracy 0.9785', 'Total loss: 2.5891', 'for batch', 17)
('GAN loss 2.5049 ', 'GAN acc 0.0000', 'Discriminator loss 0.1450', 'Discriminator accuracy 0.9766', 'Total loss: 2.6499', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.94905746)
('DISCRIMINATOR_Imagem FAKE=', 0.084164701)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.679489')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 2.5396 ', 'GAN acc 0.0000', 'Discriminator loss 0.1560', 'Discriminator accuracy 0.9688', 'Total loss: 2.6956', 'for batch', 0)
('GAN loss 2.5276 ', 'GAN acc 0.0000', 'Discriminator loss 0.1447', 'Discriminator accuracy 0.9707', 'Total loss: 2.6723', 'for batch', 1)
('GAN loss 2.4059 ', 'GAN acc 0.0000', 'Discriminator loss 0.1752', 'Discriminator accuracy 0.9707', 'Total loss: 2.5811', 'for batch', 2)
('GAN loss 2.2985 ', 'GAN acc 0.0000', 'Discriminator loss 0.1270', 'Discriminator accuracy 0.9766', 'Total loss: 2.4256', 'for batch', 3)
('GAN loss 2.1938 ', 'GAN acc 0.0000', 'Discriminator loss 0.1515', 'Discriminator accuracy 0.9707', 'Total loss: 2.3453', 'for batch', 4)
('GAN loss 2.3110 ', 'GAN acc 0.0039', 'Discriminator loss 0.1334', 'Discriminator accuracy 0.9844', 'Total loss: 2.4443', 'for batch', 5)
('GAN loss 2.5457 ', 'GAN acc 0.0000', 'Discriminator loss 0.1362', 'Discriminator accuracy 0.9766', 'Total loss: 2.6820', 'for batch', 6)
('GAN loss 2.6608 ', 'GAN acc 0.0000', 'Discriminator loss 0.0938', 'Discriminator accuracy 0.9824', 'Total loss: 2.7546', 'for batch', 7)
('GAN loss 2.6686 ', 'GAN acc 0.0000', 'Discriminator loss 0.2030', 'Discriminator accuracy 0.9668', 'Total loss: 2.8717', 'for batch', 8)
('GAN loss 2.6278 ', 'GAN acc 0.0000', 'Discriminator loss 0.1698', 'Discriminator accuracy 0.9648', 'Total loss: 2.7976', 'for batch', 9)
('GAN loss 2.7988 ', 'GAN acc 0.0000', 'Discriminator loss 0.0627', 'Discriminator accuracy 0.9922', 'Total loss: 2.8615', 'for batch', 10)
('GAN loss 2.6939 ', 'GAN acc 0.0000', 'Discriminator loss 0.1944', 'Discriminator accuracy 0.9688', 'Total loss: 2.8883', 'for batch', 11)
('GAN loss 2.4416 ', 'GAN acc 0.0000', 'Discriminator loss 0.1297', 'Discriminator accuracy 0.9766', 'Total loss: 2.5713', 'for batch', 12)
('GAN loss 2.3322 ', 'GAN acc 0.0000', 'Discriminator loss 0.1243', 'Discriminator accuracy 0.9824', 'Total loss: 2.4565', 'for batch', 13)
('GAN loss 2.3593 ', 'GAN acc 0.0000', 'Discriminator loss 0.1404', 'Discriminator accuracy 0.9727', 'Total loss: 2.4998', 'for batch', 14)
('GAN loss 2.3989 ', 'GAN acc 0.0000', 'Discriminator loss 0.1590', 'Discriminator accuracy 0.9688', 'Total loss: 2.5580', 'for batch', 15)
('GAN loss 2.3136 ', 'GAN acc 0.0000', 'Discriminator loss 0.1707', 'Discriminator accuracy 0.9668', 'Total loss: 2.4843', 'for batch', 16)
('GAN loss 2.5425 ', 'GAN acc 0.0000', 'Discriminator loss 0.1135', 'Discriminator accuracy 0.9785', 'Total loss: 2.6560', 'for batch', 17)
('GAN loss 2.5637 ', 'GAN acc 0.0000', 'Discriminator loss 0.0990', 'Discriminator accuracy 0.9844', 'Total loss: 2.6627', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95307016)
('DISCRIMINATOR_Imagem FAKE=', 0.077102415)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.172595')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 2.5238 ', 'GAN acc 0.0000', 'Discriminator loss 0.1442', 'Discriminator accuracy 0.9688', 'Total loss: 2.6681', 'for batch', 0)
('GAN loss 2.4710 ', 'GAN acc 0.0000', 'Discriminator loss 0.1890', 'Discriminator accuracy 0.9668', 'Total loss: 2.6600', 'for batch', 1)
('GAN loss 2.3014 ', 'GAN acc 0.0000', 'Discriminator loss 0.1263', 'Discriminator accuracy 0.9707', 'Total loss: 2.4277', 'for batch', 2)
('GAN loss 2.4144 ', 'GAN acc 0.0000', 'Discriminator loss 0.1108', 'Discriminator accuracy 0.9805', 'Total loss: 2.5251', 'for batch', 3)
('GAN loss 2.7452 ', 'GAN acc 0.0000', 'Discriminator loss 0.1267', 'Discriminator accuracy 0.9746', 'Total loss: 2.8719', 'for batch', 4)
('GAN loss 2.9311 ', 'GAN acc 0.0000', 'Discriminator loss 0.0870', 'Discriminator accuracy 0.9844', 'Total loss: 3.0180', 'for batch', 5)
('GAN loss 2.9850 ', 'GAN acc 0.0000', 'Discriminator loss 0.1346', 'Discriminator accuracy 0.9746', 'Total loss: 3.1196', 'for batch', 6)
('GAN loss 2.9926 ', 'GAN acc 0.0000', 'Discriminator loss 0.0782', 'Discriminator accuracy 0.9824', 'Total loss: 3.0708', 'for batch', 7)
('GAN loss 2.7614 ', 'GAN acc 0.0000', 'Discriminator loss 0.2198', 'Discriminator accuracy 0.9590', 'Total loss: 2.9812', 'for batch', 8)
('GAN loss 2.6830 ', 'GAN acc 0.0000', 'Discriminator loss 0.1280', 'Discriminator accuracy 0.9668', 'Total loss: 2.8110', 'for batch', 9)
('GAN loss 2.6175 ', 'GAN acc 0.0000', 'Discriminator loss 0.0819', 'Discriminator accuracy 0.9902', 'Total loss: 2.6994', 'for batch', 10)
('GAN loss 2.8039 ', 'GAN acc 0.0000', 'Discriminator loss 0.1389', 'Discriminator accuracy 0.9785', 'Total loss: 2.9429', 'for batch', 11)
('GAN loss 2.9184 ', 'GAN acc 0.0000', 'Discriminator loss 0.0818', 'Discriminator accuracy 0.9844', 'Total loss: 3.0002', 'for batch', 12)
('GAN loss 3.0169 ', 'GAN acc 0.0000', 'Discriminator loss 0.0792', 'Discriminator accuracy 0.9844', 'Total loss: 3.0961', 'for batch', 13)
('GAN loss 3.1108 ', 'GAN acc 0.0000', 'Discriminator loss 0.1057', 'Discriminator accuracy 0.9727', 'Total loss: 3.2165', 'for batch', 14)
('GAN loss 3.0923 ', 'GAN acc 0.0000', 'Discriminator loss 0.1434', 'Discriminator accuracy 0.9668', 'Total loss: 3.2357', 'for batch', 15)
('GAN loss 2.9337 ', 'GAN acc 0.0000', 'Discriminator loss 0.1192', 'Discriminator accuracy 0.9668', 'Total loss: 3.0529', 'for batch', 16)
('GAN loss 2.7874 ', 'GAN acc 0.0000', 'Discriminator loss 0.1150', 'Discriminator accuracy 0.9746', 'Total loss: 2.9024', 'for batch', 17)
('GAN loss 2.7593 ', 'GAN acc 0.0000', 'Discriminator loss 0.0815', 'Discriminator accuracy 0.9863', 'Total loss: 2.8409', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95621556)
('DISCRIMINATOR_Imagem FAKE=', 0.050102342)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.685169')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 2.7537 ', 'GAN acc 0.0000', 'Discriminator loss 0.1063', 'Discriminator accuracy 0.9766', 'Total loss: 2.8600', 'for batch', 0)
('GAN loss 2.7775 ', 'GAN acc 0.0000', 'Discriminator loss 0.1232', 'Discriminator accuracy 0.9727', 'Total loss: 2.9006', 'for batch', 1)
('GAN loss 2.6224 ', 'GAN acc 0.0000', 'Discriminator loss 0.0930', 'Discriminator accuracy 0.9805', 'Total loss: 2.7154', 'for batch', 2)
('GAN loss 2.5670 ', 'GAN acc 0.0000', 'Discriminator loss 0.0976', 'Discriminator accuracy 0.9805', 'Total loss: 2.6646', 'for batch', 3)
('GAN loss 2.6526 ', 'GAN acc 0.0000', 'Discriminator loss 0.1189', 'Discriminator accuracy 0.9746', 'Total loss: 2.7715', 'for batch', 4)
('GAN loss 2.6851 ', 'GAN acc 0.0000', 'Discriminator loss 0.0823', 'Discriminator accuracy 0.9863', 'Total loss: 2.7674', 'for batch', 5)
('GAN loss 2.7598 ', 'GAN acc 0.0000', 'Discriminator loss 0.1006', 'Discriminator accuracy 0.9824', 'Total loss: 2.8604', 'for batch', 6)
('GAN loss 2.7600 ', 'GAN acc 0.0000', 'Discriminator loss 0.0802', 'Discriminator accuracy 0.9883', 'Total loss: 2.8403', 'for batch', 7)
('GAN loss 2.5618 ', 'GAN acc 0.0000', 'Discriminator loss 0.1640', 'Discriminator accuracy 0.9688', 'Total loss: 2.7258', 'for batch', 8)
('GAN loss 2.3979 ', 'GAN acc 0.0039', 'Discriminator loss 0.1606', 'Discriminator accuracy 0.9688', 'Total loss: 2.5586', 'for batch', 9)
('GAN loss 2.5474 ', 'GAN acc 0.0000', 'Discriminator loss 0.0828', 'Discriminator accuracy 0.9922', 'Total loss: 2.6301', 'for batch', 10)
('GAN loss 2.6883 ', 'GAN acc 0.0000', 'Discriminator loss 0.1116', 'Discriminator accuracy 0.9805', 'Total loss: 2.7999', 'for batch', 11)
('GAN loss 2.5792 ', 'GAN acc 0.0000', 'Discriminator loss 0.1306', 'Discriminator accuracy 0.9785', 'Total loss: 2.7097', 'for batch', 12)
('GAN loss 2.6037 ', 'GAN acc 0.0000', 'Discriminator loss 0.0897', 'Discriminator accuracy 0.9863', 'Total loss: 2.6934', 'for batch', 13)
('GAN loss 2.4963 ', 'GAN acc 0.0000', 'Discriminator loss 0.1570', 'Discriminator accuracy 0.9668', 'Total loss: 2.6533', 'for batch', 14)
('GAN loss 2.4497 ', 'GAN acc 0.0000', 'Discriminator loss 0.1516', 'Discriminator accuracy 0.9648', 'Total loss: 2.6013', 'for batch', 15)
('GAN loss 2.6493 ', 'GAN acc 0.0000', 'Discriminator loss 0.1506', 'Discriminator accuracy 0.9688', 'Total loss: 2.7999', 'for batch', 16)
('GAN loss 2.8635 ', 'GAN acc 0.0000', 'Discriminator loss 0.1166', 'Discriminator accuracy 0.9766', 'Total loss: 2.9801', 'for batch', 17)
('GAN loss 2.9031 ', 'GAN acc 0.0000', 'Discriminator loss 0.1097', 'Discriminator accuracy 0.9805', 'Total loss: 3.0128', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95305336)
('DISCRIMINATOR_Imagem FAKE=', 0.052146345)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.159460')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 2.8381 ', 'GAN acc 0.0000', 'Discriminator loss 0.1466', 'Discriminator accuracy 0.9707', 'Total loss: 2.9846', 'for batch', 0)
('GAN loss 2.9732 ', 'GAN acc 0.0000', 'Discriminator loss 0.1186', 'Discriminator accuracy 0.9746', 'Total loss: 3.0918', 'for batch', 1)
('GAN loss 2.6128 ', 'GAN acc 0.0000', 'Discriminator loss 0.1468', 'Discriminator accuracy 0.9707', 'Total loss: 2.7596', 'for batch', 2)
('GAN loss 2.6608 ', 'GAN acc 0.0000', 'Discriminator loss 0.1006', 'Discriminator accuracy 0.9824', 'Total loss: 2.7614', 'for batch', 3)
('GAN loss 2.6663 ', 'GAN acc 0.0000', 'Discriminator loss 0.1312', 'Discriminator accuracy 0.9746', 'Total loss: 2.7975', 'for batch', 4)
('GAN loss 2.8013 ', 'GAN acc 0.0000', 'Discriminator loss 0.0858', 'Discriminator accuracy 0.9863', 'Total loss: 2.8871', 'for batch', 5)
('GAN loss 2.7987 ', 'GAN acc 0.0000', 'Discriminator loss 0.1082', 'Discriminator accuracy 0.9766', 'Total loss: 2.9069', 'for batch', 6)
('GAN loss 2.8917 ', 'GAN acc 0.0000', 'Discriminator loss 0.0845', 'Discriminator accuracy 0.9863', 'Total loss: 2.9762', 'for batch', 7)
('GAN loss 2.8061 ', 'GAN acc 0.0000', 'Discriminator loss 0.1256', 'Discriminator accuracy 0.9727', 'Total loss: 2.9317', 'for batch', 8)
('GAN loss 2.7877 ', 'GAN acc 0.0000', 'Discriminator loss 0.1434', 'Discriminator accuracy 0.9707', 'Total loss: 2.9311', 'for batch', 9)
('GAN loss 2.7764 ', 'GAN acc 0.0000', 'Discriminator loss 0.0694', 'Discriminator accuracy 0.9922', 'Total loss: 2.8458', 'for batch', 10)
('GAN loss 3.0216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0958', 'Discriminator accuracy 0.9805', 'Total loss: 3.1173', 'for batch', 11)
('GAN loss 2.9949 ', 'GAN acc 0.0000', 'Discriminator loss 0.0919', 'Discriminator accuracy 0.9805', 'Total loss: 3.0868', 'for batch', 12)
('GAN loss 3.0272 ', 'GAN acc 0.0000', 'Discriminator loss 0.0725', 'Discriminator accuracy 0.9883', 'Total loss: 3.0998', 'for batch', 13)
('GAN loss 3.1120 ', 'GAN acc 0.0000', 'Discriminator loss 0.1142', 'Discriminator accuracy 0.9746', 'Total loss: 3.2262', 'for batch', 14)
('GAN loss 3.0515 ', 'GAN acc 0.0000', 'Discriminator loss 0.1546', 'Discriminator accuracy 0.9648', 'Total loss: 3.2061', 'for batch', 15)
('GAN loss 3.0631 ', 'GAN acc 0.0000', 'Discriminator loss 0.1250', 'Discriminator accuracy 0.9688', 'Total loss: 3.1880', 'for batch', 16)
('GAN loss 3.0966 ', 'GAN acc 0.0000', 'Discriminator loss 0.0992', 'Discriminator accuracy 0.9785', 'Total loss: 3.1958', 'for batch', 17)
('GAN loss 2.9966 ', 'GAN acc 0.0000', 'Discriminator loss 0.0957', 'Discriminator accuracy 0.9805', 'Total loss: 3.0923', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95545876)
('DISCRIMINATOR_Imagem FAKE=', 0.044924475)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.684449')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0191 ', 'GAN acc 0.0000', 'Discriminator loss 0.1134', 'Discriminator accuracy 0.9727', 'Total loss: 3.1325', 'for batch', 0)
('GAN loss 2.9184 ', 'GAN acc 0.0000', 'Discriminator loss 0.1006', 'Discriminator accuracy 0.9766', 'Total loss: 3.0189', 'for batch', 1)
('GAN loss 2.9375 ', 'GAN acc 0.0000', 'Discriminator loss 0.0845', 'Discriminator accuracy 0.9824', 'Total loss: 3.0220', 'for batch', 2)
('GAN loss 2.9381 ', 'GAN acc 0.0000', 'Discriminator loss 0.0951', 'Discriminator accuracy 0.9785', 'Total loss: 3.0332', 'for batch', 3)
('GAN loss 2.9951 ', 'GAN acc 0.0000', 'Discriminator loss 0.1287', 'Discriminator accuracy 0.9746', 'Total loss: 3.1238', 'for batch', 4)
('GAN loss 2.9829 ', 'GAN acc 0.0000', 'Discriminator loss 0.0706', 'Discriminator accuracy 0.9883', 'Total loss: 3.0535', 'for batch', 5)
('GAN loss 2.9996 ', 'GAN acc 0.0000', 'Discriminator loss 0.1062', 'Discriminator accuracy 0.9766', 'Total loss: 3.1058', 'for batch', 6)
('GAN loss 3.0087 ', 'GAN acc 0.0000', 'Discriminator loss 0.0747', 'Discriminator accuracy 0.9844', 'Total loss: 3.0834', 'for batch', 7)
('GAN loss 3.0978 ', 'GAN acc 0.0000', 'Discriminator loss 0.1127', 'Discriminator accuracy 0.9746', 'Total loss: 3.2105', 'for batch', 8)
('GAN loss 3.1519 ', 'GAN acc 0.0000', 'Discriminator loss 0.1289', 'Discriminator accuracy 0.9688', 'Total loss: 3.2808', 'for batch', 9)
('GAN loss 3.2663 ', 'GAN acc 0.0000', 'Discriminator loss 0.0531', 'Discriminator accuracy 0.9922', 'Total loss: 3.3195', 'for batch', 10)
('GAN loss 3.1168 ', 'GAN acc 0.0000', 'Discriminator loss 0.0956', 'Discriminator accuracy 0.9785', 'Total loss: 3.2125', 'for batch', 11)
('GAN loss 3.2163 ', 'GAN acc 0.0000', 'Discriminator loss 0.0713', 'Discriminator accuracy 0.9863', 'Total loss: 3.2876', 'for batch', 12)
('GAN loss 3.1920 ', 'GAN acc 0.0000', 'Discriminator loss 0.0618', 'Discriminator accuracy 0.9883', 'Total loss: 3.2537', 'for batch', 13)
('GAN loss 3.4237 ', 'GAN acc 0.0000', 'Discriminator loss 0.1091', 'Discriminator accuracy 0.9727', 'Total loss: 3.5327', 'for batch', 14)
('GAN loss 3.3294 ', 'GAN acc 0.0000', 'Discriminator loss 0.1370', 'Discriminator accuracy 0.9668', 'Total loss: 3.4665', 'for batch', 15)
('GAN loss 3.2689 ', 'GAN acc 0.0000', 'Discriminator loss 0.1243', 'Discriminator accuracy 0.9688', 'Total loss: 3.3932', 'for batch', 16)
('GAN loss 3.2807 ', 'GAN acc 0.0000', 'Discriminator loss 0.0899', 'Discriminator accuracy 0.9785', 'Total loss: 3.3706', 'for batch', 17)
('GAN loss 3.3030 ', 'GAN acc 0.0000', 'Discriminator loss 0.0746', 'Discriminator accuracy 0.9805', 'Total loss: 3.3775', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95431858)
('DISCRIMINATOR_Imagem FAKE=', 0.030817043)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.181287')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0744 ', 'GAN acc 0.0000', 'Discriminator loss 0.1053', 'Discriminator accuracy 0.9707', 'Total loss: 3.1797', 'for batch', 0)
('GAN loss 3.1590 ', 'GAN acc 0.0000', 'Discriminator loss 0.0950', 'Discriminator accuracy 0.9766', 'Total loss: 3.2540', 'for batch', 1)
('GAN loss 3.1219 ', 'GAN acc 0.0000', 'Discriminator loss 0.0951', 'Discriminator accuracy 0.9805', 'Total loss: 3.2170', 'for batch', 2)
('GAN loss 2.9726 ', 'GAN acc 0.0000', 'Discriminator loss 0.1035', 'Discriminator accuracy 0.9785', 'Total loss: 3.0761', 'for batch', 3)
('GAN loss 2.9463 ', 'GAN acc 0.0000', 'Discriminator loss 0.1085', 'Discriminator accuracy 0.9746', 'Total loss: 3.0548', 'for batch', 4)
('GAN loss 3.1402 ', 'GAN acc 0.0000', 'Discriminator loss 0.0753', 'Discriminator accuracy 0.9863', 'Total loss: 3.2155', 'for batch', 5)
('GAN loss 3.2027 ', 'GAN acc 0.0000', 'Discriminator loss 0.1084', 'Discriminator accuracy 0.9785', 'Total loss: 3.3112', 'for batch', 6)
('GAN loss 3.2216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0649', 'Discriminator accuracy 0.9863', 'Total loss: 3.2864', 'for batch', 7)
('GAN loss 3.1139 ', 'GAN acc 0.0000', 'Discriminator loss 0.1051', 'Discriminator accuracy 0.9727', 'Total loss: 3.2191', 'for batch', 8)
('GAN loss 3.0169 ', 'GAN acc 0.0000', 'Discriminator loss 0.1280', 'Discriminator accuracy 0.9668', 'Total loss: 3.1449', 'for batch', 9)
('GAN loss 3.0806 ', 'GAN acc 0.0000', 'Discriminator loss 0.0532', 'Discriminator accuracy 0.9922', 'Total loss: 3.1338', 'for batch', 10)
('GAN loss 3.2228 ', 'GAN acc 0.0000', 'Discriminator loss 0.0910', 'Discriminator accuracy 0.9805', 'Total loss: 3.3139', 'for batch', 11)
('GAN loss 3.3060 ', 'GAN acc 0.0000', 'Discriminator loss 0.0670', 'Discriminator accuracy 0.9863', 'Total loss: 3.3730', 'for batch', 12)
('GAN loss 3.4108 ', 'GAN acc 0.0000', 'Discriminator loss 0.0585', 'Discriminator accuracy 0.9883', 'Total loss: 3.4692', 'for batch', 13)
('GAN loss 3.6100 ', 'GAN acc 0.0000', 'Discriminator loss 0.0958', 'Discriminator accuracy 0.9707', 'Total loss: 3.7058', 'for batch', 14)
('GAN loss 3.5943 ', 'GAN acc 0.0000', 'Discriminator loss 0.1141', 'Discriminator accuracy 0.9688', 'Total loss: 3.7084', 'for batch', 15)
('GAN loss 3.4787 ', 'GAN acc 0.0000', 'Discriminator loss 0.1113', 'Discriminator accuracy 0.9688', 'Total loss: 3.5900', 'for batch', 16)
('GAN loss 3.5236 ', 'GAN acc 0.0000', 'Discriminator loss 0.0837', 'Discriminator accuracy 0.9785', 'Total loss: 3.6074', 'for batch', 17)
('GAN loss 3.2776 ', 'GAN acc 0.0000', 'Discriminator loss 0.0568', 'Discriminator accuracy 0.9824', 'Total loss: 3.3344', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95665962)
('DISCRIMINATOR_Imagem FAKE=', 0.033181518)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.746430')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2157 ', 'GAN acc 0.0000', 'Discriminator loss 0.0958', 'Discriminator accuracy 0.9727', 'Total loss: 3.3115', 'for batch', 0)
('GAN loss 3.0626 ', 'GAN acc 0.0000', 'Discriminator loss 0.0968', 'Discriminator accuracy 0.9746', 'Total loss: 3.1594', 'for batch', 1)
('GAN loss 3.0788 ', 'GAN acc 0.0000', 'Discriminator loss 0.0711', 'Discriminator accuracy 0.9844', 'Total loss: 3.1499', 'for batch', 2)
('GAN loss 3.0594 ', 'GAN acc 0.0000', 'Discriminator loss 0.0815', 'Discriminator accuracy 0.9824', 'Total loss: 3.1409', 'for batch', 3)
('GAN loss 3.0859 ', 'GAN acc 0.0000', 'Discriminator loss 0.1055', 'Discriminator accuracy 0.9746', 'Total loss: 3.1914', 'for batch', 4)
('GAN loss 3.1521 ', 'GAN acc 0.0000', 'Discriminator loss 0.0785', 'Discriminator accuracy 0.9863', 'Total loss: 3.2306', 'for batch', 5)
('GAN loss 3.1911 ', 'GAN acc 0.0000', 'Discriminator loss 0.0825', 'Discriminator accuracy 0.9824', 'Total loss: 3.2735', 'for batch', 6)
('GAN loss 3.2003 ', 'GAN acc 0.0000', 'Discriminator loss 0.0631', 'Discriminator accuracy 0.9883', 'Total loss: 3.2633', 'for batch', 7)
('GAN loss 3.1397 ', 'GAN acc 0.0000', 'Discriminator loss 0.1019', 'Discriminator accuracy 0.9746', 'Total loss: 3.2416', 'for batch', 8)
('GAN loss 3.2084 ', 'GAN acc 0.0000', 'Discriminator loss 0.1060', 'Discriminator accuracy 0.9707', 'Total loss: 3.3144', 'for batch', 9)
('GAN loss 3.2169 ', 'GAN acc 0.0000', 'Discriminator loss 0.0461', 'Discriminator accuracy 0.9922', 'Total loss: 3.2630', 'for batch', 10)
('GAN loss 3.0908 ', 'GAN acc 0.0000', 'Discriminator loss 0.0960', 'Discriminator accuracy 0.9766', 'Total loss: 3.1867', 'for batch', 11)
('GAN loss 3.0846 ', 'GAN acc 0.0000', 'Discriminator loss 0.0833', 'Discriminator accuracy 0.9844', 'Total loss: 3.1679', 'for batch', 12)
('GAN loss 2.9807 ', 'GAN acc 0.0000', 'Discriminator loss 0.0654', 'Discriminator accuracy 0.9863', 'Total loss: 3.0461', 'for batch', 13)
('GAN loss 3.0101 ', 'GAN acc 0.0000', 'Discriminator loss 0.1066', 'Discriminator accuracy 0.9746', 'Total loss: 3.1167', 'for batch', 14)
('GAN loss 2.9518 ', 'GAN acc 0.0000', 'Discriminator loss 0.1241', 'Discriminator accuracy 0.9688', 'Total loss: 3.0759', 'for batch', 15)
('GAN loss 3.0046 ', 'GAN acc 0.0000', 'Discriminator loss 0.1173', 'Discriminator accuracy 0.9707', 'Total loss: 3.1220', 'for batch', 16)
('GAN loss 3.0292 ', 'GAN acc 0.0000', 'Discriminator loss 0.0981', 'Discriminator accuracy 0.9785', 'Total loss: 3.1272', 'for batch', 17)
('GAN loss 2.9195 ', 'GAN acc 0.0000', 'Discriminator loss 0.0762', 'Discriminator accuracy 0.9824', 'Total loss: 2.9957', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95802581)
('DISCRIMINATOR_Imagem FAKE=', 0.057613578)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.170033')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 2.9392 ', 'GAN acc 0.0000', 'Discriminator loss 0.1045', 'Discriminator accuracy 0.9746', 'Total loss: 3.0437', 'for batch', 0)
('GAN loss 3.0189 ', 'GAN acc 0.0000', 'Discriminator loss 0.0928', 'Discriminator accuracy 0.9785', 'Total loss: 3.1118', 'for batch', 1)
('GAN loss 3.0600 ', 'GAN acc 0.0000', 'Discriminator loss 0.0725', 'Discriminator accuracy 0.9844', 'Total loss: 3.1325', 'for batch', 2)
('GAN loss 2.9158 ', 'GAN acc 0.0000', 'Discriminator loss 0.1224', 'Discriminator accuracy 0.9785', 'Total loss: 3.0382', 'for batch', 3)
('GAN loss 2.8921 ', 'GAN acc 0.0000', 'Discriminator loss 0.1178', 'Discriminator accuracy 0.9727', 'Total loss: 3.0098', 'for batch', 4)
('GAN loss 2.9511 ', 'GAN acc 0.0000', 'Discriminator loss 0.0685', 'Discriminator accuracy 0.9883', 'Total loss: 3.0196', 'for batch', 5)
('GAN loss 2.9417 ', 'GAN acc 0.0000', 'Discriminator loss 0.0922', 'Discriminator accuracy 0.9785', 'Total loss: 3.0340', 'for batch', 6)
('GAN loss 2.9529 ', 'GAN acc 0.0000', 'Discriminator loss 0.0707', 'Discriminator accuracy 0.9844', 'Total loss: 3.0236', 'for batch', 7)
('GAN loss 2.9328 ', 'GAN acc 0.0000', 'Discriminator loss 0.1312', 'Discriminator accuracy 0.9707', 'Total loss: 3.0639', 'for batch', 8)
('GAN loss 2.9247 ', 'GAN acc 0.0000', 'Discriminator loss 0.1074', 'Discriminator accuracy 0.9746', 'Total loss: 3.0321', 'for batch', 9)
('GAN loss 2.9717 ', 'GAN acc 0.0000', 'Discriminator loss 0.0546', 'Discriminator accuracy 0.9922', 'Total loss: 3.0262', 'for batch', 10)
('GAN loss 2.9729 ', 'GAN acc 0.0000', 'Discriminator loss 0.0905', 'Discriminator accuracy 0.9805', 'Total loss: 3.0635', 'for batch', 11)
('GAN loss 3.0010 ', 'GAN acc 0.0000', 'Discriminator loss 0.0847', 'Discriminator accuracy 0.9824', 'Total loss: 3.0858', 'for batch', 12)
('GAN loss 2.9673 ', 'GAN acc 0.0000', 'Discriminator loss 0.0703', 'Discriminator accuracy 0.9863', 'Total loss: 3.0376', 'for batch', 13)
('GAN loss 3.0296 ', 'GAN acc 0.0000', 'Discriminator loss 0.1111', 'Discriminator accuracy 0.9727', 'Total loss: 3.1407', 'for batch', 14)
('GAN loss 2.9408 ', 'GAN acc 0.0000', 'Discriminator loss 0.1222', 'Discriminator accuracy 0.9707', 'Total loss: 3.0630', 'for batch', 15)
('GAN loss 3.0158 ', 'GAN acc 0.0000', 'Discriminator loss 0.1220', 'Discriminator accuracy 0.9707', 'Total loss: 3.1378', 'for batch', 16)
('GAN loss 2.9407 ', 'GAN acc 0.0000', 'Discriminator loss 0.0998', 'Discriminator accuracy 0.9785', 'Total loss: 3.0405', 'for batch', 17)
('GAN loss 2.9494 ', 'GAN acc 0.0000', 'Discriminator loss 0.0615', 'Discriminator accuracy 0.9883', 'Total loss: 3.0109', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95889992)
('DISCRIMINATOR_Imagem FAKE=', 0.058859654)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.720816')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 2.9920 ', 'GAN acc 0.0000', 'Discriminator loss 0.1096', 'Discriminator accuracy 0.9746', 'Total loss: 3.1016', 'for batch', 0)
('GAN loss 3.0551 ', 'GAN acc 0.0000', 'Discriminator loss 0.0929', 'Discriminator accuracy 0.9766', 'Total loss: 3.1480', 'for batch', 1)
('GAN loss 3.0244 ', 'GAN acc 0.0000', 'Discriminator loss 0.0687', 'Discriminator accuracy 0.9824', 'Total loss: 3.0931', 'for batch', 2)
('GAN loss 3.0115 ', 'GAN acc 0.0000', 'Discriminator loss 0.0870', 'Discriminator accuracy 0.9785', 'Total loss: 3.0986', 'for batch', 3)
('GAN loss 3.0095 ', 'GAN acc 0.0000', 'Discriminator loss 0.1005', 'Discriminator accuracy 0.9746', 'Total loss: 3.1099', 'for batch', 4)
('GAN loss 3.0835 ', 'GAN acc 0.0000', 'Discriminator loss 0.0631', 'Discriminator accuracy 0.9883', 'Total loss: 3.1467', 'for batch', 5)
('GAN loss 3.0610 ', 'GAN acc 0.0000', 'Discriminator loss 0.0859', 'Discriminator accuracy 0.9805', 'Total loss: 3.1469', 'for batch', 6)
('GAN loss 3.0727 ', 'GAN acc 0.0000', 'Discriminator loss 0.0659', 'Discriminator accuracy 0.9863', 'Total loss: 3.1386', 'for batch', 7)
('GAN loss 3.0704 ', 'GAN acc 0.0000', 'Discriminator loss 0.1104', 'Discriminator accuracy 0.9727', 'Total loss: 3.1808', 'for batch', 8)
('GAN loss 3.0055 ', 'GAN acc 0.0000', 'Discriminator loss 0.1102', 'Discriminator accuracy 0.9707', 'Total loss: 3.1157', 'for batch', 9)
('GAN loss 3.0636 ', 'GAN acc 0.0000', 'Discriminator loss 0.0487', 'Discriminator accuracy 0.9922', 'Total loss: 3.1123', 'for batch', 10)
('GAN loss 3.1044 ', 'GAN acc 0.0000', 'Discriminator loss 0.0895', 'Discriminator accuracy 0.9805', 'Total loss: 3.1939', 'for batch', 11)
('GAN loss 3.1111 ', 'GAN acc 0.0000', 'Discriminator loss 0.0722', 'Discriminator accuracy 0.9844', 'Total loss: 3.1833', 'for batch', 12)
('GAN loss 3.1528 ', 'GAN acc 0.0000', 'Discriminator loss 0.0625', 'Discriminator accuracy 0.9883', 'Total loss: 3.2152', 'for batch', 13)
('GAN loss 3.1288 ', 'GAN acc 0.0000', 'Discriminator loss 0.1137', 'Discriminator accuracy 0.9707', 'Total loss: 3.2425', 'for batch', 14)
('GAN loss 3.1361 ', 'GAN acc 0.0000', 'Discriminator loss 0.1208', 'Discriminator accuracy 0.9688', 'Total loss: 3.2568', 'for batch', 15)
('GAN loss 3.1025 ', 'GAN acc 0.0000', 'Discriminator loss 0.1162', 'Discriminator accuracy 0.9707', 'Total loss: 3.2187', 'for batch', 16)
('GAN loss 3.1090 ', 'GAN acc 0.0000', 'Discriminator loss 0.0902', 'Discriminator accuracy 0.9785', 'Total loss: 3.1992', 'for batch', 17)
('GAN loss 3.0900 ', 'GAN acc 0.0000', 'Discriminator loss 0.0660', 'Discriminator accuracy 0.9863', 'Total loss: 3.1560', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9603312)
('DISCRIMINATOR_Imagem FAKE=', 0.053212106)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.715341')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0727 ', 'GAN acc 0.0000', 'Discriminator loss 0.0988', 'Discriminator accuracy 0.9766', 'Total loss: 3.1715', 'for batch', 0)
('GAN loss 3.1012 ', 'GAN acc 0.0000', 'Discriminator loss 0.0903', 'Discriminator accuracy 0.9785', 'Total loss: 3.1915', 'for batch', 1)
('GAN loss 3.1098 ', 'GAN acc 0.0000', 'Discriminator loss 0.0700', 'Discriminator accuracy 0.9844', 'Total loss: 3.1799', 'for batch', 2)
('GAN loss 3.0897 ', 'GAN acc 0.0000', 'Discriminator loss 0.0814', 'Discriminator accuracy 0.9824', 'Total loss: 3.1711', 'for batch', 3)
('GAN loss 3.0879 ', 'GAN acc 0.0000', 'Discriminator loss 0.1043', 'Discriminator accuracy 0.9746', 'Total loss: 3.1922', 'for batch', 4)
('GAN loss 3.1036 ', 'GAN acc 0.0000', 'Discriminator loss 0.0625', 'Discriminator accuracy 0.9883', 'Total loss: 3.1661', 'for batch', 5)
('GAN loss 3.1222 ', 'GAN acc 0.0000', 'Discriminator loss 0.0869', 'Discriminator accuracy 0.9805', 'Total loss: 3.2092', 'for batch', 6)
('GAN loss 3.1330 ', 'GAN acc 0.0000', 'Discriminator loss 0.0623', 'Discriminator accuracy 0.9883', 'Total loss: 3.1954', 'for batch', 7)
('GAN loss 3.1564 ', 'GAN acc 0.0000', 'Discriminator loss 0.1044', 'Discriminator accuracy 0.9746', 'Total loss: 3.2608', 'for batch', 8)
('GAN loss 3.1785 ', 'GAN acc 0.0000', 'Discriminator loss 0.1070', 'Discriminator accuracy 0.9746', 'Total loss: 3.2855', 'for batch', 9)
('GAN loss 3.1729 ', 'GAN acc 0.0000', 'Discriminator loss 0.0485', 'Discriminator accuracy 0.9922', 'Total loss: 3.2214', 'for batch', 10)
('GAN loss 3.2070 ', 'GAN acc 0.0000', 'Discriminator loss 0.0851', 'Discriminator accuracy 0.9805', 'Total loss: 3.2921', 'for batch', 11)
('GAN loss 3.1975 ', 'GAN acc 0.0000', 'Discriminator loss 0.0680', 'Discriminator accuracy 0.9844', 'Total loss: 3.2655', 'for batch', 12)
('GAN loss 3.2199 ', 'GAN acc 0.0000', 'Discriminator loss 0.0617', 'Discriminator accuracy 0.9883', 'Total loss: 3.2816', 'for batch', 13)
('GAN loss 3.1992 ', 'GAN acc 0.0000', 'Discriminator loss 0.1095', 'Discriminator accuracy 0.9727', 'Total loss: 3.3087', 'for batch', 14)
('GAN loss 3.1909 ', 'GAN acc 0.0000', 'Discriminator loss 0.1224', 'Discriminator accuracy 0.9707', 'Total loss: 3.3133', 'for batch', 15)
('GAN loss 3.1652 ', 'GAN acc 0.0000', 'Discriminator loss 0.1178', 'Discriminator accuracy 0.9707', 'Total loss: 3.2830', 'for batch', 16)
('GAN loss 3.1557 ', 'GAN acc 0.0000', 'Discriminator loss 0.0923', 'Discriminator accuracy 0.9785', 'Total loss: 3.2480', 'for batch', 17)
('GAN loss 3.1259 ', 'GAN acc 0.0000', 'Discriminator loss 0.0537', 'Discriminator accuracy 0.9883', 'Total loss: 3.1796', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96111053)
('DISCRIMINATOR_Imagem FAKE=', 0.051885135)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.239504')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1300 ', 'GAN acc 0.0000', 'Discriminator loss 0.1000', 'Discriminator accuracy 0.9766', 'Total loss: 3.2300', 'for batch', 0)
('GAN loss 3.1319 ', 'GAN acc 0.0000', 'Discriminator loss 0.0898', 'Discriminator accuracy 0.9785', 'Total loss: 3.2218', 'for batch', 1)
('GAN loss 3.0905 ', 'GAN acc 0.0000', 'Discriminator loss 0.0707', 'Discriminator accuracy 0.9863', 'Total loss: 3.1612', 'for batch', 2)
('GAN loss 3.1195 ', 'GAN acc 0.0000', 'Discriminator loss 0.0803', 'Discriminator accuracy 0.9805', 'Total loss: 3.1998', 'for batch', 3)
('GAN loss 3.1421 ', 'GAN acc 0.0000', 'Discriminator loss 0.1080', 'Discriminator accuracy 0.9766', 'Total loss: 3.2501', 'for batch', 4)
('GAN loss 3.1193 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9883', 'Total loss: 3.1803', 'for batch', 5)
('GAN loss 3.1313 ', 'GAN acc 0.0000', 'Discriminator loss 0.0864', 'Discriminator accuracy 0.9805', 'Total loss: 3.2177', 'for batch', 6)
('GAN loss 3.1526 ', 'GAN acc 0.0000', 'Discriminator loss 0.0631', 'Discriminator accuracy 0.9883', 'Total loss: 3.2158', 'for batch', 7)
('GAN loss 3.1253 ', 'GAN acc 0.0000', 'Discriminator loss 0.1057', 'Discriminator accuracy 0.9746', 'Total loss: 3.2310', 'for batch', 8)
('GAN loss 3.1453 ', 'GAN acc 0.0000', 'Discriminator loss 0.1026', 'Discriminator accuracy 0.9766', 'Total loss: 3.2478', 'for batch', 9)
('GAN loss 3.1311 ', 'GAN acc 0.0000', 'Discriminator loss 0.0506', 'Discriminator accuracy 0.9922', 'Total loss: 3.1817', 'for batch', 10)
('GAN loss 3.1462 ', 'GAN acc 0.0000', 'Discriminator loss 0.0868', 'Discriminator accuracy 0.9805', 'Total loss: 3.2330', 'for batch', 11)
('GAN loss 3.1778 ', 'GAN acc 0.0000', 'Discriminator loss 0.0673', 'Discriminator accuracy 0.9863', 'Total loss: 3.2451', 'for batch', 12)
('GAN loss 3.1876 ', 'GAN acc 0.0000', 'Discriminator loss 0.0620', 'Discriminator accuracy 0.9883', 'Total loss: 3.2496', 'for batch', 13)
('GAN loss 3.1730 ', 'GAN acc 0.0000', 'Discriminator loss 0.1127', 'Discriminator accuracy 0.9727', 'Total loss: 3.2857', 'for batch', 14)
('GAN loss 3.1772 ', 'GAN acc 0.0000', 'Discriminator loss 0.1183', 'Discriminator accuracy 0.9707', 'Total loss: 3.2955', 'for batch', 15)
('GAN loss 3.1462 ', 'GAN acc 0.0000', 'Discriminator loss 0.1192', 'Discriminator accuracy 0.9707', 'Total loss: 3.2654', 'for batch', 16)
('GAN loss 3.1319 ', 'GAN acc 0.0000', 'Discriminator loss 0.0940', 'Discriminator accuracy 0.9785', 'Total loss: 3.2259', 'for batch', 17)
('GAN loss 3.1346 ', 'GAN acc 0.0000', 'Discriminator loss 0.0528', 'Discriminator accuracy 0.9902', 'Total loss: 3.1875', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96178591)
('DISCRIMINATOR_Imagem FAKE=', 0.051451609)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.697504')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1634 ', 'GAN acc 0.0000', 'Discriminator loss 0.0994', 'Discriminator accuracy 0.9766', 'Total loss: 3.2628', 'for batch', 0)
('GAN loss 3.1365 ', 'GAN acc 0.0000', 'Discriminator loss 0.0880', 'Discriminator accuracy 0.9785', 'Total loss: 3.2245', 'for batch', 1)
('GAN loss 3.1447 ', 'GAN acc 0.0000', 'Discriminator loss 0.0617', 'Discriminator accuracy 0.9863', 'Total loss: 3.2064', 'for batch', 2)
('GAN loss 3.1403 ', 'GAN acc 0.0000', 'Discriminator loss 0.0863', 'Discriminator accuracy 0.9805', 'Total loss: 3.2266', 'for batch', 3)
('GAN loss 3.1787 ', 'GAN acc 0.0000', 'Discriminator loss 0.1039', 'Discriminator accuracy 0.9766', 'Total loss: 3.2826', 'for batch', 4)
('GAN loss 3.1409 ', 'GAN acc 0.0000', 'Discriminator loss 0.0621', 'Discriminator accuracy 0.9883', 'Total loss: 3.2031', 'for batch', 5)
('GAN loss 3.1441 ', 'GAN acc 0.0000', 'Discriminator loss 0.0831', 'Discriminator accuracy 0.9824', 'Total loss: 3.2272', 'for batch', 6)
('GAN loss 3.1270 ', 'GAN acc 0.0000', 'Discriminator loss 0.0620', 'Discriminator accuracy 0.9883', 'Total loss: 3.1890', 'for batch', 7)
('GAN loss 3.1737 ', 'GAN acc 0.0000', 'Discriminator loss 0.1100', 'Discriminator accuracy 0.9746', 'Total loss: 3.2837', 'for batch', 8)
('GAN loss 3.1600 ', 'GAN acc 0.0000', 'Discriminator loss 0.0998', 'Discriminator accuracy 0.9766', 'Total loss: 3.2598', 'for batch', 9)
('GAN loss 3.2154 ', 'GAN acc 0.0000', 'Discriminator loss 0.0496', 'Discriminator accuracy 0.9922', 'Total loss: 3.2651', 'for batch', 10)
('GAN loss 3.1711 ', 'GAN acc 0.0000', 'Discriminator loss 0.0905', 'Discriminator accuracy 0.9805', 'Total loss: 3.2617', 'for batch', 11)
('GAN loss 3.2288 ', 'GAN acc 0.0000', 'Discriminator loss 0.0676', 'Discriminator accuracy 0.9863', 'Total loss: 3.2964', 'for batch', 12)
('GAN loss 3.2195 ', 'GAN acc 0.0000', 'Discriminator loss 0.0640', 'Discriminator accuracy 0.9883', 'Total loss: 3.2834', 'for batch', 13)
('GAN loss 3.2017 ', 'GAN acc 0.0000', 'Discriminator loss 0.1067', 'Discriminator accuracy 0.9727', 'Total loss: 3.3084', 'for batch', 14)
('GAN loss 3.2173 ', 'GAN acc 0.0000', 'Discriminator loss 0.1207', 'Discriminator accuracy 0.9707', 'Total loss: 3.3380', 'for batch', 15)
('GAN loss 3.1738 ', 'GAN acc 0.0000', 'Discriminator loss 0.1198', 'Discriminator accuracy 0.9707', 'Total loss: 3.2935', 'for batch', 16)
('GAN loss 3.1204 ', 'GAN acc 0.0000', 'Discriminator loss 0.0959', 'Discriminator accuracy 0.9785', 'Total loss: 3.2164', 'for batch', 17)
('GAN loss 3.1710 ', 'GAN acc 0.0000', 'Discriminator loss 0.0554', 'Discriminator accuracy 0.9883', 'Total loss: 3.2264', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96220952)
('DISCRIMINATOR_Imagem FAKE=', 0.050645933)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.206571')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1201 ', 'GAN acc 0.0000', 'Discriminator loss 0.1007', 'Discriminator accuracy 0.9766', 'Total loss: 3.2208', 'for batch', 0)
('GAN loss 3.1574 ', 'GAN acc 0.0000', 'Discriminator loss 0.0883', 'Discriminator accuracy 0.9805', 'Total loss: 3.2457', 'for batch', 1)
('GAN loss 3.2341 ', 'GAN acc 0.0000', 'Discriminator loss 0.0665', 'Discriminator accuracy 0.9863', 'Total loss: 3.3005', 'for batch', 2)
('GAN loss 3.1937 ', 'GAN acc 0.0000', 'Discriminator loss 0.0789', 'Discriminator accuracy 0.9824', 'Total loss: 3.2726', 'for batch', 3)
('GAN loss 3.1476 ', 'GAN acc 0.0000', 'Discriminator loss 0.1023', 'Discriminator accuracy 0.9766', 'Total loss: 3.2499', 'for batch', 4)
('GAN loss 3.2307 ', 'GAN acc 0.0000', 'Discriminator loss 0.0605', 'Discriminator accuracy 0.9883', 'Total loss: 3.2911', 'for batch', 5)
('GAN loss 3.1709 ', 'GAN acc 0.0000', 'Discriminator loss 0.0846', 'Discriminator accuracy 0.9824', 'Total loss: 3.2556', 'for batch', 6)
('GAN loss 3.1800 ', 'GAN acc 0.0000', 'Discriminator loss 0.0649', 'Discriminator accuracy 0.9883', 'Total loss: 3.2450', 'for batch', 7)
('GAN loss 3.1941 ', 'GAN acc 0.0000', 'Discriminator loss 0.1063', 'Discriminator accuracy 0.9746', 'Total loss: 3.3004', 'for batch', 8)
('GAN loss 3.1489 ', 'GAN acc 0.0000', 'Discriminator loss 0.1027', 'Discriminator accuracy 0.9766', 'Total loss: 3.2515', 'for batch', 9)
('GAN loss 3.2309 ', 'GAN acc 0.0000', 'Discriminator loss 0.0497', 'Discriminator accuracy 0.9922', 'Total loss: 3.2806', 'for batch', 10)
('GAN loss 3.2372 ', 'GAN acc 0.0000', 'Discriminator loss 0.0900', 'Discriminator accuracy 0.9805', 'Total loss: 3.3272', 'for batch', 11)
('GAN loss 3.2204 ', 'GAN acc 0.0000', 'Discriminator loss 0.0691', 'Discriminator accuracy 0.9863', 'Total loss: 3.2895', 'for batch', 12)
('GAN loss 3.2689 ', 'GAN acc 0.0000', 'Discriminator loss 0.0612', 'Discriminator accuracy 0.9883', 'Total loss: 3.3302', 'for batch', 13)
('GAN loss 3.1979 ', 'GAN acc 0.0000', 'Discriminator loss 0.1062', 'Discriminator accuracy 0.9746', 'Total loss: 3.3041', 'for batch', 14)
('GAN loss 3.2427 ', 'GAN acc 0.0000', 'Discriminator loss 0.1142', 'Discriminator accuracy 0.9707', 'Total loss: 3.3569', 'for batch', 15)
('GAN loss 3.2029 ', 'GAN acc 0.0000', 'Discriminator loss 0.1164', 'Discriminator accuracy 0.9707', 'Total loss: 3.3192', 'for batch', 16)
('GAN loss 3.2120 ', 'GAN acc 0.0000', 'Discriminator loss 0.0923', 'Discriminator accuracy 0.9805', 'Total loss: 3.3043', 'for batch', 17)
('GAN loss 3.2332 ', 'GAN acc 0.0000', 'Discriminator loss 0.0510', 'Discriminator accuracy 0.9922', 'Total loss: 3.2842', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96237892)
('DISCRIMINATOR_Imagem FAKE=', 0.048442751)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.717358')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2262 ', 'GAN acc 0.0000', 'Discriminator loss 0.1034', 'Discriminator accuracy 0.9766', 'Total loss: 3.3296', 'for batch', 0)
('GAN loss 3.1946 ', 'GAN acc 0.0000', 'Discriminator loss 0.0914', 'Discriminator accuracy 0.9785', 'Total loss: 3.2860', 'for batch', 1)
('GAN loss 3.1974 ', 'GAN acc 0.0000', 'Discriminator loss 0.0617', 'Discriminator accuracy 0.9883', 'Total loss: 3.2591', 'for batch', 2)
('GAN loss 3.2240 ', 'GAN acc 0.0000', 'Discriminator loss 0.0747', 'Discriminator accuracy 0.9824', 'Total loss: 3.2988', 'for batch', 3)
('GAN loss 3.1996 ', 'GAN acc 0.0000', 'Discriminator loss 0.1040', 'Discriminator accuracy 0.9766', 'Total loss: 3.3036', 'for batch', 4)
('GAN loss 3.2501 ', 'GAN acc 0.0000', 'Discriminator loss 0.0606', 'Discriminator accuracy 0.9883', 'Total loss: 3.3106', 'for batch', 5)
('GAN loss 3.2528 ', 'GAN acc 0.0000', 'Discriminator loss 0.0815', 'Discriminator accuracy 0.9824', 'Total loss: 3.3343', 'for batch', 6)
('GAN loss 3.2418 ', 'GAN acc 0.0000', 'Discriminator loss 0.0606', 'Discriminator accuracy 0.9883', 'Total loss: 3.3023', 'for batch', 7)
('GAN loss 3.2647 ', 'GAN acc 0.0000', 'Discriminator loss 0.1106', 'Discriminator accuracy 0.9746', 'Total loss: 3.3753', 'for batch', 8)
('GAN loss 3.2448 ', 'GAN acc 0.0000', 'Discriminator loss 0.1037', 'Discriminator accuracy 0.9766', 'Total loss: 3.3485', 'for batch', 9)
('GAN loss 3.2443 ', 'GAN acc 0.0000', 'Discriminator loss 0.0454', 'Discriminator accuracy 0.9922', 'Total loss: 3.2898', 'for batch', 10)
('GAN loss 3.2544 ', 'GAN acc 0.0000', 'Discriminator loss 0.0856', 'Discriminator accuracy 0.9805', 'Total loss: 3.3400', 'for batch', 11)
('GAN loss 3.2609 ', 'GAN acc 0.0000', 'Discriminator loss 0.0652', 'Discriminator accuracy 0.9863', 'Total loss: 3.3260', 'for batch', 12)
('GAN loss 3.2571 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9883', 'Total loss: 3.3181', 'for batch', 13)
('GAN loss 3.3140 ', 'GAN acc 0.0000', 'Discriminator loss 0.1124', 'Discriminator accuracy 0.9746', 'Total loss: 3.4264', 'for batch', 14)
('GAN loss 3.2690 ', 'GAN acc 0.0000', 'Discriminator loss 0.1179', 'Discriminator accuracy 0.9707', 'Total loss: 3.3869', 'for batch', 15)
('GAN loss 3.2146 ', 'GAN acc 0.0000', 'Discriminator loss 0.1202', 'Discriminator accuracy 0.9707', 'Total loss: 3.3347', 'for batch', 16)
('GAN loss 3.2254 ', 'GAN acc 0.0000', 'Discriminator loss 0.0877', 'Discriminator accuracy 0.9805', 'Total loss: 3.3131', 'for batch', 17)
('GAN loss 3.2192 ', 'GAN acc 0.0000', 'Discriminator loss 0.0487', 'Discriminator accuracy 0.9922', 'Total loss: 3.2679', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96245432)
('DISCRIMINATOR_Imagem FAKE=', 0.046521552)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.241857')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2527 ', 'GAN acc 0.0000', 'Discriminator loss 0.1032', 'Discriminator accuracy 0.9766', 'Total loss: 3.3559', 'for batch', 0)
('GAN loss 3.2146 ', 'GAN acc 0.0000', 'Discriminator loss 0.0899', 'Discriminator accuracy 0.9785', 'Total loss: 3.3045', 'for batch', 1)
('GAN loss 3.2069 ', 'GAN acc 0.0000', 'Discriminator loss 0.0580', 'Discriminator accuracy 0.9883', 'Total loss: 3.2649', 'for batch', 2)
('GAN loss 3.2723 ', 'GAN acc 0.0000', 'Discriminator loss 0.0751', 'Discriminator accuracy 0.9824', 'Total loss: 3.3474', 'for batch', 3)
('GAN loss 3.2460 ', 'GAN acc 0.0000', 'Discriminator loss 0.1055', 'Discriminator accuracy 0.9766', 'Total loss: 3.3515', 'for batch', 4)
('GAN loss 3.2354 ', 'GAN acc 0.0000', 'Discriminator loss 0.0620', 'Discriminator accuracy 0.9883', 'Total loss: 3.2974', 'for batch', 5)
('GAN loss 3.2394 ', 'GAN acc 0.0000', 'Discriminator loss 0.0832', 'Discriminator accuracy 0.9824', 'Total loss: 3.3226', 'for batch', 6)
('GAN loss 3.2772 ', 'GAN acc 0.0000', 'Discriminator loss 0.0599', 'Discriminator accuracy 0.9883', 'Total loss: 3.3372', 'for batch', 7)
('GAN loss 3.2714 ', 'GAN acc 0.0000', 'Discriminator loss 0.1071', 'Discriminator accuracy 0.9746', 'Total loss: 3.3786', 'for batch', 8)
('GAN loss 3.2617 ', 'GAN acc 0.0000', 'Discriminator loss 0.1015', 'Discriminator accuracy 0.9766', 'Total loss: 3.3632', 'for batch', 9)
('GAN loss 3.2936 ', 'GAN acc 0.0000', 'Discriminator loss 0.0471', 'Discriminator accuracy 0.9922', 'Total loss: 3.3407', 'for batch', 10)
('GAN loss 3.3109 ', 'GAN acc 0.0000', 'Discriminator loss 0.0908', 'Discriminator accuracy 0.9805', 'Total loss: 3.4017', 'for batch', 11)
('GAN loss 3.2444 ', 'GAN acc 0.0000', 'Discriminator loss 0.0669', 'Discriminator accuracy 0.9863', 'Total loss: 3.3113', 'for batch', 12)
('GAN loss 3.2991 ', 'GAN acc 0.0000', 'Discriminator loss 0.0627', 'Discriminator accuracy 0.9863', 'Total loss: 3.3618', 'for batch', 13)
('GAN loss 3.3236 ', 'GAN acc 0.0000', 'Discriminator loss 0.1086', 'Discriminator accuracy 0.9727', 'Total loss: 3.4322', 'for batch', 14)
('GAN loss 3.3089 ', 'GAN acc 0.0000', 'Discriminator loss 0.1194', 'Discriminator accuracy 0.9707', 'Total loss: 3.4283', 'for batch', 15)
('GAN loss 3.2543 ', 'GAN acc 0.0000', 'Discriminator loss 0.1181', 'Discriminator accuracy 0.9707', 'Total loss: 3.3724', 'for batch', 16)
('GAN loss 3.2420 ', 'GAN acc 0.0000', 'Discriminator loss 0.0866', 'Discriminator accuracy 0.9805', 'Total loss: 3.3286', 'for batch', 17)
('GAN loss 3.2746 ', 'GAN acc 0.0000', 'Discriminator loss 0.0498', 'Discriminator accuracy 0.9922', 'Total loss: 3.3244', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96262592)
('DISCRIMINATOR_Imagem FAKE=', 0.045679498)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.705935')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2703 ', 'GAN acc 0.0000', 'Discriminator loss 0.1025', 'Discriminator accuracy 0.9766', 'Total loss: 3.3728', 'for batch', 0)
('GAN loss 3.2604 ', 'GAN acc 0.0000', 'Discriminator loss 0.0854', 'Discriminator accuracy 0.9785', 'Total loss: 3.3457', 'for batch', 1)
('GAN loss 3.2421 ', 'GAN acc 0.0000', 'Discriminator loss 0.0621', 'Discriminator accuracy 0.9844', 'Total loss: 3.3042', 'for batch', 2)
('GAN loss 3.2413 ', 'GAN acc 0.0000', 'Discriminator loss 0.0768', 'Discriminator accuracy 0.9824', 'Total loss: 3.3181', 'for batch', 3)
('GAN loss 3.2923 ', 'GAN acc 0.0000', 'Discriminator loss 0.1009', 'Discriminator accuracy 0.9766', 'Total loss: 3.3932', 'for batch', 4)
('GAN loss 3.2807 ', 'GAN acc 0.0000', 'Discriminator loss 0.0602', 'Discriminator accuracy 0.9883', 'Total loss: 3.3409', 'for batch', 5)
('GAN loss 3.2705 ', 'GAN acc 0.0000', 'Discriminator loss 0.0803', 'Discriminator accuracy 0.9824', 'Total loss: 3.3507', 'for batch', 6)
('GAN loss 3.2304 ', 'GAN acc 0.0000', 'Discriminator loss 0.0598', 'Discriminator accuracy 0.9883', 'Total loss: 3.2902', 'for batch', 7)
('GAN loss 3.2770 ', 'GAN acc 0.0000', 'Discriminator loss 0.1082', 'Discriminator accuracy 0.9727', 'Total loss: 3.3852', 'for batch', 8)
('GAN loss 3.2468 ', 'GAN acc 0.0000', 'Discriminator loss 0.1022', 'Discriminator accuracy 0.9746', 'Total loss: 3.3490', 'for batch', 9)
('GAN loss 3.2881 ', 'GAN acc 0.0000', 'Discriminator loss 0.0453', 'Discriminator accuracy 0.9922', 'Total loss: 3.3334', 'for batch', 10)
('GAN loss 3.2801 ', 'GAN acc 0.0000', 'Discriminator loss 0.0853', 'Discriminator accuracy 0.9805', 'Total loss: 3.3655', 'for batch', 11)
('GAN loss 3.3009 ', 'GAN acc 0.0000', 'Discriminator loss 0.0687', 'Discriminator accuracy 0.9863', 'Total loss: 3.3696', 'for batch', 12)
('GAN loss 3.2956 ', 'GAN acc 0.0000', 'Discriminator loss 0.0595', 'Discriminator accuracy 0.9883', 'Total loss: 3.3550', 'for batch', 13)
('GAN loss 3.2703 ', 'GAN acc 0.0000', 'Discriminator loss 0.1058', 'Discriminator accuracy 0.9746', 'Total loss: 3.3761', 'for batch', 14)
('GAN loss 3.2469 ', 'GAN acc 0.0000', 'Discriminator loss 0.1179', 'Discriminator accuracy 0.9707', 'Total loss: 3.3649', 'for batch', 15)
('GAN loss 3.2216 ', 'GAN acc 0.0000', 'Discriminator loss 0.1208', 'Discriminator accuracy 0.9707', 'Total loss: 3.3424', 'for batch', 16)
('GAN loss 3.2319 ', 'GAN acc 0.0000', 'Discriminator loss 0.0878', 'Discriminator accuracy 0.9805', 'Total loss: 3.3198', 'for batch', 17)
('GAN loss 3.2434 ', 'GAN acc 0.0000', 'Discriminator loss 0.0506', 'Discriminator accuracy 0.9902', 'Total loss: 3.2940', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96282732)
('DISCRIMINATOR_Imagem FAKE=', 0.045688733)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.186639')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2236 ', 'GAN acc 0.0000', 'Discriminator loss 0.0945', 'Discriminator accuracy 0.9766', 'Total loss: 3.3180', 'for batch', 0)
('GAN loss 3.2060 ', 'GAN acc 0.0000', 'Discriminator loss 0.0867', 'Discriminator accuracy 0.9805', 'Total loss: 3.2927', 'for batch', 1)
('GAN loss 3.2132 ', 'GAN acc 0.0000', 'Discriminator loss 0.0558', 'Discriminator accuracy 0.9883', 'Total loss: 3.2691', 'for batch', 2)
('GAN loss 3.2364 ', 'GAN acc 0.0000', 'Discriminator loss 0.0752', 'Discriminator accuracy 0.9824', 'Total loss: 3.3116', 'for batch', 3)
('GAN loss 3.2302 ', 'GAN acc 0.0000', 'Discriminator loss 0.1020', 'Discriminator accuracy 0.9766', 'Total loss: 3.3322', 'for batch', 4)
('GAN loss 3.2491 ', 'GAN acc 0.0000', 'Discriminator loss 0.0611', 'Discriminator accuracy 0.9883', 'Total loss: 3.3101', 'for batch', 5)
('GAN loss 3.2857 ', 'GAN acc 0.0000', 'Discriminator loss 0.0857', 'Discriminator accuracy 0.9805', 'Total loss: 3.3713', 'for batch', 6)
('GAN loss 3.2384 ', 'GAN acc 0.0000', 'Discriminator loss 0.0581', 'Discriminator accuracy 0.9883', 'Total loss: 3.2964', 'for batch', 7)
('GAN loss 3.2596 ', 'GAN acc 0.0000', 'Discriminator loss 0.1058', 'Discriminator accuracy 0.9746', 'Total loss: 3.3654', 'for batch', 8)
('GAN loss 3.2593 ', 'GAN acc 0.0000', 'Discriminator loss 0.1005', 'Discriminator accuracy 0.9766', 'Total loss: 3.3599', 'for batch', 9)
('GAN loss 3.2417 ', 'GAN acc 0.0000', 'Discriminator loss 0.0477', 'Discriminator accuracy 0.9922', 'Total loss: 3.2893', 'for batch', 10)
('GAN loss 3.2897 ', 'GAN acc 0.0000', 'Discriminator loss 0.0868', 'Discriminator accuracy 0.9805', 'Total loss: 3.3765', 'for batch', 11)
('GAN loss 3.3121 ', 'GAN acc 0.0000', 'Discriminator loss 0.0666', 'Discriminator accuracy 0.9863', 'Total loss: 3.3787', 'for batch', 12)
('GAN loss 3.3256 ', 'GAN acc 0.0000', 'Discriminator loss 0.0608', 'Discriminator accuracy 0.9883', 'Total loss: 3.3864', 'for batch', 13)
('GAN loss 3.3047 ', 'GAN acc 0.0000', 'Discriminator loss 0.1103', 'Discriminator accuracy 0.9746', 'Total loss: 3.4150', 'for batch', 14)
('GAN loss 3.2651 ', 'GAN acc 0.0000', 'Discriminator loss 0.1099', 'Discriminator accuracy 0.9707', 'Total loss: 3.3750', 'for batch', 15)
('GAN loss 3.2143 ', 'GAN acc 0.0000', 'Discriminator loss 0.1188', 'Discriminator accuracy 0.9707', 'Total loss: 3.3332', 'for batch', 16)
('GAN loss 3.2204 ', 'GAN acc 0.0000', 'Discriminator loss 0.0876', 'Discriminator accuracy 0.9805', 'Total loss: 3.3080', 'for batch', 17)
('GAN loss 3.2571 ', 'GAN acc 0.0000', 'Discriminator loss 0.0450', 'Discriminator accuracy 0.9922', 'Total loss: 3.3021', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96288145)
('DISCRIMINATOR_Imagem FAKE=', 0.045694824)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.680724')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2661 ', 'GAN acc 0.0000', 'Discriminator loss 0.1002', 'Discriminator accuracy 0.9766', 'Total loss: 3.3663', 'for batch', 0)
('GAN loss 3.2355 ', 'GAN acc 0.0000', 'Discriminator loss 0.0863', 'Discriminator accuracy 0.9805', 'Total loss: 3.3218', 'for batch', 1)
('GAN loss 3.2604 ', 'GAN acc 0.0000', 'Discriminator loss 0.0569', 'Discriminator accuracy 0.9883', 'Total loss: 3.3174', 'for batch', 2)
('GAN loss 3.3068 ', 'GAN acc 0.0000', 'Discriminator loss 0.0726', 'Discriminator accuracy 0.9824', 'Total loss: 3.3794', 'for batch', 3)
('GAN loss 3.2687 ', 'GAN acc 0.0000', 'Discriminator loss 0.0972', 'Discriminator accuracy 0.9766', 'Total loss: 3.3659', 'for batch', 4)
('GAN loss 3.3141 ', 'GAN acc 0.0000', 'Discriminator loss 0.0613', 'Discriminator accuracy 0.9883', 'Total loss: 3.3754', 'for batch', 5)
('GAN loss 3.2898 ', 'GAN acc 0.0000', 'Discriminator loss 0.0767', 'Discriminator accuracy 0.9824', 'Total loss: 3.3665', 'for batch', 6)
('GAN loss 3.2945 ', 'GAN acc 0.0000', 'Discriminator loss 0.0598', 'Discriminator accuracy 0.9883', 'Total loss: 3.3543', 'for batch', 7)
('GAN loss 3.2831 ', 'GAN acc 0.0000', 'Discriminator loss 0.1101', 'Discriminator accuracy 0.9746', 'Total loss: 3.3931', 'for batch', 8)
('GAN loss 3.2743 ', 'GAN acc 0.0000', 'Discriminator loss 0.0967', 'Discriminator accuracy 0.9766', 'Total loss: 3.3710', 'for batch', 9)
('GAN loss 3.2695 ', 'GAN acc 0.0000', 'Discriminator loss 0.0472', 'Discriminator accuracy 0.9922', 'Total loss: 3.3167', 'for batch', 10)
('GAN loss 3.2851 ', 'GAN acc 0.0000', 'Discriminator loss 0.0889', 'Discriminator accuracy 0.9805', 'Total loss: 3.3740', 'for batch', 11)
('GAN loss 3.3094 ', 'GAN acc 0.0000', 'Discriminator loss 0.0687', 'Discriminator accuracy 0.9863', 'Total loss: 3.3781', 'for batch', 12)
('GAN loss 3.2847 ', 'GAN acc 0.0000', 'Discriminator loss 0.0604', 'Discriminator accuracy 0.9883', 'Total loss: 3.3450', 'for batch', 13)
('GAN loss 3.3012 ', 'GAN acc 0.0000', 'Discriminator loss 0.1063', 'Discriminator accuracy 0.9746', 'Total loss: 3.4074', 'for batch', 14)
('GAN loss 3.3195 ', 'GAN acc 0.0000', 'Discriminator loss 0.1163', 'Discriminator accuracy 0.9707', 'Total loss: 3.4359', 'for batch', 15)
('GAN loss 3.2997 ', 'GAN acc 0.0000', 'Discriminator loss 0.1180', 'Discriminator accuracy 0.9707', 'Total loss: 3.4177', 'for batch', 16)
('GAN loss 3.2084 ', 'GAN acc 0.0000', 'Discriminator loss 0.0858', 'Discriminator accuracy 0.9805', 'Total loss: 3.2942', 'for batch', 17)
('GAN loss 3.2471 ', 'GAN acc 0.0000', 'Discriminator loss 0.0495', 'Discriminator accuracy 0.9902', 'Total loss: 3.2966', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96296418)
('DISCRIMINATOR_Imagem FAKE=', 0.044914499)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.245434')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2589 ', 'GAN acc 0.0000', 'Discriminator loss 0.0973', 'Discriminator accuracy 0.9766', 'Total loss: 3.3563', 'for batch', 0)
('GAN loss 3.2617 ', 'GAN acc 0.0000', 'Discriminator loss 0.0847', 'Discriminator accuracy 0.9805', 'Total loss: 3.3464', 'for batch', 1)
('GAN loss 3.2553 ', 'GAN acc 0.0000', 'Discriminator loss 0.0568', 'Discriminator accuracy 0.9883', 'Total loss: 3.3121', 'for batch', 2)
('GAN loss 3.2784 ', 'GAN acc 0.0000', 'Discriminator loss 0.0736', 'Discriminator accuracy 0.9824', 'Total loss: 3.3519', 'for batch', 3)
('GAN loss 3.2606 ', 'GAN acc 0.0000', 'Discriminator loss 0.0969', 'Discriminator accuracy 0.9766', 'Total loss: 3.3575', 'for batch', 4)
('GAN loss 3.3204 ', 'GAN acc 0.0000', 'Discriminator loss 0.0591', 'Discriminator accuracy 0.9883', 'Total loss: 3.3795', 'for batch', 5)
('GAN loss 3.2792 ', 'GAN acc 0.0000', 'Discriminator loss 0.0789', 'Discriminator accuracy 0.9824', 'Total loss: 3.3581', 'for batch', 6)
('GAN loss 3.2912 ', 'GAN acc 0.0000', 'Discriminator loss 0.0587', 'Discriminator accuracy 0.9863', 'Total loss: 3.3499', 'for batch', 7)
('GAN loss 3.2923 ', 'GAN acc 0.0000', 'Discriminator loss 0.1024', 'Discriminator accuracy 0.9746', 'Total loss: 3.3947', 'for batch', 8)
('GAN loss 3.2687 ', 'GAN acc 0.0000', 'Discriminator loss 0.0995', 'Discriminator accuracy 0.9766', 'Total loss: 3.3683', 'for batch', 9)
('GAN loss 3.3175 ', 'GAN acc 0.0000', 'Discriminator loss 0.0458', 'Discriminator accuracy 0.9922', 'Total loss: 3.3633', 'for batch', 10)
('GAN loss 3.3002 ', 'GAN acc 0.0000', 'Discriminator loss 0.0876', 'Discriminator accuracy 0.9805', 'Total loss: 3.3878', 'for batch', 11)
('GAN loss 3.3084 ', 'GAN acc 0.0000', 'Discriminator loss 0.0682', 'Discriminator accuracy 0.9863', 'Total loss: 3.3766', 'for batch', 12)
('GAN loss 3.3195 ', 'GAN acc 0.0000', 'Discriminator loss 0.0582', 'Discriminator accuracy 0.9883', 'Total loss: 3.3778', 'for batch', 13)
('GAN loss 3.3213 ', 'GAN acc 0.0000', 'Discriminator loss 0.1096', 'Discriminator accuracy 0.9727', 'Total loss: 3.4309', 'for batch', 14)
('GAN loss 3.2723 ', 'GAN acc 0.0000', 'Discriminator loss 0.1170', 'Discriminator accuracy 0.9707', 'Total loss: 3.3893', 'for batch', 15)
('GAN loss 3.2636 ', 'GAN acc 0.0000', 'Discriminator loss 0.1205', 'Discriminator accuracy 0.9707', 'Total loss: 3.3841', 'for batch', 16)
('GAN loss 3.2413 ', 'GAN acc 0.0000', 'Discriminator loss 0.0844', 'Discriminator accuracy 0.9805', 'Total loss: 3.3257', 'for batch', 17)
('GAN loss 3.2856 ', 'GAN acc 0.0000', 'Discriminator loss 0.0483', 'Discriminator accuracy 0.9922', 'Total loss: 3.3339', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96307492)
('DISCRIMINATOR_Imagem FAKE=', 0.044014495)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.721040')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2864 ', 'GAN acc 0.0000', 'Discriminator loss 0.0982', 'Discriminator accuracy 0.9766', 'Total loss: 3.3846', 'for batch', 0)
('GAN loss 3.2498 ', 'GAN acc 0.0000', 'Discriminator loss 0.0871', 'Discriminator accuracy 0.9805', 'Total loss: 3.3369', 'for batch', 1)
('GAN loss 3.2894 ', 'GAN acc 0.0000', 'Discriminator loss 0.0558', 'Discriminator accuracy 0.9883', 'Total loss: 3.3451', 'for batch', 2)
('GAN loss 3.2925 ', 'GAN acc 0.0000', 'Discriminator loss 0.0728', 'Discriminator accuracy 0.9824', 'Total loss: 3.3653', 'for batch', 3)
('GAN loss 3.2721 ', 'GAN acc 0.0000', 'Discriminator loss 0.1012', 'Discriminator accuracy 0.9766', 'Total loss: 3.3734', 'for batch', 4)
('GAN loss 3.3018 ', 'GAN acc 0.0000', 'Discriminator loss 0.0622', 'Discriminator accuracy 0.9883', 'Total loss: 3.3640', 'for batch', 5)
('GAN loss 3.2829 ', 'GAN acc 0.0000', 'Discriminator loss 0.0823', 'Discriminator accuracy 0.9824', 'Total loss: 3.3652', 'for batch', 6)
('GAN loss 3.2760 ', 'GAN acc 0.0000', 'Discriminator loss 0.0539', 'Discriminator accuracy 0.9883', 'Total loss: 3.3299', 'for batch', 7)
('GAN loss 3.2807 ', 'GAN acc 0.0000', 'Discriminator loss 0.1016', 'Discriminator accuracy 0.9746', 'Total loss: 3.3823', 'for batch', 8)
('GAN loss 3.2769 ', 'GAN acc 0.0000', 'Discriminator loss 0.1022', 'Discriminator accuracy 0.9766', 'Total loss: 3.3790', 'for batch', 9)
('GAN loss 3.3139 ', 'GAN acc 0.0000', 'Discriminator loss 0.0471', 'Discriminator accuracy 0.9922', 'Total loss: 3.3609', 'for batch', 10)
('GAN loss 3.2986 ', 'GAN acc 0.0000', 'Discriminator loss 0.0850', 'Discriminator accuracy 0.9805', 'Total loss: 3.3836', 'for batch', 11)
('GAN loss 3.3274 ', 'GAN acc 0.0000', 'Discriminator loss 0.0667', 'Discriminator accuracy 0.9863', 'Total loss: 3.3941', 'for batch', 12)
('GAN loss 3.3303 ', 'GAN acc 0.0000', 'Discriminator loss 0.0596', 'Discriminator accuracy 0.9883', 'Total loss: 3.3899', 'for batch', 13)
('GAN loss 3.3407 ', 'GAN acc 0.0000', 'Discriminator loss 0.1071', 'Discriminator accuracy 0.9746', 'Total loss: 3.4478', 'for batch', 14)
('GAN loss 3.3321 ', 'GAN acc 0.0000', 'Discriminator loss 0.1114', 'Discriminator accuracy 0.9707', 'Total loss: 3.4435', 'for batch', 15)
('GAN loss 3.2763 ', 'GAN acc 0.0000', 'Discriminator loss 0.1209', 'Discriminator accuracy 0.9707', 'Total loss: 3.3972', 'for batch', 16)
('GAN loss 3.2621 ', 'GAN acc 0.0000', 'Discriminator loss 0.0877', 'Discriminator accuracy 0.9805', 'Total loss: 3.3497', 'for batch', 17)
('GAN loss 3.2458 ', 'GAN acc 0.0000', 'Discriminator loss 0.0505', 'Discriminator accuracy 0.9902', 'Total loss: 3.2963', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96314484)
('DISCRIMINATOR_Imagem FAKE=', 0.043704864)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.198415')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2689 ', 'GAN acc 0.0000', 'Discriminator loss 0.0987', 'Discriminator accuracy 0.9766', 'Total loss: 3.3677', 'for batch', 0)
('GAN loss 3.2874 ', 'GAN acc 0.0000', 'Discriminator loss 0.0852', 'Discriminator accuracy 0.9805', 'Total loss: 3.3726', 'for batch', 1)
('GAN loss 3.2802 ', 'GAN acc 0.0000', 'Discriminator loss 0.0584', 'Discriminator accuracy 0.9863', 'Total loss: 3.3385', 'for batch', 2)
('GAN loss 3.3233 ', 'GAN acc 0.0000', 'Discriminator loss 0.0724', 'Discriminator accuracy 0.9824', 'Total loss: 3.3957', 'for batch', 3)
('GAN loss 3.3030 ', 'GAN acc 0.0000', 'Discriminator loss 0.0985', 'Discriminator accuracy 0.9766', 'Total loss: 3.4015', 'for batch', 4)
('GAN loss 3.2724 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.3314', 'for batch', 5)
('GAN loss 3.2888 ', 'GAN acc 0.0000', 'Discriminator loss 0.0790', 'Discriminator accuracy 0.9805', 'Total loss: 3.3678', 'for batch', 6)
('GAN loss 3.3213 ', 'GAN acc 0.0000', 'Discriminator loss 0.0582', 'Discriminator accuracy 0.9883', 'Total loss: 3.3794', 'for batch', 7)
('GAN loss 3.2890 ', 'GAN acc 0.0000', 'Discriminator loss 0.1069', 'Discriminator accuracy 0.9746', 'Total loss: 3.3958', 'for batch', 8)
('GAN loss 3.2920 ', 'GAN acc 0.0000', 'Discriminator loss 0.1039', 'Discriminator accuracy 0.9766', 'Total loss: 3.3959', 'for batch', 9)
('GAN loss 3.2859 ', 'GAN acc 0.0000', 'Discriminator loss 0.0454', 'Discriminator accuracy 0.9922', 'Total loss: 3.3312', 'for batch', 10)
('GAN loss 3.3167 ', 'GAN acc 0.0000', 'Discriminator loss 0.0893', 'Discriminator accuracy 0.9805', 'Total loss: 3.4059', 'for batch', 11)
('GAN loss 3.3083 ', 'GAN acc 0.0000', 'Discriminator loss 0.0640', 'Discriminator accuracy 0.9863', 'Total loss: 3.3722', 'for batch', 12)
('GAN loss 3.3076 ', 'GAN acc 0.0000', 'Discriminator loss 0.0595', 'Discriminator accuracy 0.9883', 'Total loss: 3.3670', 'for batch', 13)
('GAN loss 3.3254 ', 'GAN acc 0.0000', 'Discriminator loss 0.1078', 'Discriminator accuracy 0.9746', 'Total loss: 3.4332', 'for batch', 14)
('GAN loss 3.3056 ', 'GAN acc 0.0000', 'Discriminator loss 0.1141', 'Discriminator accuracy 0.9727', 'Total loss: 3.4197', 'for batch', 15)
('GAN loss 3.2540 ', 'GAN acc 0.0000', 'Discriminator loss 0.1218', 'Discriminator accuracy 0.9707', 'Total loss: 3.3759', 'for batch', 16)
('GAN loss 3.2612 ', 'GAN acc 0.0000', 'Discriminator loss 0.0876', 'Discriminator accuracy 0.9785', 'Total loss: 3.3489', 'for batch', 17)
('GAN loss 3.2940 ', 'GAN acc 0.0000', 'Discriminator loss 0.0455', 'Discriminator accuracy 0.9922', 'Total loss: 3.3395', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96324259)
('DISCRIMINATOR_Imagem FAKE=', 0.04399642)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.708335')
----------------------------------
('Epoch', 34, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2798 ', 'GAN acc 0.0000', 'Discriminator loss 0.0956', 'Discriminator accuracy 0.9766', 'Total loss: 3.3754', 'for batch', 0)
('GAN loss 3.2900 ', 'GAN acc 0.0000', 'Discriminator loss 0.0870', 'Discriminator accuracy 0.9805', 'Total loss: 3.3771', 'for batch', 1)
('GAN loss 3.2600 ', 'GAN acc 0.0000', 'Discriminator loss 0.0544', 'Discriminator accuracy 0.9883', 'Total loss: 3.3143', 'for batch', 2)
('GAN loss 3.3036 ', 'GAN acc 0.0000', 'Discriminator loss 0.0736', 'Discriminator accuracy 0.9824', 'Total loss: 3.3773', 'for batch', 3)
('GAN loss 3.2680 ', 'GAN acc 0.0000', 'Discriminator loss 0.0950', 'Discriminator accuracy 0.9766', 'Total loss: 3.3631', 'for batch', 4)
('GAN loss 3.3161 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9883', 'Total loss: 3.3772', 'for batch', 5)
('GAN loss 3.3028 ', 'GAN acc 0.0000', 'Discriminator loss 0.0814', 'Discriminator accuracy 0.9824', 'Total loss: 3.3842', 'for batch', 6)
('GAN loss 3.2848 ', 'GAN acc 0.0000', 'Discriminator loss 0.0613', 'Discriminator accuracy 0.9883', 'Total loss: 3.3461', 'for batch', 7)
('GAN loss 3.3267 ', 'GAN acc 0.0000', 'Discriminator loss 0.1046', 'Discriminator accuracy 0.9746', 'Total loss: 3.4313', 'for batch', 8)
('GAN loss 3.3323 ', 'GAN acc 0.0000', 'Discriminator loss 0.0984', 'Discriminator accuracy 0.9766', 'Total loss: 3.4307', 'for batch', 9)
('GAN loss 3.3217 ', 'GAN acc 0.0000', 'Discriminator loss 0.0450', 'Discriminator accuracy 0.9922', 'Total loss: 3.3667', 'for batch', 10)
('GAN loss 3.3332 ', 'GAN acc 0.0000', 'Discriminator loss 0.0870', 'Discriminator accuracy 0.9805', 'Total loss: 3.4202', 'for batch', 11)
('GAN loss 3.3112 ', 'GAN acc 0.0000', 'Discriminator loss 0.0646', 'Discriminator accuracy 0.9863', 'Total loss: 3.3758', 'for batch', 12)
('GAN loss 3.3400 ', 'GAN acc 0.0000', 'Discriminator loss 0.0608', 'Discriminator accuracy 0.9883', 'Total loss: 3.4009', 'for batch', 13)
('GAN loss 3.3284 ', 'GAN acc 0.0000', 'Discriminator loss 0.1074', 'Discriminator accuracy 0.9727', 'Total loss: 3.4358', 'for batch', 14)
('GAN loss 3.3166 ', 'GAN acc 0.0000', 'Discriminator loss 0.1124', 'Discriminator accuracy 0.9707', 'Total loss: 3.4290', 'for batch', 15)
('GAN loss 3.2583 ', 'GAN acc 0.0000', 'Discriminator loss 0.1177', 'Discriminator accuracy 0.9707', 'Total loss: 3.3760', 'for batch', 16)
('GAN loss 3.2771 ', 'GAN acc 0.0000', 'Discriminator loss 0.0862', 'Discriminator accuracy 0.9805', 'Total loss: 3.3633', 'for batch', 17)
('GAN loss 3.2648 ', 'GAN acc 0.0000', 'Discriminator loss 0.0483', 'Discriminator accuracy 0.9902', 'Total loss: 3.3130', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96333218)
('DISCRIMINATOR_Imagem FAKE=', 0.043703079)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.199532')
----------------------------------
('Epoch', 35, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3053 ', 'GAN acc 0.0000', 'Discriminator loss 0.0975', 'Discriminator accuracy 0.9766', 'Total loss: 3.4028', 'for batch', 0)
('GAN loss 3.3129 ', 'GAN acc 0.0000', 'Discriminator loss 0.0830', 'Discriminator accuracy 0.9805', 'Total loss: 3.3959', 'for batch', 1)
('GAN loss 3.2900 ', 'GAN acc 0.0000', 'Discriminator loss 0.0572', 'Discriminator accuracy 0.9883', 'Total loss: 3.3472', 'for batch', 2)
('GAN loss 3.3110 ', 'GAN acc 0.0000', 'Discriminator loss 0.0746', 'Discriminator accuracy 0.9824', 'Total loss: 3.3856', 'for batch', 3)
('GAN loss 3.3024 ', 'GAN acc 0.0000', 'Discriminator loss 0.0955', 'Discriminator accuracy 0.9766', 'Total loss: 3.3979', 'for batch', 4)
('GAN loss 3.2737 ', 'GAN acc 0.0000', 'Discriminator loss 0.0571', 'Discriminator accuracy 0.9883', 'Total loss: 3.3309', 'for batch', 5)
('GAN loss 3.3182 ', 'GAN acc 0.0000', 'Discriminator loss 0.0777', 'Discriminator accuracy 0.9824', 'Total loss: 3.3959', 'for batch', 6)
('GAN loss 3.3369 ', 'GAN acc 0.0000', 'Discriminator loss 0.0588', 'Discriminator accuracy 0.9883', 'Total loss: 3.3957', 'for batch', 7)
('GAN loss 3.3421 ', 'GAN acc 0.0000', 'Discriminator loss 0.1029', 'Discriminator accuracy 0.9746', 'Total loss: 3.4450', 'for batch', 8)
('GAN loss 3.3190 ', 'GAN acc 0.0000', 'Discriminator loss 0.0985', 'Discriminator accuracy 0.9766', 'Total loss: 3.4175', 'for batch', 9)
('GAN loss 3.3105 ', 'GAN acc 0.0000', 'Discriminator loss 0.0453', 'Discriminator accuracy 0.9922', 'Total loss: 3.3558', 'for batch', 10)
('GAN loss 3.3444 ', 'GAN acc 0.0000', 'Discriminator loss 0.0799', 'Discriminator accuracy 0.9805', 'Total loss: 3.4243', 'for batch', 11)
('GAN loss 3.2859 ', 'GAN acc 0.0000', 'Discriminator loss 0.0660', 'Discriminator accuracy 0.9863', 'Total loss: 3.3519', 'for batch', 12)
('GAN loss 3.3233 ', 'GAN acc 0.0000', 'Discriminator loss 0.0577', 'Discriminator accuracy 0.9883', 'Total loss: 3.3809', 'for batch', 13)
('GAN loss 3.3474 ', 'GAN acc 0.0000', 'Discriminator loss 0.1082', 'Discriminator accuracy 0.9746', 'Total loss: 3.4556', 'for batch', 14)
('GAN loss 3.3231 ', 'GAN acc 0.0000', 'Discriminator loss 0.1089', 'Discriminator accuracy 0.9707', 'Total loss: 3.4320', 'for batch', 15)
('GAN loss 3.3012 ', 'GAN acc 0.0000', 'Discriminator loss 0.1202', 'Discriminator accuracy 0.9707', 'Total loss: 3.4214', 'for batch', 16)
('GAN loss 3.2510 ', 'GAN acc 0.0000', 'Discriminator loss 0.0847', 'Discriminator accuracy 0.9785', 'Total loss: 3.3358', 'for batch', 17)
('GAN loss 3.2992 ', 'GAN acc 0.0000', 'Discriminator loss 0.0506', 'Discriminator accuracy 0.9902', 'Total loss: 3.3498', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9634093)
('DISCRIMINATOR_Imagem FAKE=', 0.042957891)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.716085')
----------------------------------
('Epoch', 36, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2874 ', 'GAN acc 0.0000', 'Discriminator loss 0.0997', 'Discriminator accuracy 0.9766', 'Total loss: 3.3870', 'for batch', 0)
('GAN loss 3.3035 ', 'GAN acc 0.0000', 'Discriminator loss 0.0862', 'Discriminator accuracy 0.9805', 'Total loss: 3.3897', 'for batch', 1)
('GAN loss 3.2927 ', 'GAN acc 0.0000', 'Discriminator loss 0.0532', 'Discriminator accuracy 0.9902', 'Total loss: 3.3459', 'for batch', 2)
('GAN loss 3.2976 ', 'GAN acc 0.0000', 'Discriminator loss 0.0722', 'Discriminator accuracy 0.9824', 'Total loss: 3.3698', 'for batch', 3)
('GAN loss 3.3384 ', 'GAN acc 0.0000', 'Discriminator loss 0.0978', 'Discriminator accuracy 0.9766', 'Total loss: 3.4362', 'for batch', 4)
('GAN loss 3.2922 ', 'GAN acc 0.0000', 'Discriminator loss 0.0596', 'Discriminator accuracy 0.9883', 'Total loss: 3.3518', 'for batch', 5)
('GAN loss 3.2766 ', 'GAN acc 0.0000', 'Discriminator loss 0.0800', 'Discriminator accuracy 0.9805', 'Total loss: 3.3566', 'for batch', 6)
('GAN loss 3.3419 ', 'GAN acc 0.0000', 'Discriminator loss 0.0571', 'Discriminator accuracy 0.9883', 'Total loss: 3.3990', 'for batch', 7)
('GAN loss 3.2831 ', 'GAN acc 0.0000', 'Discriminator loss 0.1038', 'Discriminator accuracy 0.9746', 'Total loss: 3.3869', 'for batch', 8)
('GAN loss 3.2977 ', 'GAN acc 0.0000', 'Discriminator loss 0.0989', 'Discriminator accuracy 0.9766', 'Total loss: 3.3966', 'for batch', 9)
('GAN loss 3.3063 ', 'GAN acc 0.0000', 'Discriminator loss 0.0466', 'Discriminator accuracy 0.9922', 'Total loss: 3.3529', 'for batch', 10)
('GAN loss 3.2951 ', 'GAN acc 0.0000', 'Discriminator loss 0.0856', 'Discriminator accuracy 0.9805', 'Total loss: 3.3806', 'for batch', 11)
('GAN loss 3.3341 ', 'GAN acc 0.0000', 'Discriminator loss 0.0628', 'Discriminator accuracy 0.9863', 'Total loss: 3.3969', 'for batch', 12)
('GAN loss 3.3816 ', 'GAN acc 0.0000', 'Discriminator loss 0.0599', 'Discriminator accuracy 0.9883', 'Total loss: 3.4415', 'for batch', 13)
('GAN loss 3.3554 ', 'GAN acc 0.0000', 'Discriminator loss 0.1054', 'Discriminator accuracy 0.9746', 'Total loss: 3.4608', 'for batch', 14)
('GAN loss 3.3470 ', 'GAN acc 0.0000', 'Discriminator loss 0.1080', 'Discriminator accuracy 0.9727', 'Total loss: 3.4549', 'for batch', 15)
('GAN loss 3.3260 ', 'GAN acc 0.0000', 'Discriminator loss 0.1174', 'Discriminator accuracy 0.9707', 'Total loss: 3.4434', 'for batch', 16)
('GAN loss 3.2562 ', 'GAN acc 0.0000', 'Discriminator loss 0.0848', 'Discriminator accuracy 0.9785', 'Total loss: 3.3410', 'for batch', 17)
('GAN loss 3.3136 ', 'GAN acc 0.0000', 'Discriminator loss 0.0458', 'Discriminator accuracy 0.9922', 'Total loss: 3.3594', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96345687)
('DISCRIMINATOR_Imagem FAKE=', 0.042194884)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.193416')
----------------------------------
('Epoch', 37, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2883 ', 'GAN acc 0.0000', 'Discriminator loss 0.0952', 'Discriminator accuracy 0.9766', 'Total loss: 3.3835', 'for batch', 0)
('GAN loss 3.3087 ', 'GAN acc 0.0000', 'Discriminator loss 0.0882', 'Discriminator accuracy 0.9805', 'Total loss: 3.3969', 'for batch', 1)
('GAN loss 3.3365 ', 'GAN acc 0.0000', 'Discriminator loss 0.0514', 'Discriminator accuracy 0.9883', 'Total loss: 3.3878', 'for batch', 2)
('GAN loss 3.2742 ', 'GAN acc 0.0000', 'Discriminator loss 0.0726', 'Discriminator accuracy 0.9824', 'Total loss: 3.3468', 'for batch', 3)
('GAN loss 3.2789 ', 'GAN acc 0.0000', 'Discriminator loss 0.0979', 'Discriminator accuracy 0.9766', 'Total loss: 3.3768', 'for batch', 4)
('GAN loss 3.3384 ', 'GAN acc 0.0000', 'Discriminator loss 0.0586', 'Discriminator accuracy 0.9883', 'Total loss: 3.3970', 'for batch', 5)
('GAN loss 3.3774 ', 'GAN acc 0.0000', 'Discriminator loss 0.0781', 'Discriminator accuracy 0.9824', 'Total loss: 3.4555', 'for batch', 6)
('GAN loss 3.3353 ', 'GAN acc 0.0000', 'Discriminator loss 0.0575', 'Discriminator accuracy 0.9883', 'Total loss: 3.3927', 'for batch', 7)
('GAN loss 3.3237 ', 'GAN acc 0.0000', 'Discriminator loss 0.1081', 'Discriminator accuracy 0.9746', 'Total loss: 3.4319', 'for batch', 8)
('GAN loss 3.3147 ', 'GAN acc 0.0000', 'Discriminator loss 0.0988', 'Discriminator accuracy 0.9766', 'Total loss: 3.4135', 'for batch', 9)
('GAN loss 3.3281 ', 'GAN acc 0.0000', 'Discriminator loss 0.0473', 'Discriminator accuracy 0.9922', 'Total loss: 3.3754', 'for batch', 10)
('GAN loss 3.3683 ', 'GAN acc 0.0000', 'Discriminator loss 0.0850', 'Discriminator accuracy 0.9805', 'Total loss: 3.4533', 'for batch', 11)
('GAN loss 3.3710 ', 'GAN acc 0.0000', 'Discriminator loss 0.0664', 'Discriminator accuracy 0.9863', 'Total loss: 3.4374', 'for batch', 12)
('GAN loss 3.3630 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.4220', 'for batch', 13)
('GAN loss 3.3926 ', 'GAN acc 0.0000', 'Discriminator loss 0.1069', 'Discriminator accuracy 0.9746', 'Total loss: 3.4995', 'for batch', 14)
('GAN loss 3.3268 ', 'GAN acc 0.0000', 'Discriminator loss 0.1158', 'Discriminator accuracy 0.9707', 'Total loss: 3.4426', 'for batch', 15)
('GAN loss 3.3158 ', 'GAN acc 0.0000', 'Discriminator loss 0.1191', 'Discriminator accuracy 0.9707', 'Total loss: 3.4349', 'for batch', 16)
('GAN loss 3.2618 ', 'GAN acc 0.0000', 'Discriminator loss 0.0837', 'Discriminator accuracy 0.9805', 'Total loss: 3.3455', 'for batch', 17)
('GAN loss 3.3098 ', 'GAN acc 0.0000', 'Discriminator loss 0.0478', 'Discriminator accuracy 0.9922', 'Total loss: 3.3576', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96353382)
('DISCRIMINATOR_Imagem FAKE=', 0.042267676)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.701575')
----------------------------------
('Epoch', 38, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3355 ', 'GAN acc 0.0000', 'Discriminator loss 0.0942', 'Discriminator accuracy 0.9766', 'Total loss: 3.4297', 'for batch', 0)
('GAN loss 3.2923 ', 'GAN acc 0.0000', 'Discriminator loss 0.0819', 'Discriminator accuracy 0.9805', 'Total loss: 3.3742', 'for batch', 1)
('GAN loss 3.3188 ', 'GAN acc 0.0000', 'Discriminator loss 0.0525', 'Discriminator accuracy 0.9902', 'Total loss: 3.3713', 'for batch', 2)
('GAN loss 3.3320 ', 'GAN acc 0.0000', 'Discriminator loss 0.0692', 'Discriminator accuracy 0.9824', 'Total loss: 3.4012', 'for batch', 3)
('GAN loss 3.3731 ', 'GAN acc 0.0000', 'Discriminator loss 0.0917', 'Discriminator accuracy 0.9766', 'Total loss: 3.4648', 'for batch', 4)
('GAN loss 3.3549 ', 'GAN acc 0.0000', 'Discriminator loss 0.0580', 'Discriminator accuracy 0.9883', 'Total loss: 3.4129', 'for batch', 5)
('GAN loss 3.3659 ', 'GAN acc 0.0000', 'Discriminator loss 0.0780', 'Discriminator accuracy 0.9824', 'Total loss: 3.4439', 'for batch', 6)
('GAN loss 3.3448 ', 'GAN acc 0.0000', 'Discriminator loss 0.0599', 'Discriminator accuracy 0.9883', 'Total loss: 3.4047', 'for batch', 7)
('GAN loss 3.3499 ', 'GAN acc 0.0000', 'Discriminator loss 0.1032', 'Discriminator accuracy 0.9746', 'Total loss: 3.4531', 'for batch', 8)
('GAN loss 3.3289 ', 'GAN acc 0.0000', 'Discriminator loss 0.0970', 'Discriminator accuracy 0.9766', 'Total loss: 3.4259', 'for batch', 9)
('GAN loss 3.3332 ', 'GAN acc 0.0000', 'Discriminator loss 0.0455', 'Discriminator accuracy 0.9922', 'Total loss: 3.3787', 'for batch', 10)
('GAN loss 3.3679 ', 'GAN acc 0.0000', 'Discriminator loss 0.0817', 'Discriminator accuracy 0.9805', 'Total loss: 3.4496', 'for batch', 11)
('GAN loss 3.3559 ', 'GAN acc 0.0000', 'Discriminator loss 0.0655', 'Discriminator accuracy 0.9863', 'Total loss: 3.4214', 'for batch', 12)
('GAN loss 3.3979 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.4569', 'for batch', 13)
('GAN loss 3.3715 ', 'GAN acc 0.0000', 'Discriminator loss 0.1071', 'Discriminator accuracy 0.9746', 'Total loss: 3.4786', 'for batch', 14)
('GAN loss 3.3555 ', 'GAN acc 0.0000', 'Discriminator loss 0.1079', 'Discriminator accuracy 0.9727', 'Total loss: 3.4634', 'for batch', 15)
('GAN loss 3.3105 ', 'GAN acc 0.0000', 'Discriminator loss 0.1152', 'Discriminator accuracy 0.9707', 'Total loss: 3.4257', 'for batch', 16)
('GAN loss 3.2915 ', 'GAN acc 0.0000', 'Discriminator loss 0.0833', 'Discriminator accuracy 0.9805', 'Total loss: 3.3749', 'for batch', 17)
('GAN loss 3.3082 ', 'GAN acc 0.0000', 'Discriminator loss 0.0461', 'Discriminator accuracy 0.9922', 'Total loss: 3.3543', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96356028)
('DISCRIMINATOR_Imagem FAKE=', 0.041189879)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.208459')
----------------------------------
('Epoch', 39, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0968', 'Discriminator accuracy 0.9766', 'Total loss: 3.4184', 'for batch', 0)
('GAN loss 3.3295 ', 'GAN acc 0.0000', 'Discriminator loss 0.0825', 'Discriminator accuracy 0.9805', 'Total loss: 3.4120', 'for batch', 1)
('GAN loss 3.3379 ', 'GAN acc 0.0000', 'Discriminator loss 0.0546', 'Discriminator accuracy 0.9883', 'Total loss: 3.3926', 'for batch', 2)
('GAN loss 3.3279 ', 'GAN acc 0.0000', 'Discriminator loss 0.0753', 'Discriminator accuracy 0.9805', 'Total loss: 3.4032', 'for batch', 3)
('GAN loss 3.3348 ', 'GAN acc 0.0000', 'Discriminator loss 0.0986', 'Discriminator accuracy 0.9766', 'Total loss: 3.4334', 'for batch', 4)
('GAN loss 3.3031 ', 'GAN acc 0.0000', 'Discriminator loss 0.0594', 'Discriminator accuracy 0.9883', 'Total loss: 3.3624', 'for batch', 5)
('GAN loss 3.3540 ', 'GAN acc 0.0000', 'Discriminator loss 0.0814', 'Discriminator accuracy 0.9824', 'Total loss: 3.4354', 'for batch', 6)
('GAN loss 3.3008 ', 'GAN acc 0.0000', 'Discriminator loss 0.0583', 'Discriminator accuracy 0.9883', 'Total loss: 3.3591', 'for batch', 7)
('GAN loss 3.2890 ', 'GAN acc 0.0000', 'Discriminator loss 0.1060', 'Discriminator accuracy 0.9746', 'Total loss: 3.3950', 'for batch', 8)
('GAN loss 3.3040 ', 'GAN acc 0.0000', 'Discriminator loss 0.0990', 'Discriminator accuracy 0.9766', 'Total loss: 3.4030', 'for batch', 9)
('GAN loss 3.3379 ', 'GAN acc 0.0000', 'Discriminator loss 0.0447', 'Discriminator accuracy 0.9922', 'Total loss: 3.3826', 'for batch', 10)
('GAN loss 3.3429 ', 'GAN acc 0.0000', 'Discriminator loss 0.0832', 'Discriminator accuracy 0.9805', 'Total loss: 3.4261', 'for batch', 11)
('GAN loss 3.3067 ', 'GAN acc 0.0000', 'Discriminator loss 0.0644', 'Discriminator accuracy 0.9863', 'Total loss: 3.3710', 'for batch', 12)
('GAN loss 3.3435 ', 'GAN acc 0.0000', 'Discriminator loss 0.0608', 'Discriminator accuracy 0.9883', 'Total loss: 3.4043', 'for batch', 13)
('GAN loss 3.3768 ', 'GAN acc 0.0000', 'Discriminator loss 0.1043', 'Discriminator accuracy 0.9746', 'Total loss: 3.4811', 'for batch', 14)
('GAN loss 3.3046 ', 'GAN acc 0.0000', 'Discriminator loss 0.1110', 'Discriminator accuracy 0.9727', 'Total loss: 3.4155', 'for batch', 15)
('GAN loss 3.2929 ', 'GAN acc 0.0000', 'Discriminator loss 0.1204', 'Discriminator accuracy 0.9707', 'Total loss: 3.4134', 'for batch', 16)
('GAN loss 3.2655 ', 'GAN acc 0.0000', 'Discriminator loss 0.0837', 'Discriminator accuracy 0.9805', 'Total loss: 3.3492', 'for batch', 17)
('GAN loss 3.2846 ', 'GAN acc 0.0000', 'Discriminator loss 0.0478', 'Discriminator accuracy 0.9922', 'Total loss: 3.3324', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96370274)
('DISCRIMINATOR_Imagem FAKE=', 0.04197995)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.728342')
----------------------------------
('Epoch', 40, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2992 ', 'GAN acc 0.0000', 'Discriminator loss 0.0986', 'Discriminator accuracy 0.9766', 'Total loss: 3.3978', 'for batch', 0)
('GAN loss 3.2791 ', 'GAN acc 0.0000', 'Discriminator loss 0.0838', 'Discriminator accuracy 0.9805', 'Total loss: 3.3629', 'for batch', 1)
('GAN loss 3.2751 ', 'GAN acc 0.0000', 'Discriminator loss 0.0547', 'Discriminator accuracy 0.9902', 'Total loss: 3.3298', 'for batch', 2)
('GAN loss 3.3226 ', 'GAN acc 0.0000', 'Discriminator loss 0.0745', 'Discriminator accuracy 0.9844', 'Total loss: 3.3972', 'for batch', 3)
('GAN loss 3.3055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0921', 'Discriminator accuracy 0.9766', 'Total loss: 3.3976', 'for batch', 4)
('GAN loss 3.3169 ', 'GAN acc 0.0000', 'Discriminator loss 0.0609', 'Discriminator accuracy 0.9883', 'Total loss: 3.3779', 'for batch', 5)
('GAN loss 3.3099 ', 'GAN acc 0.0000', 'Discriminator loss 0.0805', 'Discriminator accuracy 0.9824', 'Total loss: 3.3904', 'for batch', 6)
('GAN loss 3.3382 ', 'GAN acc 0.0000', 'Discriminator loss 0.0607', 'Discriminator accuracy 0.9883', 'Total loss: 3.3989', 'for batch', 7)
('GAN loss 3.2932 ', 'GAN acc 0.0000', 'Discriminator loss 0.0996', 'Discriminator accuracy 0.9746', 'Total loss: 3.3927', 'for batch', 8)
('GAN loss 3.3194 ', 'GAN acc 0.0000', 'Discriminator loss 0.1028', 'Discriminator accuracy 0.9766', 'Total loss: 3.4221', 'for batch', 9)
('GAN loss 3.2934 ', 'GAN acc 0.0000', 'Discriminator loss 0.0450', 'Discriminator accuracy 0.9922', 'Total loss: 3.3384', 'for batch', 10)
('GAN loss 3.3496 ', 'GAN acc 0.0000', 'Discriminator loss 0.0847', 'Discriminator accuracy 0.9805', 'Total loss: 3.4342', 'for batch', 11)
('GAN loss 3.3276 ', 'GAN acc 0.0000', 'Discriminator loss 0.0640', 'Discriminator accuracy 0.9863', 'Total loss: 3.3916', 'for batch', 12)
('GAN loss 3.3291 ', 'GAN acc 0.0000', 'Discriminator loss 0.0588', 'Discriminator accuracy 0.9883', 'Total loss: 3.3878', 'for batch', 13)
('GAN loss 3.3378 ', 'GAN acc 0.0000', 'Discriminator loss 0.1061', 'Discriminator accuracy 0.9746', 'Total loss: 3.4439', 'for batch', 14)
('GAN loss 3.2954 ', 'GAN acc 0.0000', 'Discriminator loss 0.1055', 'Discriminator accuracy 0.9727', 'Total loss: 3.4009', 'for batch', 15)
('GAN loss 3.3459 ', 'GAN acc 0.0000', 'Discriminator loss 0.1194', 'Discriminator accuracy 0.9707', 'Total loss: 3.4652', 'for batch', 16)
('GAN loss 3.2842 ', 'GAN acc 0.0000', 'Discriminator loss 0.0861', 'Discriminator accuracy 0.9805', 'Total loss: 3.3703', 'for batch', 17)
('GAN loss 3.2649 ', 'GAN acc 0.0000', 'Discriminator loss 0.0480', 'Discriminator accuracy 0.9922', 'Total loss: 3.3129', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96367139)
('DISCRIMINATOR_Imagem FAKE=', 0.037673764)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.190138')
----------------------------------
('Epoch', 41, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2185 ', 'GAN acc 0.0000', 'Discriminator loss 0.0994', 'Discriminator accuracy 0.9766', 'Total loss: 3.3180', 'for batch', 0)
('GAN loss 3.1815 ', 'GAN acc 0.0000', 'Discriminator loss 0.0911', 'Discriminator accuracy 0.9805', 'Total loss: 3.2727', 'for batch', 1)
('GAN loss 3.2200 ', 'GAN acc 0.0000', 'Discriminator loss 0.0603', 'Discriminator accuracy 0.9902', 'Total loss: 3.2803', 'for batch', 2)
('GAN loss 3.2377 ', 'GAN acc 0.0000', 'Discriminator loss 0.0812', 'Discriminator accuracy 0.9824', 'Total loss: 3.3189', 'for batch', 3)
('GAN loss 3.2877 ', 'GAN acc 0.0000', 'Discriminator loss 0.0995', 'Discriminator accuracy 0.9785', 'Total loss: 3.3872', 'for batch', 4)
('GAN loss 3.3516 ', 'GAN acc 0.0000', 'Discriminator loss 0.0616', 'Discriminator accuracy 0.9883', 'Total loss: 3.4132', 'for batch', 5)
('GAN loss 3.3923 ', 'GAN acc 0.0000', 'Discriminator loss 0.0806', 'Discriminator accuracy 0.9824', 'Total loss: 3.4729', 'for batch', 6)
('GAN loss 3.4010 ', 'GAN acc 0.0000', 'Discriminator loss 0.0608', 'Discriminator accuracy 0.9883', 'Total loss: 3.4618', 'for batch', 7)
('GAN loss 3.3674 ', 'GAN acc 0.0000', 'Discriminator loss 0.1158', 'Discriminator accuracy 0.9746', 'Total loss: 3.4832', 'for batch', 8)
('GAN loss 3.4581 ', 'GAN acc 0.0000', 'Discriminator loss 0.1058', 'Discriminator accuracy 0.9766', 'Total loss: 3.5639', 'for batch', 9)
('GAN loss 3.3809 ', 'GAN acc 0.0000', 'Discriminator loss 0.0541', 'Discriminator accuracy 0.9922', 'Total loss: 3.4349', 'for batch', 10)
('GAN loss 3.6517 ', 'GAN acc 0.0000', 'Discriminator loss 0.0890', 'Discriminator accuracy 0.9805', 'Total loss: 3.7407', 'for batch', 11)
('GAN loss 3.7007 ', 'GAN acc 0.0000', 'Discriminator loss 0.0780', 'Discriminator accuracy 0.9863', 'Total loss: 3.7786', 'for batch', 12)
('GAN loss 3.8745 ', 'GAN acc 0.0000', 'Discriminator loss 0.0687', 'Discriminator accuracy 0.9863', 'Total loss: 3.9432', 'for batch', 13)
('GAN loss 4.0672 ', 'GAN acc 0.0000', 'Discriminator loss 0.1121', 'Discriminator accuracy 0.9746', 'Total loss: 4.1792', 'for batch', 14)
('GAN loss 4.1760 ', 'GAN acc 0.0000', 'Discriminator loss 0.1177', 'Discriminator accuracy 0.9688', 'Total loss: 4.2936', 'for batch', 15)
('GAN loss 4.3484 ', 'GAN acc 0.0000', 'Discriminator loss 0.1224', 'Discriminator accuracy 0.9707', 'Total loss: 4.4708', 'for batch', 16)
('GAN loss 4.1364 ', 'GAN acc 0.0000', 'Discriminator loss 0.0928', 'Discriminator accuracy 0.9785', 'Total loss: 4.2292', 'for batch', 17)
('GAN loss 4.4041 ', 'GAN acc 0.0000', 'Discriminator loss 0.0446', 'Discriminator accuracy 0.9863', 'Total loss: 4.4487', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96083874)
('DISCRIMINATOR_Imagem FAKE=', 0.007927171)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.689638')
----------------------------------
('Epoch', 42, 'of', 50)
('Number of batches', 19)
('GAN loss 4.3277 ', 'GAN acc 0.0000', 'Discriminator loss 0.0970', 'Discriminator accuracy 0.9766', 'Total loss: 4.4248', 'for batch', 0)
('GAN loss 4.2892 ', 'GAN acc 0.0000', 'Discriminator loss 0.0822', 'Discriminator accuracy 0.9805', 'Total loss: 4.3714', 'for batch', 1)
('GAN loss 4.2926 ', 'GAN acc 0.0000', 'Discriminator loss 0.0575', 'Discriminator accuracy 0.9863', 'Total loss: 4.3501', 'for batch', 2)
('GAN loss 4.5071 ', 'GAN acc 0.0000', 'Discriminator loss 0.0706', 'Discriminator accuracy 0.9824', 'Total loss: 4.5776', 'for batch', 3)
('GAN loss 4.5904 ', 'GAN acc 0.0000', 'Discriminator loss 0.0973', 'Discriminator accuracy 0.9766', 'Total loss: 4.6877', 'for batch', 4)
('GAN loss 4.6942 ', 'GAN acc 0.0000', 'Discriminator loss 0.0498', 'Discriminator accuracy 0.9883', 'Total loss: 4.7440', 'for batch', 5)
('GAN loss 4.5601 ', 'GAN acc 0.0000', 'Discriminator loss 0.0946', 'Discriminator accuracy 0.9766', 'Total loss: 4.6548', 'for batch', 6)
('GAN loss 4.6449 ', 'GAN acc 0.0000', 'Discriminator loss 0.0472', 'Discriminator accuracy 0.9883', 'Total loss: 4.6921', 'for batch', 7)
('GAN loss 4.6040 ', 'GAN acc 0.0000', 'Discriminator loss 0.0998', 'Discriminator accuracy 0.9707', 'Total loss: 4.7038', 'for batch', 8)
('GAN loss 4.6256 ', 'GAN acc 0.0000', 'Discriminator loss 0.0890', 'Discriminator accuracy 0.9727', 'Total loss: 4.7146', 'for batch', 9)
('GAN loss 4.7165 ', 'GAN acc 0.0000', 'Discriminator loss 0.0362', 'Discriminator accuracy 0.9922', 'Total loss: 4.7527', 'for batch', 10)
('GAN loss 4.5960 ', 'GAN acc 0.0000', 'Discriminator loss 0.0718', 'Discriminator accuracy 0.9805', 'Total loss: 4.6678', 'for batch', 11)
('GAN loss 4.7340 ', 'GAN acc 0.0000', 'Discriminator loss 0.0497', 'Discriminator accuracy 0.9863', 'Total loss: 4.7837', 'for batch', 12)
('GAN loss 4.7381 ', 'GAN acc 0.0000', 'Discriminator loss 0.0430', 'Discriminator accuracy 0.9883', 'Total loss: 4.7811', 'for batch', 13)
('GAN loss 4.7845 ', 'GAN acc 0.0000', 'Discriminator loss 0.0838', 'Discriminator accuracy 0.9746', 'Total loss: 4.8683', 'for batch', 14)
('GAN loss 4.7474 ', 'GAN acc 0.0000', 'Discriminator loss 0.0965', 'Discriminator accuracy 0.9707', 'Total loss: 4.8439', 'for batch', 15)
('GAN loss 4.6856 ', 'GAN acc 0.0000', 'Discriminator loss 0.0935', 'Discriminator accuracy 0.9707', 'Total loss: 4.7791', 'for batch', 16)
('GAN loss 4.5558 ', 'GAN acc 0.0000', 'Discriminator loss 0.0731', 'Discriminator accuracy 0.9785', 'Total loss: 4.6289', 'for batch', 17)
('GAN loss 4.5138 ', 'GAN acc 0.0000', 'Discriminator loss 0.0358', 'Discriminator accuracy 0.9863', 'Total loss: 4.5496', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96150255)
('DISCRIMINATOR_Imagem FAKE=', 0.010075791)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.725796')
----------------------------------
('Epoch', 43, 'of', 50)
('Number of batches', 19)
('GAN loss 4.3133 ', 'GAN acc 0.0000', 'Discriminator loss 0.0741', 'Discriminator accuracy 0.9766', 'Total loss: 4.3875', 'for batch', 0)
('GAN loss 4.2224 ', 'GAN acc 0.0000', 'Discriminator loss 0.0715', 'Discriminator accuracy 0.9785', 'Total loss: 4.2939', 'for batch', 1)
('GAN loss 4.0984 ', 'GAN acc 0.0000', 'Discriminator loss 0.0447', 'Discriminator accuracy 0.9863', 'Total loss: 4.1431', 'for batch', 2)
('GAN loss 3.9713 ', 'GAN acc 0.0000', 'Discriminator loss 0.0543', 'Discriminator accuracy 0.9824', 'Total loss: 4.0256', 'for batch', 3)
('GAN loss 3.9807 ', 'GAN acc 0.0039', 'Discriminator loss 0.0875', 'Discriminator accuracy 0.9746', 'Total loss: 4.0681', 'for batch', 4)
('GAN loss 4.1708 ', 'GAN acc 0.0000', 'Discriminator loss 0.0559', 'Discriminator accuracy 0.9844', 'Total loss: 4.2267', 'for batch', 5)
('GAN loss 4.3377 ', 'GAN acc 0.0000', 'Discriminator loss 0.0639', 'Discriminator accuracy 0.9785', 'Total loss: 4.4016', 'for batch', 6)
('GAN loss 4.3941 ', 'GAN acc 0.0000', 'Discriminator loss 0.0421', 'Discriminator accuracy 0.9883', 'Total loss: 4.4363', 'for batch', 7)
('GAN loss 3.9901 ', 'GAN acc 0.0000', 'Discriminator loss 0.0915', 'Discriminator accuracy 0.9707', 'Total loss: 4.0816', 'for batch', 8)
('GAN loss 3.6216 ', 'GAN acc 0.0000', 'Discriminator loss 0.0963', 'Discriminator accuracy 0.9707', 'Total loss: 3.7179', 'for batch', 9)
('GAN loss 3.4495 ', 'GAN acc 0.0000', 'Discriminator loss 0.0460', 'Discriminator accuracy 0.9902', 'Total loss: 3.4955', 'for batch', 10)
('GAN loss 3.5031 ', 'GAN acc 0.0039', 'Discriminator loss 0.0766', 'Discriminator accuracy 0.9746', 'Total loss: 3.5797', 'for batch', 11)
('GAN loss 3.7453 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9844', 'Total loss: 3.8064', 'for batch', 12)
('GAN loss 3.7649 ', 'GAN acc 0.0000', 'Discriminator loss 0.0499', 'Discriminator accuracy 0.9883', 'Total loss: 3.8148', 'for batch', 13)
('GAN loss 3.7027 ', 'GAN acc 0.0000', 'Discriminator loss 0.0840', 'Discriminator accuracy 0.9746', 'Total loss: 3.7867', 'for batch', 14)
('GAN loss 3.4091 ', 'GAN acc 0.0000', 'Discriminator loss 0.1175', 'Discriminator accuracy 0.9648', 'Total loss: 3.5266', 'for batch', 15)
('GAN loss 3.1687 ', 'GAN acc 0.0000', 'Discriminator loss 0.1051', 'Discriminator accuracy 0.9688', 'Total loss: 3.2738', 'for batch', 16)
('GAN loss 3.1307 ', 'GAN acc 0.0000', 'Discriminator loss 0.0856', 'Discriminator accuracy 0.9785', 'Total loss: 3.2162', 'for batch', 17)
('GAN loss 3.1324 ', 'GAN acc 0.0000', 'Discriminator loss 0.0487', 'Discriminator accuracy 0.9922', 'Total loss: 3.1811', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.95883113)
('DISCRIMINATOR_Imagem FAKE=', 0.04953013)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.244786')
----------------------------------
('Epoch', 44, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1667 ', 'GAN acc 0.0000', 'Discriminator loss 0.0835', 'Discriminator accuracy 0.9766', 'Total loss: 3.2502', 'for batch', 0)
('GAN loss 3.1579 ', 'GAN acc 0.0000', 'Discriminator loss 0.0868', 'Discriminator accuracy 0.9766', 'Total loss: 3.2447', 'for batch', 1)
('GAN loss 3.0379 ', 'GAN acc 0.0000', 'Discriminator loss 0.0886', 'Discriminator accuracy 0.9785', 'Total loss: 3.1265', 'for batch', 2)
('GAN loss 2.9111 ', 'GAN acc 0.0000', 'Discriminator loss 0.0743', 'Discriminator accuracy 0.9824', 'Total loss: 2.9854', 'for batch', 3)
('GAN loss 2.9162 ', 'GAN acc 0.0000', 'Discriminator loss 0.1011', 'Discriminator accuracy 0.9727', 'Total loss: 3.0173', 'for batch', 4)
('GAN loss 2.9312 ', 'GAN acc 0.0000', 'Discriminator loss 0.0648', 'Discriminator accuracy 0.9883', 'Total loss: 2.9960', 'for batch', 5)
('GAN loss 2.9808 ', 'GAN acc 0.0000', 'Discriminator loss 0.0758', 'Discriminator accuracy 0.9824', 'Total loss: 3.0566', 'for batch', 6)
('GAN loss 2.9945 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.0536', 'for batch', 7)
('GAN loss 3.0097 ', 'GAN acc 0.0000', 'Discriminator loss 0.0984', 'Discriminator accuracy 0.9746', 'Total loss: 3.1081', 'for batch', 8)
('GAN loss 2.9601 ', 'GAN acc 0.0000', 'Discriminator loss 0.0939', 'Discriminator accuracy 0.9766', 'Total loss: 3.0540', 'for batch', 9)
('GAN loss 2.9223 ', 'GAN acc 0.0000', 'Discriminator loss 0.0528', 'Discriminator accuracy 0.9922', 'Total loss: 2.9750', 'for batch', 10)
('GAN loss 2.9252 ', 'GAN acc 0.0000', 'Discriminator loss 0.0831', 'Discriminator accuracy 0.9805', 'Total loss: 3.0082', 'for batch', 11)
('GAN loss 2.9233 ', 'GAN acc 0.0000', 'Discriminator loss 0.0718', 'Discriminator accuracy 0.9863', 'Total loss: 2.9952', 'for batch', 12)
('GAN loss 2.9434 ', 'GAN acc 0.0000', 'Discriminator loss 0.0660', 'Discriminator accuracy 0.9863', 'Total loss: 3.0094', 'for batch', 13)
('GAN loss 2.9867 ', 'GAN acc 0.0000', 'Discriminator loss 0.1024', 'Discriminator accuracy 0.9746', 'Total loss: 3.0891', 'for batch', 14)
('GAN loss 3.0004 ', 'GAN acc 0.0000', 'Discriminator loss 0.1116', 'Discriminator accuracy 0.9707', 'Total loss: 3.1120', 'for batch', 15)
('GAN loss 2.9811 ', 'GAN acc 0.0000', 'Discriminator loss 0.1163', 'Discriminator accuracy 0.9707', 'Total loss: 3.0975', 'for batch', 16)
('GAN loss 2.9847 ', 'GAN acc 0.0000', 'Discriminator loss 0.0961', 'Discriminator accuracy 0.9785', 'Total loss: 3.0808', 'for batch', 17)
('GAN loss 3.0444 ', 'GAN acc 0.0000', 'Discriminator loss 0.0555', 'Discriminator accuracy 0.9883', 'Total loss: 3.0999', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96137005)
('DISCRIMINATOR_Imagem FAKE=', 0.059253383)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.717938')
----------------------------------
('Epoch', 45, 'of', 50)
('Number of batches', 19)
('GAN loss 3.0716 ', 'GAN acc 0.0000', 'Discriminator loss 0.0978', 'Discriminator accuracy 0.9766', 'Total loss: 3.1694', 'for batch', 0)
('GAN loss 3.0709 ', 'GAN acc 0.0000', 'Discriminator loss 0.0855', 'Discriminator accuracy 0.9805', 'Total loss: 3.1565', 'for batch', 1)
('GAN loss 3.0710 ', 'GAN acc 0.0000', 'Discriminator loss 0.0614', 'Discriminator accuracy 0.9844', 'Total loss: 3.1324', 'for batch', 2)
('GAN loss 3.1429 ', 'GAN acc 0.0000', 'Discriminator loss 0.0760', 'Discriminator accuracy 0.9824', 'Total loss: 3.2189', 'for batch', 3)
('GAN loss 3.1132 ', 'GAN acc 0.0000', 'Discriminator loss 0.1037', 'Discriminator accuracy 0.9766', 'Total loss: 3.2169', 'for batch', 4)
('GAN loss 3.1278 ', 'GAN acc 0.0000', 'Discriminator loss 0.0611', 'Discriminator accuracy 0.9883', 'Total loss: 3.1889', 'for batch', 5)
('GAN loss 3.1656 ', 'GAN acc 0.0000', 'Discriminator loss 0.0811', 'Discriminator accuracy 0.9824', 'Total loss: 3.2467', 'for batch', 6)
('GAN loss 3.2557 ', 'GAN acc 0.0000', 'Discriminator loss 0.0594', 'Discriminator accuracy 0.9883', 'Total loss: 3.3151', 'for batch', 7)
('GAN loss 3.1816 ', 'GAN acc 0.0000', 'Discriminator loss 0.1004', 'Discriminator accuracy 0.9746', 'Total loss: 3.2820', 'for batch', 8)
('GAN loss 3.2325 ', 'GAN acc 0.0000', 'Discriminator loss 0.0991', 'Discriminator accuracy 0.9766', 'Total loss: 3.3316', 'for batch', 9)
('GAN loss 3.2567 ', 'GAN acc 0.0000', 'Discriminator loss 0.0461', 'Discriminator accuracy 0.9922', 'Total loss: 3.3028', 'for batch', 10)
('GAN loss 3.2684 ', 'GAN acc 0.0000', 'Discriminator loss 0.0861', 'Discriminator accuracy 0.9805', 'Total loss: 3.3546', 'for batch', 11)
('GAN loss 3.2624 ', 'GAN acc 0.0000', 'Discriminator loss 0.0657', 'Discriminator accuracy 0.9863', 'Total loss: 3.3282', 'for batch', 12)
('GAN loss 3.2962 ', 'GAN acc 0.0000', 'Discriminator loss 0.0638', 'Discriminator accuracy 0.9863', 'Total loss: 3.3600', 'for batch', 13)
('GAN loss 3.3002 ', 'GAN acc 0.0000', 'Discriminator loss 0.1029', 'Discriminator accuracy 0.9746', 'Total loss: 3.4032', 'for batch', 14)
('GAN loss 3.2508 ', 'GAN acc 0.0000', 'Discriminator loss 0.1151', 'Discriminator accuracy 0.9707', 'Total loss: 3.3659', 'for batch', 15)
('GAN loss 3.2012 ', 'GAN acc 0.0000', 'Discriminator loss 0.1159', 'Discriminator accuracy 0.9707', 'Total loss: 3.3171', 'for batch', 16)
('GAN loss 3.1835 ', 'GAN acc 0.0000', 'Discriminator loss 0.0868', 'Discriminator accuracy 0.9785', 'Total loss: 3.2702', 'for batch', 17)
('GAN loss 3.2080 ', 'GAN acc 0.0000', 'Discriminator loss 0.0478', 'Discriminator accuracy 0.9922', 'Total loss: 3.2557', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96214586)
('DISCRIMINATOR_Imagem FAKE=', 0.04845928)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.185065')
----------------------------------
('Epoch', 46, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2269 ', 'GAN acc 0.0000', 'Discriminator loss 0.0993', 'Discriminator accuracy 0.9766', 'Total loss: 3.3262', 'for batch', 0)
('GAN loss 3.2415 ', 'GAN acc 0.0000', 'Discriminator loss 0.0864', 'Discriminator accuracy 0.9785', 'Total loss: 3.3279', 'for batch', 1)
('GAN loss 3.2264 ', 'GAN acc 0.0000', 'Discriminator loss 0.0548', 'Discriminator accuracy 0.9883', 'Total loss: 3.2812', 'for batch', 2)
('GAN loss 3.2618 ', 'GAN acc 0.0000', 'Discriminator loss 0.0734', 'Discriminator accuracy 0.9844', 'Total loss: 3.3352', 'for batch', 3)
('GAN loss 3.2644 ', 'GAN acc 0.0000', 'Discriminator loss 0.0962', 'Discriminator accuracy 0.9766', 'Total loss: 3.3606', 'for batch', 4)
('GAN loss 3.2550 ', 'GAN acc 0.0000', 'Discriminator loss 0.0562', 'Discriminator accuracy 0.9883', 'Total loss: 3.3112', 'for batch', 5)
('GAN loss 3.2938 ', 'GAN acc 0.0000', 'Discriminator loss 0.0786', 'Discriminator accuracy 0.9824', 'Total loss: 3.3724', 'for batch', 6)
('GAN loss 3.3345 ', 'GAN acc 0.0000', 'Discriminator loss 0.0616', 'Discriminator accuracy 0.9863', 'Total loss: 3.3961', 'for batch', 7)
('GAN loss 3.2979 ', 'GAN acc 0.0000', 'Discriminator loss 0.1060', 'Discriminator accuracy 0.9746', 'Total loss: 3.4039', 'for batch', 8)
('GAN loss 3.2895 ', 'GAN acc 0.0000', 'Discriminator loss 0.1029', 'Discriminator accuracy 0.9766', 'Total loss: 3.3923', 'for batch', 9)
('GAN loss 3.3127 ', 'GAN acc 0.0000', 'Discriminator loss 0.0445', 'Discriminator accuracy 0.9922', 'Total loss: 3.3573', 'for batch', 10)
('GAN loss 3.3291 ', 'GAN acc 0.0000', 'Discriminator loss 0.0834', 'Discriminator accuracy 0.9805', 'Total loss: 3.4125', 'for batch', 11)
('GAN loss 3.3392 ', 'GAN acc 0.0000', 'Discriminator loss 0.0654', 'Discriminator accuracy 0.9863', 'Total loss: 3.4046', 'for batch', 12)
('GAN loss 3.3707 ', 'GAN acc 0.0000', 'Discriminator loss 0.0590', 'Discriminator accuracy 0.9883', 'Total loss: 3.4298', 'for batch', 13)
('GAN loss 3.3197 ', 'GAN acc 0.0000', 'Discriminator loss 0.1059', 'Discriminator accuracy 0.9746', 'Total loss: 3.4257', 'for batch', 14)
('GAN loss 3.3150 ', 'GAN acc 0.0000', 'Discriminator loss 0.1181', 'Discriminator accuracy 0.9707', 'Total loss: 3.4331', 'for batch', 15)
('GAN loss 3.2697 ', 'GAN acc 0.0000', 'Discriminator loss 0.1173', 'Discriminator accuracy 0.9707', 'Total loss: 3.3869', 'for batch', 16)
('GAN loss 3.2845 ', 'GAN acc 0.0000', 'Discriminator loss 0.0875', 'Discriminator accuracy 0.9805', 'Total loss: 3.3720', 'for batch', 17)
('GAN loss 3.2910 ', 'GAN acc 0.0000', 'Discriminator loss 0.0476', 'Discriminator accuracy 0.9922', 'Total loss: 3.3386', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96239179)
('DISCRIMINATOR_Imagem FAKE=', 0.045268703)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.711520')
----------------------------------
('Epoch', 47, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2683 ', 'GAN acc 0.0000', 'Discriminator loss 0.1011', 'Discriminator accuracy 0.9766', 'Total loss: 3.3694', 'for batch', 0)
('GAN loss 3.2621 ', 'GAN acc 0.0000', 'Discriminator loss 0.0850', 'Discriminator accuracy 0.9805', 'Total loss: 3.3471', 'for batch', 1)
('GAN loss 3.2935 ', 'GAN acc 0.0000', 'Discriminator loss 0.0560', 'Discriminator accuracy 0.9883', 'Total loss: 3.3496', 'for batch', 2)
('GAN loss 3.2931 ', 'GAN acc 0.0000', 'Discriminator loss 0.0750', 'Discriminator accuracy 0.9824', 'Total loss: 3.3682', 'for batch', 3)
('GAN loss 3.2757 ', 'GAN acc 0.0000', 'Discriminator loss 0.1010', 'Discriminator accuracy 0.9766', 'Total loss: 3.3767', 'for batch', 4)
('GAN loss 3.3063 ', 'GAN acc 0.0000', 'Discriminator loss 0.0583', 'Discriminator accuracy 0.9883', 'Total loss: 3.3646', 'for batch', 5)
('GAN loss 3.3495 ', 'GAN acc 0.0000', 'Discriminator loss 0.0777', 'Discriminator accuracy 0.9824', 'Total loss: 3.4272', 'for batch', 6)
('GAN loss 3.3493 ', 'GAN acc 0.0000', 'Discriminator loss 0.0592', 'Discriminator accuracy 0.9883', 'Total loss: 3.4086', 'for batch', 7)
('GAN loss 3.3282 ', 'GAN acc 0.0000', 'Discriminator loss 0.1089', 'Discriminator accuracy 0.9727', 'Total loss: 3.4371', 'for batch', 8)
('GAN loss 3.2915 ', 'GAN acc 0.0000', 'Discriminator loss 0.0991', 'Discriminator accuracy 0.9766', 'Total loss: 3.3907', 'for batch', 9)
('GAN loss 3.3175 ', 'GAN acc 0.0000', 'Discriminator loss 0.0455', 'Discriminator accuracy 0.9922', 'Total loss: 3.3629', 'for batch', 10)
('GAN loss 3.3399 ', 'GAN acc 0.0000', 'Discriminator loss 0.0857', 'Discriminator accuracy 0.9805', 'Total loss: 3.4256', 'for batch', 11)
('GAN loss 3.3190 ', 'GAN acc 0.0000', 'Discriminator loss 0.0638', 'Discriminator accuracy 0.9863', 'Total loss: 3.3829', 'for batch', 12)
('GAN loss 3.3576 ', 'GAN acc 0.0000', 'Discriminator loss 0.0583', 'Discriminator accuracy 0.9883', 'Total loss: 3.4159', 'for batch', 13)
('GAN loss 3.3375 ', 'GAN acc 0.0000', 'Discriminator loss 0.1026', 'Discriminator accuracy 0.9746', 'Total loss: 3.4402', 'for batch', 14)
('GAN loss 3.3290 ', 'GAN acc 0.0000', 'Discriminator loss 0.1118', 'Discriminator accuracy 0.9707', 'Total loss: 3.4408', 'for batch', 15)
('GAN loss 3.2904 ', 'GAN acc 0.0000', 'Discriminator loss 0.1159', 'Discriminator accuracy 0.9707', 'Total loss: 3.4063', 'for batch', 16)
('GAN loss 3.2422 ', 'GAN acc 0.0000', 'Discriminator loss 0.0850', 'Discriminator accuracy 0.9805', 'Total loss: 3.3272', 'for batch', 17)
('GAN loss 3.2793 ', 'GAN acc 0.0000', 'Discriminator loss 0.0462', 'Discriminator accuracy 0.9922', 'Total loss: 3.3255', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96293068)
('DISCRIMINATOR_Imagem FAKE=', 0.044376649)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.190792')
----------------------------------
('Epoch', 48, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2795 ', 'GAN acc 0.0000', 'Discriminator loss 0.1001', 'Discriminator accuracy 0.9766', 'Total loss: 3.3796', 'for batch', 0)
('GAN loss 3.2628 ', 'GAN acc 0.0000', 'Discriminator loss 0.0855', 'Discriminator accuracy 0.9805', 'Total loss: 3.3483', 'for batch', 1)
('GAN loss 3.2880 ', 'GAN acc 0.0000', 'Discriminator loss 0.0531', 'Discriminator accuracy 0.9883', 'Total loss: 3.3410', 'for batch', 2)
('GAN loss 3.3511 ', 'GAN acc 0.0000', 'Discriminator loss 0.0706', 'Discriminator accuracy 0.9844', 'Total loss: 3.4217', 'for batch', 3)
('GAN loss 3.2738 ', 'GAN acc 0.0000', 'Discriminator loss 0.1005', 'Discriminator accuracy 0.9766', 'Total loss: 3.3743', 'for batch', 4)
('GAN loss 3.3546 ', 'GAN acc 0.0000', 'Discriminator loss 0.0584', 'Discriminator accuracy 0.9883', 'Total loss: 3.4130', 'for batch', 5)
('GAN loss 3.3358 ', 'GAN acc 0.0000', 'Discriminator loss 0.0799', 'Discriminator accuracy 0.9824', 'Total loss: 3.4157', 'for batch', 6)
('GAN loss 3.3747 ', 'GAN acc 0.0000', 'Discriminator loss 0.0598', 'Discriminator accuracy 0.9883', 'Total loss: 3.4346', 'for batch', 7)
('GAN loss 3.3679 ', 'GAN acc 0.0000', 'Discriminator loss 0.1041', 'Discriminator accuracy 0.9746', 'Total loss: 3.4721', 'for batch', 8)
('GAN loss 3.3563 ', 'GAN acc 0.0000', 'Discriminator loss 0.0997', 'Discriminator accuracy 0.9746', 'Total loss: 3.4560', 'for batch', 9)
('GAN loss 3.3791 ', 'GAN acc 0.0000', 'Discriminator loss 0.0465', 'Discriminator accuracy 0.9922', 'Total loss: 3.4256', 'for batch', 10)
('GAN loss 3.3361 ', 'GAN acc 0.0000', 'Discriminator loss 0.0820', 'Discriminator accuracy 0.9805', 'Total loss: 3.4181', 'for batch', 11)
('GAN loss 3.3437 ', 'GAN acc 0.0000', 'Discriminator loss 0.0640', 'Discriminator accuracy 0.9863', 'Total loss: 3.4077', 'for batch', 12)
('GAN loss 3.3886 ', 'GAN acc 0.0000', 'Discriminator loss 0.0596', 'Discriminator accuracy 0.9883', 'Total loss: 3.4481', 'for batch', 13)
('GAN loss 3.3940 ', 'GAN acc 0.0000', 'Discriminator loss 0.1064', 'Discriminator accuracy 0.9746', 'Total loss: 3.5004', 'for batch', 14)
('GAN loss 3.3369 ', 'GAN acc 0.0000', 'Discriminator loss 0.1091', 'Discriminator accuracy 0.9707', 'Total loss: 3.4460', 'for batch', 15)
('GAN loss 3.2895 ', 'GAN acc 0.0000', 'Discriminator loss 0.1156', 'Discriminator accuracy 0.9707', 'Total loss: 3.4051', 'for batch', 16)
('GAN loss 3.2692 ', 'GAN acc 0.0000', 'Discriminator loss 0.0852', 'Discriminator accuracy 0.9785', 'Total loss: 3.3544', 'for batch', 17)
('GAN loss 3.3416 ', 'GAN acc 0.0000', 'Discriminator loss 0.0474', 'Discriminator accuracy 0.9902', 'Total loss: 3.3890', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96317834)
('DISCRIMINATOR_Imagem FAKE=', 0.043865386)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.705978')
----------------------------------
('Epoch', 49, 'of', 50)
('Number of batches', 19)
('GAN loss 3.2690 ', 'GAN acc 0.0000', 'Discriminator loss 0.0997', 'Discriminator accuracy 0.9766', 'Total loss: 3.3687', 'for batch', 0)
('GAN loss 3.2704 ', 'GAN acc 0.0000', 'Discriminator loss 0.0854', 'Discriminator accuracy 0.9805', 'Total loss: 3.3558', 'for batch', 1)
('GAN loss 3.2987 ', 'GAN acc 0.0000', 'Discriminator loss 0.0532', 'Discriminator accuracy 0.9883', 'Total loss: 3.3519', 'for batch', 2)
('GAN loss 3.3150 ', 'GAN acc 0.0000', 'Discriminator loss 0.0760', 'Discriminator accuracy 0.9824', 'Total loss: 3.3910', 'for batch', 3)
('GAN loss 3.3063 ', 'GAN acc 0.0000', 'Discriminator loss 0.0961', 'Discriminator accuracy 0.9766', 'Total loss: 3.4024', 'for batch', 4)
('GAN loss 3.3084 ', 'GAN acc 0.0000', 'Discriminator loss 0.0609', 'Discriminator accuracy 0.9883', 'Total loss: 3.3693', 'for batch', 5)
('GAN loss 3.3410 ', 'GAN acc 0.0000', 'Discriminator loss 0.0760', 'Discriminator accuracy 0.9824', 'Total loss: 3.4170', 'for batch', 6)
('GAN loss 3.3956 ', 'GAN acc 0.0000', 'Discriminator loss 0.0587', 'Discriminator accuracy 0.9883', 'Total loss: 3.4543', 'for batch', 7)
('GAN loss 3.3401 ', 'GAN acc 0.0000', 'Discriminator loss 0.1047', 'Discriminator accuracy 0.9746', 'Total loss: 3.4448', 'for batch', 8)
('GAN loss 3.3350 ', 'GAN acc 0.0000', 'Discriminator loss 0.0976', 'Discriminator accuracy 0.9766', 'Total loss: 3.4326', 'for batch', 9)
('GAN loss 3.3647 ', 'GAN acc 0.0000', 'Discriminator loss 0.0473', 'Discriminator accuracy 0.9922', 'Total loss: 3.4120', 'for batch', 10)
('GAN loss 3.3362 ', 'GAN acc 0.0000', 'Discriminator loss 0.0828', 'Discriminator accuracy 0.9805', 'Total loss: 3.4190', 'for batch', 11)
('GAN loss 3.3613 ', 'GAN acc 0.0000', 'Discriminator loss 0.0651', 'Discriminator accuracy 0.9863', 'Total loss: 3.4265', 'for batch', 12)
('GAN loss 3.4309 ', 'GAN acc 0.0000', 'Discriminator loss 0.0571', 'Discriminator accuracy 0.9883', 'Total loss: 3.4880', 'for batch', 13)
('GAN loss 3.3877 ', 'GAN acc 0.0000', 'Discriminator loss 0.1049', 'Discriminator accuracy 0.9746', 'Total loss: 3.4927', 'for batch', 14)
('GAN loss 3.3410 ', 'GAN acc 0.0000', 'Discriminator loss 0.1185', 'Discriminator accuracy 0.9707', 'Total loss: 3.4595', 'for batch', 15)
('GAN loss 3.2553 ', 'GAN acc 0.0000', 'Discriminator loss 0.1181', 'Discriminator accuracy 0.9707', 'Total loss: 3.3734', 'for batch', 16)
('GAN loss 3.2634 ', 'GAN acc 0.0000', 'Discriminator loss 0.0817', 'Discriminator accuracy 0.9785', 'Total loss: 3.3451', 'for batch', 17)
('GAN loss 3.3048 ', 'GAN acc 0.0000', 'Discriminator loss 0.0462', 'Discriminator accuracy 0.9922', 'Total loss: 3.3511', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96339172)
('DISCRIMINATOR_Imagem FAKE=', 0.043631401)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.229117')
----------------------------------
('Epoch', 50, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3020 ', 'GAN acc 0.0000', 'Discriminator loss 0.0967', 'Discriminator accuracy 0.9766', 'Total loss: 3.3987', 'for batch', 0)
('GAN loss 3.3092 ', 'GAN acc 0.0000', 'Discriminator loss 0.0830', 'Discriminator accuracy 0.9785', 'Total loss: 3.3922', 'for batch', 1)
('GAN loss 3.3149 ', 'GAN acc 0.0000', 'Discriminator loss 0.0562', 'Discriminator accuracy 0.9883', 'Total loss: 3.3711', 'for batch', 2)
('GAN loss 3.3396 ', 'GAN acc 0.0000', 'Discriminator loss 0.0723', 'Discriminator accuracy 0.9844', 'Total loss: 3.4119', 'for batch', 3)
('GAN loss 3.3182 ', 'GAN acc 0.0000', 'Discriminator loss 0.0986', 'Discriminator accuracy 0.9766', 'Total loss: 3.4169', 'for batch', 4)
('GAN loss 3.2965 ', 'GAN acc 0.0000', 'Discriminator loss 0.0556', 'Discriminator accuracy 0.9883', 'Total loss: 3.3521', 'for batch', 5)
('GAN loss 3.3346 ', 'GAN acc 0.0000', 'Discriminator loss 0.0790', 'Discriminator accuracy 0.9824', 'Total loss: 3.4136', 'for batch', 6)
('GAN loss 3.3307 ', 'GAN acc 0.0000', 'Discriminator loss 0.0593', 'Discriminator accuracy 0.9883', 'Total loss: 3.3900', 'for batch', 7)
('GAN loss 3.3319 ', 'GAN acc 0.0000', 'Discriminator loss 0.1038', 'Discriminator accuracy 0.9746', 'Total loss: 3.4358', 'for batch', 8)
('GAN loss 3.2977 ', 'GAN acc 0.0000', 'Discriminator loss 0.0968', 'Discriminator accuracy 0.9766', 'Total loss: 3.3945', 'for batch', 9)
('GAN loss 3.3470 ', 'GAN acc 0.0000', 'Discriminator loss 0.0447', 'Discriminator accuracy 0.9922', 'Total loss: 3.3917', 'for batch', 10)
('GAN loss 3.3800 ', 'GAN acc 0.0000', 'Discriminator loss 0.0869', 'Discriminator accuracy 0.9805', 'Total loss: 3.4670', 'for batch', 11)
('GAN loss 3.3995 ', 'GAN acc 0.0000', 'Discriminator loss 0.0617', 'Discriminator accuracy 0.9863', 'Total loss: 3.4612', 'for batch', 12)
('GAN loss 3.3587 ', 'GAN acc 0.0000', 'Discriminator loss 0.0587', 'Discriminator accuracy 0.9883', 'Total loss: 3.4173', 'for batch', 13)
('GAN loss 3.3830 ', 'GAN acc 0.0000', 'Discriminator loss 0.1015', 'Discriminator accuracy 0.9746', 'Total loss: 3.4845', 'for batch', 14)
('GAN loss 3.3384 ', 'GAN acc 0.0000', 'Discriminator loss 0.1129', 'Discriminator accuracy 0.9707', 'Total loss: 3.4512', 'for batch', 15)
('GAN loss 3.3109 ', 'GAN acc 0.0000', 'Discriminator loss 0.1181', 'Discriminator accuracy 0.9707', 'Total loss: 3.4290', 'for batch', 16)
('GAN loss 3.2641 ', 'GAN acc 0.0000', 'Discriminator loss 0.0842', 'Discriminator accuracy 0.9805', 'Total loss: 3.3483', 'for batch', 17)
('GAN loss 3.2970 ', 'GAN acc 0.0000', 'Discriminator loss 0.0461', 'Discriminator accuracy 0.9922', 'Total loss: 3.3431', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96353781)
('DISCRIMINATOR_Imagem FAKE=', 0.043483976)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.695570')
----------------------------------
End of training
Saving histograms
----------------------------------
('Total samples = ', 5000, ' Batch size =', 256, ' Epochs = ', 50)
('Generator loss 3.2970 ', 'Discriminator loss 0.0461', 'Total: 3.3431')
----------------------------------
---DISCRIMINATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
None
----------------------------------
---GENERATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_5 (Convolution2D)  (None, 32, 32, 32)    320         convolution2d_input_2[0][0]      
____________________________________________________________________________________________________
leakyrelu_6 (LeakyReLU)          (None, 32, 32, 32)    0           convolution2d_5[0][0]            
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 64, 32, 32)    18496       leakyrelu_6[0][0]                
____________________________________________________________________________________________________
batchnormalization_1 (BatchNormal(None, 64, 32, 32)    128         convolution2d_6[0][0]            
____________________________________________________________________________________________________
leakyrelu_7 (LeakyReLU)          (None, 64, 32, 32)    0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 128, 32, 32)   73856       leakyrelu_7[0][0]                
____________________________________________________________________________________________________
batchnormalization_2 (BatchNormal(None, 128, 32, 32)   256         convolution2d_7[0][0]            
____________________________________________________________________________________________________
leakyrelu_8 (LeakyReLU)          (None, 128, 32, 32)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 256, 32, 32)   295168      leakyrelu_8[0][0]                
____________________________________________________________________________________________________
batchnormalization_3 (BatchNormal(None, 256, 32, 32)   512         convolution2d_8[0][0]            
____________________________________________________________________________________________________
leakyrelu_9 (LeakyReLU)          (None, 256, 32, 32)   0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 256, 32, 32)   590080      leakyrelu_9[0][0]                
____________________________________________________________________________________________________
batchnormalization_4 (BatchNormal(None, 256, 32, 32)   512         convolution2d_9[0][0]            
____________________________________________________________________________________________________
leakyrelu_10 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_4[0][0]       
____________________________________________________________________________________________________
convolution2d_10 (Convolution2D) (None, 128, 32, 32)   295040      leakyrelu_10[0][0]               
____________________________________________________________________________________________________
batchnormalization_5 (BatchNormal(None, 128, 32, 32)   256         convolution2d_10[0][0]           
____________________________________________________________________________________________________
leakyrelu_11 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_5[0][0]       
____________________________________________________________________________________________________
convolution2d_11 (Convolution2D) (None, 64, 32, 32)    73792       leakyrelu_11[0][0]               
____________________________________________________________________________________________________
batchnormalization_6 (BatchNormal(None, 64, 32, 32)    128         convolution2d_11[0][0]           
____________________________________________________________________________________________________
leakyrelu_12 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_6[0][0]       
____________________________________________________________________________________________________
convolution2d_12 (Convolution2D) (None, 32, 32, 32)    18464       leakyrelu_12[0][0]               
____________________________________________________________________________________________________
batchnormalization_7 (BatchNormal(None, 32, 32, 32)    64          convolution2d_12[0][0]           
____________________________________________________________________________________________________
leakyrelu_13 (LeakyReLU)         (None, 32, 32, 32)    0           batchnormalization_7[0][0]       
____________________________________________________________________________________________________
convolution2d_13 (Convolution2D) (None, 2, 32, 32)     578         leakyrelu_13[0][0]               
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 2, 32, 32)     0           convolution2d_13[0][0]           
====================================================================================================
Total params: 1367650
____________________________________________________________________________________________________
None
----------------------------------
---GAN---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
None
----------------------------------
('Training with dataset based on class - ', 'automobile', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_5 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_4 (Sequential)        (None, 1)             0           lambda_2[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_14 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_3[0][0]      
____________________________________________________________________________________________________
leakyrelu_14 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_14[0][0]           
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_14[0][0]               
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 32, 8, 8)      4640        dropout_6[0][0]                  
____________________________________________________________________________________________________
leakyrelu_15 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_15[0][0]           
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_15[0][0]               
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 64, 4, 4)      18496       dropout_7[0][0]                  
____________________________________________________________________________________________________
leakyrelu_16 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_16[0][0]               
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 128, 2, 2)     73856       dropout_8[0][0]                  
____________________________________________________________________________________________________
leakyrelu_17 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_17[0][0]           
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_17[0][0]               
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 512)           0           dropout_9[0][0]                  
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 256)           131328      flatten_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_18 (LeakyReLU)         (None, 256)           0           dense_3[0][0]                    
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 256)           0           leakyrelu_18[0][0]               
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 1)             257         dropout_10[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.4596 ', 'GAN acc 0.8281', 'Discriminator loss 2.0424', 'Discriminator accuracy 0.5078', 'Total loss: 2.5020', 'for batch', 0)
('GAN loss 0.2683 ', 'GAN acc 0.9805', 'Discriminator loss 1.3188', 'Discriminator accuracy 0.4297', 'Total loss: 1.5871', 'for batch', 1)
('GAN loss 0.2084 ', 'GAN acc 0.9648', 'Discriminator loss 1.2226', 'Discriminator accuracy 0.4629', 'Total loss: 1.4310', 'for batch', 2)
('GAN loss 0.1733 ', 'GAN acc 1.0000', 'Discriminator loss 1.1515', 'Discriminator accuracy 0.4805', 'Total loss: 1.3248', 'for batch', 3)
('GAN loss 0.1893 ', 'GAN acc 0.9922', 'Discriminator loss 1.2777', 'Discriminator accuracy 0.4863', 'Total loss: 1.4670', 'for batch', 4)
('GAN loss 0.2559 ', 'GAN acc 0.9688', 'Discriminator loss 1.1689', 'Discriminator accuracy 0.4922', 'Total loss: 1.4248', 'for batch', 5)
('GAN loss 0.3440 ', 'GAN acc 0.9141', 'Discriminator loss 1.0397', 'Discriminator accuracy 0.5020', 'Total loss: 1.3837', 'for batch', 6)
('GAN loss 0.4484 ', 'GAN acc 0.8281', 'Discriminator loss 0.8704', 'Discriminator accuracy 0.5195', 'Total loss: 1.3188', 'for batch', 7)
('GAN loss 0.4575 ', 'GAN acc 0.8477', 'Discriminator loss 0.9207', 'Discriminator accuracy 0.5195', 'Total loss: 1.3781', 'for batch', 8)
('GAN loss 0.4291 ', 'GAN acc 0.8516', 'Discriminator loss 0.7900', 'Discriminator accuracy 0.5625', 'Total loss: 1.2190', 'for batch', 9)
('GAN loss 0.3575 ', 'GAN acc 0.9180', 'Discriminator loss 0.9965', 'Discriminator accuracy 0.5059', 'Total loss: 1.3540', 'for batch', 10)
('GAN loss 0.3566 ', 'GAN acc 0.9336', 'Discriminator loss 0.8499', 'Discriminator accuracy 0.5234', 'Total loss: 1.2065', 'for batch', 11)
('GAN loss 0.3888 ', 'GAN acc 0.9102', 'Discriminator loss 0.7989', 'Discriminator accuracy 0.5176', 'Total loss: 1.1877', 'for batch', 12)
('GAN loss 0.4699 ', 'GAN acc 0.7930', 'Discriminator loss 0.7771', 'Discriminator accuracy 0.5234', 'Total loss: 1.2470', 'for batch', 13)
('GAN loss 0.4867 ', 'GAN acc 0.8242', 'Discriminator loss 0.7665', 'Discriminator accuracy 0.5391', 'Total loss: 1.2533', 'for batch', 14)
('GAN loss 0.5409 ', 'GAN acc 0.7617', 'Discriminator loss 0.7105', 'Discriminator accuracy 0.5684', 'Total loss: 1.2515', 'for batch', 15)
('GAN loss 0.5978 ', 'GAN acc 0.6914', 'Discriminator loss 0.6324', 'Discriminator accuracy 0.5957', 'Total loss: 1.2302', 'for batch', 16)
('GAN loss 0.5953 ', 'GAN acc 0.7188', 'Discriminator loss 0.7998', 'Discriminator accuracy 0.6113', 'Total loss: 1.3951', 'for batch', 17)
('GAN loss 0.5372 ', 'GAN acc 0.7812', 'Discriminator loss 0.7267', 'Discriminator accuracy 0.5820', 'Total loss: 1.2639', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.97484457)
('DISCRIMINATOR_Imagem FAKE=', 0.56527644)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.712120')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.4856 ', 'GAN acc 0.8320', 'Discriminator loss 0.7348', 'Discriminator accuracy 0.5742', 'Total loss: 1.2205', 'for batch', 0)
('GAN loss 0.4576 ', 'GAN acc 0.8828', 'Discriminator loss 0.6522', 'Discriminator accuracy 0.5488', 'Total loss: 1.1098', 'for batch', 1)
('GAN loss 0.4636 ', 'GAN acc 0.8555', 'Discriminator loss 0.6724', 'Discriminator accuracy 0.5371', 'Total loss: 1.1361', 'for batch', 2)
('GAN loss 0.5098 ', 'GAN acc 0.7891', 'Discriminator loss 0.6216', 'Discriminator accuracy 0.5508', 'Total loss: 1.1314', 'for batch', 3)
('GAN loss 0.5245 ', 'GAN acc 0.7812', 'Discriminator loss 0.5847', 'Discriminator accuracy 0.5586', 'Total loss: 1.1092', 'for batch', 4)
('GAN loss 0.5140 ', 'GAN acc 0.8125', 'Discriminator loss 0.6223', 'Discriminator accuracy 0.5918', 'Total loss: 1.1363', 'for batch', 5)
('GAN loss 0.5014 ', 'GAN acc 0.8672', 'Discriminator loss 0.7026', 'Discriminator accuracy 0.5723', 'Total loss: 1.2040', 'for batch', 6)
('GAN loss 0.4939 ', 'GAN acc 0.8672', 'Discriminator loss 0.6152', 'Discriminator accuracy 0.5371', 'Total loss: 1.1092', 'for batch', 7)
('GAN loss 0.4909 ', 'GAN acc 0.8711', 'Discriminator loss 0.6000', 'Discriminator accuracy 0.5703', 'Total loss: 1.0909', 'for batch', 8)
('GAN loss 0.4898 ', 'GAN acc 0.8672', 'Discriminator loss 0.6169', 'Discriminator accuracy 0.5410', 'Total loss: 1.1067', 'for batch', 9)
('GAN loss 0.4384 ', 'GAN acc 0.8984', 'Discriminator loss 0.7233', 'Discriminator accuracy 0.5273', 'Total loss: 1.1617', 'for batch', 10)
('GAN loss 0.4481 ', 'GAN acc 0.8945', 'Discriminator loss 0.6419', 'Discriminator accuracy 0.5410', 'Total loss: 1.0900', 'for batch', 11)
('GAN loss 0.4842 ', 'GAN acc 0.8477', 'Discriminator loss 0.6305', 'Discriminator accuracy 0.5215', 'Total loss: 1.1147', 'for batch', 12)
('GAN loss 0.5230 ', 'GAN acc 0.7969', 'Discriminator loss 0.6346', 'Discriminator accuracy 0.5527', 'Total loss: 1.1577', 'for batch', 13)
('GAN loss 0.5650 ', 'GAN acc 0.7305', 'Discriminator loss 0.5710', 'Discriminator accuracy 0.5625', 'Total loss: 1.1359', 'for batch', 14)
('GAN loss 0.6294 ', 'GAN acc 0.6797', 'Discriminator loss 0.6426', 'Discriminator accuracy 0.5996', 'Total loss: 1.2720', 'for batch', 15)
('GAN loss 0.5954 ', 'GAN acc 0.7266', 'Discriminator loss 0.6042', 'Discriminator accuracy 0.5898', 'Total loss: 1.1995', 'for batch', 16)
('GAN loss 0.5625 ', 'GAN acc 0.7539', 'Discriminator loss 0.5906', 'Discriminator accuracy 0.6172', 'Total loss: 1.1531', 'for batch', 17)
('GAN loss 0.5507 ', 'GAN acc 0.7773', 'Discriminator loss 0.5487', 'Discriminator accuracy 0.5664', 'Total loss: 1.0994', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.97612286)
('DISCRIMINATOR_Imagem FAKE=', 0.54048955)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.584536')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5335 ', 'GAN acc 0.8008', 'Discriminator loss 0.6735', 'Discriminator accuracy 0.5625', 'Total loss: 1.2070', 'for batch', 0)
('GAN loss 0.5412 ', 'GAN acc 0.7891', 'Discriminator loss 0.5751', 'Discriminator accuracy 0.5645', 'Total loss: 1.1163', 'for batch', 1)
('GAN loss 0.5509 ', 'GAN acc 0.7773', 'Discriminator loss 0.5638', 'Discriminator accuracy 0.5840', 'Total loss: 1.1147', 'for batch', 2)
('GAN loss 0.5634 ', 'GAN acc 0.7422', 'Discriminator loss 0.5466', 'Discriminator accuracy 0.5918', 'Total loss: 1.1100', 'for batch', 3)
('GAN loss 0.5516 ', 'GAN acc 0.7930', 'Discriminator loss 0.4717', 'Discriminator accuracy 0.6191', 'Total loss: 1.0234', 'for batch', 4)
('GAN loss 0.5528 ', 'GAN acc 0.7969', 'Discriminator loss 0.5161', 'Discriminator accuracy 0.5879', 'Total loss: 1.0689', 'for batch', 5)
('GAN loss 0.5710 ', 'GAN acc 0.7539', 'Discriminator loss 0.5464', 'Discriminator accuracy 0.5879', 'Total loss: 1.1174', 'for batch', 6)
('GAN loss 0.5977 ', 'GAN acc 0.6914', 'Discriminator loss 0.4812', 'Discriminator accuracy 0.6035', 'Total loss: 1.0789', 'for batch', 7)
('GAN loss 0.5631 ', 'GAN acc 0.8008', 'Discriminator loss 0.4828', 'Discriminator accuracy 0.5996', 'Total loss: 1.0458', 'for batch', 8)
('GAN loss 0.5465 ', 'GAN acc 0.8164', 'Discriminator loss 0.5560', 'Discriminator accuracy 0.6191', 'Total loss: 1.1025', 'for batch', 9)
('GAN loss 0.5696 ', 'GAN acc 0.7539', 'Discriminator loss 0.4720', 'Discriminator accuracy 0.6074', 'Total loss: 1.0416', 'for batch', 10)
('GAN loss 0.5881 ', 'GAN acc 0.7227', 'Discriminator loss 0.4904', 'Discriminator accuracy 0.5996', 'Total loss: 1.0785',('yuv.max=', 253.886, 'yuv.min=', -5.8200899999999978)
('yuv.max=', 230.196, 'yuv.min=', -28.355559999999997)
('yuv.max=', 253.185, 'yuv.min=', -47.816670000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.325330000000001)
('yuv.max=', 249.08799999999999, 'yuv.min=', -22.014679999999998)
('yuv.max=', 241.357, 'yuv.min=', -47.03631)
('yuv.max=', 253.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 227.59099999999998, 'yuv.min=', -18.474360000000001)
('yuv.max=', 255.0, 'yuv.min=', -31.690339999999988)
('yuv.max=', 212.16399999999999, 'yuv.min=', -33.985430000000001)
('yuv.max=', 161.36699999999999, 'yuv.min=', -15.330179999999991)
('yuv.max=', 251.58699999999996, 'yuv.min=', -34.763840000000002)
('yuv.max=', 233.28899999999999, 'yuv.min=', -48.380409999999983)
('yuv.max=', 243.10299999999998, 'yuv.min=', -15.721879999999999)
('yuv.max=', 252.608, 'yuv.min=', -45.075509999999994)
('yuv.max=', 212.26299999999998, 'yuv.min=', -49.265559999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -16.71994999999999)
('yuv.max=', 199.32599999999999, 'yuv.min=', -19.750250000000001)
('yuv.max=', 244.84299999999999, 'yuv.min=', -15.285960000000006)
('yuv.max=', 255.0, 'yuv.min=', -93.135149999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -40.404840000000007)
('yuv.max=', 228.33500000000001, 'yuv.min=', -13.485179999999998)
('yuv.max=', 247.29400000000001, 'yuv.min=', -79.179959999999994)
('yuv.max=', 231.06899999999996, 'yuv.min=', -54.994779999999992)
('yuv.max=', 242.43000000000001, 'yuv.min=', -28.48544999999999)
('yuv.max=', 250.59300000000002, 'yuv.min=', -34.00177)
('yuv.max=', 200.86199999999999, 'yuv.min=', -10.840099999999996)
('yuv.max=', 242.55199999999999, 'yuv.min=', -46.635419999999982)
('yuv.max=', 194.815, 'yuv.min=', -30.37527)
('yuv.max=', 195.589, 'yuv.min=', -23.416449999999998)
('yuv.max=', 255.0, 'yuv.min=', -29.775210000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.122379999999993)
('yuv.max=', 194.81800000000001, 'yuv.min=', -19.041510000000002)
('yuv.max=', 237.815, 'yuv.min=', -27.73019)
('yuv.max=', 221.83199999999997, 'yuv.min=', -17.705110000000005)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.14499999999998, 'yuv.min=', -24.610369999999989)
('yuv.max=', 230.994, 'yuv.min=', -18.795409999999997)
('yuv.max=', 216.31999999999999, 'yuv.min=', -32.015679999999996)
('yuv.max=', 255.0, 'yuv.min=', -39.065769999999986)
('yuv.max=', 248.72199999999998, 'yuv.min=', -40.510729999999995)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 222.39699999999999, 'yuv.min=', -32.909680000000009)
('yuv.max=', 252.93999999999997, 'yuv.min=', -30.04993)
('yuv.max=', 234.70499999999998, 'yuv.min=', -51.225509999999986)
('yuv.max=', 236.36799999999999, 'yuv.min=', -27.300269999999998)
('yuv.max=', 210.03699999999998, 'yuv.min=', -83.491100000000017)
('yuv.max=', 246.01599999999999, 'yuv.min=', -9.0190699999999957)
('yuv.max=', 252.71799999999996, 'yuv.min=', -54.515470000000001)
('yuv.max=', 205.90399999999997, 'yuv.min=', -21.465239999999994)
('yuv.max=', 227.33799999999999, 'yuv.min=', -12.65522)
('yuv.max=', 255.0, 'yuv.min=', -0.61499999999999488)
('yuv.max=', 246.90299999999996, 'yuv.min=', -40.130199999999988)
('yuv.max=', 253.14199999999997, 'yuv.min=', -19.535169999999997)
('yuv.max=', 195.929, 'yuv.min=', -9.4100799999999918)
('yuv.max=', 166.94199999999998, 'yuv.min=', -11.710309999999996)
('yuv.max=', 241.78300000000002, 'yuv.min=', -12.655219999999993)
('yuv.max=', 211.70699999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 243.94799999999998, 'yuv.min=', -64.230149999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.92000000000002, 'yuv.min=', -32.375469999999993)
('yuv.max=', 254.886, 'yuv.min=', -17.056809999999999)
('yuv.max=', 136.84700000000001, 'yuv.min=', -17.771080000000008)
('yuv.max=', 232.85599999999997, 'yuv.min=', -23.673919999999999)
('yuv.max=', 242.07100000000003, 'yuv.min=', -95.805539999999979)
('yuv.max=', 255.0, 'yuv.min=', -20.575519999999997)
('yuv.max=', 171.85799999999998, 'yuv.min=', -9.2754099999999973)
('yuv.max=', 188.80599999999998, 'yuv.min=', -43.162559999999999)
('yuv.max=', 217.006, 'yuv.min=', -40.715319999999984)
('yuv.max=', 251.40199999999999, 'yuv.min=', -27.61524)
('yuv.max=', 193.46199999999999, 'yuv.min=', -17.6051)
('yuv.max=', 244.57599999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -75.965769999999992)
('yuv.max=', 247.62899999999999, 'yuv.min=', -20.806990000000003)
('yuv.max=', 238.40899999999999, 'yuv.min=', -15.47500999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.18199999999996, 'yuv.min=', -49.310379999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.294829999999997)
('yuv.max=', 240.28699999999998, 'yuv.min=', -56.120199999999997)
('yuv.max=', 249.61799999999999, 'yuv.min=', -56.315649999999991)
('yuv.max=', 244.39500000000001, 'yuv.min=', -54.300509999999989)
('yuv.max=', 220.31999999999999, 'yuv.min=', -16.530300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 216.50300000000001, 'yuv.min=', -109.62062999999999)
('yuv.max=', 238.71700000000001, 'yuv.min=', -25.695899999999998)
('yuv.max=', 193.77200000000002, 'yuv.min=', -11.787260000000007)
('yuv.max=', 216.60199999999998, 'yuv.min=', -24.942880000000002)
('yuv.max=', 240.87299999999999, 'yuv.min=', -83.801829999999995)
('yuv.max=', 249.929, 'yuv.min=', -15.615269999999988)
('yuv.max=', 254.58699999999999, 'yuv.min=', -40.278750000000009)
('yuv.max=', 252.54399999999998, 'yuv.min=', -30.205670000000001)
('yuv.max=', 240.81299999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 235.24099999999999, 'yuv.min=', -41.771799999999999)
('yuv.max=', 205.71600000000001, 'yuv.min=', -31.624779999999998)
('yuv.max=', 222.88399999999999, 'yuv.min=', -11.365459999999988)
('yuv.max=', 200.66199999999998, 'yuv.min=', -57.030659999999997)
('yuv.max=', 246.84099999999998, 'yuv.min=', -87.730039999999988)
('yuv.max=', 228.22799999999998, 'yuv.min=', -24.89546)
('yuv.max=', 255.0, 'yuv.min=', -33.11578999999999)
('yuv.max=', 225.44800000000001, 'yuv.min=', -21.524999999999991)
('yuv.max=', 234.70600000000002, 'yuv.min=', -53.330289999999991)
('yuv.max=', 253.95699999999997, 'yuv.min=', -13.115019999999991)
('yuv.max=', 185.78299999999999, 'yuv.min=', -17.121750000000002)
('yuv.max=', 168.45600000000002, 'yuv.min=', -17.230369999999986)
('yuv.max=', 245.53899999999999, 'yuv.min=', -81.045539999999988)
('yuv.max=', 219.37899999999999, 'yuv.min=', -29.655689999999989)
('yuv.max=', 254.18499999999997, 'yuv.min=', -41.571359999999999)
('yuv.max=', 193.53100000000001, 'yuv.min=', -13.000070000000003)
('yuv.max=', 218.79399999999998, 'yuv.min=', -22.93834)
('yuv.max=', 250.99999999999997, 'yuv.min=', -41.760239999999996)
('yuv.max=', 236.721, 'yuv.min=', -44.519120000000001)
('yuv.max=', 252.37800000000001, 'yuv.min=', -31.630049999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.687730000000002)
('yuv.max=', 187.93699999999998, 'yuv.min=', -21.290529999999997)
('yuv.max=', 252.91799999999998, 'yuv.min=', -18.505189999999995)
('yuv.max=', 190.06299999999999, 'yuv.min=', -29.515429999999995)
('yuv.max=', 236.29300000000001, 'yuv.min=', -56.415659999999988)
('yuv.max=', 247.67500000000001, 'yuv.min=', -33.859050000000003)
('yuv.max=', 253.59799999999998, 'yuv.min=', -30.320079999999997)
('yuv.max=', 249.392, 'yuv.min=', -29.635759999999998)
('yuv.max=', 220.94899999999998, 'yuv.min=', -48.07580999999999)
('yuv.max=', 255.0, 'yuv.min=', -54.791900000000012)
('yuv.max=', 251.29900000000001, 'yuv.min=', -12.78511)
('yuv.max=', 247.626, 'yuv.min=', -38.311530000000005)
('yuv.max=', 238.327, 'yuv.min=', -26.926470000000002)
('yuv.max=', 198.15899999999999, 'yuv.min=', -86.01415999999999)
('yuv.max=', 172.339, 'yuv.min=', -38.38064)
('yuv.max=', 246.249, 'yuv.min=', -24.095379999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.970929999999996)
('yuv.max=', 223.73999999999998, 'yuv.min=', -15.60033)
('yuv.max=', 255.0, 'yuv.min=', -30.845439999999993)
('yuv.max=', 244.98899999999998, 'yuv.min=', -29.025509999999997)
('yuv.max=', 233.03999999999999, 'yuv.min=', -40.430229999999995)
('yuv.max=', 253.505, 'yuv.min=', -23.999939999999995)
('yuv.max=', 251.05999999999997, 'yuv.min=', -34.790649999999999)
('yuv.max=', 235.32999999999998, 'yuv.min=', -33.613659999999996)
('yuv.max=', 230.77399999999997, 'yuv.min=', -31.685769999999994)
('yuv.max=', 255.0, 'yuv.min=', -49.225309999999986)
('yuv.max=', 186.59100000000001, 'yuv.min=', -11.95515)
('yuv.max=', 255.0, 'yuv.min=', -32.975530000000006)
('yuv.max=', 255.0, 'yuv.min=', -8.7354099999999981)
('yuv.max=', 236.34799999999996, 'yuv.min=', -27.260019999999994)
('yuv.max=', 221.56800000000001, 'yuv.min=', -66.755709999999993)
('yuv.max=', 201.524, 'yuv.min=', -92.000589999999988)
('yuv.max=', 237.55799999999999, 'yuv.min=', -27.660060000000001)
('yuv.max=', 241.92899999999997, 'yuv.min=', -21.830789999999993)
('yuv.max=', 248.73199999999997, 'yuv.min=', -22.850439999999992)
('yuv.max=', 216.495, 'yuv.min=', -21.590879999999999)
('yuv.max=', 243.929, 'yuv.min=', -41.345259999999996)
('yuv.max=', 231.41299999999998, 'yuv.min=', -20.02028)
('yuv.max=', 251.49000000000001, 'yuv.min=', -51.895699999999991)
('yuv.max=', 235.786, 'yuv.min=', -43.930409999999995)
('yuv.max=', 249.142, 'yuv.min=', -5.7350199999999933)
('yuv.max=', 252.75, 'yuv.min=', -35.314209999999996)
('yuv.max=', 205.631, 'yuv.min=', -27.885389999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -50.980669999999989)
('yuv.max=', 207.06, 'yuv.min=', -17.675230000000003)
('yuv.max=', 247.54400000000001, 'yuv.min=', -13.00006999999999)
('yuv.max=', 213.96499999999997, 'yuv.min=', -27.885389999999983)
('yuv.max=', 252.25599999999997, 'yuv.min=', -54.705119999999994)
('yuv.max=', 247.64100000000002, 'yuv.min=', -22.654989999999998)
('yuv.max=', 232.017, 'yuv.min=', -30.915189999999996)
('yuv.max=', 206.852, 'yuv.min=', -5.9051599999999951)
('yuv.max=', 239.99499999999998, 'yuv.min=', -27.685369999999995)
('yuv.max=', 251.262, 'yuv.min=', -33.220370000000003)
('yuv.max=', 243.95999999999998, 'yuv.min=', -43.900700000000001)
('yuv.max=', 251.46699999999998, 'yuv.min=', -21.250279999999993)
('yuv.max=', 229.94999999999999, 'yuv.min=', -27.125559999999989)
('yuv.max=', 255.0, 'yuv.min=', -30.549979999999994)
('yuv.max=', 208.161, 'yuv.min=', -46.360699999999994)
('yuv.max=', 214.96099999999998, 'yuv.min=', -22.48027999999999)
('yuv.max=', 242.78699999999998, 'yuv.min=', -89.240559999999988)
('yuv.max=', 241.49599999999998, 'yuv.min=', -26.819729999999996)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 229.07499999999996, 'yuv.min=', -73.565529999999995)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.35899999999998, 'yuv.min=', -23.711399999999998)
('yuv.max=', 243.929, 'yuv.min=', -16.015309999999999)
('yuv.max=', 226.26099999999997, 'yuv.min=', -47.950489999999995)
('yuv.max=', 213.697, 'yuv.min=', -36.265489999999993)
('yuv.max=', 242.34200000000001, 'yuv.min=', -27.985399999999991)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.53399999999999, 'yuv.min=', -12.974440000000001)
('yuv.max=', 230.82599999999999, 'yuv.min=', -17.503300000000003)
('yuv.max=', 163.93299999999999, 'yuv.min=', -15.433319999999998)
('yuv.max=', 249.452, 'yuv.min=', -19.798190000000005)
('yuv.max=', 227.69300000000001, 'yuv.min=', -22.880319999999987)
('yuv.max=', 243.72899999999998, 'yuv.min=', -25.813940000000002)
('yuv.max=', 232.98199999999997, 'yuv.min=', -61.265529999999984)
('yuv.max=', 211.0, 'yuv.min=', -13.68319000000001)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.90099999999998, 'yuv.min=', -46.758250000000004)
('yuv.max=', 251.74000000000001, 'yuv.min=', -21.274340000000016)
('yuv.max=', 219.90599999999998, 'yuv.min=', -6.0051699999999926)
('yuv.max=', 214.20400000000001, 'yuv.min=', -74.14922)
('yuv.max=', 204.238, 'yuv.min=', -97.017910000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.04199999999997, 'yuv.min=', -25.510459999999998)
('yuv.max=', 232.691, 'yuv.min=', -17.513830000000013)
('yuv.max=', 254.77200000000002, 'yuv.min=', -34.720519999999993)
('yuv.max=', 236.94599999999997, 'yuv.min=', -18.001010000000001)
('yuv.max=', 214.36699999999999, 'yuv.min=', -44.205299999999994)
('yuv.max=', 213.34999999999999, 'yuv.min=', -46.68665)
('yuv.max=', 218.67799999999997, 'yuv.min=', -57.254730000000009)
('yuv.max=', 221.79999999999998, 'yuv.min=', -43.375339999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.19499999999999, 'yuv.min=', -81.090360000000004)
('yuv.max=', 185.71600000000001, 'yuv.min=', -15.445129999999992)
('yuv.max=', 239.36799999999997, 'yuv.min=', -40.260090000000005)
('yuv.max=', 205.83199999999999, 'yuv.min=', -85.158419999999992)
('yuv.max=', 230.804, 'yuv.min=', -30.130429999999993)
('yuv.max=', 191.19999999999999, 'yuv.min=', -11.955149999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 241.74800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 250.30399999999997, 'yuv.min=', -21.650319999999997)
('yuv.max=', 243.25599999999997, 'yuv.min=', -17.30506999999999)
('yuv.max=', 222.208, 'yuv.min=', -36.255119999999991)
('yuv.max=', 229.31399999999999, 'yuv.min=', -33.390509999999992)
('yuv.max=', 208.88, 'yuv.min=', -29.200459999999993)
('yuv.max=', 246.72300000000001, 'yuv.min=', -27.355460000000001)
('yuv.max=', 215.77199999999999, 'yuv.min=', -39.968760000000003)
('yuv.max=', 241.61500000000001, 'yuv.min=', -21.735389999999995)
('yuv.max=', 240.39099999999999, 'yuv.min=', -23.106750000000002)
('yuv.max=', 240.11599999999996, 'yuv.min=', -73.032489999999996)
('yuv.max=', 245.02000000000001, 'yuv.min=', -44.360499999999995)
('yuv.max=', 211.58699999999999, 'yuv.min=', -31.445499999999996)
('yuv.max=', 249.66300000000001, 'yuv.min=', -52.033700000000003)
('yuv.max=', 245.21499999999997, 'yuv.min=', -28.141140000000007)
('yuv.max=', 155.37199999999999, 'yuv.min=', -31.6007)
('yuv.max=', 225.86199999999999, 'yuv.min=', -35.777110000000008)
('yuv.max=', 254.11399999999998, 'yuv.min=', -9.7354199999999906)
('yuv.max=', 252.29899999999998, 'yuv.min=', -25.955319999999993)
('yuv.max=', 231.48799999999997, 'yuv.min=', -50.431820000000016)
('yuv.max=', 255.0, 'yuv.min=', -16.253850000000003)
('yuv.max=', 245.46600000000001, 'yuv.min=', -21.110019999999977)
('yuv.max=', 255.0, 'yuv.min=', -13.270219999999998)
('yuv.max=', 240.71199999999999, 'yuv.min=', -91.915520000000001)
('yuv.max=', 244.13800000000001, 'yuv.min=', -26.270289999999989)
('yuv.max=', 229.10900000000001, 'yuv.min=', -24.163150000000002)
('yuv.max=', 248.21100000000001, 'yuv.min=', -29.4453)
('yuv.max=', 224.11299999999997, 'yuv.min=', -42.96035999999998)
('yuv.max=', 249.31899999999999, 'yuv.min=', -34.410119999999992)
('yuv.max=', 198.71199999999999, 'yuv.min=', -86.134150000000005)
('yuv.max=', 255.0, 'yuv.min=', -27.285329999999995)
('yuv.max=', 228.58199999999999, 'yuv.min=', -35.425159999999984)
('yuv.max=', 249.07099999999997, 'yuv.min=', -7.5352000000000032)
('yuv.max=', 241.47300000000001, 'yuv.min=', -49.178520000000006)
('yuv.max=', 237.70099999999999, 'yuv.min=', -20.201050000000002)
('yuv.max=', 234.78300000000002, 'yuv.min=', -13.070199999999993)
('yuv.max=', 207.93799999999999, 'yuv.min=', -27.900329999999993)
('yuv.max=', 242.05399999999997, 'yuv.min=', -16.420120000000001)
('yuv.max=', 231.316, 'yuv.min=', -25.740359999999995)
('yuv.max=', 228.94499999999999, 'yuv.min=', -31.466140000000003)
('yuv.max=', 218.30600000000001, 'yuv.min=', -59.044569999999993)
('yuv.max=', 250.71200000000002, 'yuv.min=', -48.980469999999997)
('yuv.max=', 252.72899999999998, 'yuv.min=', -15.875049999999984)
('yuv.max=', 234.11799999999999, 'yuv.min=', -24.995469999999997)
('yuv.max=', 255.0, 'yuv.min=', -67.038419999999988)
('yuv.max=', 215.34, 'yuv.min=', -7.0202099999999916)
('yuv.max=', 216.19299999999998, 'yuv.min=', -22.635479999999987)
('yuv.max=', 229.25999999999999, 'yuv.min=', -43.975399999999993)
('yuv.max=', 231.10999999999999, 'yuv.min=', -75.135900000000007)
('yuv.max=', 241.73000000000002, 'yuv.min=', -61.21235999999999)
('yuv.max=', 177.54499999999999, 'yuv.min=', -49.910440000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.830649999999999)
('yuv.max=', 247.41200000000001, 'yuv.min=', -49.625349999999997)
('yuv.max=', 235.07999999999998, 'yuv.min=', -67.069460000000007)
('yuv.max=', 209.595, 'yuv.min=', -38.680669999999992)
('yuv.max=', 242.82900000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 190.07799999999997, 'yuv.min=', -37.680569999999982)
('yuv.max=', 251.29799999999997, 'yuv.min=', -55.292219999999993)
('yuv.max=', 190.98599999999999, 'yuv.min=', -17.128830000000001)
('yuv.max=', 254.77200000000002, 'yuv.min=', -32.075439999999993)
('yuv.max=', 238.114, 'yuv.min=', -20.921589999999998)
('yuv.max=', 252.79299999999998, 'yuv.min=', -45.160579999999996)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.1481000000000137)
('yuv.max=', 246.364, 'yuv.min=', -33.895129999999995)
('yuv.max=', 204.33199999999999, 'yuv.min=', -27.785380000000004)
('yuv.max=', 234.24200000000002, 'yuv.min=', -46.935449999999989)
('yuv.max=', 255.0, 'yuv.min=', -45.930779999999999)
('yuv.max=', 216.28700000000001, 'yuv.min=', -35.120559999999998)
('yuv.max=', 205.84299999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 210.77199999999999, 'yuv.min=', -16.887889999999999)
('yuv.max=', 225.91499999999999, 'yuv.min=', -6.7173900000000089)
('yuv.max=', 205.63799999999998, 'yuv.min=', -20.173439999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.065989999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -98.295419999999993)
('yuv.max=', 247.52499999999998, 'yuv.min=', -44.505330000000001)
('yuv.max=', 253.23899999999998, 'yuv.min=', -19.366670000000003)
('yuv.max=', 244.239, 'yuv.min=', -24.810389999999998)
('yuv.max=', 250.35500000000002, 'yuv.min=', -30.413669999999996)
('yuv.max=', 249.744, 'yuv.min=', -28.530269999999991)
('yuv.max=', 204.33499999999998, 'yuv.min=', -23.754700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.51361)
('yuv.max=', 232.78900000000002, 'yuv.min=', -8.3249099999999991)
('yuv.max=', 211.61899999999997, 'yuv.min=', -20.035219999999995)
('yuv.max=', 198.12399999999997, 'yuv.min=', -39.495689999999996)
('yuv.max=', 229.45199999999997, 'yuv.min=', -25.810489999999994)
('yuv.max=', 174.15200000000002, 'yuv.min=', -3.4302199999999949)
('yuv.max=', 247.16799999999998, 'yuv.min=', -42.330419999999989)
('yuv.max=', 255.0, 'yuv.min=', -36.233760000000004)
('yuv.max=', 237.62199999999999, 'yuv.min=', -37.670199999999994)
('yuv.max=', 154.90199999999999, 'yuv.min=', -35.850509999999986)
('yuv.max=', 250.19499999999999, 'yuv.min=', -18.545439999999992)
('yuv.max=', 235.25299999999999, 'yuv.min=', -68.145479999999992)
('yuv.max=', 228.35300000000001, 'yuv.min=', -19.319379999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.130259999999996)
('yuv.max=', 251.95699999999997, 'yuv.min=', -51.495659999999987)
('yuv.max=', 237.78899999999999, 'yuv.min=', -14.534009999999995)
('yuv.max=', 254.41299999999995, 'yuv.min=', -96.669579999999996)
('yuv.max=', 245.43699999999998, 'yuv.min=', -19.6053)
('yuv.max=', 222.07900000000001, 'yuv.min=', -29.470609999999994)
('yuv.max=', 251.011, 'yuv.min=', -23.780409999999989)
('yuv.max=', 240.92899999999997, 'yuv.min=', -55.364620000000002)
('yuv.max=', 179.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.55199999999999, 'yuv.min=', -25.610469999999982)
('yuv.max=', 235.93300000000002, 'yuv.min=', -17.520029999999998)
('yuv.max=', 246.99299999999997, 'yuv.min=', -18.47531)
('yuv.max=', 229.87499999999997, 'yuv.min=', -12.370129999999989)
('yuv.max=', 234.80099999999999, 'yuv.min=', -37.122739999999993)
('yuv.max=', 236.488, 'yuv.min=', -24.10446)
('yuv.max=', 228.69399999999999, 'yuv.min=', -47.030889999999999)
('yuv.max=', 238.56799999999998, 'yuv.min=', -13.070199999999993)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.015109999999996)
('yuv.max=', 240.98099999999999, 'yuv.min=', -22.250610000000002)
('yuv.max=', 249.33699999999999, 'yuv.min=', -67.659299999999988)
('yuv.max=', 216.786, 'yuv.min=', -52.400319999999994)
('yuv.max=', 226.26400000000001, 'yuv.min=', -16.543990000000004)
('yuv.max=', 243.77699999999999, 'yuv.min=', -23.495319999999992)
('yuv.max=', 162.036, 'yuv.min=', -22.565349999999995)
('yuv.max=', 229.49099999999999, 'yuv.min=', -36.240179999999995)
('yuv.max=', 229.113, 'yuv.min=', -26.455369999999995)
('yuv.max=', 243.39099999999999, 'yuv.min=', -57.960629999999988)
('yuv.max=', 237.60899999999998, 'yuv.min=', -47.495259999999995)
('yuv.max=', 253.16300000000001, 'yuv.min=', -17.50386)
('yuv.max=', 249.77199999999999, 'yuv.min=', -10.999870000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -42.78564999999999)
('yuv.max=', 246.69399999999996, 'yuv.min=', -66.34529999999998)
('yuv.max=', 241.869, 'yuv.min=', -10.05461)
('yuv.max=', 250.94000000000003, 'yuv.min=', -28.986360000000005)
('yuv.max=', 242.64699999999999, 'yuv.min=', -29.875219999999992)
('yuv.max=', 247.97, 'yuv.min=', -15.815289999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.94799999999998, 'yuv.min=', -26.455369999999998)
('yuv.max=', 241.84300000000002, 'yuv.min=', -31.067529999999998)
('yuv.max=', 208.00700000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 255.0, 'yuv.min=', -30.098469999999999)
('yuv.max=', 250.114, 'yuv.min=', -31.070769999999996)
('yuv.max=', 239.02699999999999, 'yuv.min=', -23.61027)
('yuv.max=', 255.0, 'yuv.min=', -73.577730000000003)
('yuv.max=', 255.0, 'yuv.min=', -12.221959999999999)
('yuv.max=', 128.02599999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 247.57999999999998, 'yuv.min=', -24.395409999999995)
('yuv.max=', 222.76499999999999, 'yuv.min=', -30.850870000000004)
('yuv.max=', 237.95499999999998, 'yuv.min=', -52.285369999999993)
('yuv.max=', 233.131, 'yuv.min=', -18.615229999999997)
('yuv.max=', 237.69299999999996, 'yuv.min=', -23.755099999999988)
('yuv.max=', 234.071, 'yuv.min=', -24.752209999999994)
('yuv.max=', 199.959, 'yuv.min=', -21.165209999999984)
('yuv.max=', 253.0, 'yuv.min=', -24.605090000000001)
('yuv.max=', 246.90699999999998, 'yuv.min=', -28.660159999999991)
('yuv.max=', 246.31, 'yuv.min=', -22.725119999999997)
('yuv.max=', 222.12799999999999, 'yuv.min=', -30.578519999999997)
('yuv.max=', 170.042, 'yuv.min=', -56.169580000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.740089999999995)
('yuv.max=', 255.0, 'yuv.min=', -16.590059999999998)
('yuv.max=', 249.316, 'yuv.min=', -50.250720000000001)
('yuv.max=', 226.18900000000002, 'yuv.min=', -39.374899999999997)
('yuv.max=', 186.27099999999999, 'yuv.min=', -32.645619999999994)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.365929999999995)
('yuv.max=', 254.886, 'yuv.min=', -23.17633)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.814450000000001)
('yuv.max=', 211.99099999999999, 'yuv.min=', -28.115289999999998)
('yuv.max=', 214.85399999999998, 'yuv.min=', -52.795789999999997)
('yuv.max=', 225.899, 'yuv.min=', -40.485419999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -6.8385600000000011)
('yuv.max=', 245.64699999999996, 'yuv.min=', -21.824849999999998)
('yuv.max=', 249.35899999999998, 'yuv.min=', -29.130329999999983)
('yuv.max=', 237.20000000000002, 'yuv.min=', -47.490400000000001)
('yuv.max=', 239.56900000000002, 'yuv.min=', -43.160379999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -41.478180000000002)
('yuv.max=', 209.035, 'yuv.min=', -33.850309999999993)
('yuv.max=', 232.0, 'yuv.min=', -36.698350000000005)
('yuv.max=', 239.98899999999998, 'yuv.min=', -39.970429999999986)
('yuv.max=', 244.76500000000001, 'yuv.min=', -35.690739999999991)
('yuv.max=', 238.42400000000001, 'yuv.min=', -36.52984)
('yuv.max=', 179.48499999999999, 'yuv.min=', -28.970559999999995)
('yuv.max=', 184.37100000000001, 'yuv.min=', -29.877760000000006)
('yuv.max=', 248.06399999999999, 'yuv.min=', -20.920369999999991)
('yuv.max=', 254.11399999999998, 'yuv.min=', -26.195510000000006)
('yuv.max=', 232.833, 'yuv.min=', -6.4235900000000044)
('yuv.max=', 251.91799999999998, 'yuv.min=', -60.075779999999995)
('yuv.max=', 242.999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 236.78899999999999, 'yuv.min=', -18.620140000000003)
('yuv.max=', 192.13800000000001, 'yuv.min=', -25.195489999999999)
('yuv.max=', 196.535, 'yuv.min=', -47.375739999999993)
('yuv.max=', 247.56799999999998, 'yuv.min=', -38.083129999999997)
('yuv.max=', 248.77199999999999, 'yuv.min=', -57.160550000000001)
('yuv.max=', 174.72699999999998, 'yuv.min=', -26.240410000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 193.10599999999999, 'yuv.min=', -24.525299999999998)
('yuv.max=', 207.78000000000003, 'yuv.min=', -27.625609999999998)
('yuv.max=', 255.0, 'yuv.min=', -19.224710000000005)
('yuv.max=', 252.03800000000001, 'yuv.min=', -59.060739999999996)
('yuv.max=', 162.35599999999999, 'yuv.min=', -36.938569999999999)
('yuv.max=', 205.08099999999999, 'yuv.min=', -42.230409999999992)
('yuv.max=', 227.34099999999998, 'yuv.min=', -18.810869999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.403250000000007)
('yuv.max=', 241.96899999999999, 'yuv.min=', -65.56595999999999)
('yuv.max=', 238.708, 'yuv.min=', -13.874269999999999)
('yuv.max=', 219.529, 'yuv.min=', -8.9502799999999887)
('yuv.max=', 217.16999999999999, 'yuv.min=', -21.605499999999989)
('yuv.max=', 241.63, 'yuv.min=', -27.585359999999998)
('yuv.max=', 200.88499999999999, 'yuv.min=', -19.350089999999998)
('yuv.max=', 245.124, 'yuv.min=', -117.26040999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -18.915329999999997)
('yuv.max=', 245.57499999999999, 'yuv.min=', -76.806100000000001)
('yuv.max=', 248.64700000000002, 'yuv.min=', -93.140950000000004)
('yuv.max=', 255.0, 'yuv.min=', -61.762990000000002)
('yuv.max=', 246.75700000000001, 'yuv.min=', -15.915299999999991)
('yuv.max=', 253.47299999999998, 'yuv.min=', -28.425689999999996)
('yuv.max=', 211.72399999999999, 'yuv.min=', -35.739530000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.225299999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.617400000000004)
('yuv.max=', 245.733, 'yuv.min=', -48.495359999999991)
('yuv.max=', 85.770999999999987, 'yuv.min=', -24.640249999999995)
('yuv.max=', 232.148, 'yuv.min=', -73.746790000000004)
('yuv.max=', 252.33699999999999, 'yuv.min=', -56.660499999999992)
('yuv.max=', 184.80799999999999, 'yuv.min=', -30.545409999999997)
('yuv.max=', 244.98899999999998, 'yuv.min=', -13.514610000000005)
('yuv.max=', 254.47300000000001, 'yuv.min=', -50.510499999999993)
('yuv.max=', 248.559, 'yuv.min=', -22.735489999999999)
('yuv.max=', 255.0, 'yuv.min=', -26.426010000000002)
('yuv.max=', 196.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 218.83999999999997, 'yuv.min=', -88.140180000000015)
('yuv.max=', 254.43000000000001, 'yuv.min=', -15.915299999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -4.6742299999999943)
('yuv.max=', 240.12499999999997, 'yuv.min=', -22.965170000000004)
('yuv.max=', 252.58699999999999, 'yuv.min=', -31.505259999999996)
('yuv.max=', 227.203, 'yuv.min=', -24.440230000000003)
('yuv.max=', 252.90699999999998, 'yuv.min=', -64.415229999999994)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -16.992329999999999)
('yuv.max=', 252.90699999999998, 'yuv.min=', -21.920469999999991)
('yuv.max=', 252.42999999999998, 'yuv.min=', -19.089550000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.152270000000001)
('yuv.max=', 244.125, 'yuv.min=', -63.702930000000002)
('yuv.max=', 224.501, 'yuv.min=', -26.185219999999994)
('yuv.max=', 248.91800000000001, 'yuv.min=', -42.705149999999989)
('yuv.max=', 242.626, 'yuv.min=', -33.635350000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.695439999999991)
('yuv.max=', 218.738, 'yuv.min=', -27.045059999999989)
('yuv.max=', 240.72299999999996, 'yuv.min=', -35.450950000000006)
('yuv.max=', 215.86399999999998, 'yuv.min=', -18.190219999999989)
('yuv.max=', 255.0, 'yuv.min=', -35.804220000000008)
('yuv.max=', 255.0, 'yuv.min=', -9.9503799999999956)
('yuv.max=', 248.52599999999998, 'yuv.min=', -45.805459999999982)
('yuv.max=', 183.03700000000001, 'yuv.min=', -31.760469999999987)
('yuv.max=', 241.92499999999998, 'yuv.min=', -77.31528999999999)
('yuv.max=', 200.10299999999998, 'yuv.min=', -25.170180000000002)
('yuv.max=', 215.81100000000001, 'yuv.min=', -71.294309999999996)
('yuv.max=', 254.70099999999999, 'yuv.min=', -15.600329999999994)
('yuv.max=', 247.976, 'yuv.min=', -68.590339999999983)
('yuv.max=', 255.0, 'yuv.min=', -10.461490000000012)
('yuv.max=', 249.267, 'yuv.min=', -35.684110000000011)
('yuv.max=', 219.53299999999999, 'yuv.min=', -59.180259999999997)
('yuv.max=', 245.13099999999997, 'yuv.min=', -7.6098999999999979)
('yuv.max=', 205.24099999999999, 'yuv.min=', -79.741560000000007)
('yuv.max=', 210.773, 'yuv.min=', -33.69511)
('yuv.max=', 255.0, 'yuv.min=', -45.420359999999988)
('yuv.max=', 243.07099999999997, 'yuv.min=', -80.07368000000001)
('yuv.max=', 221.96499999999997, 'yuv.min=', -14.592910000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 213.91799999999998, 'yuv.min=', -44.339750000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.479900000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -40.100319999999982)
('yuv.max=', 255.0, 'yuv.min=', -37.225339999999996)
('yuv.max=', 233.916, 'yuv.min=', -36.295369999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.6949699999999872)
('yuv.max=', 253.404, 'yuv.min=', -45.101480000000002)
('yuv.max=', 243.09899999999999, 'yuv.min=', -19.635120000000004)
('yuv.max=', 228.93499999999997, 'yuv.min=', -27.911809999999996)
('yuv.max=', 224.404, 'yuv.min=', -29.542439999999999)
('yuv.max=', 202.13300000000001, 'yuv.min=', -31.690339999999999)
('yuv.max=', 223.89299999999997, 'yuv.min=', -21.06063)
('yuv.max=', 224.89600000000002, 'yuv.min=', -67.960399999999993)
('yuv.max=', 248.94199999999998, 'yuv.min=', -29.160209999999999)
('yuv.max=', 220.59700000000001, 'yuv.min=', -23.390909999999998)
('yuv.max=', 237.08100000000002, 'yuv.min=', -34.705579999999998)
('yuv.max=', 202.114, 'yuv.min=', -12.795479999999984)
('yuv.max=', 125.0, 'yuv.min=', -2.6645352591003757e-15)
('yuv.max=', 255.0, 'yuv.min=', -38.865750000000006)
('yuv.max=', 250.81399999999999, 'yuv.min=', -96.790699999999987)
('yuv.max=', 211.75699999999998, 'yuv.min=', -69.990479999999991)
('yuv.max=', 206.97899999999998, 'yuv.min=', -19.805319999999995)
('yuv.max=', 229.78299999999999, 'yuv.min=', -24.110319999999994)
('yuv.max=', 249.17399999999998, 'yuv.min=', -41.047290000000004)
('yuv.max=', 246.45599999999999, 'yuv.min=', -9.0158400000000007)
('yuv.max=', 233.13899999999998, 'yuv.min=', -40.380839999999992)
('yuv.max=', 254.70099999999999, 'yuv.min=', -52.530209999999983)
('yuv.max=', 237.23599999999996, 'yuv.min=', -11.340150000000001)
('yuv.max=', 249.10300000000001, 'yuv.min=', -38.625479999999996)
('yuv.max=', 253.0, 'yuv.min=', -13.155269999999996)
('yuv.max=', 251.79299999999998, 'yuv.min=', -26.010509999999996)
('yuv.max=', 244.97800000000001, 'yuv.min=', -74.650700000000001)
('yuv.max=', 255.0, 'yuv.min=', -2.6749600000000022)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 206.60599999999999, 'yuv.min=', -30.200600000000001)
('yuv.max=', 249.995, 'yuv.min=', -59.790689999999991)
('yuv.max=', 238.95699999999997, 'yuv.min=', -10.555009999999992)
('yuv.max=', 220.91399999999999, 'yuv.min=', -70.852810000000005)
('yuv.max=', 230.80799999999999, 'yuv.min=', -20.501819999999999)
('yuv.max=', 249.02799999999999, 'yuv.min=', -61.795459999999991)
('yuv.max=', 237.62299999999999, 'yuv.min=', -35.065369999999987)
('yuv.max=', 253.20599999999999, 'yuv.min=', -23.565449999999981)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -54.190129999999996)
('yuv.max=', 251.066, 'yuv.min=', -109.19527999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.565349999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.285059999999991)
('yuv.max=', 252.33099999999999, 'yuv.min=', -15.564260000000001)
('yuv.max=', 198.37599999999998, 'yuv.min=', -24.835699999999996)
('yuv.max=', 255.0, 'yuv.min=', -41.300439999999981)
('yuv.max=', 201.084, 'yuv.min=', -22.13999999999999)
('yuv.max=', 187.34399999999999, 'yuv.min=', -11.410279999999993)
('yuv.max=', 108.444, 'yuv.min=', -23.280359999999995)
('yuv.max=', 236.39400000000001, 'yuv.min=', -43.635119999999986)
('yuv.max=', 230.28999999999999, 'yuv.min=', -47.730959999999996)
('yuv.max=', 251.98499999999999, 'yuv.min=', -41.14067)
('yuv.max=', 219.05100000000002, 'yuv.min=', -17.875249999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.411179999999998)
('yuv.max=', 210.595, 'yuv.min=', -20.505389999999988)
('yuv.max=', 217.417, 'yuv.min=', -23.95055)
('yuv.max=', 255.0, 'yuv.min=', -23.225169999999999)
('yuv.max=', 187.149, 'yuv.min=', -76.569299999999998)
('yuv.max=', 233.25900000000001, 'yuv.min=', -9.4749099999999942)
('yuv.max=', 220.22200000000001, 'yuv.min=', -27.242040000000003)
('yuv.max=', 244.32699999999997, 'yuv.min=', -6.9967399999999991)
('yuv.max=', 241.02099999999999, 'yuv.min=', -43.837469999999996)
('yuv.max=', 254.40199999999999, 'yuv.min=', -11.025179999999999)
('yuv.max=', 252.679, 'yuv.min=', -46.435399999999994)
('yuv.max=', 248.52899999999997, 'yuv.min=', -49.21036999999999)
('yuv.max=', 248.35900000000001, 'yuv.min=', -16.345219999999994)
('yuv.max=', 238.54399999999995, 'yuv.min=', -13.185149999999986)
('yuv.max=', 242.435, 'yuv.min=', -12.670190000000002)
('yuv.max=', 212.256, 'yuv.min=', -8.6636600000000001)
('yuv.max=', 255.0, 'yuv.min=', -41.945319999999981)
('yuv.max=', 255.0, 'yuv.min=', -61.626080000000009)
('yuv.max=', 252.761, 'yuv.min=', -79.169249999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.311610000000002)
('yuv.max=', 238.798, 'yuv.min=', -11.803229999999999)
('yuv.max=', 175.99999999999997, 'yuv.min=', -6.7650000000000006)
('yuv.max=', 254.40199999999999, 'yuv.min=', -22.180249999999997)
('yuv.max=', 167.94499999999999, 'yuv.min=', -14.371259999999998)
('yuv.max=', 198.61600000000001, 'yuv.min=', -43.305209999999988)
('yuv.max=', 254.65800000000002, 'yuv.min=', -68.945559999999986)
('yuv.max=', 213.66200000000001, 'yuv.min=', -24.998119999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.223240000000004)
('yuv.max=', 255.0, 'yuv.min=', -47.495320000000007)
('yuv.max=', 255.0, 'yuv.min=', -34.510130000000004)
('yuv.max=', 253.333, 'yuv.min=', -26.800219999999996)
('yuv.max=', 202.339, 'yuv.min=', -22.910199999999993)
('yuv.max=', 243.98299999999998, 'yuv.min=', -33.880189999999999)
('yuv.max=', 238.47299999999998, 'yuv.min=', -37.580559999999991)
('yuv.max=', 229.0, 'yuv.min=', -2.974989999999984)
('yuv.max=', 250.87899999999996, 'yuv.min=', -19.640800000000006)
('yuv.max=', 242.61299999999997, 'yuv.min=', -20.696290000000005)
('yuv.max=', 237.68099999999998, 'yuv.min=', -23.825230000000001)
('yuv.max=', 233.65800000000002, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 228.71899999999999, 'yuv.min=', -60.520639999999986)
('yuv.max=', 252.065, 'yuv.min=', -15.08492)
('yuv.max=', 247.62499999999997, 'yuv.min=', -22.82744000000001)
('yuv.max=', 210.87099999999998, 'yuv.min=', -19.064999999999994)
('yuv.max=', 203.333, 'yuv.min=', -27.43015999999999)
('yuv.max=', 254.886, 'yuv.min=', -38.415000000000006)
('yuv.max=', 197.91800000000001, 'yuv.min=', -10.50003000000001)
('yuv.max=', 244.762, 'yuv.min=', -15.445129999999995)
('yuv.max=', 231.15299999999996, 'yuv.min=', -44.885859999999994)
('yuv.max=', 164.035, 'yuv.min=', -20.680990000000001)
('yuv.max=', 250.46199999999996, 'yuv.min=', -66.58556999999999)
('yuv.max=', 208.38999999999999, 'yuv.min=', -44.190359999999998)
('yuv.max=', 249.744, 'yuv.min=', -38.280629999999995)
('yuv.max=', 251.71100000000001, 'yuv.min=', -11.140129999999985)
('yuv.max=', 255.0, 'yuv.min=', -43.487760000000009)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 247.29900000000004, 'yuv.min=', -3.0555499999999967)
('yuv.max=', 220.941, 'yuv.min=', -31.962759999999996)
('yuv.max=', 246.85399999999998, 'yuv.min=', -40.870519999999985)
('yuv.max=', 255.0, 'yuv.min=', -8.765199999999993)
('yuv.max=', 245.63199999999998, 'yuv.min=', -37.505130000000008)
('yuv.max=', 234.03200000000001, 'yuv.min=', -19.190319999999993)
('yuv.max=', 240.97899999999998, 'yuv.min=', -31.005209999999988)
('yuv.max=', 255.0, 'yuv.min=', -13.500119999999992)
('yuv.max=', 252.93999999999997, 'yuv.min=', -34.180520000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -15.460069999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.40011)
('yuv.max=', 157.50399999999999, 'yuv.min=', -0.87020999999999127)
('yuv.max=', 179.76999999999998, 'yuv.min=', -5.9051600000000004)
('yuv.max=', 243.95699999999997, 'yuv.min=', -16.908060000000006)
('yuv.max=', 226.976, 'yuv.min=', -2.7853399999999873)
('yuv.max=', 242.58699999999999, 'yuv.min=', -39.380739999999989)
('yuv.max=', 253.72899999999996, 'yuv.min=', -36.540210000000002)
('yuv.max=', 235.363, 'yuv.min=', -42.375239999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.3650599999999855)
('yuv.max=', 219.99499999999998, 'yuv.min=', -48.312550000000002)
('yuv.max=', 250.81399999999999, 'yuv.min=', -29.545310000000001)
('yuv.max=', 213.309, 'yuv.min=', -16.215330000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 254.41299999999995, 'yuv.min=', -23.508759999999995)
('yuv.max=', 181.41, 'yuv.min=', -44.360499999999995)
('yuv.max=', 186.07499999999999, 'yuv.min=', -39.285299999999992)
('yuv.max=', 239.11899999999997, 'yuv.min=', -72.460849999999994)
('yuv.max=', 224.97199999999998, 'yuv.min=', -28.321109999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.855339999999998)
('yuv.max=', 157.73699999999997, 'yuv.min=', -17.075169999999986)
('yuv.max=', 214.81, 'yuv.min=', -44.655959999999993)
('yuv.max=', 203.03900000000002, 'yuv.min=', -48.925279999999994)
('yuv.max=', 237.40600000000001, 'yuv.min=', -24.751550000000009)
('yuv.max=', 164.63800000000001, 'yuv.min=', -47.460810000000002)
('yuv.max=', 248.185, 'yuv.min=', -26.717870000000001)
('yuv.max=', 251.13099999999997, 'yuv.min=', -10.650449999999998)
('yuv.max=', 246.59399999999999, 'yuv.min=', -18.211650000000002)
('yuv.max=', 255.0, 'yuv.min=', -76.956869999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -34.865349999999992)
('yuv.max=', 227.541, 'yuv.min=', -70.500900000000001)
('yuv.max=', 251.10299999999998, 'yuv.min=', -41.115359999999995)
('yuv.max=', 215.125, 'yuv.min=', -42.360299999999995)
('yuv.max=', 206.886, 'yuv.min=', -32.866430000000001)
('yuv.max=', 228.58499999999998, 'yuv.min=', -18.630509999999994)
('yuv.max=', 198.21899999999997, 'yuv.min=', -53.42116)
('yuv.max=', 128.78, 'yuv.min=', -56.085749999999997)
('yuv.max=', 242.25499999999997, 'yuv.min=', -33.060599999999987)
('yuv.max=', 172.886, 'yuv.min=', -24.280459999999998)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.645420000000001)
('yuv.max=', 241.357, 'yuv.min=', -17.045289999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.985499999999991)
('yuv.max=', 249.32699999999997, 'yuv.min=', -23.182099999999991)
('yuv.max=', 229.07199999999997, 'yuv.min=', -52.095719999999993)
('yuv.max=', 250.0, 'yuv.min=', -9.166170000000001)
('yuv.max=', 248.25999999999999, 'yuv.min=', -57.220309999999991)
('yuv.max=', 240.404, 'yuv.min=', -49.528590000000001)
('yuv.max=', 252.42999999999998, 'yuv.min=', -24.755199999999995)
('yuv.max=', 252.892, 'yuv.min=', -24.810389999999998)
('yuv.max=', 235.77799999999996, 'yuv.min=', -76.913550000000001)
('yuv.max=', 246.88200000000001, 'yuv.min=', -25.880910000000004)
('yuv.max=', 207.24999999999997, 'yuv.min=', -38.425460000000001)
('yuv.max=', 238.10799999999998, 'yuv.min=', -38.135799999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 201.37899999999999, 'yuv.min=', -68.357200000000006)
('yuv.max=', 253.71799999999999, 'yuv.min=', -39.625579999999985)
('yuv.max=', 241.869, 'yuv.min=', -43.01991000000001)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.636, 'yuv.min=', -69.299289999999999)
('yuv.max=', 250.78199999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 221.09199999999998, 'yuv.min=', -26.370299999999993)
('yuv.max=', 219.49000000000001, 'yuv.min=', -12.962710000000001)
('yuv.max=', 240.30299999999997, 'yuv.min=', -42.200529999999993)
('yuv.max=', 244.17999999999998, 'yuv.min=', -38.459909999999994)
('yuv.max=', 245.71599999999998, 'yuv.min=', -33.020349999999993)
('yuv.max=', 255.0, 'yuv.min=', -41.355629999999998)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.73999999999998, 'yuv.min=', -63.00515)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.071029999999997)
('yuv.max=', 244.30700000000002, 'yuv.min=', -24.655189999999994)
('yuv.max=', 220.43499999999997, 'yuv.min=', -95.514039999999994)
('yuv.max=', 192.34700000000001, 'yuv.min=', -46.490589999999997)
('yuv.max=', 252.03199999999998, 'yuv.min=', -24.081859999999999)
('yuv.max=', 210.83399999999997, 'yuv.min=', -72.965469999999996)
('yuv.max=', 174.45399999999998, 'yuv.min=', -33.766310000000004)
('yuv.max=', 255.0, 'yuv.min=', -65.686679999999996)
('yuv.max=', 232.69, 'yuv.min=', -36.403080000000003)
('yuv.max=', 255.0, 'yuv.min=', -20.920369999999995)
('yuv.max=', 247.47299999999998, 'yuv.min=', -34.59062999999999)
('yuv.max=', 206.459, 'yuv.min=', -29.560249999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.07507)
('yuv.max=', 209.27799999999999, 'yuv.min=', -74.362259999999992)
('yuv.max=', 251.89699999999999, 'yuv.min=', -65.555589999999995)
('yuv.max=', 248.57999999999998, 'yuv.min=', -35.073459999999997)
('yuv.max=', 238.62999999999997, 'yuv.min=', -45.516820000000003)
('yuv.max=', 248.76499999999999, 'yuv.min=', -52.600339999999989)
('yuv.max=', 242.58899999999997, 'yuv.min=', -12.805450000000008)
('yuv.max=', 229.24700000000001, 'yuv.min=', -24.267709999999997)
('yuv.max=', 252.886, 'yuv.min=', -21.858270000000008)
('yuv.max=', 254.886, 'yuv.min=', -40.813850000000002)
('yuv.max=', 227.36499999999998, 'yuv.min=', -68.590339999999998)
('yuv.max=', 245.69399999999999, 'yuv.min=', -19.550109999999997)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.780309999999993)
('yuv.max=', 254.886, 'yuv.min=', -14.713340000000002)
('yuv.max=', 240.53299999999999, 'yuv.min=', -36.725290000000001)
('yuv.max=', 253.80399999999997, 'yuv.min=', -78.995130000000003)
('yuv.max=', 236.67699999999999, 'yuv.min=', -32.460539999999988)
('yuv.max=', 253.81499999999997, 'yuv.min=', -39.014770000000006)
('yuv.max=', 232.071, 'yuv.min=', -2.473550000000003)
('yuv.max=', 218.14099999999999, 'yuv.min=', -38.092199999999991)
('yuv.max=', 229.63, 'yuv.min=', -32.060499999999998)
('yuv.max=', 140.624, 'yuv.min=', -25.65528999999999)
('yuv.max=', 208.17499999999998, 'yuv.min=', -18.850039999999993)
('yuv.max=', 250.017, 'yuv.min=', -9.8746100000000006)
('yuv.max=', 243.42499999999995, 'yuv.min=', -17.219390000000004)
('yuv.max=', 195.28199999999998, 'yuv.min=', -48.440169999999995)
('yuv.max=', 249.733, 'yuv.min=', -22.420519999999982)
('yuv.max=', 235.69399999999999, 'yuv.min=', -48.350529999999992)
('yuv.max=', 234.78099999999998, 'yuv.min=', -15.834680000000013)
('yuv.max=', 253.76100000000002, 'yuv.min=', -34.850409999999997)
('yuv.max=', 217.821, 'yuv.min=', -23.345400000000005)
('yuv.max=', 246.809, 'yuv.min=', -26.125459999999986)
('yuv.max=', 237.89699999999999, 'yuv.min=', -40.730259999999994)
('yuv.max=', 255.0, 'yuv.min=', -19.737919999999999)
('yuv.max=', 252.24699999999996, 'yuv.min=', -57.530709999999985)
('yuv.max=', 255.0, 'yuv.min=', -35.813090000000003)
('yuv.max=', 237.245, 'yuv.min=', -34.56532)
('yuv.max=', 253.505, 'yuv.min=', -55.555320000000009)
('yuv.max=', 195.46599999999998, 'yuv.min=', -17.595169999999996)
('yuv.max=', 254.54400000000001, 'yuv.min=', -79.518849999999986)
('yuv.max=', 255.0, 'yuv.min=', -95.05641)
('yuv.max=', 250.62299999999999, 'yuv.min=', -58.732000000000006)
('yuv.max=', 244.47300000000001, 'yuv.min=', -33.300870000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -25.570219999999996)
('yuv.max=', 246.38700000000003, 'yuv.min=', -33.41105000000001)
('yuv.max=', 235.82599999999999, 'yuv.min=', -18.800549999999994)
('yuv.max=', 193.41, 'yuv.min=', -20.175479999999993)
('yuv.max=', 251.08099999999999, 'yuv.min=', -42.600569999999991)
('yuv.max=', 254.54400000000001, 'yuv.min=', -50.08292999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.504599999999989)
('yuv.max=', 237.06899999999999, 'yuv.min=', -25.815059999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -25.225369999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -11.187920000000002)
('yuv.max=', 239.559, 'yuv.min=', -11.340150000000007)
('yuv.max=', 255.0, 'yuv.min=', -2.6600199999999976)
('yuv.max=', 221.291, 'yuv.min=', -18.920169999999999)
('yuv.max=', 250.43499999999997, 'yuv.min=', -30.551030000000001)
('yuv.max=', 245.29999999999998, 'yuv.min=', -28.975129999999993)
('yuv.max=', 193.99499999999998, 'yuv.min=', -22.555520000000001)
('yuv.max=', 228.67899999999997, 'yuv.min=', -37.65068999999999)
('yuv.max=', 241.09899999999999, 'yuv.min=', -36.6175)
('yuv.max=', 203.96399999999997, 'yuv.min=', -47.603279999999998)
('yuv.max=', 253.12499999999997, 'yuv.min=', -28.845239999999997)
('yuv.max=', 248.97900000000001, 'yuv.min=', -11.197389999999999)
('yuv.max=', 230.316, 'yuv.min=', -15.630209999999998)
('yuv.max=', 229.524, 'yuv.min=', -15.830229999999993)
('yuv.max=', 239.88099999999997, 'yuv.min=', -24.932200000000002)
('yuv.max=', 239.20599999999996, 'yuv.min=', -16.260149999999985)
('yuv.max=', 238.17399999999998, 'yuv.min=', -49.795490000000001)
('yuv.max=', 226.65799999999999, 'yuv.min=', -22.265319999999992)
('yuv.max=', 253.64700000000002, 'yuv.min=', -32.324849999999998)
('yuv.max=', 227.30199999999999, 'yuv.min=', -42.245349999999995)
('yuv.max=', 198.26300000000001, 'yuv.min=', -45.115759999999995)
('yuv.max=', 229.505, 'yuv.min=', -38.562640000000002)
('yuv.max=', 195.83499999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 255.0, 'yuv.min=', -68.252790000000005)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.590329999999994)
('yuv.max=', 237.43899999999999, 'yuv.min=', -24.380469999999992)
('yuv.max=', 255.0, 'yuv.min=', -56.264140000000005)
('yuv.max=', 225.32300000000001, 'yuv.min=', -22.875749999999996)
('yuv.max=', 170.57999999999998, 'yuv.min=', -32.575489999999995)
('yuv.max=', 247.08999999999997, 'yuv.min=', -13.813460000000006)
('yuv.max=', 187.07300000000001, 'yuv.min=', -21.41004999999998)
('yuv.max=', 242.22399999999999, 'yuv.min=', -18.520130000000002)
('yuv.max=', 239.62200000000001, 'yuv.min=', -20.62227)
('yuv.max=', 250.01000000000002, 'yuv.min=', -7.3949399999999983)
('yuv.max=', 206.06999999999999, 'yuv.min=', -35.244649999999993)
('yuv.max=', 244.15699999999998, 'yuv.min=', -59.990709999999986)
('yuv.max=', 229.21000000000001, 'yuv.min=', -26.240409999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -22.092999999999996)
('yuv.max=', 234.928, 'yuv.min=', -28.070050000000005)
('yuv.max=', 249.11600000000001, 'yuv.min=', -20.875549999999993)
('yuv.max=', 162.24900000000002, 'yuv.min=', -12.485079999999986)
('yuv.max=', 255.0, 'yuv.min=', -6.2350699999999994)
('yuv.max=', 252.608, 'yuv.min=', -28.800419999999988)
('yuv.max=', 246.0, 'yuv.min=', -29.560249999999996)
('yuv.max=', 241.65100000000001, 'yuv.min=', -36.856290000000001)
('yuv.max=', 244.40499999999997, 'yuv.min=', -27.384129999999999)
('yuv.max=', 179.917, 'yuv.min=', -12.963499999999996)
('yuv.max=', 235.92899999999997, 'yuv.min=', -47.942480000000003)
('yuv.max=', 195.11399999999998, 'yuv.min=', -29.254120000000004)
('yuv.max=', 211.85500000000002, 'yuv.min=', -61.465550000000007)
('yuv.max=', 226.96699999999998, 'yuv.min=', -21.580189999999995)
('yuv.max=', 235.18800000000002, 'yuv.min=', -49.231330000000014)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.756, 'yuv.min=', -72.509069999999994)
('yuv.max=', 255.0, 'yuv.min=', -16.815389999999997)
('yuv.max=', 248.73199999999997, 'yuv.min=', -100.62553)
('yuv.max=', 225.40000000000001, 'yuv.min=', -19.390339999999981)
('yuv.max=', 244.43899999999999, 'yuv.min=', -32.045559999999988)
('yuv.max=', 252.00999999999999, 'yuv.min=', -40.257210000000008)
('yuv.max=', 248.10899999999998, 'yuv.min=', -35.940149999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.57086000000001)
('yuv.max=', 221.423, 'yuv.min=', -16.828860000000002)
('yuv.max=', 247.35499999999999, 'yuv.min=', -76.540520000000001)
('yuv.max=', 255.0, 'yuv.min=', -50.79558999999999)
('yuv.max=', 226.29599999999999, 'yuv.min=', -27.956729999999997)
('yuv.max=', 201.99999999999997, 'yuv.min=', -27.470409999999994)
('yuv.max=', 247.86499999999998, 'yuv.min=', -95.415869999999998)
('yuv.max=', 221.13399999999999, 'yuv.min=', -80.666240000000002)
('yuv.max=', 255.0, 'yuv.min=', -34.861909999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -12.11434)
('yuv.max=', 253.0, 'yuv.min=', -31.989319999999999)
('yuv.max=', 243.74599999999998, 'yuv.min=', -13.830799999999996)
('yuv.max=', 162.774, 'yuv.min=', -36.910369999999993)
('yuv.max=', 194.113, 'yuv.min=', -20.120289999999983)
('yuv.max=', 223.71699999999998, 'yuv.min=', -22.724240000000002)
('yuv.max=', 231.51900000000001, 'yuv.min=', -24.900029999999987)
('yuv.max=', 255.0, 'yuv.min=', -5.4372200000000035)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -5.8200899999999933)
('yuv.max=', 250.08099999999996, 'yuv.min=', -34.277480000000011)
('yuv.max=', 255.0, 'yuv.min=', -46.27563)
('yuv.max=', 255.0, 'yuv.min=', -36.099009999999993)
('yuv.max=', 244.29899999999998, 'yuv.min=', -11.95046)
('yuv.max=', 237.07199999999997, 'yuv.min=', -52.660519999999998)
('yuv.max=', 247.38, 'yuv.min=', -33.727649999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.761360000000003)
('yuv.max=', 224.62800000000001, 'yuv.min=', -7.1813399999999987)
('yuv.max=', 211.958, 'yuv.min=', -37.690939999999991)
('yuv.max=', 255.0, 'yuv.min=', -31.745529999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.150369999999995)
('yuv.max=', 210.64699999999999, 'yuv.min=', -9.4100799999999936)
('yuv.max=', 242.57599999999996, 'yuv.min=', -22.865379999999988)
('yuv.max=', 230.53800000000001, 'yuv.min=', -39.150840000000002)
('yuv.max=', 253.78899999999999, 'yuv.min=', -27.602539999999998)
('yuv.max=', 253.071, 'yuv.min=', -17.88036)
('yuv.max=', 239.31599999999997, 'yuv.min=', -48.695379999999993)
('yuv.max=', 228.80500000000001, 'yuv.min=', -55.167779999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.8189400000000049)
('yuv.max=', 251.989, 'yuv.min=', -38.61054)
('yuv.max=', 255.0, 'yuv.min=', -78.503790000000009)
('yuv.max=', 255.0, 'yuv.min=', -28.958759999999998)
('yuv.max=', 239.42999999999998, 'yuv.min=', -18.790090000000003)
('yuv.max=', 234.13499999999999, 'yuv.min=', -27.725619999999999)
('yuv.max=', 248.309, 'yuv.min=', -48.025189999999995)
('yuv.max=', 240.505, 'yuv.min=', -30.000539999999987)
('yuv.max=', 156.01600000000002, 'yuv.min=', -23.295299999999987)
('yuv.max=', 255.0, 'yuv.min=', -34.88942999999999)
('yuv.max=', 238.49199999999999, 'yuv.min=', -27.674999999999986)
('yuv.max=', 200.453, 'yuv.min=', -10.92516999999998)
('yuv.max=', 237.99100000000001, 'yuv.min=', -18.405179999999998)
('yuv.max=', 255.0, 'yuv.min=', -18.631800000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -9.9250699999999998)
('yuv.max=', 247.559, 'yuv.min=', -19.699509999999997)
('yuv.max=', 177.83399999999997, 'yuv.min=', -74.852370000000008)
('yuv.max=', 229.86899999999997, 'yuv.min=', -53.525739999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.360629999999986)
('yuv.max=', 217.90099999999998, 'yuv.min=', -17.860309999999991)
('yuv.max=', 233.56999999999999, 'yuv.min=', -15.730219999999994)
('yuv.max=', 234.38300000000001, 'yuv.min=', -21.652050000000003)
('yuv.max=', 215.13099999999997, 'yuv.min=', -44.185559999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.42199999999997, 'yuv.min=', -48.266610000000007)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.985199999999995)
('yuv.max=', 140.06799999999998, 'yuv.min=', -14.830129999999999)
('yuv.max=', 249.17399999999998, 'yuv.min=', -34.562550000000002)
('yuv.max=', 248.48799999999997, 'yuv.min=', -38.940449999999998)
('yuv.max=', 236.68599999999998, 'yuv.min=', -13.830669999999998)
('yuv.max=', 242.52200000000002, 'yuv.min=', -26.151740000000004)
('yuv.max=', 224.476, 'yuv.min=', -24.850459999999998)
('yuv.max=', 165.22499999999999, 'yuv.min=', -45.685939999999995)
('yuv.max=', 244.50799999999998, 'yuv.min=', -16.908730000000006)
('yuv.max=', 251.626, 'yuv.min=', -14.870779999999996)
('yuv.max=', 243.17399999999998, 'yuv.min=', -10.280289999999983)
('yuv.max=', 204.40299999999999, 'yuv.min=', -25.197850000000006)
('yuv.max=', 202.06900000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 247.37, 'yuv.min=', -35.282219999999995)
('yuv.max=', 236.73999999999998, 'yuv.min=', -36.654979999999995)
('yuv.max=', 233.71099999999998, 'yuv.min=', -43.975399999999993)
('yuv.max=', 248.22800000000001, 'yuv.min=', -29.180949999999996)
('yuv.max=', 213.67099999999999, 'yuv.min=', -6.8201899999999895)
('yuv.max=', 244.95699999999999, 'yuv.min=', -33.520399999999995)
('yuv.max=', 253.60399999999998, 'yuv.min=', -54.49595999999999)
('yuv.max=', 228.91199999999998, 'yuv.min=', -13.19248)
('yuv.max=', 115.28099999999999, 'yuv.min=', -39.415189999999996)
('yuv.max=', 205.60999999999999, 'yuv.min=', -60.214730000000003)
('yuv.max=', 224.202, 'yuv.min=', -49.380510000000001)
('yuv.max=', 250.20199999999997, 'yuv.min=', -38.588660000000004)
('yuv.max=', 253.63200000000001, 'yuv.min=', -13.138069999999999)
('yuv.max=', 206.85799999999998, 'yuv.min=', -69.785889999999995)
('yuv.max=', 168.94099999999997, 'yuv.min=', -17.775239999999997)
('yuv.max=', 240.65799999999999, 'yuv.min=', -28.54520999999999)
('yuv.max=', 224.584, 'yuv.min=', -19.835199999999997)
('yuv.max=', 241.52000000000001, 'yuv.min=', -50.700149999999979)
('yuv.max=', 168.11999999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 188.267, 'yuv.min=', -39.755469999999988)
('yuv.max=', 238.47299999999998, 'yuv.min=', -39.608540000000005)
('yuv.max=', 255.0, 'yuv.min=', -24.929909999999982)
('yuv.max=', 195.34799999999998, 'yuv.min=', -36.654849999999996)
('yuv.max=', 218.31999999999999, 'yuv.min=', -31.130529999999993)
('yuv.max=', 238.41299999999998, 'yuv.min=', -97.565469999999991)
('yuv.max=', 238.28999999999999, 'yuv.min=', -26.485569999999999)
('yuv.max=', 209.74099999999999, 'yuv.min=', -55.266159999999999)
('yuv.max=', 180.42499999999998, 'yuv.min=', -25.780609999999999)
('yuv.max=', 221.32499999999999, 'yuv.min=', -41.215369999999993)
('yuv.max=', 189.82499999999999, 'yuv.min=', -69.285839999999993)
('yuv.max=', 242.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.67500000000001, 'yuv.min=', -26.855409999999988)
('yuv.max=', 219.16, 'yuv.min=', -18.942410000000002)
('yuv.max=', 209.977, 'yuv.min=', -31.580290000000012)
('yuv.max=', 242.06099999999998, 'yuv.min=', -25.787010000000002)
('yuv.max=', 253.63200000000001, 'yuv.min=', -85.540189999999981)
('yuv.max=', 244.624, 'yuv.min=', -21.485979999999998)
('yuv.max=', 203.83500000000001, 'yuv.min=', -5.19015)
('yuv.max=', 211.02100000000002, 'yuv.min=', -16.315339999999999)
('yuv.max=', 228.95299999999997, 'yuv.min=', -34.735459999999989)
('yuv.max=', 250.38200000000001, 'yuv.min=', -27.040489999999998)
('yuv.max=', 219.65299999999999, 'yuv.min=', -26.325479999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.6801300000000001)
('yuv.max=', 233.54199999999997, 'yuv.min=', -62.884430000000009)
('yuv.max=', 247.875, 'yuv.min=', -25.815059999999999)
('yuv.max=', 223.44599999999997, 'yuv.min=', -24.010309999999997)
('yuv.max=', 251.16900000000001, 'yuv.min=', -26.745029999999986)
('yuv.max=', 255.0, 'yuv.min=', -19.170809999999989)
('yuv.max=', 212.10500000000002, 'yuv.min=', -27.88663)
('yuv.max=', 255.0, 'yuv.min=', -38.497750000000011)
('yuv.max=', 158.15000000000001, 'yuv.min=', -35.014670000000002)
('yuv.max=', 255.0, 'yuv.min=', -30.060960000000001)
('yuv.max=', 248.74299999999999, 'yuv.min=', -36.920739999999995)
('yuv.max=', 235.477, 'yuv.min=', -25.165610000000001)
('yuv.max=', 250.81100000000001, 'yuv.min=', -10.200159999999997)
('yuv.max=', 214.78899999999999, 'yuv.min=', -38.574859999999994)
('yuv.max=', 200.48299999999998, 'yuv.min=', -38.940449999999984)
('yuv.max=', 255.0, 'yuv.min=', -16.090009999999999)
('yuv.max=', 249.91699999999997, 'yuv.min=', -31.20523)
('yuv.max=', 244.81500000000003, 'yuv.min=', -36.880489999999995)
('yuv.max=', 246.03399999999999, 'yuv.min=', -26.300169999999994)
('yuv.max=', 252.60599999999999, 'yuv.min=', -31.580769999999994)
('yuv.max=', 187.595, 'yuv.min=', -52.83480999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -40.27046)
('yuv.max=', 232.24499999999998, 'yuv.min=', -22.37143)
('yuv.max=', 213.24799999999999, 'yuv.min=', -51.495659999999987)
('yuv.max=', 185.39299999999997, 'yuv.min=', -32.805389999999989)
('yuv.max=', 162.25800000000001, 'yuv.min=', -43.630549999999999)
('yuv.max=', 249.13199999999998, 'yuv.min=', -76.334669999999988)
('yuv.max=', 249.82599999999999, 'yuv.min=', -30.52965)
('yuv.max=', 225.852, 'yuv.min=', -35.025660000000002)
('yuv.max=', 254.316, 'yuv.min=', -20.774210000000004)
('yuv.max=', 254.41299999999995, 'yuv.min=', -22.895260000000004)
('yuv.max=', 237.45600000000002, 'yuv.min=', -16.609949999999998)
('yuv.max=', 207.32599999999999, 'yuv.min=', -40.29576999999999)
('yuv.max=', 198.34700000000001, 'yuv.min=', -61.310349999999993)
('yuv.max=', 231.14999999999998, 'yuv.min=', -49.75067)
('yuv.max=', 255.0, 'yuv.min=', -34.920539999999995)
('yuv.max=', 248.66900000000001, 'yuv.min=', -40.61074)
('yuv.max=', 248.815, 'yuv.min=', -24.61037)
('yuv.max=', 249.125, 'yuv.min=', -20.680109999999999)
('yuv.max=', 210.04500000000002, 'yuv.min=', -21.69438000000001)
('yuv.max=', 191.98299999999998, 'yuv.min=', -10.680329999999996)
('yuv.max=', 212.72399999999999, 'yuv.min=', -40.530320000000003)
('yuv.max=', 231.44499999999999, 'yuv.min=', -28.700409999999998)
('yuv.max=', 212.29999999999998, 'yuv.min=', -50.800159999999991)
('yuv.max=', 248.89699999999999, 'yuv.min=', -27.309130000000003)
('yuv.max=', 250.02800000000002, 'yuv.min=', -51.465779999999995)
('yuv.max=', 243.54399999999998, 'yuv.min=', -29.875219999999992)
('yuv.max=', 246.886, 'yuv.min=', -24.740259999999992)
('yuv.max=', 242.83999999999997, 'yuv.min=', -45.670999999999999)
('yuv.max=', 247.28100000000001, 'yuv.min=', -20.899590000000003)
('yuv.max=', 241.94999999999999, 'yuv.min=', -16.409350000000003)
('yuv.max=', 236.11099999999999, 'yuv.min=', -17.420019999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.56999999999999, 'yuv.min=', -93.345539999999986)
('yuv.max=', 254.06, 'yuv.min=', -43.43052999999999)
('yuv.max=', 201.756, 'yuv.min=', -14.691369999999999)
('yuv.max=', 227.08799999999999, 'yuv.min=', -19.035519999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.025049999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 226.303, 'yuv.min=', -78.360209999999995)
('yuv.max=', 247.142, 'yuv.min=', -25.595529999999997)
('yuv.max=', 206.09999999999999, 'yuv.min=', -33.630779999999994)
('yuv.max=', 182.89400000000001, 'yuv.min=', -15.615269999999995)
('yuv.max=', 251.45599999999996, 'yuv.min=', -18.360359999999996)
('yuv.max=', 253.01699999999997, 'yuv.min=', -11.465959999999999)
('yuv.max=', 144.58599999999998, 'yuv.min=', -26.48524999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.194890000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.505570000000002)
('yuv.max=', 235.25299999999999, 'yuv.min=', -40.67049999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', -48.290710000000004)
('yuv.max=', 255.0, 'yuv.min=', -36.120659999999987)
('yuv.max=', 254.29899999999995, 'yuv.min=', -34.96535999999999)
('yuv.max=', 253.333, 'yuv.min=', -34.501159999999999)
('yuv.max=', 253.17399999999998, 'yuv.min=', -31.794919999999983)
('yuv.max=', 193.07999999999998, 'yuv.min=', -6.1571099999999959)
('yuv.max=', 238.923, 'yuv.min=', -28.343790000000006)
('yuv.max=', 234.108, 'yuv.min=', -22.196990000000003)
('yuv.max=', 250.69999999999999, 'yuv.min=', -46.180189999999982)
('yuv.max=', 238.65899999999999, 'yuv.min=', -19.305269999999986)
('yuv.max=', 253.99999999999997, 'yuv.min=', -62.255259999999993)
('yuv.max=', 215.88599999999997, 'yuv.min=', -9.3135700000000021)
('yuv.max=', 245.54199999999997, 'yuv.min=', -44.230609999999999)
('yuv.max=', 215.73899999999998, 'yuv.min=', -81.530649999999994)
('yuv.max=', 250.90899999999999, 'yuv.min=', -89.503680000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.605469999999997)
('yuv.max=', 202.554, 'yuv.min=', -31.800719999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.685099999999991)
('yuv.max=', 209.60499999999999, 'yuv.min=', -50.495559999999983)
('yuv.max=', 194.55700000000002, 'yuv.min=', -36.995439999999988)
('yuv.max=', 216.37699999999998, 'yuv.min=', -81.741720000000001)
('yuv.max=', 228.75299999999999, 'yuv.min=', -46.105489999999989)
('yuv.max=', 255.0, 'yuv.min=', -3.1922800000000038)
('yuv.max=', 244.053, 'yuv.min=', -17.960319999999985)
('yuv.max=', 254.316, 'yuv.min=', -20.850239999999985)
('yuv.max=', 255.0, 'yuv.min=', -20.206259999999997)
('yuv.max=', 252.31, 'yuv.min=', -36.705150000000003)
('yuv.max=', 239.864, 'yuv.min=', -16.609749999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -13.966860000000004)
('yuv.max=', 235.608, 'yuv.min=', -18.511550000000007)
('yuv.max=', 246.46599999999998, 'yuv.min=', -18.075269999999996)
('yuv.max=', 207.61000000000001, 'yuv.min=', -20.175479999999997)
('yuv.max=', 194.35899999999998, 'yuv.min=', -30.965180000000004)
('yuv.max=', 245.989, 'yuv.min=', -20.984699999999997)
('yuv.max=', 231.024, 'yuv.min=', -46.39058)
('yuv.max=', 255.0, 'yuv.min=', -20.635279999999998)
('yuv.max=', 239.41499999999996, 'yuv.min=', -12.959819999999993)
('yuv.max=', 251.327, 'yuv.min=', -21.96529)
('yuv.max=', 230.76600000000002, 'yuv.min=', -54.170570000000005)
('yuv.max=', 255.0, 'yuv.min=', -40.790659999999995)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 186.69799999999998, 'yuv.min=', -26.645019999999992)
('yuv.max=', 248.142, 'yuv.min=', -29.194520000000001)
('yuv.max=', 240.30499999999998, 'yuv.min=', -44.334310000000002)
('yuv.max=', 251.90299999999999, 'yuv.min=', -21.536810000000003)
('yuv.max=', 251.07299999999998, 'yuv.min=', -29.285359999999997)
('yuv.max=', 219.886, 'yuv.min=', -17.260249999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -35.074359999999999)
('yuv.max=', 235.94999999999999, 'yuv.min=', -19.395350000000001)
('yuv.max=', 218.91499999999999, 'yuv.min=', -21.411540000000006)
('yuv.max=', 206.64999999999998, 'yuv.min=', -29.560249999999996)
('yuv.max=', 211.91699999999997, 'yuv.min=', -27.515229999999988)
('yuv.max=', 254.47300000000001, 'yuv.min=', -25.870260000000002)
('yuv.max=', 251.54399999999998, 'yuv.min=', -87.385189999999994)
('yuv.max=', 255.0, 'yuv.min=', -33.69344000000001)
('yuv.max=', 252.04899999999998, 'yuv.min=', -29.507860000000004)
('yuv.max=', 206.18700000000001, 'yuv.min=', -24.158469999999998)
('yuv.max=', 232.80500000000001, 'yuv.min=', -29.500489999999992)
('yuv.max=', 247.762, 'yuv.min=', -32.872480000000003)
('yuv.max=', 184.655, 'yuv.min=', -8.3200300000000027)
('yuv.max=', 222.41799999999995, 'yuv.min=', -16.592839999999995)
('yuv.max=', 255.0, 'yuv.min=', -19.030670000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999992)
('yuv.max=', 214.62400000000002, 'yuv.min=', -22.59066)
('yuv.max=', 255.0, 'yuv.min=', -48.665499999999994)
('yuv.max=', 255.0, 'yuv.min=', -22.218730000000004)
('yuv.max=', 245.08599999999998, 'yuv.min=', -56.115629999999996)
('yuv.max=', 255.0, 'yuv.min=', -25.324150000000003)
('yuv.max=', 255.0, 'yuv.min=', -49.777620000000006)
('yuv.max=', 237.27099999999999, 'yuv.min=', -19.275390000000002)
('yuv.max=', 189.81200000000001, 'yuv.min=', -30.875319999999995)
('yuv.max=', 205.58099999999999, 'yuv.min=', -15.039760000000001)
('yuv.max=', 197.72900000000001, 'yuv.min=', -50.555319999999995)
('yuv.max=', 251.92899999999995, 'yuv.min=', -30.224639999999997)
('yuv.max=', 199.36799999999999, 'yuv.min=', -19.860509999999987)
('yuv.max=', 227.14599999999999, 'yuv.min=', -24.76557)
('yuv.max=', 192.24099999999999, 'yuv.min=', -52.480819999999994)
('yuv.max=', 252.61500000000001, 'yuv.min=', -77.648920000000004)
('yuv.max=', 220.57799999999997, 'yuv.min=', -29.100710000000007)
('yuv.max=', 255.0, 'yuv.min=', -7.2650499999999916)
('yuv.max=', 245.62899999999999, 'yuv.min=', -70.030730000000005)
('yuv.max=', 250.29899999999998, 'yuv.min=', -35.375770000000003)
('yuv.max=', 248.989, 'yuv.min=', -14.544330000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 218.99600000000001, 'yuv.min=', -72.320589999999982)
('yuv.max=', 248.27699999999999, 'yuv.min=', -36.935679999999991)
('yuv.max=', 245.672, 'yuv.min=', -40.921590000000002)
('yuv.max=', 242.58100000000002, 'yuv.min=', -2.3450499999999934)
('yuv.max=', 240.72800000000001, 'yuv.min=', -27.870449999999988)
('yuv.max=', 255.0, 'yuv.min=', -11.255079999999992)
('yuv.max=', 248.91399999999999, 'yuv.min=', -19.825010000000006)
('yuv.max=', 254.10300000000001, 'yuv.min=', -30.405149999999985)
('yuv.max=', 237.45999999999998, 'yuv.min=', -28.866129999999998)
('yuv.max=', 184.113, 'yuv.min=', -22.725119999999997)
('yuv.max=', 225.82599999999996, 'yuv.min=', -32.415120000000002)
('yuv.max=', 252.65799999999999, 'yuv.min=', -14.585289999999995)
('yuv.max=', 248.84700000000001, 'yuv.min=', -15.015209999999986)
('yuv.max=', 226.05800000000002, 'yuv.min=', -38.365699999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.601410000000001)
('yuv.max=', 250.136, 'yuv.min=', -14.821630000000013)
('yuv.max=', 244.32699999999997, 'yuv.min=', -11.755129999999999)
('yuv.max=', 251.37799999999999, 'yuv.min=', -65.272270000000006)
('yuv.max=', 252.71799999999996, 'yuv.min=', -32.430659999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.586700000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.750429999999987)
('yuv.max=', 220.684, 'yuv.min=', -37.825399999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -40.67049999999999)
('yuv.max=', 247.00200000000001, 'yuv.min=', -36.595850000000006)
('yuv.max=', 216.23699999999999, 'yuv.min=', -47.29524)
('yuv.max=', 197.899, 'yuv.min=', -94.360579999999985)
('yuv.max=', 245.07399999999998, 'yuv.min=', -23.066559999999999)
('yuv.max=', 239.19999999999999, 'yuv.min=', -3.0451199999999936)
('yuv.max=', 211.73600000000002, 'yuv.min=', -36.48044999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.305239999999998)
('yuv.max=', 152.08199999999999, 'yuv.min=', -19.36626)
('yuv.max=', 247.33099999999999, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 248.71199999999999, 'yuv.min=', -23.980429999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -38.340389999999999)
('yuv.max=', 185.69299999999998, 'yuv.min=', -37.010379999999998)
('yuv.max=', 242.30200000000002, 'yuv.min=', -22.425089999999997)
('yuv.max=', 234.04900000000001, 'yuv.min=', -37.625379999999993)
('yuv.max=', 238.506, 'yuv.min=', -22.169879999999992)
('yuv.max=', 191.68100000000001, 'yuv.min=', -13.900159999999982)
('yuv.max=', 248.29899999999998, 'yuv.min=', -31.046289999999992)
('yuv.max=', 167.434, 'yuv.min=', -13.300099999999999)
('yuv.max=', 236.47800000000001, 'yuv.min=', -27.440529999999985)
('yuv.max=', 160.45099999999999, 'yuv.min=', -18.375299999999996)
('yuv.max=', 243.15699999999998, 'yuv.min=', -9.3126800000000074)
('yuv.max=', 233.03699999999998, 'yuv.min=', -13.040319999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.375539999999994)
('yuv.max=', 252.93999999999997, 'yuv.min=', -33.18835)
('yuv.max=', 253.97400000000002, 'yuv.min=', -18.645449999999997)
('yuv.max=', 255.0, 'yuv.min=', -3.9223300000000023)
('yuv.max=', 252.41899999999998, 'yuv.min=', -15.260049999999998)
('yuv.max=', 253.41900000000001, 'yuv.min=', -19.880019999999991)
('yuv.max=', 196.72199999999998, 'yuv.min=', -17.775239999999997)
('yuv.max=', 241.76499999999999, 'yuv.min=', -50.980669999999989)
('yuv.max=', 244.33100000000002, 'yuv.min=', -46.820499999999996)
('yuv.max=', 255.0, 'yuv.min=', -30.354750000000003)
('yuv.max=', 206.80599999999998, 'yuv.min=', -13.755329999999997)
('yuv.max=', 253.50099999999998, 'yuv.min=', -38.580659999999988)
('yuv.max=', 242.143, 'yuv.min=', -64.889969999999991)
('yuv.max=', 255.0, 'yuv.min=', -63.165719999999993)
('yuv.max=', 232.83399999999997, 'yuv.min=', -16.800430000000002)
('yuv.max=', 254.07099999999997, 'yuv.min=', -59.169889999999995)
('yuv.max=', 247.15299999999996, 'yuv.min=', -44.000709999999998)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.185, 'yuv.min=', -38.449359999999999)
('yuv.max=', 236.74599999999998, 'yuv.min=', -21.66526)
('yuv.max=', 250.505, 'yuv.min=', -29.085510000000003)
('yuv.max=', 238.41200000000001, 'yuv.min=', -25.785179999999983)
('yuv.max=', 222.45299999999997, 'yuv.min=', -36.802440000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.015009999999998)
('yuv.max=', 255.0, 'yuv.min=', -44.890170000000012)
('yuv.max=', 254.886, 'yuv.min=', -48.56548999999999)
('yuv.max=', 206.41, 'yuv.min=', -15.515259999999994)
('yuv.max=', 243.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.98299999999998, 'yuv.min=', -5.9200999999999926)
('yuv.max=', 250.22999999999999, 'yuv.min=', -36.125229999999988)
('yuv.max=', 239.56599999999997, 'yuv.min=', -88.435909999999993)
('yuv.max=', 225.49000000000001, 'yuv.min=', -43.86045)
('yuv.max=', 214.91799999999998, 'yuv.min=', -38.609770000000005)
('yuv.max=', 253.77199999999999, 'yuv.min=', -60.414829999999988)
('yuv.max=', 237.50999999999996, 'yuv.min=', -1.7483900000000006)
('yuv.max=', 241.70499999999998, 'yuv.min=', -30.945450000000001)
('yuv.max=', 203.41799999999998, 'yuv.min=', -30.630479999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.6499500000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 189.05600000000001, 'yuv.min=', -17.230369999999986)
('yuv.max=', 237.32799999999997, 'yuv.min=', -15.540569999999988)
('yuv.max=', 252.81499999999997, 'yuv.min=', -21.977520000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.708100000000002)
('yuv.max=', 174.95499999999998, 'yuv.min=', -12.055159999999983)
('yuv.max=', 238.00899999999999, 'yuv.min=', -27.665859999999995)
('yuv.max=', 232.93899999999996, 'yuv.min=', -40.257480000000001)
('yuv.max=', 255.0, 'yuv.min=', -9.7639499999999977)
('yuv.max=', 251.53299999999999, 'yuv.min=', -46.365269999999995)
('yuv.max=', 233.977, 'yuv.min=', -23.955119999999994)
('yuv.max=', 238.37699999999998, 'yuv.min=', -27.715249999999987)
('yuv.max=', 192.637, 'yuv.min=', -34.865349999999999)
('yuv.max=', 247.77200000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 217.441, 'yuv.min=', -10.33262)
('yuv.max=', 254.886, 'yuv.min=', -27.274959999999968)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 156.15199999999999, 'yuv.min=', -16.930339999999994)
('yuv.max=', 204.86499999999998, 'yuv.min=', -98.749419999999986)
('yuv.max=', 200.86599999999999, 'yuv.min=', -32.000739999999993)
('yuv.max=', 247.42599999999999, 'yuv.min=', -13.77027)
('yuv.max=', 228.63999999999999, 'yuv.min=', -54.944840000000013)
('yuv.max=', 246.04900000000001, 'yuv.min=', -110.22525999999999)
('yuv.max=', 158.86699999999999, 'yuv.min=', -29.945349999999998)
('yuv.max=', 250.929, 'yuv.min=', -44.930679999999988)
('yuv.max=', 242.68999999999997, 'yuv.min=', -100.92555999999999)
('yuv.max=', 245.91800000000001, 'yuv.min=', -49.473049999999994)
('yuv.max=', 249.28799999999998, 'yuv.min=', -29.253930000000008)
('yuv.max=', 210.357, 'yuv.min=', -66.797670000000011)
('yuv.max=', 224.31299999999999, 'yuv.min=', -24.666039999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.79300000000001, 'yuv.min=', -32.736700000000006)
('yuv.max=', 229.04599999999999, 'yuv.min=', -47.920609999999996)
('yuv.max=', 250.131, 'yuv.min=', -22.441190000000006)
('yuv.max=', 254.202, 'yuv.min=', -33.805489999999992)
('yuv.max=', 224.30500000000001, 'yuv.min=', -27.148570000000007)
('yuv.max=', 211.273, 'yuv.min=', -45.25976)
('yuv.max=', 227.0, 'yuv.min=', -26.015079999999994)
('yuv.max=', 251.05999999999997, 'yuv.min=', -4.3649300000000011)
('yuv.max=', 133.11699999999999, 'yuv.min=', -24.525300000000001)
('yuv.max=', 247.05899999999997, 'yuv.min=', -117.53513)
('yuv.max=', 237.75399999999999, 'yuv.min=', -91.045309999999972)
('yuv.max=', 229.47999999999999, 'yuv.min=', -13.785209999999989)
('yuv.max=', 253.95699999999997, 'yuv.min=', -51.176119999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.84299999999999, 'yuv.min=', -27.830809999999992)
('yuv.max=', 241.16799999999998, 'yuv.min=', -48.719640000000012)
('yuv.max=', 213.63, 'yuv.min=', -19.82025999999999)
('yuv.max=', 247.441, 'yuv.min=', -34.720519999999993)
('yuv.max=', 190.35199999999998, 'yuv.min=', -102.79006999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -34.950419999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.14099999999999, 'yuv.min=', -34.806519999999992)
('yuv.max=', 251.28799999999998, 'yuv.min=', -19.465039999999998)
('yuv.max=', 255.0, 'yuv.min=', -68.622959999999992)
('yuv.max=', 246.90699999999998, 'yuv.min=', -41.685540000000003)
('yuv.max=', 225.03299999999999, 'yuv.min=', -41.657730000000008)
('yuv.max=', 251.69400000000002, 'yuv.min=', -72.417450000000002)
('yuv.max=', 231.70599999999999, 'yuv.min=', -20.244309999999999)
('yuv.max=', 252.64099999999996, 'yuv.min=', -27.635420000000007)
('yuv.max=', 241.49899999999997, 'yuv.min=', -16.560179999999985)
('yuv.max=', 169.755, 'yuv.min=', -60.258319999999998)
('yuv.max=', 247.33099999999999, 'yuv.min=', -82.275539999999978)
('yuv.max=', 250.501, 'yuv.min=', -25.54034)
('yuv.max=', 191.774, 'yuv.min=', -23.365429999999996)
('yuv.max=', 255.0, 'yuv.min=', -49.516199999999998)
('yuv.max=', 239.25999999999999, 'yuv.min=', -40.555549999999982)
('yuv.max=', 255.0, 'yuv.min=', -35.694690000000001)
('yuv.max=', 229.63899999999998, 'yuv.min=', -49.879329999999996)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.525300000000001)
('yuv.max=', 232.50399999999999, 'yuv.min=', -45.750329999999998)
('yuv.max=', 229.85099999999997, 'yuv.min=', -48.631050000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.785849999999996)
('yuv.max=', 251.57599999999999, 'yuv.min=', -30.160309999999981)
('yuv.max=', 207.273, 'yuv.min=', -16.930339999999994)
('yuv.max=', 252.114, 'yuv.min=', -35.255240000000001)
('yuv.max=', 196.22199999999998, 'yuv.min=', -87.164210000000011)
('yuv.max=', 252.31999999999999, 'yuv.min=', -18.375299999999985)
('yuv.max=', 255.0, 'yuv.min=', -40.955589999999994)
('yuv.max=', 180.10499999999999, 'yuv.min=', -71.249809999999997)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 188.11199999999997, 'yuv.min=', -24.499649999999995)
('yuv.max=', 252.78899999999999, 'yuv.min=', -5.2349699999999828)
('yuv.max=', 254.40199999999999, 'yuv.min=', -45.805459999999997)
('yuv.max=', 236.05299999999997, 'yuv.min=', -30.230439999999991)
('yuv.max=', 63.748999999999995, 'yuv.min=', -20.615769999999998)
('yuv.max=', 249.00200000000001, 'yuv.min=', -29.358110000000003)
('yuv.max=', 255.0, 'yuv.min=', -16.458150000000003)
('yuv.max=', 212.80199999999996, 'yuv.min=', -20.920370000000002)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.825559999999996)
('yuv.max=', 188.03099999999998, 'yuv.min=', -75.785079999999994)
('yuv.max=', 226.29399999999998, 'yuv.min=', -63.885299999999987)
('yuv.max=', 212.178, 'yuv.min=', -25.595529999999993)
('yuv.max=', 229.51499999999999, 'yuv.min=', -54.375209999999988)
('yuv.max=', 214.45599999999999, 'yuv.min=', -38.839979999999997)
('yuv.max=', 181.92899999999997, 'yuv.min=', -21.237370000000002)
('yuv.max=', 219.327, 'yuv.min=', -49.56559)
('yuv.max=', 247.53700000000001, 'yuv.min=', -35.665429999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 223.78700000000001, 'yuv.min=', -40.080809999999992)
('yuv.max=', 244.18499999999997, 'yuv.min=', -21.095079999999996)
('yuv.max=', 143.517, 'yuv.min=', -42.01088)
('yuv.max=', 255.0, 'yuv.min=', -27.600570000000001)
('yuv.max=', 192.18099999999998, 'yuv.min=', -32.044340000000005)
('yuv.max=', 255.0, 'yuv.min=', -56.678540000000005)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 236.233, 'yuv.min=', -77.883540000000011)
('yuv.max=', 205.24299999999999, 'yuv.min=', -18.145399999999995)
('yuv.max=', 242.55699999999999, 'yuv.min=', -67.600609999999989)
('yuv.max=', 231.25899999999999, 'yuv.min=', -82.717879999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.309740000000001)
('yuv.max=', 234.99399999999997, 'yuv.min=', -33.939950000000003)
('yuv.max=', 180.321, 'yuv.min=', -20.370930000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.044520000000002)
('yuv.max=', 250.01099999999997, 'yuv.min=', -14.293480000000002)
('yuv.max=', 178.70099999999999, 'yuv.min=', -32.635249999999985)
('yuv.max=', 243.45199999999997, 'yuv.min=', -61.364469999999997)
('yuv.max=', 253.20599999999999, 'yuv.min=', -62.350699999999996)
('yuv.max=', 199.59699999999998, 'yuv.min=', -42.851210000000002)
('yuv.max=', 252.47299999999998, 'yuv.min=', -52.066810000000004)
('yuv.max=', 254.58699999999999, 'yuv.min=', -34.86694)
('yuv.max=', 251.48399999999998, 'yuv.min=', -10.05368)
('yuv.max=', 211.66699999999997, 'yuv.min=', -41.670599999999993)
('yuv.max=', 206.07199999999997, 'yuv.min=', -41.370569999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999988)
('yuv.max=', 255.0, 'yuv.min=', -9.1399299999999997)
('yuv.max=', 222.41900000000001, 'yuv.min=', -28.981339999999999)
('yuv.max=', 239.36099999999999, 'yuv.min=', -50.895449999999997)
('yuv.max=', 145.697, 'yuv.min=', -56.900769999999994)
('yuv.max=', 232.08199999999997, 'yuv.min=', -3.4919300000000106)
('yuv.max=', 255.0, 'yuv.min=', -8.6099999999999888)
('yuv.max=', 240.49900000000002, 'yuv.min=', -18.890289999999993)
('yuv.max=', 237.13299999999998, 'yuv.min=', -28.285429999999991)
('yuv.max=', 242.19999999999999, 'yuv.min=', -40.970529999999997)
('yuv.max=', 221.41399999999999, 'yuv.min=', -30.97533)
('yuv.max=', 236.49399999999997, 'yuv.min=', -60.005649999999996)
('yuv.max=', 245.33099999999996, 'yuv.min=', -6.8650099999999945)
('yuv.max=', 250.01099999999997, 'yuv.min=', -36.360820000000004)
('yuv.max=', 218.57499999999999, 'yuv.min=', -35.360829999999993)
('yuv.max=', 253.886, 'yuv.min=', -17.720050000000001)
('yuv.max=', 241.715, 'yuv.min=', -21.250279999999993)
('yuv.max=', 184.839, 'yuv.min=', -22.180249999999997)
('yuv.max=', 237.596, 'yuv.min=', -54.605109999999982)
('yuv.max=', 235.57599999999999, 'yuv.min=', -78.955699999999993)
('yuv.max=', 246.33099999999999, 'yuv.min=', -46.84581)
('yuv.max=', 255.0, 'yuv.min=', -21.566479999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.415419999999997)
('yuv.max=', 248.804, 'yuv.min=', -29.861509999999999)
('yuv.max=', 199.14199999999997, 'yuv.min=', -20.77467)
('yuv.max=', 221.988, 'yuv.min=', -38.546260000000004)
('yuv.max=', 234.28800000000001, 'yuv.min=', -23.912640000000007)
('yuv.max=', 135.11399999999998, 'yuv.min=', -16.716610000000003)
('yuv.max=', 255.0, 'yuv.min=', -27.074939999999991)
('yuv.max=', 250.79300000000001, 'yuv.min=', -51.75544)
('yuv.max=', 217.77299999999997, 'yuv.min=', -51.010549999999981)
('yuv.max=', 235.08299999999997, 'yuv.min=', -13.685199999999995)
('yuv.max=', 222.04900000000001, 'yuv.min=', -29.130329999999997)
('yuv.max=', 255.0, 'yuv.min=', -36.339219999999997)
('yuv.max=', 253.63200000000001, 'yuv.min=', -51.581020000000002)
('yuv.max=', 253.25599999999997, 'yuv.min=', -36.614909999999995)
('yuv.max=', 222.61899999999997, 'yuv.min=', -106.10343)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.033449999999995)
('yuv.max=', 253.77199999999999, 'yuv.min=', -32.33522)
('yuv.max=', 223.42799999999997, 'yuv.min=', -26.423940000000002)
('yuv.max=', 255.0, 'yuv.min=', -58.895169999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.006240000000005)
('yuv.max=', 247.00599999999997, 'yuv.min=', -91.160259999999994)
('yuv.max=', 225.797, 'yuv.min=', -48.120629999999991)
('yuv.max=', 223.02399999999997, 'yuv.min=', -60.980439999999994)
('yuv.max=', 219.81999999999999, 'yuv.min=', -36.701210000000003)
('yuv.max=', 255.0, 'yuv.min=', -93.235680000000002)
('yuv.max=', 233.52699999999996, 'yuv.min=', -41.455639999999988)
('yuv.max=', 224.12299999999996, 'yuv.min=', -25.372779999999999)
('yuv.max=', 234.369, 'yuv.min=', -29.973199999999999)
('yuv.max=', 255.0, 'yuv.min=', -14.549430000000001)
('yuv.max=', 179.13999999999999, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 245.20999999999998, 'yuv.min=', -29.545309999999997)
('yuv.max=', 230.11199999999999, 'yuv.min=', -5.7902099999999876)
('yuv.max=', 226.88200000000001, 'yuv.min=', -65.270499999999998)
('yuv.max=', 207.84299999999999, 'yuv.min=', -15.853250000000001)
('yuv.max=', 253.21699999999998, 'yuv.min=', -87.591009999999983)
('yuv.max=', 243.804, 'yuv.min=', -29.11186)
('yuv.max=', 252.00999999999999, 'yuv.min=', -57.21573999999999)
('yuv.max=', 233.94, 'yuv.min=', -1.0150399999999999)
('yuv.max=', 248.815, 'yuv.min=', -15.885419999999989)
('yuv.max=', 253.0, 'yuv.min=', -75.855509999999995)
('yuv.max=', 235.83999999999997, 'yuv.min=', -55.415559999999999)
('yuv.max=', 245.33999999999997, 'yuv.min=', -38.104830000000007)
('yuv.max=', 255.0, 'yuv.min=', -85.960079999999991)
('yuv.max=', 207.55399999999997, 'yuv.min=', -47.269770000000008)
('yuv.max=', 255.0, 'yuv.min=', -73.810369999999992)
('yuv.max=', 222.34, 'yuv.min=', -9.5353999999999921)
('yuv.max=', 227.81399999999999, 'yuv.min=', -28.645219999999995)
('yuv.max=', 228.11799999999999, 'yuv.min=', -85.665509999999998)
('yuv.max=', 192.10400000000001, 'yuv.min=', -112.75749999999999)
('yuv.max=', 229.16800000000001, 'yuv.min=', -19.062220000000011)
('yuv.max=', 204.91800000000001, 'yuv.min=', -34.450369999999978)
('yuv.max=', 255.0, 'yuv.min=', -83.719490000000008)
('yuv.max=', 236.44499999999999, 'yuv.min=', -36.495389999999993)
('yuv.max=', 174.11799999999999, 'yuv.min=', -11.855139999999999)
('yuv.max=', 220.78199999999998, 'yuv.min=', -47.050399999999982)
('yuv.max=', 201.69699999999997, 'yuv.min=', -31.960489999999993)
('yuv.max=', 255.0, 'yuv.min=', -22.221220000000002)
('yuv.max=', 240.24499999999998, 'yuv.min=', -24.640249999999991)
('yuv.max=', 224.02100000000002, 'yuv.min=', -35.783100000000005)
('yuv.max=', 252.17400000000001, 'yuv.min=', -32.490419999999986)
('yuv.max=', 236.52000000000001, 'yuv.min=', -25.625409999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.227360000000004)
('yuv.max=', 238.60799999999998, 'yuv.min=', -48.450539999999982)
('yuv.max=', 233.99099999999999, 'yuv.min=', -17.205059999999989)
('yuv.max=', 253.25599999999997, 'yuv.min=', -47.773820000000001)
('yuv.max=', 186.19899999999998, 'yuv.min=', -81.705359999999985)
('yuv.max=', 227.38, 'yuv.min=', -18.08436)
('yuv.max=', 223.00699999999998, 'yuv.min=', -41.93618)
('yuv.max=', 254.40199999999999, 'yuv.min=', -65.255209999999991)
('yuv.max=', 238.53499999999997, 'yuv.min=', -88.695689999999985)
('yuv.max=', 245.03199999999998, 'yuv.min=', -27.929869999999998)
('yuv.max=', 231.02599999999998, 'yuv.min=', -44.045530000000007)
('yuv.max=', 127.95, 'yuv.min=', -40.555549999999997)
('yuv.max=', 225.86199999999999, 'yuv.min=', -25.840370000000004)
('yuv.max=', 176.495, 'yuv.min=', -19.094879999999996)
('yuv.max=', 255.0, 'yuv.min=', -14.100179999999991)
('yuv.max=', 253.0, 'yuv.min=', -19.135129999999993)
('yuv.max=', 246.09700000000001, 'yuv.min=', -15.56588)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -23.237720000000007)
('yuv.max=', 254.18499999999997, 'yuv.min=', -67.730499999999992)
('yuv.max=', 234.70299999999997, 'yuv.min=', -62.220809999999993)
('yuv.max=', 245.63, 'yuv.min=', -8.6099999999999959)
('yuv.max=', 255.0, 'yuv.min=', -13.315039999999996)
('yuv.max=', 207.40299999999999, 'yuv.min=', -10.425119999999989)
('yuv.max=', 174.38499999999999, 'yuv.min=', -35.30563999999999)
('yuv.max=', 252.63, 'yuv.min=', -37.89552999999998)
('yuv.max=', 215.02599999999998, 'yuv.min=', -82.183120000000002)
('yuv.max=', 252.608, 'yuv.min=', -36.835669999999986)
('yuv.max=', 255.0, 'yuv.min=', -26.840470000000003)
('yuv.max=', 251.24699999999999, 'yuv.min=', -26.25535)
('yuv.max=', 250.18499999999997, 'yuv.min=', -31.504259999999999)
('yuv.max=', 232.93099999999998, 'yuv.min=', -16.255809999999997)
('yuv.max=', 216.87899999999999, 'yuv.min=', -21.080139999999993)
('yuv.max=', 235.08199999999999, 'yuv.min=', -25.308600000000002)
('yuv.max=', 252.989, 'yuv.min=', -40.25551999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.705009999999991)
('yuv.max=', 245.98399999999998, 'yuv.min=', -49.950689999999994)
('yuv.max=', 238.28799999999998, 'yuv.min=', -15.280210000000004)
('yuv.max=', 239.488, 'yuv.min=', -15.215229999999991)
('yuv.max=', 252.28800000000001, 'yuv.min=', -21.253010000000003)
('yuv.max=', 199.90600000000001, 'yuv.min=', -49.695479999999989)
('yuv.max=', 242.79299999999998, 'yuv.min=', -23.110219999999998)
('yuv.max=', 207.19099999999997, 'yuv.min=', -9.0399199999999897)
('yuv.max=', 210.55700000000002, 'yuv.min=', -15.133760000000001)
('yuv.max=', 255.0, 'yuv.min=', -8.7227000000000032)
('yuv.max=', 243.19499999999999, 'yuv.min=', -27.770439999999997)
('yuv.max=', 246.48399999999998, 'yuv.min=', -37.355649999999997)
('yuv.max=', 239.89699999999999, 'yuv.min=', -20.775539999999992)
('yuv.max=', 178.82099999999997, 'yuv.min=', -11.046079999999996)
('yuv.max=', 225.01799999999997, 'yuv.min=', -72.35136)
('yuv.max=', 255.0, 'yuv.min=', -46.439970000000002)
('yuv.max=', 255.0, 'yuv.min=', -48.453850000000003)
('yuv.max=', 189.88999999999999, 'yuv.min=', -11.077830000000006)
('yuv.max=', 222.26399999999998, 'yuv.min=', -23.380369999999999)
('yuv.max=', 231.24899999999997, 'yuv.min=', -46.650359999999992)
('yuv.max=', 163.60899999999998, 'yuv.min=', -1.5954600000000028)
('yuv.max=', 239.09299999999996, 'yuv.min=', -26.352980000000002)
('yuv.max=', 244.89200000000002, 'yuv.min=', -86.550660000000008)
('yuv.max=', 240.28800000000001, 'yuv.min=', -14.95364)
('yuv.max=', 248.59799999999998, 'yuv.min=', -44.460509999999999)
('yuv.max=', 247.28400000000002, 'yuv.min=', -27.315209999999983)
('yuv.max=', 209.727, 'yuv.min=', -39.428609999999999)
('yuv.max=', 217.02199999999999, 'yuv.min=', -32.260519999999993)
('yuv.max=', 250.51999999999998, 'yuv.min=', -25.444710000000004)
('yuv.max=', 211.74299999999999, 'yuv.min=', -10.641559999999998)
('yuv.max=', 242.06799999999998, 'yuv.min=', -53.479530000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.66187)
('yuv.max=', 229.94599999999997, 'yuv.min=', -51.310580000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.365979999999993)
('yuv.max=', 205.94499999999999, 'yuv.min=', -53.565489999999997)
('yuv.max=', 215.08600000000001, 'yuv.min=', -30.382569999999998)
('yuv.max=', 232.66200000000001, 'yuv.min=', -26.615139999999997)
('yuv.max=', 251.41199999999998, 'yuv.min=', -20.680099999999996)
('yuv.max=', 250.06399999999996, 'yuv.min=', -22.571820000000002)
('yuv.max=', 233.91499999999999, 'yuv.min=', -42.01544999999998)
('yuv.max=', 198.041, 'yuv.min=', -31.022600000000004)
('yuv.max=', 224.36799999999997, 'yuv.min=', -53.255589999999998)
('yuv.max=', 247.34199999999998, 'yuv.min=', -27.440529999999992)
('yuv.max=', 239.44099999999997, 'yuv.min=', -38.740429999999989)
('yuv.max=', 218.006, 'yuv.min=', -28.44791)
('yuv.max=', 242.82599999999999, 'yuv.min=', -15.030149999999997)
('yuv.max=', 235.90399999999997, 'yuv.min=', -35.015029999999996)
('yuv.max=', 200.05099999999999, 'yuv.min=', -23.306490000000004)
('yuv.max=', 230.85999999999999, 'yuv.min=', -79.800599999999989)
('yuv.max=', 246.93900000000002, 'yuv.min=', -39.070339999999987)
('yuv.max=', 150.93699999999998, 'yuv.min=', -58.034939999999999)
('yuv.max=', 251.113, 'yuv.min=', -70.935389999999984)
('yuv.max=', 131.19800000000001, 'yuv.min=', -13.95478)
('yuv.max=', 252.49200000000002, 'yuv.min=', -57.729520000000008)
('yuv.max=', 228.09599999999998, 'yuv.min=', -55.26493)
('yuv.max=', 214.042, 'yuv.min=', -10.454999999999981)
('yuv.max=', 216.50900000000001, 'yuv.min=', -14.40020999999998)
('yuv.max=', 241.75599999999997, 'yuv.min=', -64.875029999999995)
('yuv.max=', 237.59799999999998, 'yuv.min=', -67.885699999999986)
('yuv.max=', 234.48099999999999, 'yuv.min=', -44.040289999999999)
('yuv.max=', 170.94399999999999, 'yuv.min=', -53.201340000000002)
('yuv.max=', 227.58999999999997, 'yuv.min=', -38.570289999999993)
('yuv.max=', 249.30099999999999, 'yuv.min=', -31.154830000000004)
('yuv.max=', 238.94999999999999, 'yuv.min=', -23.574660000000002)
('yuv.max=', 217.64699999999999, 'yuv.min=', -56.670869999999994)
('yuv.max=', 249.733, 'yuv.min=', -34.535439999999994)
('yuv.max=', 203.46899999999999, 'yuv.min=', -9.4540900000000008)
('yuv.max=', 255.0, 'yuv.min=', -6.9799599999999966)
('yuv.max=', 181.749, 'yuv.min=', -14.930139999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -21.050259999999991)
('yuv.max=', 247.548, 'yuv.min=', -26.415119999999995)
('yuv.max=', 255.0, 'yuv.min=', -77.486040000000003)
('yuv.max=', 251.79299999999998, 'yuv.min=', -18.479309999999998)
('yuv.max=', 225.642, 'yuv.min=', -36.735659999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.305540000000008)
('yuv.max=', 207.23299999999998, 'yuv.min=', -29.913629999999998)
('yuv.max=', 211.85099999999997, 'yuv.min=', -35.432960000000008)
('yuv.max=', 242.821, 'yuv.min=', -40.67569000000001)
('yuv.max=', 226.28999999999999, 'yuv.min=', -21.635379999999998)
('yuv.max=', 222.82499999999999, 'yuv.min=', -44.045529999999999)
('yuv.max=', 237.41199999999998, 'yuv.min=', -31.475379999999994)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.95599)
('yuv.max=', 217.57899999999998, 'yuv.min=', -36.140169999999991)
('yuv.max=', 252.52699999999996, 'yuv.min=', -23.580389999999987)
('yuv.max=', 245.49799999999999, 'yuv.min=', -24.225269999999988)
('yuv.max=', 236.18899999999999, 'yuv.min=', -14.930139999999984)
('yuv.max=', 241.63199999999998, 'yuv.min=', -38.435920000000003)
('yuv.max=', 248.21800000000002, 'yuv.min=', -16.609940000000002)
('yuv.max=', 244.85299999999998, 'yuv.min=', -63.065709999999989)
('yuv.max=', 235.63399999999999, 'yuv.min=', -49.370200000000011)
('yuv.max=', 236.04500000000002, 'yuv.min=', -34.180219999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.683690000000004)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.48400000000001, 'yuv.min=', -87.280609999999996)
('yuv.max=', 219.21799999999999, 'yuv.min=', -20.555190000000003)
('yuv.max=', 255.0, 'yuv.min=', -72.842430000000007)
('yuv.max=', 230.12899999999996, 'yuv.min=', -16.375100000000003)
('yuv.max=', 105.67999999999999, 'yuv.min=', -7.6708899999999964)
('yuv.max=', 238.51199999999997, 'yuv.min=', -79.229519999999994)
('yuv.max=', 236.084, 'yuv.min=', -73.392080000000007)
('yuv.max=', 253.77199999999999, 'yuv.min=', -39.38530999999999)
('yuv.max=', 201.33099999999999, 'yuv.min=', -52.291040000000002)
('yuv.max=', 248.38999999999999, 'yuv.min=', -37.149919999999995)
('yuv.max=', 253.505, 'yuv.min=', -29.300469999999994)
('yuv.max=', 207.416, 'yuv.min=', -8.3367199999999997)
('yuv.max=', 248.48799999999997, 'yuv.min=', -21.905529999999988)
('yuv.max=', 243.619, 'yuv.min=', -24.795449999999988)
('yuv.max=', 192.15600000000001, 'yuv.min=', -22.035419999999984)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.435570000000002)
('yuv.max=', 243.22800000000001, 'yuv.min=', -44.990439999999985)
('yuv.max=', 219.06999999999999, 'yuv.min=', -17.820059999999994)
('yuv.max=', 212.80399999999997, 'yuv.min=', -95.51948999999999)
('yuv.max=', 227.25299999999999, 'yuv.min=', -19.175379999999997)
('yuv.max=', 247.81699999999998, 'yuv.min=', -23.780409999999989)
('yuv.max=', 196.797, 'yuv.min=', -17.219999999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 255.0, 'yuv.min=', -30.273140000000001)
('yuv.max=', 255.0, 'yuv.min=', -10.162979999999997)
('yuv.max=', 195.47699999999998, 'yuv.min=', -24.12525999999999)
('yuv.max=', 242.03699999999998, 'yuv.min=', -27.407880000000002)
('yuv.max=', 248.33099999999999, 'yuv.min=', -55.920179999999988)
('yuv.max=', 247.529, 'yuv.min=', -52.325619999999994)
('yuv.max=', 123.985, 'yuv.min=', -9.3020399999999981)
('yuv.max=', 240.37899999999999, 'yuv.min=', -47.587590000000006)
('yuv.max=', 241.20399999999998, 'yuv.min=', -41.951610000000002)
('yuv.max=', 224.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.26399999999995, 'yuv.min=', -39.101939999999999)
('yuv.max=', 245.684, 'yuv.min=', -54.920079999999992)
('yuv.max=', 226.62099999999998, 'yuv.min=', -101.91767)
('yuv.max=', 247.68499999999997, 'yuv.min=', -45.701189999999997)
('yuv.max=', 240.38099999999997, 'yuv.min=', -17.323450000000001)
('yuv.max=', 188.13599999999997, 'yuv.min=', -16.245209999999997)
('yuv.max=', 210.38999999999999, 'yuv.min=', -34.566549999999992)
('yuv.max=', 242.44200000000001, 'yuv.min=', -65.970569999999981)
('yuv.max=', 255.0, 'yuv.min=', -11.399909999999997)
('yuv.max=', 243.05599999999998, 'yuv.min=', -33.330269999999999)
('yuv.max=', 234.542, 'yuv.min=', -13.378679999999999)
('yuv.max=', 247.95000000000002, 'yuv.min=', -64.106090000000009)
('yuv.max=', 196.00999999999999, 'yuv.min=', -27.400279999999988)
('yuv.max=', 242.24299999999999, 'yuv.min=', -55.544059999999995)
('yuv.max=', 248.07499999999996, 'yuv.min=', -46.739999999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.84836)
('yuv.max=', 242.03299999999999, 'yuv.min=', -95.035339999999991)
('yuv.max=', 236.25699999999998, 'yuv.min=', -15.968030000000001)
('yuv.max=', 212.0, 'yuv.min=', -18.778709999999997)
('yuv.max=', 255.0, 'yuv.min=', -14.43074)
('yuv.max=', 253.08799999999999, 'yuv.min=', -17.41545)
('yuv.max=', 250.03200000000001, 'yuv.min=', -23.259359999999997)
('yuv.max=', 255.0, 'yuv.min=', -25.810489999999991)
('yuv.max=', 223.07099999999997, 'yuv.min=', -6.4241700000000037)
('yuv.max=', 255.0, 'yuv.min=', -40.964729999999996)
('yuv.max=', 245.09100000000001, 'yuv.min=', -79.883209999999991)
('yuv.max=', 226.05800000000002, 'yuv.min=', -44.960300000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.485249999999994)
('yuv.max=', 199.35899999999998, 'yuv.min=', -29.245279999999987)
('yuv.max=', 224.85799999999998, 'yuv.min=', -25.025349999999992)
('yuv.max=', 241.334, 'yuv.min=', -31.60526999999999)
('yuv.max=', 230.06899999999996, 'yuv.min=', -27.904899999999984)
('yuv.max=', 230.37399999999997, 'yuv.min=', -14.467530000000004)
('yuv.max=', 231.28800000000001, 'yuv.min=', -91.785629999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.665430000000001)
('yuv.max=', 203.69, 'yuv.min=', -35.465409999999999)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 252.89699999999999, 'yuv.min=', -21.395109999999995)
('yuv.max=', 205.94999999999999, 'yuv.min=', -47.216260000000005)
('yuv.max=', 242.643, 'yuv.min=', -32.99960999999999)
('yuv.max=', 194.29499999999999, 'yuv.min=', -38.525469999999991)
('yuv.max=', 253.82599999999996, 'yuv.min=', -14.740220000000001)
('yuv.max=', 192.072, 'yuv.min=', -21.411070000000002)
('yuv.max=', 253.72899999999996, 'yuv.min=', -24.578320000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.910920000000004)
('yuv.max=', 219.40799999999996, 'yuv.min=', -116.92012999999999)
('yuv.max=', 211.79900000000001, 'yuv.min=', -41.375139999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.493200000000002)
('yuv.max=', 254.131, 'yuv.min=', -30.560349999999993)
('yuv.max=', 249.84299999999999, 'yuv.min=', -32.3887)
('yuv.max=', 198.529, 'yuv.min=', -70.835379999999986)
('yuv.max=', 255.0, 'yuv.min=', -1.1299899999999941)
('yuv.max=', 194.81399999999999, 'yuv.min=', -20.337510000000009)
('yuv.max=', 192.91200000000001, 'yuv.min=', -12.540269999999996)
('yuv.max=', 146.27700000000002, 'yuv.min=', -15.400309999999994)
('yuv.max=', 243.0, 'yuv.min=', -37.465609999999998)
('yuv.max=', 251.77199999999999, 'yuv.min=', -15.302290000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.9949999999999868)
('yuv.max=', 255.0, 'yuv.min=', -22.695239999999988)
('yuv.max=', 246.64999999999998, 'yuv.min=', -42.645389999999992)
('yuv.max=', 252.48999999999998, 'yuv.min=', -26.310539999999996)
('yuv.max=', 214.328, 'yuv.min=', -10.925310000000003)
('yuv.max=', 231.85399999999996, 'yuv.min=', -18.43506)
('yuv.max=', 182.50099999999998, 'yuv.min=', -24.865579999999984)
('yuv.max=', 209.06799999999998, 'yuv.min=', -31.111840000000008)
('yuv.max=', 217.86399999999998, 'yuv.min=', -31.145469999999996)
('yuv.max=', 232.14399999999998, 'yuv.min=', -30.890259999999998)
('yuv.max=', 169.60999999999999, 'yuv.min=', -32.811630000000001)
('yuv.max=', 232.38399999999996, 'yuv.min=', -45.554819999999999)
('yuv.max=', 247.47099999999998, 'yuv.min=', -66.580080000000009)
('yuv.max=', 253.80399999999997, 'yuv.min=', -12.670159999999989)
('yuv.max=', 178.28799999999998, 'yuv.min=', -17.182500000000001)
('yuv.max=', 206.29399999999998, 'yuv.min=', -27.455469999999995)
('yuv.max=', 235.06, 'yuv.min=', -17.260249999999999)
('yuv.max=', 223.10199999999998, 'yuv.min=', -17.186849999999993)
('yuv.max=', 255.0, 'yuv.min=', -38.334159999999997)
('yuv.max=', 248.70099999999999, 'yuv.min=', -32.475479999999997)
('yuv.max=', 167.815, 'yuv.min=', -79.626850000000005)
('yuv.max=', 146.19699999999997, 'yuv.min=', -14.600230000000003)
('yuv.max=', 253.70099999999996, 'yuv.min=', -25.250679999999996)
('yuv.max=', 234.03200000000001, 'yuv.min=', -12.814989999999996)
('yuv.max=', 253.52699999999999, 'yuv.min=', -5.2200299999999995)
('yuv.max=', 235.90299999999999, 'yuv.min=', -29.672900000000006)
('yuv.max=', 201.715, 'yuv.min=', -38.325449999999996)
('yuv.max=', 226.67499999999998, 'yuv.min=', -27.800320000000003)
('yuv.max=', 252.0, 'yuv.min=', -9.4534699999999958)
('yuv.max=', 250.12700000000001, 'yuv.min=', -21.384009999999996)
('yuv.max=', 237.32299999999998, 'yuv.min=', -31.890359999999994)
('yuv.max=', 249.78200000000001, 'yuv.min=', -36.925309999999996)
('yuv.max=', 249.05299999999997, 'yuv.min=', -58.871089999999995)
('yuv.max=', 241.548, 'yuv.min=', -39.805400000000006)
('yuv.max=', 239.27099999999999, 'yuv.min=', -80.000619999999998)
('yuv.max=', 255.0, 'yuv.min=', -53.540679999999988)
('yuv.max=', 234.70400000000001, 'yuv.min=', -23.961909999999996)
('yuv.max=', 128.86499999999998, 'yuv.min=', -35.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -62.120799999999988)
('yuv.max=', 208.19599999999997, 'yuv.min=', -26.280659999999994)
('yuv.max=', 205.57599999999999, 'yuv.min=', -24.610369999999993)
('yuv.max=', 255.0, 'yuv.min=', -21.150270000000003)
('yuv.max=', 232.017, 'yuv.min=', -58.709830000000011)
('yuv.max=', 242.91799999999998, 'yuv.min=', -27.210629999999995)
('yuv.max=', 231.14199999999997, 'yuv.min=', -73.805800000000005)
('yuv.max=', 242.68999999999997, 'yuv.min=', -15.849739999999994)
('yuv.max=', 234.214, 'yuv.min=', -24.265519999999999)
('yuv.max=', 252.036, 'yuv.min=', -36.48044999999999)
('yuv.max=', 187.53, 'yuv.min=', -42.685639999999999)
('yuv.max=', 224.88299999999998, 'yuv.min=', -43.945520000000002)
('yuv.max=', 246.55199999999999, 'yuv.min=', -18.064899999999994)
('yuv.max=', 244.47300000000001, 'yuv.min=', -60.020589999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.619660000000007)
('yuv.max=', 246.95999999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -32.061410000000009)
('yuv.max=', 242.91799999999998, 'yuv.min=', -20.675010000000015)
('yuv.max=', 231.86600000000001, 'yuv.min=', -15.421110000000013)
('yuv.max=', 237.21599999999998, 'yuv.min=', -40.137010000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.86900000000003, 'yuv.min=', -40.825699999999991)
('yuv.max=', 246.744, 'yuv.min=', -38.755369999999992)
('yuv.max=', 223.72900000000001, 'yuv.min=', -40.640619999999998)
('yuv.max=', 226.68799999999999, 'yuv.min=', -34.044260000000001)
('yuv.max=', 251.44499999999996, 'yuv.min=', -9.3652599999999957)
('yuv.max=', 161.93999999999997, 'yuv.min=', -9.7436700000000052)
('yuv.max=', 254.35900000000001, 'yuv.min=', -55.021319999999996)
('yuv.max=', 252.68599999999998, 'yuv.min=', -20.641079999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.936579999999999)
('yuv.max=', 186.77199999999999, 'yuv.min=', -20.937799999999999)
('yuv.max=', 169.56800000000001, 'yuv.min=', -36.26549)
('yuv.max=', 219.88099999999997, 'yuv.min=', -56.159570000000002)
('yuv.max=', 218.16, 'yuv.min=', -49.211160000000007)
('yuv.max=', 243.33099999999999, 'yuv.min=', -27.85435)
('yuv.max=', 182.37299999999999, 'yuv.min=', -41.445269999999994)
('yuv.max=', 240.19499999999996, 'yuv.min=', -25.706570000000003)
('yuv.max=', 255.0, 'yuv.min=', -32.335219999999993)
('yuv.max=', 247.70699999999999, 'yuv.min=', -61.603790000000004)
('yuv.max=', 219.13999999999999, 'yuv.min=', -15.730220000000003)
('yuv.max=', 251.50500000000002, 'yuv.min=', -57.767760000000003)
('yuv.max=', 187.43100000000001, 'yuv.min=', -27.967719999999996)
('yuv.max=', 251.48399999999998, 'yuv.min=', -42.25571999999999)
('yuv.max=', 233.46299999999997, 'yuv.min=', -29.000439999999998)
('yuv.max=', 226.22799999999998, 'yuv.min=', -26.31510999999999)
('yuv.max=', 242.75500000000002, 'yuv.min=', -38.355329999999995)
('yuv.max=', 236.22799999999998, 'yuv.min=', -26.855409999999988)
('yuv.max=', 230.02699999999999, 'yuv.min=', -51.791119999999992)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 241.12099999999998, 'yuv.min=', -19.383939999999996)
('yuv.max=', 252.202, 'yuv.min=', -20.348179999999999)
('yuv.max=', 250.18499999999997, 'yuv.min=', -34.584829999999997)
('yuv.max=', 235.73599999999999, 'yuv.min=', -60.085030000000003)
('yuv.max=', 255.0, 'yuv.min=', -18.820159999999984)
('yuv.max=', 223.87900000000002, 'yuv.min=', -42.414560000000009)
('yuv.max=', 254.17400000000001, 'yuv.min=', -65.695849999999993)
('yuv.max=', 233.31799999999998, 'yuv.min=', -19.090309999999995)
('yuv.max=', 188.881, 'yuv.min=', -81.343759999999989)
('yuv.max=', 164.822, 'yuv.min=', -54.030360000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.24399999999997, 'yuv.min=', -109.02513999999999)
('yuv.max=', 255.0, 'yuv.min=', -56.073400000000007)
('yuv.max=', 241.14600000000002, 'yuv.min=', -49.21623000000001)
('yuv.max=', 169.10899999999998, 'yuv.min=', -44.354190000000003)
('yuv.max=', 255.0, 'yuv.min=', -14.144999999999992)
('yuv.max=', 249.01999999999998, 'yuv.min=', -56.35132999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', -22.705609999999989)
('yuv.max=', 186.97799999999998, 'yuv.min=', -37.480549999999994)
('yuv.max=', 251.113, 'yuv.min=', -37.749150000000007)
('yuv.max=', 210.34799999999998, 'yuv.min=', -25.840369999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.400649999999999)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 203.17999999999998, 'yuv.min=', -52.731660000000005)
('yuv.max=', 246.08299999999997, 'yuv.min=', -9.4319400000000115)
('yuv.max=', 218.84199999999998, 'yuv.min=', -52.824670000000012)
('yuv.max=', 247.078, 'yuv.min=', -34.282920000000004)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.350070000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 210.542, 'yuv.min=', -58.39054999999999)
('yuv.max=', 239.94999999999999, 'yuv.min=', -20.605399999999996)
('yuv.max=', 239.14699999999999, 'yuv.min=', -32.535240000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.415219999999998)
('yuv.max=', 239.29999999999998, 'yuv.min=', -22.827349999999999)
('yuv.max=', 212.09200000000001, 'yuv.min=', -26.500189999999986)
('yuv.max=', 189.87800000000001, 'yuv.min=', -91.960130000000007)
('yuv.max=', 234.95599999999996, 'yuv.min=', -37.074289999999998)
('yuv.max=', 203.03200000000001, 'yuv.min=', -19.435159999999996)
('yuv.max=', 234.755, 'yuv.min=', -19.205259999999996)
('yuv.max=', 137.67399999999998, 'yuv.min=', -50.791019999999989)
('yuv.max=', 240.00799999999998, 'yuv.min=', -17.318050000000007)
('yuv.max=', 233.82899999999998, 'yuv.min=', -53.164719999999996)
('yuv.max=', 208.672, 'yuv.min=', -36.84023999999998)
('yuv.max=', 227.22900000000001, 'yuv.min=', -60.017719999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.7100099999999951)
('yuv.max=', 246.60299999999998, 'yuv.min=', -47.020519999999991)
('yuv.max=', 248.96099999999998, 'yuv.min=', -53.885529999999996)
('yuv.max=', 242.232, 'yuv.min=', -47.025089999999999)
('yuv.max=', 207.78699999999998, 'yuv.min=', -20.350189999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.511020000000002)
('yuv.max=', 252.92899999999997, 'yuv.min=', -24.85521)
('yuv.max=', 234.52999999999997, 'yuv.min=', -35.235509999999991)
('yuv.max=', 236.017, 'yuv.min=', -29.444099999999999)
('yuv.max=', 240.76300000000001, 'yuv.min=', -46.714579999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.0013000000000005)
('yuv.max=', 178.70699999999999, 'yuv.min=', -44.305309999999992)
('yuv.max=', 200.83099999999999, 'yuv.min=', -21.814159999999987)
('yuv.max=', 224.07999999999998, 'yuv.min=', -24.931839999999998)
('yuv.max=', 248.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 236.52100000000002, 'yuv.min=', -34.365299999999991)
('yuv.max=', 212.45999999999998, 'yuv.min=', -62.280569999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.760099999999987)
('yuv.max=', 200.328, 'yuv.min=', -29.9466)
('yuv.max=', 248.755, 'yuv.min=', -11.495349999999991)
('yuv.max=', 247.80399999999997, 'yuv.min=', -16.175079999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.085139999999996)
('yuv.max=', 215.70999999999998, 'yuv.min=', -7.6650899999999922)
('yuv.max=', 242.72200000000001, 'yuv.min=', -40.955589999999994)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.679830000000003)
('yuv.max=', 241.68099999999998, 'yuv.min=', -64.725629999999995)
('yuv.max=', 254.11399999999998, 'yuv.min=', -22.34985)
('yuv.max=', 241.733, 'yuv.min=', -4.6050299999999922)
('yuv.max=', 252.31999999999999, 'yuv.min=', -40.880889999999994)
('yuv.max=', 244.70100000000002, 'yuv.min=', -20.050159999999984)
('yuv.max=', 202.63199999999998, 'yuv.min=', -29.855709999999995)
('yuv.max=', 225.29000000000002, 'yuv.min=', -37.359799999999979)
('yuv.max=', 255.0, 'yuv.min=', -39.710649999999994)
('yuv.max=', 249.142, 'yuv.min=', -39.144829999999992)
('yuv.max=', 226.91999999999999, 'yuv.min=', -27.230139999999984)
('yuv.max=', 255.0, 'yuv.min=', -36.395379999999989)
('yuv.max=', 242.37199999999999, 'yuv.min=', -53.800660000000008)
('yuv.max=', 196.16800000000001, 'yuv.min=', -19.646320000000003)
('yuv.max=', 255.0, 'yuv.min=', -6.6149000000000022)
('yuv.max=', 243.929, 'yuv.min=', -24.895459999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -27.745129999999996)
('yuv.max=', 245.03199999999998, 'yuv.min=', -5.0200099999999779)
('yuv.max=', 255.0, 'yuv.min=', -13.814349999999997)
('yuv.max=', 252.28800000000001, 'yuv.min=', -22.087420000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.840269999999986)
('yuv.max=', 245.488, 'yuv.min=', -18.790279999999989)
('yuv.max=', 238.815, 'yuv.min=', -75.985279999999989)
('yuv.max=', 253.87500000000003, 'yuv.min=', -80.145449999999997)
('yuv.max=', 196.136, 'yuv.min=', -29.368479999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.455299999999994)
('yuv.max=', 251.92899999999995, 'yuv.min=', -42.066370000000006)
('yuv.max=', 254.65800000000002, 'yuv.min=', -17.874340000000004)
('yuv.max=', 242.54400000000001, 'yuv.min=', -26.910599999999999)
('yuv.max=', 211.28299999999999, 'yuv.min=', -29.730390000000003)
('yuv.max=', 230.89399999999998, 'yuv.min=', -22.910199999999982)
('yuv.max=', 195.85499999999999, 'yuv.min=', -35.820629999999987)
('yuv.max=', 248.97900000000001, 'yuv.min=', -23.150469999999988)
('yuv.max=', 235.958, 'yuv.min=', -64.055440000000004)
('yuv.max=', 241.245, 'yuv.min=', -42.145340000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.392479999999999)
('yuv.max=', 235.04399999999998, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 232.721, 'yuv.min=', -0.88515000000000299)
('yuv.max=', 254.40199999999999, 'yuv.min=', -69.839209999999994)
('yuv.max=', 204.905, 'yuv.min=', -55.358320000000006)
('yuv.max=', 183.33999999999997, 'yuv.min=', -36.635649999999998)
('yuv.max=', 255.0, 'yuv.min=', -21.665259999999989)
('yuv.max=', 255.0, 'yuv.min=', -9.8250599999999935)
('yuv.max=', 229.59299999999999, 'yuv.min=', -37.140269999999987)
('yuv.max=', 254.77200000000002, 'yuv.min=', -30.96039)
('yuv.max=', 255.0, 'yuv.min=', -8.315940000000003)
('yuv.max=', 216.959, 'yuv.min=', -9.6007199999999955)
('yuv.max=', 255.0, 'yuv.min=', -8.1732300000000038)
('yuv.max=', 235.53899999999999, 'yuv.min=', -34.799590000000002)
('yuv.max=', 204.65099999999998, 'yuv.min=', -22.250379999999986)
('yuv.max=', 225.08199999999999, 'yuv.min=', -27.520690000000005)
('yuv.max=', 237.57799999999997, 'yuv.min=', -23.410629999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.43526)
('yuv.max=', 231.13099999999997, 'yuv.min=', -6.1350599999999957)
('yuv.max=', 252.309, 'yuv.min=', -49.076009999999997)
('yuv.max=', 252.15200000000002, 'yuv.min=', -45.78595)
('yuv.max=', 245.41300000000001, 'yuv.min=', -26.770339999999987)
('yuv.max=', 243.971, 'yuv.min=', -42.909100000000002)
('yuv.max=', 237.49099999999999, 'yuv.min=', -30.990269999999988)
('yuv.max=', 149.28999999999999, 'yuv.min=', -35.931009999999993)
('yuv.max=', 224.703, 'yuv.min=', -33.465209999999978)
('yuv.max=', 186.13299999999998, 'yuv.min=', -27.493270000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.54400000000001, 'yuv.min=', -16.234839999999995)
('yuv.max=', 255.0, 'yuv.min=', -29.790149999999986)
('yuv.max=', 237.59799999999998, 'yuv.min=', -13.455300000000001)
('yuv.max=', 243.34099999999998, 'yuv.min=', -91.028689999999997)
('yuv.max=', 216.398, 'yuv.min=', -41.930379999999992)
('yuv.max=', 255.0, 'yuv.min=', -29.897940000000002)
('yuv.max=', 190.43899999999999, 'yuv.min=', -50.599990000000005)
('yuv.max=', 201.637, 'yuv.min=', -26.670329999999996)
('yuv.max=', 203.94299999999998, 'yuv.min=', -31.060399999999991)
('yuv.max=', 177.93899999999999, 'yuv.min=', -16.160139999999998)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.99999999999997, 'yuv.min=', -56.64473000000001)
('yuv.max=', 199.0, 'yuv.min=', -10.909989999999997)
('yuv.max=', 245.20599999999999, 'yuv.min=', -42.299309999999991)
('yuv.max=', 209.441, 'yuv.min=', -40.570489999999992)
('yuv.max=', 238.15199999999999, 'yuv.min=', -43.760440000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -46.705549999999988)
('yuv.max=', 251.43199999999996, 'yuv.min=', -24.095379999999995)
('yuv.max=', 234.05799999999999, 'yuv.min=', -31.605269999999997)
('yuv.max=', 226.12799999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 207.92899999999997, 'yuv.min=', -32.452109999999998)
('yuv.max=', 199.352, 'yuv.min=', -60.235549999999996)
('yuv.max=', 247.02599999999998, 'yuv.min=', -35.210049999999995)
('yuv.max=', 237.07499999999999, 'yuv.min=', -49.520769999999999)
('yuv.max=', 222.78899999999999, 'yuv.min=', -40.28446000000001)
('yuv.max=', 250.57599999999996, 'yuv.min=', -36.595399999999984)
('yuv.max=', 233.92100000000002, 'yuv.min=', -11.340150000000001)
('yuv.max=', 255.0, 'yuv.min=', -42.970730000000003)
('yuv.max=', 216.01900000000001, 'yuv.min=', -26.425489999999986)
('yuv.max=', 235.62699999999998, 'yuv.min=', -39.065770000000001)
('yuv.max=', 237.017, 'yuv.min=', -54.160249999999984)
('yuv.max=', 253.80399999999997, 'yuv.min=', -24.713659999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 219.99099999999999, 'yuv.min=', -45.43072999999999)
('yuv.max=', 232.04299999999998, 'yuv.min=', -54.555719999999994)
('yuv.max=', 234.339, 'yuv.min=', -36.955189999999995)
('yuv.max=', 240.97799999999998, 'yuv.min=', -30.899399999999996)
('yuv.max=', 226.04000000000002, 'yuv.min=', -25.925439999999995)
('yuv.max=', 240.70599999999999, 'yuv.min=', -26.125459999999993)
('yuv.max=', 226.06099999999998, 'yuv.min=', -16.545239999999993)
('yuv.max=', 211.41, 'yuv.min=', -46.735429999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.550179999999997)
('yuv.max=', 201.21199999999999, 'yuv.min=', -19.505289999999984)
('yuv.max=', 226.12499999999997, 'yuv.min=', -42.945419999999999)
('yuv.max=', 243.60399999999998, 'yuv.min=', -50.83466)
('yuv.max=', 169.40899999999999, 'yuv.min=', -18.420120000000001)
('yuv.max=', 188.97699999999998, 'yuv.min=', -22.55594)
('yuv.max=', 247.90099999999998, 'yuv.min=', -15.573870000000005)
('yuv.max=', 148.98099999999999, 'yuv.min=', -38.625479999999989)
('yuv.max=', 253.13099999999997, 'yuv.min=', -72.320589999999996)
('yuv.max=', 255.0, 'yuv.min=', -66.62581999999999)
('yuv.max=', 251.15300000000002, 'yuv.min=', -57.767539999999997)
('yuv.max=', 225.15999999999997, 'yuv.min=', -44.375439999999998)
('yuv.max=', 252.114, 'yuv.min=', -15.273999999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -74.105829999999997)
('yuv.max=', 207.76299999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 255.0, 'yuv.min=', -59.941860000000005)
('yuv.max=', 250.173, 'yuv.min=', -85.844790000000003)
('yuv.max=', 236.39699999999999, 'yuv.min=', -17.030349999999991)
('yuv.max=', 201.03499999999997, 'yuv.min=', -42.905820000000006)
('yuv.max=', 228.673, 'yuv.min=', -30.396080000000001)
('yuv.max=', 250.54399999999998, 'yuv.min=', -11.819020000000009)
('yuv.max=', 255.0, 'yuv.min=', -16.415349999999986)
('yuv.max=', 199.96600000000001, 'yuv.min=', -53.225709999999992)
('yuv.max=', 254.886, 'yuv.min=', -33.536689999999993)
('yuv.max=', 160.44900000000001, 'yuv.min=', -23.525199999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.38091)
('yuv.max=', 225.28800000000001, 'yuv.min=', -16.900459999999992)
('yuv.max=', 228.64399999999998, 'yuv.min=', -35.270210000000006)
('yuv.max=', 250.25600000000003, 'yuv.min=', -60.740169999999999)
('yuv.max=', 189.08799999999997, 'yuv.min=', -18.105149999999995)
('yuv.max=', 237.42399999999998, 'yuv.min=', -11.498360000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.291240000000002)
('yuv.max=', 249.94, 'yuv.min=', -46.171590000000002)
('yuv.max=', 215.03199999999998, 'yuv.min=', -20.220299999999998)
('yuv.max=', 245.23199999999997, 'yuv.min=', -105.33056999999999)
('yuv.max=', 146.07300000000001, 'yuv.min=', -29.015379999999993)
('yuv.max=', 197.816, 'yuv.min=', -48.114050000000006)
('yuv.max=', 217.40200000000002, 'yuv.min=', -12.800049999999999)
('yuv.max=', 194.13399999999999, 'yuv.min=', -7.2604800000000012)
('yuv.max=', 251.44099999999997, 'yuv.min=', -50.175939999999997)
('yuv.max=', 245.88800000000001, 'yuv.min=', -57.820369999999983)
('yuv.max=', 237.76999999999998, 'yuv.min=', -37.390909999999991)
('yuv.max=', 216.08199999999999, 'yuv.min=', -36.301540000000003)
('yuv.max=', 202.63999999999999, 'yuv.min=', -17.305069999999986)
('yuv.max=', 248.87, 'yuv.min=', -39.166550000000008)
('yuv.max=', 224.05999999999997, 'yuv.min=', -41.795919999999995)
('yuv.max=', 250.184, 'yuv.min=', -20.756979999999999)
('yuv.max=', 181.328, 'yuv.min=', -25.450699999999991)
('yuv.max=', 202.03699999999998, 'yuv.min=', -32.720320000000001)
('yuv.max=', 249.65099999999995, 'yuv.min=', -67.030429999999996)
('yuv.max=', 249.673, 'yuv.min=', -16.63030999999998)
('yuv.max=', 223.15699999999998, 'yuv.min=', -11.351650000000001)
('yuv.max=', 230.99599999999995, 'yuv.min=', -22.197140000000001)
('yuv.max=', 242.33500000000001, 'yuv.min=', -21.220399999999991)
('yuv.max=', 248.0, 'yuv.min=', -21.825860000000002)
('yuv.max=', 239.03199999999998, 'yuv.min=', -26.785279999999993)
('yuv.max=', 254.10300000000001, 'yuv.min=', -24.153020000000001)
('yuv.max=', 138.221, 'yuv.min=', -12.185049999999995)
('yuv.max=', 242.96399999999997, 'yuv.min=', -41.090990000000005)
('yuv.max=', 247.07999999999998, 'yuv.min=', -55.315549999999988)
('yuv.max=', 237.672, 'yuv.min=', -79.066020000000009)
('yuv.max=', 243.89899999999997, 'yuv.min=', -72.466099999999997)
('yuv.max=', 247.88600000000002, 'yuv.min=', -26.600200000000001)
('yuv.max=', 249.756, 'yuv.min=', -20.053450000000012)
('yuv.max=', 221.25799999999998, 'yuv.min=', -59.463140000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.555279999999996)
('yuv.max=', 209.22299999999998, 'yuv.min=', -38.753090000000007)
('yuv.max=', 212.96099999999998, 'yuv.min=', -12.523070000000001)
('yuv.max=', 254.886, 'yuv.min=', -40.61530999999998)
('yuv.max=', 252.0, 'yuv.min=', -24.403800000000004)
('yuv.max=', 215.77600000000001, 'yuv.min=', -81.375450000000001)
('yuv.max=', 195.583, 'yuv.min=', -15.930239999999996)
('yuv.max=', 235.77199999999999, 'yuv.min=', -17.390139999999995)
('yuv.max=', 248.20500000000001, 'yuv.min=', -16.790079999999996)
('yuv.max=', 253.333, 'yuv.min=', -37.125329999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.96100000000001, 'yuv.min=', -45.460609999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.060169999999999)
('yuv.max=', 224.35500000000002, 'yuv.min=', -36.665809999999993)
('yuv.max=', 204.59100000000001, 'yuv.min=', -12.170109999999992)
('yuv.max=', 212.46099999999998, 'yuv.min=', -30.31081)
('yuv.max=', 255.0, 'yuv.min=', -18.447630000000004)
('yuv.max=', 190.399, 'yuv.min=', -23.225169999999984)
('yuv.max=', 198.13299999999998, 'yuv.min=', -28.934879999999996)
('yuv.max=', 210.83399999999997, 'yuv.min=', -55.300609999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.425219999999999)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 192.345, 'yuv.min=', -59.995279999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.095449999999985)
('yuv.max=', 244.74399999999997, 'yuv.min=', -7.1500999999999877)
('yuv.max=', 254.65800000000002, 'yuv.min=', -29.845339999999979)
('yuv.max=', 219.41300000000001, 'yuv.min=', -43.400649999999999)
('yuv.max=', 244.19399999999999, 'yuv.min=', -13.730019999999989)
('yuv.max=', 255.0, 'yuv.min=', -31.300669999999993)
('yuv.max=', 177.13299999999998, 'yuv.min=', -35.874340000000011)
('yuv.max=', 209.53100000000001, 'yuv.min=', -48.059659999999994)
('yuv.max=', 199.47599999999997, 'yuv.min=', -27.889960000000002)
('yuv.max=', 251.81499999999997, 'yuv.min=', -35.735559999999992)
('yuv.max=', 243.761, 'yuv.min=', -20.609969999999993)
('yuv.max=', 251.352, 'yuv.min=', -57.963309999999993)
('yuv.max=', 247.81499999999997, 'yuv.min=', -31.590900000000005)
('yuv.max=', 249.94599999999997, 'yuv.min=', -25.858480000000007)
('yuv.max=', 182.15199999999999, 'yuv.min=', -17.34531999999999)
('yuv.max=', 245.62799999999999, 'yuv.min=', -49.369079999999997)
('yuv.max=', 225.63799999999998, 'yuv.min=', -49.461859999999994)
('yuv.max=', 134.404, 'yuv.min=', -36.865549999999992)
('yuv.max=', 205.03899999999999, 'yuv.min=', -43.957620000000006)
('yuv.max=', 226.91799999999998, 'yuv.min=', -53.960229999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.004170000000009)
('yuv.max=', 253.56100000000001, 'yuv.min=', -36.555149999999998)
('yuv.max=', 236.70899999999997, 'yuv.min=', -16.660189999999989)
('yuv.max=', 229.10200000000003, 'yuv.min=', -36.859749999999991)
('yuv.max=', 191.18199999999999, 'yuv.min=', -16.823470000000004)
('yuv.max=', 237.98499999999999, 'yuv.min=', -23.754330000000003)
('yuv.max=', 253.989, 'yuv.min=', -17.005040000000005)
('yuv.max=', 241.10299999999998, 'yuv.min=', -21.482920000000004)
('yuv.max=', 252.89699999999999, 'yuv.min=', -62.335759999999993)
('yuv.max=', 203.98299999999998, 'yuv.min=', -9.8908999999999985)
('yuv.max=', 254.131, 'yuv.min=', -18.920169999999995)
('yuv.max=', 224.13399999999999, 'yuv.min=', -21.443060000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.949220000000004)
('yuv.max=', 242.30999999999997, 'yuv.min=', -14.996019999999998)
('yuv.max=', 199.12299999999999, 'yuv.min=', -35.450469999999989)
('yuv.max=', 255.0, 'yuv.min=', -32.025700000000001)
('yuv.max=', 208.35900000000001, 'yuv.min=', -12.375640000000004)
('yuv.max=', 252.42400000000001, 'yuv.min=', -37.640319999999988)
('yuv.max=', 171.369, 'yuv.min=', -32.555440000000004)
('yuv.max=', 238.85399999999998, 'yuv.min=', -44.250119999999995)
('yuv.max=', 237.89600000000002, 'yuv.min=', -31.160409999999992)
('yuv.max=', 248.83699999999999, 'yuv.min=', -29.390109999999986)
('yuv.max=', 237.70099999999999, 'yuv.min=', -53.025689999999997)
('yuv.max=', 233.38499999999999, 'yuv.min=', -21.951330000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.020379999999992)
('yuv.max=', 231.09899999999999, 'yuv.min=', -19.24721000000001)
('yuv.max=', 244.94999999999999, 'yuv.min=', -27.563830000000003)
('yuv.max=', 240.75899999999999, 'yuv.min=', -37.53573999999999)
('yuv.max=', 245.33799999999997, 'yuv.min=', -64.615249999999975)
('yuv.max=', 242.08500000000001, 'yuv.min=', -40.610739999999993)
('yuv.max=', 255.0, 'yuv.min=', -18.820160000000001)
('yuv.max=', 179.72899999999998, 'yuv.min=', -14.670359999999992)
('yuv.max=', 242.94999999999999, 'yuv.min=', -16.290029999999994)
('yuv.max=', 248.452, 'yuv.min=', -23.395420000000001)
('yuv.max=', 231.809, 'yuv.min=', -50.980669999999996)
('yuv.max=', 241.94999999999999, 'yuv.min=', -31.445499999999992)
('yuv.max=', 202.447, 'yuv.min=', -26.700209999999991)
('yuv.max=', 228.47, 'yuv.min=', -25.406829999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.000369999999993)
('yuv.max=', 201.34199999999998, 'yuv.min=', -40.655559999999987)
('yuv.max=', 249.78299999999996, 'yuv.min=', -9.0181400000000096)
('yuv.max=', 225.98400000000001, 'yuv.min=', -23.869219999999999)
('yuv.max=', 245.38099999999997, 'yuv.min=', -30.419939999999997)
('yuv.max=', 211.38099999999997, 'yuv.min=', -30.785680000000003)
('yuv.max=', 253.86000000000001, 'yuv.min=', -28.760169999999984)
('yuv.max=', 221.04299999999998, 'yuv.min=', -49.240249999999989)
('yuv.max=', 224.02800000000002, 'yuv.min=', -30.78059)
('yuv.max=', 253.20599999999999, 'yuv.min=', -59.505920000000003)
('yuv.max=', 218.292, 'yuv.min=', -40.355529999999987)
('yuv.max=', 253.46199999999999, 'yuv.min=', -35.45478)
('yuv.max=', 248.875, 'yuv.min=', -8.6502499999999962)
('yuv.max=', 208.70099999999999, 'yuv.min=', -21.465239999999994)
('yuv.max=', 209.017, 'yuv.min=', -36.366260000000011)
('yuv.max=', 241.35900000000001, 'yuv.min=', -47.820599999999999)
('yuv.max=', 240.29199999999997, 'yuv.min=', -61.032060000000008)
('yuv.max=', 195.52699999999999, 'yuv.min=', -23.27478)
('yuv.max=', 186.06199999999998, 'yuv.min=', -53.576640000000005)
('yuv.max=', 243.95599999999999, 'yuv.min=', -32.035189999999993)
('yuv.max=', 198.30899999999997, 'yuv.min=', -50.425429999999992)
('yuv.max=', 224.76999999999998, 'yuv.min=', -27.370399999999989)
('yuv.max=', 255.0, 'yuv.min=', -26.185219999999994)
('yuv.max=', 230.82999999999998, 'yuv.min=', -23.61027)
('yuv.max=', 167.316, 'yuv.min=', -31.875420000000002)
('yuv.max=', 255.0, 'yuv.min=', -45.520369999999986)
('yuv.max=', 191.00199999999998, 'yuv.min=', -25.324120000000001)
('yuv.max=', 248.0, 'yuv.min=', -46.58023)
('yuv.max=', 223.05099999999999, 'yuv.min=', -27.03058)
('yuv.max=', 252.60599999999999, 'yuv.min=', -30.272710000000004)
('yuv.max=', 255.0, 'yuv.min=', -17.149979999999992)
('yuv.max=', 253.0, 'yuv.min=', -5.0050699999999892)
('yuv.max=', 204.589, 'yuv.min=', -27.608259999999994)
('yuv.max=', 255.0, 'yuv.min=', -45.990539999999996)
('yuv.max=', 202.13099999999997, 'yuv.min=', -47.99618000000001)
('yuv.max=', 249.94599999999997, 'yuv.min=', -29.526240000000001)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.7801399999999994)
('yuv.max=', 253.68999999999997, 'yuv.min=', -24.780509999999996)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.01399999999998, 'yuv.min=', -22.810189999999995)
('yuv.max=', 249.73899999999998, 'yuv.min=', -31.454620000000013)
('yuv.max=', 255.0, 'yuv.min=', -11.540169999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.10877)
('yuv.max=', 230.172, 'yuv.min=', -121.38489999999997)
('yuv.max=', 214.27399999999997, 'yuv.min=', -46.805559999999993)
('yuv.max=', 252.34999999999999, 'yuv.min=', -35.603620000000006)
('yuv.max=', 255.0, 'yuv.min=', -5.2050899999999984)
('yuv.max=', 254.06, 'yuv.min=', -91.470659999999995)
('yuv.max=', 176.80799999999999, 'yuv.min=', -27.230139999999999)
('yuv.max=', 238.57999999999998, 'yuv.min=', -36.05471)
('yuv.max=', 231.67199999999997, 'yuv.min=', -55.585699999999989)
('yuv.max=', 158.30799999999999, 'yuv.min=', -14.055359999999986)
('yuv.max=', 223.01599999999999, 'yuv.min=', -31.960489999999993)
('yuv.max=', 232.26599999999999, 'yuv.min=', -51.825569999999985)
('yuv.max=', 233.84899999999999, 'yuv.min=', -33.775000000000006)
('yuv.max=', 220.745, 'yuv.min=', -51.980769999999993)
('yuv.max=', 254.43000000000001, 'yuv.min=', -66.579390000000004)
('yuv.max=', 204.245, 'yuv.min=', -34.444569999999992)
('yuv.max=', 239.11099999999999, 'yuv.min=', -35.110190000000003)
('yuv.max=', 240.465, 'yuv.min=', -48.90576999999999)
('yuv.max=', 234.84700000000001, 'yuv.min=', -31.275359999999992)
('yuv.max=', 227.13699999999997, 'yuv.min=', -26.970359999999999)
('yuv.max=', 247.24999999999997, 'yuv.min=', -11.519620000000003)
('yuv.max=', 212.989, 'yuv.min=', -16.645249999999997)
('yuv.max=', 185.86699999999999, 'yuv.min=', -34.695209999999989)
('yuv.max=', 191.43699999999998, 'yuv.min=', -39.900299999999987)
('yuv.max=', 250.65199999999999, 'yuv.min=', -13.10008)
('yuv.max=', 254.35900000000001, 'yuv.min=', -2.3301300000000111)
('yuv.max=', 255.0, 'yuv.min=', -69.713619999999992)
('yuv.max=', 178.101, 'yuv.min=', -64.088970000000003)
('yuv.max=', 241.733, 'yuv.min=', -28.855369999999994)
('yuv.max=', 248.417, 'yuv.min=', -24.636569999999992)
('yuv.max=', 249.11399999999998, 'yuv.min=', -53.015320000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.480479999999996)
('yuv.max=', 250.91799999999998, 'yuv.min=', -15.815289999999997)
('yuv.max=', 202.40000000000001, 'yuv.min=', -33.68016999999999)
('yuv.max=', 177.47800000000001, 'yuv.min=', -27.325579999999992)
('yuv.max=', 250.04899999999998, 'yuv.min=', -90.585509999999985)
('yuv.max=', 255.0, 'yuv.min=', -21.028380000000002)
('yuv.max=', 229.846, 'yuv.min=', -40.108849999999997)
('yuv.max=', 255.0, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 195.947, 'yuv.min=', -85.273110000000003)
('yuv.max=', 236.06, 'yuv.min=', -16.215329999999994)
('yuv.max=', 215.20199999999997, 'yuv.min=', -31.580479999999994)
('yuv.max=', 231.99100000000001, 'yuv.min=', -136.18514999999999)
('yuv.max=', 221.74000000000001, 'yuv.min=', -36.410319999999999)
('yuv.max=', 255.0, 'yuv.min=', -50.176569999999998)
('yuv.max=', 233.28800000000001, 'yuv.min=', -10.825159999999991)
('yuv.max=', 209.85399999999998, 'yuv.min=', -18.380320000000005)
('yuv.max=', 219.0, 'yuv.min=', -7.0129699999999993)
('yuv.max=', 207.172, 'yuv.min=', -40.440599999999996)
('yuv.max=', 253.10299999999998, 'yuv.min=', -49.695480000000003)
('yuv.max=', 158.084, 'yuv.min=', -39.680769999999995)
('yuv.max=', 218.63, 'yuv.min=', -17.128730000000001)
('yuv.max=', 250.88599999999997, 'yuv.min=', -12.380019999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.275169999999999)
('yuv.max=', 242.804, 'yuv.min=', -8.3352799999999991)
('yuv.max=', 208.95099999999999, 'yuv.min=', -47.420559999999995)
('yuv.max=', 226.56599999999997, 'yuv.min=', -42.000509999999991)
('yuv.max=', 220.68099999999998, 'yuv.min=', -24.640249999999995)
('yuv.max=', 219.09400000000002, 'yuv.min=', -36.88794)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.43000000000001, 'yuv.min=', -27.420980000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.417, 'yuv.min=', -21.050259999999994)
('yuv.max=', 255.0, 'yuv.min=', -24.465540000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.585189999999997)
('yuv.max=', 217.46600000000001, 'yuv.min=', -56.050069999999991)
('yuv.max=', 239.78299999999999, 'yuv.min=', -35.569389999999999)
('yuv.max=', 206.29099999999997, 'yuv.min=', -12.640279999999997)
('yuv.max=', 250.68999999999997, 'yuv.min=', -40.100319999999982)
('yuv.max=', 214.58399999999997, 'yuv.min=', -19.090309999999999)
('yuv.max=', 241.572, 'yuv.min=', -26.225469999999994)
('yuv.max=', 225.041, 'yuv.min=', -11.202920000000006)
('yuv.max=', 251.167, 'yuv.min=', -73.496009999999998)
('yuv.max=', 254.41299999999995, 'yuv.min=', -35.199170000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.230139999999992)
('yuv.max=', 205.40200000000002, 'yuv.min=', -23.259650000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999996)
('yuv.max=', 251.38699999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 214.51500000000001, 'yuv.min=', -102.19577)
('yuv.max=', 241.04299999999998, 'yuv.min=', -28.579330000000006)
('yuv.max=', 255.0, 'yuv.min=', -41.160179999999997)
('yuv.max=', 249.02199999999999, 'yuv.min=', -26.900230000000001)
('yuv.max=', 253.65799999999999, 'yuv.min=', -54.745369999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.249, 'yuv.min=', -36.380439999999993)
('yuv.max=', 236.86099999999999, 'yuv.min=', -47.24584999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -20.065099999999976)
('yuv.max=', 249.755, 'yuv.min=', -27.385339999999999)
('yuv.max=', 235.72300000000001, 'yuv.min=', -48.257460000000002)
('yuv.max=', 248.40799999999999, 'yuv.min=', -25.455269999999999)
('yuv.max=', 245.23899999999998, 'yuv.min=', -28.103980000000004)
('yuv.max=', 255.0, 'yuv.min=', -25.310439999999996)
('yuv.max=', 116.56, 'yuv.min=', -20.550460000000005)
('yuv.max=', 255.0, 'yuv.min=', -34.627420000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -35.483240000000009)
('yuv.max=', 140.48499999999999, 'yuv.min=', -32.275459999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 215.76100000000002, 'yuv.min=', -37.514999999999986)
('yuv.max=', 254.54400000000001, 'yuv.min=', -25.700110000000002)
('yuv.max=', 246.08699999999999, 'yuv.min=', -37.655259999999998)
('yuv.max=', 205.26399999999998, 'yuv.min=', -27.674999999999979)
('yuv.max=', 189.69299999999998, 'yuv.min=', -39.493559999999988)
('yuv.max=', 255.0, 'yuv.min=', -20.98555)
('yuv.max=', 255.0, 'yuv.min=', -24.615569999999998)
('yuv.max=', 255.0, 'yuv.min=', -63.870359999999998)
('yuv.max=', 246.0, 'yuv.min=', -82.405429999999981)
('yuv.max=', 224.18899999999999, 'yuv.min=', -32.215699999999991)
('yuv.max=', 197.95899999999997, 'yuv.min=', -19.505289999999995)
('yuv.max=', 227.10299999999998, 'yuv.min=', -38.695610000000002)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.44800000000001, 'yuv.min=', -56.861809999999991)
('yuv.max=', 250.17899999999997, 'yuv.min=', -14.830129999999983)
('yuv.max=', 239.202, 'yuv.min=', -44.715719999999997)
('yuv.max=', 250.99999999999997, 'yuv.min=', -48.296060000000004)
('yuv.max=', 244.02499999999998, 'yuv.min=', -14.230069999999991)
('yuv.max=', 200.858, 'yuv.min=', -16.315339999999999)
('yuv.max=', 237.0, 'yuv.min=', -8.8974000000000046)
('yuv.max=', 236.31, 'yuv.min=', -14.990590000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', -9.0652299999999997)
('yuv.max=', 233.239, 'yuv.min=', -32.562389999999994)
('yuv.max=', 247.09199999999998, 'yuv.min=', -30.060299999999984)
('yuv.max=', 252.13099999999997, 'yuv.min=', -24.059770000000004)
('yuv.max=', 254.886, 'yuv.min=', -14.249650000000003)
('yuv.max=', 213.77000000000001, 'yuv.min=', -3.0749999999999975)
('yuv.max=', 255.0, 'yuv.min=', -21.683690000000006)
('yuv.max=', 203.054, 'yuv.min=', -13.84631000000001)
('yuv.max=', 242.971, 'yuv.min=', -34.320479999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 198.20600000000002, 'yuv.min=', -43.031259999999996)
('yuv.max=', 243.74399999999997, 'yuv.min=', -25.470209999999987)
('yuv.max=', 206.20999999999998, 'yuv.min=', -32.460539999999995)
('yuv.max=', 224.815, 'yuv.min=', -27.210700000000003)
('yuv.max=', 225.55499999999998, 'yuv.min=', -29.715449999999986)
('yuv.max=', 255.0, 'yuv.min=', -44.949200000000005)
('yuv.max=', 249.07499999999999, 'yuv.min=', -24.175879999999999)
('yuv.max=', 214.92499999999998, 'yuv.min=', -39.180719999999994)
('yuv.max=', 217.49000000000001, 'yuv.min=', -29.990169999999992)
('yuv.max=', 247.48799999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.881, 'yuv.min=', -10.009309999999999)
('yuv.max=', 198.29900000000001, 'yuv.min=', -1.4548100000000002)
('yuv.max=', 251.13099999999997, 'yuv.min=', -23.740159999999992)
('yuv.max=', 207.185, 'yuv.min=', -46.975699999999996)
('yuv.max=', 183.953, 'yuv.min=', -25.792839999999998)
('yuv.max=', 248.88599999999997, 'yuv.min=', -33.97984000000001)
('yuv.max=', 193.27100000000002, 'yuv.min=', -12.555210000000002)
('yuv.max=', 255.0, 'yuv.min=', -51.215139999999991)
('yuv.max=', 215.74799999999999, 'yuv.min=', -24.861390000000007)
('yuv.max=', 251.42299999999997, 'yuv.min=', -52.055469999999985)
('yuv.max=', 208.24099999999999, 'yuv.min=', -25.699599999999997)
('yuv.max=', 203.80800000000002, 'yuv.min=', -19.737380000000002)
('yuv.max=', 221.82499999999996, 'yuv.min=', -83.621980000000008)
('yuv.max=', 214.09599999999998, 'yuv.min=', -35.657510000000002)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 230.93499999999997, 'yuv.min=', -31.586170000000003)
('yuv.max=', 213.97200000000001, 'yuv.min=', -23.33098)
('yuv.max=', 229.09699999999998, 'yuv.min=', -31.900729999999992)
('yuv.max=', 211.994, 'yuv.min=', -17.834999999999997)
('yuv.max=', 248.69, 'yuv.min=', -25.010409999999982)
('yuv.max=', 254.65800000000002, 'yuv.min=', -18.763080000000006)
('yuv.max=', 188.14699999999999, 'yuv.min=', -83.234769999999997)
('yuv.max=', 237.40499999999997, 'yuv.min=', -15.900980000000004)
('yuv.max=', 188.94399999999999, 'yuv.min=', -25.755299999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.19600000000003, 'yuv.min=', -34.050329999999988)
('yuv.max=', 252.114, 'yuv.min=', -11.05505999999999)
('yuv.max=', 252.77199999999999, 'yuv.min=', -4.6900999999999993)
('yuv.max=', 226.96099999999998, 'yuv.min=', -26.883729999999996)
('yuv.max=', 239.71699999999998, 'yuv.min=', -26.710579999999997)
('yuv.max=', 235.99999999999997, 'yuv.min=', -20.065100000000001)
('yuv.max=', 167.50299999999999, 'yuv.min=', -53.085449999999994)
('yuv.max=', 247.71199999999999, 'yuv.min=', -41.960259999999991)
('yuv.max=', 251.44499999999996, 'yuv.min=', -71.910179999999983)
('yuv.max=', 242.90299999999999, 'yuv.min=', -21.395090000000003)
('yuv.max=', 230.67999999999998, 'yuv.min=', -21.18014999999999)
('yuv.max=', 95.341999999999985, 'yuv.min=', -11.970089999999997)
('yuv.max=', 168.55099999999999, 'yuv.min=', -16.990140000000004)
('yuv.max=', 221.435, 'yuv.min=', -12.10193000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.175049999999992)
('yuv.max=', 255.0, 'yuv.min=', -25.585159999999995)
('yuv.max=', 220.02799999999996, 'yuv.min=', -21.74324)
('yuv.max=', 228.31799999999998, 'yuv.min=', -48.942760000000007)
('yuv.max=', 203.78899999999999, 'yuv.min=', -11.242189999999997)
('yuv.max=', 214.84299999999999, 'yuv.min=', -21.150269999999995)
('yuv.max=', 214.761, 'yuv.min=', -68.520200000000003)
('yuv.max=', 229.78100000000001, 'yuv.min=', -29.837109999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -40.940650000000005)
('yuv.max=', 255.0, 'yuv.min=', -36.829210000000003)
('yuv.max=', 255.0, 'yuv.min=', -38.73575000000001)
('yuv.max=', 221.55799999999999, 'yuv.min=', -44.866780000000013)
('yuv.max=', 252.64099999999996, 'yuv.min=', -11.64017999999999)
('yuv.max=', 233.62299999999999, 'yuv.min=', -34.069070000000004)
('yuv.max=', 243.79300000000001, 'yuv.min=', -16.16919)
('yuv.max=', 240.24299999999999, 'yuv.min=', -72.117450000000005)
('yuv.max=', 243.74499999999998, 'yuv.min=', -30.22007)
('yuv.max=', 198.64299999999997, 'yuv.min=', -23.803490000000007)
('yuv.max=', 223.26399999999998, 'yuv.min=', -16.34521999999998)
('yuv.max=', 158.14100000000002, 'yuv.min=', -63.520939999999982)
('yuv.max=', 254.70099999999999, 'yuv.min=', -47.595269999999985)
('yuv.max=', 119.67999999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 218.614, 'yuv.min=', -22.582380000000001)
('yuv.max=', 241.434, 'yuv.min=', -46.815929999999994)
('yuv.max=', 194.97099999999998, 'yuv.min=', -59.610179999999993)
('yuv.max=', 231.15799999999999, 'yuv.min=', -23.002180000000003)
('yuv.max=', 254.58699999999999, 'yuv.min=', -32.391390000000001)
('yuv.max=', 195.83999999999997, 'yuv.min=', -23.425189999999997)
('yuv.max=', 235.25999999999999, 'yuv.min=', -47.85047999999999)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 167.84399999999999, 'yuv.min=', -40.827600000000004)
('yuv.max=', 255.0, 'yuv.min=', -27.315209999999993)
('yuv.max=', 246.00399999999999, 'yuv.min=', -31.075339999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.315609999999992)
('yuv.max=', 248.28799999999995, 'yuv.min=', -91.615489999999994)
('yuv.max=', 236.79799999999997, 'yuv.min=', -52.455509999999997)
('yuv.max=', 228.40099999999998, 'yuv.min=', -23.799210000000006)
('yuv.max=', 211.42600000000002, 'yuv.min=', -52.030159999999995)
('yuv.max=', 183.46699999999998, 'yuv.min=', -25.720849999999999)
('yuv.max=', 253.70099999999996, 'yuv.min=', -82.576149999999998)
('yuv.max=', 252.24499999999998, 'yuv.min=', -7.361679999999998)
('yuv.max=', 241.93999999999997, 'yuv.min=', -44.875489999999999)
('yuv.max=', 245.48400000000001, 'yuv.min=', -9.9951999999999828)
('yuv.max=', 224.95699999999999, 'yuv.min=', -58.475619999999999)
('yuv.max=', 238.798, 'yuv.min=', -32.375469999999993)
('yuv.max=', 244.572, 'yuv.min=', -48.580429999999993)
('yuv.max=', 255.0, 'yuv.min=', -46.55034999999998)
('yuv.max=', 174.01899999999998, 'yuv.min=', -24.610369999999996)
('yuv.max=', 203.38099999999997, 'yuv.min=', -17.264970000000002)
('yuv.max=', 252.57199999999997, 'yuv.min=', -20.305369999999993)
('yuv.max=', 175.90200000000002, 'yuv.min=', -21.165210000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.63777)
('yuv.max=', 254.886, 'yuv.min=', -9.8354299999999988)
('yuv.max=', 242.54900000000001, 'yuv.min=', -29.057770000000005)
('yuv.max=', 181.06, 'yuv.min=', -15.785409999999995)
('yuv.max=', 192.54199999999997, 'yuv.min=', -40.470479999999995)
('yuv.max=', 215.53899999999999, 'yuv.min=', -62.650729999999982)
('yuv.max=', 226.28600000000003, 'yuv.min=', -24.46553999999999)
('yuv.max=', 243.31799999999998, 'yuv.min=', -27.760069999999992)
('yuv.max=', 210.52499999999998, 'yuv.min=', -39.40025)
('yuv.max=', 226.36700000000002, 'yuv.min=', -32.705379999999991)
('yuv.max=', 236.89999999999998, 'yuv.min=', -42.270659999999992)
('yuv.max=', 222.99199999999996, 'yuv.min=', -2.7152099999999884)
('yuv.max=', 253.99999999999997, 'yuv.min=', -0.61499999999999932)
('yuv.max=', 231.14399999999995, 'yuv.min=', -56.420229999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.770820000000001)
('yuv.max=', 210.72199999999998, 'yuv.min=', -39.910669999999996)
('yuv.max=', 239.71799999999999, 'yuv.min=', -35.335519999999988)
('yuv.max=', 175.09199999999998, 'yuv.min=', -39.325549999999993)
('yuv.max=', 218.126, 'yuv.min=', -56.985839999999996)
('yuv.max=', 234.38499999999999, 'yuv.min=', -10.757100000000001)
('yuv.max=', 255.0, 'yuv.min=', -32.4148)
('yuv.max=', 250.88599999999997, 'yuv.min=', -19.250080000000001)
('yuv.max=', 186.22999999999999, 'yuv.min=', -20.720349999999982)
('yuv.max=', 227.13000000000002, 'yuv.min=', -25.825429999999997)
('yuv.max=', 255.0, 'yuv.min=', -80.890340000000009)
('yuv.max=', 194.72999999999999, 'yuv.min=', -31.015579999999996)
('yuv.max=', 216.62700000000001, 'yuv.min=', -25.296990000000008)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.58699999999996, 'yuv.min=', -62.07893)
('yuv.max=', 248.84700000000001, 'yuv.min=', -18.30516999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.754650000000005)
('yuv.max=', 192.50300000000001, 'yuv.min=', -8.8801499999999916)
('yuv.max=', 162.23500000000001, 'yuv.min=', -37.065569999999994)
('yuv.max=', 161.29900000000001, 'yuv.min=', -16.347740000000009)
('yuv.max=', 255.0, 'yuv.min=', -51.255389999999991)
('yuv.max=', 232.24600000000001, 'yuv.min=', -83.475660000000005)
('yuv.max=', 252.13299999999995, 'yuv.min=', -35.498530000000002)
('yuv.max=', 207.90099999999998, 'yuv.min=', -18.390239999999995)
('yuv.max=', 207.61099999999999, 'yuv.min=', -28.604199999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.39692999999999)
('yuv.max=', 248.83599999999998, 'yuv.min=', -17.705109999999998)
('yuv.max=', 250.20699999999997, 'yuv.min=', -18.228649999999998)
('yuv.max=', 252.83199999999997, 'yuv.min=', -27.084099999999999)
('yuv.max=', 208.76499999999999, 'yuv.min=', -44.502559999999995)
('yuv.max=', 239.387, 'yuv.min=', -25.455269999999992)
('yuv.max=', 229.74099999999999, 'yuv.min=', -29.478240000000007)
('yuv.max=', 184.374, 'yuv.min=', -35.62518)
('yuv.max=', 166.49200000000002, 'yuv.min=', -19.090309999999988)
('yuv.max=', 243.18800000000002, 'yuv.min=', -37.480549999999994)
('yuv.max=', 229.10599999999999, 'yuv.min=', -2.7061399999999907)
('yuv.max=', 255.0, 'yuv.min=', -3.6900000000000013)
('yuv.max=', 226.83699999999996, 'yuv.min=', -31.775409999999997)
('yuv.max=', 173.22799999999998, 'yuv.min=', -15.230169999999996)
('yuv.max=', 238.72899999999998, 'yuv.min=', -12.099979999999999)
('yuv.max=', 250.22800000000001, 'yuv.min=', -26.830100000000002)
('yuv.max=', 251.64099999999999, 'yuv.min=', -30.805190000000003)
('yuv.max=', 247.70099999999996, 'yuv.min=', -24.540239999999994)
('yuv.max=', 220.31099999999998, 'yuv.min=', -26.025449999999996)
('yuv.max=', 205.762, 'yuv.min=', -92.537850000000006)
('yuv.max=', 255.0, 'yuv.min=', -2.0303200000000032)
('yuv.max=', 234.0, 'yuv.min=', -35.950519999999997)
('yuv.max=', 235.22399999999999, 'yuv.min=', -55.091609999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.160339999999998)
('yuv.max=', 237.85299999999998, 'yuv.min=', -18.500509999999998)
('yuv.max=', 252.92899999999997, 'yuv.min=', -17.905129999999993)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84599999999998, 'yuv.min=', -13.982730000000004)
('yuv.max=', 208.76299999999998, 'yuv.min=', -10.210160000000002)
('yuv.max=', 242.786, 'yuv.min=', -30.875319999999991)
('yuv.max=', 251.83700000000002, 'yuv.min=', -89.14054999999999)
('yuv.max=', 222.547, 'yuv.min=', -36.270059999999994)
('yuv.max=', 235.09599999999998, 'yuv.min=', -50.385179999999991)
('yuv.max=', 238.42099999999999, 'yuv.min=', -31.090279999999993)
('yuv.max=', 230.27099999999999, 'yuv.min=', -57.690479999999994)
('yuv.max=', 231.46699999999998, 'yuv.min=', -2.7600300000000075)
('yuv.max=', 233.78299999999999, 'yuv.min=', -92.845489999999998)
('yuv.max=', 253.80399999999997, 'yuv.min=', -23.727670000000007)
('yuv.max=', 240.99999999999997, 'yuv.min=', -7.0949099999999961)
('yuv.max=', 205.61899999999997, 'yuv.min=', -23.625209999999999)
('yuv.max=', 247.77599999999998, 'yuv.min=', -64.080749999999995)
('yuv.max=', 177.30099999999999, 'yuv.min=', -21.786459999999998)
('yuv.max=', 250.114, 'yuv.min=', -9.5951599999999946)
('yuv.max=', 208.999, 'yuv.min=', -27.970459999999992)
('yuv.max=', 255.0, 'yuv.min=', -21.805519999999987)
('yuv.max=', 255.0, 'yuv.min=', -21.007620000000003)
('yuv.max=', 246.80399999999997, 'yuv.min=', -105.67542)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 222.23099999999999, 'yuv.min=', -22.665200000000006)
('yuv.max=', 216.10299999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 242.61000000000001, 'yuv.min=', -51.722690000000007)
('yuv.max=', 210.90100000000001, 'yuv.min=', -57.550280000000001)
('yuv.max=', 201.86199999999997, 'yuv.min=', -15.030149999999985)
('yuv.max=', 247.11399999999998, 'yuv.min=', -23.71114)
('yuv.max=', 248.28799999999995, 'yuv.min=', -17.015409999999996)
('yuv.max=', 255.0, 'yuv.min=', -11.140129999999996)
('yuv.max=', 234.95999999999998, 'yuv.min=', -20.750229999999991)
('yuv.max=', 220.93700000000001, 'yuv.min=', -9.5845700000000136)
('yuv.max=', 210.768, 'yuv.min=', -39.401679999999999)
('yuv.max=', 234.10900000000001, 'yuv.min=', -21.825219999999995)
('yuv.max=', 255.0, 'yuv.min=', -35.983349999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -15.678830000000001)
('yuv.max=', 255.0, 'yuv.min=', -22.56609000000001)
('yuv.max=', 228.08899999999997, 'yuv.min=', -19.682410000000001)
('yuv.max=', 255.0, 'yuv.min=', -75.343700000000013)
('yuv.max=', 249.00999999999999, 'yuv.min=', -42.044029999999999)
('yuv.max=', 231.226, 'yuv.min=', -20.000769999999999)
('yuv.max=', 237.90299999999999, 'yuv.min=', -32.637770000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -62.710270000000001)
('yuv.max=', 253.505, 'yuv.min=', -56.25009)
('yuv.max=', 255.0, 'yuv.min=', -23.455069999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -21.956730000000004)
('yuv.max=', 215.09099999999998, 'yuv.min=', -54.425830000000005)
('yuv.max=', 237.14599999999996, 'yuv.min=', -13.961760000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.260419999999996)
('yuv.max=', 246.0, 'yuv.min=', -7.2693399999999997)
('yuv.max=', 221.21800000000002, 'yuv.min=', -32.484780000000001)
('yuv.max=', 207.78299999999999, 'yuv.min=', -66.200469999999996)
('yuv.max=', 198.43000000000001, 'yuv.min=', -43.945519999999988)
('yuv.max=', 255.0, 'yuv.min=', -82.120339999999999)
('yuv.max=', 255.0, 'yuv.min=', -80.934670000000011)
('yuv.max=', 250.79300000000001, 'yuv.min=', -21.911730000000006)
('yuv.max=', 250.626, 'yuv.min=', -4.9528099999999995)
('yuv.max=', 237.71599999999998, 'yuv.min=', -47.905670000000001)
('yuv.max=', 230.28100000000001, 'yuv.min=', -49.535709999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.659520000000001)
('yuv.max=', 192.69999999999999, 'yuv.min=', -24.843289999999996)
('yuv.max=', 246.12300000000002, 'yuv.min=', -46.630849999999995)
('yuv.max=', 240.47399999999999, 'yuv.min=', -24.195389999999996)
('yuv.max=', 187.80799999999999, 'yuv.min=', -34.205529999999982)
('yuv.max=', 251.495, 'yuv.min=', -27.095349999999996)
('yuv.max=', 232.45599999999999, 'yuv.min=', -12.870179999999991)
('yuv.max=', 159.16299999999998, 'yuv.min=', -13.613679999999999)
('yuv.max=', 227.822, 'yuv.min=', -26.65352)
('yuv.max=', 240.31599999999997, 'yuv.min=', -38.925509999999996)
('yuv.max=', 231.267, 'yuv.min=', -36.910369999999993)
('yuv.max=', 234.19999999999999, 'yuv.min=', -11.980460000000001)
('yuv.max=', 255.0, 'yuv.min=', -15.084649999999996)
('yuv.max=', 247.86499999999998, 'yuv.min=', -28.200359999999989)
('yuv.max=', 218.69, 'yuv.min=', -79.255729999999986)
('yuv.max=', 203.42099999999999, 'yuv.min=', -56.930649999999986)
('yuv.max=', 255.0, 'yuv.min=', -17.305069999999994)
('yuv.max=', 231.43099999999998, 'yuv.min=', -53.854680000000002)
('yuv.max=', 228.85399999999998, 'yuv.min=', -14.56635)
('yuv.max=', 246.28299999999999, 'yuv.min=', -46.285999999999994)
('yuv.max=', 255.0, 'yuv.min=', -20.947890000000001)
('yuv.max=', 241.91399999999999, 'yuv.min=', -20.196830000000002)
('yuv.max=', 242.96099999999996, 'yuv.min=', -17.034160000000014)
('yuv.max=', 240.078, 'yuv.min=', -20.606180000000002)
('yuv.max=', 164.0, 'yuv.min=', -27.685369999999999)
('yuv.max=', 197.74000000000001, 'yuv.min=', -50.970880000000001)
('yuv.max=', 252.28800000000001, 'yuv.min=', -64.625619999999998)
('yuv.max=', 148.01100000000002, 'yuv.min=', -62.520839999999993)
('yuv.max=', 253.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 204.18499999999997, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 255.0, 'yuv.min=', -23.312470000000005)
('yuv.max=', 176.285, 'yuv.min=', -13.819589999999998)
('yuv.max=', 237.70899999999997, 'yuv.min=', -24.265519999999999)
('yuv.max=', 255.0, 'yuv.min=', -67.200569999999985)
('yuv.max=', 255.0, 'yuv.min=', -78.530349999999984)
('yuv.max=', 237.13800000000001, 'yuv.min=', -21.705509999999997)
('yuv.max=', 240.54399999999998, 'yuv.min=', -33.402120000000011)
('yuv.max=', 234.834, 'yuv.min=', -54.132079999999995)
('yuv.max=', 174.95000000000002, 'yuv.min=', -25.240309999999994)
('yuv.max=', 240.22799999999998, 'yuv.min=', -53.009519999999995)
('yuv.max=', 233.32500000000002, 'yuv.min=', -95.998800000000017)
('yuv.max=', 250.83599999999998, 'yuv.min=', -63.125469999999993)
('yuv.max=', 175.79599999999996, 'yuv.min=', -35.679470000000002)
('yuv.max=', 237.32499999999999, 'yuv.min=', -34.950420000000001)
('yuv.max=', 239.95699999999999, 'yuv.min=', -32.485489999999999)
('yuv.max=', 177.45099999999999, 'yuv.min=', -33.860679999999988)
('yuv.max=', 210.05199999999999, 'yuv.min=', -24.350589999999997)
('yuv.max=', 234.31, 'yuv.min=', -29.970659999999992)
('yuv.max=', 146.08699999999999, 'yuv.min=', -15.130159999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', -24.295399999999994)
('yuv.max=', 245.65799999999999, 'yuv.min=', -25.255249999999986)
('yuv.max=', 244.08799999999999, 'yuv.min=', -16.162709999999997)
('yuv.max=', 205.91199999999998, 'yuv.min=', -60.672219999999996)
('yuv.max=', 229.58000000000001, 'yuv.min=', -48.550549999999987)
('yuv.max=', 195.61299999999997, 'yuv.min=', -44.080800000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.883890000000001)
('yuv.max=', 229.97899999999996, 'yuv.min=', -39.555449999999986)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.45799999999997, 'yuv.min=', -35.825199999999981)
('yuv.max=', 244.18899999999999, 'yuv.min=', -31.660459999999983)
('yuv.max=', 240.43999999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 213.31700000000001, 'yuv.min=', -25.855309999999978)
('yuv.max=', 243.72199999999998, 'yuv.min=', -39.040459999999996)
('yuv.max=', 118.56299999999999, 'yuv.min=', -26.695639999999997)
('yuv.max=', 229.92299999999997, 'yuv.min=', -45.346450000000004)
('yuv.max=', 184.68800000000002, 'yuv.min=', -63.565759999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 248.24699999999999, 'yuv.min=', -51.395649999999989)
('yuv.max=', 227.755, 'yuv.min=', -11.770069999999993)
('yuv.max=', 216.37, 'yuv.min=', -24.310339999999989)
('yuv.max=', 236.334, 'yuv.min=', -46.671099999999996)
('yuv.max=', 255.0, 'yuv.min=', -42.839770000000001)
('yuv.max=', 227.09799999999998, 'yuv.min=', -52.640589999999996)
('yuv.max=', 212.44399999999999, 'yuv.min=', -22.465339999999991)
('yuv.max=', 239.131, 'yuv.min=', -19.640340000000002)
('yuv.max=', 186.58099999999999, 'yuv.min=', -36.880489999999988)
('yuv.max=', 217.32900000000001, 'yuv.min=', -34.105519999999999)
('yuv.max=', 212.661, 'yuv.min=', -30.49021999999999)
('yuv.max=', 233.35499999999999, 'yuv.min=', -16.000369999999997)
('yuv.max=', 237.86099999999999, 'yuv.min=', -75.274839999999998)
('yuv.max=', 154.42099999999999, 'yuv.min=', -68.936419999999998)
('yuv.max=', 184.024, 'yuv.min=', -15.985429999999994)
('yuv.max=', 247.548, 'yuv.min=', -50.980669999999996)
('yuv.max=', 252.81499999999997, 'yuv.min=', -76.325559999999996)
('yuv.max=', 192.34399999999999, 'yuv.min=', -38.225439999999999)
('yuv.max=', 233.55599999999998, 'yuv.min=', -35.880390000000006)
('yuv.max=', 252.77199999999999, 'yuv.min=', -29.363389999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.33199999999999, 'yuv.min=', -11.440159999999995)
('yuv.max=', 214.13499999999999, 'yuv.min=', -29.715450000000004)
('yuv.max=', 252.92899999999997, 'yuv.min=', -19.675429999999995)
('yuv.max=', 255.0, 'yuv.min=', -6.4603999999999964)
('yuv.max=', 255.0, 'yuv.min=', -33.503309999999999)
('yuv.max=', 248.768, 'yuv.min=', -15.51361)
('yuv.max=', 220.91799999999998, 'yuv.min=', -14.600229999999998)
('yuv.max=', 252.821, 'yuv.min=', -46.442160000000015)
('yuv.max=', 240.071, 'yuv.min=', -153.73505999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.440340000000006)
('yuv.max=', 236.05799999999999, 'yuv.min=', -39.700279999999992)
('yuv.max=', 243.89699999999999, 'yuv.min=', -39.079479999999997)
('yuv.max=', 255.0, 'yuv.min=', -28.4452)
('yuv.max=', 221.86499999999998, 'yuv.min=', -21.820239999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.245729999999995)
('yuv.max=', 248.441, 'yuv.min=', -20.350189999999984)
('yuv.max=', 152.14999999999998, 'yuv.min=', -41.97063)
('yuv.max=', 213.75099999999998, 'yuv.min=', -10.772530000000003)
('yuv.max=', 252.886, 'yuv.min=', -9.9114700000000084)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 177.27200000000002, 'yuv.min=', -45.915839999999989)
('yuv.max=', 255.0, 'yuv.min=', -8.6908999999999992)
('yuv.max=', 195.68199999999999, 'yuv.min=', -48.850579999999979)
('yuv.max=', 231.15100000000001, 'yuv.min=', -21.132609999999993)
('yuv.max=', 242.33500000000001, 'yuv.min=', -32.19653000000001)
('yuv.max=', 250.59800000000001, 'yuv.min=', -17.160239999999988)
('yuv.max=', 254.08800000000002, 'yuv.min=', -18.337799999999994)
('yuv.max=', 205.11499999999998, 'yuv.min=', -30.84544)
('yuv.max=', 248.61499999999998, 'yuv.min=', -28.946640000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.348189999999999)
('yuv.max=', 222.04299999999998, 'yuv.min=', -24.120450000000002)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -10.969989999999989)
('yuv.max=', 210.31, 'yuv.min=', -15.41525)
('yuv.max=', 214.54599999999999, 'yuv.min=', -25.45496)
('yuv.max=', 255.0, 'yuv.min=', -20.520329999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 188.90799999999999, 'yuv.min=', -37.520799999999994)
('yuv.max=', 193.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 229.89099999999996, 'yuv.min=', -27.270389999999992)
('yuv.max=', 245.869, 'yuv.min=', -87.940429999999992)
('yuv.max=', 243.76199999999997, 'yuv.min=', -90.19999)
('yuv.max=', 236.232, 'yuv.min=', -40.900399999999991)
('yuv.max=', 233.96799999999999, 'yuv.min=', -26.998149999999995)
('yuv.max=', 248.35900000000001, 'yuv.min=', -31.532420000000005)
('yuv.max=', 255.0, 'yuv.min=', -73.335629999999995)
('yuv.max=', 255.0, 'yuv.min=', -25.740359999999992)
('yuv.max=', 229.07999999999998, 'yuv.min=', -66.015389999999996)
('yuv.max=', 233.95899999999997, 'yuv.min=', -21.852769999999996)
('yuv.max=', 200.11599999999999, 'yuv.min=', -18.953469999999999)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.4259899999999988)
('yuv.max=', 255.0, 'yuv.min=', -29.75569999999999)
('yuv.max=', 225.91800000000001, 'yuv.min=', -46.84581)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.320379999999993)
('yuv.max=', 251.989, 'yuv.min=', -27.955519999999993)
('yuv.max=', 181.37, 'yuv.min=', -4.9634300000000025)
('yuv.max=', 255.0, 'yuv.min=', -2.0304700000000224)
('yuv.max=', 238.64999999999998, 'yuv.min=', -69.190399999999997)
('yuv.max=', 197.06199999999998, 'yuv.min=', -51.395649999999989)
('yuv.max=', 240.869, 'yuv.min=', -25.035720000000001)
('yuv.max=', 242.71199999999999, 'yuv.min=', -95.590579999999989)
('yuv.max=', 254.017, 'yuv.min=', -21.390539999999994)
('yuv.max=', 246.98899999999998, 'yuv.min=', -30.160310000000003)
('yuv.max=', 248.131, 'yuv.min=', -38.385209999999987)
('yuv.max=', 226.72899999999998, 'yuv.min=', -7.9651199999999989)
('yuv.max=', 246.21699999999998, 'yuv.min=', -12.770169999999997)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.637, 'yuv.min=', -27.120989999999992)
('yuv.max=', 253.42999999999998, 'yuv.min=', -40.240579999999994)
('yuv.max=', 241.61200000000002, 'yuv.min=', -41.31537999999999)
('yuv.max=', 244.148, 'yuv.min=', -54.620049999999999)
('yuv.max=', 225.31799999999998, 'yuv.min=', -89.34057)
('yuv.max=', 249.79299999999998, 'yuv.min=', -98.365549999999999)
('yuv.max=', 220.47300000000001, 'yuv.min=', -23.795349999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -42.355729999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.34541999999999)
('yuv.max=', 224.30500000000001, 'yuv.min=', -16.504989999999999)
('yuv.max=', 208.739, 'yuv.min=', -29.579950000000004)
('yuv.max=', 250.98899999999998, 'yuv.min=', -69.375479999999996)
('yuv.max=', 236.31699999999998, 'yuv.min=', -41.015349999999991)
('yuv.max=', 220.572, 'yuv.min=', -5.3826099999999997)
('yuv.max=', 230.65699999999998, 'yuv.min=', -45.790519999999987)
('yuv.max=', 208.672, 'yuv.min=', -43.298850000000002)
('yuv.max=', 143.49199999999999, 'yuv.min=', -32.723190000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.01900000000001, 'yuv.min=', -30.530470000000001)
('yuv.max=', 247.95099999999996, 'yuv.min=', -38.556370000000008)
('yuv.max=', 185.62799999999999, 'yuv.min=', -24.675069999999998)
('yuv.max=', 248.76100000000002, 'yuv.min=', -34.410119999999992)
('yuv.max=', 210.71299999999999, 'yuv.min=', -24.995470000000005)
('yuv.max=', 233.0, 'yuv.min=', -19.251970000000014)
('yuv.max=', 239.98299999999998, 'yuv.min=', -89.349589999999992)
('yuv.max=', 250.79900000000004, 'yuv.min=', -18.583770000000005)
('yuv.max=', 166.47099999999998, 'yuv.min=', -42.971200000000003)
('yuv.max=', 255.0, 'yuv.min=', -42.442900000000009)
('yuv.max=', 234.114, 'yuv.min=', -36.060850000000002)
('yuv.max=', 235.33599999999998, 'yuv.min=', -70.34602000000001)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.148, 'yuv.min=', -96.42398)
('yuv.max=', 255.0, 'yuv.min=', -18.698729999999998)
('yuv.max=', 203.63299999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 223.95899999999997, 'yuv.min=', -12.140229999999994)
('yuv.max=', 221.375, 'yuv.min=', -30.930509999999998)
('yuv.max=', 167.85599999999999, 'yuv.min=', -23.065399999999993)
('yuv.max=', 255.0, 'yuv.min=', -33.373049999999999)
('yuv.max=', 193.43199999999999, 'yuv.min=', -21.72501999999999)
('yuv.max=', 241.76299999999995, 'yuv.min=', -58.620449999999991)
('yuv.max=', 230.14399999999998, 'yuv.min=', -36.120659999999987)
('yuv.max=', 210.02499999999998, 'yuv.min=', -43.145439999999994)
('yuv.max=', 255.0, 'yuv.min=', -14.030049999999996)
('yuv.max=', 251.804, 'yuv.min=', -28.725719999999995)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -38.120859999999993)
('yuv.max=', 240.92899999999997, 'yuv.min=', -80.59720999999999)
('yuv.max=', 245.05000000000001, 'yuv.min=', -28.83029999999999)
('yuv.max=', 251.17399999999998, 'yuv.min=', -25.570220000000003)
('yuv.max=', 254.886, 'yuv.min=', -26.294689999999996)
('yuv.max=', 248.815, 'yuv.min=', -27.355459999999994)
('yuv.max=', 253.11399999999998, 'yuv.min=', -25.755299999999998)
('yuv.max=', 228.44099999999997, 'yuv.min=', -30.620109999999997)
('yuv.max=', 234.22099999999998, 'yuv.min=', -30.855809999999991)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -42.420199999999994)
('yuv.max=', 248.38499999999996, 'yuv.min=', -19.479979999999994)
('yuv.max=', 251.49000000000001, 'yuv.min=', -61.475919999999995)
('yuv.max=', 252.92899999999997, 'yuv.min=', -41.860249999999979)
('yuv.max=', 237.77199999999999, 'yuv.min=', -37.477059999999994)
('yuv.max=', 210.82699999999997, 'yuv.min=', -42.110889999999998)
('yuv.max=', 248.74399999999997, 'yuv.min=', -37.410420000000002)
('yuv.max=', 255.0, 'yuv.min=', -41.325749999999992)
('yuv.max=', 225.14600000000002, 'yuv.min=', -36.245180000000005)
('yuv.max=', 152.28399999999999, 'yuv.min=', -27.830199999999991)
('yuv.max=', 230.637, 'yuv.min=', -42.355730000000001)
('yuv.max=', 223.59999999999999, 'yuv.min=', -21.389910000000004)
('yuv.max=', 219.33800000000002, 'yuv.min=', -10.053310000000003)
('yuv.max=', 253.0, 'yuv.min=', -30.425310000000003)
('yuv.max=', 235.72300000000001, 'yuv.min=', -44.005279999999985)
('yuv.max=', 179.167, 'yuv.min=', -31.20523)
('yuv.max=', 251.92899999999995, 'yuv.min=', -21.665260000000004)
('yuv.max=', 205.76599999999999, 'yuv.min=', -13.040319999999994)
('yuv.max=', 223.08399999999997, 'yuv.min=', -17.204310000000003)
('yuv.max=', 242.74799999999996, 'yuv.min=', -26.125459999999997)
('yuv.max=', 223.71199999999999, 'yuv.min=', -51.025489999999976)
('yuv.max=', 244.423, 'yuv.min=', -24.065499999999997)
('yuv.max=', 236.423, 'yuv.min=', -42.377190000000006)
('yuv.max=', 188.0, 'yuv.min=', -44.66052999999998)
('yuv.max=', 235.30999999999997, 'yuv.min=', -92.660410000000013)
('yuv.max=', 241.92299999999997, 'yuv.min=', -50.550749999999994)
('yuv.max=', 202.834, 'yuv.min=', -33.420389999999998)
('yuv.max=', 236.36999999999995, 'yuv.min=', -76.084699999999998)
('yuv.max=', 249.48399999999998, 'yuv.min=', -26.534130000000001)
('yuv.max=', 247.38300000000001, 'yuv.min=', -48.725259999999999)
('yuv.max=', 245.505, 'yuv.min=', -26.385239999999985)
('yuv.max=', 255.0, 'yuv.min=', -67.66037)
('yuv.max=', 255.0, 'yuv.min=', -41.587699999999998)
('yuv.max=', 217.39699999999999, 'yuv.min=', -29.61544)
('yuv.max=', 206.708, 'yuv.min=', -52.530209999999997)
('yuv.max=', 211.85199999999998, 'yuv.min=', -35.860879999999995)
('yuv.max=', 211.72300000000001, 'yuv.min=', -29.024090000000008)
('yuv.max=', 232.92099999999999, 'yuv.min=', -23.55507999999999)
('yuv.max=', 214.21899999999999, 'yuv.min=', -47.001009999999987)
('yuv.max=', 244.38399999999999, 'yuv.min=', -46.805559999999993)
('yuv.max=', 229.44800000000001, 'yuv.min=', -52.21067)
('yuv.max=', 253.03399999999999, 'yuv.min=', -83.335399999999979)
('yuv.max=', 214.00899999999996, 'yuv.min=', -29.555679999999999)
('yuv.max=', 248.91800000000001, 'yuv.min=', -38.544979999999995)
('yuv.max=', 245.05000000000001, 'yuv.min=', -5.3876400000000046)
('yuv.max=', 247.06, 'yuv.min=', -14.159939999999994)
('yuv.max=', 253.27700000000002, 'yuv.min=', -19.17183)
('yuv.max=', 237.30099999999999, 'yuv.min=', -53.370539999999984)
('yuv.max=', 194.69399999999999, 'yuv.min=', -14.530099999999994)
('yuv.max=', 220.58299999999997, 'yuv.min=', -9.6171499999999952)
('yuv.max=', 240.893, 'yuv.min=', -24.157259999999994)
('yuv.max=', 216.84999999999999, 'yuv.min=', -34.164310000000008)
('yuv.max=', 253.48399999999998, 'yuv.min=', -21.450299999999991)
('yuv.max=', 241.80399999999997, 'yuv.min=', -11.618229999999997)
('yuv.max=', 241.309, 'yuv.min=', -31.435129999999994)
('yuv.max=', 186.78999999999999, 'yuv.min=', -31.230539999999984)
('yuv.max=', 229.68100000000001, 'yuv.min=', -92.468299999999999)
('yuv.max=', 230.41199999999998, 'yuv.min=', -19.880019999999998)
('yuv.max=', 253.61499999999995, 'yuv.min=', -44.275429999999993)
('yuv.max=', 255.0, 'yuv.min=', -80.76615000000001)
('yuv.max=', 200.39099999999999, 'yuv.min=', -55.822099999999999)
('yuv.max=', 136.51399999999998, 'yuv.min=', -10.620570000000001)
('yuv.max=', 251.33099999999996, 'yuv.min=', -50.055269999999993)
('yuv.max=', 255.0, 'yuv.min=', -50.825469999999989)
('yuv.max=', 154.06100000000001, 'yuv.min=', -19.320209999999992)
('yuv.max=', 206.91899999999998, 'yuv.min=', -57.28295)
('yuv.max=', 255.0, 'yuv.min=', -34.523030000000013)
('yuv.max=', 233.256, 'yuv.min=', -37.618479999999998)
('yuv.max=', 248.78300000000002, 'yuv.min=', -56.960529999999991)
('yuv.max=', 255.0, 'yuv.min=', -18.375299999999985)
('yuv.max=', 202.03099999999998, 'yuv.min=', -37.250649999999993)
('yuv.max=', 231.78599999999997, 'yuv.min=', -34.151390000000006)
('yuv.max=', 253.0, 'yuv.min=', -33.97766)
('yuv.max=', 253.989, 'yuv.min=', -28.278040000000001)
('yuv.max=', 250.0, 'yuv.min=', -9.3399499999999982)
('yuv.max=', 250.31999999999999, 'yuv.min=', -24.744829999999993)
('yuv.max=', 238.50099999999998, 'yuv.min=', -43.652169999999998)
('yuv.max=', 232.71699999999998, 'yuv.min=', -25.166460000000001)
('yuv.max=', 240.13099999999997, 'yuv.min=', -21.38017)
('yuv.max=', 234.86399999999998, 'yuv.min=', -17.360259999999997)
('yuv.max=', 246.03200000000001, 'yuv.min=', -37.510429999999992)
('yuv.max=', 255.0, 'yuv.min=', -33.460639999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.625239999999994)
('yuv.max=', 251.74399999999997, 'yuv.min=', -29.03145)
('yuv.max=', 249.56999999999996, 'yuv.min=', -54.406319999999994)
('yuv.max=', 154.95699999999999, 'yuv.min=', -34.705580000000005)
('yuv.max=', 100.62, 'yuv.min=', -33.610039999999991)
('yuv.max=', 196.03999999999996, 'yuv.min=', -62.263669999999991)
('yuv.max=', 185.09, 'yuv.min=', -25.595529999999997)
('yuv.max=', 253.80399999999997, 'yuv.min=', -10.110149999999999)
('yuv.max=', 233.768, 'yuv.min=', -19.575419999999983)
('yuv.max=', 255.0, 'yuv.min=', -74.515039999999999)
('yuv.max=', 216.036, 'yuv.min=', -50.38060999999999)
('yuv.max=', 193.86199999999999, 'yuv.min=', -31.763530000000003)
('yuv.max=', 197.22299999999998, 'yuv.min=', -43.84550999999999)
('yuv.max=', 248.869, 'yuv.min=', -19.250080000000004)
('yuv.max=', 222.74100000000001, 'yuv.min=', -67.659190000000009)
('yuv.max=', 249.32699999999997, 'yuv.min=', -14.735240000000008)
('yuv.max=', 207.559, 'yuv.min=', -34.305539999999993)
('yuv.max=', 251.886, 'yuv.min=', -34.820529999999991)
('yuv.max=', 254.202, 'yuv.min=', -35.765439999999984)
('yuv.max=', 246.929, 'yuv.min=', -12.107869999999998)
('yuv.max=', 229.50899999999999, 'yuv.min=', -28.855609999999981)
('yuv.max=', 243.16499999999996, 'yuv.min=', -32.661060000000006)
('yuv.max=', 251.02799999999999, 'yuv.min=', -29.315040000000003)
('yuv.max=', 247.07599999999996, 'yuv.min=', -49.32074999999999)
('yuv.max=', 250.42299999999997, 'yuv.min=', -58.318110000000004)
('yuv.max=', 251.98499999999999, 'yuv.min=', -55.489050000000006)
('yuv.max=', 197.37799999999999, 'yuv.min=', -54.856980000000007)
('yuv.max=', 255.0, 'yuv.min=', -29.085509999999996)
('yuv.max=', 212.12900000000002, 'yuv.min=', -34.135400000000004)
('yuv.max=', 215.98899999999998, 'yuv.min=', -51.850879999999982)
('yuv.max=', 253.81499999999997, 'yuv.min=', -34.377859999999998)
('yuv.max=', 185.84299999999996, 'yuv.min=', -20.135229999999989)
('yuv.max=', 255.0, 'yuv.min=', -6.2051899999999875)
('yuv.max=', 179.036, 'yuv.min=', -22.780309999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', -20.12028999999999)
('yuv.max=', 241.33099999999999, 'yuv.min=', -30.050890000000003)
('yuv.max=', 202.23299999999998, 'yuv.min=', -23.910299999999992)
('yuv.max=', 187.19, 'yuv.min=', -17.123539999999998)
('yuv.max=', 255.0, 'yuv.min=', -8.3306600000000088)
('yuv.max=', 223.07099999999997, 'yuv.min=', -41.185489999999994)
('yuv.max=', 252.50499999999997, 'yuv.min=', -27.470409999999998)
('yuv.max=', 246.96100000000001, 'yuv.min=', -21.250279999999989)
('yuv.max=', 251.142, 'yuv.min=', -25.840369999999989)
('yuv.max=', 247.39099999999996, 'yuv.min=', -13.31504)
('yuv.max=', 240.67999999999998, 'yuv.min=', -26.589829999999999)
('yuv.max=', 255.0, 'yuv.min=', -17.279470000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -50.3553)
('yuv.max=', 255.0, 'yuv.min=', -35.865449999999996)
('yuv.max=', 219.57299999999998, 'yuv.min=', -15.460069999999988)
('yuv.max=', 205.74799999999999, 'yuv.min=', -26.90022999999999)
('yuv.max=', 205.42999999999998, 'yuv.min=', -41.416699999999999)
('yuv.max=', 253.68999999999997, 'yuv.min=', -12.821759999999998)
('yuv.max=', 238.62999999999997, 'yuv.min=', -25.625409999999984)
('yuv.max=', 147.63399999999999, 'yuv.min=', -36.435629999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -20.79515)
('yuv.max=', 247.21599999999998, 'yuv.min=', -65.71535999999999)
('yuv.max=', 211.03900000000002, 'yuv.min=', -21.880219999999991)
('yuv.max=', 231.316, 'yuv.min=', -39.216610000000003)
('yuv.max=', 236.86900000000003, 'yuv.min=', -25.682230000000001)
('yuv.max=', 221.93599999999998, 'yuv.min=', -54.355699999999992)
('yuv.max=', 251.41300000000001, 'yuv.min=', -20.51711000000001)
('yuv.max=', 206.13900000000001, 'yuv.min=', -49.385079999999974)
('yuv.max=', 230.21299999999999, 'yuv.min=', -32.845749999999995)
('yuv.max=', 255.0, 'yuv.min=', -24.825329999999997)
('yuv.max=', 217.85299999999995, 'yuv.min=', -43.799349999999997)
('yuv.max=', 234.33699999999999, 'yuv.min=', -23.405679999999997)
('yuv.max=', 230.27099999999999, 'yuv.min=', -30.390790000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -12.7797)
('yuv.max=', 224.37899999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 248.35900000000001, 'yuv.min=', -24.250579999999985)
('yuv.max=', 254.70099999999999, 'yuv.min=', -33.150239999999997)
('yuv.max=', 173.78899999999999, 'yuv.min=', -19.761000000000003)
('yuv.max=', 244.97800000000001, 'yuv.min=', -36.780479999999997)
('yuv.max=', 248.364, 'yuv.min=', -110.18043999999999)
('yuv.max=', 180.24600000000001, 'yuv.min=', -27.730189999999997)
('yuv.max=', 252.09899999999999, 'yuv.min=', -23.710279999999994)
('yuv.max=', 253.29900000000001, 'yuv.min=', -36.654639999999993)
('yuv.max=', 226.13099999999997, 'yuv.min=', -33.88476)
('yuv.max=', 250.929, 'yuv.min=', -53.136069999999989)
('yuv.max=', 205.42699999999999, 'yuv.min=', -27.615239999999993)
('yuv.max=', 228.21499999999997, 'yuv.min=', -32.990469999999988)
('yuv.max=', 255.0, 'yuv.min=', -7.3949399999999965)
('yuv.max=', 253.518, 'yuv.min=', -27.180749999999989)
('yuv.max=', 233.11799999999999, 'yuv.min=', -25.377520000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.756, 'yuv.min=', -23.105450000000005)
('yuv.max=', 234.505, 'yuv.min=', -62.150679999999994)
('yuv.max=', 251.90699999999995, 'yuv.min=', -47.120530000000002)
('yuv.max=', 210.41899999999998, 'yuv.min=', -32.800820000000002)
('yuv.max=', 226.98100000000002, 'yuv.min=', -32.703980000000001)
('yuv.max=', 228.447, 'yuv.min=', -37.897060000000003)
('yuv.max=', 241.39499999999998, 'yuv.min=', -50.280599999999993)
('yuv.max=', 225.797, 'yuv.min=', -30.705179999999984)
('yuv.max=', 201.86199999999997, 'yuv.min=', -23.195289999999996)
('yuv.max=', 231.60499999999999, 'yuv.min=', -32.805390000000003)
('yuv.max=', 228.07399999999998, 'yuv.min=', -18.635079999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.031509999999997)
('yuv.max=', 245.59100000000001, 'yuv.min=', -25.880619999999993)
('yuv.max=', 230.499, 'yuv.min=', -16.598800000000004)
('yuv.max=', 216.00099999999998, 'yuv.min=', -66.046080000000003)
('yuv.max=', 242.50999999999996, 'yuv.min=', -61.120699999999999)
('yuv.max=', 235.41199999999998, 'yuv.min=', -33.624979999999994)
('yuv.max=', 211.875, 'yuv.min=', -21.135329999999989)
('yuv.max=', 240.733, 'yuv.min=', -12.544239999999995)
('yuv.max=', 224.63, 'yuv.min=', -25.080539999999996)
('yuv.max=', 245.41499999999999, 'yuv.min=', -37.346400000000003)
('yuv.max=', 244.05799999999996, 'yuv.min=', -13.344619999999999)
('yuv.max=', 229.00399999999999, 'yuv.min=', -30.446350000000002)
('yuv.max=', 253.0, 'yuv.min=', -17.990199999999998)
('yuv.max=', 253.185, 'yuv.min=', -13.18713)
('yuv.max=', 255.0, 'yuv.min=', -49.821259999999995)
('yuv.max=', 252.17400000000001, 'yuv.min=', -13.568719999999999)
('yuv.max=', 229.62899999999999, 'yuv.min=', -52.364639999999994)
('yuv.max=', 222.58799999999999, 'yuv.min=', -46.00090999999999)
('yuv.max=', 249.75700000000001, 'yuv.min=', -32.174210000000009)
('yuv.max=', 255.0, 'yuv.min=', -60.552040000000005)
('yuv.max=', 250.21699999999998, 'yuv.min=', -23.310239999999997)
('yuv.max=', 248.14599999999999, 'yuv.min=', -13.000069999999997)
('yuv.max=', 255.0, 'yuv.min=', -26.200159999999993)
('yuv.max=', 186.66399999999999, 'yuv.min=', -65.685839999999999)
('yuv.max=', 253.886, 'yuv.min=', -50.110460000000003)
('yuv.max=', 204.399, 'yuv.min=', -77.800399999999996)
('yuv.max=', 240.81900000000002, 'yuv.min=', -45.50542999999999)
('yuv.max=', 254.47300000000001, 'yuv.min=', -29.358059999999998)
('yuv.max=', 204.59799999999998, 'yuv.min=', -30.445399999999992)
('yuv.max=', 225.21699999999998, 'yuv.min=', -23.117339999999999)
('yuv.max=', 248.071, 'yuv.min=', -31.608150000000006)
('yuv.max=', 255.0, 'yuv.min=', -12.810420000000001)
('yuv.max=', 251.09199999999998, 'yuv.min=', -31.790349999999997)
('yuv.max=', 173.45600000000002, 'yuv.min=', -47.481549999999999)
('yuv.max=', 241.60999999999999, 'yuv.min=', -44.176299999999998)
('yuv.max=', 232.73399999999998, 'yuv.min=', -66.296600000000012)
('yuv.max=', 233.15299999999999, 'yuv.min=', -10.925169999999994)
('yuv.max=', 238.625, 'yuv.min=', -48.03555999999999)
('yuv.max=', 240.065, 'yuv.min=', -51.655429999999996)
('yuv.max=', 237.452, 'yuv.min=', -53.270530000000001)
('yuv.max=', 237.01999999999998, 'yuv.min=', -30.47527999999998)
('yuv.max=', 211.45399999999998, 'yuv.min=', -27.770439999999983)
('yuv.max=', 238.714, 'yuv.min=', -49.680540000000001)
('yuv.max=', 253.505, 'yuv.min=', -24.310339999999993)
('yuv.max=', 207.65199999999996, 'yuv.min=', -17.590989999999998)
('yuv.max=', 232.19599999999997, 'yuv.min=', -19.313950000000002)
('yuv.max=', 242.39999999999998, 'yuv.min=', -26.223019999999998)
('yuv.max=', 225.167, 'yuv.min=', -17.849939999999997)
('yuv.max=', 153.54399999999998, 'yuv.min=', -45.290469999999985)
('yuv.max=', 223.47499999999999, 'yuv.min=', -7.5569500000000005)
('yuv.max=', 241.56999999999999, 'yuv.min=', -72.820639999999997)
('yuv.max=', 227.048, 'yuv.min=', -42.686870000000006)
('yuv.max=', 247.53799999999998, 'yuv.min=', -31.44923)
('yuv.max=', 225.06099999999998, 'yuv.min=', -32.87551999999998)
('yuv.max=', 210.233, 'yuv.min=', -24.740259999999999)
('yuv.max=', 198.23599999999999, 'yuv.min=', -29.553310000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -17.00329)
('yuv.max=', 255.0, 'yuv.min=', -14.282879999999999)
('yuv.max=', 255.0, 'yuv.min=', -34.402870000000007)
('yuv.max=', 187.51499999999999, 'yuv.min=', -20.686070000000001)
('yuv.max=', 224.785, 'yuv.min=', -27.395709999999987)
('yuv.max=', 200.559, 'yuv.min=', -34.915430000000001)
('yuv.max=', 183.27699999999999, 'yuv.min=', -41.795919999999988)
('yuv.max=', 250.245, 'yuv.min=', -8.8265400000000014)
('yuv.max=', 238.511, 'yuv.min=', -79.861350000000002)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.756, 'yuv.min=', -27.236849999999997)
('yuv.max=', 213.65299999999999, 'yuv.min=', -10.140029999999994)
('yuv.max=', 243.70099999999999, 'yuv.min=', -36.080409999999986)
('yuv.max=', 251.44499999999996, 'yuv.min=', -89.568089999999998)
('yuv.max=', 255.0, 'yuv.min=', -10.09774)
('yuv.max=', 205.625, 'yuv.min=', -99.335769999999997)
('yuv.max=', 246.35900000000001, 'yuv.min=', -40.554910000000007)
('yuv.max=', 243.42699999999999, 'yuv.min=', -33.665229999999987)
('yuv.max=', 223.92099999999999, 'yuv.min=', -40.300340000000006)
('yuv.max=', 231.14399999999998, 'yuv.min=', -96.925809999999998)
('yuv.max=', 236.374, 'yuv.min=', -24.650620000000004)
('yuv.max=', 237.47999999999996, 'yuv.min=', -31.045459999999988)
('yuv.max=', 226.45899999999997, 'yuv.min=', -20.680099999999978)
('yuv.max=', 181.07399999999998, 'yuv.min=', -16.620820000000002)
('yuv.max=', 242.99799999999999, 'yuv.min=', -35.892189999999999)
('yuv.max=', 192.05699999999999, 'yuv.min=', -64.034890000000004)
('yuv.max=', 224.327, 'yuv.min=', -26.910729999999997)
('yuv.max=', 172.72499999999997, 'yuv.min=', -89.857669999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.27699999999999, 'yuv.min=', -34.865349999999992)
('yuv.max=', 193.19799999999998, 'yuv.min=', -46.115859999999998)
('yuv.max=', 247.43000000000001, 'yuv.min=', -33.635350000000003)
('yuv.max=', 239.29300000000001, 'yuv.min=', -8.2986599999999981)
('yuv.max=', 236.07299999999998, 'yuv.min=', -17.960319999999996)
('yuv.max=', 255.0, 'yuv.min=', -6.7351199999999949)
('yuv.max=', 193.06799999999998, 'yuv.min=', 0.25978000000000634)
('yuv.max=', 201.71899999999999, 'yuv.min=', -33.190489999999983)
('yuv.max=', 236.68899999999999, 'yuv.min=', -68.738320000000002)
('yuv.max=', 172.83700000000002, 'yuv.min=', -39.721470000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -70.571029999999993)
('yuv.max=', 249.017, 'yuv.min=', -52.371739999999996)
('yuv.max=', 234.815, 'yuv.min=', -29.645319999999987)
('yuv.max=', 245.989, 'yuv.min=', -53.570559999999993)
('yuv.max=', 237.33100000000002, 'yuv.min=', -35.625250000000008)
('yuv.max=', 225.13100000000003, 'yuv.min=', -11.20308)
('yuv.max=', 255.0, 'yuv.min=', -35.755069999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.128780000000003)
('yuv.max=', 203.364, 'yuv.min=', -23.365429999999989)
('yuv.max=', 250.65199999999999, 'yuv.min=', -30.19509)
('yuv.max=', 236.245, 'yuv.min=', -35.550479999999993)
('yuv.max=', 250.20199999999997, 'yuv.min=', -8.5819000000000045)
('yuv.max=', 220.86199999999999, 'yuv.min=', -32.605369999999979)
('yuv.max=', 167.428, 'yuv.min=', -24.280459999999998)
('yuv.max=', 221.80500000000001, 'yuv.min=', -28.210729999999998)
('yuv.max=', 228.40899999999996, 'yuv.min=', -40.217500000000008)
('yuv.max=', 255.0, 'yuv.min=', -79.540819999999997)
('yuv.max=', 184.785, 'yuv.min=', -31.47537999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -3.7966200000000043)
('yuv.max=', 225.83199999999999, 'yuv.min=', -43.560419999999993)
('yuv.max=', 253.68999999999997, 'yuv.min=', -39.000209999999981)
('yuv.max=', 228.55900000000003, 'yuv.min=', -34.965359999999997)
('yuv.max=', 180.048, 'yuv.min=', -33.335319999999996)
('yuv.max=', 253.82599999999996, 'yuv.min=', -31.601880000000001)
('yuv.max=', 150.76999999999998, 'yuv.min=', -0.88248000000000104)
('yuv.max=', 210.33699999999999, 'yuv.min=', -71.050339999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.54399999999998, 'yuv.min=', -38.129330000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.786630000000002)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.812349999999999)
('yuv.max=', 251.279, 'yuv.min=', -29.036059999999999)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.85300000000001, 'yuv.min=', -27.460039999999996)
('yuv.max=', 249.83599999999998, 'yuv.min=', -59.750439999999998)
('yuv.max=', 253.505, 'yuv.min=', -18.305169999999997)
('yuv.max=', 222.58599999999998, 'yuv.min=', -22.725119999999986)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.0, 'yuv.min=', -30.590229999999995)
('yuv.max=', 248.989, 'yuv.min=', -13.029949999999994)
('yuv.max=', 255.0, 'yuv.min=', -52.432049999999997)
('yuv.max=', 175.34699999999998, 'yuv.min=', -69.460549999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.415219999999991)
('yuv.max=', 221.14999999999998, 'yuv.min=', -46.820499999999988)
('yuv.max=', 240.28299999999999, 'yuv.min=', -22.450399999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.355089999999979)
('yuv.max=', 251.13499999999999, 'yuv.min=', -91.595979999999983)
('yuv.max=', 254.886, 'yuv.min=', -33.035290000000003)
('yuv.max=', 248.124, 'yuv.min=', -23.495319999999992)
('yuv.max=', 251.27700000000002, 'yuv.min=', -45.750269999999993)
('yuv.max=', 253.17399999999998, 'yuv.min=', -43.075309999999988)
('yuv.max=', 182.46399999999997, 'yuv.min=', -45.275529999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.240750000000006)
('yuv.max=', 252.13099999999997, 'yuv.min=', -23.510259999999988)
('yuv.max=', 220.11399999999998, 'yuv.min=', -13.672010000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 213.94999999999999, 'yuv.min=', -40.025620000000004)
('yuv.max=', 228.554, 'yuv.min=', -16.890089999999997)
('yuv.max=', 231.30100000000002, 'yuv.min=', -16.515360000000001)
('yuv.max=', 251.84299999999996, 'yuv.min=', -33.250250000000001)
('yuv.max=', 242.649, 'yuv.min=', -9.4654299999999978)
('yuv.max=', 177.80699999999999, 'yuv.min=', -20.260549999999995)
('yuv.max=', 245.167, 'yuv.min=', -28.345189999999999)
('yuv.max=', 235.809, 'yuv.min=', -30.960389999999993)
('yuv.max=', 245.745, 'yuv.min=', -54.581029999999991)
('yuv.max=', 249.01999999999998, 'yuv.min=', -48.251860000000001)
('yuv.max=', 250.71099999999998, 'yuv.min=', -30.751900000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.725219999999997)
('yuv.max=', 229.38499999999999, 'yuv.min=', -28.774319999999996)
('yuv.max=', 244.928, 'yuv.min=', -39.480749999999993)
('yuv.max=', 255.0, 'yuv.min=', -32.435710000000014)
('yuv.max=', 239.23099999999997, 'yuv.min=', -59.287330000000011)
('yuv.max=', 250.22800000000001, 'yuv.min=', -34.810159999999996)
('yuv.max=', 225.07900000000001, 'yuv.min=', -34.690639999999995)
('yuv.max=', 197.13699999999997, 'yuv.min=', -46.890629999999994)
('yuv.max=', 213.10499999999999, 'yuv.min=', -61.396920000000001)
('yuv.max=', 239.131, 'yuv.min=', -65.71535999999999)
('yuv.max=', 215.041, 'yuv.min=', -12.374709999999993)
('yuv.max=', 255.0, 'yuv.min=', -35.880389999999991)
('yuv.max=', 223.62799999999999, 'yuv.min=', -37.880589999999991)
('yuv.max=', 214.11099999999999, 'yuv.min=', -37.331149999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -57.271440000000005)
('yuv.max=', 255.0, 'yuv.min=', -54.564859999999989)
('yuv.max=', 248.684, 'yuv.min=', -23.71027999999999)
('yuv.max=', 227.63999999999999, 'yuv.min=', -19.835199999999997)
('yuv.max=', 200.55499999999998, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 225.167, 'yuv.min=', -27.425589999999985)
('yuv.max=', 255.0, 'yuv.min=', -23.525199999999991)
('yuv.max=', 229.72900000000001, 'yuv.min=', -42.000509999999991)
('yuv.max=', 204.941, 'yuv.min=', -13.083960000000005)
('yuv.max=', 227.80799999999999, 'yuv.min=', -20.350189999999998)
('yuv.max=', 234.23099999999999, 'yuv.min=', -42.905169999999998)
('yuv.max=', 251.78899999999999, 'yuv.min=', -35.940149999999996)
('yuv.max=', 202.95699999999999, 'yuv.min=', -34.862459999999999)
('yuv.max=', 176.52799999999999, 'yuv.min=', -49.305809999999994)
('yuv.max=', 144.83499999999998, 'yuv.min=', -42.844179999999994)
('yuv.max=', 229.99399999999997, 'yuv.min=', -50.040329999999997)
('yuv.max=', 253.13099999999997, 'yuv.min=', -17.602340000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 177.53699999999998, 'yuv.min=', -24.540240000000004)
('yuv.max=', 241.74200000000002, 'yuv.min=', -23.095279999999995)
('yuv.max=', 240.148, 'yuv.min=', -54.515469999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.590129999999991)
('yuv.max=', 166.97499999999999, 'yuv.min=', -24.795449999999985)
('yuv.max=', 219.25300000000001, 'yuv.min=', -15.245109999999997)
('yuv.max=', 233.69499999999999, 'yuv.min=', -15.720699999999994)
('yuv.max=', 246.49399999999997, 'yuv.min=', -26.744970000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -38.200129999999987)
('yuv.max=', 227.27099999999999, 'yuv.min=', -15.711180000000002)
('yuv.max=', 228.29899999999998, 'yuv.min=', -61.18421)
('yuv.max=', 238.04399999999998, 'yuv.min=', -12.700039999999994)
('yuv.max=', 241.06, 'yuv.min=', -22.08024)
('yuv.max=', 253.16300000000001, 'yuv.min=', -43.776790000000005)
('yuv.max=', 211.054, 'yuv.min=', -38.389779999999995)
('yuv.max=', 251.34199999999996, 'yuv.min=', -22.495219999999989)
('yuv.max=', 180.96499999999997, 'yuv.min=', -36.610339999999994)
('yuv.max=', 249.98400000000001, 'yuv.min=', -47.434370000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.22799999999998, 'yuv.min=', -9.0239499999999992)
('yuv.max=', 255.0, 'yuv.min=', -23.093630000000001)
('yuv.max=', 236.327, 'yuv.min=', -25.08905)
('yuv.max=', 242.07100000000003, 'yuv.min=', -24.725320000000007)
('yuv.max=', 255.0, 'yuv.min=', -33.589299999999994)
('yuv.max=', 219.696, 'yuv.min=', -32.775509999999997)
('yuv.max=', 228.94399999999999, 'yuv.min=', -12.425319999999989)
('yuv.max=', 196.56899999999999, 'yuv.min=', -74.814809999999994)
('yuv.max=', 198.94, 'yuv.min=', -5.5360699999999952)
('yuv.max=', 196.95099999999999, 'yuv.min=', -46.345759999999999)
('yuv.max=', 201.03200000000001, 'yuv.min=', -53.955659999999995)
('yuv.max=', 177.30200000000002, 'yuv.min=', -28.530269999999991)
('yuv.max=', 201.87700000000001, 'yuv.min=', -39.734250000000003)
('yuv.max=', 240.13099999999997, 'yuv.min=', -4.068950000000001)
('yuv.max=', 209.37899999999999, 'yuv.min=', -44.360499999999988)
('yuv.max=', 255.0, 'yuv.min=', -18.386420000000001)
('yuv.max=', 239.86899999999997, 'yuv.min=', -25.578710000000008)
('yuv.max=', 249.27600000000001, 'yuv.min=', -51.13485)
('yuv.max=', 248.113, 'yuv.min=', -66.870659999999987)
('yuv.max=', 216.262, 'yuv.min=', -7.1212000000000018)
('yuv.max=', 209.309, 'yuv.min=', -51.025490000000005)
('yuv.max=', 180.131, 'yuv.min=', -5.8092100000000002)
('yuv.max=', 237.40399999999997, 'yuv.min=', -74.83578)
('yuv.max=', 231.33499999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 254.29899999999995, 'yuv.min=', -70.090489999999988)
('yuv.max=', 227.434, 'yuv.min=', -18.794779999999999)
('yuv.max=', 242.18899999999999, 'yuv.min=', -21.525829999999999)
('yuv.max=', 227.339, 'yuv.min=', -24.915970000000002)
('yuv.max=', 240.70799999999997, 'yuv.min=', -41.060169999999999)
('yuv.max=', 172.66799999999998, 'yuv.min=', -40.202330000000003)
('yuv.max=', 247.768, 'yuv.min=', -50.69896)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.790479999999992)
('yuv.max=', 216.01499999999999, 'yuv.min=', -28.686089999999993)
('yuv.max=', 255.0, 'yuv.min=', -16.83784)
('yuv.max=', 255.0, 'yuv.min=', -53.670569999999998)
('yuv.max=', 245.49900000000002, 'yuv.min=', -54.660299999999992)
('yuv.max=', 252.35299999999998, 'yuv.min=', -18.009709999999995)
('yuv.max=', 237.762, 'yuv.min=', -64.040499999999994)
('yuv.max=', 204.18599999999998, 'yuv.min=', -27.07036999999999)
('yuv.max=', 215.18899999999996, 'yuv.min=', -63.11052999999999)
('yuv.max=', 210.11600000000001, 'yuv.min=', -26.080639999999995)
('yuv.max=', 239.40199999999999, 'yuv.min=', -30.575289999999985)
('yuv.max=', 255.0, 'yuv.min=', -34.054899999999996)
('yuv.max=', 194.761, 'yuv.min=', -45.92040999999999)
('yuv.max=', 222.70400000000001, 'yuv.min=', -44.890429999999995)
('yuv.max=', 235.18299999999999, 'yuv.min=', -36.660250000000005)
('yuv.max=', 188.43499999999997, 'yuv.min=', -25.910499999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.975159999999995)
('yuv.max=', 200.84700000000001, 'yuv.min=', -34.846410000000006)
('yuv.max=', 229.60399999999998, 'yuv.min=', -31.650130000000011)
('yuv.max=', 254.77200000000002, 'yuv.min=', -16.588990000000003)
('yuv.max=', 240.869, 'yuv.min=', -85.850589999999997)
('yuv.max=', 206.16800000000001, 'yuv.min=', -38.873090000000005)
('yuv.max=', 212.71799999999999, 'yuv.min=', -61.101189999999988)
('yuv.max=', 232.96299999999999, 'yuv.min=', -34.884860000000003)
('yuv.max=', 233.017, 'yuv.min=', -27.430159999999997)
('yuv.max=', 247.22799999999998, 'yuv.min=', -19.079939999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.480509999999997)
('yuv.max=', 232.55099999999999, 'yuv.min=', -55.603479999999998)
('yuv.max=', 199.73699999999999, 'yuv.min=', -51.005010000000013)
('yuv.max=', 233.56899999999999, 'yuv.min=', -36.710349999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -32.045559999999995)
('yuv.max=', 195.15199999999999, 'yuv.min=', -18.589480000000002)
('yuv.max=', 244.249, 'yuv.min=', -21.024949999999986)
('yuv.max=', 239.55200000000002, 'yuv.min=', -58.820469999999986)
('yuv.max=', 239.66299999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 254.017, 'yuv.min=', -25.422780000000003)
('yuv.max=', 168.62599999999998, 'yuv.min=', -4.9469899999999996)
('yuv.max=', 210.05799999999999, 'yuv.min=', -59.969030000000004)
('yuv.max=', 251.58699999999996, 'yuv.min=', -55.700649999999996)
('yuv.max=', 249.31999999999999, 'yuv.min=', -30.690240000000003)
('yuv.max=', 222.58499999999998, 'yuv.min=', -39.127849999999995)
('yuv.max=', 255.0, 'yuv.min=', -62.099360000000004)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.55500000000001, 'yuv.min=', -10.457390000000004)
('yuv.max=', 179.10299999999998, 'yuv.min=', -38.195559999999986)
('yuv.max=', 254.77200000000002, 'yuv.min=', -22.395209999999985)
('yuv.max=', 222.03299999999999, 'yuv.min=', -29.368620000000004)
('yuv.max=', 255.0, 'yuv.min=', -55.985739999999993)
('yuv.max=', 213.72499999999999, 'yuv.min=', -61.520739999999989)
('yuv.max=', 185.61499999999998, 'yuv.min=', -43.385019999999997)
('yuv.max=', 253.185, 'yuv.min=', -22.473209999999995)
('yuv.max=', 230.15300000000002, 'yuv.min=', -19.430589999999992)
('yuv.max=', 245.69599999999997, 'yuv.min=', -35.456230000000005)
('yuv.max=', 252.42999999999998, 'yuv.min=', -23.510360000000002)
('yuv.max=', 236.86899999999997, 'yuv.min=', -16.260149999999996)
('yuv.max=', 254.10300000000001, 'yuv.min=', -60.355350000000008)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 220.25999999999999, 'yuv.min=', -46.135369999999995)
('yuv.max=', 220.63, 'yuv.min=', -11.922780000000003)
('yuv.max=', 227.80900000000003, 'yuv.min=', -13.932710000000007)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.505389999999988)
('yuv.max=', 232.53999999999999, 'yuv.min=', -31.69068)
('yuv.max=', 252.10499999999996, 'yuv.min=', -93.675449999999984)
('yuv.max=', 223.316, 'yuv.min=', -16.630309999999994)
('yuv.max=', 253.071, 'yuv.min=', -19.405279999999994)
('yuv.max=', 186.327, 'yuv.min=', -32.590429999999998)
('yuv.max=', 250.83599999999998, 'yuv.min=', -32.580059999999989)
('yuv.max=', 216.43899999999999, 'yuv.min=', -20.06053)
('yuv.max=', 250.34799999999996, 'yuv.min=', -19.209589999999999)
('yuv.max=', 255.0, 'yuv.min=', -6.25535)
('yuv.max=', 255.0, 'yuv.min=', -30.930509999999991)
('yuv.max=', 238.43299999999999, 'yuv.min=', -9.3404799999999977)
('yuv.max=', 244.05000000000001, 'yuv.min=', -26.615499999999997)
('yuv.max=', 234.56800000000001, 'yuv.min=', -9.4642899999999912)
('yuv.max=', 198.27099999999999, 'yuv.min=', -12.755230000000001)
('yuv.max=', 226.02999999999997, 'yuv.min=', -34.60557)
('yuv.max=', 254.54400000000001, 'yuv.min=', -14.69062000000001)
('yuv.max=', 220.64699999999999, 'yuv.min=', -12.937430000000003)
('yuv.max=', 239.863, 'yuv.min=', -8.3860100000000024)
('yuv.max=', 233.929, 'yuv.min=', -8.2890300000000039)
('yuv.max=', 243.0, 'yuv.min=', -19.060429999999993)
('yuv.max=', 253.17600000000002, 'yuv.min=', -61.480489999999989)
('yuv.max=', 170.63200000000001, 'yuv.min=', -33.111280000000008)
('yuv.max=', 174.37799999999999, 'yuv.min=', -25.114989999999999)
('yuv.max=', 238.06499999999997, 'yuv.min=', -14.60023)
('yuv.max=', 247.07300000000001, 'yuv.min=', -20.790479999999992)
('yuv.max=', 209.70399999999995, 'yuv.min=', -10.341970000000003)
('yuv.max=', 219.27699999999999, 'yuv.min=', -33.060599999999987)
('yuv.max=', 255.0, 'yuv.min=', -81.283969999999997)
('yuv.max=', 211.10299999999995, 'yuv.min=', -74.781900000000007)
('yuv.max=', 200.22899999999998, 'yuv.min=', -24.225269999999991)
('yuv.max=', 224.077, 'yuv.min=', -15.715279999999989)
('yuv.max=', 220.22799999999998, 'yuv.min=', -18.860409999999995)
('yuv.max=', 228.46000000000001, 'yuv.min=', -23.568830000000005)
('yuv.max=', 241.11799999999999, 'yuv.min=', -40.915339999999986)
('yuv.max=', 234.86799999999997, 'yuv.min=', -34.735459999999996)
('yuv.max=', 222.52699999999999, 'yuv.min=', -12.510389999999996)
('yuv.max=', 254.29899999999995, 'yuv.min=', -15.32560999999999)
('yuv.max=', 178.70899999999997, 'yuv.min=', -30.00057)
('yuv.max=', 255.0, 'yuv.min=', -73.250559999999993)
('yuv.max=', 246.18900000000002, 'yuv.min=', -61.080449999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.460070000000007)
('yuv.max=', 242.70099999999999, 'yuv.min=', -63.835909999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -12.390899999999998)
('yuv.max=', 181.76599999999999, 'yuv.min=', -54.554489999999994)
('yuv.max=', 243.13499999999999, 'yuv.min=', -14.43526)
('yuv.max=', 248.327, 'yuv.min=', -22.860750000000003)
('yuv.max=', 226.97299999999998, 'yuv.min=', -38.540409999999994)
('yuv.max=', 251.142, 'yuv.min=', -29.945349999999998)
('yuv.max=', 245.233, 'yuv.min=', -33.380139999999997)
('yuv.max=', 249.17399999999998, 'yuv.min=', -29.902100000000004)
('yuv.max=', 255.0, 'yuv.min=', -30.385639999999995)
('yuv.max=', 217.40299999999999, 'yuv.min=', -87.21380000000002)
('yuv.max=', 229.018, 'yuv.min=', -70.046769999999995)
('yuv.max=', 233.18900000000002, 'yuv.min=', -77.715329999999994)
('yuv.max=', 155.078, 'yuv.min=', -37.165579999999991)
('yuv.max=', 232.75799999999998, 'yuv.min=', -17.490149999999989)
('yuv.max=', 236.303, 'yuv.min=', -25.673340000000003)
('yuv.max=', 213.245, 'yuv.min=', -19.235139999999994)
('yuv.max=', 233.03199999999998, 'yuv.min=', -50.170219999999993)
('yuv.max=', 161.70999999999998, 'yuv.min=', -48.750569999999996)
('yuv.max=', 253.41299999999998, 'yuv.min=', -28.170390000000005)
('yuv.max=', 252.935, 'yuv.min=', -29.944110000000002)
('yuv.max=', 241.04699999999997, 'yuv.min=', -66.12236)
('yuv.max=', 250.80399999999997, 'yuv.min=', -29.845339999999993)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -28.975070000000009)
('yuv.max=', 226.47299999999998, 'yuv.min=', -21.81965000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 246.41199999999998, 'yuv.min=', -35.610240000000005)
('yuv.max=', 237.37700000000001, 'yuv.min=', -26.669810000000005)
('yuv.max=', 242.58899999999997, 'yuv.min=', -73.251169999999988)
('yuv.max=', 242.48399999999998, 'yuv.min=', -72.650499999999994)
('yuv.max=', 241.869, 'yuv.min=', -16.315339999999996)
('yuv.max=', 194.297, 'yuv.min=', -45.308389999999996)
('yuv.max=', 198.10499999999999, 'yuv.min=', -47.560819999999993)
('yuv.max=', 254.70099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 196.42899999999997, 'yuv.min=', -18.033239999999999)
('yuv.max=', 217.19300000000001, 'yuv.min=', -62.48227)
('yuv.max=', 243.989, 'yuv.min=', -6.2500099999999961)
('yuv.max=', 228.16999999999999, 'yuv.min=', -23.699740000000006)
('yuv.max=', 209.095, 'yuv.min=', -36.940249999999999)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 237.79199999999997, 'yuv.min=', -47.050399999999996)
('yuv.max=', 219.31, 'yuv.min=', -14.995699999999999)
('yuv.max=', 224.08199999999997, 'yuv.min=', -21.553300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.262, 'yuv.min=', -40.92577)
('yuv.max=', 216.44499999999999, 'yuv.min=', -29.379739999999991)
('yuv.max=', 232.81799999999998, 'yuv.min=', -95.08896)
('yuv.max=', 152.22399999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 236.74599999999998, 'yuv.min=', -19.320209999999989)
('yuv.max=', 251.76599999999999, 'yuv.min=', -101.99578999999999)
('yuv.max=', 246.77799999999996, 'yuv.min=', -34.824740000000006)
('yuv.max=', 247.90099999999998, 'yuv.min=', -18.020080000000004)
('yuv.max=', 234.12800000000001, 'yuv.min=', -46.071039999999996)
('yuv.max=', 224.69000000000003, 'yuv.min=', -8.217290000000002)
('yuv.max=', 223.57599999999999, 'yuv.min=', -36.540209999999995)
('yuv.max=', 239.40000000000001, 'yuv.min=', -90.295850000000002)
('yuv.max=', 228.41499999999999, 'yuv.min=', -34.846069999999997)
('yuv.max=', 248.04900000000001, 'yuv.min=', -28.926060000000007)
('yuv.max=', 244.518, 'yuv.min=', -22.020440000000004)
('yuv.max=', 251.21299999999999, 'yuv.min=', -49.950689999999994)
('yuv.max=', 253.46199999999999, 'yuv.min=', -20.250179999999997)
('yuv.max=', 251.15699999999998, 'yuv.min=', -8.2800899999999995)
('yuv.max=', 255.0, 'yuv.min=', -33.190489999999997)
('yuv.max=', 194.74999999999997, 'yuv.min=', -38.280630000000002)
('yuv.max=', 241.35399999999998, 'yuv.min=', -22.615290000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999998)
('yuv.max=', 220.45599999999999, 'yuv.min=', -15.545139999999996)
('yuv.max=', 226.238, 'yuv.min=', -32.375469999999993)
('yuv.max=', 245.983, 'yuv.min=', -18.152900000000002)
('yuv.max=', 251.71100000000001, 'yuv.min=', -53.81539999999999)
('yuv.max=', 244.982, 'yuv.min=', -69.560559999999995)
('yuv.max=', 244.74399999999997, 'yuv.min=', -39.433660000000003)
('yuv.max=', 224.06100000000001, 'yuv.min=', -47.175719999999984)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -53.966029999999989)
('yuv.max=', 208.96600000000001, 'yuv.min=', -3.0301799999999943)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.005209999999995)
('yuv.max=', 250.94599999999997, 'yuv.min=', -23.180349999999986)
('yuv.max=', 232.37200000000001, 'yuv.min=', -61.20085000000001)
('yuv.max=', 235.60900000000001, 'yuv.min=', -6.505219999999996)
('yuv.max=', 250.34200000000001, 'yuv.min=', -39.020300000000006)
('yuv.max=', 236.31299999999999, 'yuv.min=', -57.715789999999998)
('yuv.max=', 214.28199999999998, 'yuv.min=', -25.385139999999996)
('yuv.max=', 185.05099999999999, 'yuv.min=', -29.915469999999988)
('yuv.max=', 246.80399999999997, 'yuv.min=', -39.395679999999999)
('yuv.max=', 212.047, 'yuv.min=', -16.730179999999997)
('yuv.max=', 227.762, 'yuv.min=', -32.720319999999987)
('yuv.max=', 235.03699999999998, 'yuv.min=', -80.930589999999995)
('yuv.max=', 253.21699999999998, 'yuv.min=', -29.375169999999997)
('yuv.max=', 240.92599999999999, 'yuv.min=', -52.125599999999984)
('yuv.max=', 255.0, 'yuv.min=', -24.555179999999993)
('yuv.max=', 244.84099999999998, 'yuv.min=', -9.8951899999999959)
('yuv.max=', 251.16800000000001, 'yuv.min=', -27.315209999999986)
('yuv.max=', 233.63499999999999, 'yuv.min=', -33.950319999999998)
('yuv.max=', 253.376, 'yuv.min=', -41.879759999999997)
('yuv.max=', 223.78299999999999, 'yuv.min=', -42.645389999999992)
('yuv.max=', 205.369, 'yuv.min=', -55.230479999999986)
('yuv.max=', 255.0, 'yuv.min=', -32.950219999999987)
('yuv.max=', 206.17499999999998, 'yuv.min=', -6.7234800000000021)
('yuv.max=', 255.0, 'yuv.min=', -12.507250000000003)
('yuv.max=', 240.00499999999997, 'yuv.min=', -18.178840000000008)
('yuv.max=', 212.74899999999997, 'yuv.min=', -32.985900000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -18.005139999999997)
('yuv.max=', 213.70499999999998, 'yuv.min=', -60.824649999999991)
('yuv.max=', 249.85399999999998, 'yuv.min=', -2.3301000000000158)
('yuv.max=', 242.184, 'yuv.min=', -19.913690000000003)
('yuv.max=', 247.88600000000002, 'yuv.min=', -14.974959999999996)
('yuv.max=', 255.0, 'yuv.min=', -21.613799999999998)
('yuv.max=', 245.96099999999998, 'yuv.min=', -23.710449999999994)
('yuv.max=', 199.37299999999999, 'yuv.min=', -33.850309999999993)
('yuv.max=', 226.89399999999998, 'yuv.min=', -29.830399999999994)
('yuv.max=', 224.10299999999998, 'yuv.min=', -16.026160000000004)
('yuv.max=', 239.64099999999996, 'yuv.min=', -37.580559999999991)
('yuv.max=', 251.15699999999998, 'yuv.min=', -17.040800000000008)
('yuv.max=', 121.03400000000001, 'yuv.min=', -38.425460000000001)
('yuv.max=', 247.952, 'yuv.min=', -72.89533999999999)
('yuv.max=', 255.0, 'yuv.min=', -74.776510000000002)
('yuv.max=', 245.08799999999999, 'yuv.min=', -21.499280000000002)
('yuv.max=', 237.30999999999997, 'yuv.min=', -14.785399999999999)
('yuv.max=', 157.38399999999999, 'yuv.min=', -25.770240000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.21208)
('yuv.max=', 158.83899999999997, 'yuv.min=', -50.432699999999997)
('yuv.max=', 241.94699999999997, 'yuv.min=', -36.131450000000001)
('yuv.max=', 237.19199999999998, 'yuv.min=', -36.606700000000004)
('yuv.max=', 173.27899999999997, 'yuv.min=', -36.550579999999997)
('yuv.max=', 255.0, 'yuv.min=', -29.400439999999996)
('yuv.max=', 251.77199999999999, 'yuv.min=', -83.02042999999999)
('yuv.max=', 240.0, 'yuv.min=', -39.740529999999993)
('yuv.max=', 223.09899999999996, 'yuv.min=', -23.024160000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 225.26400000000001, 'yuv.min=', -63.970369999999996)
('yuv.max=', 205.11499999999998, 'yuv.min=', -49.970199999999991)
('yuv.max=', 209.88799999999998, 'yuv.min=', -86.446079999999995)
('yuv.max=', 244.87599999999998, 'yuv.min=', -26.201930000000008)
('yuv.max=', 240.08599999999998, 'yuv.min=', -34.25034999999999)
('yuv.max=', 250.255, 'yuv.min=', -20.980129999999992)
('yuv.max=', 254.202, 'yuv.min=', -38.971159999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 242.57900000000001, 'yuv.min=', -29.209240000000001)
('yuv.max=', 207.429, 'yuv.min=', -39.881420000000006)
('yuv.max=', 253.86000000000001, 'yuv.min=', -46.404289999999996)
('yuv.max=', 248.32599999999999, 'yuv.min=', -33.08402000000001)
('yuv.max=', 239.64799999999997, 'yuv.min=', -22.507860000000001)
('yuv.max=', 230.21699999999998, 'yuv.min=', -31.652850000000001)
('yuv.max=', 236.32900000000001, 'yuv.min=', -31.779979999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -27.740559999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -44.175419999999995)
('yuv.max=', 218.0, 'yuv.min=', -12.65954)
('yuv.max=', 253.80399999999997, 'yuv.min=', -45.905469999999994)
('yuv.max=', 228.196, 'yuv.min=', -78.151049999999998)
('yuv.max=', 200.58599999999998, 'yuv.min=', -37.035689999999995)
('yuv.max=', 254.28799999999998, 'yuv.min=', -21.365229999999993)
('yuv.max=', 246.31, 'yuv.min=', -14.030049999999994)
('yuv.max=', 237.97399999999996, 'yuv.min=', -49.865480000000005)
('yuv.max=', 201.94099999999997, 'yuv.min=', -45.275529999999989)
('yuv.max=', 246.815, 'yuv.min=', -35.605669999999996)
('yuv.max=', 245.191, 'yuv.min=', -34.420490000000001)
('yuv.max=', 127.15899999999999, 'yuv.min=', -39.340489999999996)
('yuv.max=', 253.40199999999996, 'yuv.min=', -24.710379999999997)
('yuv.max=', 240.411, 'yuv.min=', -54.437500000000014)
('yuv.max=', 255.0, 'yuv.min=', -9.87331)
('yuv.max=', 205.81699999999998, 'yuv.min=', -48.545250000000003)
('yuv.max=', 250.815, 'yuv.min=', -33.875619999999998)
('yuv.max=', 250.44499999999996, 'yuv.min=', -19.090309999999988)
('yuv.max=', 239.22799999999995, 'yuv.min=', -34.61142000000001)
('yuv.max=', 237.03, 'yuv.min=', -14.170309999999999)
('yuv.max=', 240.88599999999997, 'yuv.min=', -96.005559999999988)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.75299999999999, 'yuv.min=', -25.825429999999987)
('yuv.max=', 168.303, 'yuv.min=', -32.185819999999993)
('yuv.max=', 184.17400000000001, 'yuv.min=', -37.565619999999996)
('yuv.max=', 255.0, 'yuv.min=', -62.241759999999992)
('yuv.max=', 211.68199999999999, 'yuv.min=', -11.655119999999993)
('yuv.max=', 246.32900000000001, 'yuv.min=', -36.385009999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -76.826040000000006)
('yuv.max=', 255.0, 'yuv.min=', -14.970389999999998)
('yuv.max=', 253.99999999999997, 'yuv.min=', -38.230670000000003)
('yuv.max=', 222.798, 'yuv.min=', -18.054270000000002)
('yuv.max=', 253.40199999999996, 'yuv.min=', -12.940310000000007)
('yuv.max=', 240.78699999999998, 'yuv.min=', -50.080579999999998)
('yuv.max=', 185.94799999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 237.18799999999999, 'yuv.min=', -46.429599999999986)
('yuv.max=', 250.94599999999997, 'yuv.min=', -15.35549)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.92699999999999, 'yuv.min=', -92.865560000000002)
('yuv.max=', 255.0, 'yuv.min=', -36.080410000000001)
('yuv.max=', 206.56299999999999, 'yuv.min=', -30.345390000000002)
('yuv.max=', 245.18399999999997, 'yuv.min=', -33.050229999999999)
('yuv.max=', 201.149, 'yuv.min=', -27.870449999999998)
('yuv.max=', 199.24299999999999, 'yuv.min=', -12.805490000000006)
('yuv.max=', 245.03199999999998, 'yuv.min=', -17.690169999999988)
('yuv.max=', 245.815, 'yuv.min=', -65.551019999999994)
('yuv.max=', 247.56899999999996, 'yuv.min=', -33.172030000000007)
('yuv.max=', 222.06199999999998, 'yuv.min=', -52.070409999999995)
('yuv.max=', 198.07399999999998, 'yuv.min=', -19.22552000000001)
('yuv.max=', 252.68599999999998, 'yuv.min=', -23.61027)
('yuv.max=', 210.29299999999998, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 238.05700000000002, 'yuv.min=', -22.850439999999985)
('yuv.max=', 252.57199999999997, 'yuv.min=', -31.013190000000009)
('yuv.max=', 254.11399999999998, 'yuv.min=', -31.145469999999992)
('yuv.max=', 254.40199999999999, 'yuv.min=', -85.050510000000003)
('yuv.max=', 226.20799999999997, 'yuv.min=', -23.995369999999998)
('yuv.max=', 199.89399999999998, 'yuv.min=', -66.960299999999989)
('yuv.max=', 255.0, 'yuv.min=', -40.68544)
('yuv.max=', 154.529, 'yuv.min=', -22.505589999999987)
('yuv.max=', 251.77199999999999, 'yuv.min=', -28.097280000000001)
('yuv.max=', 240.66799999999995, 'yuv.min=', -27.188880000000001)
('yuv.max=', 248.02199999999999, 'yuv.min=', -16.3751)
('yuv.max=', 215.619, 'yuv.min=', -16.430289999999999)
('yuv.max=', 246.10300000000001, 'yuv.min=', -24.985099999999992)
('yuv.max=', 196.52799999999999, 'yuv.min=', -60.150479999999988)
('yuv.max=', 193.82999999999998, 'yuv.min=', -30.575289999999988)
('yuv.max=', 255.0, 'yuv.min=', -31.630579999999995)
('yuv.max=', 224.13999999999999, 'yuv.min=', -12.110349999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -23.770039999999991)
('yuv.max=', 218.59699999999998, 'yuv.min=', -33.182010000000005)
('yuv.max=', 248.42400000000001, 'yuv.min=', -34.750399999999985)
('yuv.max=', 214.928, 'yuv.min=', -10.969989999999985)
('yuv.max=', 161.47900000000001, 'yuv.min=', -48.92071)
('yuv.max=', 144.251, 'yuv.min=', -51.72099)
('yuv.max=', 224.33099999999996, 'yuv.min=', -20.277610000000006)
('yuv.max=', 229.065, 'yuv.min=', -38.185189999999992)
('yuv.max=', 97.0, 'yuv.min=', -3.2899599999999993)
('yuv.max=', 249.93899999999999, 'yuv.min=', -21.646489999999996)
('yuv.max=', 231.29300000000001, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 227.93899999999999, 'yuv.min=', -18.520129999999991)
('yuv.max=', 215.93199999999999, 'yuv.min=', -35.855079999999987)
('yuv.max=', 208.404, 'yuv.min=', -55.915609999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.9823599999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.3503199999999964)
('yuv.max=', 233.62099999999998, 'yuv.min=', -35.095249999999993)
('yuv.max=', 255.0, 'yuv.min=', -23.350489999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.20199999999997, 'yuv.min=', -18.037589999999994)
('yuv.max=', 208.17699999999999, 'yuv.min=', -44.800789999999992)
('yuv.max=', 181.422, 'yuv.min=', -18.36036)
('yuv.max=', 232.73999999999998, 'yuv.min=', -25.509699999999999)
('yuv.max=', 247.90800000000002, 'yuv.min=', -20.070899999999998)
('yuv.max=', 238.12899999999999, 'yuv.min=', -29.770639999999993)
('yuv.max=', 255.0, 'yuv.min=', -42.884420000000006)
('yuv.max=', 252.61899999999997, 'yuv.min=', -34.720519999999993)
('yuv.max=', 209.76700000000002, 'yuv.min=', -50.295540000000003)
('yuv.max=', 255.0, 'yuv.min=', -61.266040000000004)
('yuv.max=', 227.77000000000001, 'yuv.min=', -39.264940000000003)
('yuv.max=', 243.01399999999998, 'yuv.min=', -28.289999999999996)
('yuv.max=', 233.95299999999997, 'yuv.min=', -21.896100000000001)
('yuv.max=', 182.166, 'yuv.min=', -17.117680000000004)
('yuv.max=', 200.28399999999999, 'yuv.min=', -59.98980000000001)
('yuv.max=', 209.62199999999999, 'yuv.min=', -37.282860000000007)
('yuv.max=', 235.79699999999997, 'yuv.min=', -15.785409999999997)
('yuv.max=', 255.0, 'yuv.min=', -12.211280000000002)
('yuv.max=', 221.99399999999997, 'yuv.min=', -17.77524)
('yuv.max=', 205.12099999999998, 'yuv.min=', -36.995439999999995)
('yuv.max=', 216.08099999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 245.95699999999999, 'yuv.min=', -37.800089999999997)
('yuv.max=', 253.70099999999996, 'yuv.min=', -28.715350000000004)
('yuv.max=', 252.64099999999996, 'yuv.min=', -12.765599999999996)
('yuv.max=', 254.886, 'yuv.min=', -81.119779999999992)
('yuv.max=', 255.0, 'yuv.min=', -9.9250699999999981)
('yuv.max=', 248.91800000000001, 'yuv.min=', -16.530299999999993)
('yuv.max=', 230.86199999999999, 'yuv.min=', -34.25034999999999)
('yuv.max=', 213.161, 'yuv.min=', -24.283989999999999)
('yuv.max=', 250.565, 'yuv.min=', -53.485489999999992)
('yuv.max=', 227.87300000000002, 'yuv.min=', -42.574210000000008)
('yuv.max=', 246.64099999999999, 'yuv.min=', -32.190860000000001)
('yuv.max=', 186.46699999999998, 'yuv.min=', -28.630279999999999)
('yuv.max=', 175.26799999999997, 'yuv.min=', -35.329580000000007)
('yuv.max=', 238.18499999999997, 'yuv.min=', -20.185980000000004)
('yuv.max=', 252.06, 'yuv.min=', -25.470209999999994)
('yuv.max=', 242.744, 'yuv.min=', -18.435059999999989)
('yuv.max=', 233.33500000000001, 'yuv.min=', -89.470460000000003)
('yuv.max=', 222.65599999999998, 'yuv.min=', -21.710789999999996)
('yuv.max=', 237.28799999999998, 'yuv.min=', -37.825399999999988)
('yuv.max=', 255.0, 'yuv.min=', -35.550479999999993)
('yuv.max=', 244.797, 'yuv.min=', -30.954270000000001)
('yuv.max=', 239.89999999999998, 'yuv.min=', -43.745499999999993)
('yuv.max=', 217.06, 'yuv.min=', -32.275459999999988)
('yuv.max=', 226.20000000000002, 'yuv.min=', -56.54097999999999)
('yuv.max=', 228.62, 'yuv.min=', -40.240579999999994)
('yuv.max=', 194.00299999999999, 'yuv.min=', -39.701660000000004)
('yuv.max=', 252.935, 'yuv.min=', -36.235609999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -43.915639999999996)
('yuv.max=', 244.86899999999997, 'yuv.min=', -23.980429999999991)
('yuv.max=', 191.32399999999998, 'yuv.min=', -24.595429999999993)
('yuv.max=', 253.52699999999999, 'yuv.min=', -38.660870000000003)
('yuv.max=', 254.43000000000001, 'yuv.min=', -26.512409999999999)
('yuv.max=', 242.45000000000002, 'yuv.min=', -22.35038999999999)
('yuv.max=', 240.374, 'yuv.min=', -24.958770000000005)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.195489999999999)
('yuv.max=', 248.929, 'yuv.min=', -16.877440000000004)
('yuv.max=', 197.79300000000001, 'yuv.min=', -24.325279999999996)
('yuv.max=', 250.00199999999998, 'yuv.min=', -60.317240000000012)
('yuv.max=', 245.45499999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 249.66199999999998, 'yuv.min=', -14.996719999999996)
('yuv.max=', 174.92499999999998, 'yuv.min=', -8.9801599999999961)
('yuv.max=', 255.0, 'yuv.min=', -56.726749999999996)
('yuv.max=', 190.31399999999999, 'yuv.min=', -75.895639999999986)
('yuv.max=', 248.69, 'yuv.min=', -22.795249999999996)
('yuv.max=', 205.02499999999998, 'yuv.min=', -30.872399999999995)
('yuv.max=', 250.66899999999998, 'yuv.min=', -55.275299999999987)
('yuv.max=', 232.114, 'yuv.min=', -60.765479999999982)
('yuv.max=', 221.33799999999999, 'yuv.min=', -6.4201499999999854)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.97549999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -25.795549999999992)
('yuv.max=', 227.38499999999999, 'yuv.min=', -65.115299999999991)
('yuv.max=', 226.10400000000001, 'yuv.min=', -28.745229999999989)
('yuv.max=', 211.65600000000001, 'yuv.min=', -35.664199999999994)
('yuv.max=', 210.0, 'yuv.min=', -8.8871300000000062)
('yuv.max=', 254.245, 'yuv.min=', -43.274750000000004)
('yuv.max=', 245.50899999999999, 'yuv.min=', -38.385210000000001)
('yuv.max=', 251.70699999999999, 'yuv.min=', -56.805329999999998)
('yuv.max=', 222.03799999999998, 'yuv.min=', -17.230659999999993)
('yuv.max=', 249.91800000000001, 'yuv.min=', -24.78507999999999)
('yuv.max=', 224.71600000000001, 'yuv.min=', -37.880589999999991)
('yuv.max=', 199.61699999999999, 'yuv.min=', -34.520499999999998)
('yuv.max=', 141.15699999999998, 'yuv.min=', -6.5500399999999885)
('yuv.max=', 244.62, 'yuv.min=', -36.475880000000004)
('yuv.max=', 217.87999999999997, 'yuv.min=', -31.110850000000006)
('yuv.max=', 235.90499999999997, 'yuv.min=', -29.05236)
('yuv.max=', 245.46499999999997, 'yuv.min=', -54.955759999999998)
('yuv.max=', 232.76799999999997, 'yuv.min=', -57.527420000000014)
('yuv.max=', 245.25899999999999, 'yuv.min=', -69.757499999999993)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.69, 'yuv.min=', -20.648970000000002)
('yuv.max=', 237.17199999999997, 'yuv.min=', -52.082520000000009)
('yuv.max=', 249.529, 'yuv.min=', -41.885559999999998)
('yuv.max=', 184.19, 'yuv.min=', -7.6455799999999847)
('yuv.max=', 245.15700000000001, 'yuv.min=', -12.825359999999991)
('yuv.max=', 249.96699999999998, 'yuv.min=', -42.140769999999996)
('yuv.max=', 237.78099999999998, 'yuv.min=', -71.865359999999995)
('yuv.max=', 239.35900000000001, 'yuv.min=', -46.156880000000001)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 185.434, 'yuv.min=', -38.095549999999989)
('yuv.max=', 199.95399999999998, 'yuv.min=', -27.325170000000004)
('yuv.max=', 237.97199999999998, 'yuv.min=', -37.625379999999993)
('yuv.max=', 229.23999999999998, 'yuv.min=', -26.35535999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.030249999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -41.300439999999988)
('yuv.max=', 251.60900000000001, 'yuv.min=', -48.105689999999989)
('yuv.max=', 248.99999999999997, 'yuv.min=', -26.567969999999999)
('yuv.max=', 251.45599999999996, 'yuv.min=', -14.07471000000001)
('yuv.max=', 236.22799999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 251.75199999999998, 'yuv.min=', -49.159750000000003)
('yuv.max=', 222.178, 'yuv.min=', -34.480249999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -44.075409999999991)
('yuv.max=', 243.36999999999998, 'yuv.min=', -91.155689999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.395439999999994)
('yuv.max=', 236.80599999999998, 'yuv.min=', -11.045960000000001)
('yuv.max=', 243.22800000000001, 'yuv.min=', -37.250649999999993)
('yuv.max=', 247.33699999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 250.08199999999997, 'yuv.min=', -40.039060000000006)
('yuv.max=', 229.12900000000002, 'yuv.min=', -16.94527999999999)
('yuv.max=', 232.91, 'yuv.min=', -102.48461)
('yuv.max=', 255.0, 'yuv.min=', -33.869519999999994)
('yuv.max=', 215.47299999999998, 'yuv.min=', -20.43561)
('yuv.max=', 255.0, 'yuv.min=', -7.8501699999999968)
('yuv.max=', 201.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -31.975429999999999)
('yuv.max=', 237.74599999999998, 'yuv.min=', -56.320219999999985)
('yuv.max=', 239.65599999999998, 'yuv.min=', -65.876819999999995)
('yuv.max=', 237.114, 'yuv.min=', -12.199989999999994)
('yuv.max=', 255.0, 'yuv.min=', -27.897580000000001)
('yuv.max=', 247.58199999999997, 'yuv.min=', -46.568399999999997)
('yuv.max=', 175.17599999999999, 'yuv.min=', -24.795449999999999)
('yuv.max=', 254.316, 'yuv.min=', -20.948299999999996)
('yuv.max=', 178.815, 'yuv.min=', -7.1949199999999962)
('yuv.max=', 254.47300000000001, 'yuv.min=', -61.544030000000014)
('yuv.max=', 254.11399999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 236.90099999999998, 'yuv.min=', -35.19422999999999)
('yuv.max=', 218.298, 'yuv.min=', -22.710179999999994)
('yuv.max=', 247.58699999999999, 'yuv.min=', -32.975529999999992)
('yuv.max=', 243.96099999999998, 'yuv.min=', -58.92342)
('yuv.max=', 255.0, 'yuv.min=', -79.245360000000005)
('yuv.max=', 255.0, 'yuv.min=', -57.342320000000015)
('yuv.max=', 254.40199999999999, 'yuv.min=', -40.375039999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.616500000000006)
('yuv.max=', 251.14599999999996, 'yuv.min=', -19.78107)
('yuv.max=', 245.09200000000001, 'yuv.min=', -16.319909999999993)
('yuv.max=', 248.57599999999999, 'yuv.min=', -21.95701)
('yuv.max=', 217.18000000000001, 'yuv.min=', -95.709890000000001)
('yuv.max=', 249.673, 'yuv.min=', -35.950519999999997)
('yuv.max=', 255.0, 'yuv.min=', -43.830570000000002)
('yuv.max=', 236.04099999999997, 'yuv.min=', -38.529160000000005)
('yuv.max=', 250.0, 'yuv.min=', -35.908379999999994)
('yuv.max=', 250.86899999999997, 'yuv.min=', -53.821770000000001)
('yuv.max=', 210.47900000000001, 'yuv.min=', -32.792090000000002)
('yuv.max=', 251.02099999999999, 'yuv.min=', -31.36042999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.112640000000006)
('yuv.max=', 196.22200000000001, 'yuv.min=', -73.169299999999993)
('yuv.max=', 129.33599999999998, 'yuv.min=', -31.00063999999999)
('yuv.max=', 248.71699999999998, 'yuv.min=', -68.400689999999997)
('yuv.max=', 162.15399999999997, 'yuv.min=', -15.330180000000002)
('yuv.max=', 227.10400000000001, 'yuv.min=', -27.340520000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.52591)
('yuv.max=', 102.75699999999999, 'yuv.min=', -90.040639999999982)
('yuv.max=', 241.59099999999998, 'yuv.min=', -30.945449999999987)
('yuv.max=', 228.09100000000001, 'yuv.min=', -39.700279999999992)
('yuv.max=', 251.04900000000001, 'yuv.min=', -15.660089999999993)
('yuv.max=', 252.196, 'yuv.min=', -17.175179999999994)
('yuv.max=', 239.80399999999997, 'yuv.min=', -22.380269999999989)
('yuv.max=', 245.886, 'yuv.min=', -18.222329999999999)
('yuv.max=', 220.96899999999999, 'yuv.min=', -24.901260000000001)
('yuv.max=', 226.39400000000001, 'yuv.min=', -22.260749999999994)
('yuv.max=', 225.78599999999997, 'yuv.min=', -77.421099999999996)
('yuv.max=', 255.0, 'yuv.min=', -29.315410000000004)
('yuv.max=', 255.0, 'yuv.min=', -41.145240000000001)
('yuv.max=', 251.85300000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 218.59399999999997, 'yuv.min=', -36.550410000000007)
('yuv.max=', 255.0, 'yuv.min=', -23.250479999999985)
('yuv.max=', 202.286, 'yuv.min=', -23.759249999999994)
('yuv.max=', 255.0, 'yuv.min=', -3.3393200000000007)
('yuv.max=', 205.0, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 220.56999999999999, 'yuv.min=', -17.433239999999998)
('yuv.max=', 255.0, 'yuv.min=', -52.300309999999996)
('yuv.max=', 255.0, 'yuv.min=', -13.540369999999989)
('yuv.max=', 252.38000000000002, 'yuv.min=', -68.28573999999999)
('yuv.max=', 209.48899999999998, 'yuv.min=', -56.132469999999998)
('yuv.max=', 232.78199999999998, 'yuv.min=', -34.32808)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.141330000000004)
('yuv.max=', 212.13999999999999, 'yuv.min=', -29.240709999999993)
('yuv.max=', 237.142, 'yuv.min=', -38.181600000000003)
('yuv.max=', 230.43000000000001, 'yuv.min=', -84.586100000000002)
('yuv.max=', 216.02100000000002, 'yuv.min=', -23.510259999999995)
('yuv.max=', 167.58599999999998, 'yuv.min=', -15.601689999999998)
('yuv.max=', 239.40999999999997, 'yuv.min=', -52.790900000000008)
('yuv.max=', 252.27699999999999, 'yuv.min=', -89.115239999999986)
('yuv.max=', 229.929, 'yuv.min=', -10.840099999999996)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.779849999999982)
('yuv.max=', 255.0, 'yuv.min=', -26.719719999999995)
('yuv.max=', 248.322, 'yuv.min=', -44.899569999999997)
('yuv.max=', 245.13799999999998, 'yuv.min=', -67.015320000000003)
('yuv.max=', 247.06, 'yuv.min=', -56.388249999999999)
('yuv.max=', 241.73999999999998, 'yuv.min=', -38.650309999999998)
('yuv.max=', 204.989, 'yuv.min=', -14.996919999999996)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.385439999999996)
('yuv.max=', 248.381, 'yuv.min=', -29.630379999999999)
('yuv.max=', 238.42999999999995, 'yuv.min=', -34.158949999999997)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 200.60199999999998, 'yuv.min=', -20.920370000000002)
('yuv.max=', 210.24300000000002, 'yuv.min=', -32.975529999999978)
('yuv.max=', 194.327, 'yuv.min=', -32.175449999999984)
('yuv.max=', 233.428, 'yuv.min=', -14.118620000000007)
('yuv.max=', 224.85199999999998, 'yuv.min=', -20.936659999999989)
('yuv.max=', 195.50299999999999, 'yuv.min=', -12.855239999999998)
('yuv.max=', 181.386, 'yuv.min=', -33.905499999999989)
('yuv.max=', 250.72, 'yuv.min=', -28.065190000000001)
('yuv.max=', 233.05599999999998, 'yuv.min=', -9.954970000000003)
('yuv.max=', 219.387, 'yuv.min=', -44.535209999999992)
('yuv.max=', 243.82399999999998, 'yuv.min=', -33.75480000000001)
('yuv.max=', 248.47300000000001, 'yuv.min=', -58.560689999999987)
('yuv.max=', 193.44200000000001, 'yuv.min=', -30.945449999999987)
('yuv.max=', 202.91399999999999, 'yuv.min=', -40.785449999999997)
('yuv.max=', 177.19800000000001, 'yuv.min=', -10.480309999999996)
('yuv.max=', 241.095, 'yuv.min=', -45.412670000000006)
('yuv.max=', 255.0, 'yuv.min=', -3.0451199999999972)
('yuv.max=', 222.80099999999999, 'yuv.min=', -56.745570000000001)
('yuv.max=', 235.32099999999997, 'yuv.min=', -18.076090000000004)
('yuv.max=', 202.65199999999999, 'yuv.min=', -33.602320000000006)
('yuv.max=', 181.61799999999999, 'yuv.min=', -23.180349999999997)
('yuv.max=', 171.53200000000001, 'yuv.min=', -18.890289999999997)
('yuv.max=', 176.83000000000001, 'yuv.min=', -11.455099999999991)
('yuv.max=', 234.19999999999999, 'yuv.min=', -37.689760000000007)
('yuv.max=', 255.0, 'yuv.min=', -20.060529999999993)
('yuv.max=', 255.0, 'yuv.min=', -26.204729999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.264299999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.71199999999999, 'yuv.min=', -40.655560000000001)
('yuv.max=', 252.10300000000001, 'yuv.min=', -38.083380000000005)
('yuv.max=', 184.16499999999999, 'yuv.min=', -13.515059999999995)
('yuv.max=', 211.345, 'yuv.min=', -100.55569000000001)
('yuv.max=', 230.464, 'yuv.min=', -32.920339999999996)
('yuv.max=', 219.70099999999999, 'yuv.min=', -26.741950000000006)
('yuv.max=', 255.0, 'yuv.min=', -52.940619999999996)
('yuv.max=', 251.71800000000002, 'yuv.min=', -21.047059999999998)
('yuv.max=', 233.69, 'yuv.min=', -24.710379999999986)
('yuv.max=', 200.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 193.88200000000001, 'yuv.min=', -40.055499999999995)
('yuv.max=', 230.39500000000001, 'yuv.min=', -31.390309999999996)
('yuv.max=', 243.989, 'yuv.min=', -21.765330000000002)
('yuv.max=', 183.73499999999999, 'yuv.min=', -32.385839999999995)
('yuv.max=', 236.32799999999997, 'yuv.min=', -47.045829999999988)
('yuv.max=', 239.69, 'yuv.min=', -23.210229999999996)
('yuv.max=', 198.31399999999999, 'yuv.min=', -28.055529999999994)
('yuv.max=', 235.68000000000001, 'yuv.min=', -73.485199999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.0214600000000011)
('yuv.max=', 255.0, 'yuv.min=', -20.991760000000003)
('yuv.max=', 237.72899999999998, 'yuv.min=', -37.355229999999985)
('yuv.max=', 253.97400000000002, 'yuv.min=', -85.414869999999993)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 172.32499999999999, 'yuv.min=', -8.8249599999999937)
('yuv.max=', 196.84300000000002, 'yuv.min=', -3.6049299999999986)
('yuv.max=', 253.505, 'yuv.min=', -6.9650200000000027)
('yuv.max=', 208.76899999999998, 'yuv.min=', -55.985739999999993)
('yuv.max=', 239.797, 'yuv.min=', -50.633929999999999)
('yuv.max=', 194.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.52199999999999, 'yuv.min=', -27.145069999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.072850000000003)
('yuv.max=', 250.131, 'yuv.min=', -24.441799999999997)
('yuv.max=', 207.642, 'yuv.min=', -35.380340000000004)
('yuv.max=', 255.0, 'yuv.min=', -45.620570000000001)
('yuv.max=', 237.77199999999999, 'yuv.min=', -7.4056899999999999)
('yuv.max=', 213.745, 'yuv.min=', -45.473650000000006)
('yuv.max=', 227.48400000000001, 'yuv.min=', -57.300809999999998)
('yuv.max=', 225.482, 'yuv.min=', -18.011130000000001)
('yuv.max=', 235.608, 'yuv.min=', -28.839650000000002)
('yuv.max=', 224.90699999999998, 'yuv.min=', -22.735489999999995)
('yuv.max=', 188.44499999999999, 'yuv.min=', -26.055329999999987)
('yuv.max=', 217.79799999999997, 'yuv.min=', -37.116619999999998)
('yuv.max=', 255.0, 'yuv.min=', -25.640349999999994)
('yuv.max=', 251.41300000000001, 'yuv.min=', -32.690439999999981)
('yuv.max=', 249.85399999999998, 'yuv.min=', -19.089599999999997)
('yuv.max=', 255.0, 'yuv.min=', -27.025549999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.350589999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.8801500000000004)
('yuv.max=', 245.78100000000001, 'yuv.min=', -26.63008)
('yuv.max=', 254.886, 'yuv.min=', -66.815469999999991)
('yuv.max=', 233.13200000000001, 'yuv.min=', -18.59025999999999)
('yuv.max=', 247.46599999999998, 'yuv.min=', -30.000539999999997)
('yuv.max=', 225.97800000000001, 'yuv.min=', -34.765339999999995)
('yuv.max=', 255.0, 'yuv.min=', -43.749300000000012)
('yuv.max=', 206.65899999999999, 'yuv.min=', -63.108640000000008)
('yuv.max=', 239.88399999999999, 'yuv.min=', -97.66167999999999)
('yuv.max=', 242.874, 'yuv.min=', -60.684979999999996)
('yuv.max=', 224.89699999999999, 'yuv.min=', -58.820469999999986)
('yuv.max=', 194.94199999999998, 'yuv.min=', -18.669070000000005)
('yuv.max=', 233.03099999999998, 'yuv.min=', -65.550820000000002)
('yuv.max=', 252.114, 'yuv.min=', -13.055259999999993)
('yuv.max=', 252.935, 'yuv.min=', -24.540240000000004)
('yuv.max=', 244.72899999999998, 'yuv.min=', -24.168109999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 220.78700000000001, 'yuv.min=', -30.484979999999997)
('yuv.max=', 243.35899999999998, 'yuv.min=', -43.370769999999993)
('yuv.max=', 254.18499999999997, 'yuv.min=', -24.932120000000005)
('yuv.max=', 251.52700000000002, 'yuv.min=', -25.54033999999999)
('yuv.max=', 234.67999999999998, 'yuv.min=', -28.055529999999997)
('yuv.max=', 242.75, 'yuv.min=', -18.305169999999986)
('yuv.max=', 255.0, 'yuv.min=', -51.459979999999995)
('yuv.max=', 247.33799999999999, 'yuv.min=', -58.305479999999996)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.06399999999999, 'yuv.min=', -24.040189999999996)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.99899999999997, 'yuv.min=', -72.263640000000009)
('yuv.max=', 228.34199999999998, 'yuv.min=', -7.3501200000000004)
('yuv.max=', 249.64699999999999, 'yuv.min=', -13.25352)
('yuv.max=', 201.13599999999997, 'yuv.min=', -55.488910000000018)
('yuv.max=', 218.36699999999999, 'yuv.min=', -64.029170000000008)
('yuv.max=', 237.13499999999996, 'yuv.min=', -14.900259999999992)
('yuv.max=', 248.40899999999999, 'yuv.min=', -7.4260400000000146)
('yuv.max=', 235.46299999999999, 'yuv.min=', -29.809659999999987)
('yuv.max=', 243.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 224.68299999999999, 'yuv.min=', -13.200089999999996)
('yuv.max=', 245.43999999999997, 'yuv.min=', -55.947990000000004)
('yuv.max=', 253.58699999999999, 'yuv.min=', -20.53526999999999)
('yuv.max=', 235.262, 'yuv.min=', -23.655089999999998)
('yuv.max=', 227.54299999999995, 'yuv.min=', -25.640349999999991)
('yuv.max=', 243.75400000000002, 'yuv.min=', -26.490669999999994)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 138.67400000000001, 'yuv.min=', -14.900259999999999)
('yuv.max=', 211.89999999999998, 'yuv.min=', -30.030419999999989)
('yuv.max=', 217.059, 'yuv.min=', -40.100319999999996)
('yuv.max=', 252.309, 'yuv.min=', -43.86045)
('yuv.max=', 228.27699999999996, 'yuv.min=', -22.125059999999998)
('yuv.max=', 253.36999999999998, 'yuv.min=', -13.37727000000001)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.929, 'yuv.min=', -30.403489999999998)
('yuv.max=', 225.744, 'yuv.min=', -44.912090000000006)
('yuv.max=', 255.0, 'yuv.min=', -21.725019999999986)
('yuv.max=', 187.17999999999998, 'yuv.min=', -16.015309999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.060980000000015)
('yuv.max=', 241.17599999999999, 'yuv.min=', -62.373280000000001)
('yuv.max=', 248.51599999999996, 'yuv.min=', -47.065339999999992)
('yuv.max=', 227.03199999999998, 'yuv.min=', -51.370339999999992)
('yuv.max=', 233.821, 'yuv.min=', -21.253630000000005)
('yuv.max=', 227.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 206.41300000000001, 'yuv.min=', -71.44144)
('yuv.max=', 255.0, 'yuv.min=', -13.379280000000001)
('yuv.max=', 250.39099999999999, 'yuv.min=', -18.520129999999998)
('yuv.max=', 236.41, 'yuv.min=', -35.155470000000008)
('yuv.max=', 251.70099999999996, 'yuv.min=', -43.675370000000001)
('yuv.max=', 206.97, 'yuv.min=', -31.120159999999998)
('yuv.max=', 237.142, 'yuv.min=', -55.225909999999985)
('yuv.max=', 225.72999999999999, 'yuv.min=', -34.21249000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.276910000000008)
('yuv.max=', 236.84699999999998, 'yuv.min=', -19.939279999999997)
('yuv.max=', 159.86599999999999, 'yuv.min=', -35.060799999999986)
('yuv.max=', 255.0, 'yuv.min=', -53.614280000000008)
('yuv.max=', 223.95699999999999, 'yuv.min=', -48.0505)
('yuv.max=', 252.11599999999999, 'yuv.min=', -62.289770000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.100119999999983)
('yuv.max=', 231.23599999999996, 'yuv.min=', -33.32038)
('yuv.max=', 232.99600000000001, 'yuv.min=', -26.455369999999995)
('yuv.max=', 220.97, 'yuv.min=', -14.770369999999996)
('yuv.max=', 246.51000000000002, 'yuv.min=', -49.243240000000014)
('yuv.max=', 236.36600000000001, 'yuv.min=', -54.17062)
('yuv.max=', 239.61899999999997, 'yuv.min=', -38.039580000000008)
('yuv.max=', 221.81099999999998, 'yuv.min=', -41.830369999999995)
('yuv.max=', 212.40899999999999, 'yuv.min=', -17.660289999999989)
('yuv.max=', 253.19100000000003, 'yuv.min=', -58.143460000000012)
('yuv.max=', 215.625, 'yuv.min=', -48.140139999999995)
('yuv.max=', 229.285, 'yuv.min=', -29.499820000000003)
('yuv.max=', 184.952, 'yuv.min=', -33.290499999999994)
('yuv.max=', 165.24299999999999, 'yuv.min=', -24.090809999999998)
('yuv.max=', 251.755, 'yuv.min=', -37.585129999999992)
('yuv.max=', 234.46099999999998, 'yuv.min=', -16.892440000000008)
('yuv.max=', 248.46599999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 136.13999999999999, 'yuv.min=', -7.9499400000000016)
('yuv.max=', 255.0, 'yuv.min=', -6.5661700000000032)
('yuv.max=', 248.95699999999999, 'yuv.min=', -31.090279999999989)
('yuv.max=', 211.14999999999998, 'yuv.min=', -21.905529999999995)
('yuv.max=', 252.22999999999996, 'yuv.min=', -32.916300000000007)
('yuv.max=', 227.755, 'yuv.min=', -26.785440000000008)
('yuv.max=', 216.35199999999998, 'yuv.min=', -14.430089999999993)
('yuv.max=', 253.404, 'yuv.min=', -37.242220000000003)
('yuv.max=', 162.90099999999998, 'yuv.min=', -8.735870000000002)
('yuv.max=', 213.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.06, 'yuv.min=', -48.550550000000001)
('yuv.max=', 198.19499999999999, 'yuv.min=', -24.280459999999991)
('yuv.max=', 250.73299999999998, 'yuv.min=', -59.565359999999991)
('yuv.max=', 252.91799999999998, 'yuv.min=', -21.850339999999992)
('yuv.max=', 254.47300000000001, 'yuv.min=', -32.505359999999996)
('yuv.max=', 253.29900000000001, 'yuv.min=', -54.870689999999996)
('yuv.max=', 238.11599999999999, 'yuv.min=', -56.055890000000005)
('yuv.max=', 225.98599999999999, 'yuv.min=', -37.380539999999982)
('yuv.max=', 203.11599999999999, 'yuv.min=', -52.709300000000006)
('yuv.max=', 210.21399999999997, 'yuv.min=', -55.865620000000007)
('yuv.max=', 221.685, 'yuv.min=', -35.350459999999991)
('yuv.max=', 192.637, 'yuv.min=', -30.630479999999981)
('yuv.max=', 248.10900000000001, 'yuv.min=', -36.210299999999997)
('yuv.max=', 232.024, 'yuv.min=', -21.427000000000007)
('yuv.max=', 241.28799999999998, 'yuv.min=', -26.674899999999987)
('yuv.max=', 157.583, 'yuv.min=', -36.550579999999997)
('yuv.max=', 195.05199999999999, 'yuv.min=', -13.662229999999997)
('yuv.max=', 255.0, 'yuv.min=', -76.555459999999997)
('yuv.max=', 248.61600000000001, 'yuv.min=', -55.805450000000008)
('yuv.max=', 244.86799999999999, 'yuv.min=', -28.56594999999999)
('yuv.max=', 208.28200000000001, 'yuv.min=', -24.42528999999999)
('yuv.max=', 190.18799999999999, 'yuv.min=', -25.370199999999993)
('yuv.max=', 232.20400000000001, 'yuv.min=', -23.010209999999994)
('yuv.max=', 220.452, 'yuv.min=', -15.475090000000009)
('yuv.max=', 253.505, 'yuv.min=', -13.87027999999999)
('yuv.max=', 253.82599999999996, 'yuv.min=', -27.89246)
('yuv.max=', 232.25699999999998, 'yuv.min=', -51.725559999999987)
('yuv.max=', 190.88, 'yuv.min=', -59.96893)
('yuv.max=', 250.63, 'yuv.min=', -51.314139999999995)
('yuv.max=', 243.52699999999999, 'yuv.min=', -10.125089999999993)
('yuv.max=', 215.86199999999999, 'yuv.min=', -76.585589999999996)
('yuv.max=', 244.398, 'yuv.min=', -57.790489999999991)
('yuv.max=', 210.16499999999999, 'yuv.min=', -29.590129999999995)
('yuv.max=', 220.80399999999997, 'yuv.min=', -48.165449999999986)
('yuv.max=', 236.69399999999999, 'yuv.min=', -48.66686)
('yuv.max=', 241.04200000000003, 'yuv.min=', -17.545339999999996)
('yuv.max=', 188.328, 'yuv.min=', -29.248199999999997)
('yuv.max=', 248.0, 'yuv.min=', -13.170209999999994)
('yuv.max=', 226.85500000000002, 'yuv.min=', -29.930409999999995)
('yuv.max=', 255.0, 'yuv.min=', -57.451490000000007)
('yuv.max=', 239.58700000000002, 'yuv.min=', -74.395540000000011)
('yuv.max=', 250.42299999999997, 'yuv.min=', -29.405049999999992)
('yuv.max=', 248.71799999999999, 'yuv.min=', -12.0701)
('yuv.max=', 168.54500000000002, 'yuv.min=', -44.103129999999993)
('yuv.max=', 248.75900000000001, 'yuv.min=', -29.220340000000004)
('yuv.max=', 251.65799999999999, 'yuv.min=', -30.770739999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.981589999999997)
('yuv.max=', 243.62599999999998, 'yuv.min=', -82.754850000000005)
('yuv.max=', 165.97899999999998, 'yuv.min=', -26.702500000000001)
('yuv.max=', 251.22799999999998, 'yuv.min=', -6.2500099999999872)
('yuv.max=', 252.80399999999997, 'yuv.min=', -15.684670000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -2.4682500000000012)
('yuv.max=', 243.21999999999997, 'yuv.min=', -30.408289999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.440259999999995)
('yuv.max=', 214.077, 'yuv.min=', -38.856390000000005)
('yuv.max=', 243.28799999999998, 'yuv.min=', -26.155339999999995)
('yuv.max=', 252.02099999999996, 'yuv.min=', -76.180729999999997)
('yuv.max=', 255.0, 'yuv.min=', -82.190469999999991)
('yuv.max=', 240.71199999999999, 'yuv.min=', -14.84507)
('yuv.max=', 216.19, 'yuv.min=', -35.101060000000004)
('yuv.max=', 206.78399999999999, 'yuv.min=', -45.947080000000014)
('yuv.max=', 254.65800000000002, 'yuv.min=', -41.723320000000001)
('yuv.max=', 254.316, 'yuv.min=', -67.64542999999999)
('yuv.max=', 180.88799999999998, 'yuv.min=', -43.428770000000007)
('yuv.max=', 181.22799999999998, 'yuv.min=', -14.53979)
('yuv.max=', 189.64899999999997, 'yuv.min=', -23.835599999999996)
('yuv.max=', 250.86199999999997, 'yuv.min=', -49.500029999999995)
('yuv.max=', 247.03199999999998, 'yuv.min=', -17.280680000000004)
('yuv.max=', 221.70499999999998, 'yuv.min=', -16.96022)
('yuv.max=', 255.0, 'yuv.min=', -3.2750199999999987)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.742729999999998)
('yuv.max=', 236.27800000000002, 'yuv.min=', -7.7647499999999994)
('yuv.max=', 239.69399999999999, 'yuv.min=', -14.445029999999988)
('yuv.max=', 218.988, 'yuv.min=', -21.25028)
('yuv.max=', 196.31199999999998, 'yuv.min=', -25.329949999999997)
('yuv.max=', 249.47800000000001, 'yuv.min=', -21.980229999999999)
('yuv.max=', 249.89099999999999, 'yuv.min=', -24.853640000000002)
('yuv.max=', 194.59399999999999, 'yuv.min=', -34.665329999999997)
('yuv.max=', 253.0, 'yuv.min=', -17.305070000000001)
('yuv.max=', 244.316, 'yuv.min=', -16.32594000000001)
('yuv.max=', 243.523, 'yuv.min=', -30.370700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.425619999999997)
('yuv.max=', 201.13899999999998, 'yuv.min=', -16.488730000000007)
('yuv.max=', 207.61000000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 112.28299999999999, 'yuv.min=', -15.885169999999995)
('yuv.max=', 254.202, 'yuv.min=', -24.910399999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.028369999999995)
('yuv.max=', 224.53699999999998, 'yuv.min=', -82.005389999999991)
('yuv.max=', 227.61499999999998, 'yuv.min=', -27.15618000000001)
('yuv.max=', 169.32399999999998, 'yuv.min=', -49.020719999999983)
('yuv.max=', 253.29900000000001, 'yuv.min=', -76.385319999999979)
('yuv.max=', 239.83799999999999, 'yuv.min=', -46.79061999999999)
('yuv.max=', 244.81700000000001, 'yuv.min=', -44.546370000000003)
('yuv.max=', 199.13299999999998, 'yuv.min=', -26.825529999999986)
('yuv.max=', 165.61599999999999, 'yuv.min=', -3.4003399999999857)
('yuv.max=', 232.21699999999998, 'yuv.min=', -15.804919999999994)
('yuv.max=', 252.22999999999996, 'yuv.min=', -35.220569999999988)
('yuv.max=', 177.55799999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 248.32999999999998, 'yuv.min=', -54.160249999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.555109999999996)
('yuv.max=', 198.09299999999999, 'yuv.min=', -23.765469999999993)
('yuv.max=', 245.744, 'yuv.min=', -37.800089999999997)
('yuv.max=', 222.80500000000001, 'yuv.min=', -21.732040000000012)
('yuv.max=', 231.21700000000001, 'yuv.min=', -60.394170000000003)
('yuv.max=', 209.38, 'yuv.min=', -36.389579999999995)
('yuv.max=', 237.69799999999995, 'yuv.min=', -36.410319999999999)
('yuv.max=', 238.09999999999999, 'yuv.min=', -39.95548999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.387790000000003)
('yuv.max=', 240.89399999999998, 'yuv.min=', -17.023219999999995)
('yuv.max=', 225.96100000000001, 'yuv.min=', -15.260049999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.490119999999983)
('yuv.max=', 241.82599999999996, 'yuv.min=', -38.355329999999995)
('yuv.max=', 250.03899999999999, 'yuv.min=', -71.550389999999993)
('yuv.max=', 239.87199999999996, 'yuv.min=', -17.690169999999995)
('yuv.max=', 248.0, 'yuv.min=', -35.650489999999991)
('yuv.max=', 230.22799999999998, 'yuv.min=', -52.180790000000002)
('yuv.max=', 240.755, 'yuv.min=', -4.8050499999999925)
('yuv.max=', 225.63700000000003, 'yuv.min=', -24.436530000000001)
('yuv.max=', 243.81100000000001, 'yuv.min=', -29.743519999999997)
('yuv.max=', 240.11299999999997, 'yuv.min=', -59.005549999999999)
('yuv.max=', 250.26199999999997, 'yuv.min=', -30.848420000000004)
('yuv.max=', 230.64699999999996, 'yuv.min=', -97.536000000000001)
('yuv.max=', 249.07099999999997, 'yuv.min=', -17.454960000000007)
('yuv.max=', 231.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 216.04799999999997, 'yuv.min=', -31.150000000000013)
('yuv.max=', 236.66799999999998, 'yuv.min=', -30.920139999999989)
('yuv.max=', 250.815, 'yuv.min=', -25.345969999999994)
('yuv.max=', 249.14999999999998, 'yuv.min=', -43.930340000000001)
('yuv.max=', 216.44899999999998, 'yuv.min=', -28.285429999999995)
('yuv.max=', 202.381, 'yuv.min=', -71.065279999999987)
('yuv.max=', 233.07500000000002, 'yuv.min=', -23.550509999999999)
('yuv.max=', 241.97900000000001, 'yuv.min=', -27.699900000000007)
('yuv.max=', 193.90200000000002, 'yuv.min=', -36.920739999999995)
('yuv.max=', 245.376, 'yuv.min=', -78.144440000000003)
('yuv.max=', 252.58699999999999, 'yuv.min=', -22.829039999999996)
('yuv.max=', 239.55299999999997, 'yuv.min=', -21.068569999999998)
('yuv.max=', 252.10300000000001, 'yuv.min=', -48.965530000000001)
('yuv.max=', 159.44499999999996, 'yuv.min=', -16.736000000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.4834400000000016)
('yuv.max=', 246.35900000000001, 'yuv.min=', -32.088909999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 199.49299999999999, 'yuv.min=', -9.3756299999999957)
('yuv.max=', 247.852, 'yuv.min=', -45.433670000000006)
('yuv.max=', 251.50500000000002, 'yuv.min=', -63.910609999999991)
('yuv.max=', 243.583, 'yuv.min=', -23.438829999999999)
('yuv.max=', 247.893, 'yuv.min=', -29.100449999999991)
('yuv.max=', 255.0, 'yuv.min=', -58.420429999999982)
('yuv.max=', 231.43000000000001, 'yuv.min=', -82.101089999999999)
('yuv.max=', 251.03799999999998, 'yuv.min=', -62.955329999999989)
('yuv.max=', 255.0, 'yuv.min=', -63.544880000000013)
('yuv.max=', 156.55799999999999, 'yuv.min=', -41.360199999999992)
('yuv.max=', 246.26999999999998, 'yuv.min=', -37.302740000000007)
('yuv.max=', 250.501, 'yuv.min=', -90.544029999999978)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 225.24099999999999, 'yuv.min=', -26.885289999999994)
('yuv.max=', 176.364, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.96099999999998, 'yuv.min=', -31.630579999999995)
('yuv.max=', 252.93999999999997, 'yuv.min=', -19.710599999999999)
('yuv.max=', 255.0, 'yuv.min=', -61.540249999999993)
('yuv.max=', 207.554, 'yuv.min=', -21.05827)
('yuv.max=', 250.03200000000001, 'yuv.min=', -50.310479999999984)
('yuv.max=', 154.88900000000001, 'yuv.min=', -26.655389999999997)
('yuv.max=', 228.80199999999999, 'yuv.min=', -62.020789999999991)
('yuv.max=', 255.0, 'yuv.min=', -33.410019999999989)
('yuv.max=', 246.042, 'yuv.min=', -55.805229999999995)
('yuv.max=', 173.44099999999997, 'yuv.min=', -8.6745900000000056)
('yuv.max=', 209.82699999999997, 'yuv.min=', -70.385950000000008)
('yuv.max=', 235.72800000000001, 'yuv.min=', -57.180059999999997)
('yuv.max=', 248.00999999999999, 'yuv.min=', -51.535910000000001)
('yuv.max=', 248.869, 'yuv.min=', -56.000679999999988)
('yuv.max=', 234.20599999999996, 'yuv.min=', -44.350130000000007)
('yuv.max=', 238.39599999999999, 'yuv.min=', -22.460769999999989)
('yuv.max=', 251.72199999999998, 'yuv.min=', -53.340659999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 243.63200000000001, 'yuv.min=', -38.640419999999992)
('yuv.max=', 220.91, 'yuv.min=', -80.330529999999996)
('yuv.max=', 240.0, 'yuv.min=', -46.250320000000002)
('yuv.max=', 221.28800000000001, 'yuv.min=', -21.06519999999999)
('yuv.max=', 230.57199999999997, 'yuv.min=', -48.125199999999992)
('yuv.max=', 237.17500000000001, 'yuv.min=', -32.650189999999995)
('yuv.max=', 230.13099999999997, 'yuv.min=', -18.835099999999997)
('yuv.max=', 243.40100000000001, 'yuv.min=', -54.485589999999988)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.84299999999999, 'yuv.min=', -7.8564700000000016)
('yuv.max=', 178.0, 'yuv.min=', -14.729890000000001)
('yuv.max=', 243.34599999999998, 'yuv.min=', -43.31557999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -7.9949999999999974)
('yuv.max=', 132.42499999999998, 'yuv.min=', -25.335749999999994)
('yuv.max=', 242.92499999999998, 'yuv.min=', -24.940279999999994)
('yuv.max=', 238.53800000000001, 'yuv.min=', -23.45008)
('yuv.max=', 255.0, 'yuv.min=', -21.286039999999996)
('yuv.max=', 239.78799999999998, 'yuv.min=', -45.570989999999995)
('yuv.max=', 248.99999999999997, 'yuv.min=', -53.400419999999997)
('yuv.max=', 204.03399999999999, 'yuv.min=', -27.440529999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -30.56035)
('yuv.max=', 146.797, 'yuv.min=', -50.250719999999994)
('yuv.max=', 150.84099999999998, 'yuv.min=', -98.073429999999988)
('yuv.max=', 247.08800000000002, 'yuv.min=', -36.732150000000004)
('yuv.max=', 234.75899999999999, 'yuv.min=', -36.375950000000003)
('yuv.max=', 243.31599999999997, 'yuv.min=', -40.224460000000008)
('yuv.max=', 233.24199999999999, 'yuv.min=', -33.124929999999999)
('yuv.max=', 187.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.41800000000001, 'yuv.min=', -24.294120000000007)
('yuv.max=', 197.602, 'yuv.min=', -19.204340000000002)
('yuv.max=', 227.71099999999998, 'yuv.min=', -61.580499999999994)
('yuv.max=', 255.0, 'yuv.min=', -17.121539999999996)
('yuv.max=', 220.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -46.865319999999997)
('yuv.max=', 238.36199999999999, 'yuv.min=', -32.685869999999994)
('yuv.max=', 210.62499999999997, 'yuv.min=', -38.371350000000007)
('yuv.max=', 255.0, 'yuv.min=', -59.206560000000017)
('yuv.max=', 204.19999999999999, 'yuv.min=', -22.680299999999988)
('yuv.max=', 189.15000000000001, 'yuv.min=', -37.770840000000007)
('yuv.max=', 233.11399999999998, 'yuv.min=', -10.0702)
('yuv.max=', 254.886, 'yuv.min=', -27.586950000000005)
('yuv.max=', 235.22299999999998, 'yuv.min=', -20.080039999999986)
('yuv.max=', 251.30500000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 241.71799999999996, 'yuv.min=', -29.825220000000002)
('yuv.max=', 230.79799999999997, 'yuv.min=', -44.426190000000005)
('yuv.max=', 255.0, 'yuv.min=', -10.364379999999997)
('yuv.max=', 241.68399999999997, 'yuv.min=', -35.935579999999995)
('yuv.max=', 184.30099999999999, 'yuv.min=', -47.63064)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.72199999999998, 'yuv.min=', -21.265220000000003)
('yuv.max=', 238.43099999999998, 'yuv.min=', -89.125609999999995)
('yuv.max=', 247.36399999999998, 'yuv.min=', -18.864979999999996)
('yuv.max=', 202.935, 'yuv.min=', -26.910599999999999)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 171.94399999999999, 'yuv.min=', -28.18364)
('yuv.max=', 236.67599999999999, 'yuv.min=', -42.52006999999999)
('yuv.max=', 255.0, 'yuv.min=', -35.810259999999985)
('yuv.max=', 251.393, 'yuv.min=', -19.545539999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.370229999999996)
('yuv.max=', 250.47299999999998, 'yuv.min=', -17.560279999999988)
('yuv.max=', 246.512, 'yuv.min=', -18.185649999999995)
('yuv.max=', 217.684, 'yuv.min=', -49.37473)
('yuv.max=', 228.34800000000001, 'yuv.min=', -26.04327)
('yuv.max=', 236.85600000000002, 'yuv.min=', -8.2925699999999978)
('yuv.max=', 243.52699999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 249.20799999999997, 'yuv.min=', -34.935479999999998)
('yuv.max=', 251.54399999999998, 'yuv.min=', -58.860720000000001)
('yuv.max=', 253.0, 'yuv.min=', -15.379349999999999)
('yuv.max=', 242.88799999999998, 'yuv.min=', -24.856289999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -30.114740000000012)
('yuv.max=', 139.28699999999998, 'yuv.min=', -20.42032)
('yuv.max=', 245.727, 'yuv.min=', -39.495689999999989)
('yuv.max=', 237.88799999999998, 'yuv.min=', -17.645349999999993)
('yuv.max=', 245.76499999999999, 'yuv.min=', -46.72587)
('yuv.max=', 231.435, 'yuv.min=', -22.866860000000003)
('yuv.max=', 243.82999999999998, 'yuv.min=', -30.13043)
('yuv.max=', 250.02099999999999, 'yuv.min=', -29.59926999999999)
('yuv.max=', 230.732, 'yuv.min=', -47.950489999999995)
('yuv.max=', 199.535, 'yuv.min=', -33.620409999999985)
('yuv.max=', 241.447, 'yuv.min=', -16.13138)
('yuv.max=', 255.0, 'yuv.min=', -38.150739999999992)
('yuv.max=', 202.20699999999997, 'yuv.min=', -27.840570000000003)
('yuv.max=', 243.536, 'yuv.min=', -35.951309999999999)
('yuv.max=', 189.37200000000001, 'yuv.min=', -34.277369999999998)
('yuv.max=', 187.14899999999997, 'yuv.min=', -21.557720000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -35.350459999999998)
('yuv.max=', 252.64099999999996, 'yuv.min=', -33.385939999999998)
('yuv.max=', 255.0, 'yuv.min=', -58.170859999999998)
('yuv.max=', 233.82599999999999, 'yuv.min=', -64.065809999999999)
('yuv.max=', 250.40599999999998, 'yuv.min=', -25.927000000000007)
('yuv.max=', 255.0, 'yuv.min=', -25.640350000000002)
('yuv.max=', 247.57099999999997, 'yuv.min=', -67.685679999999991)
('yuv.max=', 254.886, 'yuv.min=', -83.29007)
('yuv.max=', 210.71100000000001, 'yuv.min=', -17.482240000000001)
('yuv.max=', 253.07700000000003, 'yuv.min=', -52.055189999999996)
('yuv.max=', 182.36600000000001, 'yuv.min=', -17.960319999999989)
('yuv.max=', 243.56999999999999, 'yuv.min=', -56.175389999999993)
('yuv.max=', 243.29800000000003, 'yuv.min=', -38.240379999999988)
('yuv.max=', 243.16099999999997, 'yuv.min=', -35.065369999999987)
('yuv.max=', 255.0, 'yuv.min=', -22.554979999999997)
('yuv.max=', 250.0, 'yuv.min=', -0.61499999999998778)
('yuv.max=', 222.84699999999998, 'yuv.min=', -38.665729999999996)
('yuv.max=', 234.17599999999999, 'yuv.min=', -41.771529999999991)
('yuv.max=', 250.53699999999998, 'yuv.min=', -31.120159999999988)
('yuv.max=', 243.33499999999998, 'yuv.min=', -28.692120000000003)
('yuv.max=', 254.06, 'yuv.min=', -21.120389999999993)
('yuv.max=', 220.25499999999997, 'yuv.min=', -32.920339999999996)
('yuv.max=', 169.35999999999999, 'yuv.min=', -39.510629999999992)
('yuv.max=', 238.23899999999998, 'yuv.min=', -36.55514999999999)
('yuv.max=', 246.06, 'yuv.min=', -27.385339999999996)
('yuv.max=', 250.27099999999999, 'yuv.min=', -26.11051999999999)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.37699999999998, 'yuv.min=', -40.151560000000003)
('yuv.max=', 255.0, 'yuv.min=', -28.911280000000001)
('yuv.max=', 238.24199999999999, 'yuv.min=', -57.151409999999991)
('yuv.max=', 241.369, 'yuv.min=', -31.655889999999999)
('yuv.max=', 253.97400000000002, 'yuv.min=', -20.838770000000004)
('yuv.max=', 231.56299999999999, 'yuv.min=', -27.14506999999999)
('yuv.max=', 235.256, 'yuv.min=', -17.89575)
('yuv.max=', 239.86899999999997, 'yuv.min=', -35.282309999999995)
('yuv.max=', 246.84599999999998, 'yuv.min=', -19.940320000000003)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.15699999999998, 'yuv.min=', -23.205300000000005)
('yuv.max=', 253.84299999999996, 'yuv.min=', -27.924470000000003)
('yuv.max=', 219.47799999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 249.56499999999997, 'yuv.min=', -9.4951499999999953)
('yuv.max=', 247.06199999999998, 'yuv.min=', -72.372879999999995)
('yuv.max=', 237.05999999999997, 'yuv.min=', -76.913740000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.778060000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -12.020250000000004)
('yuv.max=', 215.25999999999999, 'yuv.min=', -25.670229999999986)
('yuv.max=', 250.77199999999996, 'yuv.min=', -32.415379999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.411560000000001)
('yuv.max=', 246.00799999999995, 'yuv.min=', -30.12496999999999)
('yuv.max=', 236.87799999999999, 'yuv.min=', -51.070309999999992)
('yuv.max=', 248.99999999999997, 'yuv.min=', -13.185149999999993)
('yuv.max=', 226.08800000000002, 'yuv.min=', -39.906099999999995)
('yuv.max=', 234.185, 'yuv.min=', -44.830669999999998)
('yuv.max=', 217.97200000000001, 'yuv.min=', -19.935209999999998)
('yuv.max=', 234.08899999999997, 'yuv.min=', -74.700089999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -22.520529999999997)
('yuv.max=', 255.0, 'yuv.min=', -20.003800000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.15699999999998, 'yuv.min=', -20.050159999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.4672899999999913)
('yuv.max=', 246.15299999999999, 'yuv.min=', -47.549160000000001)
('yuv.max=', 255.0, 'yuv.min=', -102.29958999999999)
('yuv.max=', 236.364, 'yuv.min=', -10.825159999999997)
('yuv.max=', 204.07299999999998, 'yuv.min=', -21.725019999999997)
('yuv.max=', 217.76899999999998, 'yuv.min=', -12.910429999999995)
('yuv.max=', 255.0, 'yuv.min=', -8.3800999999999917)
('yuv.max=', 246.03399999999999, 'yuv.min=', -19.12018999999998)
('yuv.max=', 231.78, 'yuv.min=', -50.580629999999999)
('yuv.max=', 211.39500000000001, 'yuv.min=', -41.477430000000005)
('yuv.max=', 247.83599999999998, 'yuv.min=', -23.859679999999997)
('yuv.max=', 243.99999999999997, 'yuv.min=', -74.080519999999993)
('yuv.max=', 236.41399999999999, 'yuv.min=', -37.090879999999999)
('yuv.max=', 246.49299999999999, 'yuv.min=', -40.301060000000007)
('yuv.max=', 251.60599999999999, 'yuv.min=', -59.173440000000014)
('yuv.max=', 240.38300000000001, 'yuv.min=', -36.93835)
('yuv.max=', 191.11599999999999, 'yuv.min=', -14.254740000000002)
('yuv.max=', 250.76099999999997, 'yuv.min=', -45.984740000000002)
('yuv.max=', 243.91399999999999, 'yuv.min=', -25.955319999999979)
('yuv.max=', 244.38299999999998, 'yuv.min=', -82.035269999999997)
('yuv.max=', 143.14400000000001, 'yuv.min=', -14.270319999999991)
('yuv.max=', 216.84299999999999, 'yuv.min=', -23.965489999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -38.14036999999999)
('yuv.max=', 242.97800000000001, 'yuv.min=', -35.065369999999987)
('yuv.max=', 152.81699999999998, 'yuv.min=', -19.705309999999997)
('yuv.max=', 196.37, 'yuv.min=', -55.973930000000003)
('yuv.max=', 255.0, 'yuv.min=', -2.530129999999998)
('yuv.max=', 245.64099999999999, 'yuv.min=', -12.725349999999999)
('yuv.max=', 236.75699999999998, 'yuv.min=', -106.53947000000001)
('yuv.max=', 255.0, 'yuv.min=', -59.615079999999999)
('yuv.max=', 209.00300000000001, 'yuv.min=', -40.040559999999992)
('yuv.max=', 228.05799999999999, 'yuv.min=', -30.215499999999984)
('yuv.max=', 255.0, 'yuv.min=', -18.07517)
('yuv.max=', 248.58100000000002, 'yuv.min=', -70.813829999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 237.32299999999998, 'yuv.min=', -44.490389999999991)
('yuv.max=', 254.202, 'yuv.min=', -23.733560000000004)
('yuv.max=', 213.733, 'yuv.min=', -31.570310000000003)
('yuv.max=', 219.84700000000001, 'yuv.min=', -10.478809999999996)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.908230000000003)
('yuv.max=', 236.44300000000001, 'yuv.min=', -36.109060000000007)
('yuv.max=', 197.15100000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 237.10499999999999, 'yuv.min=', -57.120299999999986)
('yuv.max=', 221.62, 'yuv.min=', -16.830329999999996)
('yuv.max=', 255.0, 'yuv.min=', -4.6199699999999808)
('yuv.max=', 232.62099999999998, 'yuv.min=', -19.486999999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.90006)
('yuv.max=', 234.08799999999997, 'yuv.min=', -58.100889999999993)
('yuv.max=', 165.988, 'yuv.min=', -42.85069)
('yuv.max=', 242.89699999999999, 'yuv.min=', -11.514279999999999)
('yuv.max=', 220.447, 'yuv.min=', -31.902220000000003)
('yuv.max=', 215.012, 'yuv.min=', -80.968139999999991)
('yuv.max=', 177.35900000000001, 'yuv.min=', -36.620710000000003)
('yuv.max=', 180.46600000000001, 'yuv.min=', -41.455640000000002)
('yuv.max=', 248.56, 'yuv.min=', -28.266570000000002)
('yuv.max=', 251.733, 'yuv.min=', -11.495349999999988)
('yuv.max=', 210.38499999999999, 'yuv.min=', -18.675510000000006)
('yuv.max=', 244.137, 'yuv.min=', -53.460179999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.728379999999998)
('yuv.max=', 250.68999999999997, 'yuv.min=', -11.644749999999997)
('yuv.max=', 207.23500000000001, 'yuv.min=', -20.855130000000003)
('yuv.max=', 240.44999999999999, 'yuv.min=', -32.73669000000001)
('yuv.max=', 165.43199999999999, 'yuv.min=', -30.560349999999993)
('yuv.max=', 239.00599999999997, 'yuv.min=', -26.400179999999995)
('yuv.max=', 254.54400000000001, 'yuv.min=', -16.675129999999996)
('yuv.max=', 247.79999999999998, 'yuv.min=', -36.617449999999998)
('yuv.max=', 241.11899999999997, 'yuv.min=', -23.563309999999998)
('yuv.max=', 252.66899999999998, 'yuv.min=', -66.525220000000004)
('yuv.max=', 252.27699999999999, 'yuv.min=', -109.48036999999999)
('yuv.max=', 239.499, 'yuv.min=', -32.34102)
('yuv.max=', 232.53100000000001, 'yuv.min=', -35.226470000000006)
('yuv.max=', 226.17600000000002, 'yuv.min=', -79.840849999999989)
('yuv.max=', 242.61400000000003, 'yuv.min=', -16.119689999999999)
('yuv.max=', 253.47299999999998, 'yuv.min=', -74.722620000000006)
('yuv.max=', 126.76199999999999, 'yuv.min=', -4.5329699999999988)
('yuv.max=', 251.03199999999995, 'yuv.min=', -25.764760000000006)
('yuv.max=', 253.97400000000002, 'yuv.min=', -39.286770000000004)
('yuv.max=', 254.886, 'yuv.min=', -84.09066)
('yuv.max=', 234.74199999999999, 'yuv.min=', -31.760469999999998)
('yuv.max=', 255.0, 'yuv.min=', -54.023039999999995)
('yuv.max=', 242.55700000000002, 'yuv.min=', -27.615240000000004)
('yuv.max=', 248.245, 'yuv.min=', -25.280559999999998)
('yuv.max=', 220.29700000000003, 'yuv.min=', -72.105629999999991)
('yuv.max=', 247.83099999999996, 'yuv.min=', -70.100859999999997)
('yuv.max=', 238.03199999999998, 'yuv.min=', -20.755800000000001)
('yuv.max=', 247.84299999999999, 'yuv.min=', -28.880919999999996)
('yuv.max=', 246.11399999999998, 'yuv.min=', -43.55585)
('yuv.max=', 241.07899999999998, 'yuv.min=', -55.309030000000007)
('yuv.max=', 215.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 155.67100000000002, 'yuv.min=', -6.1051800000000007)
('yuv.max=', 212.38200000000001, 'yuv.min=', -23.585540000000002)
('yuv.max=', 210.131, 'yuv.min=', -24.240209999999983)
('yuv.max=', 213.83199999999999, 'yuv.min=', -21.050260000000005)
('yuv.max=', 254.77200000000002, 'yuv.min=', -26.277809999999999)
('yuv.max=', 227.59899999999996, 'yuv.min=', -34.982530000000011)
('yuv.max=', 125.336, 'yuv.min=', -19.161800000000003)
('yuv.max=', 231.20299999999997, 'yuv.min=', -24.325279999999985)
('yuv.max=', 155.17999999999998, 'yuv.min=', -19.105249999999987)
('yuv.max=', 241.22799999999998, 'yuv.min=', -33.820429999999988)
('yuv.max=', 250.84300000000002, 'yuv.min=', -29.493730000000006)
('yuv.max=', 248.26599999999996, 'yuv.min=', -23.606820000000006)
('yuv.max=', 215.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 214.71599999999998, 'yuv.min=', -21.23077)
('yuv.max=', 242.58100000000002, 'yuv.min=', -14.940509999999986)
('yuv.max=', 232.95899999999997, 'yuv.min=', -24.180449999999986)
('yuv.max=', 244.142, 'yuv.min=', -41.955689999999997)
('yuv.max=', 206.71499999999997, 'yuv.min=', -65.201250000000002)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.184, 'yuv.min=', -37.527250000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.810189999999995)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.12899999999999, 'yuv.min=', -12.355189999999993)
('yuv.max=', 206.68699999999998, 'yuv.min=', -37.665629999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.33700000000002, 'yuv.min=', -13.231849999999998)
('yuv.max=', 245.387, 'yuv.min=', -57.560589999999991)
('yuv.max=', 218.185, 'yuv.min=', -61.108580000000003)
('yuv.max=', 181.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.261, 'yuv.min=', -26.240410000000001)
('yuv.max=', 234.85699999999997, 'yuv.min=', -58.735399999999998)
('yuv.max=', 248.54800000000003, 'yuv.min=', -43.7455)
('yuv.max=', 224.03, 'yuv.min=', -62.415990000000001)
('yuv.max=', 245.75299999999999, 'yuv.min=', -27.366080000000004)
('yuv.max=', 198.49200000000002, 'yuv.min=', -30.660359999999987)
('yuv.max=', 231.70299999999997, 'yuv.min=', -23.910299999999989)
('yuv.max=', 232.50700000000001, 'yuv.min=', -61.095389999999995)
('yuv.max=', 216.79799999999997, 'yuv.min=', -11.670059999999996)
('yuv.max=', 251.91799999999998, 'yuv.min=', -14.75667)
('yuv.max=', 237.82299999999998, 'yuv.min=', -17.145299999999999)
('yuv.max=', 242.87299999999999, 'yuv.min=', -13.509690000000003)
('yuv.max=', 216.542, 'yuv.min=', -55.550109999999997)
('yuv.max=', 237.25, 'yuv.min=', -80.875399999999999)
('yuv.max=', 225.16799999999998, 'yuv.min=', -47.950489999999988)
('yuv.max=', 252.309, 'yuv.min=', -77.225650000000002)
('yuv.max=', 217.58999999999997, 'yuv.min=', -51.840509999999995)
('yuv.max=', 201.99099999999999, 'yuv.min=', -20.639849999999988)
('yuv.max=', 236.77599999999998, 'yuv.min=', -13.540369999999999)
('yuv.max=', 217.23799999999997, 'yuv.min=', -17.430390000000003)
('yuv.max=', 255.0, 'yuv.min=', -25.127739999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -57.656030000000001)
('yuv.max=', 248.84299999999999, 'yuv.min=', -31.965959999999999)
('yuv.max=', 254.886, 'yuv.min=', -41.130299999999991)
('yuv.max=', 235.66, 'yuv.min=', -29.154410000000006)
('yuv.max=', 255.0, 'yuv.min=', -36.016870000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -9.1717300000000019)
('yuv.max=', 217.499, 'yuv.min=', -39.255419999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.770169999999998)
('yuv.max=', 195.57899999999998, 'yuv.min=', -32.78998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -26.625510000000002)
('yuv.max=', 249.815, 'yuv.min=', -22.45176)
('yuv.max=', 244.38600000000002, 'yuv.min=', -21.323630000000001)
('yuv.max=', 235.79499999999996, 'yuv.min=', -39.270359999999997)
('yuv.max=', 216.70000000000002, 'yuv.min=', -42.512700000000002)
('yuv.max=', 243.309, 'yuv.min=', -35.614109999999989)
('yuv.max=', 230.41199999999998, 'yuv.min=', -21.180149999999998)
('yuv.max=', 255.0, 'yuv.min=', -50.71602)
('yuv.max=', 252.03399999999996, 'yuv.min=', -32.130629999999989)
('yuv.max=', 255.0, 'yuv.min=', -16.860209999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.250079999999986)
('yuv.max=', 240.184, 'yuv.min=', -66.140709999999999)
('yuv.max=', 252.309, 'yuv.min=', -38.18061999999999)
('yuv.max=', 236.92599999999999, 'yuv.min=', -48.40440000000001)
('yuv.max=', 205.40099999999998, 'yuv.min=', -19.45599)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.39999999999998, 'yuv.min=', -55.785719999999998)
('yuv.max=', 253.64700000000002, 'yuv.min=', -43.545479999999984)
('yuv.max=', 156.09399999999999, 'yuv.min=', -29.930410000000002)
('yuv.max=', 247.65800000000002, 'yuv.min=', -11.721049999999998)
('yuv.max=', 237.79699999999997, 'yuv.min=', -17.776130000000002)
('yuv.max=', 245.58799999999999, 'yuv.min=', -4.5264099999999985)
('yuv.max=', 234.38300000000001, 'yuv.min=', -66.831019999999995)
('yuv.max=', 208.82400000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 251.24499999999995, 'yuv.min=', -29.039450000000006)
('yuv.max=', 213.39099999999996, 'yuv.min=', -49.565589999999993)
('yuv.max=', 215.33399999999997, 'yuv.min=', -56.590150000000001)
('yuv.max=', 209.16, 'yuv.min=', -15.557770000000003)
('yuv.max=', 250.16999999999999, 'yuv.min=', -31.760050000000007)
('yuv.max=', 245.077, 'yuv.min=', -43.37077)
('yuv.max=', 187.453, 'yuv.min=', -48.687180000000012)
('yuv.max=', 200.29599999999996, 'yuv.min=', -16.775139999999993)
('yuv.max=', 241.61099999999999, 'yuv.min=', -24.827420000000011)
('yuv.max=', 234.99999999999997, 'yuv.min=', -74.035699999999991)
('yuv.max=', 237.21599999999998, 'yuv.min=', -30.220069999999993)
('yuv.max=', 179.52699999999999, 'yuv.min=', -34.960789999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -46.519350000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.61899999999997, 'yuv.min=', -43.960459999999991)
('yuv.max=', 238.84699999999998, 'yuv.min=', -42.486010000000007)
('yuv.max=', 240.91800000000001, 'yuv.min=', -46.950389999999992)
('yuv.max=', 209.17100000000002, 'yuv.min=', -53.240649999999988)
('yuv.max=', 195.55099999999999, 'yuv.min=', -16.745259999999998)
('yuv.max=', 208.542, 'yuv.min=', -10.340049999999991)
('yuv.max=', 152.30799999999999, 'yuv.min=', -70.893909999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.784110000000005)
('yuv.max=', 184.36999999999998, 'yuv.min=', -50.450739999999996)
('yuv.max=', 236.92699999999996, 'yuv.min=', -33.018850000000015)
('yuv.max=', 189.40100000000001, 'yuv.min=', -29.013000000000005)
('yuv.max=', 232.09900000000002, 'yuv.min=', -15.730220000000001)
('yuv.max=', 228.91399999999999, 'yuv.min=', -35.929290000000002)
('yuv.max=', 217.298, 'yuv.min=', -22.320509999999992)
('yuv.max=', 246.56899999999999, 'yuv.min=', -30.205130000000004)
('yuv.max=', 253.14199999999997, 'yuv.min=', -26.985299999999999)
('yuv.max=', 255.0, 'yuv.min=', -5.1200199999999967)
('yuv.max=', 245.43199999999999, 'yuv.min=', -39.80028999999999)
('yuv.max=', 217.71499999999997, 'yuv.min=', -24.325279999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.924769999999999)
('yuv.max=', 207.63800000000001, 'yuv.min=', -45.535309999999988)
('yuv.max=', 255.0, 'yuv.min=', -56.075379999999996)
('yuv.max=', 203.05499999999998, 'yuv.min=', -37.350659999999998)
('yuv.max=', 124.80500000000001, 'yuv.min=', -19.950149999999994)
('yuv.max=', 242.37399999999997, 'yuv.min=', -34.290599999999991)
('yuv.max=', 255.0, 'yuv.min=', -19.794949999999986)
('yuv.max=', 226.90399999999997, 'yuv.min=', -58.017980000000009)
('yuv.max=', 227.036, 'yuv.min=', -41.608890000000002)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 243.88199999999998, 'yuv.min=', -55.27073)
('yuv.max=', 212.232, 'yuv.min=', -57.635289999999998)
('yuv.max=', 251.27700000000002, 'yuv.min=', -28.184930000000008)
('yuv.max=', 237.0, 'yuv.min=', -5.3050999999999995)
('yuv.max=', 231.20599999999999, 'yuv.min=', -45.810029999999998)
('yuv.max=', 238.392, 'yuv.min=', -18.730519999999984)
('yuv.max=', 230.51999999999998, 'yuv.min=', -14.991879999999998)
('yuv.max=', 250.91799999999998, 'yuv.min=', -80.975409999999997)
('yuv.max=', 182.245, 'yuv.min=', -7.5351999999999908)
('yuv.max=', 230.423, 'yuv.min=', -16.015309999999999)
('yuv.max=', 236.14600000000002, 'yuv.min=', -27.015179999999994)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 142.80199999999999, 'yuv.min=', -16.751759999999997)
('yuv.max=', 255.0, 'yuv.min=', -72.775819999999996)
('yuv.max=', 255.0, 'yuv.min=', -94.860629999999986)
('yuv.max=', 220.21699999999998, 'yuv.min=', -40.570489999999992)
('yuv.max=', 229.88599999999997, 'yuv.min=', -41.305009999999982)
('yuv.max=', 243.67099999999996, 'yuv.min=', -20.075920000000004)
('yuv.max=', 247.52499999999998, 'yuv.min=', -21.610070000000007)
('yuv.max=', 235.74000000000001, 'yuv.min=', -28.769680000000008)
('yuv.max=', 243.30500000000001, 'yuv.min=', -26.043660000000003)
('yuv.max=', 253.0, 'yuv.min=', -36.260919999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.78994999999999)
('yuv.max=', 255.0, 'yuv.min=', -28.717800000000004)
('yuv.max=', 244.92700000000002, 'yuv.min=', -46.774510000000006)
('yuv.max=', 173.81200000000001, 'yuv.min=', -32.115690000000001)
('yuv.max=', 245.91800000000001, 'yuv.min=', -10.669959999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.479849999999999)
('yuv.max=', 189.07699999999997, 'yuv.min=', -30.615539999999999)
('yuv.max=', 164.59199999999998, 'yuv.min=', -25.955319999999997)
('yuv.max=', 227.46699999999998, 'yuv.min=', -79.681079999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.280359999999998)
('yuv.max=', 247.14599999999999, 'yuv.min=', -30.740859999999994)
('yuv.max=', 248.57599999999999, 'yuv.min=', -25.204620000000002)
('yuv.max=', 249.70099999999999, 'yuv.min=', -15.748350000000002)
('yuv.max=', 252.53299999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.385169999999988)
('yuv.max=', 253.202, 'yuv.min=', -40.530239999999999)
('yuv.max=', 233.387, 'yuv.min=', -30.064160000000001)
('yuv.max=', 245.387, 'yuv.min=', -24.409350000000007)
('yuv.max=', 173.10699999999997, 'yuv.min=', -23.19529)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.98899999999998, 'yuv.min=', -104.08563000000001)
('yuv.max=', 194.322, 'yuv.min=', -25.74418)
('yuv.max=', 234.50099999999998, 'yuv.min=', -50.065639999999988)
('yuv.max=', 253.0, 'yuv.min=', -44.890429999999981)
('yuv.max=', 219.17400000000001, 'yuv.min=', -20.165109999999991)
('yuv.max=', 254.35900000000001, 'yuv.min=', -38.140370000000004)
('yuv.max=', 216.96199999999999, 'yuv.min=', -23.438370000000013)
('yuv.max=', 225.733, 'yuv.min=', -22.850439999999999)
('yuv.max=', 229.86099999999999, 'yuv.min=', -39.570389999999996)
('yuv.max=', 245.98999999999998, 'yuv.min=', -40.025619999999989)
('yuv.max=', 246.17400000000001, 'yuv.min=', -37.765639999999991)
('yuv.max=', 248.28799999999995, 'yuv.min=', -15.575019999999995)
('yuv.max=', 247.10299999999998, 'yuv.min=', -37.240279999999998)
('yuv.max=', 249.804, 'yuv.min=', -19.651189999999993)
('yuv.max=', 236.79099999999997, 'yuv.min=', -42.140769999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.964, 'yuv.min=', -6.2902599999999822)
('yuv.max=', 177.47599999999997, 'yuv.min=', -65.400389999999987)
('yuv.max=', 158.92399999999998, 'yuv.min=', -4.945309999999985)
('yuv.max=', 255.0, 'yuv.min=', -26.038350000000001)
('yuv.max=', 255.0, 'yuv.min=', -18.211810000000007)
('yuv.max=', 226.279, 'yuv.min=', -46.990639999999999)
('yuv.max=', 152.982, 'yuv.min=', -25.525400000000001)
('yuv.max=', 199.71700000000001, 'yuv.min=', -26.940480000000001)
('yuv.max=', 252.93999999999997, 'yuv.min=', -48.405719999999988)
('yuv.max=', 255.0, 'yuv.min=', -3.7302499999999963)
('yuv.max=', 226.89399999999998, 'yuv.min=', -60.265429999999995)
('yuv.max=', 157.90600000000001, 'yuv.min=', -0.78513999999998774)
('yuv.max=', 246.31, 'yuv.min=', -43.717280000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.304379999999995)
('yuv.max=', 253.39099999999999, 'yuv.min=', -46.50553)
('yuv.max=', 250.22800000000001, 'yuv.min=', -33.135299999999994)
('yuv.max=', 231.49899999999997, 'yuv.min=', -23.029609999999998)
('yuv.max=', 225.96199999999996, 'yuv.min=', -41.415390000000002)
('yuv.max=', 247.0, 'yuv.min=', -41.586999999999996)
('yuv.max=', 225.32399999999998, 'yuv.min=', -33.999849999999995)
('yuv.max=', 243.92000000000002, 'yuv.min=', -41.625779999999992)
('yuv.max=', 171.679, 'yuv.min=', -37.140270000000001)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.744, 'yuv.min=', -32.360529999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.644949999999969)
('yuv.max=', 144.48099999999999, 'yuv.min=', -51.310580000000002)
('yuv.max=', 227.41400000000002, 'yuv.min=', -29.975230000000003)
('yuv.max=', 226.39099999999996, 'yuv.min=', -22.610169999999993)
('yuv.max=', 233.98700000000002, 'yuv.min=', -28.215299999999992)
('yuv.max=', 244.97300000000001, 'yuv.min=', -42.685639999999992)
('yuv.max=', 240.92699999999999, 'yuv.min=', -40.86014999999999)
('yuv.max=', 196.38299999999998, 'yuv.min=', -38.279140000000005)
('yuv.max=', 229.18499999999997, 'yuv.min=', -18.730519999999999)
('yuv.max=', 243.15299999999999, 'yuv.min=', -21.563890000000001)
('yuv.max=', 250.131, 'yuv.min=', -14.997420000000002)
('yuv.max=', 238.61199999999999, 'yuv.min=', -22.065300000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.890989999999999)
('yuv.max=', 255.0, 'yuv.min=', -69.205339999999978)
('yuv.max=', 187.511, 'yuv.min=', -24.795449999999995)
('yuv.max=', 237.61799999999999, 'yuv.min=', -84.620589999999993)
('yuv.max=', 252.60399999999998, 'yuv.min=', -42.255719999999997)
('yuv.max=', 219.72499999999997, 'yuv.min=', -75.170259999999985)
('yuv.max=', 238.43799999999999, 'yuv.min=', -31.875419999999991)
('yuv.max=', 209.904, 'yuv.min=', -55.641570000000002)
('yuv.max=', 247.78899999999999, 'yuv.min=', -42.14820000000001)
('yuv.max=', 243.04300000000001, 'yuv.min=', -58.400919999999992)
('yuv.max=', 212.93599999999998, 'yuv.min=', -46.916630000000005)
('yuv.max=', 215.227, 'yuv.min=', -68.70071999999999)
('yuv.max=', 242.22800000000001, 'yuv.min=', -14.930139999999998)
('yuv.max=', 255.0, 'yuv.min=', -32.284419999999997)
('yuv.max=', 254.316, 'yuv.min=', -25.591989999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.1572200000000024)
('yuv.max=', 253.80399999999997, 'yuv.min=', -86.412320000000008)
('yuv.max=', 231.44699999999997, 'yuv.min=', -22.684869999999989)
('yuv.max=', 202.91, 'yuv.min=', -34.005510000000001)
('yuv.max=', 252.50499999999997, 'yuv.min=', -36.480450000000005)
('yuv.max=', 225.31, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 228.36799999999999, 'yuv.min=', -32.805389999999996)
('yuv.max=', 248.86500000000001, 'yuv.min=', -65.429039999999986)
('yuv.max=', 253.505, 'yuv.min=', -97.840190000000007)
('yuv.max=', 223.435, 'yuv.min=', -19.620239999999992)
('yuv.max=', 205.60499999999999, 'yuv.min=', -59.575729999999993)
('yuv.max=', 245.04900000000001, 'yuv.min=', -24.510359999999995)
('yuv.max=', 255.0, 'yuv.min=', -49.520769999999992)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.250449999999994)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.56500000000003, 'yuv.min=', -73.420699999999997)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.334989999999991)
('yuv.max=', 255.0, 'yuv.min=', -83.126239999999996)
('yuv.max=', 247.09899999999999, 'yuv.min=', -66.60051)
('yuv.max=', 228.929, 'yuv.min=', -7.0949099999999952)
('yuv.max=', 234.70799999999997, 'yuv.min=', -35.425159999999998)
('yuv.max=', 255.0, 'yuv.min=', -56.590029999999992)
('yuv.max=', 255.0, 'yuv.min=', -45.886010000000006)
('yuv.max=', 232.94800000000001, 'yuv.min=', -60.329400000000007)
('yuv.max=', 249.77199999999999, 'yuv.min=', -29.730389999999986)
('yuv.max=', 255.0, 'yuv.min=', -39.985369999999996)
('yuv.max=', 182.137, 'yuv.min=', -17.075169999999986)
('yuv.max=', 232.44999999999999, 'yuv.min=', -22.850439999999995)
('yuv.max=', 209.79599999999996, 'yuv.min=', -32.445599999999999)
('yuv.max=', 185.83199999999999, 'yuv.min=', -18.594839999999998)
('yuv.max=', 185.624, 'yuv.min=', -26.140400000000003)
('yuv.max=', 250.76099999999997, 'yuv.min=', -48.780449999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -30.575289999999999)
('yuv.max=', 215.39099999999999, 'yuv.min=', -22.565349999999981)
('yuv.max=', 245.93899999999999, 'yuv.min=', -30.492070000000005)
('yuv.max=', 253.65799999999999, 'yuv.min=', -26.884)
('yuv.max=', 246.95599999999999, 'yuv.min=', -21.269920000000003)
('yuv.max=', 217.16999999999996, 'yuv.min=', -18.522379999999998)
('yuv.max=', 252.65199999999999, 'yuv.min=', -18.290229999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.830229999999986)
('yuv.max=', 231.92000000000002, 'yuv.min=', -14.330079999999997)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 223.74499999999998, 'yuv.min=', -29.41541999999999)
('yuv.max=', 183.51299999999998, 'yuv.min=', -25.580589999999994)
('yuv.max=', 245.78399999999999, 'yuv.min=', -64.279949999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.377570000000002)
('yuv.max=', 126.68999999999998, 'yuv.min=', -22.080239999999989)
('yuv.max=', 248.89599999999999, 'yuv.min=', -17.56485)
('yuv.max=', 228.87100000000001, 'yuv.min=', -9.2750199999999978)
('yuv.max=', 255.0, 'yuv.min=', -6.7399199999999979)
('yuv.max=', 249.916, 'yuv.min=', -28.845239999999997)
('yuv.max=', 237.82899999999998, 'yuv.min=', -25.455269999999999)
('yuv.max=', 250.77199999999996, 'yuv.min=', -27.285330000000002)
('yuv.max=', 160.77099999999999, 'yuv.min=', -76.601950000000002)
('yuv.max=', 234.77599999999995, 'yuv.min=', -16.676630000000003)
('yuv.max=', 187.52699999999999, 'yuv.min=', -64.781480000000002)
('yuv.max=', 224.613, 'yuv.min=', -17.476839999999999)
('yuv.max=', 248.53800000000001, 'yuv.min=', -15.100279999999991)
('yuv.max=', 248.59799999999998, 'yuv.min=', -87.080590000000001)
('yuv.max=', 252.85999999999999, 'yuv.min=', -76.285970000000006)
('yuv.max=', 253.72899999999996, 'yuv.min=', -13.66113)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84299999999999, 'yuv.min=', -22.216080000000002)
('yuv.max=', 109.88999999999999, 'yuv.min=', -40.640619999999998)
('yuv.max=', 238.77600000000001, 'yuv.min=', -33.402120000000011)
('yuv.max=', 200.06200000000001, 'yuv.min=', -40.640619999999991)
('yuv.max=', 255.0, 'yuv.min=', -62.955329999999989)
('yuv.max=', 234.78599999999997, 'yuv.min=', -41.515399999999985)
('yuv.max=', 236.59099999999998, 'yuv.min=', -25.12535999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -34.490619999999993)
('yuv.max=', 250.541, 'yuv.min=', -27.046689999999998)
('yuv.max=', 160.761, 'yuv.min=', -9.7108500000000006)
('yuv.max=', 210.96099999999998, 'yuv.min=', -24.855209999999992)
('yuv.max=', 244.35900000000001, 'yuv.min=', -14.915199999999988)
('yuv.max=', 224.25400000000002, 'yuv.min=', -31.743780000000008)
('yuv.max=', 235.041, 'yuv.min=', -24.888590000000004)
('yuv.max=', 235.50099999999998, 'yuv.min=', -40.873170000000016)
('yuv.max=', 249.39599999999999, 'yuv.min=', -24.777940000000005)
('yuv.max=', 203.57999999999998, 'yuv.min=', -32.115160000000003)
('yuv.max=', 255.0, 'yuv.min=', -13.300099999999995)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.07899999999998, 'yuv.min=', -45.380109999999988)
('yuv.max=', 248.81, 'yuv.min=', -81.169600000000017)
('yuv.max=', 171.34700000000001, 'yuv.min=', -24.69086999999999)
('yuv.max=', 228.75799999999998, 'yuv.min=', -25.181899999999999)
('yuv.max=', 151.24599999999998, 'yuv.min=', -23.666829999999997)
('yuv.max=', 243.24299999999999, 'yuv.min=', -17.875249999999991)
('yuv.max=', 255.0, 'yuv.min=', -3.2899599999999936)
('yuv.max=', 182.21999999999997, 'yuv.min=', -24.395409999999991)
('yuv.max=', 244.64099999999996, 'yuv.min=', -41.93038)
('yuv.max=', 241.869, 'yuv.min=', -26.90014)
('yuv.max=', 254.70099999999999, 'yuv.min=', -21.657550000000001)
('yuv.max=', 233.96799999999999, 'yuv.min=', -28.196840000000002)
('yuv.max=', 240.98599999999996, 'yuv.min=', -67.266330000000011)
('yuv.max=', 218.114, 'yuv.min=', -18.920169999999995)
('yuv.max=', 239.03799999999998, 'yuv.min=', -30.030420000000003)
('yuv.max=', 251.55499999999998, 'yuv.min=', -18.147749999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.243650000000002)
('yuv.max=', 254.65800000000002, 'yuv.min=', -15.296990000000005)
('yuv.max=', 243.71899999999999, 'yuv.min=', -39.384330000000006)
('yuv.max=', 230.14599999999996, 'yuv.min=', -78.240689999999987)
('yuv.max=', 173.96100000000001, 'yuv.min=', -38.910569999999993)
('yuv.max=', 173.334, 'yuv.min=', -19.809210000000004)
('yuv.max=', 255.0, 'yuv.min=', -16.728850000000008)
('yuv.max=', 249.16200000000001, 'yuv.min=', -45.720389999999995)
('yuv.max=', 244.97300000000001, 'yuv.min=', -16.645249999999997)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -83.465289999999996)
('yuv.max=', 255.0, 'yuv.min=', -27.41065)
('yuv.max=', 255.0, 'yuv.min=', -15.315239999999985)
('yuv.max=', 254.886, 'yuv.min=', -83.85687999999999)
('yuv.max=', 239.78700000000001, 'yuv.min=', -24.010309999999993)
('yuv.max=', 173.96800000000002, 'yuv.min=', -26.715149999999984)
('yuv.max=', 250.21600000000001, 'yuv.min=', -19.880019999999984)
('yuv.max=', 229.58699999999999, 'yuv.min=', -55.279869999999995)
('yuv.max=', 205.006, 'yuv.min=', -67.590239999999994)
('yuv.max=', 247.28800000000001, 'yuv.min=', -20.80659)
('yuv.max=', 238.05000000000001, 'yuv.min=', -24.92013)
('yuv.max=', 215.96899999999999, 'yuv.min=', -17.260249999999985)
('yuv.max=', 242.75500000000002, 'yuv.min=', -23.341869999999997)
('yuv.max=', 254.11399999999998, 'yuv.min=', -20.35482)
('yuv.max=', 255.0, 'yuv.min=', -45.871470000000002)
('yuv.max=', 244.01900000000001, 'yuv.min=', -43.553930000000008)
('yuv.max=', 255.0, 'yuv.min=', -10.625139999999993)
('yuv.max=', 255.0, 'yuv.min=', -20.511589999999998)
('yuv.max=', 242.411, 'yuv.min=', -25.25524999999999)
('yuv.max=', 252.61899999999997, 'yuv.min=', -38.649909999999991)
('yuv.max=', 242.43099999999995, 'yuv.min=', -33.754869999999997)
('yuv.max=', 177.75899999999999, 'yuv.min=', -23.270430000000001)
('yuv.max=', 245.24299999999999, 'yuv.min=', -54.615479999999991)
('yuv.max=', 234.03200000000001, 'yuv.min=', -43.80525999999999)
('yuv.max=', 190.38099999999997, 'yuv.min=', -30.560349999999985)
('yuv.max=', 176.23299999999998, 'yuv.min=', -25.319350000000004)
('yuv.max=', 248.131, 'yuv.min=', -24.986960000000003)
('yuv.max=', 234.82900000000001, 'yuv.min=', -51.925579999999997)
('yuv.max=', 225.28800000000001, 'yuv.min=', -27.455469999999991)
('yuv.max=', 254.245, 'yuv.min=', -8.9950999999999937)
('yuv.max=', 254.77200000000002, 'yuv.min=', -23.123209999999997)
('yuv.max=', 254.41299999999995, 'yuv.min=', -27.21976999999999)
('yuv.max=', 255.0, 'yuv.min=', -39.897530000000003)
('yuv.max=', 242.86199999999997, 'yuv.min=', -28.330249999999992)
('yuv.max=', 238.46299999999997, 'yuv.min=', -59.69248000000001)
('yuv.max=', 219.70699999999999, 'yuv.min=', -88.784099999999995)
('yuv.max=', 240.01099999999997, 'yuv.min=', -24.670320000000004)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 195.011, 'yuv.min=', -10.665389999999999)
('yuv.max=', 255.0, 'yuv.min=', -12.555210000000002)
('yuv.max=', 245.18099999999998, 'yuv.min=', -79.060630000000003)
('yuv.max=', 245.27599999999998, 'yuv.min=', -92.83214000000001)
('yuv.max=', 215.63200000000001, 'yuv.min=', -39.01057999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -12.210359999999998)
('yuv.max=', 236.43299999999999, 'yuv.min=', -31.060399999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.675329999999988)
('yuv.max=', 253.21699999999998, 'yuv.min=', -72.46584)
('yuv.max=', 247.47199999999995, 'yuv.min=', -60.250489999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.5650799999999805)
('yuv.max=', 247.48299999999995, 'yuv.min=', -42.460309999999993)
('yuv.max=', 255.0, 'yuv.min=', -45.215769999999992)
('yuv.max=', 253.99999999999997, 'yuv.min=', -90.635990000000007)
('yuv.max=', 255.0, 'yuv.min=', -42.225839999999991)
('yuv.max=', 172.30500000000001, 'yuv.min=', -10.249470000000002)
('yuv.max=', 247.07500000000002, 'yuv.min=', -50.010449999999999)
('yuv.max=', 238.761, 'yuv.min=', -29.66272)
('yuv.max=', 248.929, 'yuv.min=', -11.219700000000003)
('yuv.max=', 201.05799999999999, 'yuv.min=', -6.5350999999999893)
('yuv.max=', 251.66800000000001, 'yuv.min=', -76.978349999999992)
('yuv.max=', 243.66300000000001, 'yuv.min=', -25.438879999999997)
('yuv.max=', 253.10299999999998, 'yuv.min=', -37.565619999999996)
('yuv.max=', 193.83199999999999, 'yuv.min=', -35.840139999999991)
('yuv.max=', 249.49499999999998, 'yuv.min=', -32.609780000000001)
('yuv.max=', 223.81799999999998, 'yuv.min=', -72.345899999999986)
('yuv.max=', 255.0, 'yuv.min=', -45.409989999999993)
('yuv.max=', 206.64799999999997, 'yuv.min=', -42.530439999999984)
('yuv.max=', 234.57999999999998, 'yuv.min=', -34.635449999999992)
('yuv.max=', 253.54399999999998, 'yuv.min=', -37.821029999999993)
('yuv.max=', 214.84099999999998, 'yuv.min=', -30.045359999999992)
('yuv.max=', 192.976, 'yuv.min=', -15.915299999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', -8.0800699999999921)
('yuv.max=', 233.05799999999999, 'yuv.min=', -27.020069999999993)
('yuv.max=', 243.99999999999997, 'yuv.min=', -20.349250000000001)
('yuv.max=', 254.10300000000001, 'yuv.min=', -28.006790000000006)
('yuv.max=', 255.0, 'yuv.min=', -38.845890000000011)
('yuv.max=', 213.11700000000002, 'yuv.min=', -53.75564)
('yuv.max=', 204.40199999999999, 'yuv.min=', -9.6125499999999988)
('yuv.max=', 255.0, 'yuv.min=', -12.955249999999996)
('yuv.max=', 241.21699999999998, 'yuv.min=', -121.58035)
('yuv.max=', 204.50299999999999, 'yuv.min=', -23.826409999999999)
('yuv.max=', 229.607, 'yuv.min=', -22.436060000000001)
('yuv.max=', 253.0, 'yuv.min=', -13.415049999999994)
('yuv.max=', 254.41299999999995, 'yuv.min=', -39.446299999999994)
('yuv.max=', 241.92199999999997, 'yuv.min=', -48.480419999999995)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -52.305329999999998)
('yuv.max=', 254.886, 'yuv.min=', -43.715620000000001)
('yuv.max=', 222.15800000000002, 'yuv.min=', -42.770709999999994)
('yuv.max=', 229.65799999999996, 'yuv.min=', -19.579989999999995)
('yuv.max=', 215.0, 'yuv.min=', -38.725490000000001)
('yuv.max=', 184.804, 'yuv.min=', -17.428630000000005)
('yuv.max=', 248.02399999999997, 'yuv.min=', -41.585529999999991)
('yuv.max=', 203.785, 'yuv.min=', -9.3100699999999996)
('yuv.max=', 252.97800000000001, 'yuv.min=', -21.24822)
('yuv.max=', 255.0, 'yuv.min=', -29.675199999999997)
('yuv.max=', 200.30099999999999, 'yuv.min=', -49.135669999999983)
('yuv.max=', 221.12699999999998, 'yuv.min=', -25.970259999999989)
('yuv.max=', 220.071, 'yuv.min=', -20.835299999999989)
('yuv.max=', 253.80399999999997, 'yuv.min=', -47.110159999999993)
('yuv.max=', 247.95699999999999, 'yuv.min=', -25.324890000000003)
('yuv.max=', 195.41, 'yuv.min=', -38.065669999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.75, 'yuv.min=', -43.085679999999982)
('yuv.max=', 252.0, 'yuv.min=', -8.495049999999992)
('yuv.max=', 246.59799999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 224.29499999999999, 'yuv.min=', -70.32495999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.895190000000003)
('yuv.max=', 246.34799999999998, 'yuv.min=', -54.100489999999994)
('yuv.max=', 245.61500000000001, 'yuv.min=', -19.474540000000001)
('yuv.max=', 255.0, 'yuv.min=', -29.900529999999996)
('yuv.max=', 221.82499999999999, 'yuv.min=', -32.441750000000006)
('yuv.max=', 224.35299999999995, 'yuv.min=', -14.270319999999998)
('yuv.max=', 231.011, 'yuv.min=', -23.965489999999992)
('yuv.max=', 182.46299999999999, 'yuv.min=', -37.640319999999996)
('yuv.max=', 235.667, 'yuv.min=', -30.959589999999999)
('yuv.max=', 248.0, 'yuv.min=', -10.775769999999998)
('yuv.max=', 199.77499999999998, 'yuv.min=', -37.375969999999995)
('yuv.max=', 201.61600000000001, 'yuv.min=', -19.320209999999982)
('yuv.max=', 216.477, 'yuv.min=', -65.685479999999984)
('yuv.max=', 220.93799999999996, 'yuv.min=', -17.880670000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -86.591930000000005)
('yuv.max=', 250.10299999999998, 'yuv.min=', -46.210069999999995)
('yuv.max=', 252.90699999999998, 'yuv.min=', -20.150169999999996)
('yuv.max=', 250.24899999999997, 'yuv.min=', -46.000590000000003)
('yuv.max=', 221.63399999999999, 'yuv.min=', -27.98997)
('yuv.max=', 255.0, 'yuv.min=', -37.909040000000005)
('yuv.max=', 248.35900000000001, 'yuv.min=', -13.78716)
('yuv.max=', 251.755, 'yuv.min=', -24.609510000000007)
('yuv.max=', 235.15700000000001, 'yuv.min=', -58.905539999999988)
('yuv.max=', 249.41299999999998, 'yuv.min=', -22.46077)
('yuv.max=', 255.0, 'yuv.min=', -26.774109999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.002389999999991)
('yuv.max=', 240.03499999999997, 'yuv.min=', -25.607889999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.93291)
('yuv.max=', 223.69499999999999, 'yuv.min=', -12.140229999999997)
('yuv.max=', 250.94599999999997, 'yuv.min=', -44.130599999999994)
('yuv.max=', 228.71599999999998, 'yuv.min=', -23.694680000000005)
('yuv.max=', 217.32599999999999, 'yuv.min=', -34.780279999999983)
('yuv.max=', 186.64699999999999, 'yuv.min=', -19.504430000000003)
('yuv.max=', 227.18799999999999, 'yuv.min=', -62.982949999999995)
('yuv.max=', 213.374, 'yuv.min=', -22.605599999999992)
('yuv.max=', 245.69000000000003, 'yuv.min=', -15.975060000000001)
('yuv.max=', 219.85999999999999, 'yuv.min=', -28.948969999999999)
('yuv.max=', 213.58199999999999, 'yuv.min=', -63.583759999999998)
('yuv.max=', 218.25599999999997, 'yuv.min=', -22.78031)
('yuv.max=', 245.376, 'yuv.min=', -18.579889999999992)
('yuv.max=', 251.381, 'yuv.min=', -41.100380000000008)
('yuv.max=', 254.43000000000001, 'yuv.min=', -41.485519999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -34.935479999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.080369999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.089, 'yuv.min=', -42.585629999999988)
('yuv.max=', 212.25799999999998, 'yuv.min=', -44.745599999999996)
('yuv.max=', 255.0, 'yuv.min=', -40.870519999999992)
('yuv.max=', 255.0, 'yuv.min=', -51.609910000000006)
('yuv.max=', 217.12200000000001, 'yuv.min=', -55.755839999999999)
('yuv.max=', 238.34, 'yuv.min=', -17.145299999999988)
('yuv.max=', 206.70299999999997, 'yuv.min=', -26.353780000000015)
('yuv.max=', 253.35899999999998, 'yuv.min=', -33.624190000000006)
('yuv.max=', 219.96100000000001, 'yuv.min=', -18.805219999999998)
('yuv.max=', 221.15700000000001, 'yuv.min=', -18.590260000000001)
('yuv.max=', 240.88999999999999, 'yuv.min=', -45.090839999999993)
('yuv.max=', 211.27099999999999, 'yuv.min=', -47.080280000000002)
('yuv.max=', 253.505, 'yuv.min=', -19.505289999999995)
('yuv.max=', 249.131, 'yuv.min=', -6.5339399999999976)
('yuv.max=', 254.131, 'yuv.min=', -18.560379999999999)
('yuv.max=', 186.99499999999998, 'yuv.min=', -24.08595)
('yuv.max=', 186.90100000000001, 'yuv.min=', -33.450269999999989)
('yuv.max=', 191.96599999999998, 'yuv.min=', -70.950249999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.430759999999992)
('yuv.max=', 237.41300000000001, 'yuv.min=', -46.241139999999994)
('yuv.max=', 204.28799999999998, 'yuv.min=', -4.9523399999999924)
('yuv.max=', 245.04300000000001, 'yuv.min=', -22.125059999999998)
('yuv.max=', 152.77199999999999, 'yuv.min=', -2.0317399999999992)
('yuv.max=', 240.62099999999998, 'yuv.min=', -76.477339999999998)
('yuv.max=', 183.292, 'yuv.min=', -33.935379999999995)
('yuv.max=', 214.85400000000001, 'yuv.min=', -22.189799999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.640179999999997)
('yuv.max=', 244.41499999999999, 'yuv.min=', -28.103550000000006)
('yuv.max=', 252.42999999999998, 'yuv.min=', -39.853640000000006)
('yuv.max=', 179.23599999999999, 'yuv.min=', -49.480519999999999)
('yuv.max=', 196.22499999999997, 'yuv.min=', -45.790519999999987)
('yuv.max=', 238.61399999999998, 'yuv.min=', -88.580739999999992)
('yuv.max=', 252.47900000000001, 'yuv.min=', -55.554920000000003)
('yuv.max=', 237.03399999999999, 'yuv.min=', -20.740009999999998)
('yuv.max=', 221.64599999999999, 'yuv.min=', -18.315539999999999)
('yuv.max=', 231.15799999999999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 159.36000000000001, 'yuv.min=', -30.13043)
('yuv.max=', 246.77600000000001, 'yuv.min=', -34.790940000000006)
('yuv.max=', 199.88499999999996, 'yuv.min=', -19.780009999999997)
('yuv.max=', 187.614, 'yuv.min=', -35.675799999999995)
('yuv.max=', 200.357, 'yuv.min=', -33.776739999999997)
('yuv.max=', 255.0, 'yuv.min=', -10.778420000000004)
('yuv.max=', 249.04300000000001, 'yuv.min=', -18.168999999999997)
('yuv.max=', 183.499, 'yuv.min=', -14.355389999999996)
('yuv.max=', 197.43699999999998, 'yuv.min=', -68.580969999999994)
('yuv.max=', 244.732, 'yuv.min=', -56.320219999999978)
('yuv.max=', 238.0, 'yuv.min=', -10.027080000000002)
('yuv.max=', 248.34399999999999, 'yuv.min=', -17.05651000000001)
('yuv.max=', 179.04299999999998, 'yuv.min=', -35.590590000000006)
('yuv.max=', 241.27799999999996, 'yuv.min=', -80.115569999999991)
('yuv.max=', 255.0, 'yuv.min=', -20.220300000000002)
('yuv.max=', 233.21099999999998, 'yuv.min=', -44.71443)
('yuv.max=', 254.70099999999999, 'yuv.min=', -58.960729999999984)
('yuv.max=', 255.0, 'yuv.min=', -43.820690000000006)
('yuv.max=', 209.24700000000001, 'yuv.min=', -9.6951699999999938)
('yuv.max=', 171.16299999999998, 'yuv.min=', -57.11433000000001)
('yuv.max=', 250.34200000000001, 'yuv.min=', -24.256939999999997)
('yuv.max=', 241.702, 'yuv.min=', -28.517230000000012)
('yuv.max=', 218.10699999999997, 'yuv.min=', -24.14751)
('yuv.max=', 204.61399999999998, 'yuv.min=', -22.180249999999987)
('yuv.max=', 228.67600000000002, 'yuv.min=', -18.120089999999994)
('yuv.max=', 210.40200000000002, 'yuv.min=', -5.8051499999999976)
('yuv.max=', 245.42299999999997, 'yuv.min=', -41.930379999999992)
('yuv.max=', 247.20700000000002, 'yuv.min=', -17.334290000000003)
('yuv.max=', 196.52999999999997, 'yuv.min=', -87.544960000000003)
('yuv.max=', 255.0, 'yuv.min=', -76.460019999999986)
('yuv.max=', 168.27599999999998, 'yuv.min=', -54.970699999999979)
('yuv.max=', 178.39599999999999, 'yuv.min=', -27.915270000000003)
('yuv.max=', 207.35899999999998, 'yuv.min=', -21.395110000000003)
('yuv.max=', 205.92899999999997, 'yuv.min=', -8.4950499999999973)
('yuv.max=', 202.56399999999999, 'yuv.min=', -15.852490000000003)
('yuv.max=', 204.67099999999999, 'yuv.min=', -24.740260000000003)
('yuv.max=', 221.66399999999999, 'yuv.min=', -20.958370000000002)
('yuv.max=', 224.85999999999996, 'yuv.min=', -102.03785999999999)
('yuv.max=', 247.07300000000001, 'yuv.min=', -59.050369999999987)
('yuv.max=', 214.75, 'yuv.min=', -21.67887)
('yuv.max=', 254.77200000000002, 'yuv.min=', -28.400379999999995)
('yuv.max=', 238.88899999999998, 'yuv.min=', -77.545189999999991)
('yuv.max=', 203.89699999999999, 'yuv.min=', -23.547809999999998)
('yuv.max=', 197.78799999999998, 'yuv.min=', -24.525299999999994)
('yuv.max=', 243.47299999999998, 'yuv.min=', -66.930419999999998)
('yuv.max=', 244.40099999999995, 'yuv.min=', -48.769030000000008)
('yuv.max=', 255.0, 'yuv.min=', -1.7151099999999975)
('yuv.max=', 237.57499999999999, 'yuv.min=', -23.020579999999995)
('yuv.max=', 252.07099999999997, 'yuv.min=', -22.120490000000004)
('yuv.max=', 253.50099999999998, 'yuv.min=', -5.7648999999999955)
('yuv.max=', 206.14699999999999, 'yuv.min=', -26.500189999999993)
('yuv.max=', 241.59799999999996, 'yuv.min=', -26.970359999999992)
('yuv.max=', 255.0, 'yuv.min=', -24.025249999999993)
('yuv.max=', 251.27700000000002, 'yuv.min=', -20.705409999999986)
('yuv.max=', 235.20399999999998, 'yuv.min=', -89.185369999999992)
('yuv.max=', 234.37, 'yuv.min=', -24.810389999999995)
('yuv.max=', 220.20099999999999, 'yuv.min=', -23.18034999999999)
('yuv.max=', 172.08100000000002, 'yuv.min=', -53.840709999999987)
('yuv.max=', 206.86800000000002, 'yuv.min=', -28.055800000000005)
('yuv.max=', 219.68699999999998, 'yuv.min=', -34.681910000000002)
('yuv.max=', 249.125, 'yuv.min=', -7.4650699999999919)
('yuv.max=', 255.0, 'yuv.min=', -50.320849999999993)
('yuv.max=', 254.316, 'yuv.min=', -21.913359999999997)
('yuv.max=', 221.292, 'yuv.min=', -70.798359999999988)
('yuv.max=', 235.15300000000002, 'yuv.min=', -36.195359999999994)
('yuv.max=', 204.15799999999999, 'yuv.min=', -22.796120000000002)
('yuv.max=', 251.08799999999999, 'yuv.min=', -25.75988000000001)
('yuv.max=', 230.70599999999999, 'yuv.min=', -42.651020000000003)
('yuv.max=', 248.71199999999999, 'yuv.min=', -41.605039999999988)
('yuv.max=', 184.94799999999998, 'yuv.min=', -25.410449999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.3052999999999972)
('yuv.max=', 251.52700000000002, 'yuv.min=', -24.555179999999993)
('yuv.max=', 220.65199999999999, 'yuv.min=', -13.221040000000002)
('yuv.max=', 233.34999999999999, 'yuv.min=', -59.384849999999993)
('yuv.max=', 255.0, 'yuv.min=', -4.8377499999999998)
('yuv.max=', 242.87099999999998, 'yuv.min=', -59.827750000000002)
('yuv.max=', 210.14099999999999, 'yuv.min=', -48.980469999999983)
('yuv.max=', 245.51999999999998, 'yuv.min=', -25.490949999999998)
('yuv.max=', 218.399, 'yuv.min=', -6.4238900000000001)
('yuv.max=', 233.13399999999999, 'yuv.min=', -20.675620000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.530399999999997)
('yuv.max=', 235.69799999999998, 'yuv.min=', -46.175619999999995)
('yuv.max=', 255.0, 'yuv.min=', -47.24584999999999)
('yuv.max=', 208.846, 'yuv.min=', -48.3551)
('yuv.max=', 255.0, 'yuv.min=', -24.691850000000002)
('yuv.max=', 254.886, 'yuv.min=', -30.981949999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.101019999999991)
('yuv.max=', 246.95700000000002, 'yuv.min=', -19.684570000000001)
('yuv.max=', 255.0, 'yuv.min=', -27.200259999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 241.95099999999999, 'yuv.min=', -79.25703)
('yuv.max=', 234.47199999999998, 'yuv.min=', -20.261259999999993)
('yuv.max=', 217.785, 'yuv.min=', -23.235539999999993)
('yuv.max=', 228.16699999999997, 'yuv.min=', -28.015279999999994)
('yuv.max=', 251.50099999999998, 'yuv.min=', -47.535509999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -26.970359999999996)
('yuv.max=', 247.846, 'yuv.min=', -95.375619999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.435250000000003)
('yuv.max=', 233.005, 'yuv.min=', -23.150469999999995)
('yuv.max=', 228.27500000000001, 'yuv.min=', -25.476430000000015)
('yuv.max=', 172.96099999999998, 'yuv.min=', -15.689969999999994)
('yuv.max=', 233.59699999999998, 'yuv.min=', -33.990569999999998)
('yuv.max=', 246.28800000000001, 'yuv.min=', -22.314709999999998)
('yuv.max=', 246.19999999999999, 'yuv.min=', -58.976939999999999)
('yuv.max=', 189.232, 'yuv.min=', -18.475310000000004)
('yuv.max=', 255.0, 'yuv.min=', -21.191590000000001)
('yuv.max=', 223.417, 'yuv.min=', -22.865379999999998)
('yuv.max=', 240.36799999999999, 'yuv.min=', -65.713619999999992)
('yuv.max=', 169.86599999999999, 'yuv.min=', -27.270389999999999)
('yuv.max=', 255.0, 'yuv.min=', -51.613829999999993)
('yuv.max=', 238.095, 'yuv.min=', -35.81026)
('yuv.max=', 209.667, 'yuv.min=', -27.340520000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', -96.234229999999982)
('yuv.max=', 215.13200000000001, 'yuv.min=', -32.773960000000002)
('yuv.max=', 253.22799999999998, 'yuv.min=', -21.084270000000011)
('yuv.max=', 244.505, 'yuv.min=', -29.815460000000005)
('yuv.max=', 252.608, 'yuv.min=', -35.225139999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.2803599999999982)
('yuv.max=', 224.38999999999999, 'yuv.min=', -37.470179999999999)
('yuv.max=', 203.72399999999999, 'yuv.min=', -37.035740000000004)
('yuv.max=', 209.71600000000001, 'yuv.min=', -30.185620000000004)
('yuv.max=', 220.642, 'yuv.min=', -33.715849999999989)
('yuv.max=', 250.02199999999999, 'yuv.min=', -14.157439999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.566310000000001)
('yuv.max=', 239.38, 'yuv.min=', -51.657920000000004)
('yuv.max=', 240.071, 'yuv.min=', -71.620519999999999)
('yuv.max=', 249.857, 'yuv.min=', -59.48942000000001)
('yuv.max=', 233.25700000000001, 'yuv.min=', -20.571380000000005)
('yuv.max=', 245.04399999999998, 'yuv.min=', -31.139610000000008)
('yuv.max=', 255.0, 'yuv.min=', -2.6145100000000099)
('yuv.max=', 245.90399999999997, 'yuv.min=', -25.729989999999987)
('yuv.max=', 249.696, 'yuv.min=', -22.16530999999998)
('yuv.max=', 164.114, 'yuv.min=', -5.4752399999999994)
('yuv.max=', 249.87, 'yuv.min=', -29.490119999999987)
('yuv.max=', 253.52699999999999, 'yuv.min=', -0.50004999999999988)
('yuv.max=', 213.005, 'yuv.min=', -23.232390000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.995369999999998)
('yuv.max=', 145.626, 'yuv.min=', -38.463760000000008)
('yuv.max=', 255.0, 'yuv.min=', -35.150439999999996)
('yuv.max=', 240.58999999999997, 'yuv.min=', -37.149619999999999)
('yuv.max=', 232.22800000000001, 'yuv.min=', -12.46828)
('yuv.max=', 247.12499999999997, 'yuv.min=', -47.280299999999997)
('yuv.max=', 255.0, 'yuv.min=', -17.015409999999996)
('yuv.max=', 242.797, 'yuv.min=', -33.875640000000004)
('yuv.max=', 245.10299999999998, 'yuv.min=', -19.620239999999988)
('yuv.max=', 249.56099999999998, 'yuv.min=', -16.042970000000004)
('yuv.max=', 248.66900000000001, 'yuv.min=', -28.885489999999994)
('yuv.max=', 255.0, 'yuv.min=', -29.315409999999996)
('yuv.max=', 216.74000000000001, 'yuv.min=', -22.050359999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.0, 'yuv.min=', -74.095459999999989)
('yuv.max=', 248.22800000000001, 'yuv.min=', -23.401189999999996)
('yuv.max=', 226.22799999999998, 'yuv.min=', -24.270300000000006)
('yuv.max=', 240.95699999999999, 'yuv.min=', -9.154200000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.366070000000001)
('yuv.max=', 224.04300000000001, 'yuv.min=', -36.295369999999991)
('yuv.max=', 254.28799999999998, 'yuv.min=', -95.605519999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -67.570729999999998)
('yuv.max=', 243.322, 'yuv.min=', -33.413160000000005)
('yuv.max=', 249.70099999999999, 'yuv.min=', -18.463710000000003)
('yuv.max=', 186.43099999999998, 'yuv.min=', -28.381710000000005)
('yuv.max=', 239.57599999999999, 'yuv.min=', -36.601250000000007)
('yuv.max=', 222.51599999999996, 'yuv.min=', -27.055429999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', -42.80059)
('yuv.max=', 248.98299999999998, 'yuv.min=', -72.805700000000002)
('yuv.max=', 239.79399999999998, 'yuv.min=', -29.015379999999986)
('yuv.max=', 250.0, 'yuv.min=', -3.4899800000000001)
('yuv.max=', 248.93899999999996, 'yuv.min=', -21.080139999999989)
('yuv.max=', 238.125, 'yuv.min=', -74.111239999999995)
('yuv.max=', 181.68000000000001, 'yuv.min=', -26.780709999999992)
('yuv.max=', 176.47200000000001, 'yuv.min=', -17.075169999999993)
('yuv.max=', 239.00999999999999, 'yuv.min=', -30.830499999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.490539999999999)
('yuv.max=', 164.94799999999998, 'yuv.min=', -55.125900000000001)
('yuv.max=', 209.04899999999998, 'yuv.min=', -23.980429999999988)
('yuv.max=', 253.29900000000001, 'yuv.min=', -28.955619999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.58699999999996, 'yuv.min=', -27.825629999999997)
('yuv.max=', 253.77199999999999, 'yuv.min=', -96.674959999999999)
('yuv.max=', 250.08099999999996, 'yuv.min=', -21.248320000000003)
('yuv.max=', 253.21699999999998, 'yuv.min=', -30.920139999999993)
('yuv.max=', 252.34199999999998, 'yuv.min=', -35.465409999999991)
('yuv.max=', 254.18499999999997, 'yuv.min=', -50.181930000000008)
('yuv.max=', 167.09099999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 228.54600000000002, 'yuv.min=', -8.580120000000008)
('yuv.max=', 235.77999999999997, 'yuv.min=', -18.327090000000002)
('yuv.max=', 253.46199999999999, 'yuv.min=', -15.330179999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.890089999999997)
('yuv.max=', 216.971, 'yuv.min=', -39.825599999999994)
('yuv.max=', 252.70699999999999, 'yuv.min=', -54.360269999999979)
('yuv.max=', 175.55399999999997, 'yuv.min=', -42.630449999999996)
('yuv.max=', 201.089, 'yuv.min=', -24.795449999999995)
('yuv.max=', 227.899, 'yuv.min=', -26.795649999999995)
('yuv.max=', 243.988, 'yuv.min=', -30.464909999999996)
('yuv.max=', 239.15899999999999, 'yuv.min=', -41.825799999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.813270000000006)
('yuv.max=', 226.899, 'yuv.min=', -26.043440000000004)
('yuv.max=', 172.11600000000001, 'yuv.min=', -27.434620000000002)
('yuv.max=', 255.0, 'yuv.min=', -27.485349999999997)
('yuv.max=', 251.626, 'yuv.min=', -17.470639999999996)
('yuv.max=', 253.80399999999997, 'yuv.min=', -71.956229999999991)
('yuv.max=', 245.00699999999998, 'yuv.min=', -38.240379999999988)
('yuv.max=', 255.0, 'yuv.min=', -19.690369999999994)
('yuv.max=', 245.77199999999999, 'yuv.min=', -57.975569999999991)
('yuv.max=', 203.12200000000001, 'yuv.min=', -36.150539999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.492910000000002)
('yuv.max=', 249.43000000000001, 'yuv.min=', -16.200389999999999)
('yuv.max=', 224.0, 'yuv.min=', -23.976700000000001)
('yuv.max=', 228.52199999999996, 'yuv.min=', -25.346080000000001)
('yuv.max=', 243.42999999999998, 'yuv.min=', -3.9225100000000097)
('yuv.max=', 252.0, 'yuv.min=', -24.33803)
('yuv.max=', 253.14199999999997, 'yuv.min=', -48.365469999999995)
('yuv.max=', 176.74799999999999, 'yuv.min=', -12.955249999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.416290000000004)
('yuv.max=', 255.0, 'yuv.min=', -5.387430000000009)
('yuv.max=', 255.0, 'yuv.min=', -17.675229999999992)
('yuv.max=', 255.0, 'yuv.min=', -27.603260000000002)
('yuv.max=', 245.59699999999998, 'yuv.min=', -14.218749999999998)
('yuv.max=', 174.97299999999998, 'yuv.min=', -71.160719999999998)
('yuv.max=', 223.07499999999999, 'yuv.min=', -27.485349999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -46.203720000000004)
('yuv.max=', 231.54999999999998, 'yuv.min=', -15.100279999999994)
('yuv.max=', 229.87299999999996, 'yuv.min=', -24.910399999999996)
('yuv.max=', 247.172, 'yuv.min=', -14.124960000000002)
('yuv.max=', 254.35900000000001, 'yuv.min=', -43.282669999999996)
('yuv.max=', 246.98500000000001, 'yuv.min=', -32.97719)
('yuv.max=', 250.51499999999999, 'yuv.min=', -53.89009999999999)
('yuv.max=', 244.065, 'yuv.min=', -55.296039999999998)
('yuv.max=', 168.83699999999999, 'yuv.min=', -45.969799999999999)
('yuv.max=', 248.422, 'yuv.min=', -27.059999999999988)
('yuv.max=', 255.0, 'yuv.min=', -6.9799600000000019)
('yuv.max=', 221.21899999999999, 'yuv.min=', -32.849589999999999)
('yuv.max=', 232.0, 'yuv.min=', -7.7501599999999904)
('yuv.max=', 253.52699999999999, 'yuv.min=', -63.750839999999997)
('yuv.max=', 245.93799999999999, 'yuv.min=', -45.014070000000011)
('yuv.max=', 239.44499999999999, 'yuv.min=', -47.460809999999995)
('yuv.max=', 255.0, 'yuv.min=', -30.154509999999998)
('yuv.max=', 240.79499999999996, 'yuv.min=', -28.815359999999995)
('yuv.max=', 251.10299999999998, 'yuv.min=', -14.215129999999995)
('yuv.max=', 246.11299999999997, 'yuv.min=', -66.291460000000015)
('yuv.max=', 255.0, 'yuv.min=', -17.07517)
('yuv.max=', 209.886, 'yuv.min=', -51.794220000000003)
('yuv.max=', 217.34399999999999, 'yuv.min=', -10.995299999999986)
('yuv.max=', 255.0, 'yuv.min=', -18.049959999999992)
('yuv.max=', 238.53100000000001, 'yuv.min=', -17.345319999999997)
('yuv.max=', 244.58700000000002, 'yuv.min=', -15.415249999999995)
('yuv.max=', 252.761, 'yuv.min=', -26.870349999999998)
('yuv.max=', 234.80199999999999, 'yuv.min=', -45.000809999999994)
('yuv.max=', 239.096, 'yuv.min=', -51.00018)
('yuv.max=', 203.06299999999999, 'yuv.min=', -24.23564)
('yuv.max=', 235.87099999999995, 'yuv.min=', -24.320709999999981)
('yuv.max=', 246.869, 'yuv.min=', -69.300779999999989)
('yuv.max=', 237.899, 'yuv.min=', -37.843290000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -16.370529999999992)
('yuv.max=', 236.291, 'yuv.min=', -43.330519999999993)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.940359999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.338939999999997)
('yuv.max=', 194.16399999999999, 'yuv.min=', -25.400079999999999)
('yuv.max=', 241.39299999999997, 'yuv.min=', -30.65579)
('yuv.max=', 251.71100000000001, 'yuv.min=', -28.889319999999998)
('yuv.max=', 164.46499999999997, 'yuv.min=', -35.831000000000003)
('yuv.max=', 226.583, 'yuv.min=', -37.350660000000005)
('yuv.max=', 229.245, 'yuv.min=', -26.359719999999996)
('yuv.max=', 175.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -25.350689999999993)
('yuv.max=', 253.63200000000001, 'yuv.min=', -62.095489999999998)
('yuv.max=', 220.40899999999999, 'yuv.min=', -37.347310000000007)
('yuv.max=', 238.34199999999998, 'yuv.min=', -24.321329999999996)
('yuv.max=', 227.75899999999999, 'yuv.min=', -22.835499999999996)
('yuv.max=', 232.40000000000001, 'yuv.min=', -40.588880000000003)
('yuv.max=', 228.30999999999997, 'yuv.min=', -15.330179999999999)
('yuv.max=', 227.99299999999999, 'yuv.min=', -25.979330000000001)
('yuv.max=', 252.114, 'yuv.min=', -21.630670000000002)
('yuv.max=', 235.142, 'yuv.min=', -12.014909999999999)
('yuv.max=', 214.09500000000003, 'yuv.min=', -49.825369999999992)
('yuv.max=', 214.97800000000001, 'yuv.min=', -27.404849999999993)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.65199999999999, 'yuv.min=', -23.725219999999986)
('yuv.max=', 236.27800000000002, 'yuv.min=', -13.835679999999996)
('yuv.max=', 193.80999999999997, 'yuv.min=', -70.160619999999994)
('yuv.max=', 223.83799999999999, 'yuv.min=', -19.905329999999985)
('yuv.max=', 229.00399999999999, 'yuv.min=', -26.855409999999996)
('yuv.max=', 238.97899999999998, 'yuv.min=', -54.209459999999993)
('yuv.max=', 225.285, 'yuv.min=', -26.669560000000004)
('yuv.max=', 247.19999999999999, 'yuv.min=', -42.900599999999997)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.70100000000002, 'yuv.min=', -25.37019999999999)
('yuv.max=', 251.755, 'yuv.min=', -10.940109999999992)
('yuv.max=', 171.66, 'yuv.min=', -26.825530000000001)
('yuv.max=', 255.0, 'yuv.min=', -40.070439999999991)
('yuv.max=', 249.03899999999999, 'yuv.min=', -45.385720000000006)
('yuv.max=', 237.56899999999999, 'yuv.min=', -29.400479999999995)
('yuv.max=', 253.02799999999996, 'yuv.min=', -51.021419999999999)
('yuv.max=', 238.36599999999999, 'yuv.min=', -29.27562)
('yuv.max=', 251.62099999999998, 'yuv.min=', -27.410649999999997)
('yuv.max=', 254.43000000000001, 'yuv.min=', -10.746290000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.381, 'yuv.min=', -22.55574)
('yuv.max=', 254.10300000000001, 'yuv.min=', -12.663830000000004)
('yuv.max=', 228.96699999999998, 'yuv.min=', -50.530009999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.955039999999997)
('yuv.max=', 211.25200000000001, 'yuv.min=', -16.703199999999995)
('yuv.max=', 234.815, 'yuv.min=', -37.200720000000004)
('yuv.max=', 254.10300000000001, 'yuv.min=', -34.284440000000011)
('yuv.max=', 246.49399999999997, 'yuv.min=', -48.255089999999996)
('yuv.max=', 244.03199999999998, 'yuv.min=', -6.0499899999999975)
('yuv.max=', 208.22699999999998, 'yuv.min=', -19.835600000000007)
('yuv.max=', 233.52499999999998, 'yuv.min=', -12.070099999999989)
('yuv.max=', 254.11399999999998, 'yuv.min=', -65.686570000000003)
('yuv.max=', 233.72899999999998, 'yuv.min=', -80.430539999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.3752299999999895)
('yuv.max=', 248.86000000000001, 'yuv.min=', -15.345119999999998)
('yuv.max=', 255.0, 'yuv.min=', -41.255619999999979)
('yuv.max=', 207.29999999999998, 'yuv.min=', -53.760209999999994)
('yuv.max=', 249.11799999999999, 'yuv.min=', -44.104250000000015)
('yuv.max=', 244.29499999999999, 'yuv.min=', -19.776420000000009)
('yuv.max=', 250.99999999999997, 'yuv.min=', -64.350899999999996)
('yuv.max=', 255.0, 'yuv.min=', -8.8043900000000122)
('yuv.max=', 255.0, 'yuv.min=', -38.888779999999997)
('yuv.max=', 197.761, 'yuv.min=', -19.375399999999988)
('yuv.max=', 194.94899999999998, 'yuv.min=', -22.280259999999995)
('yuv.max=', 255.0, 'yuv.min=', -31.252000000000002)
('yuv.max=', 181.90699999999998, 'yuv.min=', -39.525569999999995)
('yuv.max=', 250.51499999999999, 'yuv.min=', -19.335149999999999)
('yuv.max=', 247.35799999999998, 'yuv.min=', -29.925839999999997)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.52599999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.565149999999981)
('yuv.max=', 255.0, 'yuv.min=', -20.520330000000001)
('yuv.max=', 223.596, 'yuv.min=', -33.226030000000009)
('yuv.max=', 228.755, 'yuv.min=', -24.588960000000004)
('yuv.max=', 168.20599999999999, 'yuv.min=', -5.5350000000000001)
('yuv.max=', 218.27500000000001, 'yuv.min=', -25.87482)
('yuv.max=', 212.48399999999998, 'yuv.min=', -30.375269999999997)
('yuv.max=', 253.11999999999998, 'yuv.min=', -4.3521300000000167)
('yuv.max=', 248.08000000000001, 'yuv.min=', -32.120899999999992)
('yuv.max=', 209.76399999999998, 'yuv.min=', -99.285509999999988)
('yuv.max=', 208.69299999999998, 'yuv.min=', -30.136399999999995)
('yuv.max=', 241.45599999999999, 'yuv.min=', -21.111670000000004)
('yuv.max=', 252.70099999999999, 'yuv.min=', -49.995509999999996)
('yuv.max=', 144.83000000000001, 'yuv.min=', -11.614869999999991)
('yuv.max=', 255.0, 'yuv.min=', -34.722680000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999987)
('yuv.max=', 242.52200000000002, 'yuv.min=', -13.440359999999995)
('yuv.max=', 235.25599999999997, 'yuv.min=', -61.358939999999997)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 252.114, 'yuv.min=', -26.940479999999997)
('yuv.max=', 246.42999999999998, 'yuv.min=', -32.905399999999986)
('yuv.max=', 230.72999999999999, 'yuv.min=', -34.335419999999985)
('yuv.max=', 226.0, 'yuv.min=', -7.8420200000000015)
('yuv.max=', 239.10699999999997, 'yuv.min=', -93.115640000000013)
('yuv.max=', 229.887, 'yuv.min=', -41.084650000000011)
('yuv.max=', 217.35199999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.729459999999996)
('yuv.max=', 241.47300000000001, 'yuv.min=', -42.040759999999992)
('yuv.max=', 251.48300000000003, 'yuv.min=', -39.055399999999999)
('yuv.max=', 205.89999999999998, 'yuv.min=', -34.545810000000003)
('yuv.max=', 249.20699999999999, 'yuv.min=', -4.679230000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.258359999999996)
('yuv.max=', 255.0, 'yuv.min=', -22.376289999999997)
('yuv.max=', 216.04999999999998, 'yuv.min=', -27.841349999999998)
('yuv.max=', 248.36599999999999, 'yuv.min=', -12.555210000000002)
('yuv.max=', 212.91499999999999, 'yuv.min=', -56.205269999999999)
('yuv.max=', 205.81899999999996, 'yuv.min=', -94.780129999999986)
('yuv.max=', 255.0, 'yuv.min=', -15.875049999999991)
('yuv.max=', 208.905, 'yuv.min=', -30.975329999999982)
('yuv.max=', 227.21499999999997, 'yuv.min=', -74.185099999999991)
('yuv.max=', 250.08099999999999, 'yuv.min=', -56.330590000000001)
('yuv.max=', 247.61899999999997, 'yuv.min=', -18.527230000000003)
('yuv.max=', 225.11199999999999, 'yuv.min=', -6.250009999999997)
('yuv.max=', 231.31899999999999, 'yuv.min=', -15.370429999999988)
('yuv.max=', 255.0, 'yuv.min=', -22.654989999999994)
('yuv.max=', 224.72199999999998, 'yuv.min=', -14.24044)
('yuv.max=', 252.22799999999998, 'yuv.min=', -12.09225)
('yuv.max=', 217.78899999999999, 'yuv.min=', -41.897189999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -30.965410000000002)
('yuv.max=', 234.09899999999999, 'yuv.min=', -26.970359999999996)
('yuv.max=', 250.28799999999998, 'yuv.min=', -52.580829999999992)
('yuv.max=', 230.39400000000001, 'yuv.min=', -23.722280000000001)
('yuv.max=', 243.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -20.479060000000004)
('yuv.max=', 249.505, 'yuv.min=', -51.032199999999996)
('yuv.max=', 207.62799999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 196.58699999999999, 'yuv.min=', -27.134699999999984)
('yuv.max=', 251.41199999999998, 'yuv.min=', -56.945589999999996)
('yuv.max=', 211.28799999999998, 'yuv.min=', -33.535339999999991)
('yuv.max=', 219.756, 'yuv.min=', -15.449250000000003)
('yuv.max=', 246.77699999999999, 'yuv.min=', -49.691780000000008)
('yuv.max=', 236.83199999999999, 'yuv.min=', -10.037960000000002)
('yuv.max=', 226.97800000000001, 'yuv.min=', -19.479979999999998)
('yuv.max=', 249.17399999999998, 'yuv.min=', -36.135600000000004)
('yuv.max=', 190.90999999999997, 'yuv.min=', -7.5844000000000023)
('yuv.max=', 237.61600000000001, 'yuv.min=', -60.573650000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.980719999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', -27.739590000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.020219999999995)
('yuv.max=', 248.262, 'yuv.min=', -28.817720000000001)
('yuv.max=', 223.83699999999999, 'yuv.min=', -35.735559999999992)
('yuv.max=', 248.809, 'yuv.min=', -13.170209999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.000269999999997)
('yuv.max=', 254.65800000000002, 'yuv.min=', -13.315039999999996)
('yuv.max=', 218.71199999999999, 'yuv.min=', -36.180419999999991)
('yuv.max=', 237.96299999999997, 'yuv.min=', -50.644450000000006)
('yuv.max=', 255.0, 'yuv.min=', -84.700839999999999)
('yuv.max=', 221.49799999999999, 'yuv.min=', -34.185820000000007)
('yuv.max=', 237.267, 'yuv.min=', -55.055769999999995)
('yuv.max=', 212.70699999999999, 'yuv.min=', -20.811630000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.745229999999999)
('yuv.max=', 198.989, 'yuv.min=', -30.590229999999991)
('yuv.max=', 185.98699999999999, 'yuv.min=', -37.776200000000003)
('yuv.max=', 252.42999999999998, 'yuv.min=', -34.160709999999987)
('yuv.max=', 254.40199999999999, 'yuv.min=', -14.129480000000001)
('yuv.max=', 255.0, 'yuv.min=', -21.058120000000002)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 161.74600000000001, 'yuv.min=', -45.750269999999993)
('yuv.max=', 217.87200000000001, 'yuv.min=', -38.510530000000003)
('yuv.max=', 237.715, 'yuv.min=', -60.235549999999989)
('yuv.max=', 149.59099999999998, 'yuv.min=', -8.0106399999999987)
('yuv.max=', 232.071, 'yuv.min=', -34.420489999999994)
('yuv.max=', 254.07099999999997, 'yuv.min=', -40.753109999999992)
('yuv.max=', 255.0, 'yuv.min=', -2.4674200000000042)
('yuv.max=', 227.27099999999999, 'yuv.min=', -35.165379999999985)
('yuv.max=', 243.66800000000001, 'yuv.min=', -48.03555999999999)
('yuv.max=', 234.25, 'yuv.min=', -26.285229999999995)
('yuv.max=', 255.0, 'yuv.min=', -21.105449999999987)
('yuv.max=', 117.136, 'yuv.min=', -56.16442)
('yuv.max=', 202.21299999999999, 'yuv.min=', -43.510500000000008)
('yuv.max=', 206.11799999999999, 'yuv.min=', -15.459190000000007)
('yuv.max=', 221.31999999999999, 'yuv.min=', -36.510329999999996)
('yuv.max=', 234.88799999999998, 'yuv.min=', -28.485449999999997)
('yuv.max=', 229.44899999999996, 'yuv.min=', -25.525399999999987)
('yuv.max=', 209.161, 'yuv.min=', -54.296030000000002)
('yuv.max=', 252.45799999999997, 'yuv.min=', -38.94267)
('yuv.max=', 251.02199999999996, 'yuv.min=', -44.453030000000012)
('yuv.max=', 227.91399999999999, 'yuv.min=', -16.090710000000005)
('yuv.max=', 246.58399999999997, 'yuv.min=', -34.82809000000001)
('yuv.max=', 232.09799999999998, 'yuv.min=', -43.560419999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.875489999999999)
('yuv.max=', 238.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 247.63, 'yuv.min=', -36.075839999999985)
('yuv.max=', 249.18499999999997, 'yuv.min=', -93.486670000000004)
('yuv.max=', 225.285, 'yuv.min=', -29.552850000000014)
('yuv.max=', 247.499, 'yuv.min=', -50.490820000000014)
('yuv.max=', 238.0, 'yuv.min=', -35.025120000000001)
('yuv.max=', 183.286, 'yuv.min=', -24.610369999999996)
('yuv.max=', 228.80599999999998, 'yuv.min=', -16.315809999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.675599999999996)
('yuv.max=', 249.52699999999999, 'yuv.min=', -22.120490000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.0501900000000006)
('yuv.max=', 203.94999999999999, 'yuv.min=', -24.589170000000006)
('yuv.max=', 240.62599999999998, 'yuv.min=', -45.565130000000011)
('yuv.max=', 251.71199999999999, 'yuv.min=', -22.035419999999998)
('yuv.max=', 233.73399999999998, 'yuv.min=', -23.365429999999989)
('yuv.max=', 223.71199999999999, 'yuv.min=', -30.38073)
('yuv.max=', 253.41299999999998, 'yuv.min=', -44.757670000000012)
('yuv.max=', 231.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.30799999999999, 'yuv.min=', -57.175489999999996)
('yuv.max=', 254.06, 'yuv.min=', -29.479749999999996)
('yuv.max=', 196.81799999999998, 'yuv.min=', -34.120459999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.912179999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.985199999999988)
('yuv.max=', 192.976, 'yuv.min=', -25.955319999999997)
('yuv.max=', 244.05999999999997, 'yuv.min=', -12.800049999999995)
('yuv.max=', 166.86500000000001, 'yuv.min=', -35.035489999999989)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.710380000000001)
('yuv.max=', 233.54300000000001, 'yuv.min=', -35.920639999999992)
('yuv.max=', 235.52099999999999, 'yuv.min=', -17.330380000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.410150000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -10.614850000000011)
('yuv.max=', 248.37399999999997, 'yuv.min=', -46.575659999999985)
('yuv.max=', 251.64299999999997, 'yuv.min=', -52.125599999999991)
('yuv.max=', 236.29899999999998, 'yuv.min=', -22.980329999999991)
('yuv.max=', 179.59699999999998, 'yuv.min=', -21.335349999999998)
('yuv.max=', 204.91999999999999, 'yuv.min=', -39.555449999999993)
('yuv.max=', 241.85600000000002, 'yuv.min=', -20.659750000000006)
('yuv.max=', 236.30199999999999, 'yuv.min=', -21.395110000000003)
('yuv.max=', 226.81499999999997, 'yuv.min=', -18.21552999999999)
('yuv.max=', 210.55500000000001, 'yuv.min=', -24.625309999999992)
('yuv.max=', 243.09, 'yuv.min=', -68.250059999999991)
('yuv.max=', 251.21299999999999, 'yuv.min=', -24.35058999999999)
('yuv.max=', 250.08099999999999, 'yuv.min=', -80.830579999999998)
('yuv.max=', 197.86199999999997, 'yuv.min=', -53.712899999999998)
('yuv.max=', 222.97199999999995, 'yuv.min=', -47.29524)
('yuv.max=', 243.733, 'yuv.min=', -20.820359999999994)
('yuv.max=', 225.39199999999997, 'yuv.min=', -16.960219999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -19.787390000000002)
('yuv.max=', 218.233, 'yuv.min=', -34.645820000000001)
('yuv.max=', 236.64099999999999, 'yuv.min=', -26.44781)
('yuv.max=', 253.989, 'yuv.min=', -69.820339999999987)
('yuv.max=', 252.63, 'yuv.min=', -15.875049999999998)
('yuv.max=', 164.31200000000001, 'yuv.min=', -42.355729999999994)
('yuv.max=', 250.66299999999998, 'yuv.min=', -24.395409999999991)
('yuv.max=', 254.245, 'yuv.min=', -7.3501199999999862)
('yuv.max=', 212.249, 'yuv.min=', -30.475279999999991)
('yuv.max=', 246.15699999999998, 'yuv.min=', -28.785479999999996)
('yuv.max=', 252.679, 'yuv.min=', -31.080530000000003)
('yuv.max=', 203.73099999999999, 'yuv.min=', -59.590669999999989)
('yuv.max=', 209.88800000000001, 'yuv.min=', -34.620509999999996)
('yuv.max=', 225.16999999999999, 'yuv.min=', -31.835169999999998)
('yuv.max=', 219.61699999999999, 'yuv.min=', -32.590429999999991)
('yuv.max=', 243.05999999999997, 'yuv.min=', -25.83793)
('yuv.max=', 209.97199999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 212.28599999999997, 'yuv.min=', -36.566860000000005)
('yuv.max=', 191.36299999999997, 'yuv.min=', -67.162390000000002)
('yuv.max=', 255.0, 'yuv.min=', -47.480319999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 224.72399999999999, 'yuv.min=', -31.545509999999993)
('yuv.max=', 224.69999999999999, 'yuv.min=', -34.56532)
('yuv.max=', 254.40199999999999, 'yuv.min=', -39.170349999999999)
('yuv.max=', 176.43299999999999, 'yuv.min=', -29.400479999999998)
('yuv.max=', 252.0, 'yuv.min=', -19.650119999999998)
('yuv.max=', 239.51599999999996, 'yuv.min=', -39.870419999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -39.580759999999998)
('yuv.max=', 255.0, 'yuv.min=', -51.498949999999994)
('yuv.max=', 245.56999999999999, 'yuv.min=', -15.449169999999995)
('yuv.max=', 237.24899999999997, 'yuv.min=', -30.460339999999984)
('yuv.max=', 176.39699999999999, 'yuv.min=', -44.700779999999995)
('yuv.max=', 238.83099999999999, 'yuv.min=', -41.800489999999996)
('yuv.max=', 203.947, 'yuv.min=', -70.100940000000008)
('yuv.max=', 199.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.41200000000001, 'yuv.min=', -39.78534999999998)
('yuv.max=', 238.81899999999999, 'yuv.min=', -27.910699999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.290769999999995)
('yuv.max=', 190.86099999999999, 'yuv.min=', -24.980529999999998)
('yuv.max=', 239.76999999999998, 'yuv.min=', -59.890699999999988)
('yuv.max=', 196.25, 'yuv.min=', -42.500559999999993)
('yuv.max=', 238.25200000000001, 'yuv.min=', -27.65549)
('yuv.max=', 210.27799999999996, 'yuv.min=', -39.319450000000003)
('yuv.max=', 240.684, 'yuv.min=', -30.630479999999999)
('yuv.max=', 231.67599999999999, 'yuv.min=', -23.67002999999999)
('yuv.max=', 234.078, 'yuv.min=', -26.625509999999998)
('yuv.max=', 227.01699999999997, 'yuv.min=', -22.598860000000002)
('yuv.max=', 197.34399999999999, 'yuv.min=', -13.355289999999982)
('yuv.max=', 220.51400000000001, 'yuv.min=', -30.408900000000003)
('yuv.max=', 253.42999999999998, 'yuv.min=', -34.880289999999988)
('yuv.max=', 213.328, 'yuv.min=', -21.665259999999993)
('yuv.max=', 242.70099999999999, 'yuv.min=', -15.54514)
('yuv.max=', 253.23899999999998, 'yuv.min=', -16.010170000000002)
('yuv.max=', 208.214, 'yuv.min=', -20.120289999999983)
('yuv.max=', 229.68999999999997, 'yuv.min=', -23.410249999999984)
('yuv.max=', 247.52700000000002, 'yuv.min=', -19.660489999999999)
('yuv.max=', 237.857, 'yuv.min=', -22.395209999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.875019999999992)
('yuv.max=', 241.18899999999999, 'yuv.min=', -48.625249999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -32.185819999999993)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.34099999999998, 'yuv.min=', -32.550179999999997)
('yuv.max=', 245.24200000000002, 'yuv.min=', -46.432780000000001)
('yuv.max=', 205.89599999999999, 'yuv.min=', -95.268470000000008)
('yuv.max=', 218.68199999999999, 'yuv.min=', -43.254750000000001)
('yuv.max=', 181.83699999999999, 'yuv.min=', -85.845489999999984)
('yuv.max=', 159.00299999999999, 'yuv.min=', -41.624050000000004)
('yuv.max=', 251.24499999999995, 'yuv.min=', -50.061040000000013)
('yuv.max=', 192.488, 'yuv.min=', -61.535679999999985)
('yuv.max=', 210.71499999999997, 'yuv.min=', -60.42653)
('yuv.max=', 240.10499999999999, 'yuv.min=', -23.870049999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.548, 'yuv.min=', -30.890259999999991)
('yuv.max=', 251.45599999999996, 'yuv.min=', -26.41554)
('yuv.max=', 242.79299999999998, 'yuv.min=', -27.309409999999986)
('yuv.max=', 252.08799999999999, 'yuv.min=', -60.241879999999995)
('yuv.max=', 241.792, 'yuv.min=', -58.31004999999999)
('yuv.max=', 193.34300000000002, 'yuv.min=', -16.730319999999999)
('yuv.max=', 234.89599999999999, 'yuv.min=', -23.525199999999991)
('yuv.max=', 171.18899999999999, 'yuv.min=', -53.785520000000005)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.559, 'yuv.min=', -5.5200599999999831)
('yuv.max=', 246.011, 'yuv.min=', -39.315179999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', -16.215329999999991)
('yuv.max=', 232.76599999999996, 'yuv.min=', -20.665159999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.886, 'yuv.min=', -40.395779999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.7432600000000029)
('yuv.max=', 239.54599999999999, 'yuv.min=', -28.84629)
('yuv.max=', 245.60799999999998, 'yuv.min=', -15.174979999999993)
('yuv.max=', 243.74399999999997, 'yuv.min=', -57.339829999999992)
('yuv.max=', 231.71899999999999, 'yuv.min=', -37.48054999999998)
('yuv.max=', 182.97800000000001, 'yuv.min=', -20.090409999999995)
('yuv.max=', 255.0, 'yuv.min=', -20.517880000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -43.778509999999997)
('yuv.max=', 238.47899999999998, 'yuv.min=', -58.679100000000005)
('yuv.max=', 227.16300000000001, 'yuv.min=', -31.345489999999995)
('yuv.max=', 217.25199999999998, 'yuv.min=', -6.1072300000000013)
('yuv.max=', 228.31399999999996, 'yuv.min=', -7.4267700000000048)
('yuv.max=', 248.60399999999998, 'yuv.min=', -40.604939999999999)
('yuv.max=', 203.20599999999999, 'yuv.min=', -50.459879999999984)
('yuv.max=', 203.012, 'yuv.min=', -30.015479999999997)
('yuv.max=', 248.21499999999997, 'yuv.min=', -14.118510000000001)
('yuv.max=', 245.65099999999998, 'yuv.min=', -51.864640000000009)
('yuv.max=', 174.34800000000001, 'yuv.min=', -14.185249999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -72.695319999999995)
('yuv.max=', 211.47299999999998, 'yuv.min=', -39.464579999999998)
('yuv.max=', 249.06399999999996, 'yuv.min=', -28.800419999999999)
('yuv.max=', 180.41399999999999, 'yuv.min=', -12.495450000000002)
('yuv.max=', 247.803, 'yuv.min=', -20.473890000000004)
('yuv.max=', 180.59100000000001, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 255.0, 'yuv.min=', -3.6899999999999995)
('yuv.max=', 208.91300000000001, 'yuv.min=', -25.48058)
('yuv.max=', 248.81099999999998, 'yuv.min=', -15.916760000000011)
('yuv.max=', 255.0, 'yuv.min=', -22.908950000000004)
('yuv.max=', 230.81900000000002, 'yuv.min=', -52.480819999999987)
('yuv.max=', 221.64100000000002, 'yuv.min=', -10.11014999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -32.175449999999991)
('yuv.max=', 197.054, 'yuv.min=', -11.440159999999993)
('yuv.max=', 245.29900000000001, 'yuv.min=', -45.660629999999998)
('yuv.max=', 192.90300000000002, 'yuv.min=', -19.744390000000006)
('yuv.max=', 189.93299999999999, 'yuv.min=', -10.410179999999992)
('yuv.max=', 225.96799999999999, 'yuv.min=', -8.4502299999999959)
('yuv.max=', 202.09399999999999, 'yuv.min=', -46.580229999999986)
('yuv.max=', 249.929, 'yuv.min=', -36.610339999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.750199999999992)
('yuv.max=', 255.0, 'yuv.min=', -58.671019999999999)
('yuv.max=', 195.892, 'yuv.min=', -12.670159999999996)
('yuv.max=', 224.21299999999999, 'yuv.min=', -20.820359999999997)
('yuv.max=', 176.88999999999999, 'yuv.min=', -12.885119999999986)
('yuv.max=', 248.161, 'yuv.min=', -25.455500000000004)
('yuv.max=', 191.81900000000002, 'yuv.min=', -72.990780000000001)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999995)
('yuv.max=', 248.65799999999999, 'yuv.min=', -12.540269999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -30.985699999999998)
('yuv.max=', 231.53100000000001, 'yuv.min=', -31.120159999999998)
('yuv.max=', 241.416, 'yuv.min=', -45.920409999999976)
('yuv.max=', 168.86399999999998, 'yuv.min=', -10.755029999999994)
('yuv.max=', 209.41499999999999, 'yuv.min=', -21.595130000000001)
('yuv.max=', 248.46099999999998, 'yuv.min=', -104.73507999999998)
('yuv.max=', 228.61099999999999, 'yuv.min=', -12.080420000000004)
('yuv.max=', 183.54300000000001, 'yuv.min=', -55.096019999999996)
('yuv.max=', 242.98499999999999, 'yuv.min=', -16.015410000000003)
('yuv.max=', 250.43399999999997, 'yuv.min=', -23.925239999999992)
('yuv.max=', 233.286, 'yuv.min=', -31.360429999999997)
('yuv.max=', 232.58699999999999, 'yuv.min=', -25.755299999999988)
('yuv.max=', 242.78699999999998, 'yuv.min=', -32.375469999999993)
('yuv.max=', 180.06400000000002, 'yuv.min=', -39.01057999999999)
('yuv.max=', 221.553, 'yuv.min=', -49.410389999999985)
('yuv.max=', 240.70699999999999, 'yuv.min=', -17.505089999999996)
('yuv.max=', 173.48999999999998, 'yuv.min=', -83.403649999999999)
('yuv.max=', 225.376, 'yuv.min=', -25.862750000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.359959999999997)
('yuv.max=', 244.28799999999998, 'yuv.min=', -34.071539999999999)
('yuv.max=', 151.642, 'yuv.min=', -22.06529999999999)
('yuv.max=', 246.47800000000001, 'yuv.min=', -57.160550000000001)
('yuv.max=', 251.74000000000001, 'yuv.min=', -18.375780000000002)
('yuv.max=', 234.47199999999995, 'yuv.min=', -23.395309999999995)
('yuv.max=', 255.0, 'yuv.min=', -9.1100499999999851)
('yuv.max=', 217.22800000000001, 'yuv.min=', -15.300299999999996)
('yuv.max=', 249.71699999999998, 'yuv.min=', -28.355559999999997)
('yuv.max=', 249.47299999999998, 'yuv.min=', -47.609210000000004)
('yuv.max=', 229.33699999999999, 'yuv.min=', -30.9117)
('yuv.max=', 220.489, 'yuv.min=', -40.055499999999981)
('yuv.max=', 250.35899999999998, 'yuv.min=', -14.630109999999981)
('yuv.max=', 218.13199999999998, 'yuv.min=', -42.434999999999995)
('yuv.max=', 248.82699999999997, 'yuv.min=', -38.42513000000001)
('yuv.max=', 235.51500000000001, 'yuv.min=', -21.860709999999987)
('yuv.max=', 254.10300000000001, 'yuv.min=', -99.328770000000006)
('yuv.max=', 160.21600000000001, 'yuv.min=', -24.995469999999987)
('yuv.max=', 251.64299999999997, 'yuv.min=', -48.480419999999988)
('yuv.max=', 251.97800000000001, 'yuv.min=', -47.750469999999993)
('yuv.max=', 169.02099999999999, 'yuv.min=', -76.840549999999993)
('yuv.max=', 251.97800000000001, 'yuv.min=', -21.780209999999993)
('yuv.max=', 209.46899999999999, 'yuv.min=', -22.44642000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.640149999999995)
('yuv.max=', 187.33699999999999, 'yuv.min=', -14.445029999999997)
('yuv.max=', 252.31, 'yuv.min=', -19.095379999999995)
('yuv.max=', 243.815, 'yuv.min=', -18.839669999999991)
('yuv.max=', 238.19199999999998, 'yuv.min=', -20.124470000000002)
('yuv.max=', 234.39099999999999, 'yuv.min=', -29.379149999999996)
('yuv.max=', 253.13099999999997, 'yuv.min=', -20.235239999999994)
('yuv.max=', 246.13599999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 228.02599999999998, 'yuv.min=', -12.702179999999998)
('yuv.max=', 211.31400000000002, 'yuv.min=', -37.026150000000001)
('yuv.max=', 240.63, 'yuv.min=', -36.524110000000007)
('yuv.max=', 247.202, 'yuv.min=', -17.490149999999986)
('yuv.max=', 185.464, 'yuv.min=', -24.410350000000001)
('yuv.max=', 253.20599999999999, 'yuv.min=', -38.850630000000002)
('yuv.max=', 255.0, 'yuv.min=', -14.200189999999992)
('yuv.max=', 253.41299999999998, 'yuv.min=', -14.532429999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.730189999999993)
('yuv.max=', 167.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.95500000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 240.71099999999998, 'yuv.min=', -24.84027)
('yuv.max=', 199.80099999999999, 'yuv.min=', -11.971260000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.781269999999999)
('yuv.max=', 222.71799999999999, 'yuv.min=', -46.933819999999997)
('yuv.max=', 242.48399999999998, 'yuv.min=', -28.515329999999992)
('yuv.max=', 226.767, 'yuv.min=', -25.670229999999989)
('yuv.max=', 253.0, 'yuv.min=', -0.51498999999999739)
('yuv.max=', 231.505, 'yuv.min=', -13.385169999999988)
('yuv.max=', 194.90000000000001, 'yuv.min=', -27.084530000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.665959999999998)
('yuv.max=', 245.57699999999997, 'yuv.min=', -24.85521)
('yuv.max=', 247.90099999999998, 'yuv.min=', -49.505829999999989)
('yuv.max=', 255.0, 'yuv.min=', -27.329689999999999)
('yuv.max=', 184.214, 'yuv.min=', -38.850809999999996)
('yuv.max=', 244.886, 'yuv.min=', -41.870449999999991)
('yuv.max=', 253.31599999999997, 'yuv.min=', -52.724429999999998)
('yuv.max=', 214.46599999999998, 'yuv.min=', -36.941479999999999)
('yuv.max=', 227.57599999999996, 'yuv.min=', -50.865719999999996)
('yuv.max=', 243.44499999999999, 'yuv.min=', -15.400309999999998)
('yuv.max=', 253.185, 'yuv.min=', -114.04057999999999)
('yuv.max=', 233.67099999999999, 'yuv.min=', -39.310609999999997)
('yuv.max=', 167.60799999999998, 'yuv.min=', -24.24905)
('yuv.max=', 251.04299999999998, 'yuv.min=', -57.805429999999987)
('yuv.max=', 198.93699999999998, 'yuv.min=', -42.050350000000009)
('yuv.max=', 239.161, 'yuv.min=', -22.402939999999994)
('yuv.max=', 255.0, 'yuv.min=', -44.490389999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.999209999999987)
('yuv.max=', 249.61799999999999, 'yuv.min=', -59.214709999999997)
('yuv.max=', 233.02099999999999, 'yuv.min=', -25.570219999999988)
('yuv.max=', 255.0, 'yuv.min=', -21.492699999999985)
('yuv.max=', 216.02699999999999, 'yuv.min=', -32.830699999999993)
('yuv.max=', 192.96799999999999, 'yuv.min=', -31.115590000000001)
('yuv.max=', 239.16799999999998, 'yuv.min=', -33.205429999999993)
('yuv.max=', 174.03800000000001, 'yuv.min=', -20.220299999999995)
('yuv.max=', 240.41899999999998, 'yuv.min=', -46.505529999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -13.329920000000001)
('yuv.max=', 242.21699999999998, 'yuv.min=', -42.90634)
('yuv.max=', 245.91800000000001, 'yuv.min=', -9.7539700000000025)
('yuv.max=', 228.89599999999996, 'yuv.min=', -53.042619999999999)
('yuv.max=', 206.94, 'yuv.min=', -25.423379999999998)
('yuv.max=', 255.0, 'yuv.min=', -46.628329999999998)
('yuv.max=', 246.18399999999997, 'yuv.min=', -19.924839999999996)
('yuv.max=', 250.83599999999998, 'yuv.min=', -45.730759999999997)
('yuv.max=', 254.10300000000001, 'yuv.min=', -31.490319999999993)
('yuv.max=', 255.0, 'yuv.min=', -27.674999999999969)
('yuv.max=', 209.06399999999999, 'yuv.min=', -37.820830000000001)
('yuv.max=', 243.815, 'yuv.min=', -46.699090000000012)
('yuv.max=', 245.26099999999997, 'yuv.min=', -62.265629999999994)
('yuv.max=', 224.04999999999998, 'yuv.min=', -53.124190000000013)
('yuv.max=', 184.60599999999999, 'yuv.min=', -36.163159999999998)
('yuv.max=', 241.78399999999999, 'yuv.min=', -28.500439999999998)
('yuv.max=', 223.74399999999997, 'yuv.min=', -76.962090000000003)
('yuv.max=', 244.14599999999999, 'yuv.min=', -6.3649599999999964)
('yuv.max=', 255.0, 'yuv.min=', -102.61992999999998)
('yuv.max=', 255.0, 'yuv.min=', -34.090579999999989)
('yuv.max=', 252.03199999999998, 'yuv.min=', -98.665580000000006)
('yuv.max=', 251.77799999999999, 'yuv.min=', -22.08024)
('yuv.max=', 208.369, 'yuv.min=', -94.527410000000003)
('yuv.max=', 177.71499999999997, 'yuv.min=', -19.320209999999996)
('yuv.max=', 180.35900000000001, 'yuv.min=', -17.805119999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.185150000000005)
('yuv.max=', 173.85500000000002, 'yuv.min=', -28.570519999999998)
('yuv.max=', 234.84299999999999, 'yuv.min=', -13.485179999999993)
('yuv.max=', 246.76599999999999, 'yuv.min=', -31.37536999999999)
('yuv.max=', 249.09899999999996, 'yuv.min=', -12.532440000000008)
('yuv.max=', 173.77199999999999, 'yuv.min=', -57.412620000000004)
('yuv.max=', 225.28399999999999, 'yuv.min=', -7.1268200000000093)
('yuv.max=', 230.267, 'yuv.min=', -39.370370000000001)
('yuv.max=', 239.39099999999996, 'yuv.min=', -29.345289999999999)
('yuv.max=', 246.26999999999998, 'yuv.min=', -29.075139999999998)
('yuv.max=', 162.73399999999998, 'yuv.min=', -34.710149999999992)
('yuv.max=', 248.73999999999998, 'yuv.min=', -13.404650000000004)
('yuv.max=', 243.03, 'yuv.min=', -53.385440000000003)
('yuv.max=', 161.70400000000001, 'yuv.min=', -10.789200000000001)
('yuv.max=', 251.16800000000001, 'yuv.min=', -45.715820000000001)
('yuv.max=', 237.94200000000001, 'yuv.min=', -6.1126000000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 207.06299999999999, 'yuv.min=', -16.446790000000004)
('yuv.max=', 243.21699999999998, 'yuv.min=', -30.645419999999991)
('yuv.max=', 244.74399999999997, 'yuv.min=', -52.410689999999995)
('yuv.max=', 186.20099999999999, 'yuv.min=', -36.505759999999995)
('yuv.max=', 174.0, 'yuv.min=', -18.3064)
('yuv.max=', 247.65199999999999, 'yuv.min=', -25.150669999999991)
('yuv.max=', 247.64100000000002, 'yuv.min=', -37.89584)
('yuv.max=', 244.25899999999999, 'yuv.min=', -38.520899999999997)
('yuv.max=', 217.15600000000001, 'yuv.min=', -24.240970000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.205829999999992)
('yuv.max=', 194.57599999999996, 'yuv.min=', -46.546360000000007)
('yuv.max=', 255.0, 'yuv.min=', -5.234969999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.050259999999987)
('yuv.max=', 243.71199999999999, 'yuv.min=', -33.265190000000004)
('yuv.max=', 167.28700000000001, 'yuv.min=', -29.829280000000004)
('yuv.max=', 255.0, 'yuv.min=', -23.895359999999997)
('yuv.max=', 244.70100000000002, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 177.661, 'yuv.min=', -151.27506)
('yuv.max=', 233.22099999999998, 'yuv.min=', -27.226589999999998)
('yuv.max=', 171.64600000000002, 'yuv.min=', -29.200459999999996)
('yuv.max=', 234.14699999999999, 'yuv.min=', -85.202629999999985)
('yuv.max=', 237.44, 'yuv.min=', -24.310699999999997)
('yuv.max=', 216.54099999999997, 'yuv.min=', -11.03426)
('yuv.max=', 230.23499999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 206.07300000000001, 'yuv.min=', -11.525229999999979)
('yuv.max=', 242.29300000000001, 'yuv.min=', -1.8956599999999995)
('yuv.max=', 255.0, 'yuv.min=', -22.165309999999998)
('yuv.max=', 252.44099999999997, 'yuv.min=', -13.215029999999985)
('yuv.max=', 233.25199999999998, 'yuv.min=', -21.535369999999997)
('yuv.max=', 119.155, 'yuv.min=', -27.070369999999997)
('yuv.max=', 251.49000000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 242.35599999999999, 'yuv.min=', -38.048710000000007)
('yuv.max=', 179.804, 'yuv.min=', -25.659859999999998)
('yuv.max=', 176.45099999999996, 'yuv.min=', -30.529970000000006)
('yuv.max=', 209.27499999999998, 'yuv.min=', -24.417719999999999)
('yuv.max=', 203.45499999999998, 'yuv.min=', -37.525369999999995)
('yuv.max=', 230.80799999999999, 'yuv.min=', -9.7430100000000053)
('yuv.max=', 248.17399999999998, 'yuv.min=', -28.555350000000004)
('yuv.max=', 241.548, 'yuv.min=', -21.619720000000008)
('yuv.max=', 253.80399999999997, 'yuv.min=', -46.033569999999997)
('yuv.max=', 200.50899999999999, 'yuv.min=', -34.465309999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.911030000000011)
('yuv.max=', 253.74600000000001, 'yuv.min=', -10.02712)
('yuv.max=', 214.71700000000001, 'yuv.min=', -37.080510000000004)
('yuv.max=', 253.25599999999997, 'yuv.min=', -27.415219999999994)
('yuv.max=', 252.17400000000001, 'yuv.min=', -20.049810000000001)
('yuv.max=', 237.92899999999997, 'yuv.min=', -96.420540000000003)
('yuv.max=', 238.20600000000002, 'yuv.min=', -14.812500000000002)
('yuv.max=', 249.886, 'yuv.min=', -14.945079999999997)
('yuv.max=', 228.12699999999998, 'yuv.min=', -38.46570999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.445399999999992)
('yuv.max=', 240.47899999999998, 'yuv.min=', -39.470379999999992)
('yuv.max=', 217.98099999999999, 'yuv.min=', -49.970199999999984)
('yuv.max=', 240.071, 'yuv.min=', -43.83970999999999)
('yuv.max=', 248.74299999999999, 'yuv.min=', -24.65518999999998)
('yuv.max=', 248.37999999999997, 'yuv.min=', -55.645459999999986)
('yuv.max=', 190.399, 'yuv.min=', -36.320679999999996)
('yuv.max=', 253.77199999999999, 'yuv.min=', -6.7649999999999988)
('yuv.max=', 243.755, 'yuv.min=', -17.215429999999991)
('yuv.max=', 215.05799999999999, 'yuv.min=', -11.565479999999994)
('yuv.max=', 228.33100000000002, 'yuv.min=', -25.000039999999991)
('yuv.max=', 255.0, 'yuv.min=', -73.580469999999977)
('yuv.max=', 184.863, 'yuv.min=', -38.070239999999991)
('yuv.max=', 231.24699999999996, 'yuv.min=', -16.775139999999997)
('yuv.max=', 240.02399999999994, 'yuv.min=', -26.685269999999996)
('yuv.max=', 253.48399999999998, 'yuv.min=', -16.183980000000005)
('yuv.max=', 243.40600000000001, 'yuv.min=', -43.445469999999993)
('yuv.max=', 253.29900000000001, 'yuv.min=', -39.428689999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.975430000000003)
('yuv.max=', 222.63999999999999, 'yuv.min=', -38.070239999999984)
('yuv.max=', 227.374, 'yuv.min=', -46.950389999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.25515)
('yuv.max=', 151.245, 'yuv.min=', -24.810389999999998)
('yuv.max=', 255.0, 'yuv.min=', -93.559269999999998)
('yuv.max=', 238.565, 'yuv.min=', -72.365409999999997)
('yuv.max=', 234.96100000000001, 'yuv.min=', -26.627310000000005)
('yuv.max=', 253.989, 'yuv.min=', -33.295070000000003)
('yuv.max=', 254.06, 'yuv.min=', -32.507170000000002)
('yuv.max=', 165.87699999999998, 'yuv.min=', -33.400190000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.170079999999984)
('yuv.max=', 245.28100000000001, 'yuv.min=', -69.030630000000002)
('yuv.max=', 215.19299999999998, 'yuv.min=', -25.679099999999991)
('yuv.max=', 186.82999999999998, 'yuv.min=', -23.295299999999983)
('yuv.max=', 250.0, 'yuv.min=', -13.595790000000001)
('yuv.max=', 242.13999999999999, 'yuv.min=', -13.785209999999985)
('yuv.max=', 254.08800000000002, 'yuv.min=', -27.630179999999996)
('yuv.max=', 255.0, 'yuv.min=', -2.4682600000000008)
('yuv.max=', 245.798, 'yuv.min=', -35.989580000000004)
('yuv.max=', 255.0, 'yuv.min=', -9.9549499999999895)
('yuv.max=', 235.80999999999997, 'yuv.min=', -71.420500000000004)
('yuv.max=', 254.08800000000002, 'yuv.min=', -32.861330000000009)
('yuv.max=', 197.89099999999996, 'yuv.min=', -23.65052)
('yuv.max=', 207.42999999999998, 'yuv.min=', -45.150210000000001)
('yuv.max=', 197.19299999999998, 'yuv.min=', -71.729109999999991)
('yuv.max=', 231.51300000000001, 'yuv.min=', -23.535569999999996)
('yuv.max=', 253.185, 'yuv.min=', -24.140199999999986)
('yuv.max=', 248.05999999999997, 'yuv.min=', -81.330629999999985)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.530169999999998)
('yuv.max=', 252.22799999999998, 'yuv.min=', -43.619349999999997)
('yuv.max=', 230.02499999999998, 'yuv.min=', -29.489310000000003)
('yuv.max=', 227.09700000000001, 'yuv.min=', -19.390339999999998)
('yuv.max=', 218.62, 'yuv.min=', -69.070879999999988)
('yuv.max=', 241.60199999999998, 'yuv.min=', -27.068540000000009)
('yuv.max=', 215.017, 'yuv.min=', -14.199609999999996)
('yuv.max=', 247.917, 'yuv.min=', -31.209720000000001)
('yuv.max=', 198.20099999999999, 'yuv.min=', -11.510289999999996)
('yuv.max=', 217.273, 'yuv.min=', -58.665269999999985)
('yuv.max=', 225.09, 'yuv.min=', -13.705169999999995)
('yuv.max=', 246.92499999999995, 'yuv.min=', -17.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.74006)
('yuv.max=', 229.38200000000001, 'yuv.min=', -93.520249999999976)
('yuv.max=', 217.45600000000002, 'yuv.min=', -29.945349999999998)
('yuv.max=', 108.22799999999999, 'yuv.min=', -0.20002000000000209)
('yuv.max=', 252.99099999999999, 'yuv.min=', -50.138730000000002)
('yuv.max=', 253.53300000000002, 'yuv.min=', -34.933040000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -68.351200000000006)
('yuv.max=', 210.92399999999998, 'yuv.min=', -50.829510000000013)
('yuv.max=', 255.0, 'yuv.min=', -88.297919999999991)
('yuv.max=', 252.08199999999999, 'yuv.min=', -34.800990000000006)
('yuv.max=', 229.62700000000001, 'yuv.min=', -40.760140000000007)
('yuv.max=', 249.04199999999997, 'yuv.min=', -27.530169999999998)
('yuv.max=', 235.37699999999998, 'yuv.min=', -39.395679999999999)
('yuv.max=', 241.82500000000002, 'yuv.min=', -19.688890000000008)
('yuv.max=', 253.376, 'yuv.min=', -67.152360000000016)
('yuv.max=', 255.0, 'yuv.min=', -49.463680000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -52.584370000000007)
('yuv.max=', 250.77100000000002, 'yuv.min=', -99.635799999999989)
('yuv.max=', 246.0, 'yuv.min=', -22.25494999999999)
('yuv.max=', 252.28800000000001, 'yuv.min=', -47.465379999999996)
('yuv.max=', 164.886, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -7.9988000000000028)
('yuv.max=', 249.15299999999999, 'yuv.min=', -3.9335100000000054)
('yuv.max=', 234.72299999999998, 'yuv.min=', -51.625550000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999989)
('yuv.max=', 223.81799999999998, 'yuv.min=', -25.726330000000004)
('yuv.max=', 241.25299999999996, 'yuv.min=', -34.175650000000005)
('yuv.max=', 181.67099999999999, 'yuv.min=', -7.2501100000000065)
('yuv.max=', 243.12899999999999, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.23899999999998, 'yuv.min=', -31.260419999999993)
('yuv.max=', 224.39099999999999, 'yuv.min=', -38.710549999999998)
('yuv.max=', 214.053, 'yuv.min=', -33.250249999999994)
('yuv.max=', 249.16899999999995, 'yuv.min=', -38.473530000000004)
('yuv.max=', 229.25799999999998, 'yuv.min=', -45.820980000000006)
('yuv.max=', 251.09199999999998, 'yuv.min=', -57.68965)
('yuv.max=', 228.12599999999998, 'yuv.min=', -30.893830000000005)
('yuv.max=', 204.56599999999997, 'yuv.min=', -22.795249999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 165.292, 'yuv.min=', -17.775239999999997)
('yuv.max=', 232.67399999999998, 'yuv.min=', -68.860489999999984)
('yuv.max=', 229.34799999999996, 'yuv.min=', -28.330249999999996)
('yuv.max=', 252.09200000000001, 'yuv.min=', -46.780249999999995)
('yuv.max=', 255.0, 'yuv.min=', -45.980169999999987)
('yuv.max=', 246.77699999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 224.148, 'yuv.min=', -11.955149999999996)
('yuv.max=', 237.57399999999998, 'yuv.min=', -25.135729999999995)
('yuv.max=', 192.06399999999999, 'yuv.min=', -40.315280000000001)
('yuv.max=', 254.07099999999997, 'yuv.min=', -26.755399999999987)
('yuv.max=', 216.387, 'yuv.min=', -27.860079999999993)
('yuv.max=', 252.04499999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 198.91499999999996, 'yuv.min=', -34.627499999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -66.460250000000002)
('yuv.max=', 255.0, 'yuv.min=', -11.335579999999993)
('yuv.max=', 241.34199999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 199.077, 'yuv.min=', -61.369249999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.068370000000009)
('yuv.max=', 170.994, 'yuv.min=', -33.020349999999993)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 234.036, 'yuv.min=', -29.119959999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.401590000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -63.859989999999996)
('yuv.max=', 236.14799999999997, 'yuv.min=', -29.630379999999995)
('yuv.max=', 203.52199999999999, 'yuv.min=', -31.415619999999997)
('yuv.max=', 188.959, 'yuv.min=', -23.76493)
('yuv.max=', 216.82599999999999, 'yuv.min=', -51.844860000000004)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.21699999999998, 'yuv.min=', -37.585129999999999)
('yuv.max=', 170.69800000000001, 'yuv.min=', -18.32011)
('yuv.max=', 183.34199999999998, 'yuv.min=', -29.000439999999998)
('yuv.max=', 207.16300000000001, 'yuv.min=', -14.478659999999998)
('yuv.max=', 236.316, 'yuv.min=', -9.4100799999999971)
('yuv.max=', 207.61899999999997, 'yuv.min=', -33.320379999999993)
('yuv.max=', 239.19399999999999, 'yuv.min=', -21.380169999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.757109999999997)
('yuv.max=', 245.81299999999999, 'yuv.min=', -22.828569999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.685039999999972)
('yuv.max=', 231.923, 'yuv.min=', -29.13032999999999)
('yuv.max=', 251.184, 'yuv.min=', -37.970229999999987)
('yuv.max=', 252.73500000000001, 'yuv.min=', -90.966039999999978)
('yuv.max=', 220.91799999999998, 'yuv.min=', -19.867100000000001)
('yuv.max=', 242.821, 'yuv.min=', -32.535520000000005)
('yuv.max=', 246.10699999999997, 'yuv.min=', -37.070139999999995)
('yuv.max=', 231.46299999999997, 'yuv.min=', -47.840109999999996)
('yuv.max=', 206.09299999999999, 'yuv.min=', -38.529660000000007)
('yuv.max=', 222.99999999999997, 'yuv.min=', -18.12008999999999)
('yuv.max=', 255.0, 'yuv.min=', -18.200749999999999)
('yuv.max=', 228.91800000000001, 'yuv.min=', -17.615469999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.707009999999997)
('yuv.max=', 205.32900000000001, 'yuv.min=', -73.580469999999991)
('yuv.max=', 232.69300000000001, 'yuv.min=', -40.610739999999986)
('yuv.max=', 162.441, 'yuv.min=', -35.85051)
('yuv.max=', 255.0, 'yuv.min=', -27.940579999999994)
('yuv.max=', 217.53300000000002, 'yuv.min=', -39.610639999999997)
('yuv.max=', 222.624, 'yuv.min=', -76.855489999999989)
('yuv.max=', 255.0, 'yuv.min=', -19.629650000000002)
('yuv.max=', 242.75500000000002, 'yuv.min=', -19.490349999999992)
('yuv.max=', 253.52699999999999, 'yuv.min=', -14.270319999999991)
('yuv.max=', 254.77200000000002, 'yuv.min=', -15.875049999999996)
('yuv.max=', 238.12900000000002, 'yuv.min=', -44.570889999999991)
('yuv.max=', 255.0, 'yuv.min=', -39.125529999999998)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -21.090510000000002)
('yuv.max=', 222.19200000000001, 'yuv.min=', -29.945349999999991)
('yuv.max=', 242.0, 'yuv.min=', -45.965229999999991)
('yuv.max=', 245.05199999999996, 'yuv.min=', -39.94054999999998)
('yuv.max=', 253.15899999999996, 'yuv.min=', -17.497840000000004)
('yuv.max=', 255.0, 'yuv.min=', -6.0603599999999851)
('yuv.max=', 222.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.185, 'yuv.min=', -15.24510999999999)
('yuv.max=', 229.80199999999999, 'yuv.min=', -36.594410000000011)
('yuv.max=', 224.06799999999998, 'yuv.min=', -30.869519999999994)
('yuv.max=', 204.40099999999998, 'yuv.min=', -19.260449999999999)
('yuv.max=', 224.16199999999998, 'yuv.min=', -45.624949999999991)
('yuv.max=', 240.64099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 230.77199999999999, 'yuv.min=', -2.2450399999999995)
('yuv.max=', 123.81199999999998, 'yuv.min=', -3.6750599999999989)
('yuv.max=', 236.566, 'yuv.min=', -17.620039999999999)
('yuv.max=', 213.80399999999997, 'yuv.min=', -36.810359999999989)
('yuv.max=', 180.21899999999999, 'yuv.min=', -42.125829999999993)
('yuv.max=', 243.33099999999999, 'yuv.min=', -47.550449999999984)
('yuv.max=', 224.10999999999999, 'yuv.min=', -21.421880000000002)
('yuv.max=', 250.56599999999997, 'yuv.min=', -13.507780000000004)
('yuv.max=', 250.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 188.75299999999999, 'yuv.min=', -41.160179999999983)
('yuv.max=', 209.21900000000002, 'yuv.min=', -89.268520000000009)
('yuv.max=', 239.93999999999997, 'yuv.min=', -0.72408999999999679)
('yuv.max=', 153.11499999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 224.102, 'yuv.min=', -30.600599999999996)
('yuv.max=', 241.17699999999996, 'yuv.min=', -33.248109999999997)
('yuv.max=', 226.12599999999998, 'yuv.min=', -24.021619999999999)
('yuv.max=', 247.86400000000003, 'yuv.min=', -55.900669999999998)
('yuv.max=', 232.47999999999996, 'yuv.min=', -63.355369999999994)
('yuv.max=', 208.285, 'yuv.min=', -42.945419999999991)
('yuv.max=', 251.37799999999999, 'yuv.min=', -29.258660000000006)
('yuv.max=', 223.54400000000001, 'yuv.min=', -5.0773899999999941)
('yuv.max=', 255.0, 'yuv.min=', -36.900739999999999)
('yuv.max=', 249.65099999999995, 'yuv.min=', -27.193539999999999)
('yuv.max=', 196.08699999999999, 'yuv.min=', -43.600669999999994)
('yuv.max=', 196.12299999999999, 'yuv.min=', -10.605629999999991)
('yuv.max=', 210.00199999999998, 'yuv.min=', -40.369239999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.888730000000002)
('yuv.max=', 197.90800000000002, 'yuv.min=', -67.369979999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.915199999999992)
('yuv.max=', 243.58699999999999, 'yuv.min=', -21.247330000000005)
('yuv.max=', 248.77199999999999, 'yuv.min=', -19.620239999999995)
('yuv.max=', 201.578, 'yuv.min=', -63.28273999999999)
('yuv.max=', 205.43599999999998, 'yuv.min=', -32.330649999999999)
('yuv.max=', 238.93099999999998, 'yuv.min=', -9.0175199999999904)
('yuv.max=', 202.21099999999998, 'yuv.min=', -22.33212)
('yuv.max=', 255.0, 'yuv.min=', -20.36056)
('yuv.max=', 234.32299999999998, 'yuv.min=', -32.880089999999988)
('yuv.max=', 238.89000000000001, 'yuv.min=', -18.860410000000002)
('yuv.max=', 254.06, 'yuv.min=', -86.250630000000001)
('yuv.max=', 250.47299999999998, 'yuv.min=', -56.427109999999999)
('yuv.max=', 244.28799999999998, 'yuv.min=', -9.1652399999999936)
('yuv.max=', 250.619, 'yuv.min=', -41.270559999999996)
('yuv.max=', 201.96100000000001, 'yuv.min=', -18.335049999999999)
('yuv.max=', 233.45599999999999, 'yuv.min=', -6.4350900000000095)
('yuv.max=', 255.0, 'yuv.min=', -18.352900000000002)
('yuv.max=', 193.87599999999998, 'yuv.min=', -12.946920000000002)
('yuv.max=', 200.98399999999998, 'yuv.min=', -24.525299999999984)
('yuv.max=', 226.08699999999999, 'yuv.min=', -37.416770000000007)
('yuv.max=', 248.10299999999998, 'yuv.min=', -37.701039999999992)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.887650000000001)
('yuv.max=', 246.77199999999999, 'yuv.min=', -22.338999999999995)
('yuv.max=', 235.26599999999999, 'yuv.min=', -49.56559)
('yuv.max=', 255.0, 'yuv.min=', -28.910130000000002)
('yuv.max=', 237.65100000000001, 'yuv.min=', -32.990469999999995)
('yuv.max=', 208.72800000000001, 'yuv.min=', -20.435259999999992)
('yuv.max=', 249.245, 'yuv.min=', -33.651740000000004)
('yuv.max=', 222.14599999999999, 'yuv.min=', -20.780109999999997)
('yuv.max=', 227.363, 'yuv.min=', -72.329419999999999)
('yuv.max=', 180.17099999999999, 'yuv.min=', -15.35549)
('yuv.max=', 248.798, 'yuv.min=', -32.820329999999991)
('yuv.max=', 199.47399999999999, 'yuv.min=', -50.39555)
('yuv.max=', 199.87900000000002, 'yuv.min=', -13.389159999999997)
('yuv.max=', 254.47300000000001, 'yuv.min=', -49.495459999999994)
('yuv.max=', 250.017, 'yuv.min=', -13.630009999999999)
('yuv.max=', 215.33099999999999, 'yuv.min=', -15.945179999999997)
('yuv.max=', 255.0, 'yuv.min=', -22.119530000000012)
('yuv.max=', 255.0, 'yuv.min=', -30.136980000000001)
('yuv.max=', 210.374, 'yuv.min=', -32.441200000000002)
('yuv.max=', 204.80399999999997, 'yuv.min=', -22.965389999999982)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.316, 'yuv.min=', -17.738499999999995)
('yuv.max=', 228.56699999999998, 'yuv.min=', -18.975359999999984)
('yuv.max=', 245.24800000000002, 'yuv.min=', -55.11553)
('yuv.max=', 248.809, 'yuv.min=', -43.65585999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.700309999999995)
('yuv.max=', 210.56799999999998, 'yuv.min=', -30.94544999999999)
('yuv.max=', 199.73499999999999, 'yuv.min=', -15.70613)
('yuv.max=', 211.81900000000002, 'yuv.min=', -20.905429999999988)
('yuv.max=', 195.12900000000002, 'yuv.min=', -38.23124)
('yuv.max=', 224.73499999999999, 'yuv.min=', -32.735259999999997)
('yuv.max=', 250.66399999999999, 'yuv.min=', -92.730539999999991)
('yuv.max=', 254.47300000000001, 'yuv.min=', -27.788030000000003)
('yuv.max=', 247.51599999999999, 'yuv.min=', -30.475280000000001)
('yuv.max=', 174.78899999999999, 'yuv.min=', -9.3100699999999978)
('yuv.max=', 255.0, 'yuv.min=', -42.164810000000003)
('yuv.max=', 183.82599999999999, 'yuv.min=', -14.500219999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.420189999999991)
('yuv.max=', 238.99999999999997, 'yuv.min=', -11.922590000000001)
('yuv.max=', 241.91899999999998, 'yuv.min=', -33.620409999999993)
('yuv.max=', 255.0, 'yuv.min=', -54.160190000000007)
('yuv.max=', 198.84999999999999, 'yuv.min=', -39.895729999999993)
('yuv.max=', 255.0, 'yuv.min=', -28.249749999999981)
('yuv.max=', 255.0, 'yuv.min=', -64.723169999999996)
('yuv.max=', 247.68000000000001, 'yuv.min=', -40.745199999999983)
('yuv.max=', 241.405, 'yuv.min=', -58.715889999999987)
('yuv.max=', 254.886, 'yuv.min=', -37.935400000000001)
('yuv.max=', 248.047, 'yuv.min=', -81.332899999999995)
('yuv.max=', 197.41399999999999, 'yuv.min=', -63.225480000000005)
('yuv.max=', 228.41299999999998, 'yuv.min=', -32.960589999999996)
('yuv.max=', 255.0, 'yuv.min=', -24.210329999999992)
('yuv.max=', 255.0, 'yuv.min=', -14.500219999999992)
('yuv.max=', 249.61799999999999, 'yuv.min=', -33.91006999999999)
('yuv.max=', 131.035, 'yuv.min=', -29.815460000000002)
('yuv.max=', 221.49899999999997, 'yuv.min=', -39.94006000000001)
('yuv.max=', 175.83199999999999, 'yuv.min=', -15.279870000000003)
('yuv.max=', 252.51599999999999, 'yuv.min=', -40.070439999999998)
('yuv.max=', 240.73399999999998, 'yuv.min=', -24.162760000000006)
('yuv.max=', 206.517, 'yuv.min=', -30.630479999999991)
('yuv.max=', 244.75199999999998, 'yuv.min=', -39.308130000000006)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.82599999999996, 'yuv.min=', -72.474559999999983)
('yuv.max=', 253.20599999999999, 'yuv.min=', -30.224890000000002)
('yuv.max=', 255.0, 'yuv.min=', -18.315770000000001)
('yuv.max=', 204.21899999999999, 'yuv.min=', -31.260420000000003)
('yuv.max=', 252.886, 'yuv.min=', -15.015209999999989)
('yuv.max=', 253.82599999999996, 'yuv.min=', -50.595569999999995)
('yuv.max=', 217.97899999999998, 'yuv.min=', -33.220369999999988)
('yuv.max=', 237.64400000000001, 'yuv.min=', -54.600539999999995)
('yuv.max=', 238.73299999999998, 'yuv.min=', -18.190219999999997)
('yuv.max=', 236.68999999999997, 'yuv.min=', -25.329799999999999)
('yuv.max=', 254.18499999999997, 'yuv.min=', -19.03603)
('yuv.max=', 246.78700000000001, 'yuv.min=', -29.470609999999997)
('yuv.max=', 254.06, 'yuv.min=', -78.310819999999993)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 245.76499999999999, 'yuv.min=', -32.290399999999984)
('yuv.max=', 232.64499999999998, 'yuv.min=', -33.990600000000001)
('yuv.max=', 249.15700000000001, 'yuv.min=', -33.790549999999996)
('yuv.max=', 246.02799999999996, 'yuv.min=', -35.544679999999993)
('yuv.max=', 251.70099999999996, 'yuv.min=', -26.91575000000001)
('yuv.max=', 255.0, 'yuv.min=', -4.9200000000000017)
('yuv.max=', 247.68999999999997, 'yuv.min=', -34.090579999999996)
('yuv.max=', 232.67199999999997, 'yuv.min=', -45.385909999999988)
('yuv.max=', 224.61000000000001, 'yuv.min=', -31.560450000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.61899999999997, 'yuv.min=', -22.495219999999996)
('yuv.max=', 234.91, 'yuv.min=', -20.165109999999991)
('yuv.max=', 255.0, 'yuv.min=', -16.690069999999992)
('yuv.max=', 242.85299999999998, 'yuv.min=', -11.329499999999996)
('yuv.max=', 239.929, 'yuv.min=', -13.844969999999988)
('yuv.max=', 217.01499999999999, 'yuv.min=', -30.320079999999994)
('yuv.max=', 205.12100000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 222.61499999999998, 'yuv.min=', -21.750329999999991)
('yuv.max=', 241.55199999999996, 'yuv.min=', -51.031010000000002)
('yuv.max=', 202.63399999999999, 'yuv.min=', -11.255079999999989)
('yuv.max=', 249.21599999999998, 'yuv.min=', -60.23809)
('yuv.max=', 227.11799999999999, 'yuv.min=', -48.333080000000017)
('yuv.max=', 252.22799999999998, 'yuv.min=', -18.85643)
('yuv.max=', 236.01599999999999, 'yuv.min=', -35.720619999999997)
('yuv.max=', 158.18000000000001, 'yuv.min=', -14.885320000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 184.494, 'yuv.min=', -13.814609999999995)
('yuv.max=', 224.90799999999999, 'yuv.min=', -13.540370000000003)
('yuv.max=', 194.99999999999997, 'yuv.min=', -12.155170000000002)
('yuv.max=', 227.52699999999999, 'yuv.min=', -43.532090000000004)
('yuv.max=', 252.01899999999995, 'yuv.min=', -53.070509999999985)
('yuv.max=', 162.054, 'yuv.min=', -21.930839999999986)
('yuv.max=', 255.0, 'yuv.min=', -90.540689999999984)
('yuv.max=', 254.70099999999999, 'yuv.min=', -17.875250000000001)
('yuv.max=', 245.298, 'yuv.min=', -68.70071999999999)
('yuv.max=', 232.35899999999998, 'yuv.min=', -83.986760000000004)
('yuv.max=', 195.59899999999999, 'yuv.min=', -51.962910000000001)
('yuv.max=', 180.13599999999997, 'yuv.min=', -23.42518999999999)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.740059999999993)
('yuv.max=', 249.62099999999998, 'yuv.min=', -31.630579999999998)
('yuv.max=', 234.59800000000001, 'yuv.min=', -42.486090000000004)
('yuv.max=', 255.0, 'yuv.min=', -28.478060000000006)
('yuv.max=', 236.22199999999998, 'yuv.min=', -30.355759999999997)
('yuv.max=', 230.024, 'yuv.min=', -19.635530000000003)
('yuv.max=', 255.0, 'yuv.min=', -63.691079999999992)
('yuv.max=', 221.22799999999998, 'yuv.min=', -19.020179999999996)
('yuv.max=', 222.19099999999997, 'yuv.min=', -90.490069999999989)
('yuv.max=', 221.58799999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 238.815, 'yuv.min=', -29.030319999999993)
('yuv.max=', 244.40199999999999, 'yuv.min=', -29.07513999999999)
('yuv.max=', 235.90399999999997, 'yuv.min=', -42.815529999999995)
('yuv.max=', 238.21100000000001, 'yuv.min=', -28.148730000000008)
('yuv.max=', 255.0, 'yuv.min=', -48.180859999999996)
('yuv.max=', 237.20299999999997, 'yuv.min=', -62.088510000000007)
('yuv.max=', 227.79900000000001, 'yuv.min=', -44.802329999999998)
('yuv.max=', 160.554, 'yuv.min=', -23.825229999999998)
('yuv.max=', 195.98399999999998, 'yuv.min=', -19.178000000000004)
('yuv.max=', 247.02799999999999, 'yuv.min=', -35.1355)
('yuv.max=', 236.327, 'yuv.min=', -38.262810000000002)
('yuv.max=', 233.97200000000001, 'yuv.min=', -17.305070000000004)
('yuv.max=', 243.62599999999998, 'yuv.min=', -59.87576)
('yuv.max=', 202.66799999999998, 'yuv.min=', -15.732389999999995)
('yuv.max=', 220.28800000000001, 'yuv.min=', -25.840369999999986)
('yuv.max=', 246.40199999999999, 'yuv.min=', -34.505559999999996)
('yuv.max=', 228.58699999999999, 'yuv.min=', -44.582839999999997)
('yuv.max=', 255.0, 'yuv.min=', -40.731529999999992)
('yuv.max=', 242.67299999999997, 'yuv.min=', -20.945679999999996)
('yuv.max=', 239.71399999999997, 'yuv.min=', -28.285429999999991)
('yuv.max=', 204.26399999999998, 'yuv.min=', -57.235249999999994)
('yuv.max=', 239.24099999999996, 'yuv.min=', -21.252860000000005)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -20.47551)
('yuv.max=', 229.76400000000001, 'yuv.min=', -32.385839999999995)
('yuv.max=', 255.0, 'yuv.min=', -36.850609999999996)
('yuv.max=', 217.33699999999999, 'yuv.min=', -21.568870000000004)
('yuv.max=', 214.49199999999996, 'yuv.min=', -29.500489999999996)
('yuv.max=', 234.62300000000002, 'yuv.min=', -54.481019999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -21.389190000000006)
('yuv.max=', 228.185, 'yuv.min=', -16.36015999999999)
('yuv.max=', 225.26000000000002, 'yuv.min=', -33.890559999999994)
('yuv.max=', 255.0, 'yuv.min=', -38.976789999999994)
('yuv.max=', 191.38900000000001, 'yuv.min=', -17.89018999999999)
('yuv.max=', 254.316, 'yuv.min=', -15.885419999999996)
('yuv.max=', 247.75500000000002, 'yuv.min=', -46.835439999999991)
('yuv.max=', 171.44899999999998, 'yuv.min=', -38.070239999999998)
('yuv.max=', 189.35499999999999, 'yuv.min=', -21.19508999999999)
('yuv.max=', 215.892, 'yuv.min=', -45.865220000000001)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.74199999999999, 'yuv.min=', -38.050730000000001)
('yuv.max=', 217.64600000000002, 'yuv.min=', -19.605300000000003)
('yuv.max=', 248.99999999999997, 'yuv.min=', -7.1501000000000001)
('yuv.max=', 205.12900000000002, 'yuv.min=', -15.800349999999991)
('yuv.max=', 240.07499999999999, 'yuv.min=', -45.215769999999992)
('yuv.max=', 213.44799999999998, 'yuv.min=', -19.80341)
('yuv.max=', 238.45799999999997, 'yuv.min=', -35.920639999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.850239999999996)
('yuv.max=', 186.886, 'yuv.min=', -14.696860000000001)
('yuv.max=', 210.339, 'yuv.min=', -24.525299999999994)
('yuv.max=', 176.46799999999999, 'yuv.min=', -46.960759999999986)
('yuv.max=', 251.804, 'yuv.min=', -34.131769999999996)
('yuv.max=', 209.84499999999997, 'yuv.min=', -14.800249999999998)
('yuv.max=', 241.75399999999999, 'yuv.min=', -30.575289999999981)
('yuv.max=', 254.131, 'yuv.min=', -81.621639999999999)
('yuv.max=', 255.0, 'yuv.min=', -10.955049999999989)
('yuv.max=', 250.55500000000001, 'yuv.min=', -69.575499999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.389639999999988)
('yuv.max=', 248.00999999999999, 'yuv.min=', -16.345219999999998)
('yuv.max=', 250.64699999999996, 'yuv.min=', -32.675499999999992)
('yuv.max=', 248.733, 'yuv.min=', -24.940279999999994)
('yuv.max=', 237.0, 'yuv.min=', -13.470239999999993)
('yuv.max=', 168.07299999999998, 'yuv.min=', -56.31277)
('yuv.max=', 255.0, 'yuv.min=', -67.930520000000001)
('yuv.max=', 255.0, 'yuv.min=', -66.445309999999978)
('yuv.max=', 239.495, 'yuv.min=', -44.425799999999995)
('yuv.max=', 206.15999999999997, 'yuv.min=', -23.259139999999995)
('yuv.max=', 228.32399999999998, 'yuv.min=', -30.490219999999983)
('yuv.max=', 208.72299999999998, 'yuv.min=', -46.805559999999993)
('yuv.max=', 205.31900000000002, 'yuv.min=', -26.025449999999985)
('yuv.max=', 255.0, 'yuv.min=', -27.749699999999983)
('yuv.max=', 255.0, 'yuv.min=', -33.17554999999998)
('yuv.max=', 235.98899999999998, 'yuv.min=', -18.690269999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.988070000000008)
('yuv.max=', 250.43399999999997, 'yuv.min=', -33.960689999999992)
('yuv.max=', 227.81899999999999, 'yuv.min=', -18.905229999999992)
('yuv.max=', 255.0, 'yuv.min=', -19.094879999999989)
('yuv.max=', 183.06999999999999, 'yuv.min=', -35.125129999999999)
('yuv.max=', 198.893, 'yuv.min=', -30.830500000000001)
('yuv.max=', 227.02799999999999, 'yuv.min=', -22.796750000000003)
('yuv.max=', 215.38800000000001, 'yuv.min=', -21.780209999999997)
('yuv.max=', 250.02800000000002, 'yuv.min=', -14.0703)
('yuv.max=', 159.87900000000002, 'yuv.min=', -16.949849999999994)
('yuv.max=', 244.499, 'yuv.min=', -8.3651599999999959)
('yuv.max=', 248.34200000000001, 'yuv.min=', -30.000539999999987)
('yuv.max=', 237.131, 'yuv.min=', -31.145469999999996)
('yuv.max=', 239.03199999999998, 'yuv.min=', -64.585369999999983)
('yuv.max=', 219.893, 'yuv.min=', -52.750970000000002)
('yuv.max=', 251.60400000000001, 'yuv.min=', -27.70030999999998)
('yuv.max=', 166.42499999999998, 'yuv.min=', -31.209389999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.650459999999995)
('yuv.max=', 252.54399999999998, 'yuv.min=', -29.00043999999999)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -29.245279999999998)
('yuv.max=', 214.166, 'yuv.min=', -48.595369999999988)
('yuv.max=', 254.886, 'yuv.min=', -18.364109999999997)
('yuv.max=', 236.40200000000002, 'yuv.min=', -8.4801100000000034)
('yuv.max=', 236.36699999999996, 'yuv.min=', -23.290729999999996)
('yuv.max=', 245.54399999999998, 'yuv.min=', -60.605709999999988)
('yuv.max=', 193.34899999999999, 'yuv.min=', -39.429099999999998)
('yuv.max=', 236.191, 'yuv.min=', -28.638370000000005)
('yuv.max=', 233.98500000000001, 'yuv.min=', -24.225269999999995)
('yuv.max=', 204.11499999999998, 'yuv.min=', -16.960219999999996)
('yuv.max=', 252.65199999999999, 'yuv.min=', -1.1150499999999992)
('yuv.max=', 245.29300000000001, 'yuv.min=', -11.644089999999998)
('yuv.max=', 204.786, 'yuv.min=', -65.359139999999996)
('yuv.max=', 207.94299999999998, 'yuv.min=', -22.165309999999998)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999985)
('yuv.max=', 230.17499999999998, 'yuv.min=', -38.159880000000001)
('yuv.max=', 150.44200000000001, 'yuv.min=', -21.845769999999995)
('yuv.max=', 255.0, 'yuv.min=', -11.41028)
('yuv.max=', 228.14599999999999, 'yuv.min=', -28.215299999999996)
('yuv.max=', 239.30499999999995, 'yuv.min=', -36.310309999999987)
('yuv.max=', 248.93599999999998, 'yuv.min=', -37.680569999999989)
('yuv.max=', 255.0, 'yuv.min=', -18.191449999999996)
('yuv.max=', 196.74099999999999, 'yuv.min=', -22.21876)
('yuv.max=', 239.79300000000001, 'yuv.min=', -24.395409999999998)
('yuv.max=', 170.26199999999997, 'yuv.min=', -15.660089999999984)
('yuv.max=', 248.48399999999998, 'yuv.min=', -53.032440000000008)
('yuv.max=', 251.12399999999997, 'yuv.min=', -27.418160000000004)
('yuv.max=', 242.62300000000002, 'yuv.min=', -26.840469999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.632580000000001)
('yuv.max=', 229.08700000000002, 'yuv.min=', -57.220309999999991)
('yuv.max=', 215.161, 'yuv.min=', -21.296720000000004)
('yuv.max=', 252.91399999999999, 'yuv.min=', -27.515280000000008)
('yuv.max=', 207.803, 'yuv.min=', -30.460339999999992)
('yuv.max=', 253.16300000000001, 'yuv.min=', -79.645399999999995)
('yuv.max=', 102.501, 'yuv.min=', -55.625949999999989)
('yuv.max=', 242.56400000000002, 'yuv.min=', -38.305939999999993)
('yuv.max=', 195.38899999999998, 'yuv.min=', -43.570789999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.3264499999999977)
('yuv.max=', 190.25200000000001, 'yuv.min=', -38.520899999999997)
('yuv.max=', 255.0, 'yuv.min=', -37.710449999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.98299999999998, 'yuv.min=', -10.12509)
('yuv.max=', 166.12100000000001, 'yuv.min=', -35.984520000000003)
('yuv.max=', 209.81299999999999, 'yuv.min=', -30.200559999999996)
('yuv.max=', 249.03200000000001, 'yuv.min=', -86.195439999999991)
('yuv.max=', 254.10300000000001, 'yuv.min=', -9.0951099999999929)
('yuv.max=', 218.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 196.91199999999998, 'yuv.min=', -46.769480000000001)
('yuv.max=', 250.28999999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 245.59999999999999, 'yuv.min=', -21.772079999999999)
('yuv.max=', 241.33700000000002, 'yuv.min=', -13.922060000000002)
('yuv.max=', 200.65100000000001, 'yuv.min=', -52.161279999999991)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.58700000000002, 'yuv.min=', -6.0350499999999965)
('yuv.max=', 247.89599999999999, 'yuv.min=', -22.696790000000007)
('yuv.max=', 202.28200000000001, 'yuv.min=', -48.985970000000009)
('yuv.max=', 238.50800000000001, 'yuv.min=', -56.726059999999997)
('yuv.max=', 237.79300000000001, 'yuv.min=', -30.230440000000002)
('yuv.max=', 190.26300000000001, 'yuv.min=', -31.405249999999995)
('yuv.max=', 225.101, 'yuv.min=', -24.462960000000002)
('yuv.max=', 223.25599999999997, 'yuv.min=', -55.450009999999992)
('yuv.max=', 234.08499999999998, 'yuv.min=', -30.275259999999992)
('yuv.max=', 230.928, 'yuv.min=', -82.360610000000008)
('yuv.max=', 236.39299999999997, 'yuv.min=', -19.634180000000001)
('yuv.max=', 239.45599999999996, 'yuv.min=', -29.794030000000003)
('yuv.max=', 246.858, 'yuv.min=', -7.1063700000000019)
('yuv.max=', 246.02799999999996, 'yuv.min=', -83.158919999999995)
('yuv.max=', 251.42299999999997, 'yuv.min=', -39.540509999999998)
('yuv.max=', 254.08800000000002, 'yuv.min=', -21.8354)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -63.212269999999997)
('yuv.max=', 252.40799999999999, 'yuv.min=', -53.270529999999994)
('yuv.max=', 248.59399999999999, 'yuv.min=', -48.210269999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.61023999999999)
('yuv.max=', 250.23399999999998, 'yuv.min=', -36.510329999999989)
('yuv.max=', 218.554, 'yuv.min=', -43.569760000000002)
('yuv.max=', 249.815, 'yuv.min=', -62.180559999999993)
('yuv.max=', 246.91199999999998, 'yuv.min=', -46.725059999999992)
('yuv.max=', 244.84899999999999, 'yuv.min=', -14.159939999999985)
('yuv.max=', 241.35299999999998, 'yuv.min=', -59.665369999999996)
('yuv.max=', 234.35099999999997, 'yuv.min=', -44.535209999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.365529999999993)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
 'for batch', 11)
('GAN loss 0.6100 ', 'GAN acc 0.7031', 'Discriminator loss 0.4596', 'Discriminator accuracy 0.5898', 'Total loss: 1.0696', 'for batch', 12)
('GAN loss 0.6329 ', 'GAN acc 0.6523', 'Discriminator loss 0.4478', 'Discriminator accuracy 0.6309', 'Total loss: 1.0807', 'for batch', 13)
('GAN loss 0.6712 ', 'GAN acc 0.6016', 'Discriminator loss 0.4820', 'Discriminator accuracy 0.6348', 'Total loss: 1.1531', 'for batch', 14)
('GAN loss 0.6823 ', 'GAN acc 0.5352', 'Discriminator loss 0.4694', 'Discriminator accuracy 0.6348', 'Total loss: 1.1518', 'for batch', 15)
('GAN loss 0.6408 ', 'GAN acc 0.6250', 'Discriminator loss 0.4728', 'Discriminator accuracy 0.6504', 'Total loss: 1.1137', 'for batch', 16)
('GAN loss 0.6339 ', 'GAN acc 0.6680', 'Discriminator loss 0.5090', 'Discriminator accuracy 0.6367', 'Total loss: 1.1429', 'for batch', 17)
('GAN loss 0.5973 ', 'GAN acc 0.7617', 'Discriminator loss 0.4861', 'Discriminator accuracy 0.6348', 'Total loss: 1.0835', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98232728)
('DISCRIMINATOR_Imagem FAKE=', 0.49914065)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.151038')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6499 ', 'GAN acc 0.5898', 'Discriminator loss 0.4374', 'Discriminator accuracy 0.6523', 'Total loss: 1.0873', 'for batch', 0)
('GAN loss 0.5742 ', 'GAN acc 0.7734', 'Discriminator loss 0.4889', 'Discriminator accuracy 0.6406', 'Total loss: 1.0631', 'for batch', 1)
('GAN loss 0.5790 ', 'GAN acc 0.7344', 'Discriminator loss 0.4663', 'Discriminator accuracy 0.6387', 'Total loss: 1.0453', 'for batch', 2)
('GAN loss 0.5777 ', 'GAN acc 0.7656', 'Discriminator loss 0.4903', 'Discriminator accuracy 0.5977', 'Total loss: 1.0679', 'for batch', 3)
('GAN loss 0.5644 ', 'GAN acc 0.8008', 'Discriminator loss 0.4568', 'Discriminator accuracy 0.5938', 'Total loss: 1.0212', 'for batch', 4)
('GAN loss 0.6198 ', 'GAN acc 0.6406', 'Discriminator loss 0.4539', 'Discriminator accuracy 0.6387', 'Total loss: 1.0737', 'for batch', 5)
('GAN loss 0.6744 ', 'GAN acc 0.6055', 'Discriminator loss 0.4297', 'Discriminator accuracy 0.6562', 'Total loss: 1.1040', 'for batch', 6)
('GAN loss 0.7035 ', 'GAN acc 0.5156', 'Discriminator loss 0.4335', 'Discriminator accuracy 0.6699', 'Total loss: 1.1369', 'for batch', 7)
('GAN loss 0.6636 ', 'GAN acc 0.5586', 'Discriminator loss 0.4726', 'Discriminator accuracy 0.6953', 'Total loss: 1.1362', 'for batch', 8)
('GAN loss 0.6857 ', 'GAN acc 0.5391', 'Discriminator loss 0.4689', 'Discriminator accuracy 0.6836', 'Total loss: 1.1546', 'for batch', 9)
('GAN loss 0.6574 ', 'GAN acc 0.6094', 'Discriminator loss 0.3973', 'Discriminator accuracy 0.7031', 'Total loss: 1.0547', 'for batch', 10)
('GAN loss 0.6596 ', 'GAN acc 0.6367', 'Discriminator loss 0.4335', 'Discriminator accuracy 0.6641', 'Total loss: 1.0931', 'for batch', 11)
('GAN loss 0.6898 ', 'GAN acc 0.5547', 'Discriminator loss 0.4394', 'Discriminator accuracy 0.6660', 'Total loss: 1.1292', 'for batch', 12)
('GAN loss 0.6937 ', 'GAN acc 0.5195', 'Discriminator loss 0.4599', 'Discriminator accuracy 0.7031', 'Total loss: 1.1536', 'for batch', 13)
('GAN loss 0.7075 ', 'GAN acc 0.5078', 'Discriminator loss 0.4116', 'Discriminator accuracy 0.7031', 'Total loss: 1.1190', 'for batch', 14)
('GAN loss 0.7655 ', 'GAN acc 0.4219', 'Discriminator loss 0.4305', 'Discriminator accuracy 0.7539', 'Total loss: 1.1960', 'for batch', 15)
('GAN loss 0.8209 ', 'GAN acc 0.3125', 'Discriminator loss 0.3769', 'Discriminator accuracy 0.7754', 'Total loss: 1.1979', 'for batch', 16)
('GAN loss 0.8429 ', 'GAN acc 0.2422', 'Discriminator loss 0.4284', 'Discriminator accuracy 0.8223', 'Total loss: 1.2714', 'for batch', 17)
('GAN loss 0.8065 ', 'GAN acc 0.2812', 'Discriminator loss 0.4811', 'Discriminator accuracy 0.8203', 'Total loss: 1.2876', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96824259)
('DISCRIMINATOR_Imagem FAKE=', 0.42330244)
('Discriminator trained', 6, 'times of', 19, 'b('yuv.max=', 253.886, 'yuv.min=', -5.8200899999999978)
('yuv.max=', 230.196, 'yuv.min=', -28.355559999999997)
('yuv.max=', 253.185, 'yuv.min=', -47.816670000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.325330000000001)
('yuv.max=', 249.08799999999999, 'yuv.min=', -22.014679999999998)
('yuv.max=', 241.357, 'yuv.min=', -47.03631)
('yuv.max=', 253.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 227.59099999999998, 'yuv.min=', -18.474360000000001)
('yuv.max=', 255.0, 'yuv.min=', -31.690339999999988)
('yuv.max=', 212.16399999999999, 'yuv.min=', -33.985430000000001)
('yuv.max=', 161.36699999999999, 'yuv.min=', -15.330179999999991)
('yuv.max=', 251.58699999999996, 'yuv.min=', -34.763840000000002)
('yuv.max=', 233.28899999999999, 'yuv.min=', -48.380409999999983)
('yuv.max=', 243.10299999999998, 'yuv.min=', -15.721879999999999)
('yuv.max=', 252.608, 'yuv.min=', -45.075509999999994)
('yuv.max=', 212.26299999999998, 'yuv.min=', -49.265559999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -16.71994999999999)
('yuv.max=', 199.32599999999999, 'yuv.min=', -19.750250000000001)
('yuv.max=', 244.84299999999999, 'yuv.min=', -15.285960000000006)
('yuv.max=', 255.0, 'yuv.min=', -93.135149999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -40.404840000000007)
('yuv.max=', 228.33500000000001, 'yuv.min=', -13.485179999999998)
('yuv.max=', 247.29400000000001, 'yuv.min=', -79.179959999999994)
('yuv.max=', 231.06899999999996, 'yuv.min=', -54.994779999999992)
('yuv.max=', 242.43000000000001, 'yuv.min=', -28.48544999999999)
('yuv.max=', 250.59300000000002, 'yuv.min=', -34.00177)
('yuv.max=', 200.86199999999999, 'yuv.min=', -10.840099999999996)
('yuv.max=', 242.55199999999999, 'yuv.min=', -46.635419999999982)
('yuv.max=', 194.815, 'yuv.min=', -30.37527)
('yuv.max=', 195.589, 'yuv.min=', -23.416449999999998)
('yuv.max=', 255.0, 'yuv.min=', -29.775210000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.122379999999993)
('yuv.max=', 194.81800000000001, 'yuv.min=', -19.041510000000002)
('yuv.max=', 237.815, 'yuv.min=', -27.73019)
('yuv.max=', 221.83199999999997, 'yuv.min=', -17.705110000000005)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.14499999999998, 'yuv.min=', -24.610369999999989)
('yuv.max=', 230.994, 'yuv.min=', -18.795409999999997)
('yuv.max=', 216.31999999999999, 'yuv.min=', -32.015679999999996)
('yuv.max=', 255.0, 'yuv.min=', -39.065769999999986)
('yuv.max=', 248.72199999999998, 'yuv.min=', -40.510729999999995)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 222.39699999999999, 'yuv.min=', -32.909680000000009)
('yuv.max=', 252.93999999999997, 'yuv.min=', -30.04993)
('yuv.max=', 234.70499999999998, 'yuv.min=', -51.225509999999986)
('yuv.max=', 236.36799999999999, 'yuv.min=', -27.300269999999998)
('yuv.max=', 210.03699999999998, 'yuv.min=', -83.491100000000017)
('yuv.max=', 246.01599999999999, 'yuv.min=', -9.0190699999999957)
('yuv.max=', 252.71799999999996, 'yuv.min=', -54.515470000000001)
('yuv.max=', 205.90399999999997, 'yuv.min=', -21.465239999999994)
('yuv.max=', 227.33799999999999, 'yuv.min=', -12.65522)
('yuv.max=', 255.0, 'yuv.min=', -0.61499999999999488)
('yuv.max=', 246.90299999999996, 'yuv.min=', -40.130199999999988)
('yuv.max=', 253.14199999999997, 'yuv.min=', -19.535169999999997)
('yuv.max=', 195.929, 'yuv.min=', -9.4100799999999918)
('yuv.max=', 166.94199999999998, 'yuv.min=', -11.710309999999996)
('yuv.max=', 241.78300000000002, 'yuv.min=', -12.655219999999993)
('yuv.max=', 211.70699999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 243.94799999999998, 'yuv.min=', -64.230149999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.92000000000002, 'yuv.min=', -32.375469999999993)
('yuv.max=', 254.886, 'yuv.min=', -17.056809999999999)
('yuv.max=', 136.84700000000001, 'yuv.min=', -17.771080000000008)
('yuv.max=', 232.85599999999997, 'yuv.min=', -23.673919999999999)
('yuv.max=', 242.07100000000003, 'yuv.min=', -95.805539999999979)
('yuv.max=', 255.0, 'yuv.min=', -20.575519999999997)
('yuv.max=', 171.85799999999998, 'yuv.min=', -9.2754099999999973)
('yuv.max=', 188.80599999999998, 'yuv.min=', -43.162559999999999)
('yuv.max=', 217.006, 'yuv.min=', -40.715319999999984)
('yuv.max=', 251.40199999999999, 'yuv.min=', -27.61524)
('yuv.max=', 193.46199999999999, 'yuv.min=', -17.6051)
('yuv.max=', 244.57599999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -75.965769999999992)
('yuv.max=', 247.62899999999999, 'yuv.min=', -20.806990000000003)
('yuv.max=', 238.40899999999999, 'yuv.min=', -15.47500999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.18199999999996, 'yuv.min=', -49.310379999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.294829999999997)
('yuv.max=', 240.28699999999998, 'yuv.min=', -56.120199999999997)
('yuv.max=', 249.61799999999999, 'yuv.min=', -56.315649999999991)
('yuv.max=', 244.39500000000001, 'yuv.min=', -54.300509999999989)
('yuv.max=', 220.31999999999999, 'yuv.min=', -16.530300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 216.50300000000001, 'yuv.min=', -109.62062999999999)
('yuv.max=', 238.71700000000001, 'yuv.min=', -25.695899999999998)
('yuv.max=', 193.77200000000002, 'yuv.min=', -11.787260000000007)
('yuv.max=', 216.60199999999998, 'yuv.min=', -24.942880000000002)
('yuv.max=', 240.87299999999999, 'yuv.min=', -83.801829999999995)
('yuv.max=', 249.929, 'yuv.min=', -15.615269999999988)
('yuv.max=', 254.58699999999999, 'yuv.min=', -40.278750000000009)
('yuv.max=', 252.54399999999998, 'yuv.min=', -30.205670000000001)
('yuv.max=', 240.81299999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 235.24099999999999, 'yuv.min=', -41.771799999999999)
('yuv.max=', 205.71600000000001, 'yuv.min=', -31.624779999999998)
('yuv.max=', 222.88399999999999, 'yuv.min=', -11.365459999999988)
('yuv.max=', 200.66199999999998, 'yuv.min=', -57.030659999999997)
('yuv.max=', 246.84099999999998, 'yuv.min=', -87.730039999999988)
('yuv.max=', 228.22799999999998, 'yuv.min=', -24.89546)
('yuv.max=', 255.0, 'yuv.min=', -33.11578999999999)
('yuv.max=', 225.44800000000001, 'yuv.min=', -21.524999999999991)
('yuv.max=', 234.70600000000002, 'yuv.min=', -53.330289999999991)
('yuv.max=', 253.95699999999997, 'yuv.min=', -13.115019999999991)
('yuv.max=', 185.78299999999999, 'yuv.min=', -17.121750000000002)
('yuv.max=', 168.45600000000002, 'yuv.min=', -17.230369999999986)
('yuv.max=', 245.53899999999999, 'yuv.min=', -81.045539999999988)
('yuv.max=', 219.37899999999999, 'yuv.min=', -29.655689999999989)
('yuv.max=', 254.18499999999997, 'yuv.min=', -41.571359999999999)
('yuv.max=', 193.53100000000001, 'yuv.min=', -13.000070000000003)
('yuv.max=', 218.79399999999998, 'yuv.min=', -22.93834)
('yuv.max=', 250.99999999999997, 'yuv.min=', -41.760239999999996)
('yuv.max=', 236.721, 'yuv.min=', -44.519120000000001)
('yuv.max=', 252.37800000000001, 'yuv.min=', -31.630049999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.687730000000002)
('yuv.max=', 187.93699999999998, 'yuv.min=', -21.290529999999997)
('yuv.max=', 252.91799999999998, 'yuv.min=', -18.505189999999995)
('yuv.max=', 190.06299999999999, 'yuv.min=', -29.515429999999995)
('yuv.max=', 236.29300000000001, 'yuv.min=', -56.415659999999988)
('yuv.max=', 247.67500000000001, 'yuv.min=', -33.859050000000003)
('yuv.max=', 253.59799999999998, 'yuv.min=', -30.320079999999997)
('yuv.max=', 249.392, 'yuv.min=', -29.635759999999998)
('yuv.max=', 220.94899999999998, 'yuv.min=', -48.07580999999999)
('yuv.max=', 255.0, 'yuv.min=', -54.791900000000012)
('yuv.max=', 251.29900000000001, 'yuv.min=', -12.78511)
('yuv.max=', 247.626, 'yuv.min=', -38.311530000000005)
('yuv.max=', 238.327, 'yuv.min=', -26.926470000000002)
('yuv.max=', 198.15899999999999, 'yuv.min=', -86.01415999999999)
('yuv.max=', 172.339, 'yuv.min=', -38.38064)
('yuv.max=', 246.249, 'yuv.min=', -24.095379999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.970929999999996)
('yuv.max=', 223.73999999999998, 'yuv.min=', -15.60033)
('yuv.max=', 255.0, 'yuv.min=', -30.845439999999993)
('yuv.max=', 244.98899999999998, 'yuv.min=', -29.025509999999997)
('yuv.max=', 233.03999999999999, 'yuv.min=', -40.430229999999995)
('yuv.max=', 253.505, 'yuv.min=', -23.999939999999995)
('yuv.max=', 251.05999999999997, 'yuv.min=', -34.790649999999999)
('yuv.max=', 235.32999999999998, 'yuv.min=', -33.613659999999996)
('yuv.max=', 230.77399999999997, 'yuv.min=', -31.685769999999994)
('yuv.max=', 255.0, 'yuv.min=', -49.225309999999986)
('yuv.max=', 186.59100000000001, 'yuv.min=', -11.95515)
('yuv.max=', 255.0, 'yuv.min=', -32.975530000000006)
('yuv.max=', 255.0, 'yuv.min=', -8.7354099999999981)
('yuv.max=', 236.34799999999996, 'yuv.min=', -27.260019999999994)
('yuv.max=', 221.56800000000001, 'yuv.min=', -66.755709999999993)
('yuv.max=', 201.524, 'yuv.min=', -92.000589999999988)
('yuv.max=', 237.55799999999999, 'yuv.min=', -27.660060000000001)
('yuv.max=', 241.92899999999997, 'yuv.min=', -21.830789999999993)
('yuv.max=', 248.73199999999997, 'yuv.min=', -22.850439999999992)
('yuv.max=', 216.495, 'yuv.min=', -21.590879999999999)
('yuv.max=', 243.929, 'yuv.min=', -41.345259999999996)
('yuv.max=', 231.41299999999998, 'yuv.min=', -20.02028)
('yuv.max=', 251.49000000000001, 'yuv.min=', -51.895699999999991)
('yuv.max=', 235.786, 'yuv.min=', -43.930409999999995)
('yuv.max=', 249.142, 'yuv.min=', -5.7350199999999933)
('yuv.max=', 252.75, 'yuv.min=', -35.314209999999996)
('yuv.max=', 205.631, 'yuv.min=', -27.885389999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -50.980669999999989)
('yuv.max=', 207.06, 'yuv.min=', -17.675230000000003)
('yuv.max=', 247.54400000000001, 'yuv.min=', -13.00006999999999)
('yuv.max=', 213.96499999999997, 'yuv.min=', -27.885389999999983)
('yuv.max=', 252.25599999999997, 'yuv.min=', -54.705119999999994)
('yuv.max=', 247.64100000000002, 'yuv.min=', -22.654989999999998)
('yuv.max=', 232.017, 'yuv.min=', -30.915189999999996)
('yuv.max=', 206.852, 'yuv.min=', -5.9051599999999951)
('yuv.max=', 239.99499999999998, 'yuv.min=', -27.685369999999995)
('yuv.max=', 251.262, 'yuv.min=', -33.220370000000003)
('yuv.max=', 243.95999999999998, 'yuv.min=', -43.900700000000001)
('yuv.max=', 251.46699999999998, 'yuv.min=', -21.250279999999993)
('yuv.max=', 229.94999999999999, 'yuv.min=', -27.125559999999989)
('yuv.max=', 255.0, 'yuv.min=', -30.549979999999994)
('yuv.max=', 208.161, 'yuv.min=', -46.360699999999994)
('yuv.max=', 214.96099999999998, 'yuv.min=', -22.48027999999999)
('yuv.max=', 242.78699999999998, 'yuv.min=', -89.240559999999988)
('yuv.max=', 241.49599999999998, 'yuv.min=', -26.819729999999996)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 229.07499999999996, 'yuv.min=', -73.565529999999995)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.35899999999998, 'yuv.min=', -23.711399999999998)
('yuv.max=', 243.929, 'yuv.min=', -16.015309999999999)
('yuv.max=', 226.26099999999997, 'yuv.min=', -47.950489999999995)
('yuv.max=', 213.697, 'yuv.min=', -36.265489999999993)
('yuv.max=', 242.34200000000001, 'yuv.min=', -27.985399999999991)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.53399999999999, 'yuv.min=', -12.974440000000001)
('yuv.max=', 230.82599999999999, 'yuv.min=', -17.503300000000003)
('yuv.max=', 163.93299999999999, 'yuv.min=', -15.433319999999998)
('yuv.max=', 249.452, 'yuv.min=', -19.798190000000005)
('yuv.max=', 227.69300000000001, 'yuv.min=', -22.880319999999987)
('yuv.max=', 243.72899999999998, 'yuv.min=', -25.813940000000002)
('yuv.max=', 232.98199999999997, 'yuv.min=', -61.265529999999984)
('yuv.max=', 211.0, 'yuv.min=', -13.68319000000001)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.90099999999998, 'yuv.min=', -46.758250000000004)
('yuv.max=', 251.74000000000001, 'yuv.min=', -21.274340000000016)
('yuv.max=', 219.90599999999998, 'yuv.min=', -6.0051699999999926)
('yuv.max=', 214.20400000000001, 'yuv.min=', -74.14922)
('yuv.max=', 204.238, 'yuv.min=', -97.017910000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.04199999999997, 'yuv.min=', -25.510459999999998)
('yuv.max=', 232.691, 'yuv.min=', -17.513830000000013)
('yuv.max=', 254.77200000000002, 'yuv.min=', -34.720519999999993)
('yuv.max=', 236.94599999999997, 'yuv.min=', -18.001010000000001)
('yuv.max=', 214.36699999999999, 'yuv.min=', -44.205299999999994)
('yuv.max=', 213.34999999999999, 'yuv.min=', -46.68665)
('yuv.max=', 218.67799999999997, 'yuv.min=', -57.254730000000009)
('yuv.max=', 221.79999999999998, 'yuv.min=', -43.375339999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.19499999999999, 'yuv.min=', -81.090360000000004)
('yuv.max=', 185.71600000000001, 'yuv.min=', -15.445129999999992)
('yuv.max=', 239.36799999999997, 'yuv.min=', -40.260090000000005)
('yuv.max=', 205.83199999999999, 'yuv.min=', -85.158419999999992)
('yuv.max=', 230.804, 'yuv.min=', -30.130429999999993)
('yuv.max=', 191.19999999999999, 'yuv.min=', -11.955149999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 241.74800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 250.30399999999997, 'yuv.min=', -21.650319999999997)
('yuv.max=', 243.25599999999997, 'yuv.min=', -17.30506999999999)
('yuv.max=', 222.208, 'yuv.min=', -36.255119999999991)
('yuv.max=', 229.31399999999999, 'yuv.min=', -33.390509999999992)
('yuv.max=', 208.88, 'yuv.min=', -29.200459999999993)
('yuv.max=', 246.72300000000001, 'yuv.min=', -27.355460000000001)
('yuv.max=', 215.77199999999999, 'yuv.min=', -39.968760000000003)
('yuv.max=', 241.61500000000001, 'yuv.min=', -21.735389999999995)
('yuv.max=', 240.39099999999999, 'yuv.min=', -23.106750000000002)
('yuv.max=', 240.11599999999996, 'yuv.min=', -73.032489999999996)
('yuv.max=', 245.02000000000001, 'yuv.min=', -44.360499999999995)
('yuv.max=', 211.58699999999999, 'yuv.min=', -31.445499999999996)
('yuv.max=', 249.66300000000001, 'yuv.min=', -52.033700000000003)
('yuv.max=', 245.21499999999997, 'yuv.min=', -28.141140000000007)
('yuv.max=', 155.37199999999999, 'yuv.min=', -31.6007)
('yuv.max=', 225.86199999999999, 'yuv.min=', -35.777110000000008)
('yuv.max=', 254.11399999999998, 'yuv.min=', -9.7354199999999906)
('yuv.max=', 252.29899999999998, 'yuv.min=', -25.955319999999993)
('yuv.max=', 231.48799999999997, 'yuv.min=', -50.431820000000016)
('yuv.max=', 255.0, 'yuv.min=', -16.253850000000003)
('yuv.max=', 245.46600000000001, 'yuv.min=', -21.110019999999977)
('yuv.max=', 255.0, 'yuv.min=', -13.270219999999998)
('yuv.max=', 240.71199999999999, 'yuv.min=', -91.915520000000001)
('yuv.max=', 244.13800000000001, 'yuv.min=', -26.270289999999989)
('yuv.max=', 229.10900000000001, 'yuv.min=', -24.163150000000002)
('yuv.max=', 248.21100000000001, 'yuv.min=', -29.4453)
('yuv.max=', 224.11299999999997, 'yuv.min=', -42.96035999999998)
('yuv.max=', 249.31899999999999, 'yuv.min=', -34.410119999999992)
('yuv.max=', 198.71199999999999, 'yuv.min=', -86.134150000000005)
('yuv.max=', 255.0, 'yuv.min=', -27.285329999999995)
('yuv.max=', 228.58199999999999, 'yuv.min=', -35.425159999999984)
('yuv.max=', 249.07099999999997, 'yuv.min=', -7.5352000000000032)
('yuv.max=', 241.47300000000001, 'yuv.min=', -49.178520000000006)
('yuv.max=', 237.70099999999999, 'yuv.min=', -20.201050000000002)
('yuv.max=', 234.78300000000002, 'yuv.min=', -13.070199999999993)
('yuv.max=', 207.93799999999999, 'yuv.min=', -27.900329999999993)
('yuv.max=', 242.05399999999997, 'yuv.min=', -16.420120000000001)
('yuv.max=', 231.316, 'yuv.min=', -25.740359999999995)
('yuv.max=', 228.94499999999999, 'yuv.min=', -31.466140000000003)
('yuv.max=', 218.30600000000001, 'yuv.min=', -59.044569999999993)
('yuv.max=', 250.71200000000002, 'yuv.min=', -48.980469999999997)
('yuv.max=', 252.72899999999998, 'yuv.min=', -15.875049999999984)
('yuv.max=', 234.11799999999999, 'yuv.min=', -24.995469999999997)
('yuv.max=', 255.0, 'yuv.min=', -67.038419999999988)
('yuv.max=', 215.34, 'yuv.min=', -7.0202099999999916)
('yuv.max=', 216.19299999999998, 'yuv.min=', -22.635479999999987)
('yuv.max=', 229.25999999999999, 'yuv.min=', -43.975399999999993)
('yuv.max=', 231.10999999999999, 'yuv.min=', -75.135900000000007)
('yuv.max=', 241.73000000000002, 'yuv.min=', -61.21235999999999)
('yuv.max=', 177.54499999999999, 'yuv.min=', -49.910440000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.830649999999999)
('yuv.max=', 247.41200000000001, 'yuv.min=', -49.625349999999997)
('yuv.max=', 235.07999999999998, 'yuv.min=', -67.069460000000007)
('yuv.max=', 209.595, 'yuv.min=', -38.680669999999992)
('yuv.max=', 242.82900000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 190.07799999999997, 'yuv.min=', -37.680569999999982)
('yuv.max=', 251.29799999999997, 'yuv.min=', -55.292219999999993)
('yuv.max=', 190.98599999999999, 'yuv.min=', -17.128830000000001)
('yuv.max=', 254.77200000000002, 'yuv.min=', -32.075439999999993)
('yuv.max=', 238.114, 'yuv.min=', -20.921589999999998)
('yuv.max=', 252.79299999999998, 'yuv.min=', -45.160579999999996)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.1481000000000137)
('yuv.max=', 246.364, 'yuv.min=', -33.895129999999995)
('yuv.max=', 204.33199999999999, 'yuv.min=', -27.785380000000004)
('yuv.max=', 234.24200000000002, 'yuv.min=', -46.935449999999989)
('yuv.max=', 255.0, 'yuv.min=', -45.930779999999999)
('yuv.max=', 216.28700000000001, 'yuv.min=', -35.120559999999998)
('yuv.max=', 205.84299999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 210.77199999999999, 'yuv.min=', -16.887889999999999)
('yuv.max=', 225.91499999999999, 'yuv.min=', -6.7173900000000089)
('yuv.max=', 205.63799999999998, 'yuv.min=', -20.173439999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.065989999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -98.295419999999993)
('yuv.max=', 247.52499999999998, 'yuv.min=', -44.505330000000001)
('yuv.max=', 253.23899999999998, 'yuv.min=', -19.366670000000003)
('yuv.max=', 244.239, 'yuv.min=', -24.810389999999998)
('yuv.max=', 250.35500000000002, 'yuv.min=', -30.413669999999996)
('yuv.max=', 249.744, 'yuv.min=', -28.530269999999991)
('yuv.max=', 204.33499999999998, 'yuv.min=', -23.754700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.51361)
('yuv.max=', 232.78900000000002, 'yuv.min=', -8.3249099999999991)
('yuv.max=', 211.61899999999997, 'yuv.min=', -20.035219999999995)
('yuv.max=', 198.12399999999997, 'yuv.min=', -39.495689999999996)
('yuv.max=', 229.45199999999997, 'yuv.min=', -25.810489999999994)
('yuv.max=', 174.15200000000002, 'yuv.min=', -3.4302199999999949)
('yuv.max=', 247.16799999999998, 'yuv.min=', -42.330419999999989)
('yuv.max=', 255.0, 'yuv.min=', -36.233760000000004)
('yuv.max=', 237.62199999999999, 'yuv.min=', -37.670199999999994)
('yuv.max=', 154.90199999999999, 'yuv.min=', -35.850509999999986)
('yuv.max=', 250.19499999999999, 'yuv.min=', -18.545439999999992)
('yuv.max=', 235.25299999999999, 'yuv.min=', -68.145479999999992)
('yuv.max=', 228.35300000000001, 'yuv.min=', -19.319379999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.130259999999996)
('yuv.max=', 251.95699999999997, 'yuv.min=', -51.495659999999987)
('yuv.max=', 237.78899999999999, 'yuv.min=', -14.534009999999995)
('yuv.max=', 254.41299999999995, 'yuv.min=', -96.669579999999996)
('yuv.max=', 245.43699999999998, 'yuv.min=', -19.6053)
('yuv.max=', 222.07900000000001, 'yuv.min=', -29.470609999999994)
('yuv.max=', 251.011, 'yuv.min=', -23.780409999999989)
('yuv.max=', 240.92899999999997, 'yuv.min=', -55.364620000000002)
('yuv.max=', 179.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.55199999999999, 'yuv.min=', -25.610469999999982)
('yuv.max=', 235.93300000000002, 'yuv.min=', -17.520029999999998)
('yuv.max=', 246.99299999999997, 'yuv.min=', -18.47531)
('yuv.max=', 229.87499999999997, 'yuv.min=', -12.370129999999989)
('yuv.max=', 234.80099999999999, 'yuv.min=', -37.122739999999993)
('yuv.max=', 236.488, 'yuv.min=', -24.10446)
('yuv.max=', 228.69399999999999, 'yuv.min=', -47.030889999999999)
('yuv.max=', 238.56799999999998, 'yuv.min=', -13.070199999999993)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.015109999999996)
('yuv.max=', 240.98099999999999, 'yuv.min=', -22.250610000000002)
('yuv.max=', 249.33699999999999, 'yuv.min=', -67.659299999999988)
('yuv.max=', 216.786, 'yuv.min=', -52.400319999999994)
('yuv.max=', 226.26400000000001, 'yuv.min=', -16.543990000000004)
('yuv.max=', 243.77699999999999, 'yuv.min=', -23.495319999999992)
('yuv.max=', 162.036, 'yuv.min=', -22.565349999999995)
('yuv.max=', 229.49099999999999, 'yuv.min=', -36.240179999999995)
('yuv.max=', 229.113, 'yuv.min=', -26.455369999999995)
('yuv.max=', 243.39099999999999, 'yuv.min=', -57.960629999999988)
('yuv.max=', 237.60899999999998, 'yuv.min=', -47.495259999999995)
('yuv.max=', 253.16300000000001, 'yuv.min=', -17.50386)
('yuv.max=', 249.77199999999999, 'yuv.min=', -10.999870000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -42.78564999999999)
('yuv.max=', 246.69399999999996, 'yuv.min=', -66.34529999999998)
('yuv.max=', 241.869, 'yuv.min=', -10.05461)
('yuv.max=', 250.94000000000003, 'yuv.min=', -28.986360000000005)
('yuv.max=', 242.64699999999999, 'yuv.min=', -29.875219999999992)
('yuv.max=', 247.97, 'yuv.min=', -15.815289999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.94799999999998, 'yuv.min=', -26.455369999999998)
('yuv.max=', 241.84300000000002, 'yuv.min=', -31.067529999999998)
('yuv.max=', 208.00700000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 255.0, 'yuv.min=', -30.098469999999999)
('yuv.max=', 250.114, 'yuv.min=', -31.070769999999996)
('yuv.max=', 239.02699999999999, 'yuv.min=', -23.61027)
('yuv.max=', 255.0, 'yuv.min=', -73.577730000000003)
('yuv.max=', 255.0, 'yuv.min=', -12.221959999999999)
('yuv.max=', 128.02599999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 247.57999999999998, 'yuv.min=', -24.395409999999995)
('yuv.max=', 222.76499999999999, 'yuv.min=', -30.850870000000004)
('yuv.max=', 237.95499999999998, 'yuv.min=', -52.285369999999993)
('yuv.max=', 233.131, 'yuv.min=', -18.615229999999997)
('yuv.max=', 237.69299999999996, 'yuv.min=', -23.755099999999988)
('yuv.max=', 234.071, 'yuv.min=', -24.752209999999994)
('yuv.max=', 199.959, 'yuv.min=', -21.165209999999984)
('yuv.max=', 253.0, 'yuv.min=', -24.605090000000001)
('yuv.max=', 246.90699999999998, 'yuv.min=', -28.660159999999991)
('yuv.max=', 246.31, 'yuv.min=', -22.725119999999997)
('yuv.max=', 222.12799999999999, 'yuv.min=', -30.578519999999997)
('yuv.max=', 170.042, 'yuv.min=', -56.169580000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.740089999999995)
('yuv.max=', 255.0, 'yuv.min=', -16.590059999999998)
('yuv.max=', 249.316, 'yuv.min=', -50.250720000000001)
('yuv.max=', 226.18900000000002, 'yuv.min=', -39.374899999999997)
('yuv.max=', 186.27099999999999, 'yuv.min=', -32.645619999999994)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.365929999999995)
('yuv.max=', 254.886, 'yuv.min=', -23.17633)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.814450000000001)
('yuv.max=', 211.99099999999999, 'yuv.min=', -28.115289999999998)
('yuv.max=', 214.85399999999998, 'yuv.min=', -52.795789999999997)
('yuv.max=', 225.899, 'yuv.min=', -40.485419999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -6.8385600000000011)
('yuv.max=', 245.64699999999996, 'yuv.min=', -21.824849999999998)
('yuv.max=', 249.35899999999998, 'yuv.min=', -29.130329999999983)
('yuv.max=', 237.20000000000002, 'yuv.min=', -47.490400000000001)
('yuv.max=', 239.56900000000002, 'yuv.min=', -43.160379999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -41.478180000000002)
('yuv.max=', 209.035, 'yuv.min=', -33.850309999999993)
('yuv.max=', 232.0, 'yuv.min=', -36.698350000000005)
('yuv.max=', 239.98899999999998, 'yuv.min=', -39.970429999999986)
('yuv.max=', 244.76500000000001, 'yuv.min=', -35.690739999999991)
('yuv.max=', 238.42400000000001, 'yuv.min=', -36.52984)
('yuv.max=', 179.48499999999999, 'yuv.min=', -28.970559999999995)
('yuv.max=', 184.37100000000001, 'yuv.min=', -29.877760000000006)
('yuv.max=', 248.06399999999999, 'yuv.min=', -20.920369999999991)
('yuv.max=', 254.11399999999998, 'yuv.min=', -26.195510000000006)
('yuv.max=', 232.833, 'yuv.min=', -6.4235900000000044)
('yuv.max=', 251.91799999999998, 'yuv.min=', -60.075779999999995)
('yuv.max=', 242.999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 236.78899999999999, 'yuv.min=', -18.620140000000003)
('yuv.max=', 192.13800000000001, 'yuv.min=', -25.195489999999999)
('yuv.max=', 196.535, 'yuv.min=', -47.375739999999993)
('yuv.max=', 247.56799999999998, 'yuv.min=', -38.083129999999997)
('yuv.max=', 248.77199999999999, 'yuv.min=', -57.160550000000001)
('yuv.max=', 174.72699999999998, 'yuv.min=', -26.240410000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 193.10599999999999, 'yuv.min=', -24.525299999999998)
('yuv.max=', 207.78000000000003, 'yuv.min=', -27.625609999999998)
('yuv.max=', 255.0, 'yuv.min=', -19.224710000000005)
('yuv.max=', 252.03800000000001, 'yuv.min=', -59.060739999999996)
('yuv.max=', 162.35599999999999, 'yuv.min=', -36.938569999999999)
('yuv.max=', 205.08099999999999, 'yuv.min=', -42.230409999999992)
('yuv.max=', 227.34099999999998, 'yuv.min=', -18.810869999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.403250000000007)
('yuv.max=', 241.96899999999999, 'yuv.min=', -65.56595999999999)
('yuv.max=', 238.708, 'yuv.min=', -13.874269999999999)
('yuv.max=', 219.529, 'yuv.min=', -8.9502799999999887)
('yuv.max=', 217.16999999999999, 'yuv.min=', -21.605499999999989)
('yuv.max=', 241.63, 'yuv.min=', -27.585359999999998)
('yuv.max=', 200.88499999999999, 'yuv.min=', -19.350089999999998)
('yuv.max=', 245.124, 'yuv.min=', -117.26040999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -18.915329999999997)
('yuv.max=', 245.57499999999999, 'yuv.min=', -76.806100000000001)
('yuv.max=', 248.64700000000002, 'yuv.min=', -93.140950000000004)
('yuv.max=', 255.0, 'yuv.min=', -61.762990000000002)
('yuv.max=', 246.75700000000001, 'yuv.min=', -15.915299999999991)
('yuv.max=', 253.47299999999998, 'yuv.min=', -28.425689999999996)
('yuv.max=', 211.72399999999999, 'yuv.min=', -35.739530000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.225299999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.617400000000004)
('yuv.max=', 245.733, 'yuv.min=', -48.495359999999991)
('yuv.max=', 85.770999999999987, 'yuv.min=', -24.640249999999995)
('yuv.max=', 232.148, 'yuv.min=', -73.746790000000004)
('yuv.max=', 252.33699999999999, 'yuv.min=', -56.660499999999992)
('yuv.max=', 184.80799999999999, 'yuv.min=', -30.545409999999997)
('yuv.max=', 244.98899999999998, 'yuv.min=', -13.514610000000005)
('yuv.max=', 254.47300000000001, 'yuv.min=', -50.510499999999993)
('yuv.max=', 248.559, 'yuv.min=', -22.735489999999999)
('yuv.max=', 255.0, 'yuv.min=', -26.426010000000002)
('yuv.max=', 196.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 218.83999999999997, 'yuv.min=', -88.140180000000015)
('yuv.max=', 254.43000000000001, 'yuv.min=', -15.915299999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -4.6742299999999943)
('yuv.max=', 240.12499999999997, 'yuv.min=', -22.965170000000004)
('yuv.max=', 252.58699999999999, 'yuv.min=', -31.505259999999996)
('yuv.max=', 227.203, 'yuv.min=', -24.440230000000003)
('yuv.max=', 252.90699999999998, 'yuv.min=', -64.415229999999994)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -16.992329999999999)
('yuv.max=', 252.90699999999998, 'yuv.min=', -21.920469999999991)
('yuv.max=', 252.42999999999998, 'yuv.min=', -19.089550000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.152270000000001)
('yuv.max=', 244.125, 'yuv.min=', -63.702930000000002)
('yuv.max=', 224.501, 'yuv.min=', -26.185219999999994)
('yuv.max=', 248.91800000000001, 'yuv.min=', -42.705149999999989)
('yuv.max=', 242.626, 'yuv.min=', -33.635350000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.695439999999991)
('yuv.max=', 218.738, 'yuv.min=', -27.045059999999989)
('yuv.max=', 240.72299999999996, 'yuv.min=', -35.450950000000006)
('yuv.max=', 215.86399999999998, 'yuv.min=', -18.190219999999989)
('yuv.max=', 255.0, 'yuv.min=', -35.804220000000008)
('yuv.max=', 255.0, 'yuv.min=', -9.9503799999999956)
('yuv.max=', 248.52599999999998, 'yuv.min=', -45.805459999999982)
('yuv.max=', 183.03700000000001, 'yuv.min=', -31.760469999999987)
('yuv.max=', 241.92499999999998, 'yuv.min=', -77.31528999999999)
('yuv.max=', 200.10299999999998, 'yuv.min=', -25.170180000000002)
('yuv.max=', 215.81100000000001, 'yuv.min=', -71.294309999999996)
('yuv.max=', 254.70099999999999, 'yuv.min=', -15.600329999999994)
('yuv.max=', 247.976, 'yuv.min=', -68.590339999999983)
('yuv.max=', 255.0, 'yuv.min=', -10.461490000000012)
('yuv.max=', 249.267, 'yuv.min=', -35.684110000000011)
('yuv.max=', 219.53299999999999, 'yuv.min=', -59.180259999999997)
('yuv.max=', 245.13099999999997, 'yuv.min=', -7.6098999999999979)
('yuv.max=', 205.24099999999999, 'yuv.min=', -79.741560000000007)
('yuv.max=', 210.773, 'yuv.min=', -33.69511)
('yuv.max=', 255.0, 'yuv.min=', -45.420359999999988)
('yuv.max=', 243.07099999999997, 'yuv.min=', -80.07368000000001)
('yuv.max=', 221.96499999999997, 'yuv.min=', -14.592910000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 213.91799999999998, 'yuv.min=', -44.339750000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.479900000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -40.100319999999982)
('yuv.max=', 255.0, 'yuv.min=', -37.225339999999996)
('yuv.max=', 233.916, 'yuv.min=', -36.295369999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.6949699999999872)
('yuv.max=', 253.404, 'yuv.min=', -45.101480000000002)
('yuv.max=', 243.09899999999999, 'yuv.min=', -19.635120000000004)
('yuv.max=', 228.93499999999997, 'yuv.min=', -27.911809999999996)
('yuv.max=', 224.404, 'yuv.min=', -29.542439999999999)
('yuv.max=', 202.13300000000001, 'yuv.min=', -31.690339999999999)
('yuv.max=', 223.89299999999997, 'yuv.min=', -21.06063)
('yuv.max=', 224.89600000000002, 'yuv.min=', -67.960399999999993)
('yuv.max=', 248.94199999999998, 'yuv.min=', -29.160209999999999)
('yuv.max=', 220.59700000000001, 'yuv.min=', -23.390909999999998)
('yuv.max=', 237.08100000000002, 'yuv.min=', -34.705579999999998)
('yuv.max=', 202.114, 'yuv.min=', -12.795479999999984)
('yuv.max=', 125.0, 'yuv.min=', -2.6645352591003757e-15)
('yuv.max=', 255.0, 'yuv.min=', -38.865750000000006)
('yuv.max=', 250.81399999999999, 'yuv.min=', -96.790699999999987)
('yuv.max=', 211.75699999999998, 'yuv.min=', -69.990479999999991)
('yuv.max=', 206.97899999999998, 'yuv.min=', -19.805319999999995)
('yuv.max=', 229.78299999999999, 'yuv.min=', -24.110319999999994)
('yuv.max=', 249.17399999999998, 'yuv.min=', -41.047290000000004)
('yuv.max=', 246.45599999999999, 'yuv.min=', -9.0158400000000007)
('yuv.max=', 233.13899999999998, 'yuv.min=', -40.380839999999992)
('yuv.max=', 254.70099999999999, 'yuv.min=', -52.530209999999983)
('yuv.max=', 237.23599999999996, 'yuv.min=', -11.340150000000001)
('yuv.max=', 249.10300000000001, 'yuv.min=', -38.625479999999996)
('yuv.max=', 253.0, 'yuv.min=', -13.155269999999996)
('yuv.max=', 251.79299999999998, 'yuv.min=', -26.010509999999996)
('yuv.max=', 244.97800000000001, 'yuv.min=', -74.650700000000001)
('yuv.max=', 255.0, 'yuv.min=', -2.6749600000000022)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 206.60599999999999, 'yuv.min=', -30.200600000000001)
('yuv.max=', 249.995, 'yuv.min=', -59.790689999999991)
('yuv.max=', 238.95699999999997, 'yuv.min=', -10.555009999999992)
('yuv.max=', 220.91399999999999, 'yuv.min=', -70.852810000000005)
('yuv.max=', 230.80799999999999, 'yuv.min=', -20.501819999999999)
('yuv.max=', 249.02799999999999, 'yuv.min=', -61.795459999999991)
('yuv.max=', 237.62299999999999, 'yuv.min=', -35.065369999999987)
('yuv.max=', 253.20599999999999, 'yuv.min=', -23.565449999999981)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -54.190129999999996)
('yuv.max=', 251.066, 'yuv.min=', -109.19527999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.565349999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.285059999999991)
('yuv.max=', 252.33099999999999, 'yuv.min=', -15.564260000000001)
('yuv.max=', 198.37599999999998, 'yuv.min=', -24.835699999999996)
('yuv.max=', 255.0, 'yuv.min=', -41.300439999999981)
('yuv.max=', 201.084, 'yuv.min=', -22.13999999999999)
('yuv.max=', 187.34399999999999, 'yuv.min=', -11.410279999999993)
('yuv.max=', 108.444, 'yuv.min=', -23.280359999999995)
('yuv.max=', 236.39400000000001, 'yuv.min=', -43.635119999999986)
('yuv.max=', 230.28999999999999, 'yuv.min=', -47.730959999999996)
('yuv.max=', 251.98499999999999, 'yuv.min=', -41.14067)
('yuv.max=', 219.05100000000002, 'yuv.min=', -17.875249999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.411179999999998)
('yuv.max=', 210.595, 'yuv.min=', -20.505389999999988)
('yuv.max=', 217.417, 'yuv.min=', -23.95055)
('yuv.max=', 255.0, 'yuv.min=', -23.225169999999999)
('yuv.max=', 187.149, 'yuv.min=', -76.569299999999998)
('yuv.max=', 233.25900000000001, 'yuv.min=', -9.4749099999999942)
('yuv.max=', 220.22200000000001, 'yuv.min=', -27.242040000000003)
('yuv.max=', 244.32699999999997, 'yuv.min=', -6.9967399999999991)
('yuv.max=', 241.02099999999999, 'yuv.min=', -43.837469999999996)
('yuv.max=', 254.40199999999999, 'yuv.min=', -11.025179999999999)
('yuv.max=', 252.679, 'yuv.min=', -46.435399999999994)
('yuv.max=', 248.52899999999997, 'yuv.min=', -49.21036999999999)
('yuv.max=', 248.35900000000001, 'yuv.min=', -16.345219999999994)
('yuv.max=', 238.54399999999995, 'yuv.min=', -13.185149999999986)
('yuv.max=', 242.435, 'yuv.min=', -12.670190000000002)
('yuv.max=', 212.256, 'yuv.min=', -8.6636600000000001)
('yuv.max=', 255.0, 'yuv.min=', -41.945319999999981)
('yuv.max=', 255.0, 'yuv.min=', -61.626080000000009)
('yuv.max=', 252.761, 'yuv.min=', -79.169249999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.311610000000002)
('yuv.max=', 238.798, 'yuv.min=', -11.803229999999999)
('yuv.max=', 175.99999999999997, 'yuv.min=', -6.7650000000000006)
('yuv.max=', 254.40199999999999, 'yuv.min=', -22.180249999999997)
('yuv.max=', 167.94499999999999, 'yuv.min=', -14.371259999999998)
('yuv.max=', 198.61600000000001, 'yuv.min=', -43.305209999999988)
('yuv.max=', 254.65800000000002, 'yuv.min=', -68.945559999999986)
('yuv.max=', 213.66200000000001, 'yuv.min=', -24.998119999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.223240000000004)
('yuv.max=', 255.0, 'yuv.min=', -47.495320000000007)
('yuv.max=', 255.0, 'yuv.min=', -34.510130000000004)
('yuv.max=', 253.333, 'yuv.min=', -26.800219999999996)
('yuv.max=', 202.339, 'yuv.min=', -22.910199999999993)
('yuv.max=', 243.98299999999998, 'yuv.min=', -33.880189999999999)
('yuv.max=', 238.47299999999998, 'yuv.min=', -37.580559999999991)
('yuv.max=', 229.0, 'yuv.min=', -2.974989999999984)
('yuv.max=', 250.87899999999996, 'yuv.min=', -19.640800000000006)
('yuv.max=', 242.61299999999997, 'yuv.min=', -20.696290000000005)
('yuv.max=', 237.68099999999998, 'yuv.min=', -23.825230000000001)
('yuv.max=', 233.65800000000002, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 228.71899999999999, 'yuv.min=', -60.520639999999986)
('yuv.max=', 252.065, 'yuv.min=', -15.08492)
('yuv.max=', 247.62499999999997, 'yuv.min=', -22.82744000000001)
('yuv.max=', 210.87099999999998, 'yuv.min=', -19.064999999999994)
('yuv.max=', 203.333, 'yuv.min=', -27.43015999999999)
('yuv.max=', 254.886, 'yuv.min=', -38.415000000000006)
('yuv.max=', 197.91800000000001, 'yuv.min=', -10.50003000000001)
('yuv.max=', 244.762, 'yuv.min=', -15.445129999999995)
('yuv.max=', 231.15299999999996, 'yuv.min=', -44.885859999999994)
('yuv.max=', 164.035, 'yuv.min=', -20.680990000000001)
('yuv.max=', 250.46199999999996, 'yuv.min=', -66.58556999999999)
('yuv.max=', 208.38999999999999, 'yuv.min=', -44.190359999999998)
('yuv.max=', 249.744, 'yuv.min=', -38.280629999999995)
('yuv.max=', 251.71100000000001, 'yuv.min=', -11.140129999999985)
('yuv.max=', 255.0, 'yuv.min=', -43.487760000000009)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 247.29900000000004, 'yuv.min=', -3.0555499999999967)
('yuv.max=', 220.941, 'yuv.min=', -31.962759999999996)
('yuv.max=', 246.85399999999998, 'yuv.min=', -40.870519999999985)
('yuv.max=', 255.0, 'yuv.min=', -8.765199999999993)
('yuv.max=', 245.63199999999998, 'yuv.min=', -37.505130000000008)
('yuv.max=', 234.03200000000001, 'yuv.min=', -19.190319999999993)
('yuv.max=', 240.97899999999998, 'yuv.min=', -31.005209999999988)
('yuv.max=', 255.0, 'yuv.min=', -13.500119999999992)
('yuv.max=', 252.93999999999997, 'yuv.min=', -34.180520000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -15.460069999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.40011)
('yuv.max=', 157.50399999999999, 'yuv.min=', -0.87020999999999127)
('yuv.max=', 179.76999999999998, 'yuv.min=', -5.9051600000000004)
('yuv.max=', 243.95699999999997, 'yuv.min=', -16.908060000000006)
('yuv.max=', 226.976, 'yuv.min=', -2.7853399999999873)
('yuv.max=', 242.58699999999999, 'yuv.min=', -39.380739999999989)
('yuv.max=', 253.72899999999996, 'yuv.min=', -36.540210000000002)
('yuv.max=', 235.363, 'yuv.min=', -42.375239999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.3650599999999855)
('yuv.max=', 219.99499999999998, 'yuv.min=', -48.312550000000002)
('yuv.max=', 250.81399999999999, 'yuv.min=', -29.545310000000001)
('yuv.max=', 213.309, 'yuv.min=', -16.215330000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 254.41299999999995, 'yuv.min=', -23.508759999999995)
('yuv.max=', 181.41, 'yuv.min=', -44.360499999999995)
('yuv.max=', 186.07499999999999, 'yuv.min=', -39.285299999999992)
('yuv.max=', 239.11899999999997, 'yuv.min=', -72.460849999999994)
('yuv.max=', 224.97199999999998, 'yuv.min=', -28.321109999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.855339999999998)
('yuv.max=', 157.73699999999997, 'yuv.min=', -17.075169999999986)
('yuv.max=', 214.81, 'yuv.min=', -44.655959999999993)
('yuv.max=', 203.03900000000002, 'yuv.min=', -48.925279999999994)
('yuv.max=', 237.40600000000001, 'yuv.min=', -24.751550000000009)
('yuv.max=', 164.63800000000001, 'yuv.min=', -47.460810000000002)
('yuv.max=', 248.185, 'yuv.min=', -26.717870000000001)
('yuv.max=', 251.13099999999997, 'yuv.min=', -10.650449999999998)
('yuv.max=', 246.59399999999999, 'yuv.min=', -18.211650000000002)
('yuv.max=', 255.0, 'yuv.min=', -76.956869999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -34.865349999999992)
('yuv.max=', 227.541, 'yuv.min=', -70.500900000000001)
('yuv.max=', 251.10299999999998, 'yuv.min=', -41.115359999999995)
('yuv.max=', 215.125, 'yuv.min=', -42.360299999999995)
('yuv.max=', 206.886, 'yuv.min=', -32.866430000000001)
('yuv.max=', 228.58499999999998, 'yuv.min=', -18.630509999999994)
('yuv.max=', 198.21899999999997, 'yuv.min=', -53.42116)
('yuv.max=', 128.78, 'yuv.min=', -56.085749999999997)
('yuv.max=', 242.25499999999997, 'yuv.min=', -33.060599999999987)
('yuv.max=', 172.886, 'yuv.min=', -24.280459999999998)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.645420000000001)
('yuv.max=', 241.357, 'yuv.min=', -17.045289999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.985499999999991)
('yuv.max=', 249.32699999999997, 'yuv.min=', -23.182099999999991)
('yuv.max=', 229.07199999999997, 'yuv.min=', -52.095719999999993)
('yuv.max=', 250.0, 'yuv.min=', -9.166170000000001)
('yuv.max=', 248.25999999999999, 'yuv.min=', -57.220309999999991)
('yuv.max=', 240.404, 'yuv.min=', -49.528590000000001)
('yuv.max=', 252.42999999999998, 'yuv.min=', -24.755199999999995)
('yuv.max=', 252.892, 'yuv.min=', -24.810389999999998)
('yuv.max=', 235.77799999999996, 'yuv.min=', -76.913550000000001)
('yuv.max=', 246.88200000000001, 'yuv.min=', -25.880910000000004)
('yuv.max=', 207.24999999999997, 'yuv.min=', -38.425460000000001)
('yuv.max=', 238.10799999999998, 'yuv.min=', -38.135799999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 201.37899999999999, 'yuv.min=', -68.357200000000006)
('yuv.max=', 253.71799999999999, 'yuv.min=', -39.625579999999985)
('yuv.max=', 241.869, 'yuv.min=', -43.01991000000001)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.636, 'yuv.min=', -69.299289999999999)
('yuv.max=', 250.78199999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 221.09199999999998, 'yuv.min=', -26.370299999999993)
('yuv.max=', 219.49000000000001, 'yuv.min=', -12.962710000000001)
('yuv.max=', 240.30299999999997, 'yuv.min=', -42.200529999999993)
('yuv.max=', 244.17999999999998, 'yuv.min=', -38.459909999999994)
('yuv.max=', 245.71599999999998, 'yuv.min=', -33.020349999999993)
('yuv.max=', 255.0, 'yuv.min=', -41.355629999999998)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.73999999999998, 'yuv.min=', -63.00515)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.071029999999997)
('yuv.max=', 244.30700000000002, 'yuv.min=', -24.655189999999994)
('yuv.max=', 220.43499999999997, 'yuv.min=', -95.514039999999994)
('yuv.max=', 192.34700000000001, 'yuv.min=', -46.490589999999997)
('yuv.max=', 252.03199999999998, 'yuv.min=', -24.081859999999999)
('yuv.max=', 210.83399999999997, 'yuv.min=', -72.965469999999996)
('yuv.max=', 174.45399999999998, 'yuv.min=', -33.766310000000004)
('yuv.max=', 255.0, 'yuv.min=', -65.686679999999996)
('yuv.max=', 232.69, 'yuv.min=', -36.403080000000003)
('yuv.max=', 255.0, 'yuv.min=', -20.920369999999995)
('yuv.max=', 247.47299999999998, 'yuv.min=', -34.59062999999999)
('yuv.max=', 206.459, 'yuv.min=', -29.560249999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.07507)
('yuv.max=', 209.27799999999999, 'yuv.min=', -74.362259999999992)
('yuv.max=', 251.89699999999999, 'yuv.min=', -65.555589999999995)
('yuv.max=', 248.57999999999998, 'yuv.min=', -35.073459999999997)
('yuv.max=', 238.62999999999997, 'yuv.min=', -45.516820000000003)
('yuv.max=', 248.76499999999999, 'yuv.min=', -52.600339999999989)
('yuv.max=', 242.58899999999997, 'yuv.min=', -12.805450000000008)
('yuv.max=', 229.24700000000001, 'yuv.min=', -24.267709999999997)
('yuv.max=', 252.886, 'yuv.min=', -21.858270000000008)
('yuv.max=', 254.886, 'yuv.min=', -40.813850000000002)
('yuv.max=', 227.36499999999998, 'yuv.min=', -68.590339999999998)
('yuv.max=', 245.69399999999999, 'yuv.min=', -19.550109999999997)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.780309999999993)
('yuv.max=', 254.886, 'yuv.min=', -14.713340000000002)
('yuv.max=', 240.53299999999999, 'yuv.min=', -36.725290000000001)
('yuv.max=', 253.80399999999997, 'yuv.min=', -78.995130000000003)
('yuv.max=', 236.67699999999999, 'yuv.min=', -32.460539999999988)
('yuv.max=', 253.81499999999997, 'yuv.min=', -39.014770000000006)
('yuv.max=', 232.071, 'yuv.min=', -2.473550000000003)
('yuv.max=', 218.14099999999999, 'yuv.min=', -38.092199999999991)
('yuv.max=', 229.63, 'yuv.min=', -32.060499999999998)
('yuv.max=', 140.624, 'yuv.min=', -25.65528999999999)
('yuv.max=', 208.17499999999998, 'yuv.min=', -18.850039999999993)
('yuv.max=', 250.017, 'yuv.min=', -9.8746100000000006)
('yuv.max=', 243.42499999999995, 'yuv.min=', -17.219390000000004)
('yuv.max=', 195.28199999999998, 'yuv.min=', -48.440169999999995)
('yuv.max=', 249.733, 'yuv.min=', -22.420519999999982)
('yuv.max=', 235.69399999999999, 'yuv.min=', -48.350529999999992)
('yuv.max=', 234.78099999999998, 'yuv.min=', -15.834680000000013)
('yuv.max=', 253.76100000000002, 'yuv.min=', -34.850409999999997)
('yuv.max=', 217.821, 'yuv.min=', -23.345400000000005)
('yuv.max=', 246.809, 'yuv.min=', -26.125459999999986)
('yuv.max=', 237.89699999999999, 'yuv.min=', -40.730259999999994)
('yuv.max=', 255.0, 'yuv.min=', -19.737919999999999)
('yuv.max=', 252.24699999999996, 'yuv.min=', -57.530709999999985)
('yuv.max=', 255.0, 'yuv.min=', -35.813090000000003)
('yuv.max=', 237.245, 'yuv.min=', -34.56532)
('yuv.max=', 253.505, 'yuv.min=', -55.555320000000009)
('yuv.max=', 195.46599999999998, 'yuv.min=', -17.595169999999996)
('yuv.max=', 254.54400000000001, 'yuv.min=', -79.518849999999986)
('yuv.max=', 255.0, 'yuv.min=', -95.05641)
('yuv.max=', 250.62299999999999, 'yuv.min=', -58.732000000000006)
('yuv.max=', 244.47300000000001, 'yuv.min=', -33.300870000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -25.570219999999996)
('yuv.max=', 246.38700000000003, 'yuv.min=', -33.41105000000001)
('yuv.max=', 235.82599999999999, 'yuv.min=', -18.800549999999994)
('yuv.max=', 193.41, 'yuv.min=', -20.175479999999993)
('yuv.max=', 251.08099999999999, 'yuv.min=', -42.600569999999991)
('yuv.max=', 254.54400000000001, 'yuv.min=', -50.08292999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.504599999999989)
('yuv.max=', 237.06899999999999, 'yuv.min=', -25.815059999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -25.225369999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -11.187920000000002)
('yuv.max=', 239.559, 'yuv.min=', -11.340150000000007)
('yuv.max=', 255.0, 'yuv.min=', -2.6600199999999976)
('yuv.max=', 221.291, 'yuv.min=', -18.920169999999999)
('yuv.max=', 250.43499999999997, 'yuv.min=', -30.551030000000001)
('yuv.max=', 245.29999999999998, 'yuv.min=', -28.975129999999993)
('yuv.max=', 193.99499999999998, 'yuv.min=', -22.555520000000001)
('yuv.max=', 228.67899999999997, 'yuv.min=', -37.65068999999999)
('yuv.max=', 241.09899999999999, 'yuv.min=', -36.6175)
('yuv.max=', 203.96399999999997, 'yuv.min=', -47.603279999999998)
('yuv.max=', 253.12499999999997, 'yuv.min=', -28.845239999999997)
('yuv.max=', 248.97900000000001, 'yuv.min=', -11.197389999999999)
('yuv.max=', 230.316, 'yuv.min=', -15.630209999999998)
('yuv.max=', 229.524, 'yuv.min=', -15.830229999999993)
('yuv.max=', 239.88099999999997, 'yuv.min=', -24.932200000000002)
('yuv.max=', 239.20599999999996, 'yuv.min=', -16.260149999999985)
('yuv.max=', 238.17399999999998, 'yuv.min=', -49.795490000000001)
('yuv.max=', 226.65799999999999, 'yuv.min=', -22.265319999999992)
('yuv.max=', 253.64700000000002, 'yuv.min=', -32.324849999999998)
('yuv.max=', 227.30199999999999, 'yuv.min=', -42.245349999999995)
('yuv.max=', 198.26300000000001, 'yuv.min=', -45.115759999999995)
('yuv.max=', 229.505, 'yuv.min=', -38.562640000000002)
('yuv.max=', 195.83499999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 255.0, 'yuv.min=', -68.252790000000005)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.590329999999994)
('yuv.max=', 237.43899999999999, 'yuv.min=', -24.380469999999992)
('yuv.max=', 255.0, 'yuv.min=', -56.264140000000005)
('yuv.max=', 225.32300000000001, 'yuv.min=', -22.875749999999996)
('yuv.max=', 170.57999999999998, 'yuv.min=', -32.575489999999995)
('yuv.max=', 247.08999999999997, 'yuv.min=', -13.813460000000006)
('yuv.max=', 187.07300000000001, 'yuv.min=', -21.41004999999998)
('yuv.max=', 242.22399999999999, 'yuv.min=', -18.520130000000002)
('yuv.max=', 239.62200000000001, 'yuv.min=', -20.62227)
('yuv.max=', 250.01000000000002, 'yuv.min=', -7.3949399999999983)
('yuv.max=', 206.06999999999999, 'yuv.min=', -35.244649999999993)
('yuv.max=', 244.15699999999998, 'yuv.min=', -59.990709999999986)
('yuv.max=', 229.21000000000001, 'yuv.min=', -26.240409999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -22.092999999999996)
('yuv.max=', 234.928, 'yuv.min=', -28.070050000000005)
('yuv.max=', 249.11600000000001, 'yuv.min=', -20.875549999999993)
('yuv.max=', 162.24900000000002, 'yuv.min=', -12.485079999999986)
('yuv.max=', 255.0, 'yuv.min=', -6.2350699999999994)
('yuv.max=', 252.608, 'yuv.min=', -28.800419999999988)
('yuv.max=', 246.0, 'yuv.min=', -29.560249999999996)
('yuv.max=', 241.65100000000001, 'yuv.min=', -36.856290000000001)
('yuv.max=', 244.40499999999997, 'yuv.min=', -27.384129999999999)
('yuv.max=', 179.917, 'yuv.min=', -12.963499999999996)
('yuv.max=', 235.92899999999997, 'yuv.min=', -47.942480000000003)
('yuv.max=', 195.11399999999998, 'yuv.min=', -29.254120000000004)
('yuv.max=', 211.85500000000002, 'yuv.min=', -61.465550000000007)
('yuv.max=', 226.96699999999998, 'yuv.min=', -21.580189999999995)
('yuv.max=', 235.18800000000002, 'yuv.min=', -49.231330000000014)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.756, 'yuv.min=', -72.509069999999994)
('yuv.max=', 255.0, 'yuv.min=', -16.815389999999997)
('yuv.max=', 248.73199999999997, 'yuv.min=', -100.62553)
('yuv.max=', 225.40000000000001, 'yuv.min=', -19.390339999999981)
('yuv.max=', 244.43899999999999, 'yuv.min=', -32.045559999999988)
('yuv.max=', 252.00999999999999, 'yuv.min=', -40.257210000000008)
('yuv.max=', 248.10899999999998, 'yuv.min=', -35.940149999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.57086000000001)
('yuv.max=', 221.423, 'yuv.min=', -16.828860000000002)
('yuv.max=', 247.35499999999999, 'yuv.min=', -76.540520000000001)
('yuv.max=', 255.0, 'yuv.min=', -50.79558999999999)
('yuv.max=', 226.29599999999999, 'yuv.min=', -27.956729999999997)
('yuv.max=', 201.99999999999997, 'yuv.min=', -27.470409999999994)
('yuv.max=', 247.86499999999998, 'yuv.min=', -95.415869999999998)
('yuv.max=', 221.13399999999999, 'yuv.min=', -80.666240000000002)
('yuv.max=', 255.0, 'yuv.min=', -34.861909999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -12.11434)
('yuv.max=', 253.0, 'yuv.min=', -31.989319999999999)
('yuv.max=', 243.74599999999998, 'yuv.min=', -13.830799999999996)
('yuv.max=', 162.774, 'yuv.min=', -36.910369999999993)
('yuv.max=', 194.113, 'yuv.min=', -20.120289999999983)
('yuv.max=', 223.71699999999998, 'yuv.min=', -22.724240000000002)
('yuv.max=', 231.51900000000001, 'yuv.min=', -24.900029999999987)
('yuv.max=', 255.0, 'yuv.min=', -5.4372200000000035)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -5.8200899999999933)
('yuv.max=', 250.08099999999996, 'yuv.min=', -34.277480000000011)
('yuv.max=', 255.0, 'yuv.min=', -46.27563)
('yuv.max=', 255.0, 'yuv.min=', -36.099009999999993)
('yuv.max=', 244.29899999999998, 'yuv.min=', -11.95046)
('yuv.max=', 237.07199999999997, 'yuv.min=', -52.660519999999998)
('yuv.max=', 247.38, 'yuv.min=', -33.727649999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.761360000000003)
('yuv.max=', 224.62800000000001, 'yuv.min=', -7.1813399999999987)
('yuv.max=', 211.958, 'yuv.min=', -37.690939999999991)
('yuv.max=', 255.0, 'yuv.min=', -31.745529999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.150369999999995)
('yuv.max=', 210.64699999999999, 'yuv.min=', -9.4100799999999936)
('yuv.max=', 242.57599999999996, 'yuv.min=', -22.865379999999988)
('yuv.max=', 230.53800000000001, 'yuv.min=', -39.150840000000002)
('yuv.max=', 253.78899999999999, 'yuv.min=', -27.602539999999998)
('yuv.max=', 253.071, 'yuv.min=', -17.88036)
('yuv.max=', 239.31599999999997, 'yuv.min=', -48.695379999999993)
('yuv.max=', 228.80500000000001, 'yuv.min=', -55.167779999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.8189400000000049)
('yuv.max=', 251.989, 'yuv.min=', -38.61054)
('yuv.max=', 255.0, 'yuv.min=', -78.503790000000009)
('yuv.max=', 255.0, 'yuv.min=', -28.958759999999998)
('yuv.max=', 239.42999999999998, 'yuv.min=', -18.790090000000003)
('yuv.max=', 234.13499999999999, 'yuv.min=', -27.725619999999999)
('yuv.max=', 248.309, 'yuv.min=', -48.025189999999995)
('yuv.max=', 240.505, 'yuv.min=', -30.000539999999987)
('yuv.max=', 156.01600000000002, 'yuv.min=', -23.295299999999987)
('yuv.max=', 255.0, 'yuv.min=', -34.88942999999999)
('yuv.max=', 238.49199999999999, 'yuv.min=', -27.674999999999986)
('yuv.max=', 200.453, 'yuv.min=', -10.92516999999998)
('yuv.max=', 237.99100000000001, 'yuv.min=', -18.405179999999998)
('yuv.max=', 255.0, 'yuv.min=', -18.631800000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -9.9250699999999998)
('yuv.max=', 247.559, 'yuv.min=', -19.699509999999997)
('yuv.max=', 177.83399999999997, 'yuv.min=', -74.852370000000008)
('yuv.max=', 229.86899999999997, 'yuv.min=', -53.525739999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.360629999999986)
('yuv.max=', 217.90099999999998, 'yuv.min=', -17.860309999999991)
('yuv.max=', 233.56999999999999, 'yuv.min=', -15.730219999999994)
('yuv.max=', 234.38300000000001, 'yuv.min=', -21.652050000000003)
('yuv.max=', 215.13099999999997, 'yuv.min=', -44.185559999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.42199999999997, 'yuv.min=', -48.266610000000007)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.985199999999995)
('yuv.max=', 140.06799999999998, 'yuv.min=', -14.830129999999999)
('yuv.max=', 249.17399999999998, 'yuv.min=', -34.562550000000002)
('yuv.max=', 248.48799999999997, 'yuv.min=', -38.940449999999998)
('yuv.max=', 236.68599999999998, 'yuv.min=', -13.830669999999998)
('yuv.max=', 242.52200000000002, 'yuv.min=', -26.151740000000004)
('yuv.max=', 224.476, 'yuv.min=', -24.850459999999998)
('yuv.max=', 165.22499999999999, 'yuv.min=', -45.685939999999995)
('yuv.max=', 244.50799999999998, 'yuv.min=', -16.908730000000006)
('yuv.max=', 251.626, 'yuv.min=', -14.870779999999996)
('yuv.max=', 243.17399999999998, 'yuv.min=', -10.280289999999983)
('yuv.max=', 204.40299999999999, 'yuv.min=', -25.197850000000006)
('yuv.max=', 202.06900000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 247.37, 'yuv.min=', -35.282219999999995)
('yuv.max=', 236.73999999999998, 'yuv.min=', -36.654979999999995)
('yuv.max=', 233.71099999999998, 'yuv.min=', -43.975399999999993)
('yuv.max=', 248.22800000000001, 'yuv.min=', -29.180949999999996)
('yuv.max=', 213.67099999999999, 'yuv.min=', -6.8201899999999895)
('yuv.max=', 244.95699999999999, 'yuv.min=', -33.520399999999995)
('yuv.max=', 253.60399999999998, 'yuv.min=', -54.49595999999999)
('yuv.max=', 228.91199999999998, 'yuv.min=', -13.19248)
('yuv.max=', 115.28099999999999, 'yuv.min=', -39.415189999999996)
('yuv.max=', 205.60999999999999, 'yuv.min=', -60.214730000000003)
('yuv.max=', 224.202, 'yuv.min=', -49.380510000000001)
('yuv.max=', 250.20199999999997, 'yuv.min=', -38.588660000000004)
('yuv.max=', 253.63200000000001, 'yuv.min=', -13.138069999999999)
('yuv.max=', 206.85799999999998, 'yuv.min=', -69.785889999999995)
('yuv.max=', 168.94099999999997, 'yuv.min=', -17.775239999999997)
('yuv.max=', 240.65799999999999, 'yuv.min=', -28.54520999999999)
('yuv.max=', 224.584, 'yuv.min=', -19.835199999999997)
('yuv.max=', 241.52000000000001, 'yuv.min=', -50.700149999999979)
('yuv.max=', 168.11999999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 188.267, 'yuv.min=', -39.755469999999988)
('yuv.max=', 238.47299999999998, 'yuv.min=', -39.608540000000005)
('yuv.max=', 255.0, 'yuv.min=', -24.929909999999982)
('yuv.max=', 195.34799999999998, 'yuv.min=', -36.654849999999996)
('yuv.max=', 218.31999999999999, 'yuv.min=', -31.130529999999993)
('yuv.max=', 238.41299999999998, 'yuv.min=', -97.565469999999991)
('yuv.max=', 238.28999999999999, 'yuv.min=', -26.485569999999999)
('yuv.max=', 209.74099999999999, 'yuv.min=', -55.266159999999999)
('yuv.max=', 180.42499999999998, 'yuv.min=', -25.780609999999999)
('yuv.max=', 221.32499999999999, 'yuv.min=', -41.215369999999993)
('yuv.max=', 189.82499999999999, 'yuv.min=', -69.285839999999993)
('yuv.max=', 242.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.67500000000001, 'yuv.min=', -26.855409999999988)
('yuv.max=', 219.16, 'yuv.min=', -18.942410000000002)
('yuv.max=', 209.977, 'yuv.min=', -31.580290000000012)
('yuv.max=', 242.06099999999998, 'yuv.min=', -25.787010000000002)
('yuv.max=', 253.63200000000001, 'yuv.min=', -85.540189999999981)
('yuv.max=', 244.624, 'yuv.min=', -21.485979999999998)
('yuv.max=', 203.83500000000001, 'yuv.min=', -5.19015)
('yuv.max=', 211.02100000000002, 'yuv.min=', -16.315339999999999)
('yuv.max=', 228.95299999999997, 'yuv.min=', -34.735459999999989)
('yuv.max=', 250.38200000000001, 'yuv.min=', -27.040489999999998)
('yuv.max=', 219.65299999999999, 'yuv.min=', -26.325479999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.6801300000000001)
('yuv.max=', 233.54199999999997, 'yuv.min=', -62.884430000000009)
('yuv.max=', 247.875, 'yuv.min=', -25.815059999999999)
('yuv.max=', 223.44599999999997, 'yuv.min=', -24.010309999999997)
('yuv.max=', 251.16900000000001, 'yuv.min=', -26.745029999999986)
('yuv.max=', 255.0, 'yuv.min=', -19.170809999999989)
('yuv.max=', 212.10500000000002, 'yuv.min=', -27.88663)
('yuv.max=', 255.0, 'yuv.min=', -38.497750000000011)
('yuv.max=', 158.15000000000001, 'yuv.min=', -35.014670000000002)
('yuv.max=', 255.0, 'yuv.min=', -30.060960000000001)
('yuv.max=', 248.74299999999999, 'yuv.min=', -36.920739999999995)
('yuv.max=', 235.477, 'yuv.min=', -25.165610000000001)
('yuv.max=', 250.81100000000001, 'yuv.min=', -10.200159999999997)
('yuv.max=', 214.78899999999999, 'yuv.min=', -38.574859999999994)
('yuv.max=', 200.48299999999998, 'yuv.min=', -38.940449999999984)
('yuv.max=', 255.0, 'yuv.min=', -16.090009999999999)
('yuv.max=', 249.91699999999997, 'yuv.min=', -31.20523)
('yuv.max=', 244.81500000000003, 'yuv.min=', -36.880489999999995)
('yuv.max=', 246.03399999999999, 'yuv.min=', -26.300169999999994)
('yuv.max=', 252.60599999999999, 'yuv.min=', -31.580769999999994)
('yuv.max=', 187.595, 'yuv.min=', -52.83480999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -40.27046)
('yuv.max=', 232.24499999999998, 'yuv.min=', -22.37143)
('yuv.max=', 213.24799999999999, 'yuv.min=', -51.495659999999987)
('yuv.max=', 185.39299999999997, 'yuv.min=', -32.805389999999989)
('yuv.max=', 162.25800000000001, 'yuv.min=', -43.630549999999999)
('yuv.max=', 249.13199999999998, 'yuv.min=', -76.334669999999988)
('yuv.max=', 249.82599999999999, 'yuv.min=', -30.52965)
('yuv.max=', 225.852, 'yuv.min=', -35.025660000000002)
('yuv.max=', 254.316, 'yuv.min=', -20.774210000000004)
('yuv.max=', 254.41299999999995, 'yuv.min=', -22.895260000000004)
('yuv.max=', 237.45600000000002, 'yuv.min=', -16.609949999999998)
('yuv.max=', 207.32599999999999, 'yuv.min=', -40.29576999999999)
('yuv.max=', 198.34700000000001, 'yuv.min=', -61.310349999999993)
('yuv.max=', 231.14999999999998, 'yuv.min=', -49.75067)
('yuv.max=', 255.0, 'yuv.min=', -34.920539999999995)
('yuv.max=', 248.66900000000001, 'yuv.min=', -40.61074)
('yuv.max=', 248.815, 'yuv.min=', -24.61037)
('yuv.max=', 249.125, 'yuv.min=', -20.680109999999999)
('yuv.max=', 210.04500000000002, 'yuv.min=', -21.69438000000001)
('yuv.max=', 191.98299999999998, 'yuv.min=', -10.680329999999996)
('yuv.max=', 212.72399999999999, 'yuv.min=', -40.530320000000003)
('yuv.max=', 231.44499999999999, 'yuv.min=', -28.700409999999998)
('yuv.max=', 212.29999999999998, 'yuv.min=', -50.800159999999991)
('yuv.max=', 248.89699999999999, 'yuv.min=', -27.309130000000003)
('yuv.max=', 250.02800000000002, 'yuv.min=', -51.465779999999995)
('yuv.max=', 243.54399999999998, 'yuv.min=', -29.875219999999992)
('yuv.max=', 246.886, 'yuv.min=', -24.740259999999992)
('yuv.max=', 242.83999999999997, 'yuv.min=', -45.670999999999999)
('yuv.max=', 247.28100000000001, 'yuv.min=', -20.899590000000003)
('yuv.max=', 241.94999999999999, 'yuv.min=', -16.409350000000003)
('yuv.max=', 236.11099999999999, 'yuv.min=', -17.420019999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.56999999999999, 'yuv.min=', -93.345539999999986)
('yuv.max=', 254.06, 'yuv.min=', -43.43052999999999)
('yuv.max=', 201.756, 'yuv.min=', -14.691369999999999)
('yuv.max=', 227.08799999999999, 'yuv.min=', -19.035519999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.025049999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 226.303, 'yuv.min=', -78.360209999999995)
('yuv.max=', 247.142, 'yuv.min=', -25.595529999999997)
('yuv.max=', 206.09999999999999, 'yuv.min=', -33.630779999999994)
('yuv.max=', 182.89400000000001, 'yuv.min=', -15.615269999999995)
('yuv.max=', 251.45599999999996, 'yuv.min=', -18.360359999999996)
('yuv.max=', 253.01699999999997, 'yuv.min=', -11.465959999999999)
('yuv.max=', 144.58599999999998, 'yuv.min=', -26.48524999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.194890000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.505570000000002)
('yuv.max=', 235.25299999999999, 'yuv.min=', -40.67049999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', -48.290710000000004)
('yuv.max=', 255.0, 'yuv.min=', -36.120659999999987)
('yuv.max=', 254.29899999999995, 'yuv.min=', -34.96535999999999)
('yuv.max=', 253.333, 'yuv.min=', -34.501159999999999)
('yuv.max=', 253.17399999999998, 'yuv.min=', -31.794919999999983)
('yuv.max=', 193.07999999999998, 'yuv.min=', -6.1571099999999959)
('yuv.max=', 238.923, 'yuv.min=', -28.343790000000006)
('yuv.max=', 234.108, 'yuv.min=', -22.196990000000003)
('yuv.max=', 250.69999999999999, 'yuv.min=', -46.180189999999982)
('yuv.max=', 238.65899999999999, 'yuv.min=', -19.305269999999986)
('yuv.max=', 253.99999999999997, 'yuv.min=', -62.255259999999993)
('yuv.max=', 215.88599999999997, 'yuv.min=', -9.3135700000000021)
('yuv.max=', 245.54199999999997, 'yuv.min=', -44.230609999999999)
('yuv.max=', 215.73899999999998, 'yuv.min=', -81.530649999999994)
('yuv.max=', 250.90899999999999, 'yuv.min=', -89.503680000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.605469999999997)
('yuv.max=', 202.554, 'yuv.min=', -31.800719999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.685099999999991)
('yuv.max=', 209.60499999999999, 'yuv.min=', -50.495559999999983)
('yuv.max=', 194.55700000000002, 'yuv.min=', -36.995439999999988)
('yuv.max=', 216.37699999999998, 'yuv.min=', -81.741720000000001)
('yuv.max=', 228.75299999999999, 'yuv.min=', -46.105489999999989)
('yuv.max=', 255.0, 'yuv.min=', -3.1922800000000038)
('yuv.max=', 244.053, 'yuv.min=', -17.960319999999985)
('yuv.max=', 254.316, 'yuv.min=', -20.850239999999985)
('yuv.max=', 255.0, 'yuv.min=', -20.206259999999997)
('yuv.max=', 252.31, 'yuv.min=', -36.705150000000003)
('yuv.max=', 239.864, 'yuv.min=', -16.609749999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -13.966860000000004)
('yuv.max=', 235.608, 'yuv.min=', -18.511550000000007)
('yuv.max=', 246.46599999999998, 'yuv.min=', -18.075269999999996)
('yuv.max=', 207.61000000000001, 'yuv.min=', -20.175479999999997)
('yuv.max=', 194.35899999999998, 'yuv.min=', -30.965180000000004)
('yuv.max=', 245.989, 'yuv.min=', -20.984699999999997)
('yuv.max=', 231.024, 'yuv.min=', -46.39058)
('yuv.max=', 255.0, 'yuv.min=', -20.635279999999998)
('yuv.max=', 239.41499999999996, 'yuv.min=', -12.959819999999993)
('yuv.max=', 251.327, 'yuv.min=', -21.96529)
('yuv.max=', 230.76600000000002, 'yuv.min=', -54.170570000000005)
('yuv.max=', 255.0, 'yuv.min=', -40.790659999999995)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 186.69799999999998, 'yuv.min=', -26.645019999999992)
('yuv.max=', 248.142, 'yuv.min=', -29.194520000000001)
('yuv.max=', 240.30499999999998, 'yuv.min=', -44.334310000000002)
('yuv.max=', 251.90299999999999, 'yuv.min=', -21.536810000000003)
('yuv.max=', 251.07299999999998, 'yuv.min=', -29.285359999999997)
('yuv.max=', 219.886, 'yuv.min=', -17.260249999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -35.074359999999999)
('yuv.max=', 235.94999999999999, 'yuv.min=', -19.395350000000001)
('yuv.max=', 218.91499999999999, 'yuv.min=', -21.411540000000006)
('yuv.max=', 206.64999999999998, 'yuv.min=', -29.560249999999996)
('yuv.max=', 211.91699999999997, 'yuv.min=', -27.515229999999988)
('yuv.max=', 254.47300000000001, 'yuv.min=', -25.870260000000002)
('yuv.max=', 251.54399999999998, 'yuv.min=', -87.385189999999994)
('yuv.max=', 255.0, 'yuv.min=', -33.69344000000001)
('yuv.max=', 252.04899999999998, 'yuv.min=', -29.507860000000004)
('yuv.max=', 206.18700000000001, 'yuv.min=', -24.158469999999998)
('yuv.max=', 232.80500000000001, 'yuv.min=', -29.500489999999992)
('yuv.max=', 247.762, 'yuv.min=', -32.872480000000003)
('yuv.max=', 184.655, 'yuv.min=', -8.3200300000000027)
('yuv.max=', 222.41799999999995, 'yuv.min=', -16.592839999999995)
('yuv.max=', 255.0, 'yuv.min=', -19.030670000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999992)
('yuv.max=', 214.62400000000002, 'yuv.min=', -22.59066)
('yuv.max=', 255.0, 'yuv.min=', -48.665499999999994)
('yuv.max=', 255.0, 'yuv.min=', -22.218730000000004)
('yuv.max=', 245.08599999999998, 'yuv.min=', -56.115629999999996)
('yuv.max=', 255.0, 'yuv.min=', -25.324150000000003)
('yuv.max=', 255.0, 'yuv.min=', -49.777620000000006)
('yuv.max=', 237.27099999999999, 'yuv.min=', -19.275390000000002)
('yuv.max=', 189.81200000000001, 'yuv.min=', -30.875319999999995)
('yuv.max=', 205.58099999999999, 'yuv.min=', -15.039760000000001)
('yuv.max=', 197.72900000000001, 'yuv.min=', -50.555319999999995)
('yuv.max=', 251.92899999999995, 'yuv.min=', -30.224639999999997)
('yuv.max=', 199.36799999999999, 'yuv.min=', -19.860509999999987)
('yuv.max=', 227.14599999999999, 'yuv.min=', -24.76557)
('yuv.max=', 192.24099999999999, 'yuv.min=', -52.480819999999994)
('yuv.max=', 252.61500000000001, 'yuv.min=', -77.648920000000004)
('yuv.max=', 220.57799999999997, 'yuv.min=', -29.100710000000007)
('yuv.max=', 255.0, 'yuv.min=', -7.2650499999999916)
('yuv.max=', 245.62899999999999, 'yuv.min=', -70.030730000000005)
('yuv.max=', 250.29899999999998, 'yuv.min=', -35.375770000000003)
('yuv.max=', 248.989, 'yuv.min=', -14.544330000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 218.99600000000001, 'yuv.min=', -72.320589999999982)
('yuv.max=', 248.27699999999999, 'yuv.min=', -36.935679999999991)
('yuv.max=', 245.672, 'yuv.min=', -40.921590000000002)
('yuv.max=', 242.58100000000002, 'yuv.min=', -2.3450499999999934)
('yuv.max=', 240.72800000000001, 'yuv.min=', -27.870449999999988)
('yuv.max=', 255.0, 'yuv.min=', -11.255079999999992)
('yuv.max=', 248.91399999999999, 'yuv.min=', -19.825010000000006)
('yuv.max=', 254.10300000000001, 'yuv.min=', -30.405149999999985)
('yuv.max=', 237.45999999999998, 'yuv.min=', -28.866129999999998)
('yuv.max=', 184.113, 'yuv.min=', -22.725119999999997)
('yuv.max=', 225.82599999999996, 'yuv.min=', -32.415120000000002)
('yuv.max=', 252.65799999999999, 'yuv.min=', -14.585289999999995)
('yuv.max=', 248.84700000000001, 'yuv.min=', -15.015209999999986)
('yuv.max=', 226.05800000000002, 'yuv.min=', -38.365699999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.601410000000001)
('yuv.max=', 250.136, 'yuv.min=', -14.821630000000013)
('yuv.max=', 244.32699999999997, 'yuv.min=', -11.755129999999999)
('yuv.max=', 251.37799999999999, 'yuv.min=', -65.272270000000006)
('yuv.max=', 252.71799999999996, 'yuv.min=', -32.430659999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.586700000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.750429999999987)
('yuv.max=', 220.684, 'yuv.min=', -37.825399999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -40.67049999999999)
('yuv.max=', 247.00200000000001, 'yuv.min=', -36.595850000000006)
('yuv.max=', 216.23699999999999, 'yuv.min=', -47.29524)
('yuv.max=', 197.899, 'yuv.min=', -94.360579999999985)
('yuv.max=', 245.07399999999998, 'yuv.min=', -23.066559999999999)
('yuv.max=', 239.19999999999999, 'yuv.min=', -3.0451199999999936)
('yuv.max=', 211.73600000000002, 'yuv.min=', -36.48044999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.305239999999998)
('yuv.max=', 152.08199999999999, 'yuv.min=', -19.36626)
('yuv.max=', 247.33099999999999, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 248.71199999999999, 'yuv.min=', -23.980429999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -38.340389999999999)
('yuv.max=', 185.69299999999998, 'yuv.min=', -37.010379999999998)
('yuv.max=', 242.30200000000002, 'yuv.min=', -22.425089999999997)
('yuv.max=', 234.04900000000001, 'yuv.min=', -37.625379999999993)
('yuv.max=', 238.506, 'yuv.min=', -22.169879999999992)
('yuv.max=', 191.68100000000001, 'yuv.min=', -13.900159999999982)
('yuv.max=', 248.29899999999998, 'yuv.min=', -31.046289999999992)
('yuv.max=', 167.434, 'yuv.min=', -13.300099999999999)
('yuv.max=', 236.47800000000001, 'yuv.min=', -27.440529999999985)
('yuv.max=', 160.45099999999999, 'yuv.min=', -18.375299999999996)
('yuv.max=', 243.15699999999998, 'yuv.min=', -9.3126800000000074)
('yuv.max=', 233.03699999999998, 'yuv.min=', -13.040319999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.375539999999994)
('yuv.max=', 252.93999999999997, 'yuv.min=', -33.18835)
('yuv.max=', 253.97400000000002, 'yuv.min=', -18.645449999999997)
('yuv.max=', 255.0, 'yuv.min=', -3.9223300000000023)
('yuv.max=', 252.41899999999998, 'yuv.min=', -15.260049999999998)
('yuv.max=', 253.41900000000001, 'yuv.min=', -19.880019999999991)
('yuv.max=', 196.72199999999998, 'yuv.min=', -17.775239999999997)
('yuv.max=', 241.76499999999999, 'yuv.min=', -50.980669999999989)
('yuv.max=', 244.33100000000002, 'yuv.min=', -46.820499999999996)
('yuv.max=', 255.0, 'yuv.min=', -30.354750000000003)
('yuv.max=', 206.80599999999998, 'yuv.min=', -13.755329999999997)
('yuv.max=', 253.50099999999998, 'yuv.min=', -38.580659999999988)
('yuv.max=', 242.143, 'yuv.min=', -64.889969999999991)
('yuv.max=', 255.0, 'yuv.min=', -63.165719999999993)
('yuv.max=', 232.83399999999997, 'yuv.min=', -16.800430000000002)
('yuv.max=', 254.07099999999997, 'yuv.min=', -59.169889999999995)
('yuv.max=', 247.15299999999996, 'yuv.min=', -44.000709999999998)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.185, 'yuv.min=', -38.449359999999999)
('yuv.max=', 236.74599999999998, 'yuv.min=', -21.66526)
('yuv.max=', 250.505, 'yuv.min=', -29.085510000000003)
('yuv.max=', 238.41200000000001, 'yuv.min=', -25.785179999999983)
('yuv.max=', 222.45299999999997, 'yuv.min=', -36.802440000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.015009999999998)
('yuv.max=', 255.0, 'yuv.min=', -44.890170000000012)
('yuv.max=', 254.886, 'yuv.min=', -48.56548999999999)
('yuv.max=', 206.41, 'yuv.min=', -15.515259999999994)
('yuv.max=', 243.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.98299999999998, 'yuv.min=', -5.9200999999999926)
('yuv.max=', 250.22999999999999, 'yuv.min=', -36.125229999999988)
('yuv.max=', 239.56599999999997, 'yuv.min=', -88.435909999999993)
('yuv.max=', 225.49000000000001, 'yuv.min=', -43.86045)
('yuv.max=', 214.91799999999998, 'yuv.min=', -38.609770000000005)
('yuv.max=', 253.77199999999999, 'yuv.min=', -60.414829999999988)
('yuv.max=', 237.50999999999996, 'yuv.min=', -1.7483900000000006)
('yuv.max=', 241.70499999999998, 'yuv.min=', -30.945450000000001)
('yuv.max=', 203.41799999999998, 'yuv.min=', -30.630479999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.6499500000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 189.05600000000001, 'yuv.min=', -17.230369999999986)
('yuv.max=', 237.32799999999997, 'yuv.min=', -15.540569999999988)
('yuv.max=', 252.81499999999997, 'yuv.min=', -21.977520000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.708100000000002)
('yuv.max=', 174.95499999999998, 'yuv.min=', -12.055159999999983)
('yuv.max=', 238.00899999999999, 'yuv.min=', -27.665859999999995)
('yuv.max=', 232.93899999999996, 'yuv.min=', -40.257480000000001)
('yuv.max=', 255.0, 'yuv.min=', -9.7639499999999977)
('yuv.max=', 251.53299999999999, 'yuv.min=', -46.365269999999995)
('yuv.max=', 233.977, 'yuv.min=', -23.955119999999994)
('yuv.max=', 238.37699999999998, 'yuv.min=', -27.715249999999987)
('yuv.max=', 192.637, 'yuv.min=', -34.865349999999999)
('yuv.max=', 247.77200000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 217.441, 'yuv.min=', -10.33262)
('yuv.max=', 254.886, 'yuv.min=', -27.274959999999968)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 156.15199999999999, 'yuv.min=', -16.930339999999994)
('yuv.max=', 204.86499999999998, 'yuv.min=', -98.749419999999986)
('yuv.max=', 200.86599999999999, 'yuv.min=', -32.000739999999993)
('yuv.max=', 247.42599999999999, 'yuv.min=', -13.77027)
('yuv.max=', 228.63999999999999, 'yuv.min=', -54.944840000000013)
('yuv.max=', 246.04900000000001, 'yuv.min=', -110.22525999999999)
('yuv.max=', 158.86699999999999, 'yuv.min=', -29.945349999999998)
('yuv.max=', 250.929, 'yuv.min=', -44.930679999999988)
('yuv.max=', 242.68999999999997, 'yuv.min=', -100.92555999999999)
('yuv.max=', 245.91800000000001, 'yuv.min=', -49.473049999999994)
('yuv.max=', 249.28799999999998, 'yuv.min=', -29.253930000000008)
('yuv.max=', 210.357, 'yuv.min=', -66.797670000000011)
('yuv.max=', 224.31299999999999, 'yuv.min=', -24.666039999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.79300000000001, 'yuv.min=', -32.736700000000006)
('yuv.max=', 229.04599999999999, 'yuv.min=', -47.920609999999996)
('yuv.max=', 250.131, 'yuv.min=', -22.441190000000006)
('yuv.max=', 254.202, 'yuv.min=', -33.805489999999992)
('yuv.max=', 224.30500000000001, 'yuv.min=', -27.148570000000007)
('yuv.max=', 211.273, 'yuv.min=', -45.25976)
('yuv.max=', 227.0, 'yuv.min=', -26.015079999999994)
('yuv.max=', 251.05999999999997, 'yuv.min=', -4.3649300000000011)
('yuv.max=', 133.11699999999999, 'yuv.min=', -24.525300000000001)
('yuv.max=', 247.05899999999997, 'yuv.min=', -117.53513)
('yuv.max=', 237.75399999999999, 'yuv.min=', -91.045309999999972)
('yuv.max=', 229.47999999999999, 'yuv.min=', -13.785209999999989)
('yuv.max=', 253.95699999999997, 'yuv.min=', -51.176119999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.84299999999999, 'yuv.min=', -27.830809999999992)
('yuv.max=', 241.16799999999998, 'yuv.min=', -48.719640000000012)
('yuv.max=', 213.63, 'yuv.min=', -19.82025999999999)
('yuv.max=', 247.441, 'yuv.min=', -34.720519999999993)
('yuv.max=', 190.35199999999998, 'yuv.min=', -102.79006999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -34.950419999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.14099999999999, 'yuv.min=', -34.806519999999992)
('yuv.max=', 251.28799999999998, 'yuv.min=', -19.465039999999998)
('yuv.max=', 255.0, 'yuv.min=', -68.622959999999992)
('yuv.max=', 246.90699999999998, 'yuv.min=', -41.685540000000003)
('yuv.max=', 225.03299999999999, 'yuv.min=', -41.657730000000008)
('yuv.max=', 251.69400000000002, 'yuv.min=', -72.417450000000002)
('yuv.max=', 231.70599999999999, 'yuv.min=', -20.244309999999999)
('yuv.max=', 252.64099999999996, 'yuv.min=', -27.635420000000007)
('yuv.max=', 241.49899999999997, 'yuv.min=', -16.560179999999985)
('yuv.max=', 169.755, 'yuv.min=', -60.258319999999998)
('yuv.max=', 247.33099999999999, 'yuv.min=', -82.275539999999978)
('yuv.max=', 250.501, 'yuv.min=', -25.54034)
('yuv.max=', 191.774, 'yuv.min=', -23.365429999999996)
('yuv.max=', 255.0, 'yuv.min=', -49.516199999999998)
('yuv.max=', 239.25999999999999, 'yuv.min=', -40.555549999999982)
('yuv.max=', 255.0, 'yuv.min=', -35.694690000000001)
('yuv.max=', 229.63899999999998, 'yuv.min=', -49.879329999999996)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.525300000000001)
('yuv.max=', 232.50399999999999, 'yuv.min=', -45.750329999999998)
('yuv.max=', 229.85099999999997, 'yuv.min=', -48.631050000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.785849999999996)
('yuv.max=', 251.57599999999999, 'yuv.min=', -30.160309999999981)
('yuv.max=', 207.273, 'yuv.min=', -16.930339999999994)
('yuv.max=', 252.114, 'yuv.min=', -35.255240000000001)
('yuv.max=', 196.22199999999998, 'yuv.min=', -87.164210000000011)
('yuv.max=', 252.31999999999999, 'yuv.min=', -18.375299999999985)
('yuv.max=', 255.0, 'yuv.min=', -40.955589999999994)
('yuv.max=', 180.10499999999999, 'yuv.min=', -71.249809999999997)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 188.11199999999997, 'yuv.min=', -24.499649999999995)
('yuv.max=', 252.78899999999999, 'yuv.min=', -5.2349699999999828)
('yuv.max=', 254.40199999999999, 'yuv.min=', -45.805459999999997)
('yuv.max=', 236.05299999999997, 'yuv.min=', -30.230439999999991)
('yuv.max=', 63.748999999999995, 'yuv.min=', -20.615769999999998)
('yuv.max=', 249.00200000000001, 'yuv.min=', -29.358110000000003)
('yuv.max=', 255.0, 'yuv.min=', -16.458150000000003)
('yuv.max=', 212.80199999999996, 'yuv.min=', -20.920370000000002)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.825559999999996)
('yuv.max=', 188.03099999999998, 'yuv.min=', -75.785079999999994)
('yuv.max=', 226.29399999999998, 'yuv.min=', -63.885299999999987)
('yuv.max=', 212.178, 'yuv.min=', -25.595529999999993)
('yuv.max=', 229.51499999999999, 'yuv.min=', -54.375209999999988)
('yuv.max=', 214.45599999999999, 'yuv.min=', -38.839979999999997)
('yuv.max=', 181.92899999999997, 'yuv.min=', -21.237370000000002)
('yuv.max=', 219.327, 'yuv.min=', -49.56559)
('yuv.max=', 247.53700000000001, 'yuv.min=', -35.665429999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 223.78700000000001, 'yuv.min=', -40.080809999999992)
('yuv.max=', 244.18499999999997, 'yuv.min=', -21.095079999999996)
('yuv.max=', 143.517, 'yuv.min=', -42.01088)
('yuv.max=', 255.0, 'yuv.min=', -27.600570000000001)
('yuv.max=', 192.18099999999998, 'yuv.min=', -32.044340000000005)
('yuv.max=', 255.0, 'yuv.min=', -56.678540000000005)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 236.233, 'yuv.min=', -77.883540000000011)
('yuv.max=', 205.24299999999999, 'yuv.min=', -18.145399999999995)
('yuv.max=', 242.55699999999999, 'yuv.min=', -67.600609999999989)
('yuv.max=', 231.25899999999999, 'yuv.min=', -82.717879999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.309740000000001)
('yuv.max=', 234.99399999999997, 'yuv.min=', -33.939950000000003)
('yuv.max=', 180.321, 'yuv.min=', -20.370930000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.044520000000002)
('yuv.max=', 250.01099999999997, 'yuv.min=', -14.293480000000002)
('yuv.max=', 178.70099999999999, 'yuv.min=', -32.635249999999985)
('yuv.max=', 243.45199999999997, 'yuv.min=', -61.364469999999997)
('yuv.max=', 253.20599999999999, 'yuv.min=', -62.350699999999996)
('yuv.max=', 199.59699999999998, 'yuv.min=', -42.851210000000002)
('yuv.max=', 252.47299999999998, 'yuv.min=', -52.066810000000004)
('yuv.max=', 254.58699999999999, 'yuv.min=', -34.86694)
('yuv.max=', 251.48399999999998, 'yuv.min=', -10.05368)
('yuv.max=', 211.66699999999997, 'yuv.min=', -41.670599999999993)
('yuv.max=', 206.07199999999997, 'yuv.min=', -41.370569999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999988)
('yuv.max=', 255.0, 'yuv.min=', -9.1399299999999997)
('yuv.max=', 222.41900000000001, 'yuv.min=', -28.981339999999999)
('yuv.max=', 239.36099999999999, 'yuv.min=', -50.895449999999997)
('yuv.max=', 145.697, 'yuv.min=', -56.900769999999994)
('yuv.max=', 232.08199999999997, 'yuv.min=', -3.4919300000000106)
('yuv.max=', 255.0, 'yuv.min=', -8.6099999999999888)
('yuv.max=', 240.49900000000002, 'yuv.min=', -18.890289999999993)
('yuv.max=', 237.13299999999998, 'yuv.min=', -28.285429999999991)
('yuv.max=', 242.19999999999999, 'yuv.min=', -40.970529999999997)
('yuv.max=', 221.41399999999999, 'yuv.min=', -30.97533)
('yuv.max=', 236.49399999999997, 'yuv.min=', -60.005649999999996)
('yuv.max=', 245.33099999999996, 'yuv.min=', -6.8650099999999945)
('yuv.max=', 250.01099999999997, 'yuv.min=', -36.360820000000004)
('yuv.max=', 218.57499999999999, 'yuv.min=', -35.360829999999993)
('yuv.max=', 253.886, 'yuv.min=', -17.720050000000001)
('yuv.max=', 241.715, 'yuv.min=', -21.250279999999993)
('yuv.max=', 184.839, 'yuv.min=', -22.180249999999997)
('yuv.max=', 237.596, 'yuv.min=', -54.605109999999982)
('yuv.max=', 235.57599999999999, 'yuv.min=', -78.955699999999993)
('yuv.max=', 246.33099999999999, 'yuv.min=', -46.84581)
('yuv.max=', 255.0, 'yuv.min=', -21.566479999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.415419999999997)
('yuv.max=', 248.804, 'yuv.min=', -29.861509999999999)
('yuv.max=', 199.14199999999997, 'yuv.min=', -20.77467)
('yuv.max=', 221.988, 'yuv.min=', -38.546260000000004)
('yuv.max=', 234.28800000000001, 'yuv.min=', -23.912640000000007)
('yuv.max=', 135.11399999999998, 'yuv.min=', -16.716610000000003)
('yuv.max=', 255.0, 'yuv.min=', -27.074939999999991)
('yuv.max=', 250.79300000000001, 'yuv.min=', -51.75544)
('yuv.max=', 217.77299999999997, 'yuv.min=', -51.010549999999981)
('yuv.max=', 235.08299999999997, 'yuv.min=', -13.685199999999995)
('yuv.max=', 222.04900000000001, 'yuv.min=', -29.130329999999997)
('yuv.max=', 255.0, 'yuv.min=', -36.339219999999997)
('yuv.max=', 253.63200000000001, 'yuv.min=', -51.581020000000002)
('yuv.max=', 253.25599999999997, 'yuv.min=', -36.614909999999995)
('yuv.max=', 222.61899999999997, 'yuv.min=', -106.10343)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.033449999999995)
('yuv.max=', 253.77199999999999, 'yuv.min=', -32.33522)
('yuv.max=', 223.42799999999997, 'yuv.min=', -26.423940000000002)
('yuv.max=', 255.0, 'yuv.min=', -58.895169999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.006240000000005)
('yuv.max=', 247.00599999999997, 'yuv.min=', -91.160259999999994)
('yuv.max=', 225.797, 'yuv.min=', -48.120629999999991)
('yuv.max=', 223.02399999999997, 'yuv.min=', -60.980439999999994)
('yuv.max=', 219.81999999999999, 'yuv.min=', -36.701210000000003)
('yuv.max=', 255.0, 'yuv.min=', -93.235680000000002)
('yuv.max=', 233.52699999999996, 'yuv.min=', -41.455639999999988)
('yuv.max=', 224.12299999999996, 'yuv.min=', -25.372779999999999)
('yuv.max=', 234.369, 'yuv.min=', -29.973199999999999)
('yuv.max=', 255.0, 'yuv.min=', -14.549430000000001)
('yuv.max=', 179.13999999999999, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 245.20999999999998, 'yuv.min=', -29.545309999999997)
('yuv.max=', 230.11199999999999, 'yuv.min=', -5.7902099999999876)
('yuv.max=', 226.88200000000001, 'yuv.min=', -65.270499999999998)
('yuv.max=', 207.84299999999999, 'yuv.min=', -15.853250000000001)
('yuv.max=', 253.21699999999998, 'yuv.min=', -87.591009999999983)
('yuv.max=', 243.804, 'yuv.min=', -29.11186)
('yuv.max=', 252.00999999999999, 'yuv.min=', -57.21573999999999)
('yuv.max=', 233.94, 'yuv.min=', -1.0150399999999999)
('yuv.max=', 248.815, 'yuv.min=', -15.885419999999989)
('yuv.max=', 253.0, 'yuv.min=', -75.855509999999995)
('yuv.max=', 235.83999999999997, 'yuv.min=', -55.415559999999999)
('yuv.max=', 245.33999999999997, 'yuv.min=', -38.104830000000007)
('yuv.max=', 255.0, 'yuv.min=', -85.960079999999991)
('yuv.max=', 207.55399999999997, 'yuv.min=', -47.269770000000008)
('yuv.max=', 255.0, 'yuv.min=', -73.810369999999992)
('yuv.max=', 222.34, 'yuv.min=', -9.5353999999999921)
('yuv.max=', 227.81399999999999, 'yuv.min=', -28.645219999999995)
('yuv.max=', 228.11799999999999, 'yuv.min=', -85.665509999999998)
('yuv.max=', 192.10400000000001, 'yuv.min=', -112.75749999999999)
('yuv.max=', 229.16800000000001, 'yuv.min=', -19.062220000000011)
('yuv.max=', 204.91800000000001, 'yuv.min=', -34.450369999999978)
('yuv.max=', 255.0, 'yuv.min=', -83.719490000000008)
('yuv.max=', 236.44499999999999, 'yuv.min=', -36.495389999999993)
('yuv.max=', 174.11799999999999, 'yuv.min=', -11.855139999999999)
('yuv.max=', 220.78199999999998, 'yuv.min=', -47.050399999999982)
('yuv.max=', 201.69699999999997, 'yuv.min=', -31.960489999999993)
('yuv.max=', 255.0, 'yuv.min=', -22.221220000000002)
('yuv.max=', 240.24499999999998, 'yuv.min=', -24.640249999999991)
('yuv.max=', 224.02100000000002, 'yuv.min=', -35.783100000000005)
('yuv.max=', 252.17400000000001, 'yuv.min=', -32.490419999999986)
('yuv.max=', 236.52000000000001, 'yuv.min=', -25.625409999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.227360000000004)
('yuv.max=', 238.60799999999998, 'yuv.min=', -48.450539999999982)
('yuv.max=', 233.99099999999999, 'yuv.min=', -17.205059999999989)
('yuv.max=', 253.25599999999997, 'yuv.min=', -47.773820000000001)
('yuv.max=', 186.19899999999998, 'yuv.min=', -81.705359999999985)
('yuv.max=', 227.38, 'yuv.min=', -18.08436)
('yuv.max=', 223.00699999999998, 'yuv.min=', -41.93618)
('yuv.max=', 254.40199999999999, 'yuv.min=', -65.255209999999991)
('yuv.max=', 238.53499999999997, 'yuv.min=', -88.695689999999985)
('yuv.max=', 245.03199999999998, 'yuv.min=', -27.929869999999998)
('yuv.max=', 231.02599999999998, 'yuv.min=', -44.045530000000007)
('yuv.max=', 127.95, 'yuv.min=', -40.555549999999997)
('yuv.max=', 225.86199999999999, 'yuv.min=', -25.840370000000004)
('yuv.max=', 176.495, 'yuv.min=', -19.094879999999996)
('yuv.max=', 255.0, 'yuv.min=', -14.100179999999991)
('yuv.max=', 253.0, 'yuv.min=', -19.135129999999993)
('yuv.max=', 246.09700000000001, 'yuv.min=', -15.56588)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -23.237720000000007)
('yuv.max=', 254.18499999999997, 'yuv.min=', -67.730499999999992)
('yuv.max=', 234.70299999999997, 'yuv.min=', -62.220809999999993)
('yuv.max=', 245.63, 'yuv.min=', -8.6099999999999959)
('yuv.max=', 255.0, 'yuv.min=', -13.315039999999996)
('yuv.max=', 207.40299999999999, 'yuv.min=', -10.425119999999989)
('yuv.max=', 174.38499999999999, 'yuv.min=', -35.30563999999999)
('yuv.max=', 252.63, 'yuv.min=', -37.89552999999998)
('yuv.max=', 215.02599999999998, 'yuv.min=', -82.183120000000002)
('yuv.max=', 252.608, 'yuv.min=', -36.835669999999986)
('yuv.max=', 255.0, 'yuv.min=', -26.840470000000003)
('yuv.max=', 251.24699999999999, 'yuv.min=', -26.25535)
('yuv.max=', 250.18499999999997, 'yuv.min=', -31.504259999999999)
('yuv.max=', 232.93099999999998, 'yuv.min=', -16.255809999999997)
('yuv.max=', 216.87899999999999, 'yuv.min=', -21.080139999999993)
('yuv.max=', 235.08199999999999, 'yuv.min=', -25.308600000000002)
('yuv.max=', 252.989, 'yuv.min=', -40.25551999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.705009999999991)
('yuv.max=', 245.98399999999998, 'yuv.min=', -49.950689999999994)
('yuv.max=', 238.28799999999998, 'yuv.min=', -15.280210000000004)
('yuv.max=', 239.488, 'yuv.min=', -15.215229999999991)
('yuv.max=', 252.28800000000001, 'yuv.min=', -21.253010000000003)
('yuv.max=', 199.90600000000001, 'yuv.min=', -49.695479999999989)
('yuv.max=', 242.79299999999998, 'yuv.min=', -23.110219999999998)
('yuv.max=', 207.19099999999997, 'yuv.min=', -9.0399199999999897)
('yuv.max=', 210.55700000000002, 'yuv.min=', -15.133760000000001)
('yuv.max=', 255.0, 'yuv.min=', -8.7227000000000032)
('yuv.max=', 243.19499999999999, 'yuv.min=', -27.770439999999997)
('yuv.max=', 246.48399999999998, 'yuv.min=', -37.355649999999997)
('yuv.max=', 239.89699999999999, 'yuv.min=', -20.775539999999992)
('yuv.max=', 178.82099999999997, 'yuv.min=', -11.046079999999996)
('yuv.max=', 225.01799999999997, 'yuv.min=', -72.35136)
('yuv.max=', 255.0, 'yuv.min=', -46.439970000000002)
('yuv.max=', 255.0, 'yuv.min=', -48.453850000000003)
('yuv.max=', 189.88999999999999, 'yuv.min=', -11.077830000000006)
('yuv.max=', 222.26399999999998, 'yuv.min=', -23.380369999999999)
('yuv.max=', 231.24899999999997, 'yuv.min=', -46.650359999999992)
('yuv.max=', 163.60899999999998, 'yuv.min=', -1.5954600000000028)
('yuv.max=', 239.09299999999996, 'yuv.min=', -26.352980000000002)
('yuv.max=', 244.89200000000002, 'yuv.min=', -86.550660000000008)
('yuv.max=', 240.28800000000001, 'yuv.min=', -14.95364)
('yuv.max=', 248.59799999999998, 'yuv.min=', -44.460509999999999)
('yuv.max=', 247.28400000000002, 'yuv.min=', -27.315209999999983)
('yuv.max=', 209.727, 'yuv.min=', -39.428609999999999)
('yuv.max=', 217.02199999999999, 'yuv.min=', -32.260519999999993)
('yuv.max=', 250.51999999999998, 'yuv.min=', -25.444710000000004)
('yuv.max=', 211.74299999999999, 'yuv.min=', -10.641559999999998)
('yuv.max=', 242.06799999999998, 'yuv.min=', -53.479530000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.66187)
('yuv.max=', 229.94599999999997, 'yuv.min=', -51.310580000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.365979999999993)
('yuv.max=', 205.94499999999999, 'yuv.min=', -53.565489999999997)
('yuv.max=', 215.08600000000001, 'yuv.min=', -30.382569999999998)
('yuv.max=', 232.66200000000001, 'yuv.min=', -26.615139999999997)
('yuv.max=', 251.41199999999998, 'yuv.min=', -20.680099999999996)
('yuv.max=', 250.06399999999996, 'yuv.min=', -22.571820000000002)
('yuv.max=', 233.91499999999999, 'yuv.min=', -42.01544999999998)
('yuv.max=', 198.041, 'yuv.min=', -31.022600000000004)
('yuv.max=', 224.36799999999997, 'yuv.min=', -53.255589999999998)
('yuv.max=', 247.34199999999998, 'yuv.min=', -27.440529999999992)
('yuv.max=', 239.44099999999997, 'yuv.min=', -38.740429999999989)
('yuv.max=', 218.006, 'yuv.min=', -28.44791)
('yuv.max=', 242.82599999999999, 'yuv.min=', -15.030149999999997)
('yuv.max=', 235.90399999999997, 'yuv.min=', -35.015029999999996)
('yuv.max=', 200.05099999999999, 'yuv.min=', -23.306490000000004)
('yuv.max=', 230.85999999999999, 'yuv.min=', -79.800599999999989)
('yuv.max=', 246.93900000000002, 'yuv.min=', -39.070339999999987)
('yuv.max=', 150.93699999999998, 'yuv.min=', -58.034939999999999)
('yuv.max=', 251.113, 'yuv.min=', -70.935389999999984)
('yuv.max=', 131.19800000000001, 'yuv.min=', -13.95478)
('yuv.max=', 252.49200000000002, 'yuv.min=', -57.729520000000008)
('yuv.max=', 228.09599999999998, 'yuv.min=', -55.26493)
('yuv.max=', 214.042, 'yuv.min=', -10.454999999999981)
('yuv.max=', 216.50900000000001, 'yuv.min=', -14.40020999999998)
('yuv.max=', 241.75599999999997, 'yuv.min=', -64.875029999999995)
('yuv.max=', 237.59799999999998, 'yuv.min=', -67.885699999999986)
('yuv.max=', 234.48099999999999, 'yuv.min=', -44.040289999999999)
('yuv.max=', 170.94399999999999, 'yuv.min=', -53.201340000000002)
('yuv.max=', 227.58999999999997, 'yuv.min=', -38.570289999999993)
('yuv.max=', 249.30099999999999, 'yuv.min=', -31.154830000000004)
('yuv.max=', 238.94999999999999, 'yuv.min=', -23.574660000000002)
('yuv.max=', 217.64699999999999, 'yuv.min=', -56.670869999999994)
('yuv.max=', 249.733, 'yuv.min=', -34.535439999999994)
('yuv.max=', 203.46899999999999, 'yuv.min=', -9.4540900000000008)
('yuv.max=', 255.0, 'yuv.min=', -6.9799599999999966)
('yuv.max=', 181.749, 'yuv.min=', -14.930139999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -21.050259999999991)
('yuv.max=', 247.548, 'yuv.min=', -26.415119999999995)
('yuv.max=', 255.0, 'yuv.min=', -77.486040000000003)
('yuv.max=', 251.79299999999998, 'yuv.min=', -18.479309999999998)
('yuv.max=', 225.642, 'yuv.min=', -36.735659999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.305540000000008)
('yuv.max=', 207.23299999999998, 'yuv.min=', -29.913629999999998)
('yuv.max=', 211.85099999999997, 'yuv.min=', -35.432960000000008)
('yuv.max=', 242.821, 'yuv.min=', -40.67569000000001)
('yuv.max=', 226.28999999999999, 'yuv.min=', -21.635379999999998)
('yuv.max=', 222.82499999999999, 'yuv.min=', -44.045529999999999)
('yuv.max=', 237.41199999999998, 'yuv.min=', -31.475379999999994)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.95599)
('yuv.max=', 217.57899999999998, 'yuv.min=', -36.140169999999991)
('yuv.max=', 252.52699999999996, 'yuv.min=', -23.580389999999987)
('yuv.max=', 245.49799999999999, 'yuv.min=', -24.225269999999988)
('yuv.max=', 236.18899999999999, 'yuv.min=', -14.930139999999984)
('yuv.max=', 241.63199999999998, 'yuv.min=', -38.435920000000003)
('yuv.max=', 248.21800000000002, 'yuv.min=', -16.609940000000002)
('yuv.max=', 244.85299999999998, 'yuv.min=', -63.065709999999989)
('yuv.max=', 235.63399999999999, 'yuv.min=', -49.370200000000011)
('yuv.max=', 236.04500000000002, 'yuv.min=', -34.180219999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.683690000000004)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.48400000000001, 'yuv.min=', -87.280609999999996)
('yuv.max=', 219.21799999999999, 'yuv.min=', -20.555190000000003)
('yuv.max=', 255.0, 'yuv.min=', -72.842430000000007)
('yuv.max=', 230.12899999999996, 'yuv.min=', -16.375100000000003)
('yuv.max=', 105.67999999999999, 'yuv.min=', -7.6708899999999964)
('yuv.max=', 238.51199999999997, 'yuv.min=', -79.229519999999994)
('yuv.max=', 236.084, 'yuv.min=', -73.392080000000007)
('yuv.max=', 253.77199999999999, 'yuv.min=', -39.38530999999999)
('yuv.max=', 201.33099999999999, 'yuv.min=', -52.291040000000002)
('yuv.max=', 248.38999999999999, 'yuv.min=', -37.149919999999995)
('yuv.max=', 253.505, 'yuv.min=', -29.300469999999994)
('yuv.max=', 207.416, 'yuv.min=', -8.3367199999999997)
('yuv.max=', 248.48799999999997, 'yuv.min=', -21.905529999999988)
('yuv.max=', 243.619, 'yuv.min=', -24.795449999999988)
('yuv.max=', 192.15600000000001, 'yuv.min=', -22.035419999999984)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.435570000000002)
('yuv.max=', 243.22800000000001, 'yuv.min=', -44.990439999999985)
('yuv.max=', 219.06999999999999, 'yuv.min=', -17.820059999999994)
('yuv.max=', 212.80399999999997, 'yuv.min=', -95.51948999999999)
('yuv.max=', 227.25299999999999, 'yuv.min=', -19.175379999999997)
('yuv.max=', 247.81699999999998, 'yuv.min=', -23.780409999999989)
('yuv.max=', 196.797, 'yuv.min=', -17.219999999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 255.0, 'yuv.min=', -30.273140000000001)
('yuv.max=', 255.0, 'yuv.min=', -10.162979999999997)
('yuv.max=', 195.47699999999998, 'yuv.min=', -24.12525999999999)
('yuv.max=', 242.03699999999998, 'yuv.min=', -27.407880000000002)
('yuv.max=', 248.33099999999999, 'yuv.min=', -55.920179999999988)
('yuv.max=', 247.529, 'yuv.min=', -52.325619999999994)
('yuv.max=', 123.985, 'yuv.min=', -9.3020399999999981)
('yuv.max=', 240.37899999999999, 'yuv.min=', -47.587590000000006)
('yuv.max=', 241.20399999999998, 'yuv.min=', -41.951610000000002)
('yuv.max=', 224.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.26399999999995, 'yuv.min=', -39.101939999999999)
('yuv.max=', 245.684, 'yuv.min=', -54.920079999999992)
('yuv.max=', 226.62099999999998, 'yuv.min=', -101.91767)
('yuv.max=', 247.68499999999997, 'yuv.min=', -45.701189999999997)
('yuv.max=', 240.38099999999997, 'yuv.min=', -17.323450000000001)
('yuv.max=', 188.13599999999997, 'yuv.min=', -16.245209999999997)
('yuv.max=', 210.38999999999999, 'yuv.min=', -34.566549999999992)
('yuv.max=', 242.44200000000001, 'yuv.min=', -65.970569999999981)
('yuv.max=', 255.0, 'yuv.min=', -11.399909999999997)
('yuv.max=', 243.05599999999998, 'yuv.min=', -33.330269999999999)
('yuv.max=', 234.542, 'yuv.min=', -13.378679999999999)
('yuv.max=', 247.95000000000002, 'yuv.min=', -64.106090000000009)
('yuv.max=', 196.00999999999999, 'yuv.min=', -27.400279999999988)
('yuv.max=', 242.24299999999999, 'yuv.min=', -55.544059999999995)
('yuv.max=', 248.07499999999996, 'yuv.min=', -46.739999999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.84836)
('yuv.max=', 242.03299999999999, 'yuv.min=', -95.035339999999991)
('yuv.max=', 236.25699999999998, 'yuv.min=', -15.968030000000001)
('yuv.max=', 212.0, 'yuv.min=', -18.778709999999997)
('yuv.max=', 255.0, 'yuv.min=', -14.43074)
('yuv.max=', 253.08799999999999, 'yuv.min=', -17.41545)
('yuv.max=', 250.03200000000001, 'yuv.min=', -23.259359999999997)
('yuv.max=', 255.0, 'yuv.min=', -25.810489999999991)
('yuv.max=', 223.07099999999997, 'yuv.min=', -6.4241700000000037)
('yuv.max=', 255.0, 'yuv.min=', -40.964729999999996)
('yuv.max=', 245.09100000000001, 'yuv.min=', -79.883209999999991)
('yuv.max=', 226.05800000000002, 'yuv.min=', -44.960300000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.485249999999994)
('yuv.max=', 199.35899999999998, 'yuv.min=', -29.245279999999987)
('yuv.max=', 224.85799999999998, 'yuv.min=', -25.025349999999992)
('yuv.max=', 241.334, 'yuv.min=', -31.60526999999999)
('yuv.max=', 230.06899999999996, 'yuv.min=', -27.904899999999984)
('yuv.max=', 230.37399999999997, 'yuv.min=', -14.467530000000004)
('yuv.max=', 231.28800000000001, 'yuv.min=', -91.785629999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.665430000000001)
('yuv.max=', 203.69, 'yuv.min=', -35.465409999999999)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 252.89699999999999, 'yuv.min=', -21.395109999999995)
('yuv.max=', 205.94999999999999, 'yuv.min=', -47.216260000000005)
('yuv.max=', 242.643, 'yuv.min=', -32.99960999999999)
('yuv.max=', 194.29499999999999, 'yuv.min=', -38.525469999999991)
('yuv.max=', 253.82599999999996, 'yuv.min=', -14.740220000000001)
('yuv.max=', 192.072, 'yuv.min=', -21.411070000000002)
('yuv.max=', 253.72899999999996, 'yuv.min=', -24.578320000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.910920000000004)
('yuv.max=', 219.40799999999996, 'yuv.min=', -116.92012999999999)
('yuv.max=', 211.79900000000001, 'yuv.min=', -41.375139999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.493200000000002)
('yuv.max=', 254.131, 'yuv.min=', -30.560349999999993)
('yuv.max=', 249.84299999999999, 'yuv.min=', -32.3887)
('yuv.max=', 198.529, 'yuv.min=', -70.835379999999986)
('yuv.max=', 255.0, 'yuv.min=', -1.1299899999999941)
('yuv.max=', 194.81399999999999, 'yuv.min=', -20.337510000000009)
('yuv.max=', 192.91200000000001, 'yuv.min=', -12.540269999999996)
('yuv.max=', 146.27700000000002, 'yuv.min=', -15.400309999999994)
('yuv.max=', 243.0, 'yuv.min=', -37.465609999999998)
('yuv.max=', 251.77199999999999, 'yuv.min=', -15.302290000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.9949999999999868)
('yuv.max=', 255.0, 'yuv.min=', -22.695239999999988)
('yuv.max=', 246.64999999999998, 'yuv.min=', -42.645389999999992)
('yuv.max=', 252.48999999999998, 'yuv.min=', -26.310539999999996)
('yuv.max=', 214.328, 'yuv.min=', -10.925310000000003)
('yuv.max=', 231.85399999999996, 'yuv.min=', -18.43506)
('yuv.max=', 182.50099999999998, 'yuv.min=', -24.865579999999984)
('yuv.max=', 209.06799999999998, 'yuv.min=', -31.111840000000008)
('yuv.max=', 217.86399999999998, 'yuv.min=', -31.145469999999996)
('yuv.max=', 232.14399999999998, 'yuv.min=', -30.890259999999998)
('yuv.max=', 169.60999999999999, 'yuv.min=', -32.811630000000001)
('yuv.max=', 232.38399999999996, 'yuv.min=', -45.554819999999999)
('yuv.max=', 247.47099999999998, 'yuv.min=', -66.580080000000009)
('yuv.max=', 253.80399999999997, 'yuv.min=', -12.670159999999989)
('yuv.max=', 178.28799999999998, 'yuv.min=', -17.182500000000001)
('yuv.max=', 206.29399999999998, 'yuv.min=', -27.455469999999995)
('yuv.max=', 235.06, 'yuv.min=', -17.260249999999999)
('yuv.max=', 223.10199999999998, 'yuv.min=', -17.186849999999993)
('yuv.max=', 255.0, 'yuv.min=', -38.334159999999997)
('yuv.max=', 248.70099999999999, 'yuv.min=', -32.475479999999997)
('yuv.max=', 167.815, 'yuv.min=', -79.626850000000005)
('yuv.max=', 146.19699999999997, 'yuv.min=', -14.600230000000003)
('yuv.max=', 253.70099999999996, 'yuv.min=', -25.250679999999996)
('yuv.max=', 234.03200000000001, 'yuv.min=', -12.814989999999996)
('yuv.max=', 253.52699999999999, 'yuv.min=', -5.2200299999999995)
('yuv.max=', 235.90299999999999, 'yuv.min=', -29.672900000000006)
('yuv.max=', 201.715, 'yuv.min=', -38.325449999999996)
('yuv.max=', 226.67499999999998, 'yuv.min=', -27.800320000000003)
('yuv.max=', 252.0, 'yuv.min=', -9.4534699999999958)
('yuv.max=', 250.12700000000001, 'yuv.min=', -21.384009999999996)
('yuv.max=', 237.32299999999998, 'yuv.min=', -31.890359999999994)
('yuv.max=', 249.78200000000001, 'yuv.min=', -36.925309999999996)
('yuv.max=', 249.05299999999997, 'yuv.min=', -58.871089999999995)
('yuv.max=', 241.548, 'yuv.min=', -39.805400000000006)
('yuv.max=', 239.27099999999999, 'yuv.min=', -80.000619999999998)
('yuv.max=', 255.0, 'yuv.min=', -53.540679999999988)
('yuv.max=', 234.70400000000001, 'yuv.min=', -23.961909999999996)
('yuv.max=', 128.86499999999998, 'yuv.min=', -35.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -62.120799999999988)
('yuv.max=', 208.19599999999997, 'yuv.min=', -26.280659999999994)
('yuv.max=', 205.57599999999999, 'yuv.min=', -24.610369999999993)
('yuv.max=', 255.0, 'yuv.min=', -21.150270000000003)
('yuv.max=', 232.017, 'yuv.min=', -58.709830000000011)
('yuv.max=', 242.91799999999998, 'yuv.min=', -27.210629999999995)
('yuv.max=', 231.14199999999997, 'yuv.min=', -73.805800000000005)
('yuv.max=', 242.68999999999997, 'yuv.min=', -15.849739999999994)
('yuv.max=', 234.214, 'yuv.min=', -24.265519999999999)
('yuv.max=', 252.036, 'yuv.min=', -36.48044999999999)
('yuv.max=', 187.53, 'yuv.min=', -42.685639999999999)
('yuv.max=', 224.88299999999998, 'yuv.min=', -43.945520000000002)
('yuv.max=', 246.55199999999999, 'yuv.min=', -18.064899999999994)
('yuv.max=', 244.47300000000001, 'yuv.min=', -60.020589999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.619660000000007)
('yuv.max=', 246.95999999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -32.061410000000009)
('yuv.max=', 242.91799999999998, 'yuv.min=', -20.675010000000015)
('yuv.max=', 231.86600000000001, 'yuv.min=', -15.421110000000013)
('yuv.max=', 237.21599999999998, 'yuv.min=', -40.137010000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.86900000000003, 'yuv.min=', -40.825699999999991)
('yuv.max=', 246.744, 'yuv.min=', -38.755369999999992)
('yuv.max=', 223.72900000000001, 'yuv.min=', -40.640619999999998)
('yuv.max=', 226.68799999999999, 'yuv.min=', -34.044260000000001)
('yuv.max=', 251.44499999999996, 'yuv.min=', -9.3652599999999957)
('yuv.max=', 161.93999999999997, 'yuv.min=', -9.7436700000000052)
('yuv.max=', 254.35900000000001, 'yuv.min=', -55.021319999999996)
('yuv.max=', 252.68599999999998, 'yuv.min=', -20.641079999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.936579999999999)
('yuv.max=', 186.77199999999999, 'yuv.min=', -20.937799999999999)
('yuv.max=', 169.56800000000001, 'yuv.min=', -36.26549)
('yuv.max=', 219.88099999999997, 'yuv.min=', -56.159570000000002)
('yuv.max=', 218.16, 'yuv.min=', -49.211160000000007)
('yuv.max=', 243.33099999999999, 'yuv.min=', -27.85435)
('yuv.max=', 182.37299999999999, 'yuv.min=', -41.445269999999994)
('yuv.max=', 240.19499999999996, 'yuv.min=', -25.706570000000003)
('yuv.max=', 255.0, 'yuv.min=', -32.335219999999993)
('yuv.max=', 247.70699999999999, 'yuv.min=', -61.603790000000004)
('yuv.max=', 219.13999999999999, 'yuv.min=', -15.730220000000003)
('yuv.max=', 251.50500000000002, 'yuv.min=', -57.767760000000003)
('yuv.max=', 187.43100000000001, 'yuv.min=', -27.967719999999996)
('yuv.max=', 251.48399999999998, 'yuv.min=', -42.25571999999999)
('yuv.max=', 233.46299999999997, 'yuv.min=', -29.000439999999998)
('yuv.max=', 226.22799999999998, 'yuv.min=', -26.31510999999999)
('yuv.max=', 242.75500000000002, 'yuv.min=', -38.355329999999995)
('yuv.max=', 236.22799999999998, 'yuv.min=', -26.855409999999988)
('yuv.max=', 230.02699999999999, 'yuv.min=', -51.791119999999992)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 241.12099999999998, 'yuv.min=', -19.383939999999996)
('yuv.max=', 252.202, 'yuv.min=', -20.348179999999999)
('yuv.max=', 250.18499999999997, 'yuv.min=', -34.584829999999997)
('yuv.max=', 235.73599999999999, 'yuv.min=', -60.085030000000003)
('yuv.max=', 255.0, 'yuv.min=', -18.820159999999984)
('yuv.max=', 223.87900000000002, 'yuv.min=', -42.414560000000009)
('yuv.max=', 254.17400000000001, 'yuv.min=', -65.695849999999993)
('yuv.max=', 233.31799999999998, 'yuv.min=', -19.090309999999995)
('yuv.max=', 188.881, 'yuv.min=', -81.343759999999989)
('yuv.max=', 164.822, 'yuv.min=', -54.030360000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.24399999999997, 'yuv.min=', -109.02513999999999)
('yuv.max=', 255.0, 'yuv.min=', -56.073400000000007)
('yuv.max=', 241.14600000000002, 'yuv.min=', -49.21623000000001)
('yuv.max=', 169.10899999999998, 'yuv.min=', -44.354190000000003)
('yuv.max=', 255.0, 'yuv.min=', -14.144999999999992)
('yuv.max=', 249.01999999999998, 'yuv.min=', -56.35132999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', -22.705609999999989)
('yuv.max=', 186.97799999999998, 'yuv.min=', -37.480549999999994)
('yuv.max=', 251.113, 'yuv.min=', -37.749150000000007)
('yuv.max=', 210.34799999999998, 'yuv.min=', -25.840369999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.400649999999999)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 203.17999999999998, 'yuv.min=', -52.731660000000005)
('yuv.max=', 246.08299999999997, 'yuv.min=', -9.4319400000000115)
('yuv.max=', 218.84199999999998, 'yuv.min=', -52.824670000000012)
('yuv.max=', 247.078, 'yuv.min=', -34.282920000000004)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.350070000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 210.542, 'yuv.min=', -58.39054999999999)
('yuv.max=', 239.94999999999999, 'yuv.min=', -20.605399999999996)
('yuv.max=', 239.14699999999999, 'yuv.min=', -32.535240000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.415219999999998)
('yuv.max=', 239.29999999999998, 'yuv.min=', -22.827349999999999)
('yuv.max=', 212.09200000000001, 'yuv.min=', -26.500189999999986)
('yuv.max=', 189.87800000000001, 'yuv.min=', -91.960130000000007)
('yuv.max=', 234.95599999999996, 'yuv.min=', -37.074289999999998)
('yuv.max=', 203.03200000000001, 'yuv.min=', -19.435159999999996)
('yuv.max=', 234.755, 'yuv.min=', -19.205259999999996)
('yuv.max=', 137.67399999999998, 'yuv.min=', -50.791019999999989)
('yuv.max=', 240.00799999999998, 'yuv.min=', -17.318050000000007)
('yuv.max=', 233.82899999999998, 'yuv.min=', -53.164719999999996)
('yuv.max=', 208.672, 'yuv.min=', -36.84023999999998)
('yuv.max=', 227.22900000000001, 'yuv.min=', -60.017719999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.7100099999999951)
('yuv.max=', 246.60299999999998, 'yuv.min=', -47.020519999999991)
('yuv.max=', 248.96099999999998, 'yuv.min=', -53.885529999999996)
('yuv.max=', 242.232, 'yuv.min=', -47.025089999999999)
('yuv.max=', 207.78699999999998, 'yuv.min=', -20.350189999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.511020000000002)
('yuv.max=', 252.92899999999997, 'yuv.min=', -24.85521)
('yuv.max=', 234.52999999999997, 'yuv.min=', -35.235509999999991)
('yuv.max=', 236.017, 'yuv.min=', -29.444099999999999)
('yuv.max=', 240.76300000000001, 'yuv.min=', -46.714579999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.0013000000000005)
('yuv.max=', 178.70699999999999, 'yuv.min=', -44.305309999999992)
('yuv.max=', 200.83099999999999, 'yuv.min=', -21.814159999999987)
('yuv.max=', 224.07999999999998, 'yuv.min=', -24.931839999999998)
('yuv.max=', 248.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 236.52100000000002, 'yuv.min=', -34.365299999999991)
('yuv.max=', 212.45999999999998, 'yuv.min=', -62.280569999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.760099999999987)
('yuv.max=', 200.328, 'yuv.min=', -29.9466)
('yuv.max=', 248.755, 'yuv.min=', -11.495349999999991)
('yuv.max=', 247.80399999999997, 'yuv.min=', -16.175079999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.085139999999996)
('yuv.max=', 215.70999999999998, 'yuv.min=', -7.6650899999999922)
('yuv.max=', 242.72200000000001, 'yuv.min=', -40.955589999999994)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.679830000000003)
('yuv.max=', 241.68099999999998, 'yuv.min=', -64.725629999999995)
('yuv.max=', 254.11399999999998, 'yuv.min=', -22.34985)
('yuv.max=', 241.733, 'yuv.min=', -4.6050299999999922)
('yuv.max=', 252.31999999999999, 'yuv.min=', -40.880889999999994)
('yuv.max=', 244.70100000000002, 'yuv.min=', -20.050159999999984)
('yuv.max=', 202.63199999999998, 'yuv.min=', -29.855709999999995)
('yuv.max=', 225.29000000000002, 'yuv.min=', -37.359799999999979)
('yuv.max=', 255.0, 'yuv.min=', -39.710649999999994)
('yuv.max=', 249.142, 'yuv.min=', -39.144829999999992)
('yuv.max=', 226.91999999999999, 'yuv.min=', -27.230139999999984)
('yuv.max=', 255.0, 'yuv.min=', -36.395379999999989)
('yuv.max=', 242.37199999999999, 'yuv.min=', -53.800660000000008)
('yuv.max=', 196.16800000000001, 'yuv.min=', -19.646320000000003)
('yuv.max=', 255.0, 'yuv.min=', -6.6149000000000022)
('yuv.max=', 243.929, 'yuv.min=', -24.895459999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -27.745129999999996)
('yuv.max=', 245.03199999999998, 'yuv.min=', -5.0200099999999779)
('yuv.max=', 255.0, 'yuv.min=', -13.814349999999997)
('yuv.max=', 252.28800000000001, 'yuv.min=', -22.087420000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.840269999999986)
('yuv.max=', 245.488, 'yuv.min=', -18.790279999999989)
('yuv.max=', 238.815, 'yuv.min=', -75.985279999999989)
('yuv.max=', 253.87500000000003, 'yuv.min=', -80.145449999999997)
('yuv.max=', 196.136, 'yuv.min=', -29.368479999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.455299999999994)
('yuv.max=', 251.92899999999995, 'yuv.min=', -42.066370000000006)
('yuv.max=', 254.65800000000002, 'yuv.min=', -17.874340000000004)
('yuv.max=', 242.54400000000001, 'yuv.min=', -26.910599999999999)
('yuv.max=', 211.28299999999999, 'yuv.min=', -29.730390000000003)
('yuv.max=', 230.89399999999998, 'yuv.min=', -22.910199999999982)
('yuv.max=', 195.85499999999999, 'yuv.min=', -35.820629999999987)
('yuv.max=', 248.97900000000001, 'yuv.min=', -23.150469999999988)
('yuv.max=', 235.958, 'yuv.min=', -64.055440000000004)
('yuv.max=', 241.245, 'yuv.min=', -42.145340000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.392479999999999)
('yuv.max=', 235.04399999999998, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 232.721, 'yuv.min=', -0.88515000000000299)
('yuv.max=', 254.40199999999999, 'yuv.min=', -69.839209999999994)
('yuv.max=', 204.905, 'yuv.min=', -55.358320000000006)
('yuv.max=', 183.33999999999997, 'yuv.min=', -36.635649999999998)
('yuv.max=', 255.0, 'yuv.min=', -21.665259999999989)
('yuv.max=', 255.0, 'yuv.min=', -9.8250599999999935)
('yuv.max=', 229.59299999999999, 'yuv.min=', -37.140269999999987)
('yuv.max=', 254.77200000000002, 'yuv.min=', -30.96039)
('yuv.max=', 255.0, 'yuv.min=', -8.315940000000003)
('yuv.max=', 216.959, 'yuv.min=', -9.6007199999999955)
('yuv.max=', 255.0, 'yuv.min=', -8.1732300000000038)
('yuv.max=', 235.53899999999999, 'yuv.min=', -34.799590000000002)
('yuv.max=', 204.65099999999998, 'yuv.min=', -22.250379999999986)
('yuv.max=', 225.08199999999999, 'yuv.min=', -27.520690000000005)
('yuv.max=', 237.57799999999997, 'yuv.min=', -23.410629999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.43526)
('yuv.max=', 231.13099999999997, 'yuv.min=', -6.1350599999999957)
('yuv.max=', 252.309, 'yuv.min=', -49.076009999999997)
('yuv.max=', 252.15200000000002, 'yuv.min=', -45.78595)
('yuv.max=', 245.41300000000001, 'yuv.min=', -26.770339999999987)
('yuv.max=', 243.971, 'yuv.min=', -42.909100000000002)
('yuv.max=', 237.49099999999999, 'yuv.min=', -30.990269999999988)
('yuv.max=', 149.28999999999999, 'yuv.min=', -35.931009999999993)
('yuv.max=', 224.703, 'yuv.min=', -33.465209999999978)
('yuv.max=', 186.13299999999998, 'yuv.min=', -27.493270000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.54400000000001, 'yuv.min=', -16.234839999999995)
('yuv.max=', 255.0, 'yuv.min=', -29.790149999999986)
('yuv.max=', 237.59799999999998, 'yuv.min=', -13.455300000000001)
('yuv.max=', 243.34099999999998, 'yuv.min=', -91.028689999999997)
('yuv.max=', 216.398, 'yuv.min=', -41.930379999999992)
('yuv.max=', 255.0, 'yuv.min=', -29.897940000000002)
('yuv.max=', 190.43899999999999, 'yuv.min=', -50.599990000000005)
('yuv.max=', 201.637, 'yuv.min=', -26.670329999999996)
('yuv.max=', 203.94299999999998, 'yuv.min=', -31.060399999999991)
('yuv.max=', 177.93899999999999, 'yuv.min=', -16.160139999999998)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.99999999999997, 'yuv.min=', -56.64473000000001)
('yuv.max=', 199.0, 'yuv.min=', -10.909989999999997)
('yuv.max=', 245.20599999999999, 'yuv.min=', -42.299309999999991)
('yuv.max=', 209.441, 'yuv.min=', -40.570489999999992)
('yuv.max=', 238.15199999999999, 'yuv.min=', -43.760440000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -46.705549999999988)
('yuv.max=', 251.43199999999996, 'yuv.min=', -24.095379999999995)
('yuv.max=', 234.05799999999999, 'yuv.min=', -31.605269999999997)
('yuv.max=', 226.12799999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 207.92899999999997, 'yuv.min=', -32.452109999999998)
('yuv.max=', 199.352, 'yuv.min=', -60.235549999999996)
('yuv.max=', 247.02599999999998, 'yuv.min=', -35.210049999999995)
('yuv.max=', 237.07499999999999, 'yuv.min=', -49.520769999999999)
('yuv.max=', 222.78899999999999, 'yuv.min=', -40.28446000000001)
('yuv.max=', 250.57599999999996, 'yuv.min=', -36.595399999999984)
('yuv.max=', 233.92100000000002, 'yuv.min=', -11.340150000000001)
('yuv.max=', 255.0, 'yuv.min=', -42.970730000000003)
('yuv.max=', 216.01900000000001, 'yuv.min=', -26.425489999999986)
('yuv.max=', 235.62699999999998, 'yuv.min=', -39.065770000000001)
('yuv.max=', 237.017, 'yuv.min=', -54.160249999999984)
('yuv.max=', 253.80399999999997, 'yuv.min=', -24.713659999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 219.99099999999999, 'yuv.min=', -45.43072999999999)
('yuv.max=', 232.04299999999998, 'yuv.min=', -54.555719999999994)
('yuv.max=', 234.339, 'yuv.min=', -36.955189999999995)
('yuv.max=', 240.97799999999998, 'yuv.min=', -30.899399999999996)
('yuv.max=', 226.04000000000002, 'yuv.min=', -25.925439999999995)
('yuv.max=', 240.70599999999999, 'yuv.min=', -26.125459999999993)
('yuv.max=', 226.06099999999998, 'yuv.min=', -16.545239999999993)
('yuv.max=', 211.41, 'yuv.min=', -46.735429999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.550179999999997)
('yuv.max=', 201.21199999999999, 'yuv.min=', -19.505289999999984)
('yuv.max=', 226.12499999999997, 'yuv.min=', -42.945419999999999)
('yuv.max=', 243.60399999999998, 'yuv.min=', -50.83466)
('yuv.max=', 169.40899999999999, 'yuv.min=', -18.420120000000001)
('yuv.max=', 188.97699999999998, 'yuv.min=', -22.55594)
('yuv.max=', 247.90099999999998, 'yuv.min=', -15.573870000000005)
('yuv.max=', 148.98099999999999, 'yuv.min=', -38.625479999999989)
('yuv.max=', 253.13099999999997, 'yuv.min=', -72.320589999999996)
('yuv.max=', 255.0, 'yuv.min=', -66.62581999999999)
('yuv.max=', 251.15300000000002, 'yuv.min=', -57.767539999999997)
('yuv.max=', 225.15999999999997, 'yuv.min=', -44.375439999999998)
('yuv.max=', 252.114, 'yuv.min=', -15.273999999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -74.105829999999997)
('yuv.max=', 207.76299999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 255.0, 'yuv.min=', -59.941860000000005)
('yuv.max=', 250.173, 'yuv.min=', -85.844790000000003)
('yuv.max=', 236.39699999999999, 'yuv.min=', -17.030349999999991)
('yuv.max=', 201.03499999999997, 'yuv.min=', -42.905820000000006)
('yuv.max=', 228.673, 'yuv.min=', -30.396080000000001)
('yuv.max=', 250.54399999999998, 'yuv.min=', -11.819020000000009)
('yuv.max=', 255.0, 'yuv.min=', -16.415349999999986)
('yuv.max=', 199.96600000000001, 'yuv.min=', -53.225709999999992)
('yuv.max=', 254.886, 'yuv.min=', -33.536689999999993)
('yuv.max=', 160.44900000000001, 'yuv.min=', -23.525199999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.38091)
('yuv.max=', 225.28800000000001, 'yuv.min=', -16.900459999999992)
('yuv.max=', 228.64399999999998, 'yuv.min=', -35.270210000000006)
('yuv.max=', 250.25600000000003, 'yuv.min=', -60.740169999999999)
('yuv.max=', 189.08799999999997, 'yuv.min=', -18.105149999999995)
('yuv.max=', 237.42399999999998, 'yuv.min=', -11.498360000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.291240000000002)
('yuv.max=', 249.94, 'yuv.min=', -46.171590000000002)
('yuv.max=', 215.03199999999998, 'yuv.min=', -20.220299999999998)
('yuv.max=', 245.23199999999997, 'yuv.min=', -105.33056999999999)
('yuv.max=', 146.07300000000001, 'yuv.min=', -29.015379999999993)
('yuv.max=', 197.816, 'yuv.min=', -48.114050000000006)
('yuv.max=', 217.40200000000002, 'yuv.min=', -12.800049999999999)
('yuv.max=', 194.13399999999999, 'yuv.min=', -7.2604800000000012)
('yuv.max=', 251.44099999999997, 'yuv.min=', -50.175939999999997)
('yuv.max=', 245.88800000000001, 'yuv.min=', -57.820369999999983)
('yuv.max=', 237.76999999999998, 'yuv.min=', -37.390909999999991)
('yuv.max=', 216.08199999999999, 'yuv.min=', -36.301540000000003)
('yuv.max=', 202.63999999999999, 'yuv.min=', -17.305069999999986)
('yuv.max=', 248.87, 'yuv.min=', -39.166550000000008)
('yuv.max=', 224.05999999999997, 'yuv.min=', -41.795919999999995)
('yuv.max=', 250.184, 'yuv.min=', -20.756979999999999)
('yuv.max=', 181.328, 'yuv.min=', -25.450699999999991)
('yuv.max=', 202.03699999999998, 'yuv.min=', -32.720320000000001)
('yuv.max=', 249.65099999999995, 'yuv.min=', -67.030429999999996)
('yuv.max=', 249.673, 'yuv.min=', -16.63030999999998)
('yuv.max=', 223.15699999999998, 'yuv.min=', -11.351650000000001)
('yuv.max=', 230.99599999999995, 'yuv.min=', -22.197140000000001)
('yuv.max=', 242.33500000000001, 'yuv.min=', -21.220399999999991)
('yuv.max=', 248.0, 'yuv.min=', -21.825860000000002)
('yuv.max=', 239.03199999999998, 'yuv.min=', -26.785279999999993)
('yuv.max=', 254.10300000000001, 'yuv.min=', -24.153020000000001)
('yuv.max=', 138.221, 'yuv.min=', -12.185049999999995)
('yuv.max=', 242.96399999999997, 'yuv.min=', -41.090990000000005)
('yuv.max=', 247.07999999999998, 'yuv.min=', -55.315549999999988)
('yuv.max=', 237.672, 'yuv.min=', -79.066020000000009)
('yuv.max=', 243.89899999999997, 'yuv.min=', -72.466099999999997)
('yuv.max=', 247.88600000000002, 'yuv.min=', -26.600200000000001)
('yuv.max=', 249.756, 'yuv.min=', -20.053450000000012)
('yuv.max=', 221.25799999999998, 'yuv.min=', -59.463140000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.555279999999996)
('yuv.max=', 209.22299999999998, 'yuv.min=', -38.753090000000007)
('yuv.max=', 212.96099999999998, 'yuv.min=', -12.523070000000001)
('yuv.max=', 254.886, 'yuv.min=', -40.61530999999998)
('yuv.max=', 252.0, 'yuv.min=', -24.403800000000004)
('yuv.max=', 215.77600000000001, 'yuv.min=', -81.375450000000001)
('yuv.max=', 195.583, 'yuv.min=', -15.930239999999996)
('yuv.max=', 235.77199999999999, 'yuv.min=', -17.390139999999995)
('yuv.max=', 248.20500000000001, 'yuv.min=', -16.790079999999996)
('yuv.max=', 253.333, 'yuv.min=', -37.125329999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.96100000000001, 'yuv.min=', -45.460609999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.060169999999999)
('yuv.max=', 224.35500000000002, 'yuv.min=', -36.665809999999993)
('yuv.max=', 204.59100000000001, 'yuv.min=', -12.170109999999992)
('yuv.max=', 212.46099999999998, 'yuv.min=', -30.31081)
('yuv.max=', 255.0, 'yuv.min=', -18.447630000000004)
('yuv.max=', 190.399, 'yuv.min=', -23.225169999999984)
('yuv.max=', 198.13299999999998, 'yuv.min=', -28.934879999999996)
('yuv.max=', 210.83399999999997, 'yuv.min=', -55.300609999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.425219999999999)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 192.345, 'yuv.min=', -59.995279999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.095449999999985)
('yuv.max=', 244.74399999999997, 'yuv.min=', -7.1500999999999877)
('yuv.max=', 254.65800000000002, 'yuv.min=', -29.845339999999979)
('yuv.max=', 219.41300000000001, 'yuv.min=', -43.400649999999999)
('yuv.max=', 244.19399999999999, 'yuv.min=', -13.730019999999989)
('yuv.max=', 255.0, 'yuv.min=', -31.300669999999993)
('yuv.max=', 177.13299999999998, 'yuv.min=', -35.874340000000011)
('yuv.max=', 209.53100000000001, 'yuv.min=', -48.059659999999994)
('yuv.max=', 199.47599999999997, 'yuv.min=', -27.889960000000002)
('yuv.max=', 251.81499999999997, 'yuv.min=', -35.735559999999992)
('yuv.max=', 243.761, 'yuv.min=', -20.609969999999993)
('yuv.max=', 251.352, 'yuv.min=', -57.963309999999993)
('yuv.max=', 247.81499999999997, 'yuv.min=', -31.590900000000005)
('yuv.max=', 249.94599999999997, 'yuv.min=', -25.858480000000007)
('yuv.max=', 182.15199999999999, 'yuv.min=', -17.34531999999999)
('yuv.max=', 245.62799999999999, 'yuv.min=', -49.369079999999997)
('yuv.max=', 225.63799999999998, 'yuv.min=', -49.461859999999994)
('yuv.max=', 134.404, 'yuv.min=', -36.865549999999992)
('yuv.max=', 205.03899999999999, 'yuv.min=', -43.957620000000006)
('yuv.max=', 226.91799999999998, 'yuv.min=', -53.960229999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.004170000000009)
('yuv.max=', 253.56100000000001, 'yuv.min=', -36.555149999999998)
('yuv.max=', 236.70899999999997, 'yuv.min=', -16.660189999999989)
('yuv.max=', 229.10200000000003, 'yuv.min=', -36.859749999999991)
('yuv.max=', 191.18199999999999, 'yuv.min=', -16.823470000000004)
('yuv.max=', 237.98499999999999, 'yuv.min=', -23.754330000000003)
('yuv.max=', 253.989, 'yuv.min=', -17.005040000000005)
('yuv.max=', 241.10299999999998, 'yuv.min=', -21.482920000000004)
('yuv.max=', 252.89699999999999, 'yuv.min=', -62.335759999999993)
('yuv.max=', 203.98299999999998, 'yuv.min=', -9.8908999999999985)
('yuv.max=', 254.131, 'yuv.min=', -18.920169999999995)
('yuv.max=', 224.13399999999999, 'yuv.min=', -21.443060000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.949220000000004)
('yuv.max=', 242.30999999999997, 'yuv.min=', -14.996019999999998)
('yuv.max=', 199.12299999999999, 'yuv.min=', -35.450469999999989)
('yuv.max=', 255.0, 'yuv.min=', -32.025700000000001)
('yuv.max=', 208.35900000000001, 'yuv.min=', -12.375640000000004)
('yuv.max=', 252.42400000000001, 'yuv.min=', -37.640319999999988)
('yuv.max=', 171.369, 'yuv.min=', -32.555440000000004)
('yuv.max=', 238.85399999999998, 'yuv.min=', -44.250119999999995)
('yuv.max=', 237.89600000000002, 'yuv.min=', -31.160409999999992)
('yuv.max=', 248.83699999999999, 'yuv.min=', -29.390109999999986)
('yuv.max=', 237.70099999999999, 'yuv.min=', -53.025689999999997)
('yuv.max=', 233.38499999999999, 'yuv.min=', -21.951330000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.020379999999992)
('yuv.max=', 231.09899999999999, 'yuv.min=', -19.24721000000001)
('yuv.max=', 244.94999999999999, 'yuv.min=', -27.563830000000003)
('yuv.max=', 240.75899999999999, 'yuv.min=', -37.53573999999999)
('yuv.max=', 245.33799999999997, 'yuv.min=', -64.615249999999975)
('yuv.max=', 242.08500000000001, 'yuv.min=', -40.610739999999993)
('yuv.max=', 255.0, 'yuv.min=', -18.820160000000001)
('yuv.max=', 179.72899999999998, 'yuv.min=', -14.670359999999992)
('yuv.max=', 242.94999999999999, 'yuv.min=', -16.290029999999994)
('yuv.max=', 248.452, 'yuv.min=', -23.395420000000001)
('yuv.max=', 231.809, 'yuv.min=', -50.980669999999996)
('yuv.max=', 241.94999999999999, 'yuv.min=', -31.445499999999992)
('yuv.max=', 202.447, 'yuv.min=', -26.700209999999991)
('yuv.max=', 228.47, 'yuv.min=', -25.406829999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.000369999999993)
('yuv.max=', 201.34199999999998, 'yuv.min=', -40.655559999999987)
('yuv.max=', 249.78299999999996, 'yuv.min=', -9.0181400000000096)
('yuv.max=', 225.98400000000001, 'yuv.min=', -23.869219999999999)
('yuv.max=', 245.38099999999997, 'yuv.min=', -30.419939999999997)
('yuv.max=', 211.38099999999997, 'yuv.min=', -30.785680000000003)
('yuv.max=', 253.86000000000001, 'yuv.min=', -28.760169999999984)
('yuv.max=', 221.04299999999998, 'yuv.min=', -49.240249999999989)
('yuv.max=', 224.02800000000002, 'yuv.min=', -30.78059)
('yuv.max=', 253.20599999999999, 'yuv.min=', -59.505920000000003)
('yuv.max=', 218.292, 'yuv.min=', -40.355529999999987)
('yuv.max=', 253.46199999999999, 'yuv.min=', -35.45478)
('yuv.max=', 248.875, 'yuv.min=', -8.6502499999999962)
('yuv.max=', 208.70099999999999, 'yuv.min=', -21.465239999999994)
('yuv.max=', 209.017, 'yuv.min=', -36.366260000000011)
('yuv.max=', 241.35900000000001, 'yuv.min=', -47.820599999999999)
('yuv.max=', 240.29199999999997, 'yuv.min=', -61.032060000000008)
('yuv.max=', 195.52699999999999, 'yuv.min=', -23.27478)
('yuv.max=', 186.06199999999998, 'yuv.min=', -53.576640000000005)
('yuv.max=', 243.95599999999999, 'yuv.min=', -32.035189999999993)
('yuv.max=', 198.30899999999997, 'yuv.min=', -50.425429999999992)
('yuv.max=', 224.76999999999998, 'yuv.min=', -27.370399999999989)
('yuv.max=', 255.0, 'yuv.min=', -26.185219999999994)
('yuv.max=', 230.82999999999998, 'yuv.min=', -23.61027)
('yuv.max=', 167.316, 'yuv.min=', -31.875420000000002)
('yuv.max=', 255.0, 'yuv.min=', -45.520369999999986)
('yuv.max=', 191.00199999999998, 'yuv.min=', -25.324120000000001)
('yuv.max=', 248.0, 'yuv.min=', -46.58023)
('yuv.max=', 223.05099999999999, 'yuv.min=', -27.03058)
('yuv.max=', 252.60599999999999, 'yuv.min=', -30.272710000000004)
('yuv.max=', 255.0, 'yuv.min=', -17.149979999999992)
('yuv.max=', 253.0, 'yuv.min=', -5.0050699999999892)
('yuv.max=', 204.589, 'yuv.min=', -27.608259999999994)
('yuv.max=', 255.0, 'yuv.min=', -45.990539999999996)
('yuv.max=', 202.13099999999997, 'yuv.min=', -47.99618000000001)
('yuv.max=', 249.94599999999997, 'yuv.min=', -29.526240000000001)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.7801399999999994)
('yuv.max=', 253.68999999999997, 'yuv.min=', -24.780509999999996)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.01399999999998, 'yuv.min=', -22.810189999999995)
('yuv.max=', 249.73899999999998, 'yuv.min=', -31.454620000000013)
('yuv.max=', 255.0, 'yuv.min=', -11.540169999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.10877)
('yuv.max=', 230.172, 'yuv.min=', -121.38489999999997)
('yuv.max=', 214.27399999999997, 'yuv.min=', -46.805559999999993)
('yuv.max=', 252.34999999999999, 'yuv.min=', -35.603620000000006)
('yuv.max=', 255.0, 'yuv.min=', -5.2050899999999984)
('yuv.max=', 254.06, 'yuv.min=', -91.470659999999995)
('yuv.max=', 176.80799999999999, 'yuv.min=', -27.230139999999999)
('yuv.max=', 238.57999999999998, 'yuv.min=', -36.05471)
('yuv.max=', 231.67199999999997, 'yuv.min=', -55.585699999999989)
('yuv.max=', 158.30799999999999, 'yuv.min=', -14.055359999999986)
('yuv.max=', 223.01599999999999, 'yuv.min=', -31.960489999999993)
('yuv.max=', 232.26599999999999, 'yuv.min=', -51.825569999999985)
('yuv.max=', 233.84899999999999, 'yuv.min=', -33.775000000000006)
('yuv.max=', 220.745, 'yuv.min=', -51.980769999999993)
('yuv.max=', 254.43000000000001, 'yuv.min=', -66.579390000000004)
('yuv.max=', 204.245, 'yuv.min=', -34.444569999999992)
('yuv.max=', 239.11099999999999, 'yuv.min=', -35.110190000000003)
('yuv.max=', 240.465, 'yuv.min=', -48.90576999999999)
('yuv.max=', 234.84700000000001, 'yuv.min=', -31.275359999999992)
('yuv.max=', 227.13699999999997, 'yuv.min=', -26.970359999999999)
('yuv.max=', 247.24999999999997, 'yuv.min=', -11.519620000000003)
('yuv.max=', 212.989, 'yuv.min=', -16.645249999999997)
('yuv.max=', 185.86699999999999, 'yuv.min=', -34.695209999999989)
('yuv.max=', 191.43699999999998, 'yuv.min=', -39.900299999999987)
('yuv.max=', 250.65199999999999, 'yuv.min=', -13.10008)
('yuv.max=', 254.35900000000001, 'yuv.min=', -2.3301300000000111)
('yuv.max=', 255.0, 'yuv.min=', -69.713619999999992)
('yuv.max=', 178.101, 'yuv.min=', -64.088970000000003)
('yuv.max=', 241.733, 'yuv.min=', -28.855369999999994)
('yuv.max=', 248.417, 'yuv.min=', -24.636569999999992)
('yuv.max=', 249.11399999999998, 'yuv.min=', -53.015320000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.480479999999996)
('yuv.max=', 250.91799999999998, 'yuv.min=', -15.815289999999997)
('yuv.max=', 202.40000000000001, 'yuv.min=', -33.68016999999999)
('yuv.max=', 177.47800000000001, 'yuv.min=', -27.325579999999992)
('yuv.max=', 250.04899999999998, 'yuv.min=', -90.585509999999985)
('yuv.max=', 255.0, 'yuv.min=', -21.028380000000002)
('yuv.max=', 229.846, 'yuv.min=', -40.108849999999997)
('yuv.max=', 255.0, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 195.947, 'yuv.min=', -85.273110000000003)
('yuv.max=', 236.06, 'yuv.min=', -16.215329999999994)
('yuv.max=', 215.20199999999997, 'yuv.min=', -31.580479999999994)
('yuv.max=', 231.99100000000001, 'yuv.min=', -136.18514999999999)
('yuv.max=', 221.74000000000001, 'yuv.min=', -36.410319999999999)
('yuv.max=', 255.0, 'yuv.min=', -50.176569999999998)
('yuv.max=', 233.28800000000001, 'yuv.min=', -10.825159999999991)
('yuv.max=', 209.85399999999998, 'yuv.min=', -18.380320000000005)
('yuv.max=', 219.0, 'yuv.min=', -7.0129699999999993)
('yuv.max=', 207.172, 'yuv.min=', -40.440599999999996)
('yuv.max=', 253.10299999999998, 'yuv.min=', -49.695480000000003)
('yuv.max=', 158.084, 'yuv.min=', -39.680769999999995)
('yuv.max=', 218.63, 'yuv.min=', -17.128730000000001)
('yuv.max=', 250.88599999999997, 'yuv.min=', -12.380019999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.275169999999999)
('yuv.max=', 242.804, 'yuv.min=', -8.3352799999999991)
('yuv.max=', 208.95099999999999, 'yuv.min=', -47.420559999999995)
('yuv.max=', 226.56599999999997, 'yuv.min=', -42.000509999999991)
('yuv.max=', 220.68099999999998, 'yuv.min=', -24.640249999999995)
('yuv.max=', 219.09400000000002, 'yuv.min=', -36.88794)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.43000000000001, 'yuv.min=', -27.420980000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.417, 'yuv.min=', -21.050259999999994)
('yuv.max=', 255.0, 'yuv.min=', -24.465540000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.585189999999997)
('yuv.max=', 217.46600000000001, 'yuv.min=', -56.050069999999991)
('yuv.max=', 239.78299999999999, 'yuv.min=', -35.569389999999999)
('yuv.max=', 206.29099999999997, 'yuv.min=', -12.640279999999997)
('yuv.max=', 250.68999999999997, 'yuv.min=', -40.100319999999982)
('yuv.max=', 214.58399999999997, 'yuv.min=', -19.090309999999999)
('yuv.max=', 241.572, 'yuv.min=', -26.225469999999994)
('yuv.max=', 225.041, 'yuv.min=', -11.202920000000006)
('yuv.max=', 251.167, 'yuv.min=', -73.496009999999998)
('yuv.max=', 254.41299999999995, 'yuv.min=', -35.199170000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.230139999999992)
('yuv.max=', 205.40200000000002, 'yuv.min=', -23.259650000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999996)
('yuv.max=', 251.38699999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 214.51500000000001, 'yuv.min=', -102.19577)
('yuv.max=', 241.04299999999998, 'yuv.min=', -28.579330000000006)
('yuv.max=', 255.0, 'yuv.min=', -41.160179999999997)
('yuv.max=', 249.02199999999999, 'yuv.min=', -26.900230000000001)
('yuv.max=', 253.65799999999999, 'yuv.min=', -54.745369999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.249, 'yuv.min=', -36.380439999999993)
('yuv.max=', 236.86099999999999, 'yuv.min=', -47.24584999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -20.065099999999976)
('yuv.max=', 249.755, 'yuv.min=', -27.385339999999999)
('yuv.max=', 235.72300000000001, 'yuv.min=', -48.257460000000002)
('yuv.max=', 248.40799999999999, 'yuv.min=', -25.455269999999999)
('yuv.max=', 245.23899999999998, 'yuv.min=', -28.103980000000004)
('yuv.max=', 255.0, 'yuv.min=', -25.310439999999996)
('yuv.max=', 116.56, 'yuv.min=', -20.550460000000005)
('yuv.max=', 255.0, 'yuv.min=', -34.627420000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -35.483240000000009)
('yuv.max=', 140.48499999999999, 'yuv.min=', -32.275459999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 215.76100000000002, 'yuv.min=', -37.514999999999986)
('yuv.max=', 254.54400000000001, 'yuv.min=', -25.700110000000002)
('yuv.max=', 246.08699999999999, 'yuv.min=', -37.655259999999998)
('yuv.max=', 205.26399999999998, 'yuv.min=', -27.674999999999979)
('yuv.max=', 189.69299999999998, 'yuv.min=', -39.493559999999988)
('yuv.max=', 255.0, 'yuv.min=', -20.98555)
('yuv.max=', 255.0, 'yuv.min=', -24.615569999999998)
('yuv.max=', 255.0, 'yuv.min=', -63.870359999999998)
('yuv.max=', 246.0, 'yuv.min=', -82.405429999999981)
('yuv.max=', 224.18899999999999, 'yuv.min=', -32.215699999999991)
('yuv.max=', 197.95899999999997, 'yuv.min=', -19.505289999999995)
('yuv.max=', 227.10299999999998, 'yuv.min=', -38.695610000000002)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.44800000000001, 'yuv.min=', -56.861809999999991)
('yuv.max=', 250.17899999999997, 'yuv.min=', -14.830129999999983)
('yuv.max=', 239.202, 'yuv.min=', -44.715719999999997)
('yuv.max=', 250.99999999999997, 'yuv.min=', -48.296060000000004)
('yuv.max=', 244.02499999999998, 'yuv.min=', -14.230069999999991)
('yuv.max=', 200.858, 'yuv.min=', -16.315339999999999)
('yuv.max=', 237.0, 'yuv.min=', -8.8974000000000046)
('yuv.max=', 236.31, 'yuv.min=', -14.990590000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', -9.0652299999999997)
('yuv.max=', 233.239, 'yuv.min=', -32.562389999999994)
('yuv.max=', 247.09199999999998, 'yuv.min=', -30.060299999999984)
('yuv.max=', 252.13099999999997, 'yuv.min=', -24.059770000000004)
('yuv.max=', 254.886, 'yuv.min=', -14.249650000000003)
('yuv.max=', 213.77000000000001, 'yuv.min=', -3.0749999999999975)
('yuv.max=', 255.0, 'yuv.min=', -21.683690000000006)
('yuv.max=', 203.054, 'yuv.min=', -13.84631000000001)
('yuv.max=', 242.971, 'yuv.min=', -34.320479999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 198.20600000000002, 'yuv.min=', -43.031259999999996)
('yuv.max=', 243.74399999999997, 'yuv.min=', -25.470209999999987)
('yuv.max=', 206.20999999999998, 'yuv.min=', -32.460539999999995)
('yuv.max=', 224.815, 'yuv.min=', -27.210700000000003)
('yuv.max=', 225.55499999999998, 'yuv.min=', -29.715449999999986)
('yuv.max=', 255.0, 'yuv.min=', -44.949200000000005)
('yuv.max=', 249.07499999999999, 'yuv.min=', -24.175879999999999)
('yuv.max=', 214.92499999999998, 'yuv.min=', -39.180719999999994)
('yuv.max=', 217.49000000000001, 'yuv.min=', -29.990169999999992)
('yuv.max=', 247.48799999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.881, 'yuv.min=', -10.009309999999999)
('yuv.max=', 198.29900000000001, 'yuv.min=', -1.4548100000000002)
('yuv.max=', 251.13099999999997, 'yuv.min=', -23.740159999999992)
('yuv.max=', 207.185, 'yuv.min=', -46.975699999999996)
('yuv.max=', 183.953, 'yuv.min=', -25.792839999999998)
('yuv.max=', 248.88599999999997, 'yuv.min=', -33.97984000000001)
('yuv.max=', 193.27100000000002, 'yuv.min=', -12.555210000000002)
('yuv.max=', 255.0, 'yuv.min=', -51.215139999999991)
('yuv.max=', 215.74799999999999, 'yuv.min=', -24.861390000000007)
('yuv.max=', 251.42299999999997, 'yuv.min=', -52.055469999999985)
('yuv.max=', 208.24099999999999, 'yuv.min=', -25.699599999999997)
('yuv.max=', 203.80800000000002, 'yuv.min=', -19.737380000000002)
('yuv.max=', 221.82499999999996, 'yuv.min=', -83.621980000000008)
('yuv.max=', 214.09599999999998, 'yuv.min=', -35.657510000000002)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 230.93499999999997, 'yuv.min=', -31.586170000000003)
('yuv.max=', 213.97200000000001, 'yuv.min=', -23.33098)
('yuv.max=', 229.09699999999998, 'yuv.min=', -31.900729999999992)
('yuv.max=', 211.994, 'yuv.min=', -17.834999999999997)
('yuv.max=', 248.69, 'yuv.min=', -25.010409999999982)
('yuv.max=', 254.65800000000002, 'yuv.min=', -18.763080000000006)
('yuv.max=', 188.14699999999999, 'yuv.min=', -83.234769999999997)
('yuv.max=', 237.40499999999997, 'yuv.min=', -15.900980000000004)
('yuv.max=', 188.94399999999999, 'yuv.min=', -25.755299999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.19600000000003, 'yuv.min=', -34.050329999999988)
('yuv.max=', 252.114, 'yuv.min=', -11.05505999999999)
('yuv.max=', 252.77199999999999, 'yuv.min=', -4.6900999999999993)
('yuv.max=', 226.96099999999998, 'yuv.min=', -26.883729999999996)
('yuv.max=', 239.71699999999998, 'yuv.min=', -26.710579999999997)
('yuv.max=', 235.99999999999997, 'yuv.min=', -20.065100000000001)
('yuv.max=', 167.50299999999999, 'yuv.min=', -53.085449999999994)
('yuv.max=', 247.71199999999999, 'yuv.min=', -41.960259999999991)
('yuv.max=', 251.44499999999996, 'yuv.min=', -71.910179999999983)
('yuv.max=', 242.90299999999999, 'yuv.min=', -21.395090000000003)
('yuv.max=', 230.67999999999998, 'yuv.min=', -21.18014999999999)
('yuv.max=', 95.341999999999985, 'yuv.min=', -11.970089999999997)
('yuv.max=', 168.55099999999999, 'yuv.min=', -16.990140000000004)
('yuv.max=', 221.435, 'yuv.min=', -12.10193000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.175049999999992)
('yuv.max=', 255.0, 'yuv.min=', -25.585159999999995)
('yuv.max=', 220.02799999999996, 'yuv.min=', -21.74324)
('yuv.max=', 228.31799999999998, 'yuv.min=', -48.942760000000007)
('yuv.max=', 203.78899999999999, 'yuv.min=', -11.242189999999997)
('yuv.max=', 214.84299999999999, 'yuv.min=', -21.150269999999995)
('yuv.max=', 214.761, 'yuv.min=', -68.520200000000003)
('yuv.max=', 229.78100000000001, 'yuv.min=', -29.837109999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -40.940650000000005)
('yuv.max=', 255.0, 'yuv.min=', -36.829210000000003)
('yuv.max=', 255.0, 'yuv.min=', -38.73575000000001)
('yuv.max=', 221.55799999999999, 'yuv.min=', -44.866780000000013)
('yuv.max=', 252.64099999999996, 'yuv.min=', -11.64017999999999)
('yuv.max=', 233.62299999999999, 'yuv.min=', -34.069070000000004)
('yuv.max=', 243.79300000000001, 'yuv.min=', -16.16919)
('yuv.max=', 240.24299999999999, 'yuv.min=', -72.117450000000005)
('yuv.max=', 243.74499999999998, 'yuv.min=', -30.22007)
('yuv.max=', 198.64299999999997, 'yuv.min=', -23.803490000000007)
('yuv.max=', 223.26399999999998, 'yuv.min=', -16.34521999999998)
('yuv.max=', 158.14100000000002, 'yuv.min=', -63.520939999999982)
('yuv.max=', 254.70099999999999, 'yuv.min=', -47.595269999999985)
('yuv.max=', 119.67999999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 218.614, 'yuv.min=', -22.582380000000001)
('yuv.max=', 241.434, 'yuv.min=', -46.815929999999994)
('yuv.max=', 194.97099999999998, 'yuv.min=', -59.610179999999993)
('yuv.max=', 231.15799999999999, 'yuv.min=', -23.002180000000003)
('yuv.max=', 254.58699999999999, 'yuv.min=', -32.391390000000001)
('yuv.max=', 195.83999999999997, 'yuv.min=', -23.425189999999997)
('yuv.max=', 235.25999999999999, 'yuv.min=', -47.85047999999999)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 167.84399999999999, 'yuv.min=', -40.827600000000004)
('yuv.max=', 255.0, 'yuv.min=', -27.315209999999993)
('yuv.max=', 246.00399999999999, 'yuv.min=', -31.075339999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.315609999999992)
('yuv.max=', 248.28799999999995, 'yuv.min=', -91.615489999999994)
('yuv.max=', 236.79799999999997, 'yuv.min=', -52.455509999999997)
('yuv.max=', 228.40099999999998, 'yuv.min=', -23.799210000000006)
('yuv.max=', 211.42600000000002, 'yuv.min=', -52.030159999999995)
('yuv.max=', 183.46699999999998, 'yuv.min=', -25.720849999999999)
('yuv.max=', 253.70099999999996, 'yuv.min=', -82.576149999999998)
('yuv.max=', 252.24499999999998, 'yuv.min=', -7.361679999999998)
('yuv.max=', 241.93999999999997, 'yuv.min=', -44.875489999999999)
('yuv.max=', 245.48400000000001, 'yuv.min=', -9.9951999999999828)
('yuv.max=', 224.95699999999999, 'yuv.min=', -58.475619999999999)
('yuv.max=', 238.798, 'yuv.min=', -32.375469999999993)
('yuv.max=', 244.572, 'yuv.min=', -48.580429999999993)
('yuv.max=', 255.0, 'yuv.min=', -46.55034999999998)
('yuv.max=', 174.01899999999998, 'yuv.min=', -24.610369999999996)
('yuv.max=', 203.38099999999997, 'yuv.min=', -17.264970000000002)
('yuv.max=', 252.57199999999997, 'yuv.min=', -20.305369999999993)
('yuv.max=', 175.90200000000002, 'yuv.min=', -21.165210000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.63777)
('yuv.max=', 254.886, 'yuv.min=', -9.8354299999999988)
('yuv.max=', 242.54900000000001, 'yuv.min=', -29.057770000000005)
('yuv.max=', 181.06, 'yuv.min=', -15.785409999999995)
('yuv.max=', 192.54199999999997, 'yuv.min=', -40.470479999999995)
('yuv.max=', 215.53899999999999, 'yuv.min=', -62.650729999999982)
('yuv.max=', 226.28600000000003, 'yuv.min=', -24.46553999999999)
('yuv.max=', 243.31799999999998, 'yuv.min=', -27.760069999999992)
('yuv.max=', 210.52499999999998, 'yuv.min=', -39.40025)
('yuv.max=', 226.36700000000002, 'yuv.min=', -32.705379999999991)
('yuv.max=', 236.89999999999998, 'yuv.min=', -42.270659999999992)
('yuv.max=', 222.99199999999996, 'yuv.min=', -2.7152099999999884)
('yuv.max=', 253.99999999999997, 'yuv.min=', -0.61499999999999932)
('yuv.max=', 231.14399999999995, 'yuv.min=', -56.420229999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.770820000000001)
('yuv.max=', 210.72199999999998, 'yuv.min=', -39.910669999999996)
('yuv.max=', 239.71799999999999, 'yuv.min=', -35.335519999999988)
('yuv.max=', 175.09199999999998, 'yuv.min=', -39.325549999999993)
('yuv.max=', 218.126, 'yuv.min=', -56.985839999999996)
('yuv.max=', 234.38499999999999, 'yuv.min=', -10.757100000000001)
('yuv.max=', 255.0, 'yuv.min=', -32.4148)
('yuv.max=', 250.88599999999997, 'yuv.min=', -19.250080000000001)
('yuv.max=', 186.22999999999999, 'yuv.min=', -20.720349999999982)
('yuv.max=', 227.13000000000002, 'yuv.min=', -25.825429999999997)
('yuv.max=', 255.0, 'yuv.min=', -80.890340000000009)
('yuv.max=', 194.72999999999999, 'yuv.min=', -31.015579999999996)
('yuv.max=', 216.62700000000001, 'yuv.min=', -25.296990000000008)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.58699999999996, 'yuv.min=', -62.07893)
('yuv.max=', 248.84700000000001, 'yuv.min=', -18.30516999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.754650000000005)
('yuv.max=', 192.50300000000001, 'yuv.min=', -8.8801499999999916)
('yuv.max=', 162.23500000000001, 'yuv.min=', -37.065569999999994)
('yuv.max=', 161.29900000000001, 'yuv.min=', -16.347740000000009)
('yuv.max=', 255.0, 'yuv.min=', -51.255389999999991)
('yuv.max=', 232.24600000000001, 'yuv.min=', -83.475660000000005)
('yuv.max=', 252.13299999999995, 'yuv.min=', -35.498530000000002)
('yuv.max=', 207.90099999999998, 'yuv.min=', -18.390239999999995)
('yuv.max=', 207.61099999999999, 'yuv.min=', -28.604199999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.39692999999999)
('yuv.max=', 248.83599999999998, 'yuv.min=', -17.705109999999998)
('yuv.max=', 250.20699999999997, 'yuv.min=', -18.228649999999998)
('yuv.max=', 252.83199999999997, 'yuv.min=', -27.084099999999999)
('yuv.max=', 208.76499999999999, 'yuv.min=', -44.502559999999995)
('yuv.max=', 239.387, 'yuv.min=', -25.455269999999992)
('yuv.max=', 229.74099999999999, 'yuv.min=', -29.478240000000007)
('yuv.max=', 184.374, 'yuv.min=', -35.62518)
('yuv.max=', 166.49200000000002, 'yuv.min=', -19.090309999999988)
('yuv.max=', 243.18800000000002, 'yuv.min=', -37.480549999999994)
('yuv.max=', 229.10599999999999, 'yuv.min=', -2.7061399999999907)
('yuv.max=', 255.0, 'yuv.min=', -3.6900000000000013)
('yuv.max=', 226.83699999999996, 'yuv.min=', -31.775409999999997)
('yuv.max=', 173.22799999999998, 'yuv.min=', -15.230169999999996)
('yuv.max=', 238.72899999999998, 'yuv.min=', -12.099979999999999)
('yuv.max=', 250.22800000000001, 'yuv.min=', -26.830100000000002)
('yuv.max=', 251.64099999999999, 'yuv.min=', -30.805190000000003)
('yuv.max=', 247.70099999999996, 'yuv.min=', -24.540239999999994)
('yuv.max=', 220.31099999999998, 'yuv.min=', -26.025449999999996)
('yuv.max=', 205.762, 'yuv.min=', -92.537850000000006)
('yuv.max=', 255.0, 'yuv.min=', -2.0303200000000032)
('yuv.max=', 234.0, 'yuv.min=', -35.950519999999997)
('yuv.max=', 235.22399999999999, 'yuv.min=', -55.091609999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.160339999999998)
('yuv.max=', 237.85299999999998, 'yuv.min=', -18.500509999999998)
('yuv.max=', 252.92899999999997, 'yuv.min=', -17.905129999999993)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84599999999998, 'yuv.min=', -13.982730000000004)
('yuv.max=', 208.76299999999998, 'yuv.min=', -10.210160000000002)
('yuv.max=', 242.786, 'yuv.min=', -30.875319999999991)
('yuv.max=', 251.83700000000002, 'yuv.min=', -89.14054999999999)
('yuv.max=', 222.547, 'yuv.min=', -36.270059999999994)
('yuv.max=', 235.09599999999998, 'yuv.min=', -50.385179999999991)
('yuv.max=', 238.42099999999999, 'yuv.min=', -31.090279999999993)
('yuv.max=', 230.27099999999999, 'yuv.min=', -57.690479999999994)
('yuv.max=', 231.46699999999998, 'yuv.min=', -2.7600300000000075)
('yuv.max=', 233.78299999999999, 'yuv.min=', -92.845489999999998)
('yuv.max=', 253.80399999999997, 'yuv.min=', -23.727670000000007)
('yuv.max=', 240.99999999999997, 'yuv.min=', -7.0949099999999961)
('yuv.max=', 205.61899999999997, 'yuv.min=', -23.625209999999999)
('yuv.max=', 247.77599999999998, 'yuv.min=', -64.080749999999995)
('yuv.max=', 177.30099999999999, 'yuv.min=', -21.786459999999998)
('yuv.max=', 250.114, 'yuv.min=', -9.5951599999999946)
('yuv.max=', 208.999, 'yuv.min=', -27.970459999999992)
('yuv.max=', 255.0, 'yuv.min=', -21.805519999999987)
('yuv.max=', 255.0, 'yuv.min=', -21.007620000000003)
('yuv.max=', 246.80399999999997, 'yuv.min=', -105.67542)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 222.23099999999999, 'yuv.min=', -22.665200000000006)
('yuv.max=', 216.10299999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 242.61000000000001, 'yuv.min=', -51.722690000000007)
('yuv.max=', 210.90100000000001, 'yuv.min=', -57.550280000000001)
('yuv.max=', 201.86199999999997, 'yuv.min=', -15.030149999999985)
('yuv.max=', 247.11399999999998, 'yuv.min=', -23.71114)
('yuv.max=', 248.28799999999995, 'yuv.min=', -17.015409999999996)
('yuv.max=', 255.0, 'yuv.min=', -11.140129999999996)
('yuv.max=', 234.95999999999998, 'yuv.min=', -20.750229999999991)
('yuv.max=', 220.93700000000001, 'yuv.min=', -9.5845700000000136)
('yuv.max=', 210.768, 'yuv.min=', -39.401679999999999)
('yuv.max=', 234.10900000000001, 'yuv.min=', -21.825219999999995)
('yuv.max=', 255.0, 'yuv.min=', -35.983349999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -15.678830000000001)
('yuv.max=', 255.0, 'yuv.min=', -22.56609000000001)
('yuv.max=', 228.08899999999997, 'yuv.min=', -19.682410000000001)
('yuv.max=', 255.0, 'yuv.min=', -75.343700000000013)
('yuv.max=', 249.00999999999999, 'yuv.min=', -42.044029999999999)
('yuv.max=', 231.226, 'yuv.min=', -20.000769999999999)
('yuv.max=', 237.90299999999999, 'yuv.min=', -32.637770000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -62.710270000000001)
('yuv.max=', 253.505, 'yuv.min=', -56.25009)
('yuv.max=', 255.0, 'yuv.min=', -23.455069999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -21.956730000000004)
('yuv.max=', 215.09099999999998, 'yuv.min=', -54.425830000000005)
('yuv.max=', 237.14599999999996, 'yuv.min=', -13.961760000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.260419999999996)
('yuv.max=', 246.0, 'yuv.min=', -7.2693399999999997)
('yuv.max=', 221.21800000000002, 'yuv.min=', -32.484780000000001)
('yuv.max=', 207.78299999999999, 'yuv.min=', -66.200469999999996)
('yuv.max=', 198.43000000000001, 'yuv.min=', -43.945519999999988)
('yuv.max=', 255.0, 'yuv.min=', -82.120339999999999)
('yuv.max=', 255.0, 'yuv.min=', -80.934670000000011)
('yuv.max=', 250.79300000000001, 'yuv.min=', -21.911730000000006)
('yuv.max=', 250.626, 'yuv.min=', -4.9528099999999995)
('yuv.max=', 237.71599999999998, 'yuv.min=', -47.905670000000001)
('yuv.max=', 230.28100000000001, 'yuv.min=', -49.535709999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.659520000000001)
('yuv.max=', 192.69999999999999, 'yuv.min=', -24.843289999999996)
('yuv.max=', 246.12300000000002, 'yuv.min=', -46.630849999999995)
('yuv.max=', 240.47399999999999, 'yuv.min=', -24.195389999999996)
('yuv.max=', 187.80799999999999, 'yuv.min=', -34.205529999999982)
('yuv.max=', 251.495, 'yuv.min=', -27.095349999999996)
('yuv.max=', 232.45599999999999, 'yuv.min=', -12.870179999999991)
('yuv.max=', 159.16299999999998, 'yuv.min=', -13.613679999999999)
('yuv.max=', 227.822, 'yuv.min=', -26.65352)
('yuv.max=', 240.31599999999997, 'yuv.min=', -38.925509999999996)
('yuv.max=', 231.267, 'yuv.min=', -36.910369999999993)
('yuv.max=', 234.19999999999999, 'yuv.min=', -11.980460000000001)
('yuv.max=', 255.0, 'yuv.min=', -15.084649999999996)
('yuv.max=', 247.86499999999998, 'yuv.min=', -28.200359999999989)
('yuv.max=', 218.69, 'yuv.min=', -79.255729999999986)
('yuv.max=', 203.42099999999999, 'yuv.min=', -56.930649999999986)
('yuv.max=', 255.0, 'yuv.min=', -17.305069999999994)
('yuv.max=', 231.43099999999998, 'yuv.min=', -53.854680000000002)
('yuv.max=', 228.85399999999998, 'yuv.min=', -14.56635)
('yuv.max=', 246.28299999999999, 'yuv.min=', -46.285999999999994)
('yuv.max=', 255.0, 'yuv.min=', -20.947890000000001)
('yuv.max=', 241.91399999999999, 'yuv.min=', -20.196830000000002)
('yuv.max=', 242.96099999999996, 'yuv.min=', -17.034160000000014)
('yuv.max=', 240.078, 'yuv.min=', -20.606180000000002)
('yuv.max=', 164.0, 'yuv.min=', -27.685369999999999)
('yuv.max=', 197.74000000000001, 'yuv.min=', -50.970880000000001)
('yuv.max=', 252.28800000000001, 'yuv.min=', -64.625619999999998)
('yuv.max=', 148.01100000000002, 'yuv.min=', -62.520839999999993)
('yuv.max=', 253.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 204.18499999999997, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 255.0, 'yuv.min=', -23.312470000000005)
('yuv.max=', 176.285, 'yuv.min=', -13.819589999999998)
('yuv.max=', 237.70899999999997, 'yuv.min=', -24.265519999999999)
('yuv.max=', 255.0, 'yuv.min=', -67.200569999999985)
('yuv.max=', 255.0, 'yuv.min=', -78.530349999999984)
('yuv.max=', 237.13800000000001, 'yuv.min=', -21.705509999999997)
('yuv.max=', 240.54399999999998, 'yuv.min=', -33.402120000000011)
('yuv.max=', 234.834, 'yuv.min=', -54.132079999999995)
('yuv.max=', 174.95000000000002, 'yuv.min=', -25.240309999999994)
('yuv.max=', 240.22799999999998, 'yuv.min=', -53.009519999999995)
('yuv.max=', 233.32500000000002, 'yuv.min=', -95.998800000000017)
('yuv.max=', 250.83599999999998, 'yuv.min=', -63.125469999999993)
('yuv.max=', 175.79599999999996, 'yuv.min=', -35.679470000000002)
('yuv.max=', 237.32499999999999, 'yuv.min=', -34.950420000000001)
('yuv.max=', 239.95699999999999, 'yuv.min=', -32.485489999999999)
('yuv.max=', 177.45099999999999, 'yuv.min=', -33.860679999999988)
('yuv.max=', 210.05199999999999, 'yuv.min=', -24.350589999999997)
('yuv.max=', 234.31, 'yuv.min=', -29.970659999999992)
('yuv.max=', 146.08699999999999, 'yuv.min=', -15.130159999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', -24.295399999999994)
('yuv.max=', 245.65799999999999, 'yuv.min=', -25.255249999999986)
('yuv.max=', 244.08799999999999, 'yuv.min=', -16.162709999999997)
('yuv.max=', 205.91199999999998, 'yuv.min=', -60.672219999999996)
('yuv.max=', 229.58000000000001, 'yuv.min=', -48.550549999999987)
('yuv.max=', 195.61299999999997, 'yuv.min=', -44.080800000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.883890000000001)
('yuv.max=', 229.97899999999996, 'yuv.min=', -39.555449999999986)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.45799999999997, 'yuv.min=', -35.825199999999981)
('yuv.max=', 244.18899999999999, 'yuv.min=', -31.660459999999983)
('yuv.max=', 240.43999999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 213.31700000000001, 'yuv.min=', -25.855309999999978)
('yuv.max=', 243.72199999999998, 'yuv.min=', -39.040459999999996)
('yuv.max=', 118.56299999999999, 'yuv.min=', -26.695639999999997)
('yuv.max=', 229.92299999999997, 'yuv.min=', -45.346450000000004)
('yuv.max=', 184.68800000000002, 'yuv.min=', -63.565759999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 248.24699999999999, 'yuv.min=', -51.395649999999989)
('yuv.max=', 227.755, 'yuv.min=', -11.770069999999993)
('yuv.max=', 216.37, 'yuv.min=', -24.310339999999989)
('yuv.max=', 236.334, 'yuv.min=', -46.671099999999996)
('yuv.max=', 255.0, 'yuv.min=', -42.839770000000001)
('yuv.max=', 227.09799999999998, 'yuv.min=', -52.640589999999996)
('yuv.max=', 212.44399999999999, 'yuv.min=', -22.465339999999991)
('yuv.max=', 239.131, 'yuv.min=', -19.640340000000002)
('yuv.max=', 186.58099999999999, 'yuv.min=', -36.880489999999988)
('yuv.max=', 217.32900000000001, 'yuv.min=', -34.105519999999999)
('yuv.max=', 212.661, 'yuv.min=', -30.49021999999999)
('yuv.max=', 233.35499999999999, 'yuv.min=', -16.000369999999997)
('yuv.max=', 237.86099999999999, 'yuv.min=', -75.274839999999998)
('yuv.max=', 154.42099999999999, 'yuv.min=', -68.936419999999998)
('yuv.max=', 184.024, 'yuv.min=', -15.985429999999994)
('yuv.max=', 247.548, 'yuv.min=', -50.980669999999996)
('yuv.max=', 252.81499999999997, 'yuv.min=', -76.325559999999996)
('yuv.max=', 192.34399999999999, 'yuv.min=', -38.225439999999999)
('yuv.max=', 233.55599999999998, 'yuv.min=', -35.880390000000006)
('yuv.max=', 252.77199999999999, 'yuv.min=', -29.363389999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.33199999999999, 'yuv.min=', -11.440159999999995)
('yuv.max=', 214.13499999999999, 'yuv.min=', -29.715450000000004)
('yuv.max=', 252.92899999999997, 'yuv.min=', -19.675429999999995)
('yuv.max=', 255.0, 'yuv.min=', -6.4603999999999964)
('yuv.max=', 255.0, 'yuv.min=', -33.503309999999999)
('yuv.max=', 248.768, 'yuv.min=', -15.51361)
('yuv.max=', 220.91799999999998, 'yuv.min=', -14.600229999999998)
('yuv.max=', 252.821, 'yuv.min=', -46.442160000000015)
('yuv.max=', 240.071, 'yuv.min=', -153.73505999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.440340000000006)
('yuv.max=', 236.05799999999999, 'yuv.min=', -39.700279999999992)
('yuv.max=', 243.89699999999999, 'yuv.min=', -39.079479999999997)
('yuv.max=', 255.0, 'yuv.min=', -28.4452)
('yuv.max=', 221.86499999999998, 'yuv.min=', -21.820239999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.245729999999995)
('yuv.max=', 248.441, 'yuv.min=', -20.350189999999984)
('yuv.max=', 152.14999999999998, 'yuv.min=', -41.97063)
('yuv.max=', 213.75099999999998, 'yuv.min=', -10.772530000000003)
('yuv.max=', 252.886, 'yuv.min=', -9.9114700000000084)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 177.27200000000002, 'yuv.min=', -45.915839999999989)
('yuv.max=', 255.0, 'yuv.min=', -8.6908999999999992)
('yuv.max=', 195.68199999999999, 'yuv.min=', -48.850579999999979)
('yuv.max=', 231.15100000000001, 'yuv.min=', -21.132609999999993)
('yuv.max=', 242.33500000000001, 'yuv.min=', -32.19653000000001)
('yuv.max=', 250.59800000000001, 'yuv.min=', -17.160239999999988)
('yuv.max=', 254.08800000000002, 'yuv.min=', -18.337799999999994)
('yuv.max=', 205.11499999999998, 'yuv.min=', -30.84544)
('yuv.max=', 248.61499999999998, 'yuv.min=', -28.946640000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.348189999999999)
('yuv.max=', 222.04299999999998, 'yuv.min=', -24.120450000000002)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -10.969989999999989)
('yuv.max=', 210.31, 'yuv.min=', -15.41525)
('yuv.max=', 214.54599999999999, 'yuv.min=', -25.45496)
('yuv.max=', 255.0, 'yuv.min=', -20.520329999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 188.90799999999999, 'yuv.min=', -37.520799999999994)
('yuv.max=', 193.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 229.89099999999996, 'yuv.min=', -27.270389999999992)
('yuv.max=', 245.869, 'yuv.min=', -87.940429999999992)
('yuv.max=', 243.76199999999997, 'yuv.min=', -90.19999)
('yuv.max=', 236.232, 'yuv.min=', -40.900399999999991)
('yuv.max=', 233.96799999999999, 'yuv.min=', -26.998149999999995)
('yuv.max=', 248.35900000000001, 'yuv.min=', -31.532420000000005)
('yuv.max=', 255.0, 'yuv.min=', -73.335629999999995)
('yuv.max=', 255.0, 'yuv.min=', -25.740359999999992)
('yuv.max=', 229.07999999999998, 'yuv.min=', -66.015389999999996)
('yuv.max=', 233.95899999999997, 'yuv.min=', -21.852769999999996)
('yuv.max=', 200.11599999999999, 'yuv.min=', -18.953469999999999)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.4259899999999988)
('yuv.max=', 255.0, 'yuv.min=', -29.75569999999999)
('yuv.max=', 225.91800000000001, 'yuv.min=', -46.84581)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.320379999999993)
('yuv.max=', 251.989, 'yuv.min=', -27.955519999999993)
('yuv.max=', 181.37, 'yuv.min=', -4.9634300000000025)
('yuv.max=', 255.0, 'yuv.min=', -2.0304700000000224)
('yuv.max=', 238.64999999999998, 'yuv.min=', -69.190399999999997)
('yuv.max=', 197.06199999999998, 'yuv.min=', -51.395649999999989)
('yuv.max=', 240.869, 'yuv.min=', -25.035720000000001)
('yuv.max=', 242.71199999999999, 'yuv.min=', -95.590579999999989)
('yuv.max=', 254.017, 'yuv.min=', -21.390539999999994)
('yuv.max=', 246.98899999999998, 'yuv.min=', -30.160310000000003)
('yuv.max=', 248.131, 'yuv.min=', -38.385209999999987)
('yuv.max=', 226.72899999999998, 'yuv.min=', -7.9651199999999989)
('yuv.max=', 246.21699999999998, 'yuv.min=', -12.770169999999997)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.637, 'yuv.min=', -27.120989999999992)
('yuv.max=', 253.42999999999998, 'yuv.min=', -40.240579999999994)
('yuv.max=', 241.61200000000002, 'yuv.min=', -41.31537999999999)
('yuv.max=', 244.148, 'yuv.min=', -54.620049999999999)
('yuv.max=', 225.31799999999998, 'yuv.min=', -89.34057)
('yuv.max=', 249.79299999999998, 'yuv.min=', -98.365549999999999)
('yuv.max=', 220.47300000000001, 'yuv.min=', -23.795349999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -42.355729999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.34541999999999)
('yuv.max=', 224.30500000000001, 'yuv.min=', -16.504989999999999)
('yuv.max=', 208.739, 'yuv.min=', -29.579950000000004)
('yuv.max=', 250.98899999999998, 'yuv.min=', -69.375479999999996)
('yuv.max=', 236.31699999999998, 'yuv.min=', -41.015349999999991)
('yuv.max=', 220.572, 'yuv.min=', -5.3826099999999997)
('yuv.max=', 230.65699999999998, 'yuv.min=', -45.790519999999987)
('yuv.max=', 208.672, 'yuv.min=', -43.298850000000002)
('yuv.max=', 143.49199999999999, 'yuv.min=', -32.723190000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.01900000000001, 'yuv.min=', -30.530470000000001)
('yuv.max=', 247.95099999999996, 'yuv.min=', -38.556370000000008)
('yuv.max=', 185.62799999999999, 'yuv.min=', -24.675069999999998)
('yuv.max=', 248.76100000000002, 'yuv.min=', -34.410119999999992)
('yuv.max=', 210.71299999999999, 'yuv.min=', -24.995470000000005)
('yuv.max=', 233.0, 'yuv.min=', -19.251970000000014)
('yuv.max=', 239.98299999999998, 'yuv.min=', -89.349589999999992)
('yuv.max=', 250.79900000000004, 'yuv.min=', -18.583770000000005)
('yuv.max=', 166.47099999999998, 'yuv.min=', -42.971200000000003)
('yuv.max=', 255.0, 'yuv.min=', -42.442900000000009)
('yuv.max=', 234.114, 'yuv.min=', -36.060850000000002)
('yuv.max=', 235.33599999999998, 'yuv.min=', -70.34602000000001)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.148, 'yuv.min=', -96.42398)
('yuv.max=', 255.0, 'yuv.min=', -18.698729999999998)
('yuv.max=', 203.63299999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 223.95899999999997, 'yuv.min=', -12.140229999999994)
('yuv.max=', 221.375, 'yuv.min=', -30.930509999999998)
('yuv.max=', 167.85599999999999, 'yuv.min=', -23.065399999999993)
('yuv.max=', 255.0, 'yuv.min=', -33.373049999999999)
('yuv.max=', 193.43199999999999, 'yuv.min=', -21.72501999999999)
('yuv.max=', 241.76299999999995, 'yuv.min=', -58.620449999999991)
('yuv.max=', 230.14399999999998, 'yuv.min=', -36.120659999999987)
('yuv.max=', 210.02499999999998, 'yuv.min=', -43.145439999999994)
('yuv.max=', 255.0, 'yuv.min=', -14.030049999999996)
('yuv.max=', 251.804, 'yuv.min=', -28.725719999999995)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -38.120859999999993)
('yuv.max=', 240.92899999999997, 'yuv.min=', -80.59720999999999)
('yuv.max=', 245.05000000000001, 'yuv.min=', -28.83029999999999)
('yuv.max=', 251.17399999999998, 'yuv.min=', -25.570220000000003)
('yuv.max=', 254.886, 'yuv.min=', -26.294689999999996)
('yuv.max=', 248.815, 'yuv.min=', -27.355459999999994)
('yuv.max=', 253.11399999999998, 'yuv.min=', -25.755299999999998)
('yuv.max=', 228.44099999999997, 'yuv.min=', -30.620109999999997)
('yuv.max=', 234.22099999999998, 'yuv.min=', -30.855809999999991)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -42.420199999999994)
('yuv.max=', 248.38499999999996, 'yuv.min=', -19.479979999999994)
('yuv.max=', 251.49000000000001, 'yuv.min=', -61.475919999999995)
('yuv.max=', 252.92899999999997, 'yuv.min=', -41.860249999999979)
('yuv.max=', 237.77199999999999, 'yuv.min=', -37.477059999999994)
('yuv.max=', 210.82699999999997, 'yuv.min=', -42.110889999999998)
('yuv.max=', 248.74399999999997, 'yuv.min=', -37.410420000000002)
('yuv.max=', 255.0, 'yuv.min=', -41.325749999999992)
('yuv.max=', 225.14600000000002, 'yuv.min=', -36.245180000000005)
('yuv.max=', 152.28399999999999, 'yuv.min=', -27.830199999999991)
('yuv.max=', 230.637, 'yuv.min=', -42.355730000000001)
('yuv.max=', 223.59999999999999, 'yuv.min=', -21.389910000000004)
('yuv.max=', 219.33800000000002, 'yuv.min=', -10.053310000000003)
('yuv.max=', 253.0, 'yuv.min=', -30.425310000000003)
('yuv.max=', 235.72300000000001, 'yuv.min=', -44.005279999999985)
('yuv.max=', 179.167, 'yuv.min=', -31.20523)
('yuv.max=', 251.92899999999995, 'yuv.min=', -21.665260000000004)
('yuv.max=', 205.76599999999999, 'yuv.min=', -13.040319999999994)
('yuv.max=', 223.08399999999997, 'yuv.min=', -17.204310000000003)
('yuv.max=', 242.74799999999996, 'yuv.min=', -26.125459999999997)
('yuv.max=', 223.71199999999999, 'yuv.min=', -51.025489999999976)
('yuv.max=', 244.423, 'yuv.min=', -24.065499999999997)
('yuv.max=', 236.423, 'yuv.min=', -42.377190000000006)
('yuv.max=', 188.0, 'yuv.min=', -44.66052999999998)
('yuv.max=', 235.30999999999997, 'yuv.min=', -92.660410000000013)
('yuv.max=', 241.92299999999997, 'yuv.min=', -50.550749999999994)
('yuv.max=', 202.834, 'yuv.min=', -33.420389999999998)
('yuv.max=', 236.36999999999995, 'yuv.min=', -76.084699999999998)
('yuv.max=', 249.48399999999998, 'yuv.min=', -26.534130000000001)
('yuv.max=', 247.38300000000001, 'yuv.min=', -48.725259999999999)
('yuv.max=', 245.505, 'yuv.min=', -26.385239999999985)
('yuv.max=', 255.0, 'yuv.min=', -67.66037)
('yuv.max=', 255.0, 'yuv.min=', -41.587699999999998)
('yuv.max=', 217.39699999999999, 'yuv.min=', -29.61544)
('yuv.max=', 206.708, 'yuv.min=', -52.530209999999997)
('yuv.max=', 211.85199999999998, 'yuv.min=', -35.860879999999995)
('yuv.max=', 211.72300000000001, 'yuv.min=', -29.024090000000008)
('yuv.max=', 232.92099999999999, 'yuv.min=', -23.55507999999999)
('yuv.max=', 214.21899999999999, 'yuv.min=', -47.001009999999987)
('yuv.max=', 244.38399999999999, 'yuv.min=', -46.805559999999993)
('yuv.max=', 229.44800000000001, 'yuv.min=', -52.21067)
('yuv.max=', 253.03399999999999, 'yuv.min=', -83.335399999999979)
('yuv.max=', 214.00899999999996, 'yuv.min=', -29.555679999999999)
('yuv.max=', 248.91800000000001, 'yuv.min=', -38.544979999999995)
('yuv.max=', 245.05000000000001, 'yuv.min=', -5.3876400000000046)
('yuv.max=', 247.06, 'yuv.min=', -14.159939999999994)
('yuv.max=', 253.27700000000002, 'yuv.min=', -19.17183)
('yuv.max=', 237.30099999999999, 'yuv.min=', -53.370539999999984)
('yuv.max=', 194.69399999999999, 'yuv.min=', -14.530099999999994)
('yuv.max=', 220.58299999999997, 'yuv.min=', -9.6171499999999952)
('yuv.max=', 240.893, 'yuv.min=', -24.157259999999994)
('yuv.max=', 216.84999999999999, 'yuv.min=', -34.164310000000008)
('yuv.max=', 253.48399999999998, 'yuv.min=', -21.450299999999991)
('yuv.max=', 241.80399999999997, 'yuv.min=', -11.618229999999997)
('yuv.max=', 241.309, 'yuv.min=', -31.435129999999994)
('yuv.max=', 186.78999999999999, 'yuv.min=', -31.230539999999984)
('yuv.max=', 229.68100000000001, 'yuv.min=', -92.468299999999999)
('yuv.max=', 230.41199999999998, 'yuv.min=', -19.880019999999998)
('yuv.max=', 253.61499999999995, 'yuv.min=', -44.275429999999993)
('yuv.max=', 255.0, 'yuv.min=', -80.76615000000001)
('yuv.max=', 200.39099999999999, 'yuv.min=', -55.822099999999999)
('yuv.max=', 136.51399999999998, 'yuv.min=', -10.620570000000001)
('yuv.max=', 251.33099999999996, 'yuv.min=', -50.055269999999993)
('yuv.max=', 255.0, 'yuv.min=', -50.825469999999989)
('yuv.max=', 154.06100000000001, 'yuv.min=', -19.320209999999992)
('yuv.max=', 206.91899999999998, 'yuv.min=', -57.28295)
('yuv.max=', 255.0, 'yuv.min=', -34.523030000000013)
('yuv.max=', 233.256, 'yuv.min=', -37.618479999999998)
('yuv.max=', 248.78300000000002, 'yuv.min=', -56.960529999999991)
('yuv.max=', 255.0, 'yuv.min=', -18.375299999999985)
('yuv.max=', 202.03099999999998, 'yuv.min=', -37.250649999999993)
('yuv.max=', 231.78599999999997, 'yuv.min=', -34.151390000000006)
('yuv.max=', 253.0, 'yuv.min=', -33.97766)
('yuv.max=', 253.989, 'yuv.min=', -28.278040000000001)
('yuv.max=', 250.0, 'yuv.min=', -9.3399499999999982)
('yuv.max=', 250.31999999999999, 'yuv.min=', -24.744829999999993)
('yuv.max=', 238.50099999999998, 'yuv.min=', -43.652169999999998)
('yuv.max=', 232.71699999999998, 'yuv.min=', -25.166460000000001)
('yuv.max=', 240.13099999999997, 'yuv.min=', -21.38017)
('yuv.max=', 234.86399999999998, 'yuv.min=', -17.360259999999997)
('yuv.max=', 246.03200000000001, 'yuv.min=', -37.510429999999992)
('yuv.max=', 255.0, 'yuv.min=', -33.460639999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.625239999999994)
('yuv.max=', 251.74399999999997, 'yuv.min=', -29.03145)
('yuv.max=', 249.56999999999996, 'yuv.min=', -54.406319999999994)
('yuv.max=', 154.95699999999999, 'yuv.min=', -34.705580000000005)
('yuv.max=', 100.62, 'yuv.min=', -33.610039999999991)
('yuv.max=', 196.03999999999996, 'yuv.min=', -62.263669999999991)
('yuv.max=', 185.09, 'yuv.min=', -25.595529999999997)
('yuv.max=', 253.80399999999997, 'yuv.min=', -10.110149999999999)
('yuv.max=', 233.768, 'yuv.min=', -19.575419999999983)
('yuv.max=', 255.0, 'yuv.min=', -74.515039999999999)
('yuv.max=', 216.036, 'yuv.min=', -50.38060999999999)
('yuv.max=', 193.86199999999999, 'yuv.min=', -31.763530000000003)
('yuv.max=', 197.22299999999998, 'yuv.min=', -43.84550999999999)
('yuv.max=', 248.869, 'yuv.min=', -19.250080000000004)
('yuv.max=', 222.74100000000001, 'yuv.min=', -67.659190000000009)
('yuv.max=', 249.32699999999997, 'yuv.min=', -14.735240000000008)
('yuv.max=', 207.559, 'yuv.min=', -34.305539999999993)
('yuv.max=', 251.886, 'yuv.min=', -34.820529999999991)
('yuv.max=', 254.202, 'yuv.min=', -35.765439999999984)
('yuv.max=', 246.929, 'yuv.min=', -12.107869999999998)
('yuv.max=', 229.50899999999999, 'yuv.min=', -28.855609999999981)
('yuv.max=', 243.16499999999996, 'yuv.min=', -32.661060000000006)
('yuv.max=', 251.02799999999999, 'yuv.min=', -29.315040000000003)
('yuv.max=', 247.07599999999996, 'yuv.min=', -49.32074999999999)
('yuv.max=', 250.42299999999997, 'yuv.min=', -58.318110000000004)
('yuv.max=', 251.98499999999999, 'yuv.min=', -55.489050000000006)
('yuv.max=', 197.37799999999999, 'yuv.min=', -54.856980000000007)
('yuv.max=', 255.0, 'yuv.min=', -29.085509999999996)
('yuv.max=', 212.12900000000002, 'yuv.min=', -34.135400000000004)
('yuv.max=', 215.98899999999998, 'yuv.min=', -51.850879999999982)
('yuv.max=', 253.81499999999997, 'yuv.min=', -34.377859999999998)
('yuv.max=', 185.84299999999996, 'yuv.min=', -20.135229999999989)
('yuv.max=', 255.0, 'yuv.min=', -6.2051899999999875)
('yuv.max=', 179.036, 'yuv.min=', -22.780309999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', -20.12028999999999)
('yuv.max=', 241.33099999999999, 'yuv.min=', -30.050890000000003)
('yuv.max=', 202.23299999999998, 'yuv.min=', -23.910299999999992)
('yuv.max=', 187.19, 'yuv.min=', -17.123539999999998)
('yuv.max=', 255.0, 'yuv.min=', -8.3306600000000088)
('yuv.max=', 223.07099999999997, 'yuv.min=', -41.185489999999994)
('yuv.max=', 252.50499999999997, 'yuv.min=', -27.470409999999998)
('yuv.max=', 246.96100000000001, 'yuv.min=', -21.250279999999989)
('yuv.max=', 251.142, 'yuv.min=', -25.840369999999989)
('yuv.max=', 247.39099999999996, 'yuv.min=', -13.31504)
('yuv.max=', 240.67999999999998, 'yuv.min=', -26.589829999999999)
('yuv.max=', 255.0, 'yuv.min=', -17.279470000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -50.3553)
('yuv.max=', 255.0, 'yuv.min=', -35.865449999999996)
('yuv.max=', 219.57299999999998, 'yuv.min=', -15.460069999999988)
('yuv.max=', 205.74799999999999, 'yuv.min=', -26.90022999999999)
('yuv.max=', 205.42999999999998, 'yuv.min=', -41.416699999999999)
('yuv.max=', 253.68999999999997, 'yuv.min=', -12.821759999999998)
('yuv.max=', 238.62999999999997, 'yuv.min=', -25.625409999999984)
('yuv.max=', 147.63399999999999, 'yuv.min=', -36.435629999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -20.79515)
('yuv.max=', 247.21599999999998, 'yuv.min=', -65.71535999999999)
('yuv.max=', 211.03900000000002, 'yuv.min=', -21.880219999999991)
('yuv.max=', 231.316, 'yuv.min=', -39.216610000000003)
('yuv.max=', 236.86900000000003, 'yuv.min=', -25.682230000000001)
('yuv.max=', 221.93599999999998, 'yuv.min=', -54.355699999999992)
('yuv.max=', 251.41300000000001, 'yuv.min=', -20.51711000000001)
('yuv.max=', 206.13900000000001, 'yuv.min=', -49.385079999999974)
('yuv.max=', 230.21299999999999, 'yuv.min=', -32.845749999999995)
('yuv.max=', 255.0, 'yuv.min=', -24.825329999999997)
('yuv.max=', 217.85299999999995, 'yuv.min=', -43.799349999999997)
('yuv.max=', 234.33699999999999, 'yuv.min=', -23.405679999999997)
('yuv.max=', 230.27099999999999, 'yuv.min=', -30.390790000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -12.7797)
('yuv.max=', 224.37899999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 248.35900000000001, 'yuv.min=', -24.250579999999985)
('yuv.max=', 254.70099999999999, 'yuv.min=', -33.150239999999997)
('yuv.max=', 173.78899999999999, 'yuv.min=', -19.761000000000003)
('yuv.max=', 244.97800000000001, 'yuv.min=', -36.780479999999997)
('yuv.max=', 248.364, 'yuv.min=', -110.18043999999999)
('yuv.max=', 180.24600000000001, 'yuv.min=', -27.730189999999997)
('yuv.max=', 252.09899999999999, 'yuv.min=', -23.710279999999994)
('yuv.max=', 253.29900000000001, 'yuv.min=', -36.654639999999993)
('yuv.max=', 226.13099999999997, 'yuv.min=', -33.88476)
('yuv.max=', 250.929, 'yuv.min=', -53.136069999999989)
('yuv.max=', 205.42699999999999, 'yuv.min=', -27.615239999999993)
('yuv.max=', 228.21499999999997, 'yuv.min=', -32.990469999999988)
('yuv.max=', 255.0, 'yuv.min=', -7.3949399999999965)
('yuv.max=', 253.518, 'yuv.min=', -27.180749999999989)
('yuv.max=', 233.11799999999999, 'yuv.min=', -25.377520000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.756, 'yuv.min=', -23.105450000000005)
('yuv.max=', 234.505, 'yuv.min=', -62.150679999999994)
('yuv.max=', 251.90699999999995, 'yuv.min=', -47.120530000000002)
('yuv.max=', 210.41899999999998, 'yuv.min=', -32.800820000000002)
('yuv.max=', 226.98100000000002, 'yuv.min=', -32.703980000000001)
('yuv.max=', 228.447, 'yuv.min=', -37.897060000000003)
('yuv.max=', 241.39499999999998, 'yuv.min=', -50.280599999999993)
('yuv.max=', 225.797, 'yuv.min=', -30.705179999999984)
('yuv.max=', 201.86199999999997, 'yuv.min=', -23.195289999999996)
('yuv.max=', 231.60499999999999, 'yuv.min=', -32.805390000000003)
('yuv.max=', 228.07399999999998, 'yuv.min=', -18.635079999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.031509999999997)
('yuv.max=', 245.59100000000001, 'yuv.min=', -25.880619999999993)
('yuv.max=', 230.499, 'yuv.min=', -16.598800000000004)
('yuv.max=', 216.00099999999998, 'yuv.min=', -66.046080000000003)
('yuv.max=', 242.50999999999996, 'yuv.min=', -61.120699999999999)
('yuv.max=', 235.41199999999998, 'yuv.min=', -33.624979999999994)
('yuv.max=', 211.875, 'yuv.min=', -21.135329999999989)
('yuv.max=', 240.733, 'yuv.min=', -12.544239999999995)
('yuv.max=', 224.63, 'yuv.min=', -25.080539999999996)
('yuv.max=', 245.41499999999999, 'yuv.min=', -37.346400000000003)
('yuv.max=', 244.05799999999996, 'yuv.min=', -13.344619999999999)
('yuv.max=', 229.00399999999999, 'yuv.min=', -30.446350000000002)
('yuv.max=', 253.0, 'yuv.min=', -17.990199999999998)
('yuv.max=', 253.185, 'yuv.min=', -13.18713)
('yuv.max=', 255.0, 'yuv.min=', -49.821259999999995)
('yuv.max=', 252.17400000000001, 'yuv.min=', -13.568719999999999)
('yuv.max=', 229.62899999999999, 'yuv.min=', -52.364639999999994)
('yuv.max=', 222.58799999999999, 'yuv.min=', -46.00090999999999)
('yuv.max=', 249.75700000000001, 'yuv.min=', -32.174210000000009)
('yuv.max=', 255.0, 'yuv.min=', -60.552040000000005)
('yuv.max=', 250.21699999999998, 'yuv.min=', -23.310239999999997)
('yuv.max=', 248.14599999999999, 'yuv.min=', -13.000069999999997)
('yuv.max=', 255.0, 'yuv.min=', -26.200159999999993)
('yuv.max=', 186.66399999999999, 'yuv.min=', -65.685839999999999)
('yuv.max=', 253.886, 'yuv.min=', -50.110460000000003)
('yuv.max=', 204.399, 'yuv.min=', -77.800399999999996)
('yuv.max=', 240.81900000000002, 'yuv.min=', -45.50542999999999)
('yuv.max=', 254.47300000000001, 'yuv.min=', -29.358059999999998)
('yuv.max=', 204.59799999999998, 'yuv.min=', -30.445399999999992)
('yuv.max=', 225.21699999999998, 'yuv.min=', -23.117339999999999)
('yuv.max=', 248.071, 'yuv.min=', -31.608150000000006)
('yuv.max=', 255.0, 'yuv.min=', -12.810420000000001)
('yuv.max=', 251.09199999999998, 'yuv.min=', -31.790349999999997)
('yuv.max=', 173.45600000000002, 'yuv.min=', -47.481549999999999)
('yuv.max=', 241.60999999999999, 'yuv.min=', -44.176299999999998)
('yuv.max=', 232.73399999999998, 'yuv.min=', -66.296600000000012)
('yuv.max=', 233.15299999999999, 'yuv.min=', -10.925169999999994)
('yuv.max=', 238.625, 'yuv.min=', -48.03555999999999)
('yuv.max=', 240.065, 'yuv.min=', -51.655429999999996)
('yuv.max=', 237.452, 'yuv.min=', -53.270530000000001)
('yuv.max=', 237.01999999999998, 'yuv.min=', -30.47527999999998)
('yuv.max=', 211.45399999999998, 'yuv.min=', -27.770439999999983)
('yuv.max=', 238.714, 'yuv.min=', -49.680540000000001)
('yuv.max=', 253.505, 'yuv.min=', -24.310339999999993)
('yuv.max=', 207.65199999999996, 'yuv.min=', -17.590989999999998)
('yuv.max=', 232.19599999999997, 'yuv.min=', -19.313950000000002)
('yuv.max=', 242.39999999999998, 'yuv.min=', -26.223019999999998)
('yuv.max=', 225.167, 'yuv.min=', -17.849939999999997)
('yuv.max=', 153.54399999999998, 'yuv.min=', -45.290469999999985)
('yuv.max=', 223.47499999999999, 'yuv.min=', -7.5569500000000005)
('yuv.max=', 241.56999999999999, 'yuv.min=', -72.820639999999997)
('yuv.max=', 227.048, 'yuv.min=', -42.686870000000006)
('yuv.max=', 247.53799999999998, 'yuv.min=', -31.44923)
('yuv.max=', 225.06099999999998, 'yuv.min=', -32.87551999999998)
('yuv.max=', 210.233, 'yuv.min=', -24.740259999999999)
('yuv.max=', 198.23599999999999, 'yuv.min=', -29.553310000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -17.00329)
('yuv.max=', 255.0, 'yuv.min=', -14.282879999999999)
('yuv.max=', 255.0, 'yuv.min=', -34.402870000000007)
('yuv.max=', 187.51499999999999, 'yuv.min=', -20.686070000000001)
('yuv.max=', 224.785, 'yuv.min=', -27.395709999999987)
('yuv.max=', 200.559, 'yuv.min=', -34.915430000000001)
('yuv.max=', 183.27699999999999, 'yuv.min=', -41.795919999999988)
('yuv.max=', 250.245, 'yuv.min=', -8.8265400000000014)
('yuv.max=', 238.511, 'yuv.min=', -79.861350000000002)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.756, 'yuv.min=', -27.236849999999997)
('yuv.max=', 213.65299999999999, 'yuv.min=', -10.140029999999994)
('yuv.max=', 243.70099999999999, 'yuv.min=', -36.080409999999986)
('yuv.max=', 251.44499999999996, 'yuv.min=', -89.568089999999998)
('yuv.max=', 255.0, 'yuv.min=', -10.09774)
('yuv.max=', 205.625, 'yuv.min=', -99.335769999999997)
('yuv.max=', 246.35900000000001, 'yuv.min=', -40.554910000000007)
('yuv.max=', 243.42699999999999, 'yuv.min=', -33.665229999999987)
('yuv.max=', 223.92099999999999, 'yuv.min=', -40.300340000000006)
('yuv.max=', 231.14399999999998, 'yuv.min=', -96.925809999999998)
('yuv.max=', 236.374, 'yuv.min=', -24.650620000000004)
('yuv.max=', 237.47999999999996, 'yuv.min=', -31.045459999999988)
('yuv.max=', 226.45899999999997, 'yuv.min=', -20.680099999999978)
('yuv.max=', 181.07399999999998, 'yuv.min=', -16.620820000000002)
('yuv.max=', 242.99799999999999, 'yuv.min=', -35.892189999999999)
('yuv.max=', 192.05699999999999, 'yuv.min=', -64.034890000000004)
('yuv.max=', 224.327, 'yuv.min=', -26.910729999999997)
('yuv.max=', 172.72499999999997, 'yuv.min=', -89.857669999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.27699999999999, 'yuv.min=', -34.865349999999992)
('yuv.max=', 193.19799999999998, 'yuv.min=', -46.115859999999998)
('yuv.max=', 247.43000000000001, 'yuv.min=', -33.635350000000003)
('yuv.max=', 239.29300000000001, 'yuv.min=', -8.2986599999999981)
('yuv.max=', 236.07299999999998, 'yuv.min=', -17.960319999999996)
('yuv.max=', 255.0, 'yuv.min=', -6.7351199999999949)
('yuv.max=', 193.06799999999998, 'yuv.min=', 0.25978000000000634)
('yuv.max=', 201.71899999999999, 'yuv.min=', -33.190489999999983)
('yuv.max=', 236.68899999999999, 'yuv.min=', -68.738320000000002)
('yuv.max=', 172.83700000000002, 'yuv.min=', -39.721470000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -70.571029999999993)
('yuv.max=', 249.017, 'yuv.min=', -52.371739999999996)
('yuv.max=', 234.815, 'yuv.min=', -29.645319999999987)
('yuv.max=', 245.989, 'yuv.min=', -53.570559999999993)
('yuv.max=', 237.33100000000002, 'yuv.min=', -35.625250000000008)
('yuv.max=', 225.13100000000003, 'yuv.min=', -11.20308)
('yuv.max=', 255.0, 'yuv.min=', -35.755069999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.128780000000003)
('yuv.max=', 203.364, 'yuv.min=', -23.365429999999989)
('yuv.max=', 250.65199999999999, 'yuv.min=', -30.19509)
('yuv.max=', 236.245, 'yuv.min=', -35.550479999999993)
('yuv.max=', 250.20199999999997, 'yuv.min=', -8.5819000000000045)
('yuv.max=', 220.86199999999999, 'yuv.min=', -32.605369999999979)
('yuv.max=', 167.428, 'yuv.min=', -24.280459999999998)
('yuv.max=', 221.80500000000001, 'yuv.min=', -28.210729999999998)
('yuv.max=', 228.40899999999996, 'yuv.min=', -40.217500000000008)
('yuv.max=', 255.0, 'yuv.min=', -79.540819999999997)
('yuv.max=', 184.785, 'yuv.min=', -31.47537999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -3.7966200000000043)
('yuv.max=', 225.83199999999999, 'yuv.min=', -43.560419999999993)
('yuv.max=', 253.68999999999997, 'yuv.min=', -39.000209999999981)
('yuv.max=', 228.55900000000003, 'yuv.min=', -34.965359999999997)
('yuv.max=', 180.048, 'yuv.min=', -33.335319999999996)
('yuv.max=', 253.82599999999996, 'yuv.min=', -31.601880000000001)
('yuv.max=', 150.76999999999998, 'yuv.min=', -0.88248000000000104)
('yuv.max=', 210.33699999999999, 'yuv.min=', -71.050339999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.54399999999998, 'yuv.min=', -38.129330000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.786630000000002)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.812349999999999)
('yuv.max=', 251.279, 'yuv.min=', -29.036059999999999)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.85300000000001, 'yuv.min=', -27.460039999999996)
('yuv.max=', 249.83599999999998, 'yuv.min=', -59.750439999999998)
('yuv.max=', 253.505, 'yuv.min=', -18.305169999999997)
('yuv.max=', 222.58599999999998, 'yuv.min=', -22.725119999999986)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.0, 'yuv.min=', -30.590229999999995)
('yuv.max=', 248.989, 'yuv.min=', -13.029949999999994)
('yuv.max=', 255.0, 'yuv.min=', -52.432049999999997)
('yuv.max=', 175.34699999999998, 'yuv.min=', -69.460549999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.415219999999991)
('yuv.max=', 221.14999999999998, 'yuv.min=', -46.820499999999988)
('yuv.max=', 240.28299999999999, 'yuv.min=', -22.450399999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.355089999999979)
('yuv.max=', 251.13499999999999, 'yuv.min=', -91.595979999999983)
('yuv.max=', 254.886, 'yuv.min=', -33.035290000000003)
('yuv.max=', 248.124, 'yuv.min=', -23.495319999999992)
('yuv.max=', 251.27700000000002, 'yuv.min=', -45.750269999999993)
('yuv.max=', 253.17399999999998, 'yuv.min=', -43.075309999999988)
('yuv.max=', 182.46399999999997, 'yuv.min=', -45.275529999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.240750000000006)
('yuv.max=', 252.13099999999997, 'yuv.min=', -23.510259999999988)
('yuv.max=', 220.11399999999998, 'yuv.min=', -13.672010000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 213.94999999999999, 'yuv.min=', -40.025620000000004)
('yuv.max=', 228.554, 'yuv.min=', -16.890089999999997)
('yuv.max=', 231.30100000000002, 'yuv.min=', -16.515360000000001)
('yuv.max=', 251.84299999999996, 'yuv.min=', -33.250250000000001)
('yuv.max=', 242.649, 'yuv.min=', -9.4654299999999978)
('yuv.max=', 177.80699999999999, 'yuv.min=', -20.260549999999995)
('yuv.max=', 245.167, 'yuv.min=', -28.345189999999999)
('yuv.max=', 235.809, 'yuv.min=', -30.960389999999993)
('yuv.max=', 245.745, 'yuv.min=', -54.581029999999991)
('yuv.max=', 249.01999999999998, 'yuv.min=', -48.251860000000001)
('yuv.max=', 250.71099999999998, 'yuv.min=', -30.751900000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.725219999999997)
('yuv.max=', 229.38499999999999, 'yuv.min=', -28.774319999999996)
('yuv.max=', 244.928, 'yuv.min=', -39.480749999999993)
('yuv.max=', 255.0, 'yuv.min=', -32.435710000000014)
('yuv.max=', 239.23099999999997, 'yuv.min=', -59.287330000000011)
('yuv.max=', 250.22800000000001, 'yuv.min=', -34.810159999999996)
('yuv.max=', 225.07900000000001, 'yuv.min=', -34.690639999999995)
('yuv.max=', 197.13699999999997, 'yuv.min=', -46.890629999999994)
('yuv.max=', 213.10499999999999, 'yuv.min=', -61.396920000000001)
('yuv.max=', 239.131, 'yuv.min=', -65.71535999999999)
('yuv.max=', 215.041, 'yuv.min=', -12.374709999999993)
('yuv.max=', 255.0, 'yuv.min=', -35.880389999999991)
('yuv.max=', 223.62799999999999, 'yuv.min=', -37.880589999999991)
('yuv.max=', 214.11099999999999, 'yuv.min=', -37.331149999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -57.271440000000005)
('yuv.max=', 255.0, 'yuv.min=', -54.564859999999989)
('yuv.max=', 248.684, 'yuv.min=', -23.71027999999999)
('yuv.max=', 227.63999999999999, 'yuv.min=', -19.835199999999997)
('yuv.max=', 200.55499999999998, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 225.167, 'yuv.min=', -27.425589999999985)
('yuv.max=', 255.0, 'yuv.min=', -23.525199999999991)
('yuv.max=', 229.72900000000001, 'yuv.min=', -42.000509999999991)
('yuv.max=', 204.941, 'yuv.min=', -13.083960000000005)
('yuv.max=', 227.80799999999999, 'yuv.min=', -20.350189999999998)
('yuv.max=', 234.23099999999999, 'yuv.min=', -42.905169999999998)
('yuv.max=', 251.78899999999999, 'yuv.min=', -35.940149999999996)
('yuv.max=', 202.95699999999999, 'yuv.min=', -34.862459999999999)
('yuv.max=', 176.52799999999999, 'yuv.min=', -49.305809999999994)
('yuv.max=', 144.83499999999998, 'yuv.min=', -42.844179999999994)
('yuv.max=', 229.99399999999997, 'yuv.min=', -50.040329999999997)
('yuv.max=', 253.13099999999997, 'yuv.min=', -17.602340000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 177.53699999999998, 'yuv.min=', -24.540240000000004)
('yuv.max=', 241.74200000000002, 'yuv.min=', -23.095279999999995)
('yuv.max=', 240.148, 'yuv.min=', -54.515469999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.590129999999991)
('yuv.max=', 166.97499999999999, 'yuv.min=', -24.795449999999985)
('yuv.max=', 219.25300000000001, 'yuv.min=', -15.245109999999997)
('yuv.max=', 233.69499999999999, 'yuv.min=', -15.720699999999994)
('yuv.max=', 246.49399999999997, 'yuv.min=', -26.744970000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -38.200129999999987)
('yuv.max=', 227.27099999999999, 'yuv.min=', -15.711180000000002)
('yuv.max=', 228.29899999999998, 'yuv.min=', -61.18421)
('yuv.max=', 238.04399999999998, 'yuv.min=', -12.700039999999994)
('yuv.max=', 241.06, 'yuv.min=', -22.08024)
('yuv.max=', 253.16300000000001, 'yuv.min=', -43.776790000000005)
('yuv.max=', 211.054, 'yuv.min=', -38.389779999999995)
('yuv.max=', 251.34199999999996, 'yuv.min=', -22.495219999999989)
('yuv.max=', 180.96499999999997, 'yuv.min=', -36.610339999999994)
('yuv.max=', 249.98400000000001, 'yuv.min=', -47.434370000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.22799999999998, 'yuv.min=', -9.0239499999999992)
('yuv.max=', 255.0, 'yuv.min=', -23.093630000000001)
('yuv.max=', 236.327, 'yuv.min=', -25.08905)
('yuv.max=', 242.07100000000003, 'yuv.min=', -24.725320000000007)
('yuv.max=', 255.0, 'yuv.min=', -33.589299999999994)
('yuv.max=', 219.696, 'yuv.min=', -32.775509999999997)
('yuv.max=', 228.94399999999999, 'yuv.min=', -12.425319999999989)
('yuv.max=', 196.56899999999999, 'yuv.min=', -74.814809999999994)
('yuv.max=', 198.94, 'yuv.min=', -5.5360699999999952)
('yuv.max=', 196.95099999999999, 'yuv.min=', -46.345759999999999)
('yuv.max=', 201.03200000000001, 'yuv.min=', -53.955659999999995)
('yuv.max=', 177.30200000000002, 'yuv.min=', -28.530269999999991)
('yuv.max=', 201.87700000000001, 'yuv.min=', -39.734250000000003)
('yuv.max=', 240.13099999999997, 'yuv.min=', -4.068950000000001)
('yuv.max=', 209.37899999999999, 'yuv.min=', -44.360499999999988)
('yuv.max=', 255.0, 'yuv.min=', -18.386420000000001)
('yuv.max=', 239.86899999999997, 'yuv.min=', -25.578710000000008)
('yuv.max=', 249.27600000000001, 'yuv.min=', -51.13485)
('yuv.max=', 248.113, 'yuv.min=', -66.870659999999987)
('yuv.max=', 216.262, 'yuv.min=', -7.1212000000000018)
('yuv.max=', 209.309, 'yuv.min=', -51.025490000000005)
('yuv.max=', 180.131, 'yuv.min=', -5.8092100000000002)
('yuv.max=', 237.40399999999997, 'yuv.min=', -74.83578)
('yuv.max=', 231.33499999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 254.29899999999995, 'yuv.min=', -70.090489999999988)
('yuv.max=', 227.434, 'yuv.min=', -18.794779999999999)
('yuv.max=', 242.18899999999999, 'yuv.min=', -21.525829999999999)
('yuv.max=', 227.339, 'yuv.min=', -24.915970000000002)
('yuv.max=', 240.70799999999997, 'yuv.min=', -41.060169999999999)
('yuv.max=', 172.66799999999998, 'yuv.min=', -40.202330000000003)
('yuv.max=', 247.768, 'yuv.min=', -50.69896)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.790479999999992)
('yuv.max=', 216.01499999999999, 'yuv.min=', -28.686089999999993)
('yuv.max=', 255.0, 'yuv.min=', -16.83784)
('yuv.max=', 255.0, 'yuv.min=', -53.670569999999998)
('yuv.max=', 245.49900000000002, 'yuv.min=', -54.660299999999992)
('yuv.max=', 252.35299999999998, 'yuv.min=', -18.009709999999995)
('yuv.max=', 237.762, 'yuv.min=', -64.040499999999994)
('yuv.max=', 204.18599999999998, 'yuv.min=', -27.07036999999999)
('yuv.max=', 215.18899999999996, 'yuv.min=', -63.11052999999999)
('yuv.max=', 210.11600000000001, 'yuv.min=', -26.080639999999995)
('yuv.max=', 239.40199999999999, 'yuv.min=', -30.575289999999985)
('yuv.max=', 255.0, 'yuv.min=', -34.054899999999996)
('yuv.max=', 194.761, 'yuv.min=', -45.92040999999999)
('yuv.max=', 222.70400000000001, 'yuv.min=', -44.890429999999995)
('yuv.max=', 235.18299999999999, 'yuv.min=', -36.660250000000005)
('yuv.max=', 188.43499999999997, 'yuv.min=', -25.910499999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.975159999999995)
('yuv.max=', 200.84700000000001, 'yuv.min=', -34.846410000000006)
('yuv.max=', 229.60399999999998, 'yuv.min=', -31.650130000000011)
('yuv.max=', 254.77200000000002, 'yuv.min=', -16.588990000000003)
('yuv.max=', 240.869, 'yuv.min=', -85.850589999999997)
('yuv.max=', 206.16800000000001, 'yuv.min=', -38.873090000000005)
('yuv.max=', 212.71799999999999, 'yuv.min=', -61.101189999999988)
('yuv.max=', 232.96299999999999, 'yuv.min=', -34.884860000000003)
('yuv.max=', 233.017, 'yuv.min=', -27.430159999999997)
('yuv.max=', 247.22799999999998, 'yuv.min=', -19.079939999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.480509999999997)
('yuv.max=', 232.55099999999999, 'yuv.min=', -55.603479999999998)
('yuv.max=', 199.73699999999999, 'yuv.min=', -51.005010000000013)
('yuv.max=', 233.56899999999999, 'yuv.min=', -36.710349999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -32.045559999999995)
('yuv.max=', 195.15199999999999, 'yuv.min=', -18.589480000000002)
('yuv.max=', 244.249, 'yuv.min=', -21.024949999999986)
('yuv.max=', 239.55200000000002, 'yuv.min=', -58.820469999999986)
('yuv.max=', 239.66299999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 254.017, 'yuv.min=', -25.422780000000003)
('yuv.max=', 168.62599999999998, 'yuv.min=', -4.9469899999999996)
('yuv.max=', 210.05799999999999, 'yuv.min=', -59.969030000000004)
('yuv.max=', 251.58699999999996, 'yuv.min=', -55.700649999999996)
('yuv.max=', 249.31999999999999, 'yuv.min=', -30.690240000000003)
('yuv.max=', 222.58499999999998, 'yuv.min=', -39.127849999999995)
('yuv.max=', 255.0, 'yuv.min=', -62.099360000000004)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.55500000000001, 'yuv.min=', -10.457390000000004)
('yuv.max=', 179.10299999999998, 'yuv.min=', -38.195559999999986)
('yuv.max=', 254.77200000000002, 'yuv.min=', -22.395209999999985)
('yuv.max=', 222.03299999999999, 'yuv.min=', -29.368620000000004)
('yuv.max=', 255.0, 'yuv.min=', -55.985739999999993)
('yuv.max=', 213.72499999999999, 'yuv.min=', -61.520739999999989)
('yuv.max=', 185.61499999999998, 'yuv.min=', -43.385019999999997)
('yuv.max=', 253.185, 'yuv.min=', -22.473209999999995)
('yuv.max=', 230.15300000000002, 'yuv.min=', -19.430589999999992)
('yuv.max=', 245.69599999999997, 'yuv.min=', -35.456230000000005)
('yuv.max=', 252.42999999999998, 'yuv.min=', -23.510360000000002)
('yuv.max=', 236.86899999999997, 'yuv.min=', -16.260149999999996)
('yuv.max=', 254.10300000000001, 'yuv.min=', -60.355350000000008)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 220.25999999999999, 'yuv.min=', -46.135369999999995)
('yuv.max=', 220.63, 'yuv.min=', -11.922780000000003)
('yuv.max=', 227.80900000000003, 'yuv.min=', -13.932710000000007)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.505389999999988)
('yuv.max=', 232.53999999999999, 'yuv.min=', -31.69068)
('yuv.max=', 252.10499999999996, 'yuv.min=', -93.675449999999984)
('yuv.max=', 223.316, 'yuv.min=', -16.630309999999994)
('yuv.max=', 253.071, 'yuv.min=', -19.405279999999994)
('yuv.max=', 186.327, 'yuv.min=', -32.590429999999998)
('yuv.max=', 250.83599999999998, 'yuv.min=', -32.580059999999989)
('yuv.max=', 216.43899999999999, 'yuv.min=', -20.06053)
('yuv.max=', 250.34799999999996, 'yuv.min=', -19.209589999999999)
('yuv.max=', 255.0, 'yuv.min=', -6.25535)
('yuv.max=', 255.0, 'yuv.min=', -30.930509999999991)
('yuv.max=', 238.43299999999999, 'yuv.min=', -9.3404799999999977)
('yuv.max=', 244.05000000000001, 'yuv.min=', -26.615499999999997)
('yuv.max=', 234.56800000000001, 'yuv.min=', -9.4642899999999912)
('yuv.max=', 198.27099999999999, 'yuv.min=', -12.755230000000001)
('yuv.max=', 226.02999999999997, 'yuv.min=', -34.60557)
('yuv.max=', 254.54400000000001, 'yuv.min=', -14.69062000000001)
('yuv.max=', 220.64699999999999, 'yuv.min=', -12.937430000000003)
('yuv.max=', 239.863, 'yuv.min=', -8.3860100000000024)
('yuv.max=', 233.929, 'yuv.min=', -8.2890300000000039)
('yuv.max=', 243.0, 'yuv.min=', -19.060429999999993)
('yuv.max=', 253.17600000000002, 'yuv.min=', -61.480489999999989)
('yuv.max=', 170.63200000000001, 'yuv.min=', -33.111280000000008)
('yuv.max=', 174.37799999999999, 'yuv.min=', -25.114989999999999)
('yuv.max=', 238.06499999999997, 'yuv.min=', -14.60023)
('yuv.max=', 247.07300000000001, 'yuv.min=', -20.790479999999992)
('yuv.max=', 209.70399999999995, 'yuv.min=', -10.341970000000003)
('yuv.max=', 219.27699999999999, 'yuv.min=', -33.060599999999987)
('yuv.max=', 255.0, 'yuv.min=', -81.283969999999997)
('yuv.max=', 211.10299999999995, 'yuv.min=', -74.781900000000007)
('yuv.max=', 200.22899999999998, 'yuv.min=', -24.225269999999991)
('yuv.max=', 224.077, 'yuv.min=', -15.715279999999989)
('yuv.max=', 220.22799999999998, 'yuv.min=', -18.860409999999995)
('yuv.max=', 228.46000000000001, 'yuv.min=', -23.568830000000005)
('yuv.max=', 241.11799999999999, 'yuv.min=', -40.915339999999986)
('yuv.max=', 234.86799999999997, 'yuv.min=', -34.735459999999996)
('yuv.max=', 222.52699999999999, 'yuv.min=', -12.510389999999996)
('yuv.max=', 254.29899999999995, 'yuv.min=', -15.32560999999999)
('yuv.max=', 178.70899999999997, 'yuv.min=', -30.00057)
('yuv.max=', 255.0, 'yuv.min=', -73.250559999999993)
('yuv.max=', 246.18900000000002, 'yuv.min=', -61.080449999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.460070000000007)
('yuv.max=', 242.70099999999999, 'yuv.min=', -63.835909999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -12.390899999999998)
('yuv.max=', 181.76599999999999, 'yuv.min=', -54.554489999999994)
('yuv.max=', 243.13499999999999, 'yuv.min=', -14.43526)
('yuv.max=', 248.327, 'yuv.min=', -22.860750000000003)
('yuv.max=', 226.97299999999998, 'yuv.min=', -38.540409999999994)
('yuv.max=', 251.142, 'yuv.min=', -29.945349999999998)
('yuv.max=', 245.233, 'yuv.min=', -33.380139999999997)
('yuv.max=', 249.17399999999998, 'yuv.min=', -29.902100000000004)
('yuv.max=', 255.0, 'yuv.min=', -30.385639999999995)
('yuv.max=', 217.40299999999999, 'yuv.min=', -87.21380000000002)
('yuv.max=', 229.018, 'yuv.min=', -70.046769999999995)
('yuv.max=', 233.18900000000002, 'yuv.min=', -77.715329999999994)
('yuv.max=', 155.078, 'yuv.min=', -37.165579999999991)
('yuv.max=', 232.75799999999998, 'yuv.min=', -17.490149999999989)
('yuv.max=', 236.303, 'yuv.min=', -25.673340000000003)
('yuv.max=', 213.245, 'yuv.min=', -19.235139999999994)
('yuv.max=', 233.03199999999998, 'yuv.min=', -50.170219999999993)
('yuv.max=', 161.70999999999998, 'yuv.min=', -48.750569999999996)
('yuv.max=', 253.41299999999998, 'yuv.min=', -28.170390000000005)
('yuv.max=', 252.935, 'yuv.min=', -29.944110000000002)
('yuv.max=', 241.04699999999997, 'yuv.min=', -66.12236)
('yuv.max=', 250.80399999999997, 'yuv.min=', -29.845339999999993)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -28.975070000000009)
('yuv.max=', 226.47299999999998, 'yuv.min=', -21.81965000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 246.41199999999998, 'yuv.min=', -35.610240000000005)
('yuv.max=', 237.37700000000001, 'yuv.min=', -26.669810000000005)
('yuv.max=', 242.58899999999997, 'yuv.min=', -73.251169999999988)
('yuv.max=', 242.48399999999998, 'yuv.min=', -72.650499999999994)
('yuv.max=', 241.869, 'yuv.min=', -16.315339999999996)
('yuv.max=', 194.297, 'yuv.min=', -45.308389999999996)
('yuv.max=', 198.10499999999999, 'yuv.min=', -47.560819999999993)
('yuv.max=', 254.70099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 196.42899999999997, 'yuv.min=', -18.033239999999999)
('yuv.max=', 217.19300000000001, 'yuv.min=', -62.48227)
('yuv.max=', 243.989, 'yuv.min=', -6.2500099999999961)
('yuv.max=', 228.16999999999999, 'yuv.min=', -23.699740000000006)
('yuv.max=', 209.095, 'yuv.min=', -36.940249999999999)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 237.79199999999997, 'yuv.min=', -47.050399999999996)
('yuv.max=', 219.31, 'yuv.min=', -14.995699999999999)
('yuv.max=', 224.08199999999997, 'yuv.min=', -21.553300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.262, 'yuv.min=', -40.92577)
('yuv.max=', 216.44499999999999, 'yuv.min=', -29.379739999999991)
('yuv.max=', 232.81799999999998, 'yuv.min=', -95.08896)
('yuv.max=', 152.22399999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 236.74599999999998, 'yuv.min=', -19.320209999999989)
('yuv.max=', 251.76599999999999, 'yuv.min=', -101.99578999999999)
('yuv.max=', 246.77799999999996, 'yuv.min=', -34.824740000000006)
('yuv.max=', 247.90099999999998, 'yuv.min=', -18.020080000000004)
('yuv.max=', 234.12800000000001, 'yuv.min=', -46.071039999999996)
('yuv.max=', 224.69000000000003, 'yuv.min=', -8.217290000000002)
('yuv.max=', 223.57599999999999, 'yuv.min=', -36.540209999999995)
('yuv.max=', 239.40000000000001, 'yuv.min=', -90.295850000000002)
('yuv.max=', 228.41499999999999, 'yuv.min=', -34.846069999999997)
('yuv.max=', 248.04900000000001, 'yuv.min=', -28.926060000000007)
('yuv.max=', 244.518, 'yuv.min=', -22.020440000000004)
('yuv.max=', 251.21299999999999, 'yuv.min=', -49.950689999999994)
('yuv.max=', 253.46199999999999, 'yuv.min=', -20.250179999999997)
('yuv.max=', 251.15699999999998, 'yuv.min=', -8.2800899999999995)
('yuv.max=', 255.0, 'yuv.min=', -33.190489999999997)
('yuv.max=', 194.74999999999997, 'yuv.min=', -38.280630000000002)
('yuv.max=', 241.35399999999998, 'yuv.min=', -22.615290000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999998)
('yuv.max=', 220.45599999999999, 'yuv.min=', -15.545139999999996)
('yuv.max=', 226.238, 'yuv.min=', -32.375469999999993)
('yuv.max=', 245.983, 'yuv.min=', -18.152900000000002)
('yuv.max=', 251.71100000000001, 'yuv.min=', -53.81539999999999)
('yuv.max=', 244.982, 'yuv.min=', -69.560559999999995)
('yuv.max=', 244.74399999999997, 'yuv.min=', -39.433660000000003)
('yuv.max=', 224.06100000000001, 'yuv.min=', -47.175719999999984)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -53.966029999999989)
('yuv.max=', 208.96600000000001, 'yuv.min=', -3.0301799999999943)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.005209999999995)
('yuv.max=', 250.94599999999997, 'yuv.min=', -23.180349999999986)
('yuv.max=', 232.37200000000001, 'yuv.min=', -61.20085000000001)
('yuv.max=', 235.60900000000001, 'yuv.min=', -6.505219999999996)
('yuv.max=', 250.34200000000001, 'yuv.min=', -39.020300000000006)
('yuv.max=', 236.31299999999999, 'yuv.min=', -57.715789999999998)
('yuv.max=', 214.28199999999998, 'yuv.min=', -25.385139999999996)
('yuv.max=', 185.05099999999999, 'yuv.min=', -29.915469999999988)
('yuv.max=', 246.80399999999997, 'yuv.min=', -39.395679999999999)
('yuv.max=', 212.047, 'yuv.min=', -16.730179999999997)
('yuv.max=', 227.762, 'yuv.min=', -32.720319999999987)
('yuv.max=', 235.03699999999998, 'yuv.min=', -80.930589999999995)
('yuv.max=', 253.21699999999998, 'yuv.min=', -29.375169999999997)
('yuv.max=', 240.92599999999999, 'yuv.min=', -52.125599999999984)
('yuv.max=', 255.0, 'yuv.min=', -24.555179999999993)
('yuv.max=', 244.84099999999998, 'yuv.min=', -9.8951899999999959)
('yuv.max=', 251.16800000000001, 'yuv.min=', -27.315209999999986)
('yuv.max=', 233.63499999999999, 'yuv.min=', -33.950319999999998)
('yuv.max=', 253.376, 'yuv.min=', -41.879759999999997)
('yuv.max=', 223.78299999999999, 'yuv.min=', -42.645389999999992)
('yuv.max=', 205.369, 'yuv.min=', -55.230479999999986)
('yuv.max=', 255.0, 'yuv.min=', -32.950219999999987)
('yuv.max=', 206.17499999999998, 'yuv.min=', -6.7234800000000021)
('yuv.max=', 255.0, 'yuv.min=', -12.507250000000003)
('yuv.max=', 240.00499999999997, 'yuv.min=', -18.178840000000008)
('yuv.max=', 212.74899999999997, 'yuv.min=', -32.985900000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -18.005139999999997)
('yuv.max=', 213.70499999999998, 'yuv.min=', -60.824649999999991)
('yuv.max=', 249.85399999999998, 'yuv.min=', -2.3301000000000158)
('yuv.max=', 242.184, 'yuv.min=', -19.913690000000003)
('yuv.max=', 247.88600000000002, 'yuv.min=', -14.974959999999996)
('yuv.max=', 255.0, 'yuv.min=', -21.613799999999998)
('yuv.max=', 245.96099999999998, 'yuv.min=', -23.710449999999994)
('yuv.max=', 199.37299999999999, 'yuv.min=', -33.850309999999993)
('yuv.max=', 226.89399999999998, 'yuv.min=', -29.830399999999994)
('yuv.max=', 224.10299999999998, 'yuv.min=', -16.026160000000004)
('yuv.max=', 239.64099999999996, 'yuv.min=', -37.580559999999991)
('yuv.max=', 251.15699999999998, 'yuv.min=', -17.040800000000008)
('yuv.max=', 121.03400000000001, 'yuv.min=', -38.425460000000001)
('yuv.max=', 247.952, 'yuv.min=', -72.89533999999999)
('yuv.max=', 255.0, 'yuv.min=', -74.776510000000002)
('yuv.max=', 245.08799999999999, 'yuv.min=', -21.499280000000002)
('yuv.max=', 237.30999999999997, 'yuv.min=', -14.785399999999999)
('yuv.max=', 157.38399999999999, 'yuv.min=', -25.770240000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.21208)
('yuv.max=', 158.83899999999997, 'yuv.min=', -50.432699999999997)
('yuv.max=', 241.94699999999997, 'yuv.min=', -36.131450000000001)
('yuv.max=', 237.19199999999998, 'yuv.min=', -36.606700000000004)
('yuv.max=', 173.27899999999997, 'yuv.min=', -36.550579999999997)
('yuv.max=', 255.0, 'yuv.min=', -29.400439999999996)
('yuv.max=', 251.77199999999999, 'yuv.min=', -83.02042999999999)
('yuv.max=', 240.0, 'yuv.min=', -39.740529999999993)
('yuv.max=', 223.09899999999996, 'yuv.min=', -23.024160000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 225.26400000000001, 'yuv.min=', -63.970369999999996)
('yuv.max=', 205.11499999999998, 'yuv.min=', -49.970199999999991)
('yuv.max=', 209.88799999999998, 'yuv.min=', -86.446079999999995)
('yuv.max=', 244.87599999999998, 'yuv.min=', -26.201930000000008)
('yuv.max=', 240.08599999999998, 'yuv.min=', -34.25034999999999)
('yuv.max=', 250.255, 'yuv.min=', -20.980129999999992)
('yuv.max=', 254.202, 'yuv.min=', -38.971159999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 242.57900000000001, 'yuv.min=', -29.209240000000001)
('yuv.max=', 207.429, 'yuv.min=', -39.881420000000006)
('yuv.max=', 253.86000000000001, 'yuv.min=', -46.404289999999996)
('yuv.max=', 248.32599999999999, 'yuv.min=', -33.08402000000001)
('yuv.max=', 239.64799999999997, 'yuv.min=', -22.507860000000001)
('yuv.max=', 230.21699999999998, 'yuv.min=', -31.652850000000001)
('yuv.max=', 236.32900000000001, 'yuv.min=', -31.779979999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -27.740559999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -44.175419999999995)
('yuv.max=', 218.0, 'yuv.min=', -12.65954)
('yuv.max=', 253.80399999999997, 'yuv.min=', -45.905469999999994)
('yuv.max=', 228.196, 'yuv.min=', -78.151049999999998)
('yuv.max=', 200.58599999999998, 'yuv.min=', -37.035689999999995)
('yuv.max=', 254.28799999999998, 'yuv.min=', -21.365229999999993)
('yuv.max=', 246.31, 'yuv.min=', -14.030049999999994)
('yuv.max=', 237.97399999999996, 'yuv.min=', -49.865480000000005)
('yuv.max=', 201.94099999999997, 'yuv.min=', -45.275529999999989)
('yuv.max=', 246.815, 'yuv.min=', -35.605669999999996)
('yuv.max=', 245.191, 'yuv.min=', -34.420490000000001)
('yuv.max=', 127.15899999999999, 'yuv.min=', -39.340489999999996)
('yuv.max=', 253.40199999999996, 'yuv.min=', -24.710379999999997)
('yuv.max=', 240.411, 'yuv.min=', -54.437500000000014)
('yuv.max=', 255.0, 'yuv.min=', -9.87331)
('yuv.max=', 205.81699999999998, 'yuv.min=', -48.545250000000003)
('yuv.max=', 250.815, 'yuv.min=', -33.875619999999998)
('yuv.max=', 250.44499999999996, 'yuv.min=', -19.090309999999988)
('yuv.max=', 239.22799999999995, 'yuv.min=', -34.61142000000001)
('yuv.max=', 237.03, 'yuv.min=', -14.170309999999999)
('yuv.max=', 240.88599999999997, 'yuv.min=', -96.005559999999988)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.75299999999999, 'yuv.min=', -25.825429999999987)
('yuv.max=', 168.303, 'yuv.min=', -32.185819999999993)
('yuv.max=', 184.17400000000001, 'yuv.min=', -37.565619999999996)
('yuv.max=', 255.0, 'yuv.min=', -62.241759999999992)
('yuv.max=', 211.68199999999999, 'yuv.min=', -11.655119999999993)
('yuv.max=', 246.32900000000001, 'yuv.min=', -36.385009999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -76.826040000000006)
('yuv.max=', 255.0, 'yuv.min=', -14.970389999999998)
('yuv.max=', 253.99999999999997, 'yuv.min=', -38.230670000000003)
('yuv.max=', 222.798, 'yuv.min=', -18.054270000000002)
('yuv.max=', 253.40199999999996, 'yuv.min=', -12.940310000000007)
('yuv.max=', 240.78699999999998, 'yuv.min=', -50.080579999999998)
('yuv.max=', 185.94799999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 237.18799999999999, 'yuv.min=', -46.429599999999986)
('yuv.max=', 250.94599999999997, 'yuv.min=', -15.35549)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.92699999999999, 'yuv.min=', -92.865560000000002)
('yuv.max=', 255.0, 'yuv.min=', -36.080410000000001)
('yuv.max=', 206.56299999999999, 'yuv.min=', -30.345390000000002)
('yuv.max=', 245.18399999999997, 'yuv.min=', -33.050229999999999)
('yuv.max=', 201.149, 'yuv.min=', -27.870449999999998)
('yuv.max=', 199.24299999999999, 'yuv.min=', -12.805490000000006)
('yuv.max=', 245.03199999999998, 'yuv.min=', -17.690169999999988)
('yuv.max=', 245.815, 'yuv.min=', -65.551019999999994)
('yuv.max=', 247.56899999999996, 'yuv.min=', -33.172030000000007)
('yuv.max=', 222.06199999999998, 'yuv.min=', -52.070409999999995)
('yuv.max=', 198.07399999999998, 'yuv.min=', -19.22552000000001)
('yuv.max=', 252.68599999999998, 'yuv.min=', -23.61027)
('yuv.max=', 210.29299999999998, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 238.05700000000002, 'yuv.min=', -22.850439999999985)
('yuv.max=', 252.57199999999997, 'yuv.min=', -31.013190000000009)
('yuv.max=', 254.11399999999998, 'yuv.min=', -31.145469999999992)
('yuv.max=', 254.40199999999999, 'yuv.min=', -85.050510000000003)
('yuv.max=', 226.20799999999997, 'yuv.min=', -23.995369999999998)
('yuv.max=', 199.89399999999998, 'yuv.min=', -66.960299999999989)
('yuv.max=', 255.0, 'yuv.min=', -40.68544)
('yuv.max=', 154.529, 'yuv.min=', -22.505589999999987)
('yuv.max=', 251.77199999999999, 'yuv.min=', -28.097280000000001)
('yuv.max=', 240.66799999999995, 'yuv.min=', -27.188880000000001)
('yuv.max=', 248.02199999999999, 'yuv.min=', -16.3751)
('yuv.max=', 215.619, 'yuv.min=', -16.430289999999999)
('yuv.max=', 246.10300000000001, 'yuv.min=', -24.985099999999992)
('yuv.max=', 196.52799999999999, 'yuv.min=', -60.150479999999988)
('yuv.max=', 193.82999999999998, 'yuv.min=', -30.575289999999988)
('yuv.max=', 255.0, 'yuv.min=', -31.630579999999995)
('yuv.max=', 224.13999999999999, 'yuv.min=', -12.110349999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -23.770039999999991)
('yuv.max=', 218.59699999999998, 'yuv.min=', -33.182010000000005)
('yuv.max=', 248.42400000000001, 'yuv.min=', -34.750399999999985)
('yuv.max=', 214.928, 'yuv.min=', -10.969989999999985)
('yuv.max=', 161.47900000000001, 'yuv.min=', -48.92071)
('yuv.max=', 144.251, 'yuv.min=', -51.72099)
('yuv.max=', 224.33099999999996, 'yuv.min=', -20.277610000000006)
('yuv.max=', 229.065, 'yuv.min=', -38.185189999999992)
('yuv.max=', 97.0, 'yuv.min=', -3.2899599999999993)
('yuv.max=', 249.93899999999999, 'yuv.min=', -21.646489999999996)
('yuv.max=', 231.29300000000001, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 227.93899999999999, 'yuv.min=', -18.520129999999991)
('yuv.max=', 215.93199999999999, 'yuv.min=', -35.855079999999987)
('yuv.max=', 208.404, 'yuv.min=', -55.915609999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.9823599999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.3503199999999964)
('yuv.max=', 233.62099999999998, 'yuv.min=', -35.095249999999993)
('yuv.max=', 255.0, 'yuv.min=', -23.350489999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.20199999999997, 'yuv.min=', -18.037589999999994)
('yuv.max=', 208.17699999999999, 'yuv.min=', -44.800789999999992)
('yuv.max=', 181.422, 'yuv.min=', -18.36036)
('yuv.max=', 232.73999999999998, 'yuv.min=', -25.509699999999999)
('yuv.max=', 247.90800000000002, 'yuv.min=', -20.070899999999998)
('yuv.max=', 238.12899999999999, 'yuv.min=', -29.770639999999993)
('yuv.max=', 255.0, 'yuv.min=', -42.884420000000006)
('yuv.max=', 252.61899999999997, 'yuv.min=', -34.720519999999993)
('yuv.max=', 209.76700000000002, 'yuv.min=', -50.295540000000003)
('yuv.max=', 255.0, 'yuv.min=', -61.266040000000004)
('yuv.max=', 227.77000000000001, 'yuv.min=', -39.264940000000003)
('yuv.max=', 243.01399999999998, 'yuv.min=', -28.289999999999996)
('yuv.max=', 233.95299999999997, 'yuv.min=', -21.896100000000001)
('yuv.max=', 182.166, 'yuv.min=', -17.117680000000004)
('yuv.max=', 200.28399999999999, 'yuv.min=', -59.98980000000001)
('yuv.max=', 209.62199999999999, 'yuv.min=', -37.282860000000007)
('yuv.max=', 235.79699999999997, 'yuv.min=', -15.785409999999997)
('yuv.max=', 255.0, 'yuv.min=', -12.211280000000002)
('yuv.max=', 221.99399999999997, 'yuv.min=', -17.77524)
('yuv.max=', 205.12099999999998, 'yuv.min=', -36.995439999999995)
('yuv.max=', 216.08099999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 245.95699999999999, 'yuv.min=', -37.800089999999997)
('yuv.max=', 253.70099999999996, 'yuv.min=', -28.715350000000004)
('yuv.max=', 252.64099999999996, 'yuv.min=', -12.765599999999996)
('yuv.max=', 254.886, 'yuv.min=', -81.119779999999992)
('yuv.max=', 255.0, 'yuv.min=', -9.9250699999999981)
('yuv.max=', 248.91800000000001, 'yuv.min=', -16.530299999999993)
('yuv.max=', 230.86199999999999, 'yuv.min=', -34.25034999999999)
('yuv.max=', 213.161, 'yuv.min=', -24.283989999999999)
('yuv.max=', 250.565, 'yuv.min=', -53.485489999999992)
('yuv.max=', 227.87300000000002, 'yuv.min=', -42.574210000000008)
('yuv.max=', 246.64099999999999, 'yuv.min=', -32.190860000000001)
('yuv.max=', 186.46699999999998, 'yuv.min=', -28.630279999999999)
('yuv.max=', 175.26799999999997, 'yuv.min=', -35.329580000000007)
('yuv.max=', 238.18499999999997, 'yuv.min=', -20.185980000000004)
('yuv.max=', 252.06, 'yuv.min=', -25.470209999999994)
('yuv.max=', 242.744, 'yuv.min=', -18.435059999999989)
('yuv.max=', 233.33500000000001, 'yuv.min=', -89.470460000000003)
('yuv.max=', 222.65599999999998, 'yuv.min=', -21.710789999999996)
('yuv.max=', 237.28799999999998, 'yuv.min=', -37.825399999999988)
('yuv.max=', 255.0, 'yuv.min=', -35.550479999999993)
('yuv.max=', 244.797, 'yuv.min=', -30.954270000000001)
('yuv.max=', 239.89999999999998, 'yuv.min=', -43.745499999999993)
('yuv.max=', 217.06, 'yuv.min=', -32.275459999999988)
('yuv.max=', 226.20000000000002, 'yuv.min=', -56.54097999999999)
('yuv.max=', 228.62, 'yuv.min=', -40.240579999999994)
('yuv.max=', 194.00299999999999, 'yuv.min=', -39.701660000000004)
('yuv.max=', 252.935, 'yuv.min=', -36.235609999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -43.915639999999996)
('yuv.max=', 244.86899999999997, 'yuv.min=', -23.980429999999991)
('yuv.max=', 191.32399999999998, 'yuv.min=', -24.595429999999993)
('yuv.max=', 253.52699999999999, 'yuv.min=', -38.660870000000003)
('yuv.max=', 254.43000000000001, 'yuv.min=', -26.512409999999999)
('yuv.max=', 242.45000000000002, 'yuv.min=', -22.35038999999999)
('yuv.max=', 240.374, 'yuv.min=', -24.958770000000005)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.195489999999999)
('yuv.max=', 248.929, 'yuv.min=', -16.877440000000004)
('yuv.max=', 197.79300000000001, 'yuv.min=', -24.325279999999996)
('yuv.max=', 250.00199999999998, 'yuv.min=', -60.317240000000012)
('yuv.max=', 245.45499999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 249.66199999999998, 'yuv.min=', -14.996719999999996)
('yuv.max=', 174.92499999999998, 'yuv.min=', -8.9801599999999961)
('yuv.max=', 255.0, 'yuv.min=', -56.726749999999996)
('yuv.max=', 190.31399999999999, 'yuv.min=', -75.895639999999986)
('yuv.max=', 248.69, 'yuv.min=', -22.795249999999996)
('yuv.max=', 205.02499999999998, 'yuv.min=', -30.872399999999995)
('yuv.max=', 250.66899999999998, 'yuv.min=', -55.275299999999987)
('yuv.max=', 232.114, 'yuv.min=', -60.765479999999982)
('yuv.max=', 221.33799999999999, 'yuv.min=', -6.4201499999999854)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.97549999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -25.795549999999992)
('yuv.max=', 227.38499999999999, 'yuv.min=', -65.115299999999991)
('yuv.max=', 226.10400000000001, 'yuv.min=', -28.745229999999989)
('yuv.max=', 211.65600000000001, 'yuv.min=', -35.664199999999994)
('yuv.max=', 210.0, 'yuv.min=', -8.8871300000000062)
('yuv.max=', 254.245, 'yuv.min=', -43.274750000000004)
('yuv.max=', 245.50899999999999, 'yuv.min=', -38.385210000000001)
('yuv.max=', 251.70699999999999, 'yuv.min=', -56.805329999999998)
('yuv.max=', 222.03799999999998, 'yuv.min=', -17.230659999999993)
('yuv.max=', 249.91800000000001, 'yuv.min=', -24.78507999999999)
('yuv.max=', 224.71600000000001, 'yuv.min=', -37.880589999999991)
('yuv.max=', 199.61699999999999, 'yuv.min=', -34.520499999999998)
('yuv.max=', 141.15699999999998, 'yuv.min=', -6.5500399999999885)
('yuv.max=', 244.62, 'yuv.min=', -36.475880000000004)
('yuv.max=', 217.87999999999997, 'yuv.min=', -31.110850000000006)
('yuv.max=', 235.90499999999997, 'yuv.min=', -29.05236)
('yuv.max=', 245.46499999999997, 'yuv.min=', -54.955759999999998)
('yuv.max=', 232.76799999999997, 'yuv.min=', -57.527420000000014)
('yuv.max=', 245.25899999999999, 'yuv.min=', -69.757499999999993)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.69, 'yuv.min=', -20.648970000000002)
('yuv.max=', 237.17199999999997, 'yuv.min=', -52.082520000000009)
('yuv.max=', 249.529, 'yuv.min=', -41.885559999999998)
('yuv.max=', 184.19, 'yuv.min=', -7.6455799999999847)
('yuv.max=', 245.15700000000001, 'yuv.min=', -12.825359999999991)
('yuv.max=', 249.96699999999998, 'yuv.min=', -42.140769999999996)
('yuv.max=', 237.78099999999998, 'yuv.min=', -71.865359999999995)
('yuv.max=', 239.35900000000001, 'yuv.min=', -46.156880000000001)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 185.434, 'yuv.min=', -38.095549999999989)
('yuv.max=', 199.95399999999998, 'yuv.min=', -27.325170000000004)
('yuv.max=', 237.97199999999998, 'yuv.min=', -37.625379999999993)
('yuv.max=', 229.23999999999998, 'yuv.min=', -26.35535999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.030249999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -41.300439999999988)
('yuv.max=', 251.60900000000001, 'yuv.min=', -48.105689999999989)
('yuv.max=', 248.99999999999997, 'yuv.min=', -26.567969999999999)
('yuv.max=', 251.45599999999996, 'yuv.min=', -14.07471000000001)
('yuv.max=', 236.22799999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 251.75199999999998, 'yuv.min=', -49.159750000000003)
('yuv.max=', 222.178, 'yuv.min=', -34.480249999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -44.075409999999991)
('yuv.max=', 243.36999999999998, 'yuv.min=', -91.155689999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.395439999999994)
('yuv.max=', 236.80599999999998, 'yuv.min=', -11.045960000000001)
('yuv.max=', 243.22800000000001, 'yuv.min=', -37.250649999999993)
('yuv.max=', 247.33699999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 250.08199999999997, 'yuv.min=', -40.039060000000006)
('yuv.max=', 229.12900000000002, 'yuv.min=', -16.94527999999999)
('yuv.max=', 232.91, 'yuv.min=', -102.48461)
('yuv.max=', 255.0, 'yuv.min=', -33.869519999999994)
('yuv.max=', 215.47299999999998, 'yuv.min=', -20.43561)
('yuv.max=', 255.0, 'yuv.min=', -7.8501699999999968)
('yuv.max=', 201.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -31.975429999999999)
('yuv.max=', 237.74599999999998, 'yuv.min=', -56.320219999999985)
('yuv.max=', 239.65599999999998, 'yuv.min=', -65.876819999999995)
('yuv.max=', 237.114, 'yuv.min=', -12.199989999999994)
('yuv.max=', 255.0, 'yuv.min=', -27.897580000000001)
('yuv.max=', 247.58199999999997, 'yuv.min=', -46.568399999999997)
('yuv.max=', 175.17599999999999, 'yuv.min=', -24.795449999999999)
('yuv.max=', 254.316, 'yuv.min=', -20.948299999999996)
('yuv.max=', 178.815, 'yuv.min=', -7.1949199999999962)
('yuv.max=', 254.47300000000001, 'yuv.min=', -61.544030000000014)
('yuv.max=', 254.11399999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 236.90099999999998, 'yuv.min=', -35.19422999999999)
('yuv.max=', 218.298, 'yuv.min=', -22.710179999999994)
('yuv.max=', 247.58699999999999, 'yuv.min=', -32.975529999999992)
('yuv.max=', 243.96099999999998, 'yuv.min=', -58.92342)
('yuv.max=', 255.0, 'yuv.min=', -79.245360000000005)
('yuv.max=', 255.0, 'yuv.min=', -57.342320000000015)
('yuv.max=', 254.40199999999999, 'yuv.min=', -40.375039999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.616500000000006)
('yuv.max=', 251.14599999999996, 'yuv.min=', -19.78107)
('yuv.max=', 245.09200000000001, 'yuv.min=', -16.319909999999993)
('yuv.max=', 248.57599999999999, 'yuv.min=', -21.95701)
('yuv.max=', 217.18000000000001, 'yuv.min=', -95.709890000000001)
('yuv.max=', 249.673, 'yuv.min=', -35.950519999999997)
('yuv.max=', 255.0, 'yuv.min=', -43.830570000000002)
('yuv.max=', 236.04099999999997, 'yuv.min=', -38.529160000000005)
('yuv.max=', 250.0, 'yuv.min=', -35.908379999999994)
('yuv.max=', 250.86899999999997, 'yuv.min=', -53.821770000000001)
('yuv.max=', 210.47900000000001, 'yuv.min=', -32.792090000000002)
('yuv.max=', 251.02099999999999, 'yuv.min=', -31.36042999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.112640000000006)
('yuv.max=', 196.22200000000001, 'yuv.min=', -73.169299999999993)
('yuv.max=', 129.33599999999998, 'yuv.min=', -31.00063999999999)
('yuv.max=', 248.71699999999998, 'yuv.min=', -68.400689999999997)
('yuv.max=', 162.15399999999997, 'yuv.min=', -15.330180000000002)
('yuv.max=', 227.10400000000001, 'yuv.min=', -27.340520000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.52591)
('yuv.max=', 102.75699999999999, 'yuv.min=', -90.040639999999982)
('yuv.max=', 241.59099999999998, 'yuv.min=', -30.945449999999987)
('yuv.max=', 228.09100000000001, 'yuv.min=', -39.700279999999992)
('yuv.max=', 251.04900000000001, 'yuv.min=', -15.660089999999993)
('yuv.max=', 252.196, 'yuv.min=', -17.175179999999994)
('yuv.max=', 239.80399999999997, 'yuv.min=', -22.380269999999989)
('yuv.max=', 245.886, 'yuv.min=', -18.222329999999999)
('yuv.max=', 220.96899999999999, 'yuv.min=', -24.901260000000001)
('yuv.max=', 226.39400000000001, 'yuv.min=', -22.260749999999994)
('yuv.max=', 225.78599999999997, 'yuv.min=', -77.421099999999996)
('yuv.max=', 255.0, 'yuv.min=', -29.315410000000004)
('yuv.max=', 255.0, 'yuv.min=', -41.145240000000001)
('yuv.max=', 251.85300000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 218.59399999999997, 'yuv.min=', -36.550410000000007)
('yuv.max=', 255.0, 'yuv.min=', -23.250479999999985)
('yuv.max=', 202.286, 'yuv.min=', -23.759249999999994)
('yuv.max=', 255.0, 'yuv.min=', -3.3393200000000007)
('yuv.max=', 205.0, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 220.56999999999999, 'yuv.min=', -17.433239999999998)
('yuv.max=', 255.0, 'yuv.min=', -52.300309999999996)
('yuv.max=', 255.0, 'yuv.min=', -13.540369999999989)
('yuv.max=', 252.38000000000002, 'yuv.min=', -68.28573999999999)
('yuv.max=', 209.48899999999998, 'yuv.min=', -56.132469999999998)
('yuv.max=', 232.78199999999998, 'yuv.min=', -34.32808)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.141330000000004)
('yuv.max=', 212.13999999999999, 'yuv.min=', -29.240709999999993)
('yuv.max=', 237.142, 'yuv.min=', -38.181600000000003)
('yuv.max=', 230.43000000000001, 'yuv.min=', -84.586100000000002)
('yuv.max=', 216.02100000000002, 'yuv.min=', -23.510259999999995)
('yuv.max=', 167.58599999999998, 'yuv.min=', -15.601689999999998)
('yuv.max=', 239.40999999999997, 'yuv.min=', -52.790900000000008)
('yuv.max=', 252.27699999999999, 'yuv.min=', -89.115239999999986)
('yuv.max=', 229.929, 'yuv.min=', -10.840099999999996)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.779849999999982)
('yuv.max=', 255.0, 'yuv.min=', -26.719719999999995)
('yuv.max=', 248.322, 'yuv.min=', -44.899569999999997)
('yuv.max=', 245.13799999999998, 'yuv.min=', -67.015320000000003)
('yuv.max=', 247.06, 'yuv.min=', -56.388249999999999)
('yuv.max=', 241.73999999999998, 'yuv.min=', -38.650309999999998)
('yuv.max=', 204.989, 'yuv.min=', -14.996919999999996)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.385439999999996)
('yuv.max=', 248.381, 'yuv.min=', -29.630379999999999)
('yuv.max=', 238.42999999999995, 'yuv.min=', -34.158949999999997)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 200.60199999999998, 'yuv.min=', -20.920370000000002)
('yuv.max=', 210.24300000000002, 'yuv.min=', -32.975529999999978)
('yuv.max=', 194.327, 'yuv.min=', -32.175449999999984)
('yuv.max=', 233.428, 'yuv.min=', -14.118620000000007)
('yuv.max=', 224.85199999999998, 'yuv.min=', -20.936659999999989)
('yuv.max=', 195.50299999999999, 'yuv.min=', -12.855239999999998)
('yuv.max=', 181.386, 'yuv.min=', -33.905499999999989)
('yuv.max=', 250.72, 'yuv.min=', -28.065190000000001)
('yuv.max=', 233.05599999999998, 'yuv.min=', -9.954970000000003)
('yuv.max=', 219.387, 'yuv.min=', -44.535209999999992)
('yuv.max=', 243.82399999999998, 'yuv.min=', -33.75480000000001)
('yuv.max=', 248.47300000000001, 'yuv.min=', -58.560689999999987)
('yuv.max=', 193.44200000000001, 'yuv.min=', -30.945449999999987)
('yuv.max=', 202.91399999999999, 'yuv.min=', -40.785449999999997)
('yuv.max=', 177.19800000000001, 'yuv.min=', -10.480309999999996)
('yuv.max=', 241.095, 'yuv.min=', -45.412670000000006)
('yuv.max=', 255.0, 'yuv.min=', -3.0451199999999972)
('yuv.max=', 222.80099999999999, 'yuv.min=', -56.745570000000001)
('yuv.max=', 235.32099999999997, 'yuv.min=', -18.076090000000004)
('yuv.max=', 202.65199999999999, 'yuv.min=', -33.602320000000006)
('yuv.max=', 181.61799999999999, 'yuv.min=', -23.180349999999997)
('yuv.max=', 171.53200000000001, 'yuv.min=', -18.890289999999997)
('yuv.max=', 176.83000000000001, 'yuv.min=', -11.455099999999991)
('yuv.max=', 234.19999999999999, 'yuv.min=', -37.689760000000007)
('yuv.max=', 255.0, 'yuv.min=', -20.060529999999993)
('yuv.max=', 255.0, 'yuv.min=', -26.204729999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.264299999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.71199999999999, 'yuv.min=', -40.655560000000001)
('yuv.max=', 252.10300000000001, 'yuv.min=', -38.083380000000005)
('yuv.max=', 184.16499999999999, 'yuv.min=', -13.515059999999995)
('yuv.max=', 211.345, 'yuv.min=', -100.55569000000001)
('yuv.max=', 230.464, 'yuv.min=', -32.920339999999996)
('yuv.max=', 219.70099999999999, 'yuv.min=', -26.741950000000006)
('yuv.max=', 255.0, 'yuv.min=', -52.940619999999996)
('yuv.max=', 251.71800000000002, 'yuv.min=', -21.047059999999998)
('yuv.max=', 233.69, 'yuv.min=', -24.710379999999986)
('yuv.max=', 200.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 193.88200000000001, 'yuv.min=', -40.055499999999995)
('yuv.max=', 230.39500000000001, 'yuv.min=', -31.390309999999996)
('yuv.max=', 243.989, 'yuv.min=', -21.765330000000002)
('yuv.max=', 183.73499999999999, 'yuv.min=', -32.385839999999995)
('yuv.max=', 236.32799999999997, 'yuv.min=', -47.045829999999988)
('yuv.max=', 239.69, 'yuv.min=', -23.210229999999996)
('yuv.max=', 198.31399999999999, 'yuv.min=', -28.055529999999994)
('yuv.max=', 235.68000000000001, 'yuv.min=', -73.485199999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.0214600000000011)
('yuv.max=', 255.0, 'yuv.min=', -20.991760000000003)
('yuv.max=', 237.72899999999998, 'yuv.min=', -37.355229999999985)
('yuv.max=', 253.97400000000002, 'yuv.min=', -85.414869999999993)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 172.32499999999999, 'yuv.min=', -8.8249599999999937)
('yuv.max=', 196.84300000000002, 'yuv.min=', -3.6049299999999986)
('yuv.max=', 253.505, 'yuv.min=', -6.9650200000000027)
('yuv.max=', 208.76899999999998, 'yuv.min=', -55.985739999999993)
('yuv.max=', 239.797, 'yuv.min=', -50.633929999999999)
('yuv.max=', 194.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.52199999999999, 'yuv.min=', -27.145069999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.072850000000003)
('yuv.max=', 250.131, 'yuv.min=', -24.441799999999997)
('yuv.max=', 207.642, 'yuv.min=', -35.380340000000004)
('yuv.max=', 255.0, 'yuv.min=', -45.620570000000001)
('yuv.max=', 237.77199999999999, 'yuv.min=', -7.4056899999999999)
('yuv.max=', 213.745, 'yuv.min=', -45.473650000000006)
('yuv.max=', 227.48400000000001, 'yuv.min=', -57.300809999999998)
('yuv.max=', 225.482, 'yuv.min=', -18.011130000000001)
('yuv.max=', 235.608, 'yuv.min=', -28.839650000000002)
('yuv.max=', 224.90699999999998, 'yuv.min=', -22.735489999999995)
('yuv.max=', 188.44499999999999, 'yuv.min=', -26.055329999999987)
('yuv.max=', 217.79799999999997, 'yuv.min=', -37.116619999999998)
('yuv.max=', 255.0, 'yuv.min=', -25.640349999999994)
('yuv.max=', 251.41300000000001, 'yuv.min=', -32.690439999999981)
('yuv.max=', 249.85399999999998, 'yuv.min=', -19.089599999999997)
('yuv.max=', 255.0, 'yuv.min=', -27.025549999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.350589999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.8801500000000004)
('yuv.max=', 245.78100000000001, 'yuv.min=', -26.63008)
('yuv.max=', 254.886, 'yuv.min=', -66.815469999999991)
('yuv.max=', 233.13200000000001, 'yuv.min=', -18.59025999999999)
('yuv.max=', 247.46599999999998, 'yuv.min=', -30.000539999999997)
('yuv.max=', 225.97800000000001, 'yuv.min=', -34.765339999999995)
('yuv.max=', 255.0, 'yuv.min=', -43.749300000000012)
('yuv.max=', 206.65899999999999, 'yuv.min=', -63.108640000000008)
('yuv.max=', 239.88399999999999, 'yuv.min=', -97.66167999999999)
('yuv.max=', 242.874, 'yuv.min=', -60.684979999999996)
('yuv.max=', 224.89699999999999, 'yuv.min=', -58.820469999999986)
('yuv.max=', 194.94199999999998, 'yuv.min=', -18.669070000000005)
('yuv.max=', 233.03099999999998, 'yuv.min=', -65.550820000000002)
('yuv.max=', 252.114, 'yuv.min=', -13.055259999999993)
('yuv.max=', 252.935, 'yuv.min=', -24.540240000000004)
('yuv.max=', 244.72899999999998, 'yuv.min=', -24.168109999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 220.78700000000001, 'yuv.min=', -30.484979999999997)
('yuv.max=', 243.35899999999998, 'yuv.min=', -43.370769999999993)
('yuv.max=', 254.18499999999997, 'yuv.min=', -24.932120000000005)
('yuv.max=', 251.52700000000002, 'yuv.min=', -25.54033999999999)
('yuv.max=', 234.67999999999998, 'yuv.min=', -28.055529999999997)
('yuv.max=', 242.75, 'yuv.min=', -18.305169999999986)
('yuv.max=', 255.0, 'yuv.min=', -51.459979999999995)
('yuv.max=', 247.33799999999999, 'yuv.min=', -58.305479999999996)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.06399999999999, 'yuv.min=', -24.040189999999996)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.99899999999997, 'yuv.min=', -72.263640000000009)
('yuv.max=', 228.34199999999998, 'yuv.min=', -7.3501200000000004)
('yuv.max=', 249.64699999999999, 'yuv.min=', -13.25352)
('yuv.max=', 201.13599999999997, 'yuv.min=', -55.488910000000018)
('yuv.max=', 218.36699999999999, 'yuv.min=', -64.029170000000008)
('yuv.max=', 237.13499999999996, 'yuv.min=', -14.900259999999992)
('yuv.max=', 248.40899999999999, 'yuv.min=', -7.4260400000000146)
('yuv.max=', 235.46299999999999, 'yuv.min=', -29.809659999999987)
('yuv.max=', 243.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 224.68299999999999, 'yuv.min=', -13.200089999999996)
('yuv.max=', 245.43999999999997, 'yuv.min=', -55.947990000000004)
('yuv.max=', 253.58699999999999, 'yuv.min=', -20.53526999999999)
('yuv.max=', 235.262, 'yuv.min=', -23.655089999999998)
('yuv.max=', 227.54299999999995, 'yuv.min=', -25.640349999999991)
('yuv.max=', 243.75400000000002, 'yuv.min=', -26.490669999999994)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 138.67400000000001, 'yuv.min=', -14.900259999999999)
('yuv.max=', 211.89999999999998, 'yuv.min=', -30.030419999999989)
('yuv.max=', 217.059, 'yuv.min=', -40.100319999999996)
('yuv.max=', 252.309, 'yuv.min=', -43.86045)
('yuv.max=', 228.27699999999996, 'yuv.min=', -22.125059999999998)
('yuv.max=', 253.36999999999998, 'yuv.min=', -13.37727000000001)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.929, 'yuv.min=', -30.403489999999998)
('yuv.max=', 225.744, 'yuv.min=', -44.912090000000006)
('yuv.max=', 255.0, 'yuv.min=', -21.725019999999986)
('yuv.max=', 187.17999999999998, 'yuv.min=', -16.015309999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.060980000000015)
('yuv.max=', 241.17599999999999, 'yuv.min=', -62.373280000000001)
('yuv.max=', 248.51599999999996, 'yuv.min=', -47.065339999999992)
('yuv.max=', 227.03199999999998, 'yuv.min=', -51.370339999999992)
('yuv.max=', 233.821, 'yuv.min=', -21.253630000000005)
('yuv.max=', 227.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 206.41300000000001, 'yuv.min=', -71.44144)
('yuv.max=', 255.0, 'yuv.min=', -13.379280000000001)
('yuv.max=', 250.39099999999999, 'yuv.min=', -18.520129999999998)
('yuv.max=', 236.41, 'yuv.min=', -35.155470000000008)
('yuv.max=', 251.70099999999996, 'yuv.min=', -43.675370000000001)
('yuv.max=', 206.97, 'yuv.min=', -31.120159999999998)
('yuv.max=', 237.142, 'yuv.min=', -55.225909999999985)
('yuv.max=', 225.72999999999999, 'yuv.min=', -34.21249000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.276910000000008)
('yuv.max=', 236.84699999999998, 'yuv.min=', -19.939279999999997)
('yuv.max=', 159.86599999999999, 'yuv.min=', -35.060799999999986)
('yuv.max=', 255.0, 'yuv.min=', -53.614280000000008)
('yuv.max=', 223.95699999999999, 'yuv.min=', -48.0505)
('yuv.max=', 252.11599999999999, 'yuv.min=', -62.289770000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.100119999999983)
('yuv.max=', 231.23599999999996, 'yuv.min=', -33.32038)
('yuv.max=', 232.99600000000001, 'yuv.min=', -26.455369999999995)
('yuv.max=', 220.97, 'yuv.min=', -14.770369999999996)
('yuv.max=', 246.51000000000002, 'yuv.min=', -49.243240000000014)
('yuv.max=', 236.36600000000001, 'yuv.min=', -54.17062)
('yuv.max=', 239.61899999999997, 'yuv.min=', -38.039580000000008)
('yuv.max=', 221.81099999999998, 'yuv.min=', -41.830369999999995)
('yuv.max=', 212.40899999999999, 'yuv.min=', -17.660289999999989)
('yuv.max=', 253.19100000000003, 'yuv.min=', -58.143460000000012)
('yuv.max=', 215.625, 'yuv.min=', -48.140139999999995)
('yuv.max=', 229.285, 'yuv.min=', -29.499820000000003)
('yuv.max=', 184.952, 'yuv.min=', -33.290499999999994)
('yuv.max=', 165.24299999999999, 'yuv.min=', -24.090809999999998)
('yuv.max=', 251.755, 'yuv.min=', -37.585129999999992)
('yuv.max=', 234.46099999999998, 'yuv.min=', -16.892440000000008)
('yuv.max=', 248.46599999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 136.13999999999999, 'yuv.min=', -7.9499400000000016)
('yuv.max=', 255.0, 'yuv.min=', -6.5661700000000032)
('yuv.max=', 248.95699999999999, 'yuv.min=', -31.090279999999989)
('yuv.max=', 211.14999999999998, 'yuv.min=', -21.905529999999995)
('yuv.max=', 252.22999999999996, 'yuv.min=', -32.916300000000007)
('yuv.max=', 227.755, 'yuv.min=', -26.785440000000008)
('yuv.max=', 216.35199999999998, 'yuv.min=', -14.430089999999993)
('yuv.max=', 253.404, 'yuv.min=', -37.242220000000003)
('yuv.max=', 162.90099999999998, 'yuv.min=', -8.735870000000002)
('yuv.max=', 213.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.06, 'yuv.min=', -48.550550000000001)
('yuv.max=', 198.19499999999999, 'yuv.min=', -24.280459999999991)
('yuv.max=', 250.73299999999998, 'yuv.min=', -59.565359999999991)
('yuv.max=', 252.91799999999998, 'yuv.min=', -21.850339999999992)
('yuv.max=', 254.47300000000001, 'yuv.min=', -32.505359999999996)
('yuv.max=', 253.29900000000001, 'yuv.min=', -54.870689999999996)
('yuv.max=', 238.11599999999999, 'yuv.min=', -56.055890000000005)
('yuv.max=', 225.98599999999999, 'yuv.min=', -37.380539999999982)
('yuv.max=', 203.11599999999999, 'yuv.min=', -52.709300000000006)
('yuv.max=', 210.21399999999997, 'yuv.min=', -55.865620000000007)
('yuv.max=', 221.685, 'yuv.min=', -35.350459999999991)
('yuv.max=', 192.637, 'yuv.min=', -30.630479999999981)
('yuv.max=', 248.10900000000001, 'yuv.min=', -36.210299999999997)
('yuv.max=', 232.024, 'yuv.min=', -21.427000000000007)
('yuv.max=', 241.28799999999998, 'yuv.min=', -26.674899999999987)
('yuv.max=', 157.583, 'yuv.min=', -36.550579999999997)
('yuv.max=', 195.05199999999999, 'yuv.min=', -13.662229999999997)
('yuv.max=', 255.0, 'yuv.min=', -76.555459999999997)
('yuv.max=', 248.61600000000001, 'yuv.min=', -55.805450000000008)
('yuv.max=', 244.86799999999999, 'yuv.min=', -28.56594999999999)
('yuv.max=', 208.28200000000001, 'yuv.min=', -24.42528999999999)
('yuv.max=', 190.18799999999999, 'yuv.min=', -25.370199999999993)
('yuv.max=', 232.20400000000001, 'yuv.min=', -23.010209999999994)
('yuv.max=', 220.452, 'yuv.min=', -15.475090000000009)
('yuv.max=', 253.505, 'yuv.min=', -13.87027999999999)
('yuv.max=', 253.82599999999996, 'yuv.min=', -27.89246)
('yuv.max=', 232.25699999999998, 'yuv.min=', -51.725559999999987)
('yuv.max=', 190.88, 'yuv.min=', -59.96893)
('yuv.max=', 250.63, 'yuv.min=', -51.314139999999995)
('yuv.max=', 243.52699999999999, 'yuv.min=', -10.125089999999993)
('yuv.max=', 215.86199999999999, 'yuv.min=', -76.585589999999996)
('yuv.max=', 244.398, 'yuv.min=', -57.790489999999991)
('yuv.max=', 210.16499999999999, 'yuv.min=', -29.590129999999995)
('yuv.max=', 220.80399999999997, 'yuv.min=', -48.165449999999986)
('yuv.max=', 236.69399999999999, 'yuv.min=', -48.66686)
('yuv.max=', 241.04200000000003, 'yuv.min=', -17.545339999999996)
('yuv.max=', 188.328, 'yuv.min=', -29.248199999999997)
('yuv.max=', 248.0, 'yuv.min=', -13.170209999999994)
('yuv.max=', 226.85500000000002, 'yuv.min=', -29.930409999999995)
('yuv.max=', 255.0, 'yuv.min=', -57.451490000000007)
('yuv.max=', 239.58700000000002, 'yuv.min=', -74.395540000000011)
('yuv.max=', 250.42299999999997, 'yuv.min=', -29.405049999999992)
('yuv.max=', 248.71799999999999, 'yuv.min=', -12.0701)
('yuv.max=', 168.54500000000002, 'yuv.min=', -44.103129999999993)
('yuv.max=', 248.75900000000001, 'yuv.min=', -29.220340000000004)
('yuv.max=', 251.65799999999999, 'yuv.min=', -30.770739999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.981589999999997)
('yuv.max=', 243.62599999999998, 'yuv.min=', -82.754850000000005)
('yuv.max=', 165.97899999999998, 'yuv.min=', -26.702500000000001)
('yuv.max=', 251.22799999999998, 'yuv.min=', -6.2500099999999872)
('yuv.max=', 252.80399999999997, 'yuv.min=', -15.684670000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -2.4682500000000012)
('yuv.max=', 243.21999999999997, 'yuv.min=', -30.408289999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.440259999999995)
('yuv.max=', 214.077, 'yuv.min=', -38.856390000000005)
('yuv.max=', 243.28799999999998, 'yuv.min=', -26.155339999999995)
('yuv.max=', 252.02099999999996, 'yuv.min=', -76.180729999999997)
('yuv.max=', 255.0, 'yuv.min=', -82.190469999999991)
('yuv.max=', 240.71199999999999, 'yuv.min=', -14.84507)
('yuv.max=', 216.19, 'yuv.min=', -35.101060000000004)
('yuv.max=', 206.78399999999999, 'yuv.min=', -45.947080000000014)
('yuv.max=', 254.65800000000002, 'yuv.min=', -41.723320000000001)
('yuv.max=', 254.316, 'yuv.min=', -67.64542999999999)
('yuv.max=', 180.88799999999998, 'yuv.min=', -43.428770000000007)
('yuv.max=', 181.22799999999998, 'yuv.min=', -14.53979)
('yuv.max=', 189.64899999999997, 'yuv.min=', -23.835599999999996)
('yuv.max=', 250.86199999999997, 'yuv.min=', -49.500029999999995)
('yuv.max=', 247.03199999999998, 'yuv.min=', -17.280680000000004)
('yuv.max=', 221.70499999999998, 'yuv.min=', -16.96022)
('yuv.max=', 255.0, 'yuv.min=', -3.2750199999999987)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.742729999999998)
('yuv.max=', 236.27800000000002, 'yuv.min=', -7.7647499999999994)
('yuv.max=', 239.69399999999999, 'yuv.min=', -14.445029999999988)
('yuv.max=', 218.988, 'yuv.min=', -21.25028)
('yuv.max=', 196.31199999999998, 'yuv.min=', -25.329949999999997)
('yuv.max=', 249.47800000000001, 'yuv.min=', -21.980229999999999)
('yuv.max=', 249.89099999999999, 'yuv.min=', -24.853640000000002)
('yuv.max=', 194.59399999999999, 'yuv.min=', -34.665329999999997)
('yuv.max=', 253.0, 'yuv.min=', -17.305070000000001)
('yuv.max=', 244.316, 'yuv.min=', -16.32594000000001)
('yuv.max=', 243.523, 'yuv.min=', -30.370700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.425619999999997)
('yuv.max=', 201.13899999999998, 'yuv.min=', -16.488730000000007)
('yuv.max=', 207.61000000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 112.28299999999999, 'yuv.min=', -15.885169999999995)
('yuv.max=', 254.202, 'yuv.min=', -24.910399999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.028369999999995)
('yuv.max=', 224.53699999999998, 'yuv.min=', -82.005389999999991)
('yuv.max=', 227.61499999999998, 'yuv.min=', -27.15618000000001)
('yuv.max=', 169.32399999999998, 'yuv.min=', -49.020719999999983)
('yuv.max=', 253.29900000000001, 'yuv.min=', -76.385319999999979)
('yuv.max=', 239.83799999999999, 'yuv.min=', -46.79061999999999)
('yuv.max=', 244.81700000000001, 'yuv.min=', -44.546370000000003)
('yuv.max=', 199.13299999999998, 'yuv.min=', -26.825529999999986)
('yuv.max=', 165.61599999999999, 'yuv.min=', -3.4003399999999857)
('yuv.max=', 232.21699999999998, 'yuv.min=', -15.804919999999994)
('yuv.max=', 252.22999999999996, 'yuv.min=', -35.220569999999988)
('yuv.max=', 177.55799999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 248.32999999999998, 'yuv.min=', -54.160249999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.555109999999996)
('yuv.max=', 198.09299999999999, 'yuv.min=', -23.765469999999993)
('yuv.max=', 245.744, 'yuv.min=', -37.800089999999997)
('yuv.max=', 222.80500000000001, 'yuv.min=', -21.732040000000012)
('yuv.max=', 231.21700000000001, 'yuv.min=', -60.394170000000003)
('yuv.max=', 209.38, 'yuv.min=', -36.389579999999995)
('yuv.max=', 237.69799999999995, 'yuv.min=', -36.410319999999999)
('yuv.max=', 238.09999999999999, 'yuv.min=', -39.95548999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.387790000000003)
('yuv.max=', 240.89399999999998, 'yuv.min=', -17.023219999999995)
('yuv.max=', 225.96100000000001, 'yuv.min=', -15.260049999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.490119999999983)
('yuv.max=', 241.82599999999996, 'yuv.min=', -38.355329999999995)
('yuv.max=', 250.03899999999999, 'yuv.min=', -71.550389999999993)
('yuv.max=', 239.87199999999996, 'yuv.min=', -17.690169999999995)
('yuv.max=', 248.0, 'yuv.min=', -35.650489999999991)
('yuv.max=', 230.22799999999998, 'yuv.min=', -52.180790000000002)
('yuv.max=', 240.755, 'yuv.min=', -4.8050499999999925)
('yuv.max=', 225.63700000000003, 'yuv.min=', -24.436530000000001)
('yuv.max=', 243.81100000000001, 'yuv.min=', -29.743519999999997)
('yuv.max=', 240.11299999999997, 'yuv.min=', -59.005549999999999)
('yuv.max=', 250.26199999999997, 'yuv.min=', -30.848420000000004)
('yuv.max=', 230.64699999999996, 'yuv.min=', -97.536000000000001)
('yuv.max=', 249.07099999999997, 'yuv.min=', -17.454960000000007)
('yuv.max=', 231.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 216.04799999999997, 'yuv.min=', -31.150000000000013)
('yuv.max=', 236.66799999999998, 'yuv.min=', -30.920139999999989)
('yuv.max=', 250.815, 'yuv.min=', -25.345969999999994)
('yuv.max=', 249.14999999999998, 'yuv.min=', -43.930340000000001)
('yuv.max=', 216.44899999999998, 'yuv.min=', -28.285429999999995)
('yuv.max=', 202.381, 'yuv.min=', -71.065279999999987)
('yuv.max=', 233.07500000000002, 'yuv.min=', -23.550509999999999)
('yuv.max=', 241.97900000000001, 'yuv.min=', -27.699900000000007)
('yuv.max=', 193.90200000000002, 'yuv.min=', -36.920739999999995)
('yuv.max=', 245.376, 'yuv.min=', -78.144440000000003)
('yuv.max=', 252.58699999999999, 'yuv.min=', -22.829039999999996)
('yuv.max=', 239.55299999999997, 'yuv.min=', -21.068569999999998)
('yuv.max=', 252.10300000000001, 'yuv.min=', -48.965530000000001)
('yuv.max=', 159.44499999999996, 'yuv.min=', -16.736000000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.4834400000000016)
('yuv.max=', 246.35900000000001, 'yuv.min=', -32.088909999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 199.49299999999999, 'yuv.min=', -9.3756299999999957)
('yuv.max=', 247.852, 'yuv.min=', -45.433670000000006)
('yuv.max=', 251.50500000000002, 'yuv.min=', -63.910609999999991)
('yuv.max=', 243.583, 'yuv.min=', -23.438829999999999)
('yuv.max=', 247.893, 'yuv.min=', -29.100449999999991)
('yuv.max=', 255.0, 'yuv.min=', -58.420429999999982)
('yuv.max=', 231.43000000000001, 'yuv.min=', -82.101089999999999)
('yuv.max=', 251.03799999999998, 'yuv.min=', -62.955329999999989)
('yuv.max=', 255.0, 'yuv.min=', -63.544880000000013)
('yuv.max=', 156.55799999999999, 'yuv.min=', -41.360199999999992)
('yuv.max=', 246.26999999999998, 'yuv.min=', -37.302740000000007)
('yuv.max=', 250.501, 'yuv.min=', -90.544029999999978)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 225.24099999999999, 'yuv.min=', -26.885289999999994)
('yuv.max=', 176.364, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.96099999999998, 'yuv.min=', -31.630579999999995)
('yuv.max=', 252.93999999999997, 'yuv.min=', -19.710599999999999)
('yuv.max=', 255.0, 'yuv.min=', -61.540249999999993)
('yuv.max=', 207.554, 'yuv.min=', -21.05827)
('yuv.max=', 250.03200000000001, 'yuv.min=', -50.310479999999984)
('yuv.max=', 154.88900000000001, 'yuv.min=', -26.655389999999997)
('yuv.max=', 228.80199999999999, 'yuv.min=', -62.020789999999991)
('yuv.max=', 255.0, 'yuv.min=', -33.410019999999989)
('yuv.max=', 246.042, 'yuv.min=', -55.805229999999995)
('yuv.max=', 173.44099999999997, 'yuv.min=', -8.6745900000000056)
('yuv.max=', 209.82699999999997, 'yuv.min=', -70.385950000000008)
('yuv.max=', 235.72800000000001, 'yuv.min=', -57.180059999999997)
('yuv.max=', 248.00999999999999, 'yuv.min=', -51.535910000000001)
('yuv.max=', 248.869, 'yuv.min=', -56.000679999999988)
('yuv.max=', 234.20599999999996, 'yuv.min=', -44.350130000000007)
('yuv.max=', 238.39599999999999, 'yuv.min=', -22.460769999999989)
('yuv.max=', 251.72199999999998, 'yuv.min=', -53.340659999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 243.63200000000001, 'yuv.min=', -38.640419999999992)
('yuv.max=', 220.91, 'yuv.min=', -80.330529999999996)
('yuv.max=', 240.0, 'yuv.min=', -46.250320000000002)
('yuv.max=', 221.28800000000001, 'yuv.min=', -21.06519999999999)
('yuv.max=', 230.57199999999997, 'yuv.min=', -48.125199999999992)
('yuv.max=', 237.17500000000001, 'yuv.min=', -32.650189999999995)
('yuv.max=', 230.13099999999997, 'yuv.min=', -18.835099999999997)
('yuv.max=', 243.40100000000001, 'yuv.min=', -54.485589999999988)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.84299999999999, 'yuv.min=', -7.8564700000000016)
('yuv.max=', 178.0, 'yuv.min=', -14.729890000000001)
('yuv.max=', 243.34599999999998, 'yuv.min=', -43.31557999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -7.9949999999999974)
('yuv.max=', 132.42499999999998, 'yuv.min=', -25.335749999999994)
('yuv.max=', 242.92499999999998, 'yuv.min=', -24.940279999999994)
('yuv.max=', 238.53800000000001, 'yuv.min=', -23.45008)
('yuv.max=', 255.0, 'yuv.min=', -21.286039999999996)
('yuv.max=', 239.78799999999998, 'yuv.min=', -45.570989999999995)
('yuv.max=', 248.99999999999997, 'yuv.min=', -53.400419999999997)
('yuv.max=', 204.03399999999999, 'yuv.min=', -27.440529999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -30.56035)
('yuv.max=', 146.797, 'yuv.min=', -50.250719999999994)
('yuv.max=', 150.84099999999998, 'yuv.min=', -98.073429999999988)
('yuv.max=', 247.08800000000002, 'yuv.min=', -36.732150000000004)
('yuv.max=', 234.75899999999999, 'yuv.min=', -36.375950000000003)
('yuv.max=', 243.31599999999997, 'yuv.min=', -40.224460000000008)
('yuv.max=', 233.24199999999999, 'yuv.min=', -33.124929999999999)
('yuv.max=', 187.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.41800000000001, 'yuv.min=', -24.294120000000007)
('yuv.max=', 197.602, 'yuv.min=', -19.204340000000002)
('yuv.max=', 227.71099999999998, 'yuv.min=', -61.580499999999994)
('yuv.max=', 255.0, 'yuv.min=', -17.121539999999996)
('yuv.max=', 220.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -46.865319999999997)
('yuv.max=', 238.36199999999999, 'yuv.min=', -32.685869999999994)
('yuv.max=', 210.62499999999997, 'yuv.min=', -38.371350000000007)
('yuv.max=', 255.0, 'yuv.min=', -59.206560000000017)
('yuv.max=', 204.19999999999999, 'yuv.min=', -22.680299999999988)
('yuv.max=', 189.15000000000001, 'yuv.min=', -37.770840000000007)
('yuv.max=', 233.11399999999998, 'yuv.min=', -10.0702)
('yuv.max=', 254.886, 'yuv.min=', -27.586950000000005)
('yuv.max=', 235.22299999999998, 'yuv.min=', -20.080039999999986)
('yuv.max=', 251.30500000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 241.71799999999996, 'yuv.min=', -29.825220000000002)
('yuv.max=', 230.79799999999997, 'yuv.min=', -44.426190000000005)
('yuv.max=', 255.0, 'yuv.min=', -10.364379999999997)
('yuv.max=', 241.68399999999997, 'yuv.min=', -35.935579999999995)
('yuv.max=', 184.30099999999999, 'yuv.min=', -47.63064)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.72199999999998, 'yuv.min=', -21.265220000000003)
('yuv.max=', 238.43099999999998, 'yuv.min=', -89.125609999999995)
('yuv.max=', 247.36399999999998, 'yuv.min=', -18.864979999999996)
('yuv.max=', 202.935, 'yuv.min=', -26.910599999999999)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 171.94399999999999, 'yuv.min=', -28.18364)
('yuv.max=', 236.67599999999999, 'yuv.min=', -42.52006999999999)
('yuv.max=', 255.0, 'yuv.min=', -35.810259999999985)
('yuv.max=', 251.393, 'yuv.min=', -19.545539999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.370229999999996)
('yuv.max=', 250.47299999999998, 'yuv.min=', -17.560279999999988)
('yuv.max=', 246.512, 'yuv.min=', -18.185649999999995)
('yuv.max=', 217.684, 'yuv.min=', -49.37473)
('yuv.max=', 228.34800000000001, 'yuv.min=', -26.04327)
('yuv.max=', 236.85600000000002, 'yuv.min=', -8.2925699999999978)
('yuv.max=', 243.52699999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 249.20799999999997, 'yuv.min=', -34.935479999999998)
('yuv.max=', 251.54399999999998, 'yuv.min=', -58.860720000000001)
('yuv.max=', 253.0, 'yuv.min=', -15.379349999999999)
('yuv.max=', 242.88799999999998, 'yuv.min=', -24.856289999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -30.114740000000012)
('yuv.max=', 139.28699999999998, 'yuv.min=', -20.42032)
('yuv.max=', 245.727, 'yuv.min=', -39.495689999999989)
('yuv.max=', 237.88799999999998, 'yuv.min=', -17.645349999999993)
('yuv.max=', 245.76499999999999, 'yuv.min=', -46.72587)
('yuv.max=', 231.435, 'yuv.min=', -22.866860000000003)
('yuv.max=', 243.82999999999998, 'yuv.min=', -30.13043)
('yuv.max=', 250.02099999999999, 'yuv.min=', -29.59926999999999)
('yuv.max=', 230.732, 'yuv.min=', -47.950489999999995)
('yuv.max=', 199.535, 'yuv.min=', -33.620409999999985)
('yuv.max=', 241.447, 'yuv.min=', -16.13138)
('yuv.max=', 255.0, 'yuv.min=', -38.150739999999992)
('yuv.max=', 202.20699999999997, 'yuv.min=', -27.840570000000003)
('yuv.max=', 243.536, 'yuv.min=', -35.951309999999999)
('yuv.max=', 189.37200000000001, 'yuv.min=', -34.277369999999998)
('yuv.max=', 187.14899999999997, 'yuv.min=', -21.557720000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -35.350459999999998)
('yuv.max=', 252.64099999999996, 'yuv.min=', -33.385939999999998)
('yuv.max=', 255.0, 'yuv.min=', -58.170859999999998)
('yuv.max=', 233.82599999999999, 'yuv.min=', -64.065809999999999)
('yuv.max=', 250.40599999999998, 'yuv.min=', -25.927000000000007)
('yuv.max=', 255.0, 'yuv.min=', -25.640350000000002)
('yuv.max=', 247.57099999999997, 'yuv.min=', -67.685679999999991)
('yuv.max=', 254.886, 'yuv.min=', -83.29007)
('yuv.max=', 210.71100000000001, 'yuv.min=', -17.482240000000001)
('yuv.max=', 253.07700000000003, 'yuv.min=', -52.055189999999996)
('yuv.max=', 182.36600000000001, 'yuv.min=', -17.960319999999989)
('yuv.max=', 243.56999999999999, 'yuv.min=', -56.175389999999993)
('yuv.max=', 243.29800000000003, 'yuv.min=', -38.240379999999988)
('yuv.max=', 243.16099999999997, 'yuv.min=', -35.065369999999987)
('yuv.max=', 255.0, 'yuv.min=', -22.554979999999997)
('yuv.max=', 250.0, 'yuv.min=', -0.61499999999998778)
('yuv.max=', 222.84699999999998, 'yuv.min=', -38.665729999999996)
('yuv.max=', 234.17599999999999, 'yuv.min=', -41.771529999999991)
('yuv.max=', 250.53699999999998, 'yuv.min=', -31.120159999999988)
('yuv.max=', 243.33499999999998, 'yuv.min=', -28.692120000000003)
('yuv.max=', 254.06, 'yuv.min=', -21.120389999999993)
('yuv.max=', 220.25499999999997, 'yuv.min=', -32.920339999999996)
('yuv.max=', 169.35999999999999, 'yuv.min=', -39.510629999999992)
('yuv.max=', 238.23899999999998, 'yuv.min=', -36.55514999999999)
('yuv.max=', 246.06, 'yuv.min=', -27.385339999999996)
('yuv.max=', 250.27099999999999, 'yuv.min=', -26.11051999999999)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.37699999999998, 'yuv.min=', -40.151560000000003)
('yuv.max=', 255.0, 'yuv.min=', -28.911280000000001)
('yuv.max=', 238.24199999999999, 'yuv.min=', -57.151409999999991)
('yuv.max=', 241.369, 'yuv.min=', -31.655889999999999)
('yuv.max=', 253.97400000000002, 'yuv.min=', -20.838770000000004)
('yuv.max=', 231.56299999999999, 'yuv.min=', -27.14506999999999)
('yuv.max=', 235.256, 'yuv.min=', -17.89575)
('yuv.max=', 239.86899999999997, 'yuv.min=', -35.282309999999995)
('yuv.max=', 246.84599999999998, 'yuv.min=', -19.940320000000003)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.15699999999998, 'yuv.min=', -23.205300000000005)
('yuv.max=', 253.84299999999996, 'yuv.min=', -27.924470000000003)
('yuv.max=', 219.47799999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 249.56499999999997, 'yuv.min=', -9.4951499999999953)
('yuv.max=', 247.06199999999998, 'yuv.min=', -72.372879999999995)
('yuv.max=', 237.05999999999997, 'yuv.min=', -76.913740000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.778060000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -12.020250000000004)
('yuv.max=', 215.25999999999999, 'yuv.min=', -25.670229999999986)
('yuv.max=', 250.77199999999996, 'yuv.min=', -32.415379999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.411560000000001)
('yuv.max=', 246.00799999999995, 'yuv.min=', -30.12496999999999)
('yuv.max=', 236.87799999999999, 'yuv.min=', -51.070309999999992)
('yuv.max=', 248.99999999999997, 'yuv.min=', -13.185149999999993)
('yuv.max=', 226.08800000000002, 'yuv.min=', -39.906099999999995)
('yuv.max=', 234.185, 'yuv.min=', -44.830669999999998)
('yuv.max=', 217.97200000000001, 'yuv.min=', -19.935209999999998)
('yuv.max=', 234.08899999999997, 'yuv.min=', -74.700089999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -22.520529999999997)
('yuv.max=', 255.0, 'yuv.min=', -20.003800000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.15699999999998, 'yuv.min=', -20.050159999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.4672899999999913)
('yuv.max=', 246.15299999999999, 'yuv.min=', -47.549160000000001)
('yuv.max=', 255.0, 'yuv.min=', -102.29958999999999)
('yuv.max=', 236.364, 'yuv.min=', -10.825159999999997)
('yuv.max=', 204.07299999999998, 'yuv.min=', -21.725019999999997)
('yuv.max=', 217.76899999999998, 'yuv.min=', -12.910429999999995)
('yuv.max=', 255.0, 'yuv.min=', -8.3800999999999917)
('yuv.max=', 246.03399999999999, 'yuv.min=', -19.12018999999998)
('yuv.max=', 231.78, 'yuv.min=', -50.580629999999999)
('yuv.max=', 211.39500000000001, 'yuv.min=', -41.477430000000005)
('yuv.max=', 247.83599999999998, 'yuv.min=', -23.859679999999997)
('yuv.max=', 243.99999999999997, 'yuv.min=', -74.080519999999993)
('yuv.max=', 236.41399999999999, 'yuv.min=', -37.090879999999999)
('yuv.max=', 246.49299999999999, 'yuv.min=', -40.301060000000007)
('yuv.max=', 251.60599999999999, 'yuv.min=', -59.173440000000014)
('yuv.max=', 240.38300000000001, 'yuv.min=', -36.93835)
('yuv.max=', 191.11599999999999, 'yuv.min=', -14.254740000000002)
('yuv.max=', 250.76099999999997, 'yuv.min=', -45.984740000000002)
('yuv.max=', 243.91399999999999, 'yuv.min=', -25.955319999999979)
('yuv.max=', 244.38299999999998, 'yuv.min=', -82.035269999999997)
('yuv.max=', 143.14400000000001, 'yuv.min=', -14.270319999999991)
('yuv.max=', 216.84299999999999, 'yuv.min=', -23.965489999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -38.14036999999999)
('yuv.max=', 242.97800000000001, 'yuv.min=', -35.065369999999987)
('yuv.max=', 152.81699999999998, 'yuv.min=', -19.705309999999997)
('yuv.max=', 196.37, 'yuv.min=', -55.973930000000003)
('yuv.max=', 255.0, 'yuv.min=', -2.530129999999998)
('yuv.max=', 245.64099999999999, 'yuv.min=', -12.725349999999999)
('yuv.max=', 236.75699999999998, 'yuv.min=', -106.53947000000001)
('yuv.max=', 255.0, 'yuv.min=', -59.615079999999999)
('yuv.max=', 209.00300000000001, 'yuv.min=', -40.040559999999992)
('yuv.max=', 228.05799999999999, 'yuv.min=', -30.215499999999984)
('yuv.max=', 255.0, 'yuv.min=', -18.07517)
('yuv.max=', 248.58100000000002, 'yuv.min=', -70.813829999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 237.32299999999998, 'yuv.min=', -44.490389999999991)
('yuv.max=', 254.202, 'yuv.min=', -23.733560000000004)
('yuv.max=', 213.733, 'yuv.min=', -31.570310000000003)
('yuv.max=', 219.84700000000001, 'yuv.min=', -10.478809999999996)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.908230000000003)
('yuv.max=', 236.44300000000001, 'yuv.min=', -36.109060000000007)
('yuv.max=', 197.15100000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 237.10499999999999, 'yuv.min=', -57.120299999999986)
('yuv.max=', 221.62, 'yuv.min=', -16.830329999999996)
('yuv.max=', 255.0, 'yuv.min=', -4.6199699999999808)
('yuv.max=', 232.62099999999998, 'yuv.min=', -19.486999999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.90006)
('yuv.max=', 234.08799999999997, 'yuv.min=', -58.100889999999993)
('yuv.max=', 165.988, 'yuv.min=', -42.85069)
('yuv.max=', 242.89699999999999, 'yuv.min=', -11.514279999999999)
('yuv.max=', 220.447, 'yuv.min=', -31.902220000000003)
('yuv.max=', 215.012, 'yuv.min=', -80.968139999999991)
('yuv.max=', 177.35900000000001, 'yuv.min=', -36.620710000000003)
('yuv.max=', 180.46600000000001, 'yuv.min=', -41.455640000000002)
('yuv.max=', 248.56, 'yuv.min=', -28.266570000000002)
('yuv.max=', 251.733, 'yuv.min=', -11.495349999999988)
('yuv.max=', 210.38499999999999, 'yuv.min=', -18.675510000000006)
('yuv.max=', 244.137, 'yuv.min=', -53.460179999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.728379999999998)
('yuv.max=', 250.68999999999997, 'yuv.min=', -11.644749999999997)
('yuv.max=', 207.23500000000001, 'yuv.min=', -20.855130000000003)
('yuv.max=', 240.44999999999999, 'yuv.min=', -32.73669000000001)
('yuv.max=', 165.43199999999999, 'yuv.min=', -30.560349999999993)
('yuv.max=', 239.00599999999997, 'yuv.min=', -26.400179999999995)
('yuv.max=', 254.54400000000001, 'yuv.min=', -16.675129999999996)
('yuv.max=', 247.79999999999998, 'yuv.min=', -36.617449999999998)
('yuv.max=', 241.11899999999997, 'yuv.min=', -23.563309999999998)
('yuv.max=', 252.66899999999998, 'yuv.min=', -66.525220000000004)
('yuv.max=', 252.27699999999999, 'yuv.min=', -109.48036999999999)
('yuv.max=', 239.499, 'yuv.min=', -32.34102)
('yuv.max=', 232.53100000000001, 'yuv.min=', -35.226470000000006)
('yuv.max=', 226.17600000000002, 'yuv.min=', -79.840849999999989)
('yuv.max=', 242.61400000000003, 'yuv.min=', -16.119689999999999)
('yuv.max=', 253.47299999999998, 'yuv.min=', -74.722620000000006)
('yuv.max=', 126.76199999999999, 'yuv.min=', -4.5329699999999988)
('yuv.max=', 251.03199999999995, 'yuv.min=', -25.764760000000006)
('yuv.max=', 253.97400000000002, 'yuv.min=', -39.286770000000004)
('yuv.max=', 254.886, 'yuv.min=', -84.09066)
('yuv.max=', 234.74199999999999, 'yuv.min=', -31.760469999999998)
('yuv.max=', 255.0, 'yuv.min=', -54.023039999999995)
('yuv.max=', 242.55700000000002, 'yuv.min=', -27.615240000000004)
('yuv.max=', 248.245, 'yuv.min=', -25.280559999999998)
('yuv.max=', 220.29700000000003, 'yuv.min=', -72.105629999999991)
('yuv.max=', 247.83099999999996, 'yuv.min=', -70.100859999999997)
('yuv.max=', 238.03199999999998, 'yuv.min=', -20.755800000000001)
('yuv.max=', 247.84299999999999, 'yuv.min=', -28.880919999999996)
('yuv.max=', 246.11399999999998, 'yuv.min=', -43.55585)
('yuv.max=', 241.07899999999998, 'yuv.min=', -55.309030000000007)
('yuv.max=', 215.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 155.67100000000002, 'yuv.min=', -6.1051800000000007)
('yuv.max=', 212.38200000000001, 'yuv.min=', -23.585540000000002)
('yuv.max=', 210.131, 'yuv.min=', -24.240209999999983)
('yuv.max=', 213.83199999999999, 'yuv.min=', -21.050260000000005)
('yuv.max=', 254.77200000000002, 'yuv.min=', -26.277809999999999)
('yuv.max=', 227.59899999999996, 'yuv.min=', -34.982530000000011)
('yuv.max=', 125.336, 'yuv.min=', -19.161800000000003)
('yuv.max=', 231.20299999999997, 'yuv.min=', -24.325279999999985)
('yuv.max=', 155.17999999999998, 'yuv.min=', -19.105249999999987)
('yuv.max=', 241.22799999999998, 'yuv.min=', -33.820429999999988)
('yuv.max=', 250.84300000000002, 'yuv.min=', -29.493730000000006)
('yuv.max=', 248.26599999999996, 'yuv.min=', -23.606820000000006)
('yuv.max=', 215.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 214.71599999999998, 'yuv.min=', -21.23077)
('yuv.max=', 242.58100000000002, 'yuv.min=', -14.940509999999986)
('yuv.max=', 232.95899999999997, 'yuv.min=', -24.180449999999986)
('yuv.max=', 244.142, 'yuv.min=', -41.955689999999997)
('yuv.max=', 206.71499999999997, 'yuv.min=', -65.201250000000002)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.184, 'yuv.min=', -37.527250000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.810189999999995)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.12899999999999, 'yuv.min=', -12.355189999999993)
('yuv.max=', 206.68699999999998, 'yuv.min=', -37.665629999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.33700000000002, 'yuv.min=', -13.231849999999998)
('yuv.max=', 245.387, 'yuv.min=', -57.560589999999991)
('yuv.max=', 218.185, 'yuv.min=', -61.108580000000003)
('yuv.max=', 181.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.261, 'yuv.min=', -26.240410000000001)
('yuv.max=', 234.85699999999997, 'yuv.min=', -58.735399999999998)
('yuv.max=', 248.54800000000003, 'yuv.min=', -43.7455)
('yuv.max=', 224.03, 'yuv.min=', -62.415990000000001)
('yuv.max=', 245.75299999999999, 'yuv.min=', -27.366080000000004)
('yuv.max=', 198.49200000000002, 'yuv.min=', -30.660359999999987)
('yuv.max=', 231.70299999999997, 'yuv.min=', -23.910299999999989)
('yuv.max=', 232.50700000000001, 'yuv.min=', -61.095389999999995)
('yuv.max=', 216.79799999999997, 'yuv.min=', -11.670059999999996)
('yuv.max=', 251.91799999999998, 'yuv.min=', -14.75667)
('yuv.max=', 237.82299999999998, 'yuv.min=', -17.145299999999999)
('yuv.max=', 242.87299999999999, 'yuv.min=', -13.509690000000003)
('yuv.max=', 216.542, 'yuv.min=', -55.550109999999997)
('yuv.max=', 237.25, 'yuv.min=', -80.875399999999999)
('yuv.max=', 225.16799999999998, 'yuv.min=', -47.950489999999988)
('yuv.max=', 252.309, 'yuv.min=', -77.225650000000002)
('yuv.max=', 217.58999999999997, 'yuv.min=', -51.840509999999995)
('yuv.max=', 201.99099999999999, 'yuv.min=', -20.639849999999988)
('yuv.max=', 236.77599999999998, 'yuv.min=', -13.540369999999999)
('yuv.max=', 217.23799999999997, 'yuv.min=', -17.430390000000003)
('yuv.max=', 255.0, 'yuv.min=', -25.127739999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -57.656030000000001)
('yuv.max=', 248.84299999999999, 'yuv.min=', -31.965959999999999)
('yuv.max=', 254.886, 'yuv.min=', -41.130299999999991)
('yuv.max=', 235.66, 'yuv.min=', -29.154410000000006)
('yuv.max=', 255.0, 'yuv.min=', -36.016870000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -9.1717300000000019)
('yuv.max=', 217.499, 'yuv.min=', -39.255419999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.770169999999998)
('yuv.max=', 195.57899999999998, 'yuv.min=', -32.78998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -26.625510000000002)
('yuv.max=', 249.815, 'yuv.min=', -22.45176)
('yuv.max=', 244.38600000000002, 'yuv.min=', -21.323630000000001)
('yuv.max=', 235.79499999999996, 'yuv.min=', -39.270359999999997)
('yuv.max=', 216.70000000000002, 'yuv.min=', -42.512700000000002)
('yuv.max=', 243.309, 'yuv.min=', -35.614109999999989)
('yuv.max=', 230.41199999999998, 'yuv.min=', -21.180149999999998)
('yuv.max=', 255.0, 'yuv.min=', -50.71602)
('yuv.max=', 252.03399999999996, 'yuv.min=', -32.130629999999989)
('yuv.max=', 255.0, 'yuv.min=', -16.860209999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.250079999999986)
('yuv.max=', 240.184, 'yuv.min=', -66.140709999999999)
('yuv.max=', 252.309, 'yuv.min=', -38.18061999999999)
('yuv.max=', 236.92599999999999, 'yuv.min=', -48.40440000000001)
('yuv.max=', 205.40099999999998, 'yuv.min=', -19.45599)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.39999999999998, 'yuv.min=', -55.785719999999998)
('yuv.max=', 253.64700000000002, 'yuv.min=', -43.545479999999984)
('yuv.max=', 156.09399999999999, 'yuv.min=', -29.930410000000002)
('yuv.max=', 247.65800000000002, 'yuv.min=', -11.721049999999998)
('yuv.max=', 237.79699999999997, 'yuv.min=', -17.776130000000002)
('yuv.max=', 245.58799999999999, 'yuv.min=', -4.5264099999999985)
('yuv.max=', 234.38300000000001, 'yuv.min=', -66.831019999999995)
('yuv.max=', 208.82400000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 251.24499999999995, 'yuv.min=', -29.039450000000006)
('yuv.max=', 213.39099999999996, 'yuv.min=', -49.565589999999993)
('yuv.max=', 215.33399999999997, 'yuv.min=', -56.590150000000001)
('yuv.max=', 209.16, 'yuv.min=', -15.557770000000003)
('yuv.max=', 250.16999999999999, 'yuv.min=', -31.760050000000007)
('yuv.max=', 245.077, 'yuv.min=', -43.37077)
('yuv.max=', 187.453, 'yuv.min=', -48.687180000000012)
('yuv.max=', 200.29599999999996, 'yuv.min=', -16.775139999999993)
('yuv.max=', 241.61099999999999, 'yuv.min=', -24.827420000000011)
('yuv.max=', 234.99999999999997, 'yuv.min=', -74.035699999999991)
('yuv.max=', 237.21599999999998, 'yuv.min=', -30.220069999999993)
('yuv.max=', 179.52699999999999, 'yuv.min=', -34.960789999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -46.519350000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.61899999999997, 'yuv.min=', -43.960459999999991)
('yuv.max=', 238.84699999999998, 'yuv.min=', -42.486010000000007)
('yuv.max=', 240.91800000000001, 'yuv.min=', -46.950389999999992)
('yuv.max=', 209.17100000000002, 'yuv.min=', -53.240649999999988)
('yuv.max=', 195.55099999999999, 'yuv.min=', -16.745259999999998)
('yuv.max=', 208.542, 'yuv.min=', -10.340049999999991)
('yuv.max=', 152.30799999999999, 'yuv.min=', -70.893909999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.784110000000005)
('yuv.max=', 184.36999999999998, 'yuv.min=', -50.450739999999996)
('yuv.max=', 236.92699999999996, 'yuv.min=', -33.018850000000015)
('yuv.max=', 189.40100000000001, 'yuv.min=', -29.013000000000005)
('yuv.max=', 232.09900000000002, 'yuv.min=', -15.730220000000001)
('yuv.max=', 228.91399999999999, 'yuv.min=', -35.929290000000002)
('yuv.max=', 217.298, 'yuv.min=', -22.320509999999992)
('yuv.max=', 246.56899999999999, 'yuv.min=', -30.205130000000004)
('yuv.max=', 253.14199999999997, 'yuv.min=', -26.985299999999999)
('yuv.max=', 255.0, 'yuv.min=', -5.1200199999999967)
('yuv.max=', 245.43199999999999, 'yuv.min=', -39.80028999999999)
('yuv.max=', 217.71499999999997, 'yuv.min=', -24.325279999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.924769999999999)
('yuv.max=', 207.63800000000001, 'yuv.min=', -45.535309999999988)
('yuv.max=', 255.0, 'yuv.min=', -56.075379999999996)
('yuv.max=', 203.05499999999998, 'yuv.min=', -37.350659999999998)
('yuv.max=', 124.80500000000001, 'yuv.min=', -19.950149999999994)
('yuv.max=', 242.37399999999997, 'yuv.min=', -34.290599999999991)
('yuv.max=', 255.0, 'yuv.min=', -19.794949999999986)
('yuv.max=', 226.90399999999997, 'yuv.min=', -58.017980000000009)
('yuv.max=', 227.036, 'yuv.min=', -41.608890000000002)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 243.88199999999998, 'yuv.min=', -55.27073)
('yuv.max=', 212.232, 'yuv.min=', -57.635289999999998)
('yuv.max=', 251.27700000000002, 'yuv.min=', -28.184930000000008)
('yuv.max=', 237.0, 'yuv.min=', -5.3050999999999995)
('yuv.max=', 231.20599999999999, 'yuv.min=', -45.810029999999998)
('yuv.max=', 238.392, 'yuv.min=', -18.730519999999984)
('yuv.max=', 230.51999999999998, 'yuv.min=', -14.991879999999998)
('yuv.max=', 250.91799999999998, 'yuv.min=', -80.975409999999997)
('yuv.max=', 182.245, 'yuv.min=', -7.5351999999999908)
('yuv.max=', 230.423, 'yuv.min=', -16.015309999999999)
('yuv.max=', 236.14600000000002, 'yuv.min=', -27.015179999999994)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 142.80199999999999, 'yuv.min=', -16.751759999999997)
('yuv.max=', 255.0, 'yuv.min=', -72.775819999999996)
('yuv.max=', 255.0, 'yuv.min=', -94.860629999999986)
('yuv.max=', 220.21699999999998, 'yuv.min=', -40.570489999999992)
('yuv.max=', 229.88599999999997, 'yuv.min=', -41.305009999999982)
('yuv.max=', 243.67099999999996, 'yuv.min=', -20.075920000000004)
('yuv.max=', 247.52499999999998, 'yuv.min=', -21.610070000000007)
('yuv.max=', 235.74000000000001, 'yuv.min=', -28.769680000000008)
('yuv.max=', 243.30500000000001, 'yuv.min=', -26.043660000000003)
('yuv.max=', 253.0, 'yuv.min=', -36.260919999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.78994999999999)
('yuv.max=', 255.0, 'yuv.min=', -28.717800000000004)
('yuv.max=', 244.92700000000002, 'yuv.min=', -46.774510000000006)
('yuv.max=', 173.81200000000001, 'yuv.min=', -32.115690000000001)
('yuv.max=', 245.91800000000001, 'yuv.min=', -10.669959999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.479849999999999)
('yuv.max=', 189.07699999999997, 'yuv.min=', -30.615539999999999)
('yuv.max=', 164.59199999999998, 'yuv.min=', -25.955319999999997)
('yuv.max=', 227.46699999999998, 'yuv.min=', -79.681079999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.280359999999998)
('yuv.max=', 247.14599999999999, 'yuv.min=', -30.740859999999994)
('yuv.max=', 248.57599999999999, 'yuv.min=', -25.204620000000002)
('yuv.max=', 249.70099999999999, 'yuv.min=', -15.748350000000002)
('yuv.max=', 252.53299999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.385169999999988)
('yuv.max=', 253.202, 'yuv.min=', -40.530239999999999)
('yuv.max=', 233.387, 'yuv.min=', -30.064160000000001)
('yuv.max=', 245.387, 'yuv.min=', -24.409350000000007)
('yuv.max=', 173.10699999999997, 'yuv.min=', -23.19529)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.98899999999998, 'yuv.min=', -104.08563000000001)
('yuv.max=', 194.322, 'yuv.min=', -25.74418)
('yuv.max=', 234.50099999999998, 'yuv.min=', -50.065639999999988)
('yuv.max=', 253.0, 'yuv.min=', -44.890429999999981)
('yuv.max=', 219.17400000000001, 'yuv.min=', -20.165109999999991)
('yuv.max=', 254.35900000000001, 'yuv.min=', -38.140370000000004)
('yuv.max=', 216.96199999999999, 'yuv.min=', -23.438370000000013)
('yuv.max=', 225.733, 'yuv.min=', -22.850439999999999)
('yuv.max=', 229.86099999999999, 'yuv.min=', -39.570389999999996)
('yuv.max=', 245.98999999999998, 'yuv.min=', -40.025619999999989)
('yuv.max=', 246.17400000000001, 'yuv.min=', -37.765639999999991)
('yuv.max=', 248.28799999999995, 'yuv.min=', -15.575019999999995)
('yuv.max=', 247.10299999999998, 'yuv.min=', -37.240279999999998)
('yuv.max=', 249.804, 'yuv.min=', -19.651189999999993)
('yuv.max=', 236.79099999999997, 'yuv.min=', -42.140769999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.964, 'yuv.min=', -6.2902599999999822)
('yuv.max=', 177.47599999999997, 'yuv.min=', -65.400389999999987)
('yuv.max=', 158.92399999999998, 'yuv.min=', -4.945309999999985)
('yuv.max=', 255.0, 'yuv.min=', -26.038350000000001)
('yuv.max=', 255.0, 'yuv.min=', -18.211810000000007)
('yuv.max=', 226.279, 'yuv.min=', -46.990639999999999)
('yuv.max=', 152.982, 'yuv.min=', -25.525400000000001)
('yuv.max=', 199.71700000000001, 'yuv.min=', -26.940480000000001)
('yuv.max=', 252.93999999999997, 'yuv.min=', -48.405719999999988)
('yuv.max=', 255.0, 'yuv.min=', -3.7302499999999963)
('yuv.max=', 226.89399999999998, 'yuv.min=', -60.265429999999995)
('yuv.max=', 157.90600000000001, 'yuv.min=', -0.78513999999998774)
('yuv.max=', 246.31, 'yuv.min=', -43.717280000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.304379999999995)
('yuv.max=', 253.39099999999999, 'yuv.min=', -46.50553)
('yuv.max=', 250.22800000000001, 'yuv.min=', -33.135299999999994)
('yuv.max=', 231.49899999999997, 'yuv.min=', -23.029609999999998)
('yuv.max=', 225.96199999999996, 'yuv.min=', -41.415390000000002)
('yuv.max=', 247.0, 'yuv.min=', -41.586999999999996)
('yuv.max=', 225.32399999999998, 'yuv.min=', -33.999849999999995)
('yuv.max=', 243.92000000000002, 'yuv.min=', -41.625779999999992)
('yuv.max=', 171.679, 'yuv.min=', -37.140270000000001)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.744, 'yuv.min=', -32.360529999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.644949999999969)
('yuv.max=', 144.48099999999999, 'yuv.min=', -51.310580000000002)
('yuv.max=', 227.41400000000002, 'yuv.min=', -29.975230000000003)
('yuv.max=', 226.39099999999996, 'yuv.min=', -22.610169999999993)
('yuv.max=', 233.98700000000002, 'yuv.min=', -28.215299999999992)
('yuv.max=', 244.97300000000001, 'yuv.min=', -42.685639999999992)
('yuv.max=', 240.92699999999999, 'yuv.min=', -40.86014999999999)
('yuv.max=', 196.38299999999998, 'yuv.min=', -38.279140000000005)
('yuv.max=', 229.18499999999997, 'yuv.min=', -18.730519999999999)
('yuv.max=', 243.15299999999999, 'yuv.min=', -21.563890000000001)
('yuv.max=', 250.131, 'yuv.min=', -14.997420000000002)
('yuv.max=', 238.61199999999999, 'yuv.min=', -22.065300000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.890989999999999)
('yuv.max=', 255.0, 'yuv.min=', -69.205339999999978)
('yuv.max=', 187.511, 'yuv.min=', -24.795449999999995)
('yuv.max=', 237.61799999999999, 'yuv.min=', -84.620589999999993)
('yuv.max=', 252.60399999999998, 'yuv.min=', -42.255719999999997)
('yuv.max=', 219.72499999999997, 'yuv.min=', -75.170259999999985)
('yuv.max=', 238.43799999999999, 'yuv.min=', -31.875419999999991)
('yuv.max=', 209.904, 'yuv.min=', -55.641570000000002)
('yuv.max=', 247.78899999999999, 'yuv.min=', -42.14820000000001)
('yuv.max=', 243.04300000000001, 'yuv.min=', -58.400919999999992)
('yuv.max=', 212.93599999999998, 'yuv.min=', -46.916630000000005)
('yuv.max=', 215.227, 'yuv.min=', -68.70071999999999)
('yuv.max=', 242.22800000000001, 'yuv.min=', -14.930139999999998)
('yuv.max=', 255.0, 'yuv.min=', -32.284419999999997)
('yuv.max=', 254.316, 'yuv.min=', -25.591989999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.1572200000000024)
('yuv.max=', 253.80399999999997, 'yuv.min=', -86.412320000000008)
('yuv.max=', 231.44699999999997, 'yuv.min=', -22.684869999999989)
('yuv.max=', 202.91, 'yuv.min=', -34.005510000000001)
('yuv.max=', 252.50499999999997, 'yuv.min=', -36.480450000000005)
('yuv.max=', 225.31, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 228.36799999999999, 'yuv.min=', -32.805389999999996)
('yuv.max=', 248.86500000000001, 'yuv.min=', -65.429039999999986)
('yuv.max=', 253.505, 'yuv.min=', -97.840190000000007)
('yuv.max=', 223.435, 'yuv.min=', -19.620239999999992)
('yuv.max=', 205.60499999999999, 'yuv.min=', -59.575729999999993)
('yuv.max=', 245.04900000000001, 'yuv.min=', -24.510359999999995)
('yuv.max=', 255.0, 'yuv.min=', -49.520769999999992)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.250449999999994)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.56500000000003, 'yuv.min=', -73.420699999999997)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.334989999999991)
('yuv.max=', 255.0, 'yuv.min=', -83.126239999999996)
('yuv.max=', 247.09899999999999, 'yuv.min=', -66.60051)
('yuv.max=', 228.929, 'yuv.min=', -7.0949099999999952)
('yuv.max=', 234.70799999999997, 'yuv.min=', -35.425159999999998)
('yuv.max=', 255.0, 'yuv.min=', -56.590029999999992)
('yuv.max=', 255.0, 'yuv.min=', -45.886010000000006)
('yuv.max=', 232.94800000000001, 'yuv.min=', -60.329400000000007)
('yuv.max=', 249.77199999999999, 'yuv.min=', -29.730389999999986)
('yuv.max=', 255.0, 'yuv.min=', -39.985369999999996)
('yuv.max=', 182.137, 'yuv.min=', -17.075169999999986)
('yuv.max=', 232.44999999999999, 'yuv.min=', -22.850439999999995)
('yuv.max=', 209.79599999999996, 'yuv.min=', -32.445599999999999)
('yuv.max=', 185.83199999999999, 'yuv.min=', -18.594839999999998)
('yuv.max=', 185.624, 'yuv.min=', -26.140400000000003)
('yuv.max=', 250.76099999999997, 'yuv.min=', -48.780449999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -30.575289999999999)
('yuv.max=', 215.39099999999999, 'yuv.min=', -22.565349999999981)
('yuv.max=', 245.93899999999999, 'yuv.min=', -30.492070000000005)
('yuv.max=', 253.65799999999999, 'yuv.min=', -26.884)
('yuv.max=', 246.95599999999999, 'yuv.min=', -21.269920000000003)
('yuv.max=', 217.16999999999996, 'yuv.min=', -18.522379999999998)
('yuv.max=', 252.65199999999999, 'yuv.min=', -18.290229999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.830229999999986)
('yuv.max=', 231.92000000000002, 'yuv.min=', -14.330079999999997)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 223.74499999999998, 'yuv.min=', -29.41541999999999)
('yuv.max=', 183.51299999999998, 'yuv.min=', -25.580589999999994)
('yuv.max=', 245.78399999999999, 'yuv.min=', -64.279949999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.377570000000002)
('yuv.max=', 126.68999999999998, 'yuv.min=', -22.080239999999989)
('yuv.max=', 248.89599999999999, 'yuv.min=', -17.56485)
('yuv.max=', 228.87100000000001, 'yuv.min=', -9.2750199999999978)
('yuv.max=', 255.0, 'yuv.min=', -6.7399199999999979)
('yuv.max=', 249.916, 'yuv.min=', -28.845239999999997)
('yuv.max=', 237.82899999999998, 'yuv.min=', -25.455269999999999)
('yuv.max=', 250.77199999999996, 'yuv.min=', -27.285330000000002)
('yuv.max=', 160.77099999999999, 'yuv.min=', -76.601950000000002)
('yuv.max=', 234.77599999999995, 'yuv.min=', -16.676630000000003)
('yuv.max=', 187.52699999999999, 'yuv.min=', -64.781480000000002)
('yuv.max=', 224.613, 'yuv.min=', -17.476839999999999)
('yuv.max=', 248.53800000000001, 'yuv.min=', -15.100279999999991)
('yuv.max=', 248.59799999999998, 'yuv.min=', -87.080590000000001)
('yuv.max=', 252.85999999999999, 'yuv.min=', -76.285970000000006)
('yuv.max=', 253.72899999999996, 'yuv.min=', -13.66113)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84299999999999, 'yuv.min=', -22.216080000000002)
('yuv.max=', 109.88999999999999, 'yuv.min=', -40.640619999999998)
('yuv.max=', 238.77600000000001, 'yuv.min=', -33.402120000000011)
('yuv.max=', 200.06200000000001, 'yuv.min=', -40.640619999999991)
('yuv.max=', 255.0, 'yuv.min=', -62.955329999999989)
('yuv.max=', 234.78599999999997, 'yuv.min=', -41.515399999999985)
('yuv.max=', 236.59099999999998, 'yuv.min=', -25.12535999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -34.490619999999993)
('yuv.max=', 250.541, 'yuv.min=', -27.046689999999998)
('yuv.max=', 160.761, 'yuv.min=', -9.7108500000000006)
('yuv.max=', 210.96099999999998, 'yuv.min=', -24.855209999999992)
('yuv.max=', 244.35900000000001, 'yuv.min=', -14.915199999999988)
('yuv.max=', 224.25400000000002, 'yuv.min=', -31.743780000000008)
('yuv.max=', 235.041, 'yuv.min=', -24.888590000000004)
('yuv.max=', 235.50099999999998, 'yuv.min=', -40.873170000000016)
('yuv.max=', 249.39599999999999, 'yuv.min=', -24.777940000000005)
('yuv.max=', 203.57999999999998, 'yuv.min=', -32.115160000000003)
('yuv.max=', 255.0, 'yuv.min=', -13.300099999999995)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.07899999999998, 'yuv.min=', -45.380109999999988)
('yuv.max=', 248.81, 'yuv.min=', -81.169600000000017)
('yuv.max=', 171.34700000000001, 'yuv.min=', -24.69086999999999)
('yuv.max=', 228.75799999999998, 'yuv.min=', -25.181899999999999)
('yuv.max=', 151.24599999999998, 'yuv.min=', -23.666829999999997)
('yuv.max=', 243.24299999999999, 'yuv.min=', -17.875249999999991)
('yuv.max=', 255.0, 'yuv.min=', -3.2899599999999936)
('yuv.max=', 182.21999999999997, 'yuv.min=', -24.395409999999991)
('yuv.max=', 244.64099999999996, 'yuv.min=', -41.93038)
('yuv.max=', 241.869, 'yuv.min=', -26.90014)
('yuv.max=', 254.70099999999999, 'yuv.min=', -21.657550000000001)
('yuv.max=', 233.96799999999999, 'yuv.min=', -28.196840000000002)
('yuv.max=', 240.98599999999996, 'yuv.min=', -67.266330000000011)
('yuv.max=', 218.114, 'yuv.min=', -18.920169999999995)
('yuv.max=', 239.03799999999998, 'yuv.min=', -30.030420000000003)
('yuv.max=', 251.55499999999998, 'yuv.min=', -18.147749999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.243650000000002)
('yuv.max=', 254.65800000000002, 'yuv.min=', -15.296990000000005)
('yuv.max=', 243.71899999999999, 'yuv.min=', -39.384330000000006)
('yuv.max=', 230.14599999999996, 'yuv.min=', -78.240689999999987)
('yuv.max=', 173.96100000000001, 'yuv.min=', -38.910569999999993)
('yuv.max=', 173.334, 'yuv.min=', -19.809210000000004)
('yuv.max=', 255.0, 'yuv.min=', -16.728850000000008)
('yuv.max=', 249.16200000000001, 'yuv.min=', -45.720389999999995)
('yuv.max=', 244.97300000000001, 'yuv.min=', -16.645249999999997)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -83.465289999999996)
('yuv.max=', 255.0, 'yuv.min=', -27.41065)
('yuv.max=', 255.0, 'yuv.min=', -15.315239999999985)
('yuv.max=', 254.886, 'yuv.min=', -83.85687999999999)
('yuv.max=', 239.78700000000001, 'yuv.min=', -24.010309999999993)
('yuv.max=', 173.96800000000002, 'yuv.min=', -26.715149999999984)
('yuv.max=', 250.21600000000001, 'yuv.min=', -19.880019999999984)
('yuv.max=', 229.58699999999999, 'yuv.min=', -55.279869999999995)
('yuv.max=', 205.006, 'yuv.min=', -67.590239999999994)
('yuv.max=', 247.28800000000001, 'yuv.min=', -20.80659)
('yuv.max=', 238.05000000000001, 'yuv.min=', -24.92013)
('yuv.max=', 215.96899999999999, 'yuv.min=', -17.260249999999985)
('yuv.max=', 242.75500000000002, 'yuv.min=', -23.341869999999997)
('yuv.max=', 254.11399999999998, 'yuv.min=', -20.35482)
('yuv.max=', 255.0, 'yuv.min=', -45.871470000000002)
('yuv.max=', 244.01900000000001, 'yuv.min=', -43.553930000000008)
('yuv.max=', 255.0, 'yuv.min=', -10.625139999999993)
('yuv.max=', 255.0, 'yuv.min=', -20.511589999999998)
('yuv.max=', 242.411, 'yuv.min=', -25.25524999999999)
('yuv.max=', 252.61899999999997, 'yuv.min=', -38.649909999999991)
('yuv.max=', 242.43099999999995, 'yuv.min=', -33.754869999999997)
('yuv.max=', 177.75899999999999, 'yuv.min=', -23.270430000000001)
('yuv.max=', 245.24299999999999, 'yuv.min=', -54.615479999999991)
('yuv.max=', 234.03200000000001, 'yuv.min=', -43.80525999999999)
('yuv.max=', 190.38099999999997, 'yuv.min=', -30.560349999999985)
('yuv.max=', 176.23299999999998, 'yuv.min=', -25.319350000000004)
('yuv.max=', 248.131, 'yuv.min=', -24.986960000000003)
('yuv.max=', 234.82900000000001, 'yuv.min=', -51.925579999999997)
('yuv.max=', 225.28800000000001, 'yuv.min=', -27.455469999999991)
('yuv.max=', 254.245, 'yuv.min=', -8.9950999999999937)
('yuv.max=', 254.77200000000002, 'yuv.min=', -23.123209999999997)
('yuv.max=', 254.41299999999995, 'yuv.min=', -27.21976999999999)
('yuv.max=', 255.0, 'yuv.min=', -39.897530000000003)
('yuv.max=', 242.86199999999997, 'yuv.min=', -28.330249999999992)
('yuv.max=', 238.46299999999997, 'yuv.min=', -59.69248000000001)
('yuv.max=', 219.70699999999999, 'yuv.min=', -88.784099999999995)
('yuv.max=', 240.01099999999997, 'yuv.min=', -24.670320000000004)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 195.011, 'yuv.min=', -10.665389999999999)
('yuv.max=', 255.0, 'yuv.min=', -12.555210000000002)
('yuv.max=', 245.18099999999998, 'yuv.min=', -79.060630000000003)
('yuv.max=', 245.27599999999998, 'yuv.min=', -92.83214000000001)
('yuv.max=', 215.63200000000001, 'yuv.min=', -39.01057999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -12.210359999999998)
('yuv.max=', 236.43299999999999, 'yuv.min=', -31.060399999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.675329999999988)
('yuv.max=', 253.21699999999998, 'yuv.min=', -72.46584)
('yuv.max=', 247.47199999999995, 'yuv.min=', -60.250489999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.5650799999999805)
('yuv.max=', 247.48299999999995, 'yuv.min=', -42.460309999999993)
('yuv.max=', 255.0, 'yuv.min=', -45.215769999999992)
('yuv.max=', 253.99999999999997, 'yuv.min=', -90.635990000000007)
('yuv.max=', 255.0, 'yuv.min=', -42.225839999999991)
('yuv.max=', 172.30500000000001, 'yuv.min=', -10.249470000000002)
('yuv.max=', 247.07500000000002, 'yuv.min=', -50.010449999999999)
('yuv.max=', 238.761, 'yuv.min=', -29.66272)
('yuv.max=', 248.929, 'yuv.min=', -11.219700000000003)
('yuv.max=', 201.05799999999999, 'yuv.min=', -6.5350999999999893)
('yuv.max=', 251.66800000000001, 'yuv.min=', -76.978349999999992)
('yuv.max=', 243.66300000000001, 'yuv.min=', -25.438879999999997)
('yuv.max=', 253.10299999999998, 'yuv.min=', -37.565619999999996)
('yuv.max=', 193.83199999999999, 'yuv.min=', -35.840139999999991)
('yuv.max=', 249.49499999999998, 'yuv.min=', -32.609780000000001)
('yuv.max=', 223.81799999999998, 'yuv.min=', -72.345899999999986)
('yuv.max=', 255.0, 'yuv.min=', -45.409989999999993)
('yuv.max=', 206.64799999999997, 'yuv.min=', -42.530439999999984)
('yuv.max=', 234.57999999999998, 'yuv.min=', -34.635449999999992)
('yuv.max=', 253.54399999999998, 'yuv.min=', -37.821029999999993)
('yuv.max=', 214.84099999999998, 'yuv.min=', -30.045359999999992)
('yuv.max=', 192.976, 'yuv.min=', -15.915299999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', -8.0800699999999921)
('yuv.max=', 233.05799999999999, 'yuv.min=', -27.020069999999993)
('yuv.max=', 243.99999999999997, 'yuv.min=', -20.349250000000001)
('yuv.max=', 254.10300000000001, 'yuv.min=', -28.006790000000006)
('yuv.max=', 255.0, 'yuv.min=', -38.845890000000011)
('yuv.max=', 213.11700000000002, 'yuv.min=', -53.75564)
('yuv.max=', 204.40199999999999, 'yuv.min=', -9.6125499999999988)
('yuv.max=', 255.0, 'yuv.min=', -12.955249999999996)
('yuv.max=', 241.21699999999998, 'yuv.min=', -121.58035)
('yuv.max=', 204.50299999999999, 'yuv.min=', -23.826409999999999)
('yuv.max=', 229.607, 'yuv.min=', -22.436060000000001)
('yuv.max=', 253.0, 'yuv.min=', -13.415049999999994)
('yuv.max=', 254.41299999999995, 'yuv.min=', -39.446299999999994)
('yuv.max=', 241.92199999999997, 'yuv.min=', -48.480419999999995)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -52.305329999999998)
('yuv.max=', 254.886, 'yuv.min=', -43.715620000000001)
('yuv.max=', 222.15800000000002, 'yuv.min=', -42.770709999999994)
('yuv.max=', 229.65799999999996, 'yuv.min=', -19.579989999999995)
('yuv.max=', 215.0, 'yuv.min=', -38.725490000000001)
('yuv.max=', 184.804, 'yuv.min=', -17.428630000000005)
('yuv.max=', 248.02399999999997, 'yuv.min=', -41.585529999999991)
('yuv.max=', 203.785, 'yuv.min=', -9.3100699999999996)
('yuv.max=', 252.97800000000001, 'yuv.min=', -21.24822)
('yuv.max=', 255.0, 'yuv.min=', -29.675199999999997)
('yuv.max=', 200.30099999999999, 'yuv.min=', -49.135669999999983)
('yuv.max=', 221.12699999999998, 'yuv.min=', -25.970259999999989)
('yuv.max=', 220.071, 'yuv.min=', -20.835299999999989)
('yuv.max=', 253.80399999999997, 'yuv.min=', -47.110159999999993)
('yuv.max=', 247.95699999999999, 'yuv.min=', -25.324890000000003)
('yuv.max=', 195.41, 'yuv.min=', -38.065669999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.75, 'yuv.min=', -43.085679999999982)
('yuv.max=', 252.0, 'yuv.min=', -8.495049999999992)
('yuv.max=', 246.59799999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 224.29499999999999, 'yuv.min=', -70.32495999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.895190000000003)
('yuv.max=', 246.34799999999998, 'yuv.min=', -54.100489999999994)
('yuv.max=', 245.61500000000001, 'yuv.min=', -19.474540000000001)
('yuv.max=', 255.0, 'yuv.min=', -29.900529999999996)
('yuv.max=', 221.82499999999999, 'yuv.min=', -32.441750000000006)
('yuv.max=', 224.35299999999995, 'yuv.min=', -14.270319999999998)
('yuv.max=', 231.011, 'yuv.min=', -23.965489999999992)
('yuv.max=', 182.46299999999999, 'yuv.min=', -37.640319999999996)
('yuv.max=', 235.667, 'yuv.min=', -30.959589999999999)
('yuv.max=', 248.0, 'yuv.min=', -10.775769999999998)
('yuv.max=', 199.77499999999998, 'yuv.min=', -37.375969999999995)
('yuv.max=', 201.61600000000001, 'yuv.min=', -19.320209999999982)
('yuv.max=', 216.477, 'yuv.min=', -65.685479999999984)
('yuv.max=', 220.93799999999996, 'yuv.min=', -17.880670000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -86.591930000000005)
('yuv.max=', 250.10299999999998, 'yuv.min=', -46.210069999999995)
('yuv.max=', 252.90699999999998, 'yuv.min=', -20.150169999999996)
('yuv.max=', 250.24899999999997, 'yuv.min=', -46.000590000000003)
('yuv.max=', 221.63399999999999, 'yuv.min=', -27.98997)
('yuv.max=', 255.0, 'yuv.min=', -37.909040000000005)
('yuv.max=', 248.35900000000001, 'yuv.min=', -13.78716)
('yuv.max=', 251.755, 'yuv.min=', -24.609510000000007)
('yuv.max=', 235.15700000000001, 'yuv.min=', -58.905539999999988)
('yuv.max=', 249.41299999999998, 'yuv.min=', -22.46077)
('yuv.max=', 255.0, 'yuv.min=', -26.774109999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.002389999999991)
('yuv.max=', 240.03499999999997, 'yuv.min=', -25.607889999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.93291)
('yuv.max=', 223.69499999999999, 'yuv.min=', -12.140229999999997)
('yuv.max=', 250.94599999999997, 'yuv.min=', -44.130599999999994)
('yuv.max=', 228.71599999999998, 'yuv.min=', -23.694680000000005)
('yuv.max=', 217.32599999999999, 'yuv.min=', -34.780279999999983)
('yuv.max=', 186.64699999999999, 'yuv.min=', -19.504430000000003)
('yuv.max=', 227.18799999999999, 'yuv.min=', -62.982949999999995)
('yuv.max=', 213.374, 'yuv.min=', -22.605599999999992)
('yuv.max=', 245.69000000000003, 'yuv.min=', -15.975060000000001)
('yuv.max=', 219.85999999999999, 'yuv.min=', -28.948969999999999)
('yuv.max=', 213.58199999999999, 'yuv.min=', -63.583759999999998)
('yuv.max=', 218.25599999999997, 'yuv.min=', -22.78031)
('yuv.max=', 245.376, 'yuv.min=', -18.579889999999992)
('yuv.max=', 251.381, 'yuv.min=', -41.100380000000008)
('yuv.max=', 254.43000000000001, 'yuv.min=', -41.485519999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -34.935479999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.080369999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.089, 'yuv.min=', -42.585629999999988)
('yuv.max=', 212.25799999999998, 'yuv.min=', -44.745599999999996)
('yuv.max=', 255.0, 'yuv.min=', -40.870519999999992)
('yuv.max=', 255.0, 'yuv.min=', -51.609910000000006)
('yuv.max=', 217.12200000000001, 'yuv.min=', -55.755839999999999)
('yuv.max=', 238.34, 'yuv.min=', -17.145299999999988)
('yuv.max=', 206.70299999999997, 'yuv.min=', -26.353780000000015)
('yuv.max=', 253.35899999999998, 'yuv.min=', -33.624190000000006)
('yuv.max=', 219.96100000000001, 'yuv.min=', -18.805219999999998)
('yuv.max=', 221.15700000000001, 'yuv.min=', -18.590260000000001)
('yuv.max=', 240.88999999999999, 'yuv.min=', -45.090839999999993)
('yuv.max=', 211.27099999999999, 'yuv.min=', -47.080280000000002)
('yuv.max=', 253.505, 'yuv.min=', -19.505289999999995)
('yuv.max=', 249.131, 'yuv.min=', -6.5339399999999976)
('yuv.max=', 254.131, 'yuv.min=', -18.560379999999999)
('yuv.max=', 186.99499999999998, 'yuv.min=', -24.08595)
('yuv.max=', 186.90100000000001, 'yuv.min=', -33.450269999999989)
('yuv.max=', 191.96599999999998, 'yuv.min=', -70.950249999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.430759999999992)
('yuv.max=', 237.41300000000001, 'yuv.min=', -46.241139999999994)
('yuv.max=', 204.28799999999998, 'yuv.min=', -4.9523399999999924)
('yuv.max=', 245.04300000000001, 'yuv.min=', -22.125059999999998)
('yuv.max=', 152.77199999999999, 'yuv.min=', -2.0317399999999992)
('yuv.max=', 240.62099999999998, 'yuv.min=', -76.477339999999998)
('yuv.max=', 183.292, 'yuv.min=', -33.935379999999995)
('yuv.max=', 214.85400000000001, 'yuv.min=', -22.189799999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.640179999999997)
('yuv.max=', 244.41499999999999, 'yuv.min=', -28.103550000000006)
('yuv.max=', 252.42999999999998, 'yuv.min=', -39.853640000000006)
('yuv.max=', 179.23599999999999, 'yuv.min=', -49.480519999999999)
('yuv.max=', 196.22499999999997, 'yuv.min=', -45.790519999999987)
('yuv.max=', 238.61399999999998, 'yuv.min=', -88.580739999999992)
('yuv.max=', 252.47900000000001, 'yuv.min=', -55.554920000000003)
('yuv.max=', 237.03399999999999, 'yuv.min=', -20.740009999999998)
('yuv.max=', 221.64599999999999, 'yuv.min=', -18.315539999999999)
('yuv.max=', 231.15799999999999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 159.36000000000001, 'yuv.min=', -30.13043)
('yuv.max=', 246.77600000000001, 'yuv.min=', -34.790940000000006)
('yuv.max=', 199.88499999999996, 'yuv.min=', -19.780009999999997)
('yuv.max=', 187.614, 'yuv.min=', -35.675799999999995)
('yuv.max=', 200.357, 'yuv.min=', -33.776739999999997)
('yuv.max=', 255.0, 'yuv.min=', -10.778420000000004)
('yuv.max=', 249.04300000000001, 'yuv.min=', -18.168999999999997)
('yuv.max=', 183.499, 'yuv.min=', -14.355389999999996)
('yuv.max=', 197.43699999999998, 'yuv.min=', -68.580969999999994)
('yuv.max=', 244.732, 'yuv.min=', -56.320219999999978)
('yuv.max=', 238.0, 'yuv.min=', -10.027080000000002)
('yuv.max=', 248.34399999999999, 'yuv.min=', -17.05651000000001)
('yuv.max=', 179.04299999999998, 'yuv.min=', -35.590590000000006)
('yuv.max=', 241.27799999999996, 'yuv.min=', -80.115569999999991)
('yuv.max=', 255.0, 'yuv.min=', -20.220300000000002)
('yuv.max=', 233.21099999999998, 'yuv.min=', -44.71443)
('yuv.max=', 254.70099999999999, 'yuv.min=', -58.960729999999984)
('yuv.max=', 255.0, 'yuv.min=', -43.820690000000006)
('yuv.max=', 209.24700000000001, 'yuv.min=', -9.6951699999999938)
('yuv.max=', 171.16299999999998, 'yuv.min=', -57.11433000000001)
('yuv.max=', 250.34200000000001, 'yuv.min=', -24.256939999999997)
('yuv.max=', 241.702, 'yuv.min=', -28.517230000000012)
('yuv.max=', 218.10699999999997, 'yuv.min=', -24.14751)
('yuv.max=', 204.61399999999998, 'yuv.min=', -22.180249999999987)
('yuv.max=', 228.67600000000002, 'yuv.min=', -18.120089999999994)
('yuv.max=', 210.40200000000002, 'yuv.min=', -5.8051499999999976)
('yuv.max=', 245.42299999999997, 'yuv.min=', -41.930379999999992)
('yuv.max=', 247.20700000000002, 'yuv.min=', -17.334290000000003)
('yuv.max=', 196.52999999999997, 'yuv.min=', -87.544960000000003)
('yuv.max=', 255.0, 'yuv.min=', -76.460019999999986)
('yuv.max=', 168.27599999999998, 'yuv.min=', -54.970699999999979)
('yuv.max=', 178.39599999999999, 'yuv.min=', -27.915270000000003)
('yuv.max=', 207.35899999999998, 'yuv.min=', -21.395110000000003)
('yuv.max=', 205.92899999999997, 'yuv.min=', -8.4950499999999973)
('yuv.max=', 202.56399999999999, 'yuv.min=', -15.852490000000003)
('yuv.max=', 204.67099999999999, 'yuv.min=', -24.740260000000003)
('yuv.max=', 221.66399999999999, 'yuv.min=', -20.958370000000002)
('yuv.max=', 224.85999999999996, 'yuv.min=', -102.03785999999999)
('yuv.max=', 247.07300000000001, 'yuv.min=', -59.050369999999987)
('yuv.max=', 214.75, 'yuv.min=', -21.67887)
('yuv.max=', 254.77200000000002, 'yuv.min=', -28.400379999999995)
('yuv.max=', 238.88899999999998, 'yuv.min=', -77.545189999999991)
('yuv.max=', 203.89699999999999, 'yuv.min=', -23.547809999999998)
('yuv.max=', 197.78799999999998, 'yuv.min=', -24.525299999999994)
('yuv.max=', 243.47299999999998, 'yuv.min=', -66.930419999999998)
('yuv.max=', 244.40099999999995, 'yuv.min=', -48.769030000000008)
('yuv.max=', 255.0, 'yuv.min=', -1.7151099999999975)
('yuv.max=', 237.57499999999999, 'yuv.min=', -23.020579999999995)
('yuv.max=', 252.07099999999997, 'yuv.min=', -22.120490000000004)
('yuv.max=', 253.50099999999998, 'yuv.min=', -5.7648999999999955)
('yuv.max=', 206.14699999999999, 'yuv.min=', -26.500189999999993)
('yuv.max=', 241.59799999999996, 'yuv.min=', -26.970359999999992)
('yuv.max=', 255.0, 'yuv.min=', -24.025249999999993)
('yuv.max=', 251.27700000000002, 'yuv.min=', -20.705409999999986)
('yuv.max=', 235.20399999999998, 'yuv.min=', -89.185369999999992)
('yuv.max=', 234.37, 'yuv.min=', -24.810389999999995)
('yuv.max=', 220.20099999999999, 'yuv.min=', -23.18034999999999)
('yuv.max=', 172.08100000000002, 'yuv.min=', -53.840709999999987)
('yuv.max=', 206.86800000000002, 'yuv.min=', -28.055800000000005)
('yuv.max=', 219.68699999999998, 'yuv.min=', -34.681910000000002)
('yuv.max=', 249.125, 'yuv.min=', -7.4650699999999919)
('yuv.max=', 255.0, 'yuv.min=', -50.320849999999993)
('yuv.max=', 254.316, 'yuv.min=', -21.913359999999997)
('yuv.max=', 221.292, 'yuv.min=', -70.798359999999988)
('yuv.max=', 235.15300000000002, 'yuv.min=', -36.195359999999994)
('yuv.max=', 204.15799999999999, 'yuv.min=', -22.796120000000002)
('yuv.max=', 251.08799999999999, 'yuv.min=', -25.75988000000001)
('yuv.max=', 230.70599999999999, 'yuv.min=', -42.651020000000003)
('yuv.max=', 248.71199999999999, 'yuv.min=', -41.605039999999988)
('yuv.max=', 184.94799999999998, 'yuv.min=', -25.410449999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.3052999999999972)
('yuv.max=', 251.52700000000002, 'yuv.min=', -24.555179999999993)
('yuv.max=', 220.65199999999999, 'yuv.min=', -13.221040000000002)
('yuv.max=', 233.34999999999999, 'yuv.min=', -59.384849999999993)
('yuv.max=', 255.0, 'yuv.min=', -4.8377499999999998)
('yuv.max=', 242.87099999999998, 'yuv.min=', -59.827750000000002)
('yuv.max=', 210.14099999999999, 'yuv.min=', -48.980469999999983)
('yuv.max=', 245.51999999999998, 'yuv.min=', -25.490949999999998)
('yuv.max=', 218.399, 'yuv.min=', -6.4238900000000001)
('yuv.max=', 233.13399999999999, 'yuv.min=', -20.675620000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.530399999999997)
('yuv.max=', 235.69799999999998, 'yuv.min=', -46.175619999999995)
('yuv.max=', 255.0, 'yuv.min=', -47.24584999999999)
('yuv.max=', 208.846, 'yuv.min=', -48.3551)
('yuv.max=', 255.0, 'yuv.min=', -24.691850000000002)
('yuv.max=', 254.886, 'yuv.min=', -30.981949999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.101019999999991)
('yuv.max=', 246.95700000000002, 'yuv.min=', -19.684570000000001)
('yuv.max=', 255.0, 'yuv.min=', -27.200259999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 241.95099999999999, 'yuv.min=', -79.25703)
('yuv.max=', 234.47199999999998, 'yuv.min=', -20.261259999999993)
('yuv.max=', 217.785, 'yuv.min=', -23.235539999999993)
('yuv.max=', 228.16699999999997, 'yuv.min=', -28.015279999999994)
('yuv.max=', 251.50099999999998, 'yuv.min=', -47.535509999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -26.970359999999996)
('yuv.max=', 247.846, 'yuv.min=', -95.375619999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.435250000000003)
('yuv.max=', 233.005, 'yuv.min=', -23.150469999999995)
('yuv.max=', 228.27500000000001, 'yuv.min=', -25.476430000000015)
('yuv.max=', 172.96099999999998, 'yuv.min=', -15.689969999999994)
('yuv.max=', 233.59699999999998, 'yuv.min=', -33.990569999999998)
('yuv.max=', 246.28800000000001, 'yuv.min=', -22.314709999999998)
('yuv.max=', 246.19999999999999, 'yuv.min=', -58.976939999999999)
('yuv.max=', 189.232, 'yuv.min=', -18.475310000000004)
('yuv.max=', 255.0, 'yuv.min=', -21.191590000000001)
('yuv.max=', 223.417, 'yuv.min=', -22.865379999999998)
('yuv.max=', 240.36799999999999, 'yuv.min=', -65.713619999999992)
('yuv.max=', 169.86599999999999, 'yuv.min=', -27.270389999999999)
('yuv.max=', 255.0, 'yuv.min=', -51.613829999999993)
('yuv.max=', 238.095, 'yuv.min=', -35.81026)
('yuv.max=', 209.667, 'yuv.min=', -27.340520000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', -96.234229999999982)
('yuv.max=', 215.13200000000001, 'yuv.min=', -32.773960000000002)
('yuv.max=', 253.22799999999998, 'yuv.min=', -21.084270000000011)
('yuv.max=', 244.505, 'yuv.min=', -29.815460000000005)
('yuv.max=', 252.608, 'yuv.min=', -35.225139999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.2803599999999982)
('yuv.max=', 224.38999999999999, 'yuv.min=', -37.470179999999999)
('yuv.max=', 203.72399999999999, 'yuv.min=', -37.035740000000004)
('yuv.max=', 209.71600000000001, 'yuv.min=', -30.185620000000004)
('yuv.max=', 220.642, 'yuv.min=', -33.715849999999989)
('yuv.max=', 250.02199999999999, 'yuv.min=', -14.157439999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.566310000000001)
('yuv.max=', 239.38, 'yuv.min=', -51.657920000000004)
('yuv.max=', 240.071, 'yuv.min=', -71.620519999999999)
('yuv.max=', 249.857, 'yuv.min=', -59.48942000000001)
('yuv.max=', 233.25700000000001, 'yuv.min=', -20.571380000000005)
('yuv.max=', 245.04399999999998, 'yuv.min=', -31.139610000000008)
('yuv.max=', 255.0, 'yuv.min=', -2.6145100000000099)
('yuv.max=', 245.90399999999997, 'yuv.min=', -25.729989999999987)
('yuv.max=', 249.696, 'yuv.min=', -22.16530999999998)
('yuv.max=', 164.114, 'yuv.min=', -5.4752399999999994)
('yuv.max=', 249.87, 'yuv.min=', -29.490119999999987)
('yuv.max=', 253.52699999999999, 'yuv.min=', -0.50004999999999988)
('yuv.max=', 213.005, 'yuv.min=', -23.232390000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.995369999999998)
('yuv.max=', 145.626, 'yuv.min=', -38.463760000000008)
('yuv.max=', 255.0, 'yuv.min=', -35.150439999999996)
('yuv.max=', 240.58999999999997, 'yuv.min=', -37.149619999999999)
('yuv.max=', 232.22800000000001, 'yuv.min=', -12.46828)
('yuv.max=', 247.12499999999997, 'yuv.min=', -47.280299999999997)
('yuv.max=', 255.0, 'yuv.min=', -17.015409999999996)
('yuv.max=', 242.797, 'yuv.min=', -33.875640000000004)
('yuv.max=', 245.10299999999998, 'yuv.min=', -19.620239999999988)
('yuv.max=', 249.56099999999998, 'yuv.min=', -16.042970000000004)
('yuv.max=', 248.66900000000001, 'yuv.min=', -28.885489999999994)
('yuv.max=', 255.0, 'yuv.min=', -29.315409999999996)
('yuv.max=', 216.74000000000001, 'yuv.min=', -22.050359999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.0, 'yuv.min=', -74.095459999999989)
('yuv.max=', 248.22800000000001, 'yuv.min=', -23.401189999999996)
('yuv.max=', 226.22799999999998, 'yuv.min=', -24.270300000000006)
('yuv.max=', 240.95699999999999, 'yuv.min=', -9.154200000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.366070000000001)
('yuv.max=', 224.04300000000001, 'yuv.min=', -36.295369999999991)
('yuv.max=', 254.28799999999998, 'yuv.min=', -95.605519999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -67.570729999999998)
('yuv.max=', 243.322, 'yuv.min=', -33.413160000000005)
('yuv.max=', 249.70099999999999, 'yuv.min=', -18.463710000000003)
('yuv.max=', 186.43099999999998, 'yuv.min=', -28.381710000000005)
('yuv.max=', 239.57599999999999, 'yuv.min=', -36.601250000000007)
('yuv.max=', 222.51599999999996, 'yuv.min=', -27.055429999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', -42.80059)
('yuv.max=', 248.98299999999998, 'yuv.min=', -72.805700000000002)
('yuv.max=', 239.79399999999998, 'yuv.min=', -29.015379999999986)
('yuv.max=', 250.0, 'yuv.min=', -3.4899800000000001)
('yuv.max=', 248.93899999999996, 'yuv.min=', -21.080139999999989)
('yuv.max=', 238.125, 'yuv.min=', -74.111239999999995)
('yuv.max=', 181.68000000000001, 'yuv.min=', -26.780709999999992)
('yuv.max=', 176.47200000000001, 'yuv.min=', -17.075169999999993)
('yuv.max=', 239.00999999999999, 'yuv.min=', -30.830499999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.490539999999999)
('yuv.max=', 164.94799999999998, 'yuv.min=', -55.125900000000001)
('yuv.max=', 209.04899999999998, 'yuv.min=', -23.980429999999988)
('yuv.max=', 253.29900000000001, 'yuv.min=', -28.955619999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.58699999999996, 'yuv.min=', -27.825629999999997)
('yuv.max=', 253.77199999999999, 'yuv.min=', -96.674959999999999)
('yuv.max=', 250.08099999999996, 'yuv.min=', -21.248320000000003)
('yuv.max=', 253.21699999999998, 'yuv.min=', -30.920139999999993)
('yuv.max=', 252.34199999999998, 'yuv.min=', -35.465409999999991)
('yuv.max=', 254.18499999999997, 'yuv.min=', -50.181930000000008)
('yuv.max=', 167.09099999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 228.54600000000002, 'yuv.min=', -8.580120000000008)
('yuv.max=', 235.77999999999997, 'yuv.min=', -18.327090000000002)
('yuv.max=', 253.46199999999999, 'yuv.min=', -15.330179999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.890089999999997)
('yuv.max=', 216.971, 'yuv.min=', -39.825599999999994)
('yuv.max=', 252.70699999999999, 'yuv.min=', -54.360269999999979)
('yuv.max=', 175.55399999999997, 'yuv.min=', -42.630449999999996)
('yuv.max=', 201.089, 'yuv.min=', -24.795449999999995)
('yuv.max=', 227.899, 'yuv.min=', -26.795649999999995)
('yuv.max=', 243.988, 'yuv.min=', -30.464909999999996)
('yuv.max=', 239.15899999999999, 'yuv.min=', -41.825799999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.813270000000006)
('yuv.max=', 226.899, 'yuv.min=', -26.043440000000004)
('yuv.max=', 172.11600000000001, 'yuv.min=', -27.434620000000002)
('yuv.max=', 255.0, 'yuv.min=', -27.485349999999997)
('yuv.max=', 251.626, 'yuv.min=', -17.470639999999996)
('yuv.max=', 253.80399999999997, 'yuv.min=', -71.956229999999991)
('yuv.max=', 245.00699999999998, 'yuv.min=', -38.240379999999988)
('yuv.max=', 255.0, 'yuv.min=', -19.690369999999994)
('yuv.max=', 245.77199999999999, 'yuv.min=', -57.975569999999991)
('yuv.max=', 203.12200000000001, 'yuv.min=', -36.150539999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.492910000000002)
('yuv.max=', 249.43000000000001, 'yuv.min=', -16.200389999999999)
('yuv.max=', 224.0, 'yuv.min=', -23.976700000000001)
('yuv.max=', 228.52199999999996, 'yuv.min=', -25.346080000000001)
('yuv.max=', 243.42999999999998, 'yuv.min=', -3.9225100000000097)
('yuv.max=', 252.0, 'yuv.min=', -24.33803)
('yuv.max=', 253.14199999999997, 'yuv.min=', -48.365469999999995)
('yuv.max=', 176.74799999999999, 'yuv.min=', -12.955249999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.416290000000004)
('yuv.max=', 255.0, 'yuv.min=', -5.387430000000009)
('yuv.max=', 255.0, 'yuv.min=', -17.675229999999992)
('yuv.max=', 255.0, 'yuv.min=', -27.603260000000002)
('yuv.max=', 245.59699999999998, 'yuv.min=', -14.218749999999998)
('yuv.max=', 174.97299999999998, 'yuv.min=', -71.160719999999998)
('yuv.max=', 223.07499999999999, 'yuv.min=', -27.485349999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -46.203720000000004)
('yuv.max=', 231.54999999999998, 'yuv.min=', -15.100279999999994)
('yuv.max=', 229.87299999999996, 'yuv.min=', -24.910399999999996)
('yuv.max=', 247.172, 'yuv.min=', -14.124960000000002)
('yuv.max=', 254.35900000000001, 'yuv.min=', -43.282669999999996)
('yuv.max=', 246.98500000000001, 'yuv.min=', -32.97719)
('yuv.max=', 250.51499999999999, 'yuv.min=', -53.89009999999999)
('yuv.max=', 244.065, 'yuv.min=', -55.296039999999998)
('yuv.max=', 168.83699999999999, 'yuv.min=', -45.969799999999999)
('yuv.max=', 248.422, 'yuv.min=', -27.059999999999988)
('yuv.max=', 255.0, 'yuv.min=', -6.9799600000000019)
('yuv.max=', 221.21899999999999, 'yuv.min=', -32.849589999999999)
('yuv.max=', 232.0, 'yuv.min=', -7.7501599999999904)
('yuv.max=', 253.52699999999999, 'yuv.min=', -63.750839999999997)
('yuv.max=', 245.93799999999999, 'yuv.min=', -45.014070000000011)
('yuv.max=', 239.44499999999999, 'yuv.min=', -47.460809999999995)
('yuv.max=', 255.0, 'yuv.min=', -30.154509999999998)
('yuv.max=', 240.79499999999996, 'yuv.min=', -28.815359999999995)
('yuv.max=', 251.10299999999998, 'yuv.min=', -14.215129999999995)
('yuv.max=', 246.11299999999997, 'yuv.min=', -66.291460000000015)
('yuv.max=', 255.0, 'yuv.min=', -17.07517)
('yuv.max=', 209.886, 'yuv.min=', -51.794220000000003)
('yuv.max=', 217.34399999999999, 'yuv.min=', -10.995299999999986)
('yuv.max=', 255.0, 'yuv.min=', -18.049959999999992)
('yuv.max=', 238.53100000000001, 'yuv.min=', -17.345319999999997)
('yuv.max=', 244.58700000000002, 'yuv.min=', -15.415249999999995)
('yuv.max=', 252.761, 'yuv.min=', -26.870349999999998)
('yuv.max=', 234.80199999999999, 'yuv.min=', -45.000809999999994)
('yuv.max=', 239.096, 'yuv.min=', -51.00018)
('yuv.max=', 203.06299999999999, 'yuv.min=', -24.23564)
('yuv.max=', 235.87099999999995, 'yuv.min=', -24.320709999999981)
('yuv.max=', 246.869, 'yuv.min=', -69.300779999999989)
('yuv.max=', 237.899, 'yuv.min=', -37.843290000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -16.370529999999992)
('yuv.max=', 236.291, 'yuv.min=', -43.330519999999993)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.940359999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.338939999999997)
('yuv.max=', 194.16399999999999, 'yuv.min=', -25.400079999999999)
('yuv.max=', 241.39299999999997, 'yuv.min=', -30.65579)
('yuv.max=', 251.71100000000001, 'yuv.min=', -28.889319999999998)
('yuv.max=', 164.46499999999997, 'yuv.min=', -35.831000000000003)
('yuv.max=', 226.583, 'yuv.min=', -37.350660000000005)
('yuv.max=', 229.245, 'yuv.min=', -26.359719999999996)
('yuv.max=', 175.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -25.350689999999993)
('yuv.max=', 253.63200000000001, 'yuv.min=', -62.095489999999998)
('yuv.max=', 220.40899999999999, 'yuv.min=', -37.347310000000007)
('yuv.max=', 238.34199999999998, 'yuv.min=', -24.321329999999996)
('yuv.max=', 227.75899999999999, 'yuv.min=', -22.835499999999996)
('yuv.max=', 232.40000000000001, 'yuv.min=', -40.588880000000003)
('yuv.max=', 228.30999999999997, 'yuv.min=', -15.330179999999999)
('yuv.max=', 227.99299999999999, 'yuv.min=', -25.979330000000001)
('yuv.max=', 252.114, 'yuv.min=', -21.630670000000002)
('yuv.max=', 235.142, 'yuv.min=', -12.014909999999999)
('yuv.max=', 214.09500000000003, 'yuv.min=', -49.825369999999992)
('yuv.max=', 214.97800000000001, 'yuv.min=', -27.404849999999993)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.65199999999999, 'yuv.min=', -23.725219999999986)
('yuv.max=', 236.27800000000002, 'yuv.min=', -13.835679999999996)
('yuv.max=', 193.80999999999997, 'yuv.min=', -70.160619999999994)
('yuv.max=', 223.83799999999999, 'yuv.min=', -19.905329999999985)
('yuv.max=', 229.00399999999999, 'yuv.min=', -26.855409999999996)
('yuv.max=', 238.97899999999998, 'yuv.min=', -54.209459999999993)
('yuv.max=', 225.285, 'yuv.min=', -26.669560000000004)
('yuv.max=', 247.19999999999999, 'yuv.min=', -42.900599999999997)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.70100000000002, 'yuv.min=', -25.37019999999999)
('yuv.max=', 251.755, 'yuv.min=', -10.940109999999992)
('yuv.max=', 171.66, 'yuv.min=', -26.825530000000001)
('yuv.max=', 255.0, 'yuv.min=', -40.070439999999991)
('yuv.max=', 249.03899999999999, 'yuv.min=', -45.385720000000006)
('yuv.max=', 237.56899999999999, 'yuv.min=', -29.400479999999995)
('yuv.max=', 253.02799999999996, 'yuv.min=', -51.021419999999999)
('yuv.max=', 238.36599999999999, 'yuv.min=', -29.27562)
('yuv.max=', 251.62099999999998, 'yuv.min=', -27.410649999999997)
('yuv.max=', 254.43000000000001, 'yuv.min=', -10.746290000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.381, 'yuv.min=', -22.55574)
('yuv.max=', 254.10300000000001, 'yuv.min=', -12.663830000000004)
('yuv.max=', 228.96699999999998, 'yuv.min=', -50.530009999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.955039999999997)
('yuv.max=', 211.25200000000001, 'yuv.min=', -16.703199999999995)
('yuv.max=', 234.815, 'yuv.min=', -37.200720000000004)
('yuv.max=', 254.10300000000001, 'yuv.min=', -34.284440000000011)
('yuv.max=', 246.49399999999997, 'yuv.min=', -48.255089999999996)
('yuv.max=', 244.03199999999998, 'yuv.min=', -6.0499899999999975)
('yuv.max=', 208.22699999999998, 'yuv.min=', -19.835600000000007)
('yuv.max=', 233.52499999999998, 'yuv.min=', -12.070099999999989)
('yuv.max=', 254.11399999999998, 'yuv.min=', -65.686570000000003)
('yuv.max=', 233.72899999999998, 'yuv.min=', -80.430539999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.3752299999999895)
('yuv.max=', 248.86000000000001, 'yuv.min=', -15.345119999999998)
('yuv.max=', 255.0, 'yuv.min=', -41.255619999999979)
('yuv.max=', 207.29999999999998, 'yuv.min=', -53.760209999999994)
('yuv.max=', 249.11799999999999, 'yuv.min=', -44.104250000000015)
('yuv.max=', 244.29499999999999, 'yuv.min=', -19.776420000000009)
('yuv.max=', 250.99999999999997, 'yuv.min=', -64.350899999999996)
('yuv.max=', 255.0, 'yuv.min=', -8.8043900000000122)
('yuv.max=', 255.0, 'yuv.min=', -38.888779999999997)
('yuv.max=', 197.761, 'yuv.min=', -19.375399999999988)
('yuv.max=', 194.94899999999998, 'yuv.min=', -22.280259999999995)
('yuv.max=', 255.0, 'yuv.min=', -31.252000000000002)
('yuv.max=', 181.90699999999998, 'yuv.min=', -39.525569999999995)
('yuv.max=', 250.51499999999999, 'yuv.min=', -19.335149999999999)
('yuv.max=', 247.35799999999998, 'yuv.min=', -29.925839999999997)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.52599999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.565149999999981)
('yuv.max=', 255.0, 'yuv.min=', -20.520330000000001)
('yuv.max=', 223.596, 'yuv.min=', -33.226030000000009)
('yuv.max=', 228.755, 'yuv.min=', -24.588960000000004)
('yuv.max=', 168.20599999999999, 'yuv.min=', -5.5350000000000001)
('yuv.max=', 218.27500000000001, 'yuv.min=', -25.87482)
('yuv.max=', 212.48399999999998, 'yuv.min=', -30.375269999999997)
('yuv.max=', 253.11999999999998, 'yuv.min=', -4.3521300000000167)
('yuv.max=', 248.08000000000001, 'yuv.min=', -32.120899999999992)
('yuv.max=', 209.76399999999998, 'yuv.min=', -99.285509999999988)
('yuv.max=', 208.69299999999998, 'yuv.min=', -30.136399999999995)
('yuv.max=', 241.45599999999999, 'yuv.min=', -21.111670000000004)
('yuv.max=', 252.70099999999999, 'yuv.min=', -49.995509999999996)
('yuv.max=', 144.83000000000001, 'yuv.min=', -11.614869999999991)
('yuv.max=', 255.0, 'yuv.min=', -34.722680000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999987)
('yuv.max=', 242.52200000000002, 'yuv.min=', -13.440359999999995)
('yuv.max=', 235.25599999999997, 'yuv.min=', -61.358939999999997)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 252.114, 'yuv.min=', -26.940479999999997)
('yuv.max=', 246.42999999999998, 'yuv.min=', -32.905399999999986)
('yuv.max=', 230.72999999999999, 'yuv.min=', -34.335419999999985)
('yuv.max=', 226.0, 'yuv.min=', -7.8420200000000015)
('yuv.max=', 239.10699999999997, 'yuv.min=', -93.115640000000013)
('yuv.max=', 229.887, 'yuv.min=', -41.084650000000011)
('yuv.max=', 217.35199999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.729459999999996)
('yuv.max=', 241.47300000000001, 'yuv.min=', -42.040759999999992)
('yuv.max=', 251.48300000000003, 'yuv.min=', -39.055399999999999)
('yuv.max=', 205.89999999999998, 'yuv.min=', -34.545810000000003)
('yuv.max=', 249.20699999999999, 'yuv.min=', -4.679230000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.258359999999996)
('yuv.max=', 255.0, 'yuv.min=', -22.376289999999997)
('yuv.max=', 216.04999999999998, 'yuv.min=', -27.841349999999998)
('yuv.max=', 248.36599999999999, 'yuv.min=', -12.555210000000002)
('yuv.max=', 212.91499999999999, 'yuv.min=', -56.205269999999999)
('yuv.max=', 205.81899999999996, 'yuv.min=', -94.780129999999986)
('yuv.max=', 255.0, 'yuv.min=', -15.875049999999991)
('yuv.max=', 208.905, 'yuv.min=', -30.975329999999982)
('yuv.max=', 227.21499999999997, 'yuv.min=', -74.185099999999991)
('yuv.max=', 250.08099999999999, 'yuv.min=', -56.330590000000001)
('yuv.max=', 247.61899999999997, 'yuv.min=', -18.527230000000003)
('yuv.max=', 225.11199999999999, 'yuv.min=', -6.250009999999997)
('yuv.max=', 231.31899999999999, 'yuv.min=', -15.370429999999988)
('yuv.max=', 255.0, 'yuv.min=', -22.654989999999994)
('yuv.max=', 224.72199999999998, 'yuv.min=', -14.24044)
('yuv.max=', 252.22799999999998, 'yuv.min=', -12.09225)
('yuv.max=', 217.78899999999999, 'yuv.min=', -41.897189999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -30.965410000000002)
('yuv.max=', 234.09899999999999, 'yuv.min=', -26.970359999999996)
('yuv.max=', 250.28799999999998, 'yuv.min=', -52.580829999999992)
('yuv.max=', 230.39400000000001, 'yuv.min=', -23.722280000000001)
('yuv.max=', 243.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -20.479060000000004)
('yuv.max=', 249.505, 'yuv.min=', -51.032199999999996)
('yuv.max=', 207.62799999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 196.58699999999999, 'yuv.min=', -27.134699999999984)
('yuv.max=', 251.41199999999998, 'yuv.min=', -56.945589999999996)
('yuv.max=', 211.28799999999998, 'yuv.min=', -33.535339999999991)
('yuv.max=', 219.756, 'yuv.min=', -15.449250000000003)
('yuv.max=', 246.77699999999999, 'yuv.min=', -49.691780000000008)
('yuv.max=', 236.83199999999999, 'yuv.min=', -10.037960000000002)
('yuv.max=', 226.97800000000001, 'yuv.min=', -19.479979999999998)
('yuv.max=', 249.17399999999998, 'yuv.min=', -36.135600000000004)
('yuv.max=', 190.90999999999997, 'yuv.min=', -7.5844000000000023)
('yuv.max=', 237.61600000000001, 'yuv.min=', -60.573650000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.980719999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', -27.739590000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.020219999999995)
('yuv.max=', 248.262, 'yuv.min=', -28.817720000000001)
('yuv.max=', 223.83699999999999, 'yuv.min=', -35.735559999999992)
('yuv.max=', 248.809, 'yuv.min=', -13.170209999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.000269999999997)
('yuv.max=', 254.65800000000002, 'yuv.min=', -13.315039999999996)
('yuv.max=', 218.71199999999999, 'yuv.min=', -36.180419999999991)
('yuv.max=', 237.96299999999997, 'yuv.min=', -50.644450000000006)
('yuv.max=', 255.0, 'yuv.min=', -84.700839999999999)
('yuv.max=', 221.49799999999999, 'yuv.min=', -34.185820000000007)
('yuv.max=', 237.267, 'yuv.min=', -55.055769999999995)
('yuv.max=', 212.70699999999999, 'yuv.min=', -20.811630000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.745229999999999)
('yuv.max=', 198.989, 'yuv.min=', -30.590229999999991)
('yuv.max=', 185.98699999999999, 'yuv.min=', -37.776200000000003)
('yuv.max=', 252.42999999999998, 'yuv.min=', -34.160709999999987)
('yuv.max=', 254.40199999999999, 'yuv.min=', -14.129480000000001)
('yuv.max=', 255.0, 'yuv.min=', -21.058120000000002)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 161.74600000000001, 'yuv.min=', -45.750269999999993)
('yuv.max=', 217.87200000000001, 'yuv.min=', -38.510530000000003)
('yuv.max=', 237.715, 'yuv.min=', -60.235549999999989)
('yuv.max=', 149.59099999999998, 'yuv.min=', -8.0106399999999987)
('yuv.max=', 232.071, 'yuv.min=', -34.420489999999994)
('yuv.max=', 254.07099999999997, 'yuv.min=', -40.753109999999992)
('yuv.max=', 255.0, 'yuv.min=', -2.4674200000000042)
('yuv.max=', 227.27099999999999, 'yuv.min=', -35.165379999999985)
('yuv.max=', 243.66800000000001, 'yuv.min=', -48.03555999999999)
('yuv.max=', 234.25, 'yuv.min=', -26.285229999999995)
('yuv.max=', 255.0, 'yuv.min=', -21.105449999999987)
('yuv.max=', 117.136, 'yuv.min=', -56.16442)
('yuv.max=', 202.21299999999999, 'yuv.min=', -43.510500000000008)
('yuv.max=', 206.11799999999999, 'yuv.min=', -15.459190000000007)
('yuv.max=', 221.31999999999999, 'yuv.min=', -36.510329999999996)
('yuv.max=', 234.88799999999998, 'yuv.min=', -28.485449999999997)
('yuv.max=', 229.44899999999996, 'yuv.min=', -25.525399999999987)
('yuv.max=', 209.161, 'yuv.min=', -54.296030000000002)
('yuv.max=', 252.45799999999997, 'yuv.min=', -38.94267)
('yuv.max=', 251.02199999999996, 'yuv.min=', -44.453030000000012)
('yuv.max=', 227.91399999999999, 'yuv.min=', -16.090710000000005)
('yuv.max=', 246.58399999999997, 'yuv.min=', -34.82809000000001)
('yuv.max=', 232.09799999999998, 'yuv.min=', -43.560419999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.875489999999999)
('yuv.max=', 238.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 247.63, 'yuv.min=', -36.075839999999985)
('yuv.max=', 249.18499999999997, 'yuv.min=', -93.486670000000004)
('yuv.max=', 225.285, 'yuv.min=', -29.552850000000014)
('yuv.max=', 247.499, 'yuv.min=', -50.490820000000014)
('yuv.max=', 238.0, 'yuv.min=', -35.025120000000001)
('yuv.max=', 183.286, 'yuv.min=', -24.610369999999996)
('yuv.max=', 228.80599999999998, 'yuv.min=', -16.315809999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.675599999999996)
('yuv.max=', 249.52699999999999, 'yuv.min=', -22.120490000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.0501900000000006)
('yuv.max=', 203.94999999999999, 'yuv.min=', -24.589170000000006)
('yuv.max=', 240.62599999999998, 'yuv.min=', -45.565130000000011)
('yuv.max=', 251.71199999999999, 'yuv.min=', -22.035419999999998)
('yuv.max=', 233.73399999999998, 'yuv.min=', -23.365429999999989)
('yuv.max=', 223.71199999999999, 'yuv.min=', -30.38073)
('yuv.max=', 253.41299999999998, 'yuv.min=', -44.757670000000012)
('yuv.max=', 231.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.30799999999999, 'yuv.min=', -57.175489999999996)
('yuv.max=', 254.06, 'yuv.min=', -29.479749999999996)
('yuv.max=', 196.81799999999998, 'yuv.min=', -34.120459999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.912179999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.985199999999988)
('yuv.max=', 192.976, 'yuv.min=', -25.955319999999997)
('yuv.max=', 244.05999999999997, 'yuv.min=', -12.800049999999995)
('yuv.max=', 166.86500000000001, 'yuv.min=', -35.035489999999989)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.710380000000001)
('yuv.max=', 233.54300000000001, 'yuv.min=', -35.920639999999992)
('yuv.max=', 235.52099999999999, 'yuv.min=', -17.330380000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.410150000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -10.614850000000011)
('yuv.max=', 248.37399999999997, 'yuv.min=', -46.575659999999985)
('yuv.max=', 251.64299999999997, 'yuv.min=', -52.125599999999991)
('yuv.max=', 236.29899999999998, 'yuv.min=', -22.980329999999991)
('yuv.max=', 179.59699999999998, 'yuv.min=', -21.335349999999998)
('yuv.max=', 204.91999999999999, 'yuv.min=', -39.555449999999993)
('yuv.max=', 241.85600000000002, 'yuv.min=', -20.659750000000006)
('yuv.max=', 236.30199999999999, 'yuv.min=', -21.395110000000003)
('yuv.max=', 226.81499999999997, 'yuv.min=', -18.21552999999999)
('yuv.max=', 210.55500000000001, 'yuv.min=', -24.625309999999992)
('yuv.max=', 243.09, 'yuv.min=', -68.250059999999991)
('yuv.max=', 251.21299999999999, 'yuv.min=', -24.35058999999999)
('yuv.max=', 250.08099999999999, 'yuv.min=', -80.830579999999998)
('yuv.max=', 197.86199999999997, 'yuv.min=', -53.712899999999998)
('yuv.max=', 222.97199999999995, 'yuv.min=', -47.29524)
('yuv.max=', 243.733, 'yuv.min=', -20.820359999999994)
('yuv.max=', 225.39199999999997, 'yuv.min=', -16.960219999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -19.787390000000002)
('yuv.max=', 218.233, 'yuv.min=', -34.645820000000001)
('yuv.max=', 236.64099999999999, 'yuv.min=', -26.44781)
('yuv.max=', 253.989, 'yuv.min=', -69.820339999999987)
('yuv.max=', 252.63, 'yuv.min=', -15.875049999999998)
('yuv.max=', 164.31200000000001, 'yuv.min=', -42.355729999999994)
('yuv.max=', 250.66299999999998, 'yuv.min=', -24.395409999999991)
('yuv.max=', 254.245, 'yuv.min=', -7.3501199999999862)
('yuv.max=', 212.249, 'yuv.min=', -30.475279999999991)
('yuv.max=', 246.15699999999998, 'yuv.min=', -28.785479999999996)
('yuv.max=', 252.679, 'yuv.min=', -31.080530000000003)
('yuv.max=', 203.73099999999999, 'yuv.min=', -59.590669999999989)
('yuv.max=', 209.88800000000001, 'yuv.min=', -34.620509999999996)
('yuv.max=', 225.16999999999999, 'yuv.min=', -31.835169999999998)
('yuv.max=', 219.61699999999999, 'yuv.min=', -32.590429999999991)
('yuv.max=', 243.05999999999997, 'yuv.min=', -25.83793)
('yuv.max=', 209.97199999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 212.28599999999997, 'yuv.min=', -36.566860000000005)
('yuv.max=', 191.36299999999997, 'yuv.min=', -67.162390000000002)
('yuv.max=', 255.0, 'yuv.min=', -47.480319999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 224.72399999999999, 'yuv.min=', -31.545509999999993)
('yuv.max=', 224.69999999999999, 'yuv.min=', -34.56532)
('yuv.max=', 254.40199999999999, 'yuv.min=', -39.170349999999999)
('yuv.max=', 176.43299999999999, 'yuv.min=', -29.400479999999998)
('yuv.max=', 252.0, 'yuv.min=', -19.650119999999998)
('yuv.max=', 239.51599999999996, 'yuv.min=', -39.870419999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -39.580759999999998)
('yuv.max=', 255.0, 'yuv.min=', -51.498949999999994)
('yuv.max=', 245.56999999999999, 'yuv.min=', -15.449169999999995)
('yuv.max=', 237.24899999999997, 'yuv.min=', -30.460339999999984)
('yuv.max=', 176.39699999999999, 'yuv.min=', -44.700779999999995)
('yuv.max=', 238.83099999999999, 'yuv.min=', -41.800489999999996)
('yuv.max=', 203.947, 'yuv.min=', -70.100940000000008)
('yuv.max=', 199.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.41200000000001, 'yuv.min=', -39.78534999999998)
('yuv.max=', 238.81899999999999, 'yuv.min=', -27.910699999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.290769999999995)
('yuv.max=', 190.86099999999999, 'yuv.min=', -24.980529999999998)
('yuv.max=', 239.76999999999998, 'yuv.min=', -59.890699999999988)
('yuv.max=', 196.25, 'yuv.min=', -42.500559999999993)
('yuv.max=', 238.25200000000001, 'yuv.min=', -27.65549)
('yuv.max=', 210.27799999999996, 'yuv.min=', -39.319450000000003)
('yuv.max=', 240.684, 'yuv.min=', -30.630479999999999)
('yuv.max=', 231.67599999999999, 'yuv.min=', -23.67002999999999)
('yuv.max=', 234.078, 'yuv.min=', -26.625509999999998)
('yuv.max=', 227.01699999999997, 'yuv.min=', -22.598860000000002)
('yuv.max=', 197.34399999999999, 'yuv.min=', -13.355289999999982)
('yuv.max=', 220.51400000000001, 'yuv.min=', -30.408900000000003)
('yuv.max=', 253.42999999999998, 'yuv.min=', -34.880289999999988)
('yuv.max=', 213.328, 'yuv.min=', -21.665259999999993)
('yuv.max=', 242.70099999999999, 'yuv.min=', -15.54514)
('yuv.max=', 253.23899999999998, 'yuv.min=', -16.010170000000002)
('yuv.max=', 208.214, 'yuv.min=', -20.120289999999983)
('yuv.max=', 229.68999999999997, 'yuv.min=', -23.410249999999984)
('yuv.max=', 247.52700000000002, 'yuv.min=', -19.660489999999999)
('yuv.max=', 237.857, 'yuv.min=', -22.395209999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.875019999999992)
('yuv.max=', 241.18899999999999, 'yuv.min=', -48.625249999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -32.185819999999993)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.34099999999998, 'yuv.min=', -32.550179999999997)
('yuv.max=', 245.24200000000002, 'yuv.min=', -46.432780000000001)
('yuv.max=', 205.89599999999999, 'yuv.min=', -95.268470000000008)
('yuv.max=', 218.68199999999999, 'yuv.min=', -43.254750000000001)
('yuv.max=', 181.83699999999999, 'yuv.min=', -85.845489999999984)
('yuv.max=', 159.00299999999999, 'yuv.min=', -41.624050000000004)
('yuv.max=', 251.24499999999995, 'yuv.min=', -50.061040000000013)
('yuv.max=', 192.488, 'yuv.min=', -61.535679999999985)
('yuv.max=', 210.71499999999997, 'yuv.min=', -60.42653)
('yuv.max=', 240.10499999999999, 'yuv.min=', -23.870049999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.548, 'yuv.min=', -30.890259999999991)
('yuv.max=', 251.45599999999996, 'yuv.min=', -26.41554)
('yuv.max=', 242.79299999999998, 'yuv.min=', -27.309409999999986)
('yuv.max=', 252.08799999999999, 'yuv.min=', -60.241879999999995)
('yuv.max=', 241.792, 'yuv.min=', -58.31004999999999)
('yuv.max=', 193.34300000000002, 'yuv.min=', -16.730319999999999)
('yuv.max=', 234.89599999999999, 'yuv.min=', -23.525199999999991)
('yuv.max=', 171.18899999999999, 'yuv.min=', -53.785520000000005)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.559, 'yuv.min=', -5.5200599999999831)
('yuv.max=', 246.011, 'yuv.min=', -39.315179999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', -16.215329999999991)
('yuv.max=', 232.76599999999996, 'yuv.min=', -20.665159999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.886, 'yuv.min=', -40.395779999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.7432600000000029)
('yuv.max=', 239.54599999999999, 'yuv.min=', -28.84629)
('yuv.max=', 245.60799999999998, 'yuv.min=', -15.174979999999993)
('yuv.max=', 243.74399999999997, 'yuv.min=', -57.339829999999992)
('yuv.max=', 231.71899999999999, 'yuv.min=', -37.48054999999998)
('yuv.max=', 182.97800000000001, 'yuv.min=', -20.090409999999995)
('yuv.max=', 255.0, 'yuv.min=', -20.517880000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -43.778509999999997)
('yuv.max=', 238.47899999999998, 'yuv.min=', -58.679100000000005)
('yuv.max=', 227.16300000000001, 'yuv.min=', -31.345489999999995)
('yuv.max=', 217.25199999999998, 'yuv.min=', -6.1072300000000013)
('yuv.max=', 228.31399999999996, 'yuv.min=', -7.4267700000000048)
('yuv.max=', 248.60399999999998, 'yuv.min=', -40.604939999999999)
('yuv.max=', 203.20599999999999, 'yuv.min=', -50.459879999999984)
('yuv.max=', 203.012, 'yuv.min=', -30.015479999999997)
('yuv.max=', 248.21499999999997, 'yuv.min=', -14.118510000000001)
('yuv.max=', 245.65099999999998, 'yuv.min=', -51.864640000000009)
('yuv.max=', 174.34800000000001, 'yuv.min=', -14.185249999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -72.695319999999995)
('yuv.max=', 211.47299999999998, 'yuv.min=', -39.464579999999998)
('yuv.max=', 249.06399999999996, 'yuv.min=', -28.800419999999999)
('yuv.max=', 180.41399999999999, 'yuv.min=', -12.495450000000002)
('yuv.max=', 247.803, 'yuv.min=', -20.473890000000004)
('yuv.max=', 180.59100000000001, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 255.0, 'yuv.min=', -3.6899999999999995)
('yuv.max=', 208.91300000000001, 'yuv.min=', -25.48058)
('yuv.max=', 248.81099999999998, 'yuv.min=', -15.916760000000011)
('yuv.max=', 255.0, 'yuv.min=', -22.908950000000004)
('yuv.max=', 230.81900000000002, 'yuv.min=', -52.480819999999987)
('yuv.max=', 221.64100000000002, 'yuv.min=', -10.11014999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -32.175449999999991)
('yuv.max=', 197.054, 'yuv.min=', -11.440159999999993)
('yuv.max=', 245.29900000000001, 'yuv.min=', -45.660629999999998)
('yuv.max=', 192.90300000000002, 'yuv.min=', -19.744390000000006)
('yuv.max=', 189.93299999999999, 'yuv.min=', -10.410179999999992)
('yuv.max=', 225.96799999999999, 'yuv.min=', -8.4502299999999959)
('yuv.max=', 202.09399999999999, 'yuv.min=', -46.580229999999986)
('yuv.max=', 249.929, 'yuv.min=', -36.610339999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.750199999999992)
('yuv.max=', 255.0, 'yuv.min=', -58.671019999999999)
('yuv.max=', 195.892, 'yuv.min=', -12.670159999999996)
('yuv.max=', 224.21299999999999, 'yuv.min=', -20.820359999999997)
('yuv.max=', 176.88999999999999, 'yuv.min=', -12.885119999999986)
('yuv.max=', 248.161, 'yuv.min=', -25.455500000000004)
('yuv.max=', 191.81900000000002, 'yuv.min=', -72.990780000000001)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999995)
('yuv.max=', 248.65799999999999, 'yuv.min=', -12.540269999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -30.985699999999998)
('yuv.max=', 231.53100000000001, 'yuv.min=', -31.120159999999998)
('yuv.max=', 241.416, 'yuv.min=', -45.920409999999976)
('yuv.max=', 168.86399999999998, 'yuv.min=', -10.755029999999994)
('yuv.max=', 209.41499999999999, 'yuv.min=', -21.595130000000001)
('yuv.max=', 248.46099999999998, 'yuv.min=', -104.73507999999998)
('yuv.max=', 228.61099999999999, 'yuv.min=', -12.080420000000004)
('yuv.max=', 183.54300000000001, 'yuv.min=', -55.096019999999996)
('yuv.max=', 242.98499999999999, 'yuv.min=', -16.015410000000003)
('yuv.max=', 250.43399999999997, 'yuv.min=', -23.925239999999992)
('yuv.max=', 233.286, 'yuv.min=', -31.360429999999997)
('yuv.max=', 232.58699999999999, 'yuv.min=', -25.755299999999988)
('yuv.max=', 242.78699999999998, 'yuv.min=', -32.375469999999993)
('yuv.max=', 180.06400000000002, 'yuv.min=', -39.01057999999999)
('yuv.max=', 221.553, 'yuv.min=', -49.410389999999985)
('yuv.max=', 240.70699999999999, 'yuv.min=', -17.505089999999996)
('yuv.max=', 173.48999999999998, 'yuv.min=', -83.403649999999999)
('yuv.max=', 225.376, 'yuv.min=', -25.862750000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.359959999999997)
('yuv.max=', 244.28799999999998, 'yuv.min=', -34.071539999999999)
('yuv.max=', 151.642, 'yuv.min=', -22.06529999999999)
('yuv.max=', 246.47800000000001, 'yuv.min=', -57.160550000000001)
('yuv.max=', 251.74000000000001, 'yuv.min=', -18.375780000000002)
('yuv.max=', 234.47199999999995, 'yuv.min=', -23.395309999999995)
('yuv.max=', 255.0, 'yuv.min=', -9.1100499999999851)
('yuv.max=', 217.22800000000001, 'yuv.min=', -15.300299999999996)
('yuv.max=', 249.71699999999998, 'yuv.min=', -28.355559999999997)
('yuv.max=', 249.47299999999998, 'yuv.min=', -47.609210000000004)
('yuv.max=', 229.33699999999999, 'yuv.min=', -30.9117)
('yuv.max=', 220.489, 'yuv.min=', -40.055499999999981)
('yuv.max=', 250.35899999999998, 'yuv.min=', -14.630109999999981)
('yuv.max=', 218.13199999999998, 'yuv.min=', -42.434999999999995)
('yuv.max=', 248.82699999999997, 'yuv.min=', -38.42513000000001)
('yuv.max=', 235.51500000000001, 'yuv.min=', -21.860709999999987)
('yuv.max=', 254.10300000000001, 'yuv.min=', -99.328770000000006)
('yuv.max=', 160.21600000000001, 'yuv.min=', -24.995469999999987)
('yuv.max=', 251.64299999999997, 'yuv.min=', -48.480419999999988)
('yuv.max=', 251.97800000000001, 'yuv.min=', -47.750469999999993)
('yuv.max=', 169.02099999999999, 'yuv.min=', -76.840549999999993)
('yuv.max=', 251.97800000000001, 'yuv.min=', -21.780209999999993)
('yuv.max=', 209.46899999999999, 'yuv.min=', -22.44642000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.640149999999995)
('yuv.max=', 187.33699999999999, 'yuv.min=', -14.445029999999997)
('yuv.max=', 252.31, 'yuv.min=', -19.095379999999995)
('yuv.max=', 243.815, 'yuv.min=', -18.839669999999991)
('yuv.max=', 238.19199999999998, 'yuv.min=', -20.124470000000002)
('yuv.max=', 234.39099999999999, 'yuv.min=', -29.379149999999996)
('yuv.max=', 253.13099999999997, 'yuv.min=', -20.235239999999994)
('yuv.max=', 246.13599999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 228.02599999999998, 'yuv.min=', -12.702179999999998)
('yuv.max=', 211.31400000000002, 'yuv.min=', -37.026150000000001)
('yuv.max=', 240.63, 'yuv.min=', -36.524110000000007)
('yuv.max=', 247.202, 'yuv.min=', -17.490149999999986)
('yuv.max=', 185.464, 'yuv.min=', -24.410350000000001)
('yuv.max=', 253.20599999999999, 'yuv.min=', -38.850630000000002)
('yuv.max=', 255.0, 'yuv.min=', -14.200189999999992)
('yuv.max=', 253.41299999999998, 'yuv.min=', -14.532429999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.730189999999993)
('yuv.max=', 167.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.95500000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 240.71099999999998, 'yuv.min=', -24.84027)
('yuv.max=', 199.80099999999999, 'yuv.min=', -11.971260000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.781269999999999)
('yuv.max=', 222.71799999999999, 'yuv.min=', -46.933819999999997)
('yuv.max=', 242.48399999999998, 'yuv.min=', -28.515329999999992)
('yuv.max=', 226.767, 'yuv.min=', -25.670229999999989)
('yuv.max=', 253.0, 'yuv.min=', -0.51498999999999739)
('yuv.max=', 231.505, 'yuv.min=', -13.385169999999988)
('yuv.max=', 194.90000000000001, 'yuv.min=', -27.084530000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.665959999999998)
('yuv.max=', 245.57699999999997, 'yuv.min=', -24.85521)
('yuv.max=', 247.90099999999998, 'yuv.min=', -49.505829999999989)
('yuv.max=', 255.0, 'yuv.min=', -27.329689999999999)
('yuv.max=', 184.214, 'yuv.min=', -38.850809999999996)
('yuv.max=', 244.886, 'yuv.min=', -41.870449999999991)
('yuv.max=', 253.31599999999997, 'yuv.min=', -52.724429999999998)
('yuv.max=', 214.46599999999998, 'yuv.min=', -36.941479999999999)
('yuv.max=', 227.57599999999996, 'yuv.min=', -50.865719999999996)
('yuv.max=', 243.44499999999999, 'yuv.min=', -15.400309999999998)
('yuv.max=', 253.185, 'yuv.min=', -114.04057999999999)
('yuv.max=', 233.67099999999999, 'yuv.min=', -39.310609999999997)
('yuv.max=', 167.60799999999998, 'yuv.min=', -24.24905)
('yuv.max=', 251.04299999999998, 'yuv.min=', -57.805429999999987)
('yuv.max=', 198.93699999999998, 'yuv.min=', -42.050350000000009)
('yuv.max=', 239.161, 'yuv.min=', -22.402939999999994)
('yuv.max=', 255.0, 'yuv.min=', -44.490389999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.999209999999987)
('yuv.max=', 249.61799999999999, 'yuv.min=', -59.214709999999997)
('yuv.max=', 233.02099999999999, 'yuv.min=', -25.570219999999988)
('yuv.max=', 255.0, 'yuv.min=', -21.492699999999985)
('yuv.max=', 216.02699999999999, 'yuv.min=', -32.830699999999993)
('yuv.max=', 192.96799999999999, 'yuv.min=', -31.115590000000001)
('yuv.max=', 239.16799999999998, 'yuv.min=', -33.205429999999993)
('yuv.max=', 174.03800000000001, 'yuv.min=', -20.220299999999995)
('yuv.max=', 240.41899999999998, 'yuv.min=', -46.505529999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -13.329920000000001)
('yuv.max=', 242.21699999999998, 'yuv.min=', -42.90634)
('yuv.max=', 245.91800000000001, 'yuv.min=', -9.7539700000000025)
('yuv.max=', 228.89599999999996, 'yuv.min=', -53.042619999999999)
('yuv.max=', 206.94, 'yuv.min=', -25.423379999999998)
('yuv.max=', 255.0, 'yuv.min=', -46.628329999999998)
('yuv.max=', 246.18399999999997, 'yuv.min=', -19.924839999999996)
('yuv.max=', 250.83599999999998, 'yuv.min=', -45.730759999999997)
('yuv.max=', 254.10300000000001, 'yuv.min=', -31.490319999999993)
('yuv.max=', 255.0, 'yuv.min=', -27.674999999999969)
('yuv.max=', 209.06399999999999, 'yuv.min=', -37.820830000000001)
('yuv.max=', 243.815, 'yuv.min=', -46.699090000000012)
('yuv.max=', 245.26099999999997, 'yuv.min=', -62.265629999999994)
('yuv.max=', 224.04999999999998, 'yuv.min=', -53.124190000000013)
('yuv.max=', 184.60599999999999, 'yuv.min=', -36.163159999999998)
('yuv.max=', 241.78399999999999, 'yuv.min=', -28.500439999999998)
('yuv.max=', 223.74399999999997, 'yuv.min=', -76.962090000000003)
('yuv.max=', 244.14599999999999, 'yuv.min=', -6.3649599999999964)
('yuv.max=', 255.0, 'yuv.min=', -102.61992999999998)
('yuv.max=', 255.0, 'yuv.min=', -34.090579999999989)
('yuv.max=', 252.03199999999998, 'yuv.min=', -98.665580000000006)
('yuv.max=', 251.77799999999999, 'yuv.min=', -22.08024)
('yuv.max=', 208.369, 'yuv.min=', -94.527410000000003)
('yuv.max=', 177.71499999999997, 'yuv.min=', -19.320209999999996)
('yuv.max=', 180.35900000000001, 'yuv.min=', -17.805119999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.185150000000005)
('yuv.max=', 173.85500000000002, 'yuv.min=', -28.570519999999998)
('yuv.max=', 234.84299999999999, 'yuv.min=', -13.485179999999993)
('yuv.max=', 246.76599999999999, 'yuv.min=', -31.37536999999999)
('yuv.max=', 249.09899999999996, 'yuv.min=', -12.532440000000008)
('yuv.max=', 173.77199999999999, 'yuv.min=', -57.412620000000004)
('yuv.max=', 225.28399999999999, 'yuv.min=', -7.1268200000000093)
('yuv.max=', 230.267, 'yuv.min=', -39.370370000000001)
('yuv.max=', 239.39099999999996, 'yuv.min=', -29.345289999999999)
('yuv.max=', 246.26999999999998, 'yuv.min=', -29.075139999999998)
('yuv.max=', 162.73399999999998, 'yuv.min=', -34.710149999999992)
('yuv.max=', 248.73999999999998, 'yuv.min=', -13.404650000000004)
('yuv.max=', 243.03, 'yuv.min=', -53.385440000000003)
('yuv.max=', 161.70400000000001, 'yuv.min=', -10.789200000000001)
('yuv.max=', 251.16800000000001, 'yuv.min=', -45.715820000000001)
('yuv.max=', 237.94200000000001, 'yuv.min=', -6.1126000000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 207.06299999999999, 'yuv.min=', -16.446790000000004)
('yuv.max=', 243.21699999999998, 'yuv.min=', -30.645419999999991)
('yuv.max=', 244.74399999999997, 'yuv.min=', -52.410689999999995)
('yuv.max=', 186.20099999999999, 'yuv.min=', -36.505759999999995)
('yuv.max=', 174.0, 'yuv.min=', -18.3064)
('yuv.max=', 247.65199999999999, 'yuv.min=', -25.150669999999991)
('yuv.max=', 247.64100000000002, 'yuv.min=', -37.89584)
('yuv.max=', 244.25899999999999, 'yuv.min=', -38.520899999999997)
('yuv.max=', 217.15600000000001, 'yuv.min=', -24.240970000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.205829999999992)
('yuv.max=', 194.57599999999996, 'yuv.min=', -46.546360000000007)
('yuv.max=', 255.0, 'yuv.min=', -5.234969999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.050259999999987)
('yuv.max=', 243.71199999999999, 'yuv.min=', -33.265190000000004)
('yuv.max=', 167.28700000000001, 'yuv.min=', -29.829280000000004)
('yuv.max=', 255.0, 'yuv.min=', -23.895359999999997)
('yuv.max=', 244.70100000000002, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 177.661, 'yuv.min=', -151.27506)
('yuv.max=', 233.22099999999998, 'yuv.min=', -27.226589999999998)
('yuv.max=', 171.64600000000002, 'yuv.min=', -29.200459999999996)
('yuv.max=', 234.14699999999999, 'yuv.min=', -85.202629999999985)
('yuv.max=', 237.44, 'yuv.min=', -24.310699999999997)
('yuv.max=', 216.54099999999997, 'yuv.min=', -11.03426)
('yuv.max=', 230.23499999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 206.07300000000001, 'yuv.min=', -11.525229999999979)
('yuv.max=', 242.29300000000001, 'yuv.min=', -1.8956599999999995)
('yuv.max=', 255.0, 'yuv.min=', -22.165309999999998)
('yuv.max=', 252.44099999999997, 'yuv.min=', -13.215029999999985)
('yuv.max=', 233.25199999999998, 'yuv.min=', -21.535369999999997)
('yuv.max=', 119.155, 'yuv.min=', -27.070369999999997)
('yuv.max=', 251.49000000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 242.35599999999999, 'yuv.min=', -38.048710000000007)
('yuv.max=', 179.804, 'yuv.min=', -25.659859999999998)
('yuv.max=', 176.45099999999996, 'yuv.min=', -30.529970000000006)
('yuv.max=', 209.27499999999998, 'yuv.min=', -24.417719999999999)
('yuv.max=', 203.45499999999998, 'yuv.min=', -37.525369999999995)
('yuv.max=', 230.80799999999999, 'yuv.min=', -9.7430100000000053)
('yuv.max=', 248.17399999999998, 'yuv.min=', -28.555350000000004)
('yuv.max=', 241.548, 'yuv.min=', -21.619720000000008)
('yuv.max=', 253.80399999999997, 'yuv.min=', -46.033569999999997)
('yuv.max=', 200.50899999999999, 'yuv.min=', -34.465309999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.911030000000011)
('yuv.max=', 253.74600000000001, 'yuv.min=', -10.02712)
('yuv.max=', 214.71700000000001, 'yuv.min=', -37.080510000000004)
('yuv.max=', 253.25599999999997, 'yuv.min=', -27.415219999999994)
('yuv.max=', 252.17400000000001, 'yuv.min=', -20.049810000000001)
('yuv.max=', 237.92899999999997, 'yuv.min=', -96.420540000000003)
('yuv.max=', 238.20600000000002, 'yuv.min=', -14.812500000000002)
('yuv.max=', 249.886, 'yuv.min=', -14.945079999999997)
('yuv.max=', 228.12699999999998, 'yuv.min=', -38.46570999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.445399999999992)
('yuv.max=', 240.47899999999998, 'yuv.min=', -39.470379999999992)
('yuv.max=', 217.98099999999999, 'yuv.min=', -49.970199999999984)
('yuv.max=', 240.071, 'yuv.min=', -43.83970999999999)
('yuv.max=', 248.74299999999999, 'yuv.min=', -24.65518999999998)
('yuv.max=', 248.37999999999997, 'yuv.min=', -55.645459999999986)
('yuv.max=', 190.399, 'yuv.min=', -36.320679999999996)
('yuv.max=', 253.77199999999999, 'yuv.min=', -6.7649999999999988)
('yuv.max=', 243.755, 'yuv.min=', -17.215429999999991)
('yuv.max=', 215.05799999999999, 'yuv.min=', -11.565479999999994)
('yuv.max=', 228.33100000000002, 'yuv.min=', -25.000039999999991)
('yuv.max=', 255.0, 'yuv.min=', -73.580469999999977)
('yuv.max=', 184.863, 'yuv.min=', -38.070239999999991)
('yuv.max=', 231.24699999999996, 'yuv.min=', -16.775139999999997)
('yuv.max=', 240.02399999999994, 'yuv.min=', -26.685269999999996)
('yuv.max=', 253.48399999999998, 'yuv.min=', -16.183980000000005)
('yuv.max=', 243.40600000000001, 'yuv.min=', -43.445469999999993)
('yuv.max=', 253.29900000000001, 'yuv.min=', -39.428689999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.975430000000003)
('yuv.max=', 222.63999999999999, 'yuv.min=', -38.070239999999984)
('yuv.max=', 227.374, 'yuv.min=', -46.950389999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.25515)
('yuv.max=', 151.245, 'yuv.min=', -24.810389999999998)
('yuv.max=', 255.0, 'yuv.min=', -93.559269999999998)
('yuv.max=', 238.565, 'yuv.min=', -72.365409999999997)
('yuv.max=', 234.96100000000001, 'yuv.min=', -26.627310000000005)
('yuv.max=', 253.989, 'yuv.min=', -33.295070000000003)
('yuv.max=', 254.06, 'yuv.min=', -32.507170000000002)
('yuv.max=', 165.87699999999998, 'yuv.min=', -33.400190000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.170079999999984)
('yuv.max=', 245.28100000000001, 'yuv.min=', -69.030630000000002)
('yuv.max=', 215.19299999999998, 'yuv.min=', -25.679099999999991)
('yuv.max=', 186.82999999999998, 'yuv.min=', -23.295299999999983)
('yuv.max=', 250.0, 'yuv.min=', -13.595790000000001)
('yuv.max=', 242.13999999999999, 'yuv.min=', -13.785209999999985)
('yuv.max=', 254.08800000000002, 'yuv.min=', -27.630179999999996)
('yuv.max=', 255.0, 'yuv.min=', -2.4682600000000008)
('yuv.max=', 245.798, 'yuv.min=', -35.989580000000004)
('yuv.max=', 255.0, 'yuv.min=', -9.9549499999999895)
('yuv.max=', 235.80999999999997, 'yuv.min=', -71.420500000000004)
('yuv.max=', 254.08800000000002, 'yuv.min=', -32.861330000000009)
('yuv.max=', 197.89099999999996, 'yuv.min=', -23.65052)
('yuv.max=', 207.42999999999998, 'yuv.min=', -45.150210000000001)
('yuv.max=', 197.19299999999998, 'yuv.min=', -71.729109999999991)
('yuv.max=', 231.51300000000001, 'yuv.min=', -23.535569999999996)
('yuv.max=', 253.185, 'yuv.min=', -24.140199999999986)
('yuv.max=', 248.05999999999997, 'yuv.min=', -81.330629999999985)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.530169999999998)
('yuv.max=', 252.22799999999998, 'yuv.min=', -43.619349999999997)
('yuv.max=', 230.02499999999998, 'yuv.min=', -29.489310000000003)
('yuv.max=', 227.09700000000001, 'yuv.min=', -19.390339999999998)
('yuv.max=', 218.62, 'yuv.min=', -69.070879999999988)
('yuv.max=', 241.60199999999998, 'yuv.min=', -27.068540000000009)
('yuv.max=', 215.017, 'yuv.min=', -14.199609999999996)
('yuv.max=', 247.917, 'yuv.min=', -31.209720000000001)
('yuv.max=', 198.20099999999999, 'yuv.min=', -11.510289999999996)
('yuv.max=', 217.273, 'yuv.min=', -58.665269999999985)
('yuv.max=', 225.09, 'yuv.min=', -13.705169999999995)
('yuv.max=', 246.92499999999995, 'yuv.min=', -17.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.74006)
('yuv.max=', 229.38200000000001, 'yuv.min=', -93.520249999999976)
('yuv.max=', 217.45600000000002, 'yuv.min=', -29.945349999999998)
('yuv.max=', 108.22799999999999, 'yuv.min=', -0.20002000000000209)
('yuv.max=', 252.99099999999999, 'yuv.min=', -50.138730000000002)
('yuv.max=', 253.53300000000002, 'yuv.min=', -34.933040000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -68.351200000000006)
('yuv.max=', 210.92399999999998, 'yuv.min=', -50.829510000000013)
('yuv.max=', 255.0, 'yuv.min=', -88.297919999999991)
('yuv.max=', 252.08199999999999, 'yuv.min=', -34.800990000000006)
('yuv.max=', 229.62700000000001, 'yuv.min=', -40.760140000000007)
('yuv.max=', 249.04199999999997, 'yuv.min=', -27.530169999999998)
('yuv.max=', 235.37699999999998, 'yuv.min=', -39.395679999999999)
('yuv.max=', 241.82500000000002, 'yuv.min=', -19.688890000000008)
('yuv.max=', 253.376, 'yuv.min=', -67.152360000000016)
('yuv.max=', 255.0, 'yuv.min=', -49.463680000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -52.584370000000007)
('yuv.max=', 250.77100000000002, 'yuv.min=', -99.635799999999989)
('yuv.max=', 246.0, 'yuv.min=', -22.25494999999999)
('yuv.max=', 252.28800000000001, 'yuv.min=', -47.465379999999996)
('yuv.max=', 164.886, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -7.9988000000000028)
('yuv.max=', 249.15299999999999, 'yuv.min=', -3.9335100000000054)
('yuv.max=', 234.72299999999998, 'yuv.min=', -51.625550000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999989)
('yuv.max=', 223.81799999999998, 'yuv.min=', -25.726330000000004)
('yuv.max=', 241.25299999999996, 'yuv.min=', -34.175650000000005)
('yuv.max=', 181.67099999999999, 'yuv.min=', -7.2501100000000065)
('yuv.max=', 243.12899999999999, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.23899999999998, 'yuv.min=', -31.260419999999993)
('yuv.max=', 224.39099999999999, 'yuv.min=', -38.710549999999998)
('yuv.max=', 214.053, 'yuv.min=', -33.250249999999994)
('yuv.max=', 249.16899999999995, 'yuv.min=', -38.473530000000004)
('yuv.max=', 229.25799999999998, 'yuv.min=', -45.820980000000006)
('yuv.max=', 251.09199999999998, 'yuv.min=', -57.68965)
('yuv.max=', 228.12599999999998, 'yuv.min=', -30.893830000000005)
('yuv.max=', 204.56599999999997, 'yuv.min=', -22.795249999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 165.292, 'yuv.min=', -17.775239999999997)
('yuv.max=', 232.67399999999998, 'yuv.min=', -68.860489999999984)
('yuv.max=', 229.34799999999996, 'yuv.min=', -28.330249999999996)
('yuv.max=', 252.09200000000001, 'yuv.min=', -46.780249999999995)
('yuv.max=', 255.0, 'yuv.min=', -45.980169999999987)
('yuv.max=', 246.77699999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 224.148, 'yuv.min=', -11.955149999999996)
('yuv.max=', 237.57399999999998, 'yuv.min=', -25.135729999999995)
('yuv.max=', 192.06399999999999, 'yuv.min=', -40.315280000000001)
('yuv.max=', 254.07099999999997, 'yuv.min=', -26.755399999999987)
('yuv.max=', 216.387, 'yuv.min=', -27.860079999999993)
('yuv.max=', 252.04499999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 198.91499999999996, 'yuv.min=', -34.627499999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -66.460250000000002)
('yuv.max=', 255.0, 'yuv.min=', -11.335579999999993)
('yuv.max=', 241.34199999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 199.077, 'yuv.min=', -61.369249999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.068370000000009)
('yuv.max=', 170.994, 'yuv.min=', -33.020349999999993)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 234.036, 'yuv.min=', -29.119959999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.401590000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -63.859989999999996)
('yuv.max=', 236.14799999999997, 'yuv.min=', -29.630379999999995)
('yuv.max=', 203.52199999999999, 'yuv.min=', -31.415619999999997)
('yuv.max=', 188.959, 'yuv.min=', -23.76493)
('yuv.max=', 216.82599999999999, 'yuv.min=', -51.844860000000004)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.21699999999998, 'yuv.min=', -37.585129999999999)
('yuv.max=', 170.69800000000001, 'yuv.min=', -18.32011)
('yuv.max=', 183.34199999999998, 'yuv.min=', -29.000439999999998)
('yuv.max=', 207.16300000000001, 'yuv.min=', -14.478659999999998)
('yuv.max=', 236.316, 'yuv.min=', -9.4100799999999971)
('yuv.max=', 207.61899999999997, 'yuv.min=', -33.320379999999993)
('yuv.max=', 239.19399999999999, 'yuv.min=', -21.380169999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.757109999999997)
('yuv.max=', 245.81299999999999, 'yuv.min=', -22.828569999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.685039999999972)
('yuv.max=', 231.923, 'yuv.min=', -29.13032999999999)
('yuv.max=', 251.184, 'yuv.min=', -37.970229999999987)
('yuv.max=', 252.73500000000001, 'yuv.min=', -90.966039999999978)
('yuv.max=', 220.91799999999998, 'yuv.min=', -19.867100000000001)
('yuv.max=', 242.821, 'yuv.min=', -32.535520000000005)
('yuv.max=', 246.10699999999997, 'yuv.min=', -37.070139999999995)
('yuv.max=', 231.46299999999997, 'yuv.min=', -47.840109999999996)
('yuv.max=', 206.09299999999999, 'yuv.min=', -38.529660000000007)
('yuv.max=', 222.99999999999997, 'yuv.min=', -18.12008999999999)
('yuv.max=', 255.0, 'yuv.min=', -18.200749999999999)
('yuv.max=', 228.91800000000001, 'yuv.min=', -17.615469999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.707009999999997)
('yuv.max=', 205.32900000000001, 'yuv.min=', -73.580469999999991)
('yuv.max=', 232.69300000000001, 'yuv.min=', -40.610739999999986)
('yuv.max=', 162.441, 'yuv.min=', -35.85051)
('yuv.max=', 255.0, 'yuv.min=', -27.940579999999994)
('yuv.max=', 217.53300000000002, 'yuv.min=', -39.610639999999997)
('yuv.max=', 222.624, 'yuv.min=', -76.855489999999989)
('yuv.max=', 255.0, 'yuv.min=', -19.629650000000002)
('yuv.max=', 242.75500000000002, 'yuv.min=', -19.490349999999992)
('yuv.max=', 253.52699999999999, 'yuv.min=', -14.270319999999991)
('yuv.max=', 254.77200000000002, 'yuv.min=', -15.875049999999996)
('yuv.max=', 238.12900000000002, 'yuv.min=', -44.570889999999991)
('yuv.max=', 255.0, 'yuv.min=', -39.125529999999998)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -21.090510000000002)
('yuv.max=', 222.19200000000001, 'yuv.min=', -29.945349999999991)
('yuv.max=', 242.0, 'yuv.min=', -45.965229999999991)
('yuv.max=', 245.05199999999996, 'yuv.min=', -39.94054999999998)
('yuv.max=', 253.15899999999996, 'yuv.min=', -17.497840000000004)
('yuv.max=', 255.0, 'yuv.min=', -6.0603599999999851)
('yuv.max=', 222.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.185, 'yuv.min=', -15.24510999999999)
('yuv.max=', 229.80199999999999, 'yuv.min=', -36.594410000000011)
('yuv.max=', 224.06799999999998, 'yuv.min=', -30.869519999999994)
('yuv.max=', 204.40099999999998, 'yuv.min=', -19.260449999999999)
('yuv.max=', 224.16199999999998, 'yuv.min=', -45.624949999999991)
('yuv.max=', 240.64099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 230.77199999999999, 'yuv.min=', -2.2450399999999995)
('yuv.max=', 123.81199999999998, 'yuv.min=', -3.6750599999999989)
('yuv.max=', 236.566, 'yuv.min=', -17.620039999999999)
('yuv.max=', 213.80399999999997, 'yuv.min=', -36.810359999999989)
('yuv.max=', 180.21899999999999, 'yuv.min=', -42.125829999999993)
('yuv.max=', 243.33099999999999, 'yuv.min=', -47.550449999999984)
('yuv.max=', 224.10999999999999, 'yuv.min=', -21.421880000000002)
('yuv.max=', 250.56599999999997, 'yuv.min=', -13.507780000000004)
('yuv.max=', 250.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 188.75299999999999, 'yuv.min=', -41.160179999999983)
('yuv.max=', 209.21900000000002, 'yuv.min=', -89.268520000000009)
('yuv.max=', 239.93999999999997, 'yuv.min=', -0.72408999999999679)
('yuv.max=', 153.11499999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 224.102, 'yuv.min=', -30.600599999999996)
('yuv.max=', 241.17699999999996, 'yuv.min=', -33.248109999999997)
('yuv.max=', 226.12599999999998, 'yuv.min=', -24.021619999999999)
('yuv.max=', 247.86400000000003, 'yuv.min=', -55.900669999999998)
('yuv.max=', 232.47999999999996, 'yuv.min=', -63.355369999999994)
('yuv.max=', 208.285, 'yuv.min=', -42.945419999999991)
('yuv.max=', 251.37799999999999, 'yuv.min=', -29.258660000000006)
('yuv.max=', 223.54400000000001, 'yuv.min=', -5.0773899999999941)
('yuv.max=', 255.0, 'yuv.min=', -36.900739999999999)
('yuv.max=', 249.65099999999995, 'yuv.min=', -27.193539999999999)
('yuv.max=', 196.08699999999999, 'yuv.min=', -43.600669999999994)
('yuv.max=', 196.12299999999999, 'yuv.min=', -10.605629999999991)
('yuv.max=', 210.00199999999998, 'yuv.min=', -40.369239999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.888730000000002)
('yuv.max=', 197.90800000000002, 'yuv.min=', -67.369979999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.915199999999992)
('yuv.max=', 243.58699999999999, 'yuv.min=', -21.247330000000005)
('yuv.max=', 248.77199999999999, 'yuv.min=', -19.620239999999995)
('yuv.max=', 201.578, 'yuv.min=', -63.28273999999999)
('yuv.max=', 205.43599999999998, 'yuv.min=', -32.330649999999999)
('yuv.max=', 238.93099999999998, 'yuv.min=', -9.0175199999999904)
('yuv.max=', 202.21099999999998, 'yuv.min=', -22.33212)
('yuv.max=', 255.0, 'yuv.min=', -20.36056)
('yuv.max=', 234.32299999999998, 'yuv.min=', -32.880089999999988)
('yuv.max=', 238.89000000000001, 'yuv.min=', -18.860410000000002)
('yuv.max=', 254.06, 'yuv.min=', -86.250630000000001)
('yuv.max=', 250.47299999999998, 'yuv.min=', -56.427109999999999)
('yuv.max=', 244.28799999999998, 'yuv.min=', -9.1652399999999936)
('yuv.max=', 250.619, 'yuv.min=', -41.270559999999996)
('yuv.max=', 201.96100000000001, 'yuv.min=', -18.335049999999999)
('yuv.max=', 233.45599999999999, 'yuv.min=', -6.4350900000000095)
('yuv.max=', 255.0, 'yuv.min=', -18.352900000000002)
('yuv.max=', 193.87599999999998, 'yuv.min=', -12.946920000000002)
('yuv.max=', 200.98399999999998, 'yuv.min=', -24.525299999999984)
('yuv.max=', 226.08699999999999, 'yuv.min=', -37.416770000000007)
('yuv.max=', 248.10299999999998, 'yuv.min=', -37.701039999999992)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.887650000000001)
('yuv.max=', 246.77199999999999, 'yuv.min=', -22.338999999999995)
('yuv.max=', 235.26599999999999, 'yuv.min=', -49.56559)
('yuv.max=', 255.0, 'yuv.min=', -28.910130000000002)
('yuv.max=', 237.65100000000001, 'yuv.min=', -32.990469999999995)
('yuv.max=', 208.72800000000001, 'yuv.min=', -20.435259999999992)
('yuv.max=', 249.245, 'yuv.min=', -33.651740000000004)
('yuv.max=', 222.14599999999999, 'yuv.min=', -20.780109999999997)
('yuv.max=', 227.363, 'yuv.min=', -72.329419999999999)
('yuv.max=', 180.17099999999999, 'yuv.min=', -15.35549)
('yuv.max=', 248.798, 'yuv.min=', -32.820329999999991)
('yuv.max=', 199.47399999999999, 'yuv.min=', -50.39555)
('yuv.max=', 199.87900000000002, 'yuv.min=', -13.389159999999997)
('yuv.max=', 254.47300000000001, 'yuv.min=', -49.495459999999994)
('yuv.max=', 250.017, 'yuv.min=', -13.630009999999999)
('yuv.max=', 215.33099999999999, 'yuv.min=', -15.945179999999997)
('yuv.max=', 255.0, 'yuv.min=', -22.119530000000012)
('yuv.max=', 255.0, 'yuv.min=', -30.136980000000001)
('yuv.max=', 210.374, 'yuv.min=', -32.441200000000002)
('yuv.max=', 204.80399999999997, 'yuv.min=', -22.965389999999982)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.316, 'yuv.min=', -17.738499999999995)
('yuv.max=', 228.56699999999998, 'yuv.min=', -18.975359999999984)
('yuv.max=', 245.24800000000002, 'yuv.min=', -55.11553)
('yuv.max=', 248.809, 'yuv.min=', -43.65585999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.700309999999995)
('yuv.max=', 210.56799999999998, 'yuv.min=', -30.94544999999999)
('yuv.max=', 199.73499999999999, 'yuv.min=', -15.70613)
('yuv.max=', 211.81900000000002, 'yuv.min=', -20.905429999999988)
('yuv.max=', 195.12900000000002, 'yuv.min=', -38.23124)
('yuv.max=', 224.73499999999999, 'yuv.min=', -32.735259999999997)
('yuv.max=', 250.66399999999999, 'yuv.min=', -92.730539999999991)
('yuv.max=', 254.47300000000001, 'yuv.min=', -27.788030000000003)
('yuv.max=', 247.51599999999999, 'yuv.min=', -30.475280000000001)
('yuv.max=', 174.78899999999999, 'yuv.min=', -9.3100699999999978)
('yuv.max=', 255.0, 'yuv.min=', -42.164810000000003)
('yuv.max=', 183.82599999999999, 'yuv.min=', -14.500219999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.420189999999991)
('yuv.max=', 238.99999999999997, 'yuv.min=', -11.922590000000001)
('yuv.max=', 241.91899999999998, 'yuv.min=', -33.620409999999993)
('yuv.max=', 255.0, 'yuv.min=', -54.160190000000007)
('yuv.max=', 198.84999999999999, 'yuv.min=', -39.895729999999993)
('yuv.max=', 255.0, 'yuv.min=', -28.249749999999981)
('yuv.max=', 255.0, 'yuv.min=', -64.723169999999996)
('yuv.max=', 247.68000000000001, 'yuv.min=', -40.745199999999983)
('yuv.max=', 241.405, 'yuv.min=', -58.715889999999987)
('yuv.max=', 254.886, 'yuv.min=', -37.935400000000001)
('yuv.max=', 248.047, 'yuv.min=', -81.332899999999995)
('yuv.max=', 197.41399999999999, 'yuv.min=', -63.225480000000005)
('yuv.max=', 228.41299999999998, 'yuv.min=', -32.960589999999996)
('yuv.max=', 255.0, 'yuv.min=', -24.210329999999992)
('yuv.max=', 255.0, 'yuv.min=', -14.500219999999992)
('yuv.max=', 249.61799999999999, 'yuv.min=', -33.91006999999999)
('yuv.max=', 131.035, 'yuv.min=', -29.815460000000002)
('yuv.max=', 221.49899999999997, 'yuv.min=', -39.94006000000001)
('yuv.max=', 175.83199999999999, 'yuv.min=', -15.279870000000003)
('yuv.max=', 252.51599999999999, 'yuv.min=', -40.070439999999998)
('yuv.max=', 240.73399999999998, 'yuv.min=', -24.162760000000006)
('yuv.max=', 206.517, 'yuv.min=', -30.630479999999991)
('yuv.max=', 244.75199999999998, 'yuv.min=', -39.308130000000006)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.82599999999996, 'yuv.min=', -72.474559999999983)
('yuv.max=', 253.20599999999999, 'yuv.min=', -30.224890000000002)
('yuv.max=', 255.0, 'yuv.min=', -18.315770000000001)
('yuv.max=', 204.21899999999999, 'yuv.min=', -31.260420000000003)
('yuv.max=', 252.886, 'yuv.min=', -15.015209999999989)
('yuv.max=', 253.82599999999996, 'yuv.min=', -50.595569999999995)
('yuv.max=', 217.97899999999998, 'yuv.min=', -33.220369999999988)
('yuv.max=', 237.64400000000001, 'yuv.min=', -54.600539999999995)
('yuv.max=', 238.73299999999998, 'yuv.min=', -18.190219999999997)
('yuv.max=', 236.68999999999997, 'yuv.min=', -25.329799999999999)
('yuv.max=', 254.18499999999997, 'yuv.min=', -19.03603)
('yuv.max=', 246.78700000000001, 'yuv.min=', -29.470609999999997)
('yuv.max=', 254.06, 'yuv.min=', -78.310819999999993)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 245.76499999999999, 'yuv.min=', -32.290399999999984)
('yuv.max=', 232.64499999999998, 'yuv.min=', -33.990600000000001)
('yuv.max=', 249.15700000000001, 'yuv.min=', -33.790549999999996)
('yuv.max=', 246.02799999999996, 'yuv.min=', -35.544679999999993)
('yuv.max=', 251.70099999999996, 'yuv.min=', -26.91575000000001)
('yuv.max=', 255.0, 'yuv.min=', -4.9200000000000017)
('yuv.max=', 247.68999999999997, 'yuv.min=', -34.090579999999996)
('yuv.max=', 232.67199999999997, 'yuv.min=', -45.385909999999988)
('yuv.max=', 224.61000000000001, 'yuv.min=', -31.560450000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.61899999999997, 'yuv.min=', -22.495219999999996)
('yuv.max=', 234.91, 'yuv.min=', -20.165109999999991)
('yuv.max=', 255.0, 'yuv.min=', -16.690069999999992)
('yuv.max=', 242.85299999999998, 'yuv.min=', -11.329499999999996)
('yuv.max=', 239.929, 'yuv.min=', -13.844969999999988)
('yuv.max=', 217.01499999999999, 'yuv.min=', -30.320079999999994)
('yuv.max=', 205.12100000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 222.61499999999998, 'yuv.min=', -21.750329999999991)
('yuv.max=', 241.55199999999996, 'yuv.min=', -51.031010000000002)
('yuv.max=', 202.63399999999999, 'yuv.min=', -11.255079999999989)
('yuv.max=', 249.21599999999998, 'yuv.min=', -60.23809)
('yuv.max=', 227.11799999999999, 'yuv.min=', -48.333080000000017)
('yuv.max=', 252.22799999999998, 'yuv.min=', -18.85643)
('yuv.max=', 236.01599999999999, 'yuv.min=', -35.720619999999997)
('yuv.max=', 158.18000000000001, 'yuv.min=', -14.885320000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 184.494, 'yuv.min=', -13.814609999999995)
('yuv.max=', 224.90799999999999, 'yuv.min=', -13.540370000000003)
('yuv.max=', 194.99999999999997, 'yuv.min=', -12.155170000000002)
('yuv.max=', 227.52699999999999, 'yuv.min=', -43.532090000000004)
('yuv.max=', 252.01899999999995, 'yuv.min=', -53.070509999999985)
('yuv.max=', 162.054, 'yuv.min=', -21.930839999999986)
('yuv.max=', 255.0, 'yuv.min=', -90.540689999999984)
('yuv.max=', 254.70099999999999, 'yuv.min=', -17.875250000000001)
('yuv.max=', 245.298, 'yuv.min=', -68.70071999999999)
('yuv.max=', 232.35899999999998, 'yuv.min=', -83.986760000000004)
('yuv.max=', 195.59899999999999, 'yuv.min=', -51.962910000000001)
('yuv.max=', 180.13599999999997, 'yuv.min=', -23.42518999999999)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.740059999999993)
('yuv.max=', 249.62099999999998, 'yuv.min=', -31.630579999999998)
('yuv.max=', 234.59800000000001, 'yuv.min=', -42.486090000000004)
('yuv.max=', 255.0, 'yuv.min=', -28.478060000000006)
('yuv.max=', 236.22199999999998, 'yuv.min=', -30.355759999999997)
('yuv.max=', 230.024, 'yuv.min=', -19.635530000000003)
('yuv.max=', 255.0, 'yuv.min=', -63.691079999999992)
('yuv.max=', 221.22799999999998, 'yuv.min=', -19.020179999999996)
('yuv.max=', 222.19099999999997, 'yuv.min=', -90.490069999999989)
('yuv.max=', 221.58799999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 238.815, 'yuv.min=', -29.030319999999993)
('yuv.max=', 244.40199999999999, 'yuv.min=', -29.07513999999999)
('yuv.max=', 235.90399999999997, 'yuv.min=', -42.815529999999995)
('yuv.max=', 238.21100000000001, 'yuv.min=', -28.148730000000008)
('yuv.max=', 255.0, 'yuv.min=', -48.180859999999996)
('yuv.max=', 237.20299999999997, 'yuv.min=', -62.088510000000007)
('yuv.max=', 227.79900000000001, 'yuv.min=', -44.802329999999998)
('yuv.max=', 160.554, 'yuv.min=', -23.825229999999998)
('yuv.max=', 195.98399999999998, 'yuv.min=', -19.178000000000004)
('yuv.max=', 247.02799999999999, 'yuv.min=', -35.1355)
('yuv.max=', 236.327, 'yuv.min=', -38.262810000000002)
('yuv.max=', 233.97200000000001, 'yuv.min=', -17.305070000000004)
('yuv.max=', 243.62599999999998, 'yuv.min=', -59.87576)
('yuv.max=', 202.66799999999998, 'yuv.min=', -15.732389999999995)
('yuv.max=', 220.28800000000001, 'yuv.min=', -25.840369999999986)
('yuv.max=', 246.40199999999999, 'yuv.min=', -34.505559999999996)
('yuv.max=', 228.58699999999999, 'yuv.min=', -44.582839999999997)
('yuv.max=', 255.0, 'yuv.min=', -40.731529999999992)
('yuv.max=', 242.67299999999997, 'yuv.min=', -20.945679999999996)
('yuv.max=', 239.71399999999997, 'yuv.min=', -28.285429999999991)
('yuv.max=', 204.26399999999998, 'yuv.min=', -57.235249999999994)
('yuv.max=', 239.24099999999996, 'yuv.min=', -21.252860000000005)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -20.47551)
('yuv.max=', 229.76400000000001, 'yuv.min=', -32.385839999999995)
('yuv.max=', 255.0, 'yuv.min=', -36.850609999999996)
('yuv.max=', 217.33699999999999, 'yuv.min=', -21.568870000000004)
('yuv.max=', 214.49199999999996, 'yuv.min=', -29.500489999999996)
('yuv.max=', 234.62300000000002, 'yuv.min=', -54.481019999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -21.389190000000006)
('yuv.max=', 228.185, 'yuv.min=', -16.36015999999999)
('yuv.max=', 225.26000000000002, 'yuv.min=', -33.890559999999994)
('yuv.max=', 255.0, 'yuv.min=', -38.976789999999994)
('yuv.max=', 191.38900000000001, 'yuv.min=', -17.89018999999999)
('yuv.max=', 254.316, 'yuv.min=', -15.885419999999996)
('yuv.max=', 247.75500000000002, 'yuv.min=', -46.835439999999991)
('yuv.max=', 171.44899999999998, 'yuv.min=', -38.070239999999998)
('yuv.max=', 189.35499999999999, 'yuv.min=', -21.19508999999999)
('yuv.max=', 215.892, 'yuv.min=', -45.865220000000001)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.74199999999999, 'yuv.min=', -38.050730000000001)
('yuv.max=', 217.64600000000002, 'yuv.min=', -19.605300000000003)
('yuv.max=', 248.99999999999997, 'yuv.min=', -7.1501000000000001)
('yuv.max=', 205.12900000000002, 'yuv.min=', -15.800349999999991)
('yuv.max=', 240.07499999999999, 'yuv.min=', -45.215769999999992)
('yuv.max=', 213.44799999999998, 'yuv.min=', -19.80341)
('yuv.max=', 238.45799999999997, 'yuv.min=', -35.920639999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.850239999999996)
('yuv.max=', 186.886, 'yuv.min=', -14.696860000000001)
('yuv.max=', 210.339, 'yuv.min=', -24.525299999999994)
('yuv.max=', 176.46799999999999, 'yuv.min=', -46.960759999999986)
('yuv.max=', 251.804, 'yuv.min=', -34.131769999999996)
('yuv.max=', 209.84499999999997, 'yuv.min=', -14.800249999999998)
('yuv.max=', 241.75399999999999, 'yuv.min=', -30.575289999999981)
('yuv.max=', 254.131, 'yuv.min=', -81.621639999999999)
('yuv.max=', 255.0, 'yuv.min=', -10.955049999999989)
('yuv.max=', 250.55500000000001, 'yuv.min=', -69.575499999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.389639999999988)
('yuv.max=', 248.00999999999999, 'yuv.min=', -16.345219999999998)
('yuv.max=', 250.64699999999996, 'yuv.min=', -32.675499999999992)
('yuv.max=', 248.733, 'yuv.min=', -24.940279999999994)
('yuv.max=', 237.0, 'yuv.min=', -13.470239999999993)
('yuv.max=', 168.07299999999998, 'yuv.min=', -56.31277)
('yuv.max=', 255.0, 'yuv.min=', -67.930520000000001)
('yuv.max=', 255.0, 'yuv.min=', -66.445309999999978)
('yuv.max=', 239.495, 'yuv.min=', -44.425799999999995)
('yuv.max=', 206.15999999999997, 'yuv.min=', -23.259139999999995)
('yuv.max=', 228.32399999999998, 'yuv.min=', -30.490219999999983)
('yuv.max=', 208.72299999999998, 'yuv.min=', -46.805559999999993)
('yuv.max=', 205.31900000000002, 'yuv.min=', -26.025449999999985)
('yuv.max=', 255.0, 'yuv.min=', -27.749699999999983)
('yuv.max=', 255.0, 'yuv.min=', -33.17554999999998)
('yuv.max=', 235.98899999999998, 'yuv.min=', -18.690269999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.988070000000008)
('yuv.max=', 250.43399999999997, 'yuv.min=', -33.960689999999992)
('yuv.max=', 227.81899999999999, 'yuv.min=', -18.905229999999992)
('yuv.max=', 255.0, 'yuv.min=', -19.094879999999989)
('yuv.max=', 183.06999999999999, 'yuv.min=', -35.125129999999999)
('yuv.max=', 198.893, 'yuv.min=', -30.830500000000001)
('yuv.max=', 227.02799999999999, 'yuv.min=', -22.796750000000003)
('yuv.max=', 215.38800000000001, 'yuv.min=', -21.780209999999997)
('yuv.max=', 250.02800000000002, 'yuv.min=', -14.0703)
('yuv.max=', 159.87900000000002, 'yuv.min=', -16.949849999999994)
('yuv.max=', 244.499, 'yuv.min=', -8.3651599999999959)
('yuv.max=', 248.34200000000001, 'yuv.min=', -30.000539999999987)
('yuv.max=', 237.131, 'yuv.min=', -31.145469999999996)
('yuv.max=', 239.03199999999998, 'yuv.min=', -64.585369999999983)
('yuv.max=', 219.893, 'yuv.min=', -52.750970000000002)
('yuv.max=', 251.60400000000001, 'yuv.min=', -27.70030999999998)
('yuv.max=', 166.42499999999998, 'yuv.min=', -31.209389999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.650459999999995)
('yuv.max=', 252.54399999999998, 'yuv.min=', -29.00043999999999)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -29.245279999999998)
('yuv.max=', 214.166, 'yuv.min=', -48.595369999999988)
('yuv.max=', 254.886, 'yuv.min=', -18.364109999999997)
('yuv.max=', 236.40200000000002, 'yuv.min=', -8.4801100000000034)
('yuv.max=', 236.36699999999996, 'yuv.min=', -23.290729999999996)
('yuv.max=', 245.54399999999998, 'yuv.min=', -60.605709999999988)
('yuv.max=', 193.34899999999999, 'yuv.min=', -39.429099999999998)
('yuv.max=', 236.191, 'yuv.min=', -28.638370000000005)
('yuv.max=', 233.98500000000001, 'yuv.min=', -24.225269999999995)
('yuv.max=', 204.11499999999998, 'yuv.min=', -16.960219999999996)
('yuv.max=', 252.65199999999999, 'yuv.min=', -1.1150499999999992)
('yuv.max=', 245.29300000000001, 'yuv.min=', -11.644089999999998)
('yuv.max=', 204.786, 'yuv.min=', -65.359139999999996)
('yuv.max=', 207.94299999999998, 'yuv.min=', -22.165309999999998)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999985)
('yuv.max=', 230.17499999999998, 'yuv.min=', -38.159880000000001)
('yuv.max=', 150.44200000000001, 'yuv.min=', -21.845769999999995)
('yuv.max=', 255.0, 'yuv.min=', -11.41028)
('yuv.max=', 228.14599999999999, 'yuv.min=', -28.215299999999996)
('yuv.max=', 239.30499999999995, 'yuv.min=', -36.310309999999987)
('yuv.max=', 248.93599999999998, 'yuv.min=', -37.680569999999989)
('yuv.max=', 255.0, 'yuv.min=', -18.191449999999996)
('yuv.max=', 196.74099999999999, 'yuv.min=', -22.21876)
('yuv.max=', 239.79300000000001, 'yuv.min=', -24.395409999999998)
('yuv.max=', 170.26199999999997, 'yuv.min=', -15.660089999999984)
('yuv.max=', 248.48399999999998, 'yuv.min=', -53.032440000000008)
('yuv.max=', 251.12399999999997, 'yuv.min=', -27.418160000000004)
('yuv.max=', 242.62300000000002, 'yuv.min=', -26.840469999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.632580000000001)
('yuv.max=', 229.08700000000002, 'yuv.min=', -57.220309999999991)
('yuv.max=', 215.161, 'yuv.min=', -21.296720000000004)
('yuv.max=', 252.91399999999999, 'yuv.min=', -27.515280000000008)
('yuv.max=', 207.803, 'yuv.min=', -30.460339999999992)
('yuv.max=', 253.16300000000001, 'yuv.min=', -79.645399999999995)
('yuv.max=', 102.501, 'yuv.min=', -55.625949999999989)
('yuv.max=', 242.56400000000002, 'yuv.min=', -38.305939999999993)
('yuv.max=', 195.38899999999998, 'yuv.min=', -43.570789999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.3264499999999977)
('yuv.max=', 190.25200000000001, 'yuv.min=', -38.520899999999997)
('yuv.max=', 255.0, 'yuv.min=', -37.710449999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.98299999999998, 'yuv.min=', -10.12509)
('yuv.max=', 166.12100000000001, 'yuv.min=', -35.984520000000003)
('yuv.max=', 209.81299999999999, 'yuv.min=', -30.200559999999996)
('yuv.max=', 249.03200000000001, 'yuv.min=', -86.195439999999991)
('yuv.max=', 254.10300000000001, 'yuv.min=', -9.0951099999999929)
('yuv.max=', 218.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 196.91199999999998, 'yuv.min=', -46.769480000000001)
('yuv.max=', 250.28999999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 245.59999999999999, 'yuv.min=', -21.772079999999999)
('yuv.max=', 241.33700000000002, 'yuv.min=', -13.922060000000002)
('yuv.max=', 200.65100000000001, 'yuv.min=', -52.161279999999991)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.58700000000002, 'yuv.min=', -6.0350499999999965)
('yuv.max=', 247.89599999999999, 'yuv.min=', -22.696790000000007)
('yuv.max=', 202.28200000000001, 'yuv.min=', -48.985970000000009)
('yuv.max=', 238.50800000000001, 'yuv.min=', -56.726059999999997)
('yuv.max=', 237.79300000000001, 'yuv.min=', -30.230440000000002)
('yuv.max=', 190.26300000000001, 'yuv.min=', -31.405249999999995)
('yuv.max=', 225.101, 'yuv.min=', -24.462960000000002)
('yuv.max=', 223.25599999999997, 'yuv.min=', -55.450009999999992)
('yuv.max=', 234.08499999999998, 'yuv.min=', -30.275259999999992)
('yuv.max=', 230.928, 'yuv.min=', -82.360610000000008)
('yuv.max=', 236.39299999999997, 'yuv.min=', -19.634180000000001)
('yuv.max=', 239.45599999999996, 'yuv.min=', -29.794030000000003)
('yuv.max=', 246.858, 'yuv.min=', -7.1063700000000019)
('yuv.max=', 246.02799999999996, 'yuv.min=', -83.158919999999995)
('yuv.max=', 251.42299999999997, 'yuv.min=', -39.540509999999998)
('yuv.max=', 254.08800000000002, 'yuv.min=', -21.8354)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -63.212269999999997)
('yuv.max=', 252.40799999999999, 'yuv.min=', -53.270529999999994)
('yuv.max=', 248.59399999999999, 'yuv.min=', -48.210269999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.61023999999999)
('yuv.max=', 250.23399999999998, 'yuv.min=', -36.510329999999989)
('yuv.max=', 218.554, 'yuv.min=', -43.569760000000002)
('yuv.max=', 249.815, 'yuv.min=', -62.180559999999993)
('yuv.max=', 246.91199999999998, 'yuv.min=', -46.725059999999992)
('yuv.max=', 244.84899999999999, 'yuv.min=', -14.159939999999985)
('yuv.max=', 241.35299999999998, 'yuv.min=', -59.665369999999996)
('yuv.max=', 234.35099999999997, 'yuv.min=', -44.535209999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.365529999999993)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
atchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.704193')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7799 ', 'GAN acc 0.3477', 'Discriminator loss 0.4728', 'Discriminator accuracy 0.8125', 'Total loss: 1.2527', 'for batch', 0)
('GAN loss 0.7303 ', 'GAN acc 0.4258', 'Discriminator loss 0.4285', 'Discriminator accuracy 0.7773', 'Total loss: 1.1588', 'for batch', 1)
('GAN loss 0.7470 ', 'GAN acc 0.3984', 'Discriminator loss 0.3545', 'Discriminator accuracy 0.7656', 'Total loss: 1.1015', 'for batch', 2)
('GAN loss 0.7276 ', 'GAN acc 0.4414', 'Discriminator loss 0.3832', 'Discriminator accuracy 0.7891', 'Total loss: 1.1107', 'for batch', 3)
('GAN loss 0.7107 ', 'GAN acc 0.5039', 'Discriminator loss 0.3987', 'Discriminator accuracy 0.7832', 'Total loss: 1.1094', 'for batch', 4)
('GAN loss 0.7351 ', 'GAN acc 0.4375', 'Discriminator loss 0.4111', 'Discriminator accuracy 0.7578', 'Total loss: 1.1461', 'for batch', 5)
('GAN loss 0.7249 ', 'GAN acc 0.4805', 'Discriminator loss 0.4410', 'Discriminator accuracy 0.7148', 'Total loss: 1.1658', 'for batch', 6)
('GAN loss 0.7524 ', 'GAN acc 0.4062', 'Discriminator loss 0.3826', 'Discriminator accuracy 0.7617', 'Total loss: 1.1350', 'for batch', 7)
('GAN loss 0.7825 ', 'GAN acc 0.3516', 'Discriminator loss 0.3609', 'Discriminator accuracy 0.7734', 'Total loss: 1.1433', 'for batch', 8)
('GAN loss 0.7872 ', 'GAN acc 0.3516', 'Discriminator loss 0.3997', 'Discriminator accuracy 0.7715', 'Total loss: 1.1868', 'for batch', 9)
('GAN loss 0.7717 ', 'GAN acc 0.3359', 'Discriminator loss 0.4183', 'Discriminator accuracy 0.8047', 'Total loss: 1.1900', 'for batch', 10)
('GAN loss 0.7955 ', 'GAN acc 0.3477', 'Discriminator loss 0.3357', 'Discriminator accuracy 0.7949', 'Total loss: 1.1312', 'for batch', 11)
('GAN loss 0.8502 ', 'GAN acc 0.1953', 'Discriminator loss 0.3633', 'Discriminator accuracy 0.8223', 'Total loss: 1.2135', 'for batch', 12)
('GAN loss 0.8499 ', 'GAN acc 0.2031', 'Discriminator loss 0.4072', 'Discriminator accuracy 0.8496', 'Total loss: 1.2571', 'for batch', 13)
('GAN loss 0.8556 ', 'GAN acc 0.2383', 'Discriminator loss 0.3453', 'Discriminator accuracy 0.8652', 'Total loss: 1.2010', 'for batch', 14)
('GAN loss 0.8381 ', 'GAN acc 0.2109', 'Discriminator loss 0.3505', 'Discriminator accuracy 0.8770', 'Total loss: 1.1886', 'for batch', 15)
('GAN loss 0.8071 ', 'GAN acc 0.2695', 'Discriminator loss 0.3442', 'Discriminator accuracy 0.8496', 'Total loss: 1.1513', 'for batch', 16)
('GAN loss 0.7949 ', 'GAN acc 0.3281', 'Discriminator loss 0.4159', 'Discriminator accuracy 0.8301', 'Total loss: 1.2109', 'for batch', 17)
('GAN loss 0.8294 ', 'GAN acc 0.2188', 'Discriminator loss 0.3435', 'Discriminator accuracy 0.8145', 'Total loss: 1.1729', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98222435)
('DISCRIMINATOR_Imagem FAKE=', 0.40779275)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.226639')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8310 ', 'GAN acc 0.2344', 'Discriminator loss 0.3251', 'Discriminator accuracy 0.8594', 'Total loss: 1.1561', 'for batch', 0)
('GAN loss 0.8278 ', 'GAN acc 0.2734', 'Discriminator loss 0.3367', 'Discriminator accuracy 0.8418', 'Total loss: 1.1645', 'for batch', 1)
('GAN loss 0.8074 ', 'GAN acc 0.2461', 'Discriminator loss 0.3488', 'Discriminator accuracy 0.8984', 'Total loss: 1.1563', 'for batch', 2)
('GAN loss 0.8162 ', 'GAN acc 0.2969', 'Discriminator loss 0.3592', 'Discriminator accuracy 0.8340', 'Total loss: 1.1753', 'for batch', 3)
('GAN loss 0.7954 ', 'GAN acc 0.3242', 'Discriminator loss 0.3765', 'Discriminator accuracy 0.8223', 'Total loss: 1.1719', 'for batch', 4)
('GAN loss 0.8109 ', 'GAN acc 0.2656', 'Discriminator loss 0.3686', 'Discriminator accuracy 0.8457', 'Total loss: 1.1795', 'for batch', 5)
('GAN loss 0.8232 ', 'GAN acc 0.2617', 'Discriminator loss 0.3658', 'Discriminator accuracy 0.8164', 'Total loss: 1.1('yuv.max=', 253.886, 'yuv.min=', -5.8200899999999978)
('yuv.max=', 230.196, 'yuv.min=', -28.355559999999997)
('yuv.max=', 253.185, 'yuv.min=', -47.816670000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.325330000000001)
('yuv.max=', 249.08799999999999, 'yuv.min=', -22.014679999999998)
('yuv.max=', 241.357, 'yuv.min=', -47.03631)
('yuv.max=', 253.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 227.59099999999998, 'yuv.min=', -18.474360000000001)
('yuv.max=', 255.0, 'yuv.min=', -31.690339999999988)
('yuv.max=', 212.16399999999999, 'yuv.min=', -33.985430000000001)
('yuv.max=', 161.36699999999999, 'yuv.min=', -15.330179999999991)
('yuv.max=', 251.58699999999996, 'yuv.min=', -34.763840000000002)
('yuv.max=', 233.28899999999999, 'yuv.min=', -48.380409999999983)
('yuv.max=', 243.10299999999998, 'yuv.min=', -15.721879999999999)
('yuv.max=', 252.608, 'yuv.min=', -45.075509999999994)
('yuv.max=', 212.26299999999998, 'yuv.min=', -49.265559999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -16.71994999999999)
('yuv.max=', 199.32599999999999, 'yuv.min=', -19.750250000000001)
('yuv.max=', 244.84299999999999, 'yuv.min=', -15.285960000000006)
('yuv.max=', 255.0, 'yuv.min=', -93.135149999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -40.404840000000007)
('yuv.max=', 228.33500000000001, 'yuv.min=', -13.485179999999998)
('yuv.max=', 247.29400000000001, 'yuv.min=', -79.179959999999994)
('yuv.max=', 231.06899999999996, 'yuv.min=', -54.994779999999992)
('yuv.max=', 242.43000000000001, 'yuv.min=', -28.48544999999999)
('yuv.max=', 250.59300000000002, 'yuv.min=', -34.00177)
('yuv.max=', 200.86199999999999, 'yuv.min=', -10.840099999999996)
('yuv.max=', 242.55199999999999, 'yuv.min=', -46.635419999999982)
('yuv.max=', 194.815, 'yuv.min=', -30.37527)
('yuv.max=', 195.589, 'yuv.min=', -23.416449999999998)
('yuv.max=', 255.0, 'yuv.min=', -29.775210000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.122379999999993)
('yuv.max=', 194.81800000000001, 'yuv.min=', -19.041510000000002)
('yuv.max=', 237.815, 'yuv.min=', -27.73019)
('yuv.max=', 221.83199999999997, 'yuv.min=', -17.705110000000005)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.14499999999998, 'yuv.min=', -24.610369999999989)
('yuv.max=', 230.994, 'yuv.min=', -18.795409999999997)
('yuv.max=', 216.31999999999999, 'yuv.min=', -32.015679999999996)
('yuv.max=', 255.0, 'yuv.min=', -39.065769999999986)
('yuv.max=', 248.72199999999998, 'yuv.min=', -40.510729999999995)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 222.39699999999999, 'yuv.min=', -32.909680000000009)
('yuv.max=', 252.93999999999997, 'yuv.min=', -30.04993)
('yuv.max=', 234.70499999999998, 'yuv.min=', -51.225509999999986)
('yuv.max=', 236.36799999999999, 'yuv.min=', -27.300269999999998)
('yuv.max=', 210.03699999999998, 'yuv.min=', -83.491100000000017)
('yuv.max=', 246.01599999999999, 'yuv.min=', -9.0190699999999957)
('yuv.max=', 252.71799999999996, 'yuv.min=', -54.515470000000001)
('yuv.max=', 205.90399999999997, 'yuv.min=', -21.465239999999994)
('yuv.max=', 227.33799999999999, 'yuv.min=', -12.65522)
('yuv.max=', 255.0, 'yuv.min=', -0.61499999999999488)
('yuv.max=', 246.90299999999996, 'yuv.min=', -40.130199999999988)
('yuv.max=', 253.14199999999997, 'yuv.min=', -19.535169999999997)
('yuv.max=', 195.929, 'yuv.min=', -9.4100799999999918)
('yuv.max=', 166.94199999999998, 'yuv.min=', -11.710309999999996)
('yuv.max=', 241.78300000000002, 'yuv.min=', -12.655219999999993)
('yuv.max=', 211.70699999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 243.94799999999998, 'yuv.min=', -64.230149999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.92000000000002, 'yuv.min=', -32.375469999999993)
('yuv.max=', 254.886, 'yuv.min=', -17.056809999999999)
('yuv.max=', 136.84700000000001, 'yuv.min=', -17.771080000000008)
('yuv.max=', 232.85599999999997, 'yuv.min=', -23.673919999999999)
('yuv.max=', 242.07100000000003, 'yuv.min=', -95.805539999999979)
('yuv.max=', 255.0, 'yuv.min=', -20.575519999999997)
('yuv.max=', 171.85799999999998, 'yuv.min=', -9.2754099999999973)
('yuv.max=', 188.80599999999998, 'yuv.min=', -43.162559999999999)
('yuv.max=', 217.006, 'yuv.min=', -40.715319999999984)
('yuv.max=', 251.40199999999999, 'yuv.min=', -27.61524)
('yuv.max=', 193.46199999999999, 'yuv.min=', -17.6051)
('yuv.max=', 244.57599999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -75.965769999999992)
('yuv.max=', 247.62899999999999, 'yuv.min=', -20.806990000000003)
('yuv.max=', 238.40899999999999, 'yuv.min=', -15.47500999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.18199999999996, 'yuv.min=', -49.310379999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.294829999999997)
('yuv.max=', 240.28699999999998, 'yuv.min=', -56.120199999999997)
('yuv.max=', 249.61799999999999, 'yuv.min=', -56.315649999999991)
('yuv.max=', 244.39500000000001, 'yuv.min=', -54.300509999999989)
('yuv.max=', 220.31999999999999, 'yuv.min=', -16.530300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 216.50300000000001, 'yuv.min=', -109.62062999999999)
('yuv.max=', 238.71700000000001, 'yuv.min=', -25.695899999999998)
('yuv.max=', 193.77200000000002, 'yuv.min=', -11.787260000000007)
('yuv.max=', 216.60199999999998, 'yuv.min=', -24.942880000000002)
('yuv.max=', 240.87299999999999, 'yuv.min=', -83.801829999999995)
('yuv.max=', 249.929, 'yuv.min=', -15.615269999999988)
('yuv.max=', 254.58699999999999, 'yuv.min=', -40.278750000000009)
('yuv.max=', 252.54399999999998, 'yuv.min=', -30.205670000000001)
('yuv.max=', 240.81299999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 235.24099999999999, 'yuv.min=', -41.771799999999999)
('yuv.max=', 205.71600000000001, 'yuv.min=', -31.624779999999998)
('yuv.max=', 222.88399999999999, 'yuv.min=', -11.365459999999988)
('yuv.max=', 200.66199999999998, 'yuv.min=', -57.030659999999997)
('yuv.max=', 246.84099999999998, 'yuv.min=', -87.730039999999988)
('yuv.max=', 228.22799999999998, 'yuv.min=', -24.89546)
('yuv.max=', 255.0, 'yuv.min=', -33.11578999999999)
('yuv.max=', 225.44800000000001, 'yuv.min=', -21.524999999999991)
('yuv.max=', 234.70600000000002, 'yuv.min=', -53.330289999999991)
('yuv.max=', 253.95699999999997, 'yuv.min=', -13.115019999999991)
('yuv.max=', 185.78299999999999, 'yuv.min=', -17.121750000000002)
('yuv.max=', 168.45600000000002, 'yuv.min=', -17.230369999999986)
('yuv.max=', 245.53899999999999, 'yuv.min=', -81.045539999999988)
('yuv.max=', 219.37899999999999, 'yuv.min=', -29.655689999999989)
('yuv.max=', 254.18499999999997, 'yuv.min=', -41.571359999999999)
('yuv.max=', 193.53100000000001, 'yuv.min=', -13.000070000000003)
('yuv.max=', 218.79399999999998, 'yuv.min=', -22.93834)
('yuv.max=', 250.99999999999997, 'yuv.min=', -41.760239999999996)
('yuv.max=', 236.721, 'yuv.min=', -44.519120000000001)
('yuv.max=', 252.37800000000001, 'yuv.min=', -31.630049999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.687730000000002)
('yuv.max=', 187.93699999999998, 'yuv.min=', -21.290529999999997)
('yuv.max=', 252.91799999999998, 'yuv.min=', -18.505189999999995)
('yuv.max=', 190.06299999999999, 'yuv.min=', -29.515429999999995)
('yuv.max=', 236.29300000000001, 'yuv.min=', -56.415659999999988)
('yuv.max=', 247.67500000000001, 'yuv.min=', -33.859050000000003)
('yuv.max=', 253.59799999999998, 'yuv.min=', -30.320079999999997)
('yuv.max=', 249.392, 'yuv.min=', -29.635759999999998)
('yuv.max=', 220.94899999999998, 'yuv.min=', -48.07580999999999)
('yuv.max=', 255.0, 'yuv.min=', -54.791900000000012)
('yuv.max=', 251.29900000000001, 'yuv.min=', -12.78511)
('yuv.max=', 247.626, 'yuv.min=', -38.311530000000005)
('yuv.max=', 238.327, 'yuv.min=', -26.926470000000002)
('yuv.max=', 198.15899999999999, 'yuv.min=', -86.01415999999999)
('yuv.max=', 172.339, 'yuv.min=', -38.38064)
('yuv.max=', 246.249, 'yuv.min=', -24.095379999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.970929999999996)
('yuv.max=', 223.73999999999998, 'yuv.min=', -15.60033)
('yuv.max=', 255.0, 'yuv.min=', -30.845439999999993)
('yuv.max=', 244.98899999999998, 'yuv.min=', -29.025509999999997)
('yuv.max=', 233.03999999999999, 'yuv.min=', -40.430229999999995)
('yuv.max=', 253.505, 'yuv.min=', -23.999939999999995)
('yuv.max=', 251.05999999999997, 'yuv.min=', -34.790649999999999)
('yuv.max=', 235.32999999999998, 'yuv.min=', -33.613659999999996)
('yuv.max=', 230.77399999999997, 'yuv.min=', -31.685769999999994)
('yuv.max=', 255.0, 'yuv.min=', -49.225309999999986)
('yuv.max=', 186.59100000000001, 'yuv.min=', -11.95515)
('yuv.max=', 255.0, 'yuv.min=', -32.975530000000006)
('yuv.max=', 255.0, 'yuv.min=', -8.7354099999999981)
('yuv.max=', 236.34799999999996, 'yuv.min=', -27.260019999999994)
('yuv.max=', 221.56800000000001, 'yuv.min=', -66.755709999999993)
('yuv.max=', 201.524, 'yuv.min=', -92.000589999999988)
('yuv.max=', 237.55799999999999, 'yuv.min=', -27.660060000000001)
('yuv.max=', 241.92899999999997, 'yuv.min=', -21.830789999999993)
('yuv.max=', 248.73199999999997, 'yuv.min=', -22.850439999999992)
('yuv.max=', 216.495, 'yuv.min=', -21.590879999999999)
('yuv.max=', 243.929, 'yuv.min=', -41.345259999999996)
('yuv.max=', 231.41299999999998, 'yuv.min=', -20.02028)
('yuv.max=', 251.49000000000001, 'yuv.min=', -51.895699999999991)
('yuv.max=', 235.786, 'yuv.min=', -43.930409999999995)
('yuv.max=', 249.142, 'yuv.min=', -5.7350199999999933)
('yuv.max=', 252.75, 'yuv.min=', -35.314209999999996)
('yuv.max=', 205.631, 'yuv.min=', -27.885389999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -50.980669999999989)
('yuv.max=', 207.06, 'yuv.min=', -17.675230000000003)
('yuv.max=', 247.54400000000001, 'yuv.min=', -13.00006999999999)
('yuv.max=', 213.96499999999997, 'yuv.min=', -27.885389999999983)
('yuv.max=', 252.25599999999997, 'yuv.min=', -54.705119999999994)
('yuv.max=', 247.64100000000002, 'yuv.min=', -22.654989999999998)
('yuv.max=', 232.017, 'yuv.min=', -30.915189999999996)
('yuv.max=', 206.852, 'yuv.min=', -5.9051599999999951)
('yuv.max=', 239.99499999999998, 'yuv.min=', -27.685369999999995)
('yuv.max=', 251.262, 'yuv.min=', -33.220370000000003)
('yuv.max=', 243.95999999999998, 'yuv.min=', -43.900700000000001)
('yuv.max=', 251.46699999999998, 'yuv.min=', -21.250279999999993)
('yuv.max=', 229.94999999999999, 'yuv.min=', -27.125559999999989)
('yuv.max=', 255.0, 'yuv.min=', -30.549979999999994)
('yuv.max=', 208.161, 'yuv.min=', -46.360699999999994)
('yuv.max=', 214.96099999999998, 'yuv.min=', -22.48027999999999)
('yuv.max=', 242.78699999999998, 'yuv.min=', -89.240559999999988)
('yuv.max=', 241.49599999999998, 'yuv.min=', -26.819729999999996)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 229.07499999999996, 'yuv.min=', -73.565529999999995)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.35899999999998, 'yuv.min=', -23.711399999999998)
('yuv.max=', 243.929, 'yuv.min=', -16.015309999999999)
('yuv.max=', 226.26099999999997, 'yuv.min=', -47.950489999999995)
('yuv.max=', 213.697, 'yuv.min=', -36.265489999999993)
('yuv.max=', 242.34200000000001, 'yuv.min=', -27.985399999999991)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.53399999999999, 'yuv.min=', -12.974440000000001)
('yuv.max=', 230.82599999999999, 'yuv.min=', -17.503300000000003)
('yuv.max=', 163.93299999999999, 'yuv.min=', -15.433319999999998)
('yuv.max=', 249.452, 'yuv.min=', -19.798190000000005)
('yuv.max=', 227.69300000000001, 'yuv.min=', -22.880319999999987)
('yuv.max=', 243.72899999999998, 'yuv.min=', -25.813940000000002)
('yuv.max=', 232.98199999999997, 'yuv.min=', -61.265529999999984)
('yuv.max=', 211.0, 'yuv.min=', -13.68319000000001)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.90099999999998, 'yuv.min=', -46.758250000000004)
('yuv.max=', 251.74000000000001, 'yuv.min=', -21.274340000000016)
('yuv.max=', 219.90599999999998, 'yuv.min=', -6.0051699999999926)
('yuv.max=', 214.20400000000001, 'yuv.min=', -74.14922)
('yuv.max=', 204.238, 'yuv.min=', -97.017910000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.04199999999997, 'yuv.min=', -25.510459999999998)
('yuv.max=', 232.691, 'yuv.min=', -17.513830000000013)
('yuv.max=', 254.77200000000002, 'yuv.min=', -34.720519999999993)
('yuv.max=', 236.94599999999997, 'yuv.min=', -18.001010000000001)
('yuv.max=', 214.36699999999999, 'yuv.min=', -44.205299999999994)
('yuv.max=', 213.34999999999999, 'yuv.min=', -46.68665)
('yuv.max=', 218.67799999999997, 'yuv.min=', -57.254730000000009)
('yuv.max=', 221.79999999999998, 'yuv.min=', -43.375339999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.19499999999999, 'yuv.min=', -81.090360000000004)
('yuv.max=', 185.71600000000001, 'yuv.min=', -15.445129999999992)
('yuv.max=', 239.36799999999997, 'yuv.min=', -40.260090000000005)
('yuv.max=', 205.83199999999999, 'yuv.min=', -85.158419999999992)
('yuv.max=', 230.804, 'yuv.min=', -30.130429999999993)
('yuv.max=', 191.19999999999999, 'yuv.min=', -11.955149999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 241.74800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 250.30399999999997, 'yuv.min=', -21.650319999999997)
('yuv.max=', 243.25599999999997, 'yuv.min=', -17.30506999999999)
('yuv.max=', 222.208, 'yuv.min=', -36.255119999999991)
('yuv.max=', 229.31399999999999, 'yuv.min=', -33.390509999999992)
('yuv.max=', 208.88, 'yuv.min=', -29.200459999999993)
('yuv.max=', 246.72300000000001, 'yuv.min=', -27.355460000000001)
('yuv.max=', 215.77199999999999, 'yuv.min=', -39.968760000000003)
('yuv.max=', 241.61500000000001, 'yuv.min=', -21.735389999999995)
('yuv.max=', 240.39099999999999, 'yuv.min=', -23.106750000000002)
('yuv.max=', 240.11599999999996, 'yuv.min=', -73.032489999999996)
('yuv.max=', 245.02000000000001, 'yuv.min=', -44.360499999999995)
('yuv.max=', 211.58699999999999, 'yuv.min=', -31.445499999999996)
('yuv.max=', 249.66300000000001, 'yuv.min=', -52.033700000000003)
('yuv.max=', 245.21499999999997, 'yuv.min=', -28.141140000000007)
('yuv.max=', 155.37199999999999, 'yuv.min=', -31.6007)
('yuv.max=', 225.86199999999999, 'yuv.min=', -35.777110000000008)
('yuv.max=', 254.11399999999998, 'yuv.min=', -9.7354199999999906)
('yuv.max=', 252.29899999999998, 'yuv.min=', -25.955319999999993)
('yuv.max=', 231.48799999999997, 'yuv.min=', -50.431820000000016)
('yuv.max=', 255.0, 'yuv.min=', -16.253850000000003)
('yuv.max=', 245.46600000000001, 'yuv.min=', -21.110019999999977)
('yuv.max=', 255.0, 'yuv.min=', -13.270219999999998)
('yuv.max=', 240.71199999999999, 'yuv.min=', -91.915520000000001)
('yuv.max=', 244.13800000000001, 'yuv.min=', -26.270289999999989)
('yuv.max=', 229.10900000000001, 'yuv.min=', -24.163150000000002)
('yuv.max=', 248.21100000000001, 'yuv.min=', -29.4453)
('yuv.max=', 224.11299999999997, 'yuv.min=', -42.96035999999998)
('yuv.max=', 249.31899999999999, 'yuv.min=', -34.410119999999992)
('yuv.max=', 198.71199999999999, 'yuv.min=', -86.134150000000005)
('yuv.max=', 255.0, 'yuv.min=', -27.285329999999995)
('yuv.max=', 228.58199999999999, 'yuv.min=', -35.425159999999984)
('yuv.max=', 249.07099999999997, 'yuv.min=', -7.5352000000000032)
('yuv.max=', 241.47300000000001, 'yuv.min=', -49.178520000000006)
('yuv.max=', 237.70099999999999, 'yuv.min=', -20.201050000000002)
('yuv.max=', 234.78300000000002, 'yuv.min=', -13.070199999999993)
('yuv.max=', 207.93799999999999, 'yuv.min=', -27.900329999999993)
('yuv.max=', 242.05399999999997, 'yuv.min=', -16.420120000000001)
('yuv.max=', 231.316, 'yuv.min=', -25.740359999999995)
('yuv.max=', 228.94499999999999, 'yuv.min=', -31.466140000000003)
('yuv.max=', 218.30600000000001, 'yuv.min=', -59.044569999999993)
('yuv.max=', 250.71200000000002, 'yuv.min=', -48.980469999999997)
('yuv.max=', 252.72899999999998, 'yuv.min=', -15.875049999999984)
('yuv.max=', 234.11799999999999, 'yuv.min=', -24.995469999999997)
('yuv.max=', 255.0, 'yuv.min=', -67.038419999999988)
('yuv.max=', 215.34, 'yuv.min=', -7.0202099999999916)
('yuv.max=', 216.19299999999998, 'yuv.min=', -22.635479999999987)
('yuv.max=', 229.25999999999999, 'yuv.min=', -43.975399999999993)
('yuv.max=', 231.10999999999999, 'yuv.min=', -75.135900000000007)
('yuv.max=', 241.73000000000002, 'yuv.min=', -61.21235999999999)
('yuv.max=', 177.54499999999999, 'yuv.min=', -49.910440000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.830649999999999)
('yuv.max=', 247.41200000000001, 'yuv.min=', -49.625349999999997)
('yuv.max=', 235.07999999999998, 'yuv.min=', -67.069460000000007)
('yuv.max=', 209.595, 'yuv.min=', -38.680669999999992)
('yuv.max=', 242.82900000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 190.07799999999997, 'yuv.min=', -37.680569999999982)
('yuv.max=', 251.29799999999997, 'yuv.min=', -55.292219999999993)
('yuv.max=', 190.98599999999999, 'yuv.min=', -17.128830000000001)
('yuv.max=', 254.77200000000002, 'yuv.min=', -32.075439999999993)
('yuv.max=', 238.114, 'yuv.min=', -20.921589999999998)
('yuv.max=', 252.79299999999998, 'yuv.min=', -45.160579999999996)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.1481000000000137)
('yuv.max=', 246.364, 'yuv.min=', -33.895129999999995)
('yuv.max=', 204.33199999999999, 'yuv.min=', -27.785380000000004)
('yuv.max=', 234.24200000000002, 'yuv.min=', -46.935449999999989)
('yuv.max=', 255.0, 'yuv.min=', -45.930779999999999)
('yuv.max=', 216.28700000000001, 'yuv.min=', -35.120559999999998)
('yuv.max=', 205.84299999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 210.77199999999999, 'yuv.min=', -16.887889999999999)
('yuv.max=', 225.91499999999999, 'yuv.min=', -6.7173900000000089)
('yuv.max=', 205.63799999999998, 'yuv.min=', -20.173439999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.065989999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -98.295419999999993)
('yuv.max=', 247.52499999999998, 'yuv.min=', -44.505330000000001)
('yuv.max=', 253.23899999999998, 'yuv.min=', -19.366670000000003)
('yuv.max=', 244.239, 'yuv.min=', -24.810389999999998)
('yuv.max=', 250.35500000000002, 'yuv.min=', -30.413669999999996)
('yuv.max=', 249.744, 'yuv.min=', -28.530269999999991)
('yuv.max=', 204.33499999999998, 'yuv.min=', -23.754700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.51361)
('yuv.max=', 232.78900000000002, 'yuv.min=', -8.3249099999999991)
('yuv.max=', 211.61899999999997, 'yuv.min=', -20.035219999999995)
('yuv.max=', 198.12399999999997, 'yuv.min=', -39.495689999999996)
('yuv.max=', 229.45199999999997, 'yuv.min=', -25.810489999999994)
('yuv.max=', 174.15200000000002, 'yuv.min=', -3.4302199999999949)
('yuv.max=', 247.16799999999998, 'yuv.min=', -42.330419999999989)
('yuv.max=', 255.0, 'yuv.min=', -36.233760000000004)
('yuv.max=', 237.62199999999999, 'yuv.min=', -37.670199999999994)
('yuv.max=', 154.90199999999999, 'yuv.min=', -35.850509999999986)
('yuv.max=', 250.19499999999999, 'yuv.min=', -18.545439999999992)
('yuv.max=', 235.25299999999999, 'yuv.min=', -68.145479999999992)
('yuv.max=', 228.35300000000001, 'yuv.min=', -19.319379999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.130259999999996)
('yuv.max=', 251.95699999999997, 'yuv.min=', -51.495659999999987)
('yuv.max=', 237.78899999999999, 'yuv.min=', -14.534009999999995)
('yuv.max=', 254.41299999999995, 'yuv.min=', -96.669579999999996)
('yuv.max=', 245.43699999999998, 'yuv.min=', -19.6053)
('yuv.max=', 222.07900000000001, 'yuv.min=', -29.470609999999994)
('yuv.max=', 251.011, 'yuv.min=', -23.780409999999989)
('yuv.max=', 240.92899999999997, 'yuv.min=', -55.364620000000002)
('yuv.max=', 179.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.55199999999999, 'yuv.min=', -25.610469999999982)
('yuv.max=', 235.93300000000002, 'yuv.min=', -17.520029999999998)
('yuv.max=', 246.99299999999997, 'yuv.min=', -18.47531)
('yuv.max=', 229.87499999999997, 'yuv.min=', -12.370129999999989)
('yuv.max=', 234.80099999999999, 'yuv.min=', -37.122739999999993)
('yuv.max=', 236.488, 'yuv.min=', -24.10446)
('yuv.max=', 228.69399999999999, 'yuv.min=', -47.030889999999999)
('yuv.max=', 238.56799999999998, 'yuv.min=', -13.070199999999993)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.015109999999996)
('yuv.max=', 240.98099999999999, 'yuv.min=', -22.250610000000002)
('yuv.max=', 249.33699999999999, 'yuv.min=', -67.659299999999988)
('yuv.max=', 216.786, 'yuv.min=', -52.400319999999994)
('yuv.max=', 226.26400000000001, 'yuv.min=', -16.543990000000004)
('yuv.max=', 243.77699999999999, 'yuv.min=', -23.495319999999992)
('yuv.max=', 162.036, 'yuv.min=', -22.565349999999995)
('yuv.max=', 229.49099999999999, 'yuv.min=', -36.240179999999995)
('yuv.max=', 229.113, 'yuv.min=', -26.455369999999995)
('yuv.max=', 243.39099999999999, 'yuv.min=', -57.960629999999988)
('yuv.max=', 237.60899999999998, 'yuv.min=', -47.495259999999995)
('yuv.max=', 253.16300000000001, 'yuv.min=', -17.50386)
('yuv.max=', 249.77199999999999, 'yuv.min=', -10.999870000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -42.78564999999999)
('yuv.max=', 246.69399999999996, 'yuv.min=', -66.34529999999998)
('yuv.max=', 241.869, 'yuv.min=', -10.05461)
('yuv.max=', 250.94000000000003, 'yuv.min=', -28.986360000000005)
('yuv.max=', 242.64699999999999, 'yuv.min=', -29.875219999999992)
('yuv.max=', 247.97, 'yuv.min=', -15.815289999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.94799999999998, 'yuv.min=', -26.455369999999998)
('yuv.max=', 241.84300000000002, 'yuv.min=', -31.067529999999998)
('yuv.max=', 208.00700000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 255.0, 'yuv.min=', -30.098469999999999)
('yuv.max=', 250.114, 'yuv.min=', -31.070769999999996)
('yuv.max=', 239.02699999999999, 'yuv.min=', -23.61027)
('yuv.max=', 255.0, 'yuv.min=', -73.577730000000003)
('yuv.max=', 255.0, 'yuv.min=', -12.221959999999999)
('yuv.max=', 128.02599999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 247.57999999999998, 'yuv.min=', -24.395409999999995)
('yuv.max=', 222.76499999999999, 'yuv.min=', -30.850870000000004)
('yuv.max=', 237.95499999999998, 'yuv.min=', -52.285369999999993)
('yuv.max=', 233.131, 'yuv.min=', -18.615229999999997)
('yuv.max=', 237.69299999999996, 'yuv.min=', -23.755099999999988)
('yuv.max=', 234.071, 'yuv.min=', -24.752209999999994)
('yuv.max=', 199.959, 'yuv.min=', -21.165209999999984)
('yuv.max=', 253.0, 'yuv.min=', -24.605090000000001)
('yuv.max=', 246.90699999999998, 'yuv.min=', -28.660159999999991)
('yuv.max=', 246.31, 'yuv.min=', -22.725119999999997)
('yuv.max=', 222.12799999999999, 'yuv.min=', -30.578519999999997)
('yuv.max=', 170.042, 'yuv.min=', -56.169580000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.740089999999995)
('yuv.max=', 255.0, 'yuv.min=', -16.590059999999998)
('yuv.max=', 249.316, 'yuv.min=', -50.250720000000001)
('yuv.max=', 226.18900000000002, 'yuv.min=', -39.374899999999997)
('yuv.max=', 186.27099999999999, 'yuv.min=', -32.645619999999994)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.365929999999995)
('yuv.max=', 254.886, 'yuv.min=', -23.17633)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.814450000000001)
('yuv.max=', 211.99099999999999, 'yuv.min=', -28.115289999999998)
('yuv.max=', 214.85399999999998, 'yuv.min=', -52.795789999999997)
('yuv.max=', 225.899, 'yuv.min=', -40.485419999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -6.8385600000000011)
('yuv.max=', 245.64699999999996, 'yuv.min=', -21.824849999999998)
('yuv.max=', 249.35899999999998, 'yuv.min=', -29.130329999999983)
('yuv.max=', 237.20000000000002, 'yuv.min=', -47.490400000000001)
('yuv.max=', 239.56900000000002, 'yuv.min=', -43.160379999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -41.478180000000002)
('yuv.max=', 209.035, 'yuv.min=', -33.850309999999993)
('yuv.max=', 232.0, 'yuv.min=', -36.698350000000005)
('yuv.max=', 239.98899999999998, 'yuv.min=', -39.970429999999986)
('yuv.max=', 244.76500000000001, 'yuv.min=', -35.690739999999991)
('yuv.max=', 238.42400000000001, 'yuv.min=', -36.52984)
('yuv.max=', 179.48499999999999, 'yuv.min=', -28.970559999999995)
('yuv.max=', 184.37100000000001, 'yuv.min=', -29.877760000000006)
('yuv.max=', 248.06399999999999, 'yuv.min=', -20.920369999999991)
('yuv.max=', 254.11399999999998, 'yuv.min=', -26.195510000000006)
('yuv.max=', 232.833, 'yuv.min=', -6.4235900000000044)
('yuv.max=', 251.91799999999998, 'yuv.min=', -60.075779999999995)
('yuv.max=', 242.999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 236.78899999999999, 'yuv.min=', -18.620140000000003)
('yuv.max=', 192.13800000000001, 'yuv.min=', -25.195489999999999)
('yuv.max=', 196.535, 'yuv.min=', -47.375739999999993)
('yuv.max=', 247.56799999999998, 'yuv.min=', -38.083129999999997)
('yuv.max=', 248.77199999999999, 'yuv.min=', -57.160550000000001)
('yuv.max=', 174.72699999999998, 'yuv.min=', -26.240410000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 193.10599999999999, 'yuv.min=', -24.525299999999998)
('yuv.max=', 207.78000000000003, 'yuv.min=', -27.625609999999998)
('yuv.max=', 255.0, 'yuv.min=', -19.224710000000005)
('yuv.max=', 252.03800000000001, 'yuv.min=', -59.060739999999996)
('yuv.max=', 162.35599999999999, 'yuv.min=', -36.938569999999999)
('yuv.max=', 205.08099999999999, 'yuv.min=', -42.230409999999992)
('yuv.max=', 227.34099999999998, 'yuv.min=', -18.810869999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.403250000000007)
('yuv.max=', 241.96899999999999, 'yuv.min=', -65.56595999999999)
('yuv.max=', 238.708, 'yuv.min=', -13.874269999999999)
('yuv.max=', 219.529, 'yuv.min=', -8.9502799999999887)
('yuv.max=', 217.16999999999999, 'yuv.min=', -21.605499999999989)
('yuv.max=', 241.63, 'yuv.min=', -27.585359999999998)
('yuv.max=', 200.88499999999999, 'yuv.min=', -19.350089999999998)
('yuv.max=', 245.124, 'yuv.min=', -117.26040999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -18.915329999999997)
('yuv.max=', 245.57499999999999, 'yuv.min=', -76.806100000000001)
('yuv.max=', 248.64700000000002, 'yuv.min=', -93.140950000000004)
('yuv.max=', 255.0, 'yuv.min=', -61.762990000000002)
('yuv.max=', 246.75700000000001, 'yuv.min=', -15.915299999999991)
('yuv.max=', 253.47299999999998, 'yuv.min=', -28.425689999999996)
('yuv.max=', 211.72399999999999, 'yuv.min=', -35.739530000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.225299999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.617400000000004)
('yuv.max=', 245.733, 'yuv.min=', -48.495359999999991)
('yuv.max=', 85.770999999999987, 'yuv.min=', -24.640249999999995)
('yuv.max=', 232.148, 'yuv.min=', -73.746790000000004)
('yuv.max=', 252.33699999999999, 'yuv.min=', -56.660499999999992)
('yuv.max=', 184.80799999999999, 'yuv.min=', -30.545409999999997)
('yuv.max=', 244.98899999999998, 'yuv.min=', -13.514610000000005)
('yuv.max=', 254.47300000000001, 'yuv.min=', -50.510499999999993)
('yuv.max=', 248.559, 'yuv.min=', -22.735489999999999)
('yuv.max=', 255.0, 'yuv.min=', -26.426010000000002)
('yuv.max=', 196.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 218.83999999999997, 'yuv.min=', -88.140180000000015)
('yuv.max=', 254.43000000000001, 'yuv.min=', -15.915299999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -4.6742299999999943)
('yuv.max=', 240.12499999999997, 'yuv.min=', -22.965170000000004)
('yuv.max=', 252.58699999999999, 'yuv.min=', -31.505259999999996)
('yuv.max=', 227.203, 'yuv.min=', -24.440230000000003)
('yuv.max=', 252.90699999999998, 'yuv.min=', -64.415229999999994)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -16.992329999999999)
('yuv.max=', 252.90699999999998, 'yuv.min=', -21.920469999999991)
('yuv.max=', 252.42999999999998, 'yuv.min=', -19.089550000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.152270000000001)
('yuv.max=', 244.125, 'yuv.min=', -63.702930000000002)
('yuv.max=', 224.501, 'yuv.min=', -26.185219999999994)
('yuv.max=', 248.91800000000001, 'yuv.min=', -42.705149999999989)
('yuv.max=', 242.626, 'yuv.min=', -33.635350000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.695439999999991)
('yuv.max=', 218.738, 'yuv.min=', -27.045059999999989)
('yuv.max=', 240.72299999999996, 'yuv.min=', -35.450950000000006)
('yuv.max=', 215.86399999999998, 'yuv.min=', -18.190219999999989)
('yuv.max=', 255.0, 'yuv.min=', -35.804220000000008)
('yuv.max=', 255.0, 'yuv.min=', -9.9503799999999956)
('yuv.max=', 248.52599999999998, 'yuv.min=', -45.805459999999982)
('yuv.max=', 183.03700000000001, 'yuv.min=', -31.760469999999987)
('yuv.max=', 241.92499999999998, 'yuv.min=', -77.31528999999999)
('yuv.max=', 200.10299999999998, 'yuv.min=', -25.170180000000002)
('yuv.max=', 215.81100000000001, 'yuv.min=', -71.294309999999996)
('yuv.max=', 254.70099999999999, 'yuv.min=', -15.600329999999994)
('yuv.max=', 247.976, 'yuv.min=', -68.590339999999983)
('yuv.max=', 255.0, 'yuv.min=', -10.461490000000012)
('yuv.max=', 249.267, 'yuv.min=', -35.684110000000011)
('yuv.max=', 219.53299999999999, 'yuv.min=', -59.180259999999997)
('yuv.max=', 245.13099999999997, 'yuv.min=', -7.6098999999999979)
('yuv.max=', 205.24099999999999, 'yuv.min=', -79.741560000000007)
('yuv.max=', 210.773, 'yuv.min=', -33.69511)
('yuv.max=', 255.0, 'yuv.min=', -45.420359999999988)
('yuv.max=', 243.07099999999997, 'yuv.min=', -80.07368000000001)
('yuv.max=', 221.96499999999997, 'yuv.min=', -14.592910000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 213.91799999999998, 'yuv.min=', -44.339750000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.479900000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -40.100319999999982)
('yuv.max=', 255.0, 'yuv.min=', -37.225339999999996)
('yuv.max=', 233.916, 'yuv.min=', -36.295369999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.6949699999999872)
('yuv.max=', 253.404, 'yuv.min=', -45.101480000000002)
('yuv.max=', 243.09899999999999, 'yuv.min=', -19.635120000000004)
('yuv.max=', 228.93499999999997, 'yuv.min=', -27.911809999999996)
('yuv.max=', 224.404, 'yuv.min=', -29.542439999999999)
('yuv.max=', 202.13300000000001, 'yuv.min=', -31.690339999999999)
('yuv.max=', 223.89299999999997, 'yuv.min=', -21.06063)
('yuv.max=', 224.89600000000002, 'yuv.min=', -67.960399999999993)
('yuv.max=', 248.94199999999998, 'yuv.min=', -29.160209999999999)
('yuv.max=', 220.59700000000001, 'yuv.min=', -23.390909999999998)
('yuv.max=', 237.08100000000002, 'yuv.min=', -34.705579999999998)
('yuv.max=', 202.114, 'yuv.min=', -12.795479999999984)
('yuv.max=', 125.0, 'yuv.min=', -2.6645352591003757e-15)
('yuv.max=', 255.0, 'yuv.min=', -38.865750000000006)
('yuv.max=', 250.81399999999999, 'yuv.min=', -96.790699999999987)
('yuv.max=', 211.75699999999998, 'yuv.min=', -69.990479999999991)
('yuv.max=', 206.97899999999998, 'yuv.min=', -19.805319999999995)
('yuv.max=', 229.78299999999999, 'yuv.min=', -24.110319999999994)
('yuv.max=', 249.17399999999998, 'yuv.min=', -41.047290000000004)
('yuv.max=', 246.45599999999999, 'yuv.min=', -9.0158400000000007)
('yuv.max=', 233.13899999999998, 'yuv.min=', -40.380839999999992)
('yuv.max=', 254.70099999999999, 'yuv.min=', -52.530209999999983)
('yuv.max=', 237.23599999999996, 'yuv.min=', -11.340150000000001)
('yuv.max=', 249.10300000000001, 'yuv.min=', -38.625479999999996)
('yuv.max=', 253.0, 'yuv.min=', -13.155269999999996)
('yuv.max=', 251.79299999999998, 'yuv.min=', -26.010509999999996)
('yuv.max=', 244.97800000000001, 'yuv.min=', -74.650700000000001)
('yuv.max=', 255.0, 'yuv.min=', -2.6749600000000022)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 206.60599999999999, 'yuv.min=', -30.200600000000001)
('yuv.max=', 249.995, 'yuv.min=', -59.790689999999991)
('yuv.max=', 238.95699999999997, 'yuv.min=', -10.555009999999992)
('yuv.max=', 220.91399999999999, 'yuv.min=', -70.852810000000005)
('yuv.max=', 230.80799999999999, 'yuv.min=', -20.501819999999999)
('yuv.max=', 249.02799999999999, 'yuv.min=', -61.795459999999991)
('yuv.max=', 237.62299999999999, 'yuv.min=', -35.065369999999987)
('yuv.max=', 253.20599999999999, 'yuv.min=', -23.565449999999981)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -54.190129999999996)
('yuv.max=', 251.066, 'yuv.min=', -109.19527999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.565349999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.285059999999991)
('yuv.max=', 252.33099999999999, 'yuv.min=', -15.564260000000001)
('yuv.max=', 198.37599999999998, 'yuv.min=', -24.835699999999996)
('yuv.max=', 255.0, 'yuv.min=', -41.300439999999981)
('yuv.max=', 201.084, 'yuv.min=', -22.13999999999999)
('yuv.max=', 187.34399999999999, 'yuv.min=', -11.410279999999993)
('yuv.max=', 108.444, 'yuv.min=', -23.280359999999995)
('yuv.max=', 236.39400000000001, 'yuv.min=', -43.635119999999986)
('yuv.max=', 230.28999999999999, 'yuv.min=', -47.730959999999996)
('yuv.max=', 251.98499999999999, 'yuv.min=', -41.14067)
('yuv.max=', 219.05100000000002, 'yuv.min=', -17.875249999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.411179999999998)
('yuv.max=', 210.595, 'yuv.min=', -20.505389999999988)
('yuv.max=', 217.417, 'yuv.min=', -23.95055)
('yuv.max=', 255.0, 'yuv.min=', -23.225169999999999)
('yuv.max=', 187.149, 'yuv.min=', -76.569299999999998)
('yuv.max=', 233.25900000000001, 'yuv.min=', -9.4749099999999942)
('yuv.max=', 220.22200000000001, 'yuv.min=', -27.242040000000003)
('yuv.max=', 244.32699999999997, 'yuv.min=', -6.9967399999999991)
('yuv.max=', 241.02099999999999, 'yuv.min=', -43.837469999999996)
('yuv.max=', 254.40199999999999, 'yuv.min=', -11.025179999999999)
('yuv.max=', 252.679, 'yuv.min=', -46.435399999999994)
('yuv.max=', 248.52899999999997, 'yuv.min=', -49.21036999999999)
('yuv.max=', 248.35900000000001, 'yuv.min=', -16.345219999999994)
('yuv.max=', 238.54399999999995, 'yuv.min=', -13.185149999999986)
('yuv.max=', 242.435, 'yuv.min=', -12.670190000000002)
('yuv.max=', 212.256, 'yuv.min=', -8.6636600000000001)
('yuv.max=', 255.0, 'yuv.min=', -41.945319999999981)
('yuv.max=', 255.0, 'yuv.min=', -61.626080000000009)
('yuv.max=', 252.761, 'yuv.min=', -79.169249999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.311610000000002)
('yuv.max=', 238.798, 'yuv.min=', -11.803229999999999)
('yuv.max=', 175.99999999999997, 'yuv.min=', -6.7650000000000006)
('yuv.max=', 254.40199999999999, 'yuv.min=', -22.180249999999997)
('yuv.max=', 167.94499999999999, 'yuv.min=', -14.371259999999998)
('yuv.max=', 198.61600000000001, 'yuv.min=', -43.305209999999988)
('yuv.max=', 254.65800000000002, 'yuv.min=', -68.945559999999986)
('yuv.max=', 213.66200000000001, 'yuv.min=', -24.998119999999997)
('yuv.max=', 255.0, 'yuv.min=', -32.223240000000004)
('yuv.max=', 255.0, 'yuv.min=', -47.495320000000007)
('yuv.max=', 255.0, 'yuv.min=', -34.510130000000004)
('yuv.max=', 253.333, 'yuv.min=', -26.800219999999996)
('yuv.max=', 202.339, 'yuv.min=', -22.910199999999993)
('yuv.max=', 243.98299999999998, 'yuv.min=', -33.880189999999999)
('yuv.max=', 238.47299999999998, 'yuv.min=', -37.580559999999991)
('yuv.max=', 229.0, 'yuv.min=', -2.974989999999984)
('yuv.max=', 250.87899999999996, 'yuv.min=', -19.640800000000006)
('yuv.max=', 242.61299999999997, 'yuv.min=', -20.696290000000005)
('yuv.max=', 237.68099999999998, 'yuv.min=', -23.825230000000001)
('yuv.max=', 233.65800000000002, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 228.71899999999999, 'yuv.min=', -60.520639999999986)
('yuv.max=', 252.065, 'yuv.min=', -15.08492)
('yuv.max=', 247.62499999999997, 'yuv.min=', -22.82744000000001)
('yuv.max=', 210.87099999999998, 'yuv.min=', -19.064999999999994)
('yuv.max=', 203.333, 'yuv.min=', -27.43015999999999)
('yuv.max=', 254.886, 'yuv.min=', -38.415000000000006)
('yuv.max=', 197.91800000000001, 'yuv.min=', -10.50003000000001)
('yuv.max=', 244.762, 'yuv.min=', -15.445129999999995)
('yuv.max=', 231.15299999999996, 'yuv.min=', -44.885859999999994)
('yuv.max=', 164.035, 'yuv.min=', -20.680990000000001)
('yuv.max=', 250.46199999999996, 'yuv.min=', -66.58556999999999)
('yuv.max=', 208.38999999999999, 'yuv.min=', -44.190359999999998)
('yuv.max=', 249.744, 'yuv.min=', -38.280629999999995)
('yuv.max=', 251.71100000000001, 'yuv.min=', -11.140129999999985)
('yuv.max=', 255.0, 'yuv.min=', -43.487760000000009)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 247.29900000000004, 'yuv.min=', -3.0555499999999967)
('yuv.max=', 220.941, 'yuv.min=', -31.962759999999996)
('yuv.max=', 246.85399999999998, 'yuv.min=', -40.870519999999985)
('yuv.max=', 255.0, 'yuv.min=', -8.765199999999993)
('yuv.max=', 245.63199999999998, 'yuv.min=', -37.505130000000008)
('yuv.max=', 234.03200000000001, 'yuv.min=', -19.190319999999993)
('yuv.max=', 240.97899999999998, 'yuv.min=', -31.005209999999988)
('yuv.max=', 255.0, 'yuv.min=', -13.500119999999992)
('yuv.max=', 252.93999999999997, 'yuv.min=', -34.180520000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -15.460069999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.40011)
('yuv.max=', 157.50399999999999, 'yuv.min=', -0.87020999999999127)
('yuv.max=', 179.76999999999998, 'yuv.min=', -5.9051600000000004)
('yuv.max=', 243.95699999999997, 'yuv.min=', -16.908060000000006)
('yuv.max=', 226.976, 'yuv.min=', -2.7853399999999873)
('yuv.max=', 242.58699999999999, 'yuv.min=', -39.380739999999989)
('yuv.max=', 253.72899999999996, 'yuv.min=', -36.540210000000002)
('yuv.max=', 235.363, 'yuv.min=', -42.375239999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.3650599999999855)
('yuv.max=', 219.99499999999998, 'yuv.min=', -48.312550000000002)
('yuv.max=', 250.81399999999999, 'yuv.min=', -29.545310000000001)
('yuv.max=', 213.309, 'yuv.min=', -16.215330000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 254.41299999999995, 'yuv.min=', -23.508759999999995)
('yuv.max=', 181.41, 'yuv.min=', -44.360499999999995)
('yuv.max=', 186.07499999999999, 'yuv.min=', -39.285299999999992)
('yuv.max=', 239.11899999999997, 'yuv.min=', -72.460849999999994)
('yuv.max=', 224.97199999999998, 'yuv.min=', -28.321109999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.855339999999998)
('yuv.max=', 157.73699999999997, 'yuv.min=', -17.075169999999986)
('yuv.max=', 214.81, 'yuv.min=', -44.655959999999993)
('yuv.max=', 203.03900000000002, 'yuv.min=', -48.925279999999994)
('yuv.max=', 237.40600000000001, 'yuv.min=', -24.751550000000009)
('yuv.max=', 164.63800000000001, 'yuv.min=', -47.460810000000002)
('yuv.max=', 248.185, 'yuv.min=', -26.717870000000001)
('yuv.max=', 251.13099999999997, 'yuv.min=', -10.650449999999998)
('yuv.max=', 246.59399999999999, 'yuv.min=', -18.211650000000002)
('yuv.max=', 255.0, 'yuv.min=', -76.956869999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -34.865349999999992)
('yuv.max=', 227.541, 'yuv.min=', -70.500900000000001)
('yuv.max=', 251.10299999999998, 'yuv.min=', -41.115359999999995)
('yuv.max=', 215.125, 'yuv.min=', -42.360299999999995)
('yuv.max=', 206.886, 'yuv.min=', -32.866430000000001)
('yuv.max=', 228.58499999999998, 'yuv.min=', -18.630509999999994)
('yuv.max=', 198.21899999999997, 'yuv.min=', -53.42116)
('yuv.max=', 128.78, 'yuv.min=', -56.085749999999997)
('yuv.max=', 242.25499999999997, 'yuv.min=', -33.060599999999987)
('yuv.max=', 172.886, 'yuv.min=', -24.280459999999998)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.645420000000001)
('yuv.max=', 241.357, 'yuv.min=', -17.045289999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.985499999999991)
('yuv.max=', 249.32699999999997, 'yuv.min=', -23.182099999999991)
('yuv.max=', 229.07199999999997, 'yuv.min=', -52.095719999999993)
('yuv.max=', 250.0, 'yuv.min=', -9.166170000000001)
('yuv.max=', 248.25999999999999, 'yuv.min=', -57.220309999999991)
('yuv.max=', 240.404, 'yuv.min=', -49.528590000000001)
('yuv.max=', 252.42999999999998, 'yuv.min=', -24.755199999999995)
('yuv.max=', 252.892, 'yuv.min=', -24.810389999999998)
('yuv.max=', 235.77799999999996, 'yuv.min=', -76.913550000000001)
('yuv.max=', 246.88200000000001, 'yuv.min=', -25.880910000000004)
('yuv.max=', 207.24999999999997, 'yuv.min=', -38.425460000000001)
('yuv.max=', 238.10799999999998, 'yuv.min=', -38.135799999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 201.37899999999999, 'yuv.min=', -68.357200000000006)
('yuv.max=', 253.71799999999999, 'yuv.min=', -39.625579999999985)
('yuv.max=', 241.869, 'yuv.min=', -43.01991000000001)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.636, 'yuv.min=', -69.299289999999999)
('yuv.max=', 250.78199999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 221.09199999999998, 'yuv.min=', -26.370299999999993)
('yuv.max=', 219.49000000000001, 'yuv.min=', -12.962710000000001)
('yuv.max=', 240.30299999999997, 'yuv.min=', -42.200529999999993)
('yuv.max=', 244.17999999999998, 'yuv.min=', -38.459909999999994)
('yuv.max=', 245.71599999999998, 'yuv.min=', -33.020349999999993)
('yuv.max=', 255.0, 'yuv.min=', -41.355629999999998)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.73999999999998, 'yuv.min=', -63.00515)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.071029999999997)
('yuv.max=', 244.30700000000002, 'yuv.min=', -24.655189999999994)
('yuv.max=', 220.43499999999997, 'yuv.min=', -95.514039999999994)
('yuv.max=', 192.34700000000001, 'yuv.min=', -46.490589999999997)
('yuv.max=', 252.03199999999998, 'yuv.min=', -24.081859999999999)
('yuv.max=', 210.83399999999997, 'yuv.min=', -72.965469999999996)
('yuv.max=', 174.45399999999998, 'yuv.min=', -33.766310000000004)
('yuv.max=', 255.0, 'yuv.min=', -65.686679999999996)
('yuv.max=', 232.69, 'yuv.min=', -36.403080000000003)
('yuv.max=', 255.0, 'yuv.min=', -20.920369999999995)
('yuv.max=', 247.47299999999998, 'yuv.min=', -34.59062999999999)
('yuv.max=', 206.459, 'yuv.min=', -29.560249999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.07507)
('yuv.max=', 209.27799999999999, 'yuv.min=', -74.362259999999992)
('yuv.max=', 251.89699999999999, 'yuv.min=', -65.555589999999995)
('yuv.max=', 248.57999999999998, 'yuv.min=', -35.073459999999997)
('yuv.max=', 238.62999999999997, 'yuv.min=', -45.516820000000003)
('yuv.max=', 248.76499999999999, 'yuv.min=', -52.600339999999989)
('yuv.max=', 242.58899999999997, 'yuv.min=', -12.805450000000008)
('yuv.max=', 229.24700000000001, 'yuv.min=', -24.267709999999997)
('yuv.max=', 252.886, 'yuv.min=', -21.858270000000008)
('yuv.max=', 254.886, 'yuv.min=', -40.813850000000002)
('yuv.max=', 227.36499999999998, 'yuv.min=', -68.590339999999998)
('yuv.max=', 245.69399999999999, 'yuv.min=', -19.550109999999997)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.780309999999993)
('yuv.max=', 254.886, 'yuv.min=', -14.713340000000002)
('yuv.max=', 240.53299999999999, 'yuv.min=', -36.725290000000001)
('yuv.max=', 253.80399999999997, 'yuv.min=', -78.995130000000003)
('yuv.max=', 236.67699999999999, 'yuv.min=', -32.460539999999988)
('yuv.max=', 253.81499999999997, 'yuv.min=', -39.014770000000006)
('yuv.max=', 232.071, 'yuv.min=', -2.473550000000003)
('yuv.max=', 218.14099999999999, 'yuv.min=', -38.092199999999991)
('yuv.max=', 229.63, 'yuv.min=', -32.060499999999998)
('yuv.max=', 140.624, 'yuv.min=', -25.65528999999999)
('yuv.max=', 208.17499999999998, 'yuv.min=', -18.850039999999993)
('yuv.max=', 250.017, 'yuv.min=', -9.8746100000000006)
('yuv.max=', 243.42499999999995, 'yuv.min=', -17.219390000000004)
('yuv.max=', 195.28199999999998, 'yuv.min=', -48.440169999999995)
('yuv.max=', 249.733, 'yuv.min=', -22.420519999999982)
('yuv.max=', 235.69399999999999, 'yuv.min=', -48.350529999999992)
('yuv.max=', 234.78099999999998, 'yuv.min=', -15.834680000000013)
('yuv.max=', 253.76100000000002, 'yuv.min=', -34.850409999999997)
('yuv.max=', 217.821, 'yuv.min=', -23.345400000000005)
('yuv.max=', 246.809, 'yuv.min=', -26.125459999999986)
('yuv.max=', 237.89699999999999, 'yuv.min=', -40.730259999999994)
('yuv.max=', 255.0, 'yuv.min=', -19.737919999999999)
('yuv.max=', 252.24699999999996, 'yuv.min=', -57.530709999999985)
('yuv.max=', 255.0, 'yuv.min=', -35.813090000000003)
('yuv.max=', 237.245, 'yuv.min=', -34.56532)
('yuv.max=', 253.505, 'yuv.min=', -55.555320000000009)
('yuv.max=', 195.46599999999998, 'yuv.min=', -17.595169999999996)
('yuv.max=', 254.54400000000001, 'yuv.min=', -79.518849999999986)
('yuv.max=', 255.0, 'yuv.min=', -95.05641)
('yuv.max=', 250.62299999999999, 'yuv.min=', -58.732000000000006)
('yuv.max=', 244.47300000000001, 'yuv.min=', -33.300870000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -25.570219999999996)
('yuv.max=', 246.38700000000003, 'yuv.min=', -33.41105000000001)
('yuv.max=', 235.82599999999999, 'yuv.min=', -18.800549999999994)
('yuv.max=', 193.41, 'yuv.min=', -20.175479999999993)
('yuv.max=', 251.08099999999999, 'yuv.min=', -42.600569999999991)
('yuv.max=', 254.54400000000001, 'yuv.min=', -50.08292999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.504599999999989)
('yuv.max=', 237.06899999999999, 'yuv.min=', -25.815059999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -25.225369999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -11.187920000000002)
('yuv.max=', 239.559, 'yuv.min=', -11.340150000000007)
('yuv.max=', 255.0, 'yuv.min=', -2.6600199999999976)
('yuv.max=', 221.291, 'yuv.min=', -18.920169999999999)
('yuv.max=', 250.43499999999997, 'yuv.min=', -30.551030000000001)
('yuv.max=', 245.29999999999998, 'yuv.min=', -28.975129999999993)
('yuv.max=', 193.99499999999998, 'yuv.min=', -22.555520000000001)
('yuv.max=', 228.67899999999997, 'yuv.min=', -37.65068999999999)
('yuv.max=', 241.09899999999999, 'yuv.min=', -36.6175)
('yuv.max=', 203.96399999999997, 'yuv.min=', -47.603279999999998)
('yuv.max=', 253.12499999999997, 'yuv.min=', -28.845239999999997)
('yuv.max=', 248.97900000000001, 'yuv.min=', -11.197389999999999)
('yuv.max=', 230.316, 'yuv.min=', -15.630209999999998)
('yuv.max=', 229.524, 'yuv.min=', -15.830229999999993)
('yuv.max=', 239.88099999999997, 'yuv.min=', -24.932200000000002)
('yuv.max=', 239.20599999999996, 'yuv.min=', -16.260149999999985)
('yuv.max=', 238.17399999999998, 'yuv.min=', -49.795490000000001)
('yuv.max=', 226.65799999999999, 'yuv.min=', -22.265319999999992)
('yuv.max=', 253.64700000000002, 'yuv.min=', -32.324849999999998)
('yuv.max=', 227.30199999999999, 'yuv.min=', -42.245349999999995)
('yuv.max=', 198.26300000000001, 'yuv.min=', -45.115759999999995)
('yuv.max=', 229.505, 'yuv.min=', -38.562640000000002)
('yuv.max=', 195.83499999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 255.0, 'yuv.min=', -68.252790000000005)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.590329999999994)
('yuv.max=', 237.43899999999999, 'yuv.min=', -24.380469999999992)
('yuv.max=', 255.0, 'yuv.min=', -56.264140000000005)
('yuv.max=', 225.32300000000001, 'yuv.min=', -22.875749999999996)
('yuv.max=', 170.57999999999998, 'yuv.min=', -32.575489999999995)
('yuv.max=', 247.08999999999997, 'yuv.min=', -13.813460000000006)
('yuv.max=', 187.07300000000001, 'yuv.min=', -21.41004999999998)
('yuv.max=', 242.22399999999999, 'yuv.min=', -18.520130000000002)
('yuv.max=', 239.62200000000001, 'yuv.min=', -20.62227)
('yuv.max=', 250.01000000000002, 'yuv.min=', -7.3949399999999983)
('yuv.max=', 206.06999999999999, 'yuv.min=', -35.244649999999993)
('yuv.max=', 244.15699999999998, 'yuv.min=', -59.990709999999986)
('yuv.max=', 229.21000000000001, 'yuv.min=', -26.240409999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -22.092999999999996)
('yuv.max=', 234.928, 'yuv.min=', -28.070050000000005)
('yuv.max=', 249.11600000000001, 'yuv.min=', -20.875549999999993)
('yuv.max=', 162.24900000000002, 'yuv.min=', -12.485079999999986)
('yuv.max=', 255.0, 'yuv.min=', -6.2350699999999994)
('yuv.max=', 252.608, 'yuv.min=', -28.800419999999988)
('yuv.max=', 246.0, 'yuv.min=', -29.560249999999996)
('yuv.max=', 241.65100000000001, 'yuv.min=', -36.856290000000001)
('yuv.max=', 244.40499999999997, 'yuv.min=', -27.384129999999999)
('yuv.max=', 179.917, 'yuv.min=', -12.963499999999996)
('yuv.max=', 235.92899999999997, 'yuv.min=', -47.942480000000003)
('yuv.max=', 195.11399999999998, 'yuv.min=', -29.254120000000004)
('yuv.max=', 211.85500000000002, 'yuv.min=', -61.465550000000007)
('yuv.max=', 226.96699999999998, 'yuv.min=', -21.580189999999995)
('yuv.max=', 235.18800000000002, 'yuv.min=', -49.231330000000014)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.756, 'yuv.min=', -72.509069999999994)
('yuv.max=', 255.0, 'yuv.min=', -16.815389999999997)
('yuv.max=', 248.73199999999997, 'yuv.min=', -100.62553)
('yuv.max=', 225.40000000000001, 'yuv.min=', -19.390339999999981)
('yuv.max=', 244.43899999999999, 'yuv.min=', -32.045559999999988)
('yuv.max=', 252.00999999999999, 'yuv.min=', -40.257210000000008)
('yuv.max=', 248.10899999999998, 'yuv.min=', -35.940149999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.57086000000001)
('yuv.max=', 221.423, 'yuv.min=', -16.828860000000002)
('yuv.max=', 247.35499999999999, 'yuv.min=', -76.540520000000001)
('yuv.max=', 255.0, 'yuv.min=', -50.79558999999999)
('yuv.max=', 226.29599999999999, 'yuv.min=', -27.956729999999997)
('yuv.max=', 201.99999999999997, 'yuv.min=', -27.470409999999994)
('yuv.max=', 247.86499999999998, 'yuv.min=', -95.415869999999998)
('yuv.max=', 221.13399999999999, 'yuv.min=', -80.666240000000002)
('yuv.max=', 255.0, 'yuv.min=', -34.861909999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -12.11434)
('yuv.max=', 253.0, 'yuv.min=', -31.989319999999999)
('yuv.max=', 243.74599999999998, 'yuv.min=', -13.830799999999996)
('yuv.max=', 162.774, 'yuv.min=', -36.910369999999993)
('yuv.max=', 194.113, 'yuv.min=', -20.120289999999983)
('yuv.max=', 223.71699999999998, 'yuv.min=', -22.724240000000002)
('yuv.max=', 231.51900000000001, 'yuv.min=', -24.900029999999987)
('yuv.max=', 255.0, 'yuv.min=', -5.4372200000000035)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -5.8200899999999933)
('yuv.max=', 250.08099999999996, 'yuv.min=', -34.277480000000011)
('yuv.max=', 255.0, 'yuv.min=', -46.27563)
('yuv.max=', 255.0, 'yuv.min=', -36.099009999999993)
('yuv.max=', 244.29899999999998, 'yuv.min=', -11.95046)
('yuv.max=', 237.07199999999997, 'yuv.min=', -52.660519999999998)
('yuv.max=', 247.38, 'yuv.min=', -33.727649999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.761360000000003)
('yuv.max=', 224.62800000000001, 'yuv.min=', -7.1813399999999987)
('yuv.max=', 211.958, 'yuv.min=', -37.690939999999991)
('yuv.max=', 255.0, 'yuv.min=', -31.745529999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.150369999999995)
('yuv.max=', 210.64699999999999, 'yuv.min=', -9.4100799999999936)
('yuv.max=', 242.57599999999996, 'yuv.min=', -22.865379999999988)
('yuv.max=', 230.53800000000001, 'yuv.min=', -39.150840000000002)
('yuv.max=', 253.78899999999999, 'yuv.min=', -27.602539999999998)
('yuv.max=', 253.071, 'yuv.min=', -17.88036)
('yuv.max=', 239.31599999999997, 'yuv.min=', -48.695379999999993)
('yuv.max=', 228.80500000000001, 'yuv.min=', -55.167779999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.8189400000000049)
('yuv.max=', 251.989, 'yuv.min=', -38.61054)
('yuv.max=', 255.0, 'yuv.min=', -78.503790000000009)
('yuv.max=', 255.0, 'yuv.min=', -28.958759999999998)
('yuv.max=', 239.42999999999998, 'yuv.min=', -18.790090000000003)
('yuv.max=', 234.13499999999999, 'yuv.min=', -27.725619999999999)
('yuv.max=', 248.309, 'yuv.min=', -48.025189999999995)
('yuv.max=', 240.505, 'yuv.min=', -30.000539999999987)
('yuv.max=', 156.01600000000002, 'yuv.min=', -23.295299999999987)
('yuv.max=', 255.0, 'yuv.min=', -34.88942999999999)
('yuv.max=', 238.49199999999999, 'yuv.min=', -27.674999999999986)
('yuv.max=', 200.453, 'yuv.min=', -10.92516999999998)
('yuv.max=', 237.99100000000001, 'yuv.min=', -18.405179999999998)
('yuv.max=', 255.0, 'yuv.min=', -18.631800000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -9.9250699999999998)
('yuv.max=', 247.559, 'yuv.min=', -19.699509999999997)
('yuv.max=', 177.83399999999997, 'yuv.min=', -74.852370000000008)
('yuv.max=', 229.86899999999997, 'yuv.min=', -53.525739999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.360629999999986)
('yuv.max=', 217.90099999999998, 'yuv.min=', -17.860309999999991)
('yuv.max=', 233.56999999999999, 'yuv.min=', -15.730219999999994)
('yuv.max=', 234.38300000000001, 'yuv.min=', -21.652050000000003)
('yuv.max=', 215.13099999999997, 'yuv.min=', -44.185559999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 207.42199999999997, 'yuv.min=', -48.266610000000007)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.985199999999995)
('yuv.max=', 140.06799999999998, 'yuv.min=', -14.830129999999999)
('yuv.max=', 249.17399999999998, 'yuv.min=', -34.562550000000002)
('yuv.max=', 248.48799999999997, 'yuv.min=', -38.940449999999998)
('yuv.max=', 236.68599999999998, 'yuv.min=', -13.830669999999998)
('yuv.max=', 242.52200000000002, 'yuv.min=', -26.151740000000004)
('yuv.max=', 224.476, 'yuv.min=', -24.850459999999998)
('yuv.max=', 165.22499999999999, 'yuv.min=', -45.685939999999995)
('yuv.max=', 244.50799999999998, 'yuv.min=', -16.908730000000006)
('yuv.max=', 251.626, 'yuv.min=', -14.870779999999996)
('yuv.max=', 243.17399999999998, 'yuv.min=', -10.280289999999983)
('yuv.max=', 204.40299999999999, 'yuv.min=', -25.197850000000006)
('yuv.max=', 202.06900000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 247.37, 'yuv.min=', -35.282219999999995)
('yuv.max=', 236.73999999999998, 'yuv.min=', -36.654979999999995)
('yuv.max=', 233.71099999999998, 'yuv.min=', -43.975399999999993)
('yuv.max=', 248.22800000000001, 'yuv.min=', -29.180949999999996)
('yuv.max=', 213.67099999999999, 'yuv.min=', -6.8201899999999895)
('yuv.max=', 244.95699999999999, 'yuv.min=', -33.520399999999995)
('yuv.max=', 253.60399999999998, 'yuv.min=', -54.49595999999999)
('yuv.max=', 228.91199999999998, 'yuv.min=', -13.19248)
('yuv.max=', 115.28099999999999, 'yuv.min=', -39.415189999999996)
('yuv.max=', 205.60999999999999, 'yuv.min=', -60.214730000000003)
('yuv.max=', 224.202, 'yuv.min=', -49.380510000000001)
('yuv.max=', 250.20199999999997, 'yuv.min=', -38.588660000000004)
('yuv.max=', 253.63200000000001, 'yuv.min=', -13.138069999999999)
('yuv.max=', 206.85799999999998, 'yuv.min=', -69.785889999999995)
('yuv.max=', 168.94099999999997, 'yuv.min=', -17.775239999999997)
('yuv.max=', 240.65799999999999, 'yuv.min=', -28.54520999999999)
('yuv.max=', 224.584, 'yuv.min=', -19.835199999999997)
('yuv.max=', 241.52000000000001, 'yuv.min=', -50.700149999999979)
('yuv.max=', 168.11999999999998, 'yuv.min=', -25.655289999999997)
('yuv.max=', 188.267, 'yuv.min=', -39.755469999999988)
('yuv.max=', 238.47299999999998, 'yuv.min=', -39.608540000000005)
('yuv.max=', 255.0, 'yuv.min=', -24.929909999999982)
('yuv.max=', 195.34799999999998, 'yuv.min=', -36.654849999999996)
('yuv.max=', 218.31999999999999, 'yuv.min=', -31.130529999999993)
('yuv.max=', 238.41299999999998, 'yuv.min=', -97.565469999999991)
('yuv.max=', 238.28999999999999, 'yuv.min=', -26.485569999999999)
('yuv.max=', 209.74099999999999, 'yuv.min=', -55.266159999999999)
('yuv.max=', 180.42499999999998, 'yuv.min=', -25.780609999999999)
('yuv.max=', 221.32499999999999, 'yuv.min=', -41.215369999999993)
('yuv.max=', 189.82499999999999, 'yuv.min=', -69.285839999999993)
('yuv.max=', 242.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.67500000000001, 'yuv.min=', -26.855409999999988)
('yuv.max=', 219.16, 'yuv.min=', -18.942410000000002)
('yuv.max=', 209.977, 'yuv.min=', -31.580290000000012)
('yuv.max=', 242.06099999999998, 'yuv.min=', -25.787010000000002)
('yuv.max=', 253.63200000000001, 'yuv.min=', -85.540189999999981)
('yuv.max=', 244.624, 'yuv.min=', -21.485979999999998)
('yuv.max=', 203.83500000000001, 'yuv.min=', -5.19015)
('yuv.max=', 211.02100000000002, 'yuv.min=', -16.315339999999999)
('yuv.max=', 228.95299999999997, 'yuv.min=', -34.735459999999989)
('yuv.max=', 250.38200000000001, 'yuv.min=', -27.040489999999998)
('yuv.max=', 219.65299999999999, 'yuv.min=', -26.325479999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.6801300000000001)
('yuv.max=', 233.54199999999997, 'yuv.min=', -62.884430000000009)
('yuv.max=', 247.875, 'yuv.min=', -25.815059999999999)
('yuv.max=', 223.44599999999997, 'yuv.min=', -24.010309999999997)
('yuv.max=', 251.16900000000001, 'yuv.min=', -26.745029999999986)
('yuv.max=', 255.0, 'yuv.min=', -19.170809999999989)
('yuv.max=', 212.10500000000002, 'yuv.min=', -27.88663)
('yuv.max=', 255.0, 'yuv.min=', -38.497750000000011)
('yuv.max=', 158.15000000000001, 'yuv.min=', -35.014670000000002)
('yuv.max=', 255.0, 'yuv.min=', -30.060960000000001)
('yuv.max=', 248.74299999999999, 'yuv.min=', -36.920739999999995)
('yuv.max=', 235.477, 'yuv.min=', -25.165610000000001)
('yuv.max=', 250.81100000000001, 'yuv.min=', -10.200159999999997)
('yuv.max=', 214.78899999999999, 'yuv.min=', -38.574859999999994)
('yuv.max=', 200.48299999999998, 'yuv.min=', -38.940449999999984)
('yuv.max=', 255.0, 'yuv.min=', -16.090009999999999)
('yuv.max=', 249.91699999999997, 'yuv.min=', -31.20523)
('yuv.max=', 244.81500000000003, 'yuv.min=', -36.880489999999995)
('yuv.max=', 246.03399999999999, 'yuv.min=', -26.300169999999994)
('yuv.max=', 252.60599999999999, 'yuv.min=', -31.580769999999994)
('yuv.max=', 187.595, 'yuv.min=', -52.83480999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -40.27046)
('yuv.max=', 232.24499999999998, 'yuv.min=', -22.37143)
('yuv.max=', 213.24799999999999, 'yuv.min=', -51.495659999999987)
('yuv.max=', 185.39299999999997, 'yuv.min=', -32.805389999999989)
('yuv.max=', 162.25800000000001, 'yuv.min=', -43.630549999999999)
('yuv.max=', 249.13199999999998, 'yuv.min=', -76.334669999999988)
('yuv.max=', 249.82599999999999, 'yuv.min=', -30.52965)
('yuv.max=', 225.852, 'yuv.min=', -35.025660000000002)
('yuv.max=', 254.316, 'yuv.min=', -20.774210000000004)
('yuv.max=', 254.41299999999995, 'yuv.min=', -22.895260000000004)
('yuv.max=', 237.45600000000002, 'yuv.min=', -16.609949999999998)
('yuv.max=', 207.32599999999999, 'yuv.min=', -40.29576999999999)
('yuv.max=', 198.34700000000001, 'yuv.min=', -61.310349999999993)
('yuv.max=', 231.14999999999998, 'yuv.min=', -49.75067)
('yuv.max=', 255.0, 'yuv.min=', -34.920539999999995)
('yuv.max=', 248.66900000000001, 'yuv.min=', -40.61074)
('yuv.max=', 248.815, 'yuv.min=', -24.61037)
('yuv.max=', 249.125, 'yuv.min=', -20.680109999999999)
('yuv.max=', 210.04500000000002, 'yuv.min=', -21.69438000000001)
('yuv.max=', 191.98299999999998, 'yuv.min=', -10.680329999999996)
('yuv.max=', 212.72399999999999, 'yuv.min=', -40.530320000000003)
('yuv.max=', 231.44499999999999, 'yuv.min=', -28.700409999999998)
('yuv.max=', 212.29999999999998, 'yuv.min=', -50.800159999999991)
('yuv.max=', 248.89699999999999, 'yuv.min=', -27.309130000000003)
('yuv.max=', 250.02800000000002, 'yuv.min=', -51.465779999999995)
('yuv.max=', 243.54399999999998, 'yuv.min=', -29.875219999999992)
('yuv.max=', 246.886, 'yuv.min=', -24.740259999999992)
('yuv.max=', 242.83999999999997, 'yuv.min=', -45.670999999999999)
('yuv.max=', 247.28100000000001, 'yuv.min=', -20.899590000000003)
('yuv.max=', 241.94999999999999, 'yuv.min=', -16.409350000000003)
('yuv.max=', 236.11099999999999, 'yuv.min=', -17.420019999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.56999999999999, 'yuv.min=', -93.345539999999986)
('yuv.max=', 254.06, 'yuv.min=', -43.43052999999999)
('yuv.max=', 201.756, 'yuv.min=', -14.691369999999999)
('yuv.max=', 227.08799999999999, 'yuv.min=', -19.035519999999998)
('yuv.max=', 255.0, 'yuv.min=', -22.025049999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 226.303, 'yuv.min=', -78.360209999999995)
('yuv.max=', 247.142, 'yuv.min=', -25.595529999999997)
('yuv.max=', 206.09999999999999, 'yuv.min=', -33.630779999999994)
('yuv.max=', 182.89400000000001, 'yuv.min=', -15.615269999999995)
('yuv.max=', 251.45599999999996, 'yuv.min=', -18.360359999999996)
('yuv.max=', 253.01699999999997, 'yuv.min=', -11.465959999999999)
('yuv.max=', 144.58599999999998, 'yuv.min=', -26.48524999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.194890000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.505570000000002)
('yuv.max=', 235.25299999999999, 'yuv.min=', -40.67049999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', -48.290710000000004)
('yuv.max=', 255.0, 'yuv.min=', -36.120659999999987)
('yuv.max=', 254.29899999999995, 'yuv.min=', -34.96535999999999)
('yuv.max=', 253.333, 'yuv.min=', -34.501159999999999)
('yuv.max=', 253.17399999999998, 'yuv.min=', -31.794919999999983)
('yuv.max=', 193.07999999999998, 'yuv.min=', -6.1571099999999959)
('yuv.max=', 238.923, 'yuv.min=', -28.343790000000006)
('yuv.max=', 234.108, 'yuv.min=', -22.196990000000003)
('yuv.max=', 250.69999999999999, 'yuv.min=', -46.180189999999982)
('yuv.max=', 238.65899999999999, 'yuv.min=', -19.305269999999986)
('yuv.max=', 253.99999999999997, 'yuv.min=', -62.255259999999993)
('yuv.max=', 215.88599999999997, 'yuv.min=', -9.3135700000000021)
('yuv.max=', 245.54199999999997, 'yuv.min=', -44.230609999999999)
('yuv.max=', 215.73899999999998, 'yuv.min=', -81.530649999999994)
('yuv.max=', 250.90899999999999, 'yuv.min=', -89.503680000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.605469999999997)
('yuv.max=', 202.554, 'yuv.min=', -31.800719999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.685099999999991)
('yuv.max=', 209.60499999999999, 'yuv.min=', -50.495559999999983)
('yuv.max=', 194.55700000000002, 'yuv.min=', -36.995439999999988)
('yuv.max=', 216.37699999999998, 'yuv.min=', -81.741720000000001)
('yuv.max=', 228.75299999999999, 'yuv.min=', -46.105489999999989)
('yuv.max=', 255.0, 'yuv.min=', -3.1922800000000038)
('yuv.max=', 244.053, 'yuv.min=', -17.960319999999985)
('yuv.max=', 254.316, 'yuv.min=', -20.850239999999985)
('yuv.max=', 255.0, 'yuv.min=', -20.206259999999997)
('yuv.max=', 252.31, 'yuv.min=', -36.705150000000003)
('yuv.max=', 239.864, 'yuv.min=', -16.609749999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -13.966860000000004)
('yuv.max=', 235.608, 'yuv.min=', -18.511550000000007)
('yuv.max=', 246.46599999999998, 'yuv.min=', -18.075269999999996)
('yuv.max=', 207.61000000000001, 'yuv.min=', -20.175479999999997)
('yuv.max=', 194.35899999999998, 'yuv.min=', -30.965180000000004)
('yuv.max=', 245.989, 'yuv.min=', -20.984699999999997)
('yuv.max=', 231.024, 'yuv.min=', -46.39058)
('yuv.max=', 255.0, 'yuv.min=', -20.635279999999998)
('yuv.max=', 239.41499999999996, 'yuv.min=', -12.959819999999993)
('yuv.max=', 251.327, 'yuv.min=', -21.96529)
('yuv.max=', 230.76600000000002, 'yuv.min=', -54.170570000000005)
('yuv.max=', 255.0, 'yuv.min=', -40.790659999999995)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 186.69799999999998, 'yuv.min=', -26.645019999999992)
('yuv.max=', 248.142, 'yuv.min=', -29.194520000000001)
('yuv.max=', 240.30499999999998, 'yuv.min=', -44.334310000000002)
('yuv.max=', 251.90299999999999, 'yuv.min=', -21.536810000000003)
('yuv.max=', 251.07299999999998, 'yuv.min=', -29.285359999999997)
('yuv.max=', 219.886, 'yuv.min=', -17.260249999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -35.074359999999999)
('yuv.max=', 235.94999999999999, 'yuv.min=', -19.395350000000001)
('yuv.max=', 218.91499999999999, 'yuv.min=', -21.411540000000006)
('yuv.max=', 206.64999999999998, 'yuv.min=', -29.560249999999996)
('yuv.max=', 211.91699999999997, 'yuv.min=', -27.515229999999988)
('yuv.max=', 254.47300000000001, 'yuv.min=', -25.870260000000002)
('yuv.max=', 251.54399999999998, 'yuv.min=', -87.385189999999994)
('yuv.max=', 255.0, 'yuv.min=', -33.69344000000001)
('yuv.max=', 252.04899999999998, 'yuv.min=', -29.507860000000004)
('yuv.max=', 206.18700000000001, 'yuv.min=', -24.158469999999998)
('yuv.max=', 232.80500000000001, 'yuv.min=', -29.500489999999992)
('yuv.max=', 247.762, 'yuv.min=', -32.872480000000003)
('yuv.max=', 184.655, 'yuv.min=', -8.3200300000000027)
('yuv.max=', 222.41799999999995, 'yuv.min=', -16.592839999999995)
('yuv.max=', 255.0, 'yuv.min=', -19.030670000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999992)
('yuv.max=', 214.62400000000002, 'yuv.min=', -22.59066)
('yuv.max=', 255.0, 'yuv.min=', -48.665499999999994)
('yuv.max=', 255.0, 'yuv.min=', -22.218730000000004)
('yuv.max=', 245.08599999999998, 'yuv.min=', -56.115629999999996)
('yuv.max=', 255.0, 'yuv.min=', -25.324150000000003)
('yuv.max=', 255.0, 'yuv.min=', -49.777620000000006)
('yuv.max=', 237.27099999999999, 'yuv.min=', -19.275390000000002)
('yuv.max=', 189.81200000000001, 'yuv.min=', -30.875319999999995)
('yuv.max=', 205.58099999999999, 'yuv.min=', -15.039760000000001)
('yuv.max=', 197.72900000000001, 'yuv.min=', -50.555319999999995)
('yuv.max=', 251.92899999999995, 'yuv.min=', -30.224639999999997)
('yuv.max=', 199.36799999999999, 'yuv.min=', -19.860509999999987)
('yuv.max=', 227.14599999999999, 'yuv.min=', -24.76557)
('yuv.max=', 192.24099999999999, 'yuv.min=', -52.480819999999994)
('yuv.max=', 252.61500000000001, 'yuv.min=', -77.648920000000004)
('yuv.max=', 220.57799999999997, 'yuv.min=', -29.100710000000007)
('yuv.max=', 255.0, 'yuv.min=', -7.2650499999999916)
('yuv.max=', 245.62899999999999, 'yuv.min=', -70.030730000000005)
('yuv.max=', 250.29899999999998, 'yuv.min=', -35.375770000000003)
('yuv.max=', 248.989, 'yuv.min=', -14.544330000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 218.99600000000001, 'yuv.min=', -72.320589999999982)
('yuv.max=', 248.27699999999999, 'yuv.min=', -36.935679999999991)
('yuv.max=', 245.672, 'yuv.min=', -40.921590000000002)
('yuv.max=', 242.58100000000002, 'yuv.min=', -2.3450499999999934)
('yuv.max=', 240.72800000000001, 'yuv.min=', -27.870449999999988)
('yuv.max=', 255.0, 'yuv.min=', -11.255079999999992)
('yuv.max=', 248.91399999999999, 'yuv.min=', -19.825010000000006)
('yuv.max=', 254.10300000000001, 'yuv.min=', -30.405149999999985)
('yuv.max=', 237.45999999999998, 'yuv.min=', -28.866129999999998)
('yuv.max=', 184.113, 'yuv.min=', -22.725119999999997)
('yuv.max=', 225.82599999999996, 'yuv.min=', -32.415120000000002)
('yuv.max=', 252.65799999999999, 'yuv.min=', -14.585289999999995)
('yuv.max=', 248.84700000000001, 'yuv.min=', -15.015209999999986)
('yuv.max=', 226.05800000000002, 'yuv.min=', -38.365699999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.601410000000001)
('yuv.max=', 250.136, 'yuv.min=', -14.821630000000013)
('yuv.max=', 244.32699999999997, 'yuv.min=', -11.755129999999999)
('yuv.max=', 251.37799999999999, 'yuv.min=', -65.272270000000006)
('yuv.max=', 252.71799999999996, 'yuv.min=', -32.430659999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.586700000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -30.830500000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -22.750429999999987)
('yuv.max=', 220.684, 'yuv.min=', -37.825399999999995)
('yuv.max=', 248.81699999999998, 'yuv.min=', -40.67049999999999)
('yuv.max=', 247.00200000000001, 'yuv.min=', -36.595850000000006)
('yuv.max=', 216.23699999999999, 'yuv.min=', -47.29524)
('yuv.max=', 197.899, 'yuv.min=', -94.360579999999985)
('yuv.max=', 245.07399999999998, 'yuv.min=', -23.066559999999999)
('yuv.max=', 239.19999999999999, 'yuv.min=', -3.0451199999999936)
('yuv.max=', 211.73600000000002, 'yuv.min=', -36.48044999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.305239999999998)
('yuv.max=', 152.08199999999999, 'yuv.min=', -19.36626)
('yuv.max=', 247.33099999999999, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 248.71199999999999, 'yuv.min=', -23.980429999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -38.340389999999999)
('yuv.max=', 185.69299999999998, 'yuv.min=', -37.010379999999998)
('yuv.max=', 242.30200000000002, 'yuv.min=', -22.425089999999997)
('yuv.max=', 234.04900000000001, 'yuv.min=', -37.625379999999993)
('yuv.max=', 238.506, 'yuv.min=', -22.169879999999992)
('yuv.max=', 191.68100000000001, 'yuv.min=', -13.900159999999982)
('yuv.max=', 248.29899999999998, 'yuv.min=', -31.046289999999992)
('yuv.max=', 167.434, 'yuv.min=', -13.300099999999999)
('yuv.max=', 236.47800000000001, 'yuv.min=', -27.440529999999985)
('yuv.max=', 160.45099999999999, 'yuv.min=', -18.375299999999996)
('yuv.max=', 243.15699999999998, 'yuv.min=', -9.3126800000000074)
('yuv.max=', 233.03699999999998, 'yuv.min=', -13.040319999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.375539999999994)
('yuv.max=', 252.93999999999997, 'yuv.min=', -33.18835)
('yuv.max=', 253.97400000000002, 'yuv.min=', -18.645449999999997)
('yuv.max=', 255.0, 'yuv.min=', -3.9223300000000023)
('yuv.max=', 252.41899999999998, 'yuv.min=', -15.260049999999998)
('yuv.max=', 253.41900000000001, 'yuv.min=', -19.880019999999991)
('yuv.max=', 196.72199999999998, 'yuv.min=', -17.775239999999997)
('yuv.max=', 241.76499999999999, 'yuv.min=', -50.980669999999989)
('yuv.max=', 244.33100000000002, 'yuv.min=', -46.820499999999996)
('yuv.max=', 255.0, 'yuv.min=', -30.354750000000003)
('yuv.max=', 206.80599999999998, 'yuv.min=', -13.755329999999997)
('yuv.max=', 253.50099999999998, 'yuv.min=', -38.580659999999988)
('yuv.max=', 242.143, 'yuv.min=', -64.889969999999991)
('yuv.max=', 255.0, 'yuv.min=', -63.165719999999993)
('yuv.max=', 232.83399999999997, 'yuv.min=', -16.800430000000002)
('yuv.max=', 254.07099999999997, 'yuv.min=', -59.169889999999995)
('yuv.max=', 247.15299999999996, 'yuv.min=', -44.000709999999998)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.185, 'yuv.min=', -38.449359999999999)
('yuv.max=', 236.74599999999998, 'yuv.min=', -21.66526)
('yuv.max=', 250.505, 'yuv.min=', -29.085510000000003)
('yuv.max=', 238.41200000000001, 'yuv.min=', -25.785179999999983)
('yuv.max=', 222.45299999999997, 'yuv.min=', -36.802440000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.015009999999998)
('yuv.max=', 255.0, 'yuv.min=', -44.890170000000012)
('yuv.max=', 254.886, 'yuv.min=', -48.56548999999999)
('yuv.max=', 206.41, 'yuv.min=', -15.515259999999994)
('yuv.max=', 243.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 235.98299999999998, 'yuv.min=', -5.9200999999999926)
('yuv.max=', 250.22999999999999, 'yuv.min=', -36.125229999999988)
('yuv.max=', 239.56599999999997, 'yuv.min=', -88.435909999999993)
('yuv.max=', 225.49000000000001, 'yuv.min=', -43.86045)
('yuv.max=', 214.91799999999998, 'yuv.min=', -38.609770000000005)
('yuv.max=', 253.77199999999999, 'yuv.min=', -60.414829999999988)
('yuv.max=', 237.50999999999996, 'yuv.min=', -1.7483900000000006)
('yuv.max=', 241.70499999999998, 'yuv.min=', -30.945450000000001)
('yuv.max=', 203.41799999999998, 'yuv.min=', -30.630479999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.6499500000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 189.05600000000001, 'yuv.min=', -17.230369999999986)
('yuv.max=', 237.32799999999997, 'yuv.min=', -15.540569999999988)
('yuv.max=', 252.81499999999997, 'yuv.min=', -21.977520000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.708100000000002)
('yuv.max=', 174.95499999999998, 'yuv.min=', -12.055159999999983)
('yuv.max=', 238.00899999999999, 'yuv.min=', -27.665859999999995)
('yuv.max=', 232.93899999999996, 'yuv.min=', -40.257480000000001)
('yuv.max=', 255.0, 'yuv.min=', -9.7639499999999977)
('yuv.max=', 251.53299999999999, 'yuv.min=', -46.365269999999995)
('yuv.max=', 233.977, 'yuv.min=', -23.955119999999994)
('yuv.max=', 238.37699999999998, 'yuv.min=', -27.715249999999987)
('yuv.max=', 192.637, 'yuv.min=', -34.865349999999999)
('yuv.max=', 247.77200000000002, 'yuv.min=', -33.105419999999995)
('yuv.max=', 217.441, 'yuv.min=', -10.33262)
('yuv.max=', 254.886, 'yuv.min=', -27.274959999999968)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 156.15199999999999, 'yuv.min=', -16.930339999999994)
('yuv.max=', 204.86499999999998, 'yuv.min=', -98.749419999999986)
('yuv.max=', 200.86599999999999, 'yuv.min=', -32.000739999999993)
('yuv.max=', 247.42599999999999, 'yuv.min=', -13.77027)
('yuv.max=', 228.63999999999999, 'yuv.min=', -54.944840000000013)
('yuv.max=', 246.04900000000001, 'yuv.min=', -110.22525999999999)
('yuv.max=', 158.86699999999999, 'yuv.min=', -29.945349999999998)
('yuv.max=', 250.929, 'yuv.min=', -44.930679999999988)
('yuv.max=', 242.68999999999997, 'yuv.min=', -100.92555999999999)
('yuv.max=', 245.91800000000001, 'yuv.min=', -49.473049999999994)
('yuv.max=', 249.28799999999998, 'yuv.min=', -29.253930000000008)
('yuv.max=', 210.357, 'yuv.min=', -66.797670000000011)
('yuv.max=', 224.31299999999999, 'yuv.min=', -24.666039999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.79300000000001, 'yuv.min=', -32.736700000000006)
('yuv.max=', 229.04599999999999, 'yuv.min=', -47.920609999999996)
('yuv.max=', 250.131, 'yuv.min=', -22.441190000000006)
('yuv.max=', 254.202, 'yuv.min=', -33.805489999999992)
('yuv.max=', 224.30500000000001, 'yuv.min=', -27.148570000000007)
('yuv.max=', 211.273, 'yuv.min=', -45.25976)
('yuv.max=', 227.0, 'yuv.min=', -26.015079999999994)
('yuv.max=', 251.05999999999997, 'yuv.min=', -4.3649300000000011)
('yuv.max=', 133.11699999999999, 'yuv.min=', -24.525300000000001)
('yuv.max=', 247.05899999999997, 'yuv.min=', -117.53513)
('yuv.max=', 237.75399999999999, 'yuv.min=', -91.045309999999972)
('yuv.max=', 229.47999999999999, 'yuv.min=', -13.785209999999989)
('yuv.max=', 253.95699999999997, 'yuv.min=', -51.176119999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.84299999999999, 'yuv.min=', -27.830809999999992)
('yuv.max=', 241.16799999999998, 'yuv.min=', -48.719640000000012)
('yuv.max=', 213.63, 'yuv.min=', -19.82025999999999)
('yuv.max=', 247.441, 'yuv.min=', -34.720519999999993)
('yuv.max=', 190.35199999999998, 'yuv.min=', -102.79006999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', -34.950419999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.14099999999999, 'yuv.min=', -34.806519999999992)
('yuv.max=', 251.28799999999998, 'yuv.min=', -19.465039999999998)
('yuv.max=', 255.0, 'yuv.min=', -68.622959999999992)
('yuv.max=', 246.90699999999998, 'yuv.min=', -41.685540000000003)
('yuv.max=', 225.03299999999999, 'yuv.min=', -41.657730000000008)
('yuv.max=', 251.69400000000002, 'yuv.min=', -72.417450000000002)
('yuv.max=', 231.70599999999999, 'yuv.min=', -20.244309999999999)
('yuv.max=', 252.64099999999996, 'yuv.min=', -27.635420000000007)
('yuv.max=', 241.49899999999997, 'yuv.min=', -16.560179999999985)
('yuv.max=', 169.755, 'yuv.min=', -60.258319999999998)
('yuv.max=', 247.33099999999999, 'yuv.min=', -82.275539999999978)
('yuv.max=', 250.501, 'yuv.min=', -25.54034)
('yuv.max=', 191.774, 'yuv.min=', -23.365429999999996)
('yuv.max=', 255.0, 'yuv.min=', -49.516199999999998)
('yuv.max=', 239.25999999999999, 'yuv.min=', -40.555549999999982)
('yuv.max=', 255.0, 'yuv.min=', -35.694690000000001)
('yuv.max=', 229.63899999999998, 'yuv.min=', -49.879329999999996)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.525300000000001)
('yuv.max=', 232.50399999999999, 'yuv.min=', -45.750329999999998)
('yuv.max=', 229.85099999999997, 'yuv.min=', -48.631050000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.785849999999996)
('yuv.max=', 251.57599999999999, 'yuv.min=', -30.160309999999981)
('yuv.max=', 207.273, 'yuv.min=', -16.930339999999994)
('yuv.max=', 252.114, 'yuv.min=', -35.255240000000001)
('yuv.max=', 196.22199999999998, 'yuv.min=', -87.164210000000011)
('yuv.max=', 252.31999999999999, 'yuv.min=', -18.375299999999985)
('yuv.max=', 255.0, 'yuv.min=', -40.955589999999994)
('yuv.max=', 180.10499999999999, 'yuv.min=', -71.249809999999997)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 188.11199999999997, 'yuv.min=', -24.499649999999995)
('yuv.max=', 252.78899999999999, 'yuv.min=', -5.2349699999999828)
('yuv.max=', 254.40199999999999, 'yuv.min=', -45.805459999999997)
('yuv.max=', 236.05299999999997, 'yuv.min=', -30.230439999999991)
('yuv.max=', 63.748999999999995, 'yuv.min=', -20.615769999999998)
('yuv.max=', 249.00200000000001, 'yuv.min=', -29.358110000000003)
('yuv.max=', 255.0, 'yuv.min=', -16.458150000000003)
('yuv.max=', 212.80199999999996, 'yuv.min=', -20.920370000000002)
('yuv.max=', 254.41299999999995, 'yuv.min=', -14.825559999999996)
('yuv.max=', 188.03099999999998, 'yuv.min=', -75.785079999999994)
('yuv.max=', 226.29399999999998, 'yuv.min=', -63.885299999999987)
('yuv.max=', 212.178, 'yuv.min=', -25.595529999999993)
('yuv.max=', 229.51499999999999, 'yuv.min=', -54.375209999999988)
('yuv.max=', 214.45599999999999, 'yuv.min=', -38.839979999999997)
('yuv.max=', 181.92899999999997, 'yuv.min=', -21.237370000000002)
('yuv.max=', 219.327, 'yuv.min=', -49.56559)
('yuv.max=', 247.53700000000001, 'yuv.min=', -35.665429999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 223.78700000000001, 'yuv.min=', -40.080809999999992)
('yuv.max=', 244.18499999999997, 'yuv.min=', -21.095079999999996)
('yuv.max=', 143.517, 'yuv.min=', -42.01088)
('yuv.max=', 255.0, 'yuv.min=', -27.600570000000001)
('yuv.max=', 192.18099999999998, 'yuv.min=', -32.044340000000005)
('yuv.max=', 255.0, 'yuv.min=', -56.678540000000005)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 236.233, 'yuv.min=', -77.883540000000011)
('yuv.max=', 205.24299999999999, 'yuv.min=', -18.145399999999995)
('yuv.max=', 242.55699999999999, 'yuv.min=', -67.600609999999989)
('yuv.max=', 231.25899999999999, 'yuv.min=', -82.717879999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.309740000000001)
('yuv.max=', 234.99399999999997, 'yuv.min=', -33.939950000000003)
('yuv.max=', 180.321, 'yuv.min=', -20.370930000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.044520000000002)
('yuv.max=', 250.01099999999997, 'yuv.min=', -14.293480000000002)
('yuv.max=', 178.70099999999999, 'yuv.min=', -32.635249999999985)
('yuv.max=', 243.45199999999997, 'yuv.min=', -61.364469999999997)
('yuv.max=', 253.20599999999999, 'yuv.min=', -62.350699999999996)
('yuv.max=', 199.59699999999998, 'yuv.min=', -42.851210000000002)
('yuv.max=', 252.47299999999998, 'yuv.min=', -52.066810000000004)
('yuv.max=', 254.58699999999999, 'yuv.min=', -34.86694)
('yuv.max=', 251.48399999999998, 'yuv.min=', -10.05368)
('yuv.max=', 211.66699999999997, 'yuv.min=', -41.670599999999993)
('yuv.max=', 206.07199999999997, 'yuv.min=', -41.370569999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999988)
('yuv.max=', 255.0, 'yuv.min=', -9.1399299999999997)
('yuv.max=', 222.41900000000001, 'yuv.min=', -28.981339999999999)
('yuv.max=', 239.36099999999999, 'yuv.min=', -50.895449999999997)
('yuv.max=', 145.697, 'yuv.min=', -56.900769999999994)
('yuv.max=', 232.08199999999997, 'yuv.min=', -3.4919300000000106)
('yuv.max=', 255.0, 'yuv.min=', -8.6099999999999888)
('yuv.max=', 240.49900000000002, 'yuv.min=', -18.890289999999993)
('yuv.max=', 237.13299999999998, 'yuv.min=', -28.285429999999991)
('yuv.max=', 242.19999999999999, 'yuv.min=', -40.970529999999997)
('yuv.max=', 221.41399999999999, 'yuv.min=', -30.97533)
('yuv.max=', 236.49399999999997, 'yuv.min=', -60.005649999999996)
('yuv.max=', 245.33099999999996, 'yuv.min=', -6.8650099999999945)
('yuv.max=', 250.01099999999997, 'yuv.min=', -36.360820000000004)
('yuv.max=', 218.57499999999999, 'yuv.min=', -35.360829999999993)
('yuv.max=', 253.886, 'yuv.min=', -17.720050000000001)
('yuv.max=', 241.715, 'yuv.min=', -21.250279999999993)
('yuv.max=', 184.839, 'yuv.min=', -22.180249999999997)
('yuv.max=', 237.596, 'yuv.min=', -54.605109999999982)
('yuv.max=', 235.57599999999999, 'yuv.min=', -78.955699999999993)
('yuv.max=', 246.33099999999999, 'yuv.min=', -46.84581)
('yuv.max=', 255.0, 'yuv.min=', -21.566479999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.415419999999997)
('yuv.max=', 248.804, 'yuv.min=', -29.861509999999999)
('yuv.max=', 199.14199999999997, 'yuv.min=', -20.77467)
('yuv.max=', 221.988, 'yuv.min=', -38.546260000000004)
('yuv.max=', 234.28800000000001, 'yuv.min=', -23.912640000000007)
('yuv.max=', 135.11399999999998, 'yuv.min=', -16.716610000000003)
('yuv.max=', 255.0, 'yuv.min=', -27.074939999999991)
('yuv.max=', 250.79300000000001, 'yuv.min=', -51.75544)
('yuv.max=', 217.77299999999997, 'yuv.min=', -51.010549999999981)
('yuv.max=', 235.08299999999997, 'yuv.min=', -13.685199999999995)
('yuv.max=', 222.04900000000001, 'yuv.min=', -29.130329999999997)
('yuv.max=', 255.0, 'yuv.min=', -36.339219999999997)
('yuv.max=', 253.63200000000001, 'yuv.min=', -51.581020000000002)
('yuv.max=', 253.25599999999997, 'yuv.min=', -36.614909999999995)
('yuv.max=', 222.61899999999997, 'yuv.min=', -106.10343)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.033449999999995)
('yuv.max=', 253.77199999999999, 'yuv.min=', -32.33522)
('yuv.max=', 223.42799999999997, 'yuv.min=', -26.423940000000002)
('yuv.max=', 255.0, 'yuv.min=', -58.895169999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.006240000000005)
('yuv.max=', 247.00599999999997, 'yuv.min=', -91.160259999999994)
('yuv.max=', 225.797, 'yuv.min=', -48.120629999999991)
('yuv.max=', 223.02399999999997, 'yuv.min=', -60.980439999999994)
('yuv.max=', 219.81999999999999, 'yuv.min=', -36.701210000000003)
('yuv.max=', 255.0, 'yuv.min=', -93.235680000000002)
('yuv.max=', 233.52699999999996, 'yuv.min=', -41.455639999999988)
('yuv.max=', 224.12299999999996, 'yuv.min=', -25.372779999999999)
('yuv.max=', 234.369, 'yuv.min=', -29.973199999999999)
('yuv.max=', 255.0, 'yuv.min=', -14.549430000000001)
('yuv.max=', 179.13999999999999, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 245.20999999999998, 'yuv.min=', -29.545309999999997)
('yuv.max=', 230.11199999999999, 'yuv.min=', -5.7902099999999876)
('yuv.max=', 226.88200000000001, 'yuv.min=', -65.270499999999998)
('yuv.max=', 207.84299999999999, 'yuv.min=', -15.853250000000001)
('yuv.max=', 253.21699999999998, 'yuv.min=', -87.591009999999983)
('yuv.max=', 243.804, 'yuv.min=', -29.11186)
('yuv.max=', 252.00999999999999, 'yuv.min=', -57.21573999999999)
('yuv.max=', 233.94, 'yuv.min=', -1.0150399999999999)
('yuv.max=', 248.815, 'yuv.min=', -15.885419999999989)
('yuv.max=', 253.0, 'yuv.min=', -75.855509999999995)
('yuv.max=', 235.83999999999997, 'yuv.min=', -55.415559999999999)
('yuv.max=', 245.33999999999997, 'yuv.min=', -38.104830000000007)
('yuv.max=', 255.0, 'yuv.min=', -85.960079999999991)
('yuv.max=', 207.55399999999997, 'yuv.min=', -47.269770000000008)
('yuv.max=', 255.0, 'yuv.min=', -73.810369999999992)
('yuv.max=', 222.34, 'yuv.min=', -9.5353999999999921)
('yuv.max=', 227.81399999999999, 'yuv.min=', -28.645219999999995)
('yuv.max=', 228.11799999999999, 'yuv.min=', -85.665509999999998)
('yuv.max=', 192.10400000000001, 'yuv.min=', -112.75749999999999)
('yuv.max=', 229.16800000000001, 'yuv.min=', -19.062220000000011)
('yuv.max=', 204.91800000000001, 'yuv.min=', -34.450369999999978)
('yuv.max=', 255.0, 'yuv.min=', -83.719490000000008)
('yuv.max=', 236.44499999999999, 'yuv.min=', -36.495389999999993)
('yuv.max=', 174.11799999999999, 'yuv.min=', -11.855139999999999)
('yuv.max=', 220.78199999999998, 'yuv.min=', -47.050399999999982)
('yuv.max=', 201.69699999999997, 'yuv.min=', -31.960489999999993)
('yuv.max=', 255.0, 'yuv.min=', -22.221220000000002)
('yuv.max=', 240.24499999999998, 'yuv.min=', -24.640249999999991)
('yuv.max=', 224.02100000000002, 'yuv.min=', -35.783100000000005)
('yuv.max=', 252.17400000000001, 'yuv.min=', -32.490419999999986)
('yuv.max=', 236.52000000000001, 'yuv.min=', -25.625409999999999)
('yuv.max=', 255.0, 'yuv.min=', -49.227360000000004)
('yuv.max=', 238.60799999999998, 'yuv.min=', -48.450539999999982)
('yuv.max=', 233.99099999999999, 'yuv.min=', -17.205059999999989)
('yuv.max=', 253.25599999999997, 'yuv.min=', -47.773820000000001)
('yuv.max=', 186.19899999999998, 'yuv.min=', -81.705359999999985)
('yuv.max=', 227.38, 'yuv.min=', -18.08436)
('yuv.max=', 223.00699999999998, 'yuv.min=', -41.93618)
('yuv.max=', 254.40199999999999, 'yuv.min=', -65.255209999999991)
('yuv.max=', 238.53499999999997, 'yuv.min=', -88.695689999999985)
('yuv.max=', 245.03199999999998, 'yuv.min=', -27.929869999999998)
('yuv.max=', 231.02599999999998, 'yuv.min=', -44.045530000000007)
('yuv.max=', 127.95, 'yuv.min=', -40.555549999999997)
('yuv.max=', 225.86199999999999, 'yuv.min=', -25.840370000000004)
('yuv.max=', 176.495, 'yuv.min=', -19.094879999999996)
('yuv.max=', 255.0, 'yuv.min=', -14.100179999999991)
('yuv.max=', 253.0, 'yuv.min=', -19.135129999999993)
('yuv.max=', 246.09700000000001, 'yuv.min=', -15.56588)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -23.237720000000007)
('yuv.max=', 254.18499999999997, 'yuv.min=', -67.730499999999992)
('yuv.max=', 234.70299999999997, 'yuv.min=', -62.220809999999993)
('yuv.max=', 245.63, 'yuv.min=', -8.6099999999999959)
('yuv.max=', 255.0, 'yuv.min=', -13.315039999999996)
('yuv.max=', 207.40299999999999, 'yuv.min=', -10.425119999999989)
('yuv.max=', 174.38499999999999, 'yuv.min=', -35.30563999999999)
('yuv.max=', 252.63, 'yuv.min=', -37.89552999999998)
('yuv.max=', 215.02599999999998, 'yuv.min=', -82.183120000000002)
('yuv.max=', 252.608, 'yuv.min=', -36.835669999999986)
('yuv.max=', 255.0, 'yuv.min=', -26.840470000000003)
('yuv.max=', 251.24699999999999, 'yuv.min=', -26.25535)
('yuv.max=', 250.18499999999997, 'yuv.min=', -31.504259999999999)
('yuv.max=', 232.93099999999998, 'yuv.min=', -16.255809999999997)
('yuv.max=', 216.87899999999999, 'yuv.min=', -21.080139999999993)
('yuv.max=', 235.08199999999999, 'yuv.min=', -25.308600000000002)
('yuv.max=', 252.989, 'yuv.min=', -40.25551999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.705009999999991)
('yuv.max=', 245.98399999999998, 'yuv.min=', -49.950689999999994)
('yuv.max=', 238.28799999999998, 'yuv.min=', -15.280210000000004)
('yuv.max=', 239.488, 'yuv.min=', -15.215229999999991)
('yuv.max=', 252.28800000000001, 'yuv.min=', -21.253010000000003)
('yuv.max=', 199.90600000000001, 'yuv.min=', -49.695479999999989)
('yuv.max=', 242.79299999999998, 'yuv.min=', -23.110219999999998)
('yuv.max=', 207.19099999999997, 'yuv.min=', -9.0399199999999897)
('yuv.max=', 210.55700000000002, 'yuv.min=', -15.133760000000001)
('yuv.max=', 255.0, 'yuv.min=', -8.7227000000000032)
('yuv.max=', 243.19499999999999, 'yuv.min=', -27.770439999999997)
('yuv.max=', 246.48399999999998, 'yuv.min=', -37.355649999999997)
('yuv.max=', 239.89699999999999, 'yuv.min=', -20.775539999999992)
('yuv.max=', 178.82099999999997, 'yuv.min=', -11.046079999999996)
('yuv.max=', 225.01799999999997, 'yuv.min=', -72.35136)
('yuv.max=', 255.0, 'yuv.min=', -46.439970000000002)
('yuv.max=', 255.0, 'yuv.min=', -48.453850000000003)
('yuv.max=', 189.88999999999999, 'yuv.min=', -11.077830000000006)
('yuv.max=', 222.26399999999998, 'yuv.min=', -23.380369999999999)
('yuv.max=', 231.24899999999997, 'yuv.min=', -46.650359999999992)
('yuv.max=', 163.60899999999998, 'yuv.min=', -1.5954600000000028)
('yuv.max=', 239.09299999999996, 'yuv.min=', -26.352980000000002)
('yuv.max=', 244.89200000000002, 'yuv.min=', -86.550660000000008)
('yuv.max=', 240.28800000000001, 'yuv.min=', -14.95364)
('yuv.max=', 248.59799999999998, 'yuv.min=', -44.460509999999999)
('yuv.max=', 247.28400000000002, 'yuv.min=', -27.315209999999983)
('yuv.max=', 209.727, 'yuv.min=', -39.428609999999999)
('yuv.max=', 217.02199999999999, 'yuv.min=', -32.260519999999993)
('yuv.max=', 250.51999999999998, 'yuv.min=', -25.444710000000004)
('yuv.max=', 211.74299999999999, 'yuv.min=', -10.641559999999998)
('yuv.max=', 242.06799999999998, 'yuv.min=', -53.479530000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.66187)
('yuv.max=', 229.94599999999997, 'yuv.min=', -51.310580000000002)
('yuv.max=', 255.0, 'yuv.min=', -44.365979999999993)
('yuv.max=', 205.94499999999999, 'yuv.min=', -53.565489999999997)
('yuv.max=', 215.08600000000001, 'yuv.min=', -30.382569999999998)
('yuv.max=', 232.66200000000001, 'yuv.min=', -26.615139999999997)
('yuv.max=', 251.41199999999998, 'yuv.min=', -20.680099999999996)
('yuv.max=', 250.06399999999996, 'yuv.min=', -22.571820000000002)
('yuv.max=', 233.91499999999999, 'yuv.min=', -42.01544999999998)
('yuv.max=', 198.041, 'yuv.min=', -31.022600000000004)
('yuv.max=', 224.36799999999997, 'yuv.min=', -53.255589999999998)
('yuv.max=', 247.34199999999998, 'yuv.min=', -27.440529999999992)
('yuv.max=', 239.44099999999997, 'yuv.min=', -38.740429999999989)
('yuv.max=', 218.006, 'yuv.min=', -28.44791)
('yuv.max=', 242.82599999999999, 'yuv.min=', -15.030149999999997)
('yuv.max=', 235.90399999999997, 'yuv.min=', -35.015029999999996)
('yuv.max=', 200.05099999999999, 'yuv.min=', -23.306490000000004)
('yuv.max=', 230.85999999999999, 'yuv.min=', -79.800599999999989)
('yuv.max=', 246.93900000000002, 'yuv.min=', -39.070339999999987)
('yuv.max=', 150.93699999999998, 'yuv.min=', -58.034939999999999)
('yuv.max=', 251.113, 'yuv.min=', -70.935389999999984)
('yuv.max=', 131.19800000000001, 'yuv.min=', -13.95478)
('yuv.max=', 252.49200000000002, 'yuv.min=', -57.729520000000008)
('yuv.max=', 228.09599999999998, 'yuv.min=', -55.26493)
('yuv.max=', 214.042, 'yuv.min=', -10.454999999999981)
('yuv.max=', 216.50900000000001, 'yuv.min=', -14.40020999999998)
('yuv.max=', 241.75599999999997, 'yuv.min=', -64.875029999999995)
('yuv.max=', 237.59799999999998, 'yuv.min=', -67.885699999999986)
('yuv.max=', 234.48099999999999, 'yuv.min=', -44.040289999999999)
('yuv.max=', 170.94399999999999, 'yuv.min=', -53.201340000000002)
('yuv.max=', 227.58999999999997, 'yuv.min=', -38.570289999999993)
('yuv.max=', 249.30099999999999, 'yuv.min=', -31.154830000000004)
('yuv.max=', 238.94999999999999, 'yuv.min=', -23.574660000000002)
('yuv.max=', 217.64699999999999, 'yuv.min=', -56.670869999999994)
('yuv.max=', 249.733, 'yuv.min=', -34.535439999999994)
('yuv.max=', 203.46899999999999, 'yuv.min=', -9.4540900000000008)
('yuv.max=', 255.0, 'yuv.min=', -6.9799599999999966)
('yuv.max=', 181.749, 'yuv.min=', -14.930139999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -21.050259999999991)
('yuv.max=', 247.548, 'yuv.min=', -26.415119999999995)
('yuv.max=', 255.0, 'yuv.min=', -77.486040000000003)
('yuv.max=', 251.79299999999998, 'yuv.min=', -18.479309999999998)
('yuv.max=', 225.642, 'yuv.min=', -36.735659999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.305540000000008)
('yuv.max=', 207.23299999999998, 'yuv.min=', -29.913629999999998)
('yuv.max=', 211.85099999999997, 'yuv.min=', -35.432960000000008)
('yuv.max=', 242.821, 'yuv.min=', -40.67569000000001)
('yuv.max=', 226.28999999999999, 'yuv.min=', -21.635379999999998)
('yuv.max=', 222.82499999999999, 'yuv.min=', -44.045529999999999)
('yuv.max=', 237.41199999999998, 'yuv.min=', -31.475379999999994)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.95599)
('yuv.max=', 217.57899999999998, 'yuv.min=', -36.140169999999991)
('yuv.max=', 252.52699999999996, 'yuv.min=', -23.580389999999987)
('yuv.max=', 245.49799999999999, 'yuv.min=', -24.225269999999988)
('yuv.max=', 236.18899999999999, 'yuv.min=', -14.930139999999984)
('yuv.max=', 241.63199999999998, 'yuv.min=', -38.435920000000003)
('yuv.max=', 248.21800000000002, 'yuv.min=', -16.609940000000002)
('yuv.max=', 244.85299999999998, 'yuv.min=', -63.065709999999989)
('yuv.max=', 235.63399999999999, 'yuv.min=', -49.370200000000011)
('yuv.max=', 236.04500000000002, 'yuv.min=', -34.180219999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.683690000000004)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.48400000000001, 'yuv.min=', -87.280609999999996)
('yuv.max=', 219.21799999999999, 'yuv.min=', -20.555190000000003)
('yuv.max=', 255.0, 'yuv.min=', -72.842430000000007)
('yuv.max=', 230.12899999999996, 'yuv.min=', -16.375100000000003)
('yuv.max=', 105.67999999999999, 'yuv.min=', -7.6708899999999964)
('yuv.max=', 238.51199999999997, 'yuv.min=', -79.229519999999994)
('yuv.max=', 236.084, 'yuv.min=', -73.392080000000007)
('yuv.max=', 253.77199999999999, 'yuv.min=', -39.38530999999999)
('yuv.max=', 201.33099999999999, 'yuv.min=', -52.291040000000002)
('yuv.max=', 248.38999999999999, 'yuv.min=', -37.149919999999995)
('yuv.max=', 253.505, 'yuv.min=', -29.300469999999994)
('yuv.max=', 207.416, 'yuv.min=', -8.3367199999999997)
('yuv.max=', 248.48799999999997, 'yuv.min=', -21.905529999999988)
('yuv.max=', 243.619, 'yuv.min=', -24.795449999999988)
('yuv.max=', 192.15600000000001, 'yuv.min=', -22.035419999999984)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.435570000000002)
('yuv.max=', 243.22800000000001, 'yuv.min=', -44.990439999999985)
('yuv.max=', 219.06999999999999, 'yuv.min=', -17.820059999999994)
('yuv.max=', 212.80399999999997, 'yuv.min=', -95.51948999999999)
('yuv.max=', 227.25299999999999, 'yuv.min=', -19.175379999999997)
('yuv.max=', 247.81699999999998, 'yuv.min=', -23.780409999999989)
('yuv.max=', 196.797, 'yuv.min=', -17.219999999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 255.0, 'yuv.min=', -30.273140000000001)
('yuv.max=', 255.0, 'yuv.min=', -10.162979999999997)
('yuv.max=', 195.47699999999998, 'yuv.min=', -24.12525999999999)
('yuv.max=', 242.03699999999998, 'yuv.min=', -27.407880000000002)
('yuv.max=', 248.33099999999999, 'yuv.min=', -55.920179999999988)
('yuv.max=', 247.529, 'yuv.min=', -52.325619999999994)
('yuv.max=', 123.985, 'yuv.min=', -9.3020399999999981)
('yuv.max=', 240.37899999999999, 'yuv.min=', -47.587590000000006)
('yuv.max=', 241.20399999999998, 'yuv.min=', -41.951610000000002)
('yuv.max=', 224.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.26399999999995, 'yuv.min=', -39.101939999999999)
('yuv.max=', 245.684, 'yuv.min=', -54.920079999999992)
('yuv.max=', 226.62099999999998, 'yuv.min=', -101.91767)
('yuv.max=', 247.68499999999997, 'yuv.min=', -45.701189999999997)
('yuv.max=', 240.38099999999997, 'yuv.min=', -17.323450000000001)
('yuv.max=', 188.13599999999997, 'yuv.min=', -16.245209999999997)
('yuv.max=', 210.38999999999999, 'yuv.min=', -34.566549999999992)
('yuv.max=', 242.44200000000001, 'yuv.min=', -65.970569999999981)
('yuv.max=', 255.0, 'yuv.min=', -11.399909999999997)
('yuv.max=', 243.05599999999998, 'yuv.min=', -33.330269999999999)
('yuv.max=', 234.542, 'yuv.min=', -13.378679999999999)
('yuv.max=', 247.95000000000002, 'yuv.min=', -64.106090000000009)
('yuv.max=', 196.00999999999999, 'yuv.min=', -27.400279999999988)
('yuv.max=', 242.24299999999999, 'yuv.min=', -55.544059999999995)
('yuv.max=', 248.07499999999996, 'yuv.min=', -46.739999999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.84836)
('yuv.max=', 242.03299999999999, 'yuv.min=', -95.035339999999991)
('yuv.max=', 236.25699999999998, 'yuv.min=', -15.968030000000001)
('yuv.max=', 212.0, 'yuv.min=', -18.778709999999997)
('yuv.max=', 255.0, 'yuv.min=', -14.43074)
('yuv.max=', 253.08799999999999, 'yuv.min=', -17.41545)
('yuv.max=', 250.03200000000001, 'yuv.min=', -23.259359999999997)
('yuv.max=', 255.0, 'yuv.min=', -25.810489999999991)
('yuv.max=', 223.07099999999997, 'yuv.min=', -6.4241700000000037)
('yuv.max=', 255.0, 'yuv.min=', -40.964729999999996)
('yuv.max=', 245.09100000000001, 'yuv.min=', -79.883209999999991)
('yuv.max=', 226.05800000000002, 'yuv.min=', -44.960300000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.485249999999994)
('yuv.max=', 199.35899999999998, 'yuv.min=', -29.245279999999987)
('yuv.max=', 224.85799999999998, 'yuv.min=', -25.025349999999992)
('yuv.max=', 241.334, 'yuv.min=', -31.60526999999999)
('yuv.max=', 230.06899999999996, 'yuv.min=', -27.904899999999984)
('yuv.max=', 230.37399999999997, 'yuv.min=', -14.467530000000004)
('yuv.max=', 231.28800000000001, 'yuv.min=', -91.785629999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.665430000000001)
('yuv.max=', 203.69, 'yuv.min=', -35.465409999999999)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 252.89699999999999, 'yuv.min=', -21.395109999999995)
('yuv.max=', 205.94999999999999, 'yuv.min=', -47.216260000000005)
('yuv.max=', 242.643, 'yuv.min=', -32.99960999999999)
('yuv.max=', 194.29499999999999, 'yuv.min=', -38.525469999999991)
('yuv.max=', 253.82599999999996, 'yuv.min=', -14.740220000000001)
('yuv.max=', 192.072, 'yuv.min=', -21.411070000000002)
('yuv.max=', 253.72899999999996, 'yuv.min=', -24.578320000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.910920000000004)
('yuv.max=', 219.40799999999996, 'yuv.min=', -116.92012999999999)
('yuv.max=', 211.79900000000001, 'yuv.min=', -41.375139999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.493200000000002)
('yuv.max=', 254.131, 'yuv.min=', -30.560349999999993)
('yuv.max=', 249.84299999999999, 'yuv.min=', -32.3887)
('yuv.max=', 198.529, 'yuv.min=', -70.835379999999986)
('yuv.max=', 255.0, 'yuv.min=', -1.1299899999999941)
('yuv.max=', 194.81399999999999, 'yuv.min=', -20.337510000000009)
('yuv.max=', 192.91200000000001, 'yuv.min=', -12.540269999999996)
('yuv.max=', 146.27700000000002, 'yuv.min=', -15.400309999999994)
('yuv.max=', 243.0, 'yuv.min=', -37.465609999999998)
('yuv.max=', 251.77199999999999, 'yuv.min=', -15.302290000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.9949999999999868)
('yuv.max=', 255.0, 'yuv.min=', -22.695239999999988)
('yuv.max=', 246.64999999999998, 'yuv.min=', -42.645389999999992)
('yuv.max=', 252.48999999999998, 'yuv.min=', -26.310539999999996)
('yuv.max=', 214.328, 'yuv.min=', -10.925310000000003)
('yuv.max=', 231.85399999999996, 'yuv.min=', -18.43506)
('yuv.max=', 182.50099999999998, 'yuv.min=', -24.865579999999984)
('yuv.max=', 209.06799999999998, 'yuv.min=', -31.111840000000008)
('yuv.max=', 217.86399999999998, 'yuv.min=', -31.145469999999996)
('yuv.max=', 232.14399999999998, 'yuv.min=', -30.890259999999998)
('yuv.max=', 169.60999999999999, 'yuv.min=', -32.811630000000001)
('yuv.max=', 232.38399999999996, 'yuv.min=', -45.554819999999999)
('yuv.max=', 247.47099999999998, 'yuv.min=', -66.580080000000009)
('yuv.max=', 253.80399999999997, 'yuv.min=', -12.670159999999989)
('yuv.max=', 178.28799999999998, 'yuv.min=', -17.182500000000001)
('yuv.max=', 206.29399999999998, 'yuv.min=', -27.455469999999995)
('yuv.max=', 235.06, 'yuv.min=', -17.260249999999999)
('yuv.max=', 223.10199999999998, 'yuv.min=', -17.186849999999993)
('yuv.max=', 255.0, 'yuv.min=', -38.334159999999997)
('yuv.max=', 248.70099999999999, 'yuv.min=', -32.475479999999997)
('yuv.max=', 167.815, 'yuv.min=', -79.626850000000005)
('yuv.max=', 146.19699999999997, 'yuv.min=', -14.600230000000003)
('yuv.max=', 253.70099999999996, 'yuv.min=', -25.250679999999996)
('yuv.max=', 234.03200000000001, 'yuv.min=', -12.814989999999996)
('yuv.max=', 253.52699999999999, 'yuv.min=', -5.2200299999999995)
('yuv.max=', 235.90299999999999, 'yuv.min=', -29.672900000000006)
('yuv.max=', 201.715, 'yuv.min=', -38.325449999999996)
('yuv.max=', 226.67499999999998, 'yuv.min=', -27.800320000000003)
('yuv.max=', 252.0, 'yuv.min=', -9.4534699999999958)
('yuv.max=', 250.12700000000001, 'yuv.min=', -21.384009999999996)
('yuv.max=', 237.32299999999998, 'yuv.min=', -31.890359999999994)
('yuv.max=', 249.78200000000001, 'yuv.min=', -36.925309999999996)
('yuv.max=', 249.05299999999997, 'yuv.min=', -58.871089999999995)
('yuv.max=', 241.548, 'yuv.min=', -39.805400000000006)
('yuv.max=', 239.27099999999999, 'yuv.min=', -80.000619999999998)
('yuv.max=', 255.0, 'yuv.min=', -53.540679999999988)
('yuv.max=', 234.70400000000001, 'yuv.min=', -23.961909999999996)
('yuv.max=', 128.86499999999998, 'yuv.min=', -35.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -62.120799999999988)
('yuv.max=', 208.19599999999997, 'yuv.min=', -26.280659999999994)
('yuv.max=', 205.57599999999999, 'yuv.min=', -24.610369999999993)
('yuv.max=', 255.0, 'yuv.min=', -21.150270000000003)
('yuv.max=', 232.017, 'yuv.min=', -58.709830000000011)
('yuv.max=', 242.91799999999998, 'yuv.min=', -27.210629999999995)
('yuv.max=', 231.14199999999997, 'yuv.min=', -73.805800000000005)
('yuv.max=', 242.68999999999997, 'yuv.min=', -15.849739999999994)
('yuv.max=', 234.214, 'yuv.min=', -24.265519999999999)
('yuv.max=', 252.036, 'yuv.min=', -36.48044999999999)
('yuv.max=', 187.53, 'yuv.min=', -42.685639999999999)
('yuv.max=', 224.88299999999998, 'yuv.min=', -43.945520000000002)
('yuv.max=', 246.55199999999999, 'yuv.min=', -18.064899999999994)
('yuv.max=', 244.47300000000001, 'yuv.min=', -60.020589999999991)
('yuv.max=', 255.0, 'yuv.min=', -29.619660000000007)
('yuv.max=', 246.95999999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -32.061410000000009)
('yuv.max=', 242.91799999999998, 'yuv.min=', -20.675010000000015)
('yuv.max=', 231.86600000000001, 'yuv.min=', -15.421110000000013)
('yuv.max=', 237.21599999999998, 'yuv.min=', -40.137010000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.86900000000003, 'yuv.min=', -40.825699999999991)
('yuv.max=', 246.744, 'yuv.min=', -38.755369999999992)
('yuv.max=', 223.72900000000001, 'yuv.min=', -40.640619999999998)
('yuv.max=', 226.68799999999999, 'yuv.min=', -34.044260000000001)
('yuv.max=', 251.44499999999996, 'yuv.min=', -9.3652599999999957)
('yuv.max=', 161.93999999999997, 'yuv.min=', -9.7436700000000052)
('yuv.max=', 254.35900000000001, 'yuv.min=', -55.021319999999996)
('yuv.max=', 252.68599999999998, 'yuv.min=', -20.641079999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -10.936579999999999)
('yuv.max=', 186.77199999999999, 'yuv.min=', -20.937799999999999)
('yuv.max=', 169.56800000000001, 'yuv.min=', -36.26549)
('yuv.max=', 219.88099999999997, 'yuv.min=', -56.159570000000002)
('yuv.max=', 218.16, 'yuv.min=', -49.211160000000007)
('yuv.max=', 243.33099999999999, 'yuv.min=', -27.85435)
('yuv.max=', 182.37299999999999, 'yuv.min=', -41.445269999999994)
('yuv.max=', 240.19499999999996, 'yuv.min=', -25.706570000000003)
('yuv.max=', 255.0, 'yuv.min=', -32.335219999999993)
('yuv.max=', 247.70699999999999, 'yuv.min=', -61.603790000000004)
('yuv.max=', 219.13999999999999, 'yuv.min=', -15.730220000000003)
('yuv.max=', 251.50500000000002, 'yuv.min=', -57.767760000000003)
('yuv.max=', 187.43100000000001, 'yuv.min=', -27.967719999999996)
('yuv.max=', 251.48399999999998, 'yuv.min=', -42.25571999999999)
('yuv.max=', 233.46299999999997, 'yuv.min=', -29.000439999999998)
('yuv.max=', 226.22799999999998, 'yuv.min=', -26.31510999999999)
('yuv.max=', 242.75500000000002, 'yuv.min=', -38.355329999999995)
('yuv.max=', 236.22799999999998, 'yuv.min=', -26.855409999999988)
('yuv.max=', 230.02699999999999, 'yuv.min=', -51.791119999999992)
('yuv.max=', 234.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 241.12099999999998, 'yuv.min=', -19.383939999999996)
('yuv.max=', 252.202, 'yuv.min=', -20.348179999999999)
('yuv.max=', 250.18499999999997, 'yuv.min=', -34.584829999999997)
('yuv.max=', 235.73599999999999, 'yuv.min=', -60.085030000000003)
('yuv.max=', 255.0, 'yuv.min=', -18.820159999999984)
('yuv.max=', 223.87900000000002, 'yuv.min=', -42.414560000000009)
('yuv.max=', 254.17400000000001, 'yuv.min=', -65.695849999999993)
('yuv.max=', 233.31799999999998, 'yuv.min=', -19.090309999999995)
('yuv.max=', 188.881, 'yuv.min=', -81.343759999999989)
('yuv.max=', 164.822, 'yuv.min=', -54.030360000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.24399999999997, 'yuv.min=', -109.02513999999999)
('yuv.max=', 255.0, 'yuv.min=', -56.073400000000007)
('yuv.max=', 241.14600000000002, 'yuv.min=', -49.21623000000001)
('yuv.max=', 169.10899999999998, 'yuv.min=', -44.354190000000003)
('yuv.max=', 255.0, 'yuv.min=', -14.144999999999992)
('yuv.max=', 249.01999999999998, 'yuv.min=', -56.35132999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', -22.705609999999989)
('yuv.max=', 186.97799999999998, 'yuv.min=', -37.480549999999994)
('yuv.max=', 251.113, 'yuv.min=', -37.749150000000007)
('yuv.max=', 210.34799999999998, 'yuv.min=', -25.840369999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.400649999999999)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 203.17999999999998, 'yuv.min=', -52.731660000000005)
('yuv.max=', 246.08299999999997, 'yuv.min=', -9.4319400000000115)
('yuv.max=', 218.84199999999998, 'yuv.min=', -52.824670000000012)
('yuv.max=', 247.078, 'yuv.min=', -34.282920000000004)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.350070000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 210.542, 'yuv.min=', -58.39054999999999)
('yuv.max=', 239.94999999999999, 'yuv.min=', -20.605399999999996)
('yuv.max=', 239.14699999999999, 'yuv.min=', -32.535240000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.415219999999998)
('yuv.max=', 239.29999999999998, 'yuv.min=', -22.827349999999999)
('yuv.max=', 212.09200000000001, 'yuv.min=', -26.500189999999986)
('yuv.max=', 189.87800000000001, 'yuv.min=', -91.960130000000007)
('yuv.max=', 234.95599999999996, 'yuv.min=', -37.074289999999998)
('yuv.max=', 203.03200000000001, 'yuv.min=', -19.435159999999996)
('yuv.max=', 234.755, 'yuv.min=', -19.205259999999996)
('yuv.max=', 137.67399999999998, 'yuv.min=', -50.791019999999989)
('yuv.max=', 240.00799999999998, 'yuv.min=', -17.318050000000007)
('yuv.max=', 233.82899999999998, 'yuv.min=', -53.164719999999996)
('yuv.max=', 208.672, 'yuv.min=', -36.84023999999998)
('yuv.max=', 227.22900000000001, 'yuv.min=', -60.017719999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.7100099999999951)
('yuv.max=', 246.60299999999998, 'yuv.min=', -47.020519999999991)
('yuv.max=', 248.96099999999998, 'yuv.min=', -53.885529999999996)
('yuv.max=', 242.232, 'yuv.min=', -47.025089999999999)
('yuv.max=', 207.78699999999998, 'yuv.min=', -20.350189999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.511020000000002)
('yuv.max=', 252.92899999999997, 'yuv.min=', -24.85521)
('yuv.max=', 234.52999999999997, 'yuv.min=', -35.235509999999991)
('yuv.max=', 236.017, 'yuv.min=', -29.444099999999999)
('yuv.max=', 240.76300000000001, 'yuv.min=', -46.714579999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.0013000000000005)
('yuv.max=', 178.70699999999999, 'yuv.min=', -44.305309999999992)
('yuv.max=', 200.83099999999999, 'yuv.min=', -21.814159999999987)
('yuv.max=', 224.07999999999998, 'yuv.min=', -24.931839999999998)
('yuv.max=', 248.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 236.52100000000002, 'yuv.min=', -34.365299999999991)
('yuv.max=', 212.45999999999998, 'yuv.min=', -62.280569999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.760099999999987)
('yuv.max=', 200.328, 'yuv.min=', -29.9466)
('yuv.max=', 248.755, 'yuv.min=', -11.495349999999991)
('yuv.max=', 247.80399999999997, 'yuv.min=', -16.175079999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.085139999999996)
('yuv.max=', 215.70999999999998, 'yuv.min=', -7.6650899999999922)
('yuv.max=', 242.72200000000001, 'yuv.min=', -40.955589999999994)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.679830000000003)
('yuv.max=', 241.68099999999998, 'yuv.min=', -64.725629999999995)
('yuv.max=', 254.11399999999998, 'yuv.min=', -22.34985)
('yuv.max=', 241.733, 'yuv.min=', -4.6050299999999922)
('yuv.max=', 252.31999999999999, 'yuv.min=', -40.880889999999994)
('yuv.max=', 244.70100000000002, 'yuv.min=', -20.050159999999984)
('yuv.max=', 202.63199999999998, 'yuv.min=', -29.855709999999995)
('yuv.max=', 225.29000000000002, 'yuv.min=', -37.359799999999979)
('yuv.max=', 255.0, 'yuv.min=', -39.710649999999994)
('yuv.max=', 249.142, 'yuv.min=', -39.144829999999992)
('yuv.max=', 226.91999999999999, 'yuv.min=', -27.230139999999984)
('yuv.max=', 255.0, 'yuv.min=', -36.395379999999989)
('yuv.max=', 242.37199999999999, 'yuv.min=', -53.800660000000008)
('yuv.max=', 196.16800000000001, 'yuv.min=', -19.646320000000003)
('yuv.max=', 255.0, 'yuv.min=', -6.6149000000000022)
('yuv.max=', 243.929, 'yuv.min=', -24.895459999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', -27.745129999999996)
('yuv.max=', 245.03199999999998, 'yuv.min=', -5.0200099999999779)
('yuv.max=', 255.0, 'yuv.min=', -13.814349999999997)
('yuv.max=', 252.28800000000001, 'yuv.min=', -22.087420000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.840269999999986)
('yuv.max=', 245.488, 'yuv.min=', -18.790279999999989)
('yuv.max=', 238.815, 'yuv.min=', -75.985279999999989)
('yuv.max=', 253.87500000000003, 'yuv.min=', -80.145449999999997)
('yuv.max=', 196.136, 'yuv.min=', -29.368479999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.455299999999994)
('yuv.max=', 251.92899999999995, 'yuv.min=', -42.066370000000006)
('yuv.max=', 254.65800000000002, 'yuv.min=', -17.874340000000004)
('yuv.max=', 242.54400000000001, 'yuv.min=', -26.910599999999999)
('yuv.max=', 211.28299999999999, 'yuv.min=', -29.730390000000003)
('yuv.max=', 230.89399999999998, 'yuv.min=', -22.910199999999982)
('yuv.max=', 195.85499999999999, 'yuv.min=', -35.820629999999987)
('yuv.max=', 248.97900000000001, 'yuv.min=', -23.150469999999988)
('yuv.max=', 235.958, 'yuv.min=', -64.055440000000004)
('yuv.max=', 241.245, 'yuv.min=', -42.145340000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.392479999999999)
('yuv.max=', 235.04399999999998, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -37.895530000000001)
('yuv.max=', 232.721, 'yuv.min=', -0.88515000000000299)
('yuv.max=', 254.40199999999999, 'yuv.min=', -69.839209999999994)
('yuv.max=', 204.905, 'yuv.min=', -55.358320000000006)
('yuv.max=', 183.33999999999997, 'yuv.min=', -36.635649999999998)
('yuv.max=', 255.0, 'yuv.min=', -21.665259999999989)
('yuv.max=', 255.0, 'yuv.min=', -9.8250599999999935)
('yuv.max=', 229.59299999999999, 'yuv.min=', -37.140269999999987)
('yuv.max=', 254.77200000000002, 'yuv.min=', -30.96039)
('yuv.max=', 255.0, 'yuv.min=', -8.315940000000003)
('yuv.max=', 216.959, 'yuv.min=', -9.6007199999999955)
('yuv.max=', 255.0, 'yuv.min=', -8.1732300000000038)
('yuv.max=', 235.53899999999999, 'yuv.min=', -34.799590000000002)
('yuv.max=', 204.65099999999998, 'yuv.min=', -22.250379999999986)
('yuv.max=', 225.08199999999999, 'yuv.min=', -27.520690000000005)
('yuv.max=', 237.57799999999997, 'yuv.min=', -23.410629999999998)
('yuv.max=', 255.0, 'yuv.min=', -20.43526)
('yuv.max=', 231.13099999999997, 'yuv.min=', -6.1350599999999957)
('yuv.max=', 252.309, 'yuv.min=', -49.076009999999997)
('yuv.max=', 252.15200000000002, 'yuv.min=', -45.78595)
('yuv.max=', 245.41300000000001, 'yuv.min=', -26.770339999999987)
('yuv.max=', 243.971, 'yuv.min=', -42.909100000000002)
('yuv.max=', 237.49099999999999, 'yuv.min=', -30.990269999999988)
('yuv.max=', 149.28999999999999, 'yuv.min=', -35.931009999999993)
('yuv.max=', 224.703, 'yuv.min=', -33.465209999999978)
('yuv.max=', 186.13299999999998, 'yuv.min=', -27.493270000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.54400000000001, 'yuv.min=', -16.234839999999995)
('yuv.max=', 255.0, 'yuv.min=', -29.790149999999986)
('yuv.max=', 237.59799999999998, 'yuv.min=', -13.455300000000001)
('yuv.max=', 243.34099999999998, 'yuv.min=', -91.028689999999997)
('yuv.max=', 216.398, 'yuv.min=', -41.930379999999992)
('yuv.max=', 255.0, 'yuv.min=', -29.897940000000002)
('yuv.max=', 190.43899999999999, 'yuv.min=', -50.599990000000005)
('yuv.max=', 201.637, 'yuv.min=', -26.670329999999996)
('yuv.max=', 203.94299999999998, 'yuv.min=', -31.060399999999991)
('yuv.max=', 177.93899999999999, 'yuv.min=', -16.160139999999998)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.99999999999997, 'yuv.min=', -56.64473000000001)
('yuv.max=', 199.0, 'yuv.min=', -10.909989999999997)
('yuv.max=', 245.20599999999999, 'yuv.min=', -42.299309999999991)
('yuv.max=', 209.441, 'yuv.min=', -40.570489999999992)
('yuv.max=', 238.15199999999999, 'yuv.min=', -43.760440000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -46.705549999999988)
('yuv.max=', 251.43199999999996, 'yuv.min=', -24.095379999999995)
('yuv.max=', 234.05799999999999, 'yuv.min=', -31.605269999999997)
('yuv.max=', 226.12799999999999, 'yuv.min=', -41.425759999999997)
('yuv.max=', 207.92899999999997, 'yuv.min=', -32.452109999999998)
('yuv.max=', 199.352, 'yuv.min=', -60.235549999999996)
('yuv.max=', 247.02599999999998, 'yuv.min=', -35.210049999999995)
('yuv.max=', 237.07499999999999, 'yuv.min=', -49.520769999999999)
('yuv.max=', 222.78899999999999, 'yuv.min=', -40.28446000000001)
('yuv.max=', 250.57599999999996, 'yuv.min=', -36.595399999999984)
('yuv.max=', 233.92100000000002, 'yuv.min=', -11.340150000000001)
('yuv.max=', 255.0, 'yuv.min=', -42.970730000000003)
('yuv.max=', 216.01900000000001, 'yuv.min=', -26.425489999999986)
('yuv.max=', 235.62699999999998, 'yuv.min=', -39.065770000000001)
('yuv.max=', 237.017, 'yuv.min=', -54.160249999999984)
('yuv.max=', 253.80399999999997, 'yuv.min=', -24.713659999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 219.99099999999999, 'yuv.min=', -45.43072999999999)
('yuv.max=', 232.04299999999998, 'yuv.min=', -54.555719999999994)
('yuv.max=', 234.339, 'yuv.min=', -36.955189999999995)
('yuv.max=', 240.97799999999998, 'yuv.min=', -30.899399999999996)
('yuv.max=', 226.04000000000002, 'yuv.min=', -25.925439999999995)
('yuv.max=', 240.70599999999999, 'yuv.min=', -26.125459999999993)
('yuv.max=', 226.06099999999998, 'yuv.min=', -16.545239999999993)
('yuv.max=', 211.41, 'yuv.min=', -46.735429999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.550179999999997)
('yuv.max=', 201.21199999999999, 'yuv.min=', -19.505289999999984)
('yuv.max=', 226.12499999999997, 'yuv.min=', -42.945419999999999)
('yuv.max=', 243.60399999999998, 'yuv.min=', -50.83466)
('yuv.max=', 169.40899999999999, 'yuv.min=', -18.420120000000001)
('yuv.max=', 188.97699999999998, 'yuv.min=', -22.55594)
('yuv.max=', 247.90099999999998, 'yuv.min=', -15.573870000000005)
('yuv.max=', 148.98099999999999, 'yuv.min=', -38.625479999999989)
('yuv.max=', 253.13099999999997, 'yuv.min=', -72.320589999999996)
('yuv.max=', 255.0, 'yuv.min=', -66.62581999999999)
('yuv.max=', 251.15300000000002, 'yuv.min=', -57.767539999999997)
('yuv.max=', 225.15999999999997, 'yuv.min=', -44.375439999999998)
('yuv.max=', 252.114, 'yuv.min=', -15.273999999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -74.105829999999997)
('yuv.max=', 207.76299999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 255.0, 'yuv.min=', -59.941860000000005)
('yuv.max=', 250.173, 'yuv.min=', -85.844790000000003)
('yuv.max=', 236.39699999999999, 'yuv.min=', -17.030349999999991)
('yuv.max=', 201.03499999999997, 'yuv.min=', -42.905820000000006)
('yuv.max=', 228.673, 'yuv.min=', -30.396080000000001)
('yuv.max=', 250.54399999999998, 'yuv.min=', -11.819020000000009)
('yuv.max=', 255.0, 'yuv.min=', -16.415349999999986)
('yuv.max=', 199.96600000000001, 'yuv.min=', -53.225709999999992)
('yuv.max=', 254.886, 'yuv.min=', -33.536689999999993)
('yuv.max=', 160.44900000000001, 'yuv.min=', -23.525199999999998)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.38091)
('yuv.max=', 225.28800000000001, 'yuv.min=', -16.900459999999992)
('yuv.max=', 228.64399999999998, 'yuv.min=', -35.270210000000006)
('yuv.max=', 250.25600000000003, 'yuv.min=', -60.740169999999999)
('yuv.max=', 189.08799999999997, 'yuv.min=', -18.105149999999995)
('yuv.max=', 237.42399999999998, 'yuv.min=', -11.498360000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.291240000000002)
('yuv.max=', 249.94, 'yuv.min=', -46.171590000000002)
('yuv.max=', 215.03199999999998, 'yuv.min=', -20.220299999999998)
('yuv.max=', 245.23199999999997, 'yuv.min=', -105.33056999999999)
('yuv.max=', 146.07300000000001, 'yuv.min=', -29.015379999999993)
('yuv.max=', 197.816, 'yuv.min=', -48.114050000000006)
('yuv.max=', 217.40200000000002, 'yuv.min=', -12.800049999999999)
('yuv.max=', 194.13399999999999, 'yuv.min=', -7.2604800000000012)
('yuv.max=', 251.44099999999997, 'yuv.min=', -50.175939999999997)
('yuv.max=', 245.88800000000001, 'yuv.min=', -57.820369999999983)
('yuv.max=', 237.76999999999998, 'yuv.min=', -37.390909999999991)
('yuv.max=', 216.08199999999999, 'yuv.min=', -36.301540000000003)
('yuv.max=', 202.63999999999999, 'yuv.min=', -17.305069999999986)
('yuv.max=', 248.87, 'yuv.min=', -39.166550000000008)
('yuv.max=', 224.05999999999997, 'yuv.min=', -41.795919999999995)
('yuv.max=', 250.184, 'yuv.min=', -20.756979999999999)
('yuv.max=', 181.328, 'yuv.min=', -25.450699999999991)
('yuv.max=', 202.03699999999998, 'yuv.min=', -32.720320000000001)
('yuv.max=', 249.65099999999995, 'yuv.min=', -67.030429999999996)
('yuv.max=', 249.673, 'yuv.min=', -16.63030999999998)
('yuv.max=', 223.15699999999998, 'yuv.min=', -11.351650000000001)
('yuv.max=', 230.99599999999995, 'yuv.min=', -22.197140000000001)
('yuv.max=', 242.33500000000001, 'yuv.min=', -21.220399999999991)
('yuv.max=', 248.0, 'yuv.min=', -21.825860000000002)
('yuv.max=', 239.03199999999998, 'yuv.min=', -26.785279999999993)
('yuv.max=', 254.10300000000001, 'yuv.min=', -24.153020000000001)
('yuv.max=', 138.221, 'yuv.min=', -12.185049999999995)
('yuv.max=', 242.96399999999997, 'yuv.min=', -41.090990000000005)
('yuv.max=', 247.07999999999998, 'yuv.min=', -55.315549999999988)
('yuv.max=', 237.672, 'yuv.min=', -79.066020000000009)
('yuv.max=', 243.89899999999997, 'yuv.min=', -72.466099999999997)
('yuv.max=', 247.88600000000002, 'yuv.min=', -26.600200000000001)
('yuv.max=', 249.756, 'yuv.min=', -20.053450000000012)
('yuv.max=', 221.25799999999998, 'yuv.min=', -59.463140000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -25.555279999999996)
('yuv.max=', 209.22299999999998, 'yuv.min=', -38.753090000000007)
('yuv.max=', 212.96099999999998, 'yuv.min=', -12.523070000000001)
('yuv.max=', 254.886, 'yuv.min=', -40.61530999999998)
('yuv.max=', 252.0, 'yuv.min=', -24.403800000000004)
('yuv.max=', 215.77600000000001, 'yuv.min=', -81.375450000000001)
('yuv.max=', 195.583, 'yuv.min=', -15.930239999999996)
('yuv.max=', 235.77199999999999, 'yuv.min=', -17.390139999999995)
('yuv.max=', 248.20500000000001, 'yuv.min=', -16.790079999999996)
('yuv.max=', 253.333, 'yuv.min=', -37.125329999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 245.96100000000001, 'yuv.min=', -45.460609999999988)
('yuv.max=', 255.0, 'yuv.min=', -41.060169999999999)
('yuv.max=', 224.35500000000002, 'yuv.min=', -36.665809999999993)
('yuv.max=', 204.59100000000001, 'yuv.min=', -12.170109999999992)
('yuv.max=', 212.46099999999998, 'yuv.min=', -30.31081)
('yuv.max=', 255.0, 'yuv.min=', -18.447630000000004)
('yuv.max=', 190.399, 'yuv.min=', -23.225169999999984)
('yuv.max=', 198.13299999999998, 'yuv.min=', -28.934879999999996)
('yuv.max=', 210.83399999999997, 'yuv.min=', -55.300609999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.425219999999999)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 192.345, 'yuv.min=', -59.995279999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.095449999999985)
('yuv.max=', 244.74399999999997, 'yuv.min=', -7.1500999999999877)
('yuv.max=', 254.65800000000002, 'yuv.min=', -29.845339999999979)
('yuv.max=', 219.41300000000001, 'yuv.min=', -43.400649999999999)
('yuv.max=', 244.19399999999999, 'yuv.min=', -13.730019999999989)
('yuv.max=', 255.0, 'yuv.min=', -31.300669999999993)
('yuv.max=', 177.13299999999998, 'yuv.min=', -35.874340000000011)
('yuv.max=', 209.53100000000001, 'yuv.min=', -48.059659999999994)
('yuv.max=', 199.47599999999997, 'yuv.min=', -27.889960000000002)
('yuv.max=', 251.81499999999997, 'yuv.min=', -35.735559999999992)
('yuv.max=', 243.761, 'yuv.min=', -20.609969999999993)
('yuv.max=', 251.352, 'yuv.min=', -57.963309999999993)
('yuv.max=', 247.81499999999997, 'yuv.min=', -31.590900000000005)
('yuv.max=', 249.94599999999997, 'yuv.min=', -25.858480000000007)
('yuv.max=', 182.15199999999999, 'yuv.min=', -17.34531999999999)
('yuv.max=', 245.62799999999999, 'yuv.min=', -49.369079999999997)
('yuv.max=', 225.63799999999998, 'yuv.min=', -49.461859999999994)
('yuv.max=', 134.404, 'yuv.min=', -36.865549999999992)
('yuv.max=', 205.03899999999999, 'yuv.min=', -43.957620000000006)
('yuv.max=', 226.91799999999998, 'yuv.min=', -53.960229999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.004170000000009)
('yuv.max=', 253.56100000000001, 'yuv.min=', -36.555149999999998)
('yuv.max=', 236.70899999999997, 'yuv.min=', -16.660189999999989)
('yuv.max=', 229.10200000000003, 'yuv.min=', -36.859749999999991)
('yuv.max=', 191.18199999999999, 'yuv.min=', -16.823470000000004)
('yuv.max=', 237.98499999999999, 'yuv.min=', -23.754330000000003)
('yuv.max=', 253.989, 'yuv.min=', -17.005040000000005)
('yuv.max=', 241.10299999999998, 'yuv.min=', -21.482920000000004)
('yuv.max=', 252.89699999999999, 'yuv.min=', -62.335759999999993)
('yuv.max=', 203.98299999999998, 'yuv.min=', -9.8908999999999985)
('yuv.max=', 254.131, 'yuv.min=', -18.920169999999995)
('yuv.max=', 224.13399999999999, 'yuv.min=', -21.443060000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -28.949220000000004)
('yuv.max=', 242.30999999999997, 'yuv.min=', -14.996019999999998)
('yuv.max=', 199.12299999999999, 'yuv.min=', -35.450469999999989)
('yuv.max=', 255.0, 'yuv.min=', -32.025700000000001)
('yuv.max=', 208.35900000000001, 'yuv.min=', -12.375640000000004)
('yuv.max=', 252.42400000000001, 'yuv.min=', -37.640319999999988)
('yuv.max=', 171.369, 'yuv.min=', -32.555440000000004)
('yuv.max=', 238.85399999999998, 'yuv.min=', -44.250119999999995)
('yuv.max=', 237.89600000000002, 'yuv.min=', -31.160409999999992)
('yuv.max=', 248.83699999999999, 'yuv.min=', -29.390109999999986)
('yuv.max=', 237.70099999999999, 'yuv.min=', -53.025689999999997)
('yuv.max=', 233.38499999999999, 'yuv.min=', -21.951330000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.020379999999992)
('yuv.max=', 231.09899999999999, 'yuv.min=', -19.24721000000001)
('yuv.max=', 244.94999999999999, 'yuv.min=', -27.563830000000003)
('yuv.max=', 240.75899999999999, 'yuv.min=', -37.53573999999999)
('yuv.max=', 245.33799999999997, 'yuv.min=', -64.615249999999975)
('yuv.max=', 242.08500000000001, 'yuv.min=', -40.610739999999993)
('yuv.max=', 255.0, 'yuv.min=', -18.820160000000001)
('yuv.max=', 179.72899999999998, 'yuv.min=', -14.670359999999992)
('yuv.max=', 242.94999999999999, 'yuv.min=', -16.290029999999994)
('yuv.max=', 248.452, 'yuv.min=', -23.395420000000001)
('yuv.max=', 231.809, 'yuv.min=', -50.980669999999996)
('yuv.max=', 241.94999999999999, 'yuv.min=', -31.445499999999992)
('yuv.max=', 202.447, 'yuv.min=', -26.700209999999991)
('yuv.max=', 228.47, 'yuv.min=', -25.406829999999996)
('yuv.max=', 255.0, 'yuv.min=', -16.000369999999993)
('yuv.max=', 201.34199999999998, 'yuv.min=', -40.655559999999987)
('yuv.max=', 249.78299999999996, 'yuv.min=', -9.0181400000000096)
('yuv.max=', 225.98400000000001, 'yuv.min=', -23.869219999999999)
('yuv.max=', 245.38099999999997, 'yuv.min=', -30.419939999999997)
('yuv.max=', 211.38099999999997, 'yuv.min=', -30.785680000000003)
('yuv.max=', 253.86000000000001, 'yuv.min=', -28.760169999999984)
('yuv.max=', 221.04299999999998, 'yuv.min=', -49.240249999999989)
('yuv.max=', 224.02800000000002, 'yuv.min=', -30.78059)
('yuv.max=', 253.20599999999999, 'yuv.min=', -59.505920000000003)
('yuv.max=', 218.292, 'yuv.min=', -40.355529999999987)
('yuv.max=', 253.46199999999999, 'yuv.min=', -35.45478)
('yuv.max=', 248.875, 'yuv.min=', -8.6502499999999962)
('yuv.max=', 208.70099999999999, 'yuv.min=', -21.465239999999994)
('yuv.max=', 209.017, 'yuv.min=', -36.366260000000011)
('yuv.max=', 241.35900000000001, 'yuv.min=', -47.820599999999999)
('yuv.max=', 240.29199999999997, 'yuv.min=', -61.032060000000008)
('yuv.max=', 195.52699999999999, 'yuv.min=', -23.27478)
('yuv.max=', 186.06199999999998, 'yuv.min=', -53.576640000000005)
('yuv.max=', 243.95599999999999, 'yuv.min=', -32.035189999999993)
('yuv.max=', 198.30899999999997, 'yuv.min=', -50.425429999999992)
('yuv.max=', 224.76999999999998, 'yuv.min=', -27.370399999999989)
('yuv.max=', 255.0, 'yuv.min=', -26.185219999999994)
('yuv.max=', 230.82999999999998, 'yuv.min=', -23.61027)
('yuv.max=', 167.316, 'yuv.min=', -31.875420000000002)
('yuv.max=', 255.0, 'yuv.min=', -45.520369999999986)
('yuv.max=', 191.00199999999998, 'yuv.min=', -25.324120000000001)
('yuv.max=', 248.0, 'yuv.min=', -46.58023)
('yuv.max=', 223.05099999999999, 'yuv.min=', -27.03058)
('yuv.max=', 252.60599999999999, 'yuv.min=', -30.272710000000004)
('yuv.max=', 255.0, 'yuv.min=', -17.149979999999992)
('yuv.max=', 253.0, 'yuv.min=', -5.0050699999999892)
('yuv.max=', 204.589, 'yuv.min=', -27.608259999999994)
('yuv.max=', 255.0, 'yuv.min=', -45.990539999999996)
('yuv.max=', 202.13099999999997, 'yuv.min=', -47.99618000000001)
('yuv.max=', 249.94599999999997, 'yuv.min=', -29.526240000000001)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.7801399999999994)
('yuv.max=', 253.68999999999997, 'yuv.min=', -24.780509999999996)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.01399999999998, 'yuv.min=', -22.810189999999995)
('yuv.max=', 249.73899999999998, 'yuv.min=', -31.454620000000013)
('yuv.max=', 255.0, 'yuv.min=', -11.540169999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -14.10877)
('yuv.max=', 230.172, 'yuv.min=', -121.38489999999997)
('yuv.max=', 214.27399999999997, 'yuv.min=', -46.805559999999993)
('yuv.max=', 252.34999999999999, 'yuv.min=', -35.603620000000006)
('yuv.max=', 255.0, 'yuv.min=', -5.2050899999999984)
('yuv.max=', 254.06, 'yuv.min=', -91.470659999999995)
('yuv.max=', 176.80799999999999, 'yuv.min=', -27.230139999999999)
('yuv.max=', 238.57999999999998, 'yuv.min=', -36.05471)
('yuv.max=', 231.67199999999997, 'yuv.min=', -55.585699999999989)
('yuv.max=', 158.30799999999999, 'yuv.min=', -14.055359999999986)
('yuv.max=', 223.01599999999999, 'yuv.min=', -31.960489999999993)
('yuv.max=', 232.26599999999999, 'yuv.min=', -51.825569999999985)
('yuv.max=', 233.84899999999999, 'yuv.min=', -33.775000000000006)
('yuv.max=', 220.745, 'yuv.min=', -51.980769999999993)
('yuv.max=', 254.43000000000001, 'yuv.min=', -66.579390000000004)
('yuv.max=', 204.245, 'yuv.min=', -34.444569999999992)
('yuv.max=', 239.11099999999999, 'yuv.min=', -35.110190000000003)
('yuv.max=', 240.465, 'yuv.min=', -48.90576999999999)
('yuv.max=', 234.84700000000001, 'yuv.min=', -31.275359999999992)
('yuv.max=', 227.13699999999997, 'yuv.min=', -26.970359999999999)
('yuv.max=', 247.24999999999997, 'yuv.min=', -11.519620000000003)
('yuv.max=', 212.989, 'yuv.min=', -16.645249999999997)
('yuv.max=', 185.86699999999999, 'yuv.min=', -34.695209999999989)
('yuv.max=', 191.43699999999998, 'yuv.min=', -39.900299999999987)
('yuv.max=', 250.65199999999999, 'yuv.min=', -13.10008)
('yuv.max=', 254.35900000000001, 'yuv.min=', -2.3301300000000111)
('yuv.max=', 255.0, 'yuv.min=', -69.713619999999992)
('yuv.max=', 178.101, 'yuv.min=', -64.088970000000003)
('yuv.max=', 241.733, 'yuv.min=', -28.855369999999994)
('yuv.max=', 248.417, 'yuv.min=', -24.636569999999992)
('yuv.max=', 249.11399999999998, 'yuv.min=', -53.015320000000003)
('yuv.max=', 255.0, 'yuv.min=', -24.480479999999996)
('yuv.max=', 250.91799999999998, 'yuv.min=', -15.815289999999997)
('yuv.max=', 202.40000000000001, 'yuv.min=', -33.68016999999999)
('yuv.max=', 177.47800000000001, 'yuv.min=', -27.325579999999992)
('yuv.max=', 250.04899999999998, 'yuv.min=', -90.585509999999985)
('yuv.max=', 255.0, 'yuv.min=', -21.028380000000002)
('yuv.max=', 229.846, 'yuv.min=', -40.108849999999997)
('yuv.max=', 255.0, 'yuv.min=', -9.8399999999999928)
('yuv.max=', 195.947, 'yuv.min=', -85.273110000000003)
('yuv.max=', 236.06, 'yuv.min=', -16.215329999999994)
('yuv.max=', 215.20199999999997, 'yuv.min=', -31.580479999999994)
('yuv.max=', 231.99100000000001, 'yuv.min=', -136.18514999999999)
('yuv.max=', 221.74000000000001, 'yuv.min=', -36.410319999999999)
('yuv.max=', 255.0, 'yuv.min=', -50.176569999999998)
('yuv.max=', 233.28800000000001, 'yuv.min=', -10.825159999999991)
('yuv.max=', 209.85399999999998, 'yuv.min=', -18.380320000000005)
('yuv.max=', 219.0, 'yuv.min=', -7.0129699999999993)
('yuv.max=', 207.172, 'yuv.min=', -40.440599999999996)
('yuv.max=', 253.10299999999998, 'yuv.min=', -49.695480000000003)
('yuv.max=', 158.084, 'yuv.min=', -39.680769999999995)
('yuv.max=', 218.63, 'yuv.min=', -17.128730000000001)
('yuv.max=', 250.88599999999997, 'yuv.min=', -12.380019999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -21.275169999999999)
('yuv.max=', 242.804, 'yuv.min=', -8.3352799999999991)
('yuv.max=', 208.95099999999999, 'yuv.min=', -47.420559999999995)
('yuv.max=', 226.56599999999997, 'yuv.min=', -42.000509999999991)
('yuv.max=', 220.68099999999998, 'yuv.min=', -24.640249999999995)
('yuv.max=', 219.09400000000002, 'yuv.min=', -36.88794)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.43000000000001, 'yuv.min=', -27.420980000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.417, 'yuv.min=', -21.050259999999994)
('yuv.max=', 255.0, 'yuv.min=', -24.465540000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.585189999999997)
('yuv.max=', 217.46600000000001, 'yuv.min=', -56.050069999999991)
('yuv.max=', 239.78299999999999, 'yuv.min=', -35.569389999999999)
('yuv.max=', 206.29099999999997, 'yuv.min=', -12.640279999999997)
('yuv.max=', 250.68999999999997, 'yuv.min=', -40.100319999999982)
('yuv.max=', 214.58399999999997, 'yuv.min=', -19.090309999999999)
('yuv.max=', 241.572, 'yuv.min=', -26.225469999999994)
('yuv.max=', 225.041, 'yuv.min=', -11.202920000000006)
('yuv.max=', 251.167, 'yuv.min=', -73.496009999999998)
('yuv.max=', 254.41299999999995, 'yuv.min=', -35.199170000000009)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.230139999999992)
('yuv.max=', 205.40200000000002, 'yuv.min=', -23.259650000000001)
('yuv.max=', 255.0, 'yuv.min=', -25.025349999999996)
('yuv.max=', 251.38699999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 214.51500000000001, 'yuv.min=', -102.19577)
('yuv.max=', 241.04299999999998, 'yuv.min=', -28.579330000000006)
('yuv.max=', 255.0, 'yuv.min=', -41.160179999999997)
('yuv.max=', 249.02199999999999, 'yuv.min=', -26.900230000000001)
('yuv.max=', 253.65799999999999, 'yuv.min=', -54.745369999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.249, 'yuv.min=', -36.380439999999993)
('yuv.max=', 236.86099999999999, 'yuv.min=', -47.24584999999999)
('yuv.max=', 254.08800000000002, 'yuv.min=', -20.065099999999976)
('yuv.max=', 249.755, 'yuv.min=', -27.385339999999999)
('yuv.max=', 235.72300000000001, 'yuv.min=', -48.257460000000002)
('yuv.max=', 248.40799999999999, 'yuv.min=', -25.455269999999999)
('yuv.max=', 245.23899999999998, 'yuv.min=', -28.103980000000004)
('yuv.max=', 255.0, 'yuv.min=', -25.310439999999996)
('yuv.max=', 116.56, 'yuv.min=', -20.550460000000005)
('yuv.max=', 255.0, 'yuv.min=', -34.627420000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', -35.483240000000009)
('yuv.max=', 140.48499999999999, 'yuv.min=', -32.275459999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 215.76100000000002, 'yuv.min=', -37.514999999999986)
('yuv.max=', 254.54400000000001, 'yuv.min=', -25.700110000000002)
('yuv.max=', 246.08699999999999, 'yuv.min=', -37.655259999999998)
('yuv.max=', 205.26399999999998, 'yuv.min=', -27.674999999999979)
('yuv.max=', 189.69299999999998, 'yuv.min=', -39.493559999999988)
('yuv.max=', 255.0, 'yuv.min=', -20.98555)
('yuv.max=', 255.0, 'yuv.min=', -24.615569999999998)
('yuv.max=', 255.0, 'yuv.min=', -63.870359999999998)
('yuv.max=', 246.0, 'yuv.min=', -82.405429999999981)
('yuv.max=', 224.18899999999999, 'yuv.min=', -32.215699999999991)
('yuv.max=', 197.95899999999997, 'yuv.min=', -19.505289999999995)
('yuv.max=', 227.10299999999998, 'yuv.min=', -38.695610000000002)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 211.44800000000001, 'yuv.min=', -56.861809999999991)
('yuv.max=', 250.17899999999997, 'yuv.min=', -14.830129999999983)
('yuv.max=', 239.202, 'yuv.min=', -44.715719999999997)
('yuv.max=', 250.99999999999997, 'yuv.min=', -48.296060000000004)
('yuv.max=', 244.02499999999998, 'yuv.min=', -14.230069999999991)
('yuv.max=', 200.858, 'yuv.min=', -16.315339999999999)
('yuv.max=', 237.0, 'yuv.min=', -8.8974000000000046)
('yuv.max=', 236.31, 'yuv.min=', -14.990590000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', -9.0652299999999997)
('yuv.max=', 233.239, 'yuv.min=', -32.562389999999994)
('yuv.max=', 247.09199999999998, 'yuv.min=', -30.060299999999984)
('yuv.max=', 252.13099999999997, 'yuv.min=', -24.059770000000004)
('yuv.max=', 254.886, 'yuv.min=', -14.249650000000003)
('yuv.max=', 213.77000000000001, 'yuv.min=', -3.0749999999999975)
('yuv.max=', 255.0, 'yuv.min=', -21.683690000000006)
('yuv.max=', 203.054, 'yuv.min=', -13.84631000000001)
('yuv.max=', 242.971, 'yuv.min=', -34.320479999999989)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 198.20600000000002, 'yuv.min=', -43.031259999999996)
('yuv.max=', 243.74399999999997, 'yuv.min=', -25.470209999999987)
('yuv.max=', 206.20999999999998, 'yuv.min=', -32.460539999999995)
('yuv.max=', 224.815, 'yuv.min=', -27.210700000000003)
('yuv.max=', 225.55499999999998, 'yuv.min=', -29.715449999999986)
('yuv.max=', 255.0, 'yuv.min=', -44.949200000000005)
('yuv.max=', 249.07499999999999, 'yuv.min=', -24.175879999999999)
('yuv.max=', 214.92499999999998, 'yuv.min=', -39.180719999999994)
('yuv.max=', 217.49000000000001, 'yuv.min=', -29.990169999999992)
('yuv.max=', 247.48799999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.881, 'yuv.min=', -10.009309999999999)
('yuv.max=', 198.29900000000001, 'yuv.min=', -1.4548100000000002)
('yuv.max=', 251.13099999999997, 'yuv.min=', -23.740159999999992)
('yuv.max=', 207.185, 'yuv.min=', -46.975699999999996)
('yuv.max=', 183.953, 'yuv.min=', -25.792839999999998)
('yuv.max=', 248.88599999999997, 'yuv.min=', -33.97984000000001)
('yuv.max=', 193.27100000000002, 'yuv.min=', -12.555210000000002)
('yuv.max=', 255.0, 'yuv.min=', -51.215139999999991)
('yuv.max=', 215.74799999999999, 'yuv.min=', -24.861390000000007)
('yuv.max=', 251.42299999999997, 'yuv.min=', -52.055469999999985)
('yuv.max=', 208.24099999999999, 'yuv.min=', -25.699599999999997)
('yuv.max=', 203.80800000000002, 'yuv.min=', -19.737380000000002)
('yuv.max=', 221.82499999999996, 'yuv.min=', -83.621980000000008)
('yuv.max=', 214.09599999999998, 'yuv.min=', -35.657510000000002)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 230.93499999999997, 'yuv.min=', -31.586170000000003)
('yuv.max=', 213.97200000000001, 'yuv.min=', -23.33098)
('yuv.max=', 229.09699999999998, 'yuv.min=', -31.900729999999992)
('yuv.max=', 211.994, 'yuv.min=', -17.834999999999997)
('yuv.max=', 248.69, 'yuv.min=', -25.010409999999982)
('yuv.max=', 254.65800000000002, 'yuv.min=', -18.763080000000006)
('yuv.max=', 188.14699999999999, 'yuv.min=', -83.234769999999997)
('yuv.max=', 237.40499999999997, 'yuv.min=', -15.900980000000004)
('yuv.max=', 188.94399999999999, 'yuv.min=', -25.755299999999995)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.19600000000003, 'yuv.min=', -34.050329999999988)
('yuv.max=', 252.114, 'yuv.min=', -11.05505999999999)
('yuv.max=', 252.77199999999999, 'yuv.min=', -4.6900999999999993)
('yuv.max=', 226.96099999999998, 'yuv.min=', -26.883729999999996)
('yuv.max=', 239.71699999999998, 'yuv.min=', -26.710579999999997)
('yuv.max=', 235.99999999999997, 'yuv.min=', -20.065100000000001)
('yuv.max=', 167.50299999999999, 'yuv.min=', -53.085449999999994)
('yuv.max=', 247.71199999999999, 'yuv.min=', -41.960259999999991)
('yuv.max=', 251.44499999999996, 'yuv.min=', -71.910179999999983)
('yuv.max=', 242.90299999999999, 'yuv.min=', -21.395090000000003)
('yuv.max=', 230.67999999999998, 'yuv.min=', -21.18014999999999)
('yuv.max=', 95.341999999999985, 'yuv.min=', -11.970089999999997)
('yuv.max=', 168.55099999999999, 'yuv.min=', -16.990140000000004)
('yuv.max=', 221.435, 'yuv.min=', -12.10193000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.175049999999992)
('yuv.max=', 255.0, 'yuv.min=', -25.585159999999995)
('yuv.max=', 220.02799999999996, 'yuv.min=', -21.74324)
('yuv.max=', 228.31799999999998, 'yuv.min=', -48.942760000000007)
('yuv.max=', 203.78899999999999, 'yuv.min=', -11.242189999999997)
('yuv.max=', 214.84299999999999, 'yuv.min=', -21.150269999999995)
('yuv.max=', 214.761, 'yuv.min=', -68.520200000000003)
('yuv.max=', 229.78100000000001, 'yuv.min=', -29.837109999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -40.940650000000005)
('yuv.max=', 255.0, 'yuv.min=', -36.829210000000003)
('yuv.max=', 255.0, 'yuv.min=', -38.73575000000001)
('yuv.max=', 221.55799999999999, 'yuv.min=', -44.866780000000013)
('yuv.max=', 252.64099999999996, 'yuv.min=', -11.64017999999999)
('yuv.max=', 233.62299999999999, 'yuv.min=', -34.069070000000004)
('yuv.max=', 243.79300000000001, 'yuv.min=', -16.16919)
('yuv.max=', 240.24299999999999, 'yuv.min=', -72.117450000000005)
('yuv.max=', 243.74499999999998, 'yuv.min=', -30.22007)
('yuv.max=', 198.64299999999997, 'yuv.min=', -23.803490000000007)
('yuv.max=', 223.26399999999998, 'yuv.min=', -16.34521999999998)
('yuv.max=', 158.14100000000002, 'yuv.min=', -63.520939999999982)
('yuv.max=', 254.70099999999999, 'yuv.min=', -47.595269999999985)
('yuv.max=', 119.67999999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 218.614, 'yuv.min=', -22.582380000000001)
('yuv.max=', 241.434, 'yuv.min=', -46.815929999999994)
('yuv.max=', 194.97099999999998, 'yuv.min=', -59.610179999999993)
('yuv.max=', 231.15799999999999, 'yuv.min=', -23.002180000000003)
('yuv.max=', 254.58699999999999, 'yuv.min=', -32.391390000000001)
('yuv.max=', 195.83999999999997, 'yuv.min=', -23.425189999999997)
('yuv.max=', 235.25999999999999, 'yuv.min=', -47.85047999999999)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 167.84399999999999, 'yuv.min=', -40.827600000000004)
('yuv.max=', 255.0, 'yuv.min=', -27.315209999999993)
('yuv.max=', 246.00399999999999, 'yuv.min=', -31.075339999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.315609999999992)
('yuv.max=', 248.28799999999995, 'yuv.min=', -91.615489999999994)
('yuv.max=', 236.79799999999997, 'yuv.min=', -52.455509999999997)
('yuv.max=', 228.40099999999998, 'yuv.min=', -23.799210000000006)
('yuv.max=', 211.42600000000002, 'yuv.min=', -52.030159999999995)
('yuv.max=', 183.46699999999998, 'yuv.min=', -25.720849999999999)
('yuv.max=', 253.70099999999996, 'yuv.min=', -82.576149999999998)
('yuv.max=', 252.24499999999998, 'yuv.min=', -7.361679999999998)
('yuv.max=', 241.93999999999997, 'yuv.min=', -44.875489999999999)
('yuv.max=', 245.48400000000001, 'yuv.min=', -9.9951999999999828)
('yuv.max=', 224.95699999999999, 'yuv.min=', -58.475619999999999)
('yuv.max=', 238.798, 'yuv.min=', -32.375469999999993)
('yuv.max=', 244.572, 'yuv.min=', -48.580429999999993)
('yuv.max=', 255.0, 'yuv.min=', -46.55034999999998)
('yuv.max=', 174.01899999999998, 'yuv.min=', -24.610369999999996)
('yuv.max=', 203.38099999999997, 'yuv.min=', -17.264970000000002)
('yuv.max=', 252.57199999999997, 'yuv.min=', -20.305369999999993)
('yuv.max=', 175.90200000000002, 'yuv.min=', -21.165210000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.63777)
('yuv.max=', 254.886, 'yuv.min=', -9.8354299999999988)
('yuv.max=', 242.54900000000001, 'yuv.min=', -29.057770000000005)
('yuv.max=', 181.06, 'yuv.min=', -15.785409999999995)
('yuv.max=', 192.54199999999997, 'yuv.min=', -40.470479999999995)
('yuv.max=', 215.53899999999999, 'yuv.min=', -62.650729999999982)
('yuv.max=', 226.28600000000003, 'yuv.min=', -24.46553999999999)
('yuv.max=', 243.31799999999998, 'yuv.min=', -27.760069999999992)
('yuv.max=', 210.52499999999998, 'yuv.min=', -39.40025)
('yuv.max=', 226.36700000000002, 'yuv.min=', -32.705379999999991)
('yuv.max=', 236.89999999999998, 'yuv.min=', -42.270659999999992)
('yuv.max=', 222.99199999999996, 'yuv.min=', -2.7152099999999884)
('yuv.max=', 253.99999999999997, 'yuv.min=', -0.61499999999999932)
('yuv.max=', 231.14399999999995, 'yuv.min=', -56.420229999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.770820000000001)
('yuv.max=', 210.72199999999998, 'yuv.min=', -39.910669999999996)
('yuv.max=', 239.71799999999999, 'yuv.min=', -35.335519999999988)
('yuv.max=', 175.09199999999998, 'yuv.min=', -39.325549999999993)
('yuv.max=', 218.126, 'yuv.min=', -56.985839999999996)
('yuv.max=', 234.38499999999999, 'yuv.min=', -10.757100000000001)
('yuv.max=', 255.0, 'yuv.min=', -32.4148)
('yuv.max=', 250.88599999999997, 'yuv.min=', -19.250080000000001)
('yuv.max=', 186.22999999999999, 'yuv.min=', -20.720349999999982)
('yuv.max=', 227.13000000000002, 'yuv.min=', -25.825429999999997)
('yuv.max=', 255.0, 'yuv.min=', -80.890340000000009)
('yuv.max=', 194.72999999999999, 'yuv.min=', -31.015579999999996)
('yuv.max=', 216.62700000000001, 'yuv.min=', -25.296990000000008)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.58699999999996, 'yuv.min=', -62.07893)
('yuv.max=', 248.84700000000001, 'yuv.min=', -18.30516999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.754650000000005)
('yuv.max=', 192.50300000000001, 'yuv.min=', -8.8801499999999916)
('yuv.max=', 162.23500000000001, 'yuv.min=', -37.065569999999994)
('yuv.max=', 161.29900000000001, 'yuv.min=', -16.347740000000009)
('yuv.max=', 255.0, 'yuv.min=', -51.255389999999991)
('yuv.max=', 232.24600000000001, 'yuv.min=', -83.475660000000005)
('yuv.max=', 252.13299999999995, 'yuv.min=', -35.498530000000002)
('yuv.max=', 207.90099999999998, 'yuv.min=', -18.390239999999995)
('yuv.max=', 207.61099999999999, 'yuv.min=', -28.604199999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.39692999999999)
('yuv.max=', 248.83599999999998, 'yuv.min=', -17.705109999999998)
('yuv.max=', 250.20699999999997, 'yuv.min=', -18.228649999999998)
('yuv.max=', 252.83199999999997, 'yuv.min=', -27.084099999999999)
('yuv.max=', 208.76499999999999, 'yuv.min=', -44.502559999999995)
('yuv.max=', 239.387, 'yuv.min=', -25.455269999999992)
('yuv.max=', 229.74099999999999, 'yuv.min=', -29.478240000000007)
('yuv.max=', 184.374, 'yuv.min=', -35.62518)
('yuv.max=', 166.49200000000002, 'yuv.min=', -19.090309999999988)
('yuv.max=', 243.18800000000002, 'yuv.min=', -37.480549999999994)
('yuv.max=', 229.10599999999999, 'yuv.min=', -2.7061399999999907)
('yuv.max=', 255.0, 'yuv.min=', -3.6900000000000013)
('yuv.max=', 226.83699999999996, 'yuv.min=', -31.775409999999997)
('yuv.max=', 173.22799999999998, 'yuv.min=', -15.230169999999996)
('yuv.max=', 238.72899999999998, 'yuv.min=', -12.099979999999999)
('yuv.max=', 250.22800000000001, 'yuv.min=', -26.830100000000002)
('yuv.max=', 251.64099999999999, 'yuv.min=', -30.805190000000003)
('yuv.max=', 247.70099999999996, 'yuv.min=', -24.540239999999994)
('yuv.max=', 220.31099999999998, 'yuv.min=', -26.025449999999996)
('yuv.max=', 205.762, 'yuv.min=', -92.537850000000006)
('yuv.max=', 255.0, 'yuv.min=', -2.0303200000000032)
('yuv.max=', 234.0, 'yuv.min=', -35.950519999999997)
('yuv.max=', 235.22399999999999, 'yuv.min=', -55.091609999999996)
('yuv.max=', 255.0, 'yuv.min=', -18.160339999999998)
('yuv.max=', 237.85299999999998, 'yuv.min=', -18.500509999999998)
('yuv.max=', 252.92899999999997, 'yuv.min=', -17.905129999999993)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84599999999998, 'yuv.min=', -13.982730000000004)
('yuv.max=', 208.76299999999998, 'yuv.min=', -10.210160000000002)
('yuv.max=', 242.786, 'yuv.min=', -30.875319999999991)
('yuv.max=', 251.83700000000002, 'yuv.min=', -89.14054999999999)
('yuv.max=', 222.547, 'yuv.min=', -36.270059999999994)
('yuv.max=', 235.09599999999998, 'yuv.min=', -50.385179999999991)
('yuv.max=', 238.42099999999999, 'yuv.min=', -31.090279999999993)
('yuv.max=', 230.27099999999999, 'yuv.min=', -57.690479999999994)
('yuv.max=', 231.46699999999998, 'yuv.min=', -2.7600300000000075)
('yuv.max=', 233.78299999999999, 'yuv.min=', -92.845489999999998)
('yuv.max=', 253.80399999999997, 'yuv.min=', -23.727670000000007)
('yuv.max=', 240.99999999999997, 'yuv.min=', -7.0949099999999961)
('yuv.max=', 205.61899999999997, 'yuv.min=', -23.625209999999999)
('yuv.max=', 247.77599999999998, 'yuv.min=', -64.080749999999995)
('yuv.max=', 177.30099999999999, 'yuv.min=', -21.786459999999998)
('yuv.max=', 250.114, 'yuv.min=', -9.5951599999999946)
('yuv.max=', 208.999, 'yuv.min=', -27.970459999999992)
('yuv.max=', 255.0, 'yuv.min=', -21.805519999999987)
('yuv.max=', 255.0, 'yuv.min=', -21.007620000000003)
('yuv.max=', 246.80399999999997, 'yuv.min=', -105.67542)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 222.23099999999999, 'yuv.min=', -22.665200000000006)
('yuv.max=', 216.10299999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 242.61000000000001, 'yuv.min=', -51.722690000000007)
('yuv.max=', 210.90100000000001, 'yuv.min=', -57.550280000000001)
('yuv.max=', 201.86199999999997, 'yuv.min=', -15.030149999999985)
('yuv.max=', 247.11399999999998, 'yuv.min=', -23.71114)
('yuv.max=', 248.28799999999995, 'yuv.min=', -17.015409999999996)
('yuv.max=', 255.0, 'yuv.min=', -11.140129999999996)
('yuv.max=', 234.95999999999998, 'yuv.min=', -20.750229999999991)
('yuv.max=', 220.93700000000001, 'yuv.min=', -9.5845700000000136)
('yuv.max=', 210.768, 'yuv.min=', -39.401679999999999)
('yuv.max=', 234.10900000000001, 'yuv.min=', -21.825219999999995)
('yuv.max=', 255.0, 'yuv.min=', -35.983349999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -15.678830000000001)
('yuv.max=', 255.0, 'yuv.min=', -22.56609000000001)
('yuv.max=', 228.08899999999997, 'yuv.min=', -19.682410000000001)
('yuv.max=', 255.0, 'yuv.min=', -75.343700000000013)
('yuv.max=', 249.00999999999999, 'yuv.min=', -42.044029999999999)
('yuv.max=', 231.226, 'yuv.min=', -20.000769999999999)
('yuv.max=', 237.90299999999999, 'yuv.min=', -32.637770000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', -62.710270000000001)
('yuv.max=', 253.505, 'yuv.min=', -56.25009)
('yuv.max=', 255.0, 'yuv.min=', -23.455069999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', -21.956730000000004)
('yuv.max=', 215.09099999999998, 'yuv.min=', -54.425830000000005)
('yuv.max=', 237.14599999999996, 'yuv.min=', -13.961760000000002)
('yuv.max=', 255.0, 'yuv.min=', -31.260419999999996)
('yuv.max=', 246.0, 'yuv.min=', -7.2693399999999997)
('yuv.max=', 221.21800000000002, 'yuv.min=', -32.484780000000001)
('yuv.max=', 207.78299999999999, 'yuv.min=', -66.200469999999996)
('yuv.max=', 198.43000000000001, 'yuv.min=', -43.945519999999988)
('yuv.max=', 255.0, 'yuv.min=', -82.120339999999999)
('yuv.max=', 255.0, 'yuv.min=', -80.934670000000011)
('yuv.max=', 250.79300000000001, 'yuv.min=', -21.911730000000006)
('yuv.max=', 250.626, 'yuv.min=', -4.9528099999999995)
('yuv.max=', 237.71599999999998, 'yuv.min=', -47.905670000000001)
('yuv.max=', 230.28100000000001, 'yuv.min=', -49.535709999999995)
('yuv.max=', 255.0, 'yuv.min=', -40.659520000000001)
('yuv.max=', 192.69999999999999, 'yuv.min=', -24.843289999999996)
('yuv.max=', 246.12300000000002, 'yuv.min=', -46.630849999999995)
('yuv.max=', 240.47399999999999, 'yuv.min=', -24.195389999999996)
('yuv.max=', 187.80799999999999, 'yuv.min=', -34.205529999999982)
('yuv.max=', 251.495, 'yuv.min=', -27.095349999999996)
('yuv.max=', 232.45599999999999, 'yuv.min=', -12.870179999999991)
('yuv.max=', 159.16299999999998, 'yuv.min=', -13.613679999999999)
('yuv.max=', 227.822, 'yuv.min=', -26.65352)
('yuv.max=', 240.31599999999997, 'yuv.min=', -38.925509999999996)
('yuv.max=', 231.267, 'yuv.min=', -36.910369999999993)
('yuv.max=', 234.19999999999999, 'yuv.min=', -11.980460000000001)
('yuv.max=', 255.0, 'yuv.min=', -15.084649999999996)
('yuv.max=', 247.86499999999998, 'yuv.min=', -28.200359999999989)
('yuv.max=', 218.69, 'yuv.min=', -79.255729999999986)
('yuv.max=', 203.42099999999999, 'yuv.min=', -56.930649999999986)
('yuv.max=', 255.0, 'yuv.min=', -17.305069999999994)
('yuv.max=', 231.43099999999998, 'yuv.min=', -53.854680000000002)
('yuv.max=', 228.85399999999998, 'yuv.min=', -14.56635)
('yuv.max=', 246.28299999999999, 'yuv.min=', -46.285999999999994)
('yuv.max=', 255.0, 'yuv.min=', -20.947890000000001)
('yuv.max=', 241.91399999999999, 'yuv.min=', -20.196830000000002)
('yuv.max=', 242.96099999999996, 'yuv.min=', -17.034160000000014)
('yuv.max=', 240.078, 'yuv.min=', -20.606180000000002)
('yuv.max=', 164.0, 'yuv.min=', -27.685369999999999)
('yuv.max=', 197.74000000000001, 'yuv.min=', -50.970880000000001)
('yuv.max=', 252.28800000000001, 'yuv.min=', -64.625619999999998)
('yuv.max=', 148.01100000000002, 'yuv.min=', -62.520839999999993)
('yuv.max=', 253.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 204.18499999999997, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 255.0, 'yuv.min=', -23.312470000000005)
('yuv.max=', 176.285, 'yuv.min=', -13.819589999999998)
('yuv.max=', 237.70899999999997, 'yuv.min=', -24.265519999999999)
('yuv.max=', 255.0, 'yuv.min=', -67.200569999999985)
('yuv.max=', 255.0, 'yuv.min=', -78.530349999999984)
('yuv.max=', 237.13800000000001, 'yuv.min=', -21.705509999999997)
('yuv.max=', 240.54399999999998, 'yuv.min=', -33.402120000000011)
('yuv.max=', 234.834, 'yuv.min=', -54.132079999999995)
('yuv.max=', 174.95000000000002, 'yuv.min=', -25.240309999999994)
('yuv.max=', 240.22799999999998, 'yuv.min=', -53.009519999999995)
('yuv.max=', 233.32500000000002, 'yuv.min=', -95.998800000000017)
('yuv.max=', 250.83599999999998, 'yuv.min=', -63.125469999999993)
('yuv.max=', 175.79599999999996, 'yuv.min=', -35.679470000000002)
('yuv.max=', 237.32499999999999, 'yuv.min=', -34.950420000000001)
('yuv.max=', 239.95699999999999, 'yuv.min=', -32.485489999999999)
('yuv.max=', 177.45099999999999, 'yuv.min=', -33.860679999999988)
('yuv.max=', 210.05199999999999, 'yuv.min=', -24.350589999999997)
('yuv.max=', 234.31, 'yuv.min=', -29.970659999999992)
('yuv.max=', 146.08699999999999, 'yuv.min=', -15.130159999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', -24.295399999999994)
('yuv.max=', 245.65799999999999, 'yuv.min=', -25.255249999999986)
('yuv.max=', 244.08799999999999, 'yuv.min=', -16.162709999999997)
('yuv.max=', 205.91199999999998, 'yuv.min=', -60.672219999999996)
('yuv.max=', 229.58000000000001, 'yuv.min=', -48.550549999999987)
('yuv.max=', 195.61299999999997, 'yuv.min=', -44.080800000000004)
('yuv.max=', 255.0, 'yuv.min=', -26.883890000000001)
('yuv.max=', 229.97899999999996, 'yuv.min=', -39.555449999999986)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.45799999999997, 'yuv.min=', -35.825199999999981)
('yuv.max=', 244.18899999999999, 'yuv.min=', -31.660459999999983)
('yuv.max=', 240.43999999999997, 'yuv.min=', -44.575459999999993)
('yuv.max=', 213.31700000000001, 'yuv.min=', -25.855309999999978)
('yuv.max=', 243.72199999999998, 'yuv.min=', -39.040459999999996)
('yuv.max=', 118.56299999999999, 'yuv.min=', -26.695639999999997)
('yuv.max=', 229.92299999999997, 'yuv.min=', -45.346450000000004)
('yuv.max=', 184.68800000000002, 'yuv.min=', -63.565759999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 248.24699999999999, 'yuv.min=', -51.395649999999989)
('yuv.max=', 227.755, 'yuv.min=', -11.770069999999993)
('yuv.max=', 216.37, 'yuv.min=', -24.310339999999989)
('yuv.max=', 236.334, 'yuv.min=', -46.671099999999996)
('yuv.max=', 255.0, 'yuv.min=', -42.839770000000001)
('yuv.max=', 227.09799999999998, 'yuv.min=', -52.640589999999996)
('yuv.max=', 212.44399999999999, 'yuv.min=', -22.465339999999991)
('yuv.max=', 239.131, 'yuv.min=', -19.640340000000002)
('yuv.max=', 186.58099999999999, 'yuv.min=', -36.880489999999988)
('yuv.max=', 217.32900000000001, 'yuv.min=', -34.105519999999999)
('yuv.max=', 212.661, 'yuv.min=', -30.49021999999999)
('yuv.max=', 233.35499999999999, 'yuv.min=', -16.000369999999997)
('yuv.max=', 237.86099999999999, 'yuv.min=', -75.274839999999998)
('yuv.max=', 154.42099999999999, 'yuv.min=', -68.936419999999998)
('yuv.max=', 184.024, 'yuv.min=', -15.985429999999994)
('yuv.max=', 247.548, 'yuv.min=', -50.980669999999996)
('yuv.max=', 252.81499999999997, 'yuv.min=', -76.325559999999996)
('yuv.max=', 192.34399999999999, 'yuv.min=', -38.225439999999999)
('yuv.max=', 233.55599999999998, 'yuv.min=', -35.880390000000006)
('yuv.max=', 252.77199999999999, 'yuv.min=', -29.363389999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 235.33199999999999, 'yuv.min=', -11.440159999999995)
('yuv.max=', 214.13499999999999, 'yuv.min=', -29.715450000000004)
('yuv.max=', 252.92899999999997, 'yuv.min=', -19.675429999999995)
('yuv.max=', 255.0, 'yuv.min=', -6.4603999999999964)
('yuv.max=', 255.0, 'yuv.min=', -33.503309999999999)
('yuv.max=', 248.768, 'yuv.min=', -15.51361)
('yuv.max=', 220.91799999999998, 'yuv.min=', -14.600229999999998)
('yuv.max=', 252.821, 'yuv.min=', -46.442160000000015)
('yuv.max=', 240.071, 'yuv.min=', -153.73505999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.440340000000006)
('yuv.max=', 236.05799999999999, 'yuv.min=', -39.700279999999992)
('yuv.max=', 243.89699999999999, 'yuv.min=', -39.079479999999997)
('yuv.max=', 255.0, 'yuv.min=', -28.4452)
('yuv.max=', 221.86499999999998, 'yuv.min=', -21.820239999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.245729999999995)
('yuv.max=', 248.441, 'yuv.min=', -20.350189999999984)
('yuv.max=', 152.14999999999998, 'yuv.min=', -41.97063)
('yuv.max=', 213.75099999999998, 'yuv.min=', -10.772530000000003)
('yuv.max=', 252.886, 'yuv.min=', -9.9114700000000084)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 177.27200000000002, 'yuv.min=', -45.915839999999989)
('yuv.max=', 255.0, 'yuv.min=', -8.6908999999999992)
('yuv.max=', 195.68199999999999, 'yuv.min=', -48.850579999999979)
('yuv.max=', 231.15100000000001, 'yuv.min=', -21.132609999999993)
('yuv.max=', 242.33500000000001, 'yuv.min=', -32.19653000000001)
('yuv.max=', 250.59800000000001, 'yuv.min=', -17.160239999999988)
('yuv.max=', 254.08800000000002, 'yuv.min=', -18.337799999999994)
('yuv.max=', 205.11499999999998, 'yuv.min=', -30.84544)
('yuv.max=', 248.61499999999998, 'yuv.min=', -28.946640000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.348189999999999)
('yuv.max=', 222.04299999999998, 'yuv.min=', -24.120450000000002)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -10.969989999999989)
('yuv.max=', 210.31, 'yuv.min=', -15.41525)
('yuv.max=', 214.54599999999999, 'yuv.min=', -25.45496)
('yuv.max=', 255.0, 'yuv.min=', -20.520329999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 188.90799999999999, 'yuv.min=', -37.520799999999994)
('yuv.max=', 193.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 229.89099999999996, 'yuv.min=', -27.270389999999992)
('yuv.max=', 245.869, 'yuv.min=', -87.940429999999992)
('yuv.max=', 243.76199999999997, 'yuv.min=', -90.19999)
('yuv.max=', 236.232, 'yuv.min=', -40.900399999999991)
('yuv.max=', 233.96799999999999, 'yuv.min=', -26.998149999999995)
('yuv.max=', 248.35900000000001, 'yuv.min=', -31.532420000000005)
('yuv.max=', 255.0, 'yuv.min=', -73.335629999999995)
('yuv.max=', 255.0, 'yuv.min=', -25.740359999999992)
('yuv.max=', 229.07999999999998, 'yuv.min=', -66.015389999999996)
('yuv.max=', 233.95899999999997, 'yuv.min=', -21.852769999999996)
('yuv.max=', 200.11599999999999, 'yuv.min=', -18.953469999999999)
('yuv.max=', 254.28799999999998, 'yuv.min=', -7.4259899999999988)
('yuv.max=', 255.0, 'yuv.min=', -29.75569999999999)
('yuv.max=', 225.91800000000001, 'yuv.min=', -46.84581)
('yuv.max=', 254.40199999999999, 'yuv.min=', -33.320379999999993)
('yuv.max=', 251.989, 'yuv.min=', -27.955519999999993)
('yuv.max=', 181.37, 'yuv.min=', -4.9634300000000025)
('yuv.max=', 255.0, 'yuv.min=', -2.0304700000000224)
('yuv.max=', 238.64999999999998, 'yuv.min=', -69.190399999999997)
('yuv.max=', 197.06199999999998, 'yuv.min=', -51.395649999999989)
('yuv.max=', 240.869, 'yuv.min=', -25.035720000000001)
('yuv.max=', 242.71199999999999, 'yuv.min=', -95.590579999999989)
('yuv.max=', 254.017, 'yuv.min=', -21.390539999999994)
('yuv.max=', 246.98899999999998, 'yuv.min=', -30.160310000000003)
('yuv.max=', 248.131, 'yuv.min=', -38.385209999999987)
('yuv.max=', 226.72899999999998, 'yuv.min=', -7.9651199999999989)
('yuv.max=', 246.21699999999998, 'yuv.min=', -12.770169999999997)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.637, 'yuv.min=', -27.120989999999992)
('yuv.max=', 253.42999999999998, 'yuv.min=', -40.240579999999994)
('yuv.max=', 241.61200000000002, 'yuv.min=', -41.31537999999999)
('yuv.max=', 244.148, 'yuv.min=', -54.620049999999999)
('yuv.max=', 225.31799999999998, 'yuv.min=', -89.34057)
('yuv.max=', 249.79299999999998, 'yuv.min=', -98.365549999999999)
('yuv.max=', 220.47300000000001, 'yuv.min=', -23.795349999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -42.355729999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.34541999999999)
('yuv.max=', 224.30500000000001, 'yuv.min=', -16.504989999999999)
('yuv.max=', 208.739, 'yuv.min=', -29.579950000000004)
('yuv.max=', 250.98899999999998, 'yuv.min=', -69.375479999999996)
('yuv.max=', 236.31699999999998, 'yuv.min=', -41.015349999999991)
('yuv.max=', 220.572, 'yuv.min=', -5.3826099999999997)
('yuv.max=', 230.65699999999998, 'yuv.min=', -45.790519999999987)
('yuv.max=', 208.672, 'yuv.min=', -43.298850000000002)
('yuv.max=', 143.49199999999999, 'yuv.min=', -32.723190000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.01900000000001, 'yuv.min=', -30.530470000000001)
('yuv.max=', 247.95099999999996, 'yuv.min=', -38.556370000000008)
('yuv.max=', 185.62799999999999, 'yuv.min=', -24.675069999999998)
('yuv.max=', 248.76100000000002, 'yuv.min=', -34.410119999999992)
('yuv.max=', 210.71299999999999, 'yuv.min=', -24.995470000000005)
('yuv.max=', 233.0, 'yuv.min=', -19.251970000000014)
('yuv.max=', 239.98299999999998, 'yuv.min=', -89.349589999999992)
('yuv.max=', 250.79900000000004, 'yuv.min=', -18.583770000000005)
('yuv.max=', 166.47099999999998, 'yuv.min=', -42.971200000000003)
('yuv.max=', 255.0, 'yuv.min=', -42.442900000000009)
('yuv.max=', 234.114, 'yuv.min=', -36.060850000000002)
('yuv.max=', 235.33599999999998, 'yuv.min=', -70.34602000000001)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.148, 'yuv.min=', -96.42398)
('yuv.max=', 255.0, 'yuv.min=', -18.698729999999998)
('yuv.max=', 203.63299999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 223.95899999999997, 'yuv.min=', -12.140229999999994)
('yuv.max=', 221.375, 'yuv.min=', -30.930509999999998)
('yuv.max=', 167.85599999999999, 'yuv.min=', -23.065399999999993)
('yuv.max=', 255.0, 'yuv.min=', -33.373049999999999)
('yuv.max=', 193.43199999999999, 'yuv.min=', -21.72501999999999)
('yuv.max=', 241.76299999999995, 'yuv.min=', -58.620449999999991)
('yuv.max=', 230.14399999999998, 'yuv.min=', -36.120659999999987)
('yuv.max=', 210.02499999999998, 'yuv.min=', -43.145439999999994)
('yuv.max=', 255.0, 'yuv.min=', -14.030049999999996)
('yuv.max=', 251.804, 'yuv.min=', -28.725719999999995)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -38.120859999999993)
('yuv.max=', 240.92899999999997, 'yuv.min=', -80.59720999999999)
('yuv.max=', 245.05000000000001, 'yuv.min=', -28.83029999999999)
('yuv.max=', 251.17399999999998, 'yuv.min=', -25.570220000000003)
('yuv.max=', 254.886, 'yuv.min=', -26.294689999999996)
('yuv.max=', 248.815, 'yuv.min=', -27.355459999999994)
('yuv.max=', 253.11399999999998, 'yuv.min=', -25.755299999999998)
('yuv.max=', 228.44099999999997, 'yuv.min=', -30.620109999999997)
('yuv.max=', 234.22099999999998, 'yuv.min=', -30.855809999999991)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -42.420199999999994)
('yuv.max=', 248.38499999999996, 'yuv.min=', -19.479979999999994)
('yuv.max=', 251.49000000000001, 'yuv.min=', -61.475919999999995)
('yuv.max=', 252.92899999999997, 'yuv.min=', -41.860249999999979)
('yuv.max=', 237.77199999999999, 'yuv.min=', -37.477059999999994)
('yuv.max=', 210.82699999999997, 'yuv.min=', -42.110889999999998)
('yuv.max=', 248.74399999999997, 'yuv.min=', -37.410420000000002)
('yuv.max=', 255.0, 'yuv.min=', -41.325749999999992)
('yuv.max=', 225.14600000000002, 'yuv.min=', -36.245180000000005)
('yuv.max=', 152.28399999999999, 'yuv.min=', -27.830199999999991)
('yuv.max=', 230.637, 'yuv.min=', -42.355730000000001)
('yuv.max=', 223.59999999999999, 'yuv.min=', -21.389910000000004)
('yuv.max=', 219.33800000000002, 'yuv.min=', -10.053310000000003)
('yuv.max=', 253.0, 'yuv.min=', -30.425310000000003)
('yuv.max=', 235.72300000000001, 'yuv.min=', -44.005279999999985)
('yuv.max=', 179.167, 'yuv.min=', -31.20523)
('yuv.max=', 251.92899999999995, 'yuv.min=', -21.665260000000004)
('yuv.max=', 205.76599999999999, 'yuv.min=', -13.040319999999994)
('yuv.max=', 223.08399999999997, 'yuv.min=', -17.204310000000003)
('yuv.max=', 242.74799999999996, 'yuv.min=', -26.125459999999997)
('yuv.max=', 223.71199999999999, 'yuv.min=', -51.025489999999976)
('yuv.max=', 244.423, 'yuv.min=', -24.065499999999997)
('yuv.max=', 236.423, 'yuv.min=', -42.377190000000006)
('yuv.max=', 188.0, 'yuv.min=', -44.66052999999998)
('yuv.max=', 235.30999999999997, 'yuv.min=', -92.660410000000013)
('yuv.max=', 241.92299999999997, 'yuv.min=', -50.550749999999994)
('yuv.max=', 202.834, 'yuv.min=', -33.420389999999998)
('yuv.max=', 236.36999999999995, 'yuv.min=', -76.084699999999998)
('yuv.max=', 249.48399999999998, 'yuv.min=', -26.534130000000001)
('yuv.max=', 247.38300000000001, 'yuv.min=', -48.725259999999999)
('yuv.max=', 245.505, 'yuv.min=', -26.385239999999985)
('yuv.max=', 255.0, 'yuv.min=', -67.66037)
('yuv.max=', 255.0, 'yuv.min=', -41.587699999999998)
('yuv.max=', 217.39699999999999, 'yuv.min=', -29.61544)
('yuv.max=', 206.708, 'yuv.min=', -52.530209999999997)
('yuv.max=', 211.85199999999998, 'yuv.min=', -35.860879999999995)
('yuv.max=', 211.72300000000001, 'yuv.min=', -29.024090000000008)
('yuv.max=', 232.92099999999999, 'yuv.min=', -23.55507999999999)
('yuv.max=', 214.21899999999999, 'yuv.min=', -47.001009999999987)
('yuv.max=', 244.38399999999999, 'yuv.min=', -46.805559999999993)
('yuv.max=', 229.44800000000001, 'yuv.min=', -52.21067)
('yuv.max=', 253.03399999999999, 'yuv.min=', -83.335399999999979)
('yuv.max=', 214.00899999999996, 'yuv.min=', -29.555679999999999)
('yuv.max=', 248.91800000000001, 'yuv.min=', -38.544979999999995)
('yuv.max=', 245.05000000000001, 'yuv.min=', -5.3876400000000046)
('yuv.max=', 247.06, 'yuv.min=', -14.159939999999994)
('yuv.max=', 253.27700000000002, 'yuv.min=', -19.17183)
('yuv.max=', 237.30099999999999, 'yuv.min=', -53.370539999999984)
('yuv.max=', 194.69399999999999, 'yuv.min=', -14.530099999999994)
('yuv.max=', 220.58299999999997, 'yuv.min=', -9.6171499999999952)
('yuv.max=', 240.893, 'yuv.min=', -24.157259999999994)
('yuv.max=', 216.84999999999999, 'yuv.min=', -34.164310000000008)
('yuv.max=', 253.48399999999998, 'yuv.min=', -21.450299999999991)
('yuv.max=', 241.80399999999997, 'yuv.min=', -11.618229999999997)
('yuv.max=', 241.309, 'yuv.min=', -31.435129999999994)
('yuv.max=', 186.78999999999999, 'yuv.min=', -31.230539999999984)
('yuv.max=', 229.68100000000001, 'yuv.min=', -92.468299999999999)
('yuv.max=', 230.41199999999998, 'yuv.min=', -19.880019999999998)
('yuv.max=', 253.61499999999995, 'yuv.min=', -44.275429999999993)
('yuv.max=', 255.0, 'yuv.min=', -80.76615000000001)
('yuv.max=', 200.39099999999999, 'yuv.min=', -55.822099999999999)
('yuv.max=', 136.51399999999998, 'yuv.min=', -10.620570000000001)
('yuv.max=', 251.33099999999996, 'yuv.min=', -50.055269999999993)
('yuv.max=', 255.0, 'yuv.min=', -50.825469999999989)
('yuv.max=', 154.06100000000001, 'yuv.min=', -19.320209999999992)
('yuv.max=', 206.91899999999998, 'yuv.min=', -57.28295)
('yuv.max=', 255.0, 'yuv.min=', -34.523030000000013)
('yuv.max=', 233.256, 'yuv.min=', -37.618479999999998)
('yuv.max=', 248.78300000000002, 'yuv.min=', -56.960529999999991)
('yuv.max=', 255.0, 'yuv.min=', -18.375299999999985)
('yuv.max=', 202.03099999999998, 'yuv.min=', -37.250649999999993)
('yuv.max=', 231.78599999999997, 'yuv.min=', -34.151390000000006)
('yuv.max=', 253.0, 'yuv.min=', -33.97766)
('yuv.max=', 253.989, 'yuv.min=', -28.278040000000001)
('yuv.max=', 250.0, 'yuv.min=', -9.3399499999999982)
('yuv.max=', 250.31999999999999, 'yuv.min=', -24.744829999999993)
('yuv.max=', 238.50099999999998, 'yuv.min=', -43.652169999999998)
('yuv.max=', 232.71699999999998, 'yuv.min=', -25.166460000000001)
('yuv.max=', 240.13099999999997, 'yuv.min=', -21.38017)
('yuv.max=', 234.86399999999998, 'yuv.min=', -17.360259999999997)
('yuv.max=', 246.03200000000001, 'yuv.min=', -37.510429999999992)
('yuv.max=', 255.0, 'yuv.min=', -33.460639999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.625239999999994)
('yuv.max=', 251.74399999999997, 'yuv.min=', -29.03145)
('yuv.max=', 249.56999999999996, 'yuv.min=', -54.406319999999994)
('yuv.max=', 154.95699999999999, 'yuv.min=', -34.705580000000005)
('yuv.max=', 100.62, 'yuv.min=', -33.610039999999991)
('yuv.max=', 196.03999999999996, 'yuv.min=', -62.263669999999991)
('yuv.max=', 185.09, 'yuv.min=', -25.595529999999997)
('yuv.max=', 253.80399999999997, 'yuv.min=', -10.110149999999999)
('yuv.max=', 233.768, 'yuv.min=', -19.575419999999983)
('yuv.max=', 255.0, 'yuv.min=', -74.515039999999999)
('yuv.max=', 216.036, 'yuv.min=', -50.38060999999999)
('yuv.max=', 193.86199999999999, 'yuv.min=', -31.763530000000003)
('yuv.max=', 197.22299999999998, 'yuv.min=', -43.84550999999999)
('yuv.max=', 248.869, 'yuv.min=', -19.250080000000004)
('yuv.max=', 222.74100000000001, 'yuv.min=', -67.659190000000009)
('yuv.max=', 249.32699999999997, 'yuv.min=', -14.735240000000008)
('yuv.max=', 207.559, 'yuv.min=', -34.305539999999993)
('yuv.max=', 251.886, 'yuv.min=', -34.820529999999991)
('yuv.max=', 254.202, 'yuv.min=', -35.765439999999984)
('yuv.max=', 246.929, 'yuv.min=', -12.107869999999998)
('yuv.max=', 229.50899999999999, 'yuv.min=', -28.855609999999981)
('yuv.max=', 243.16499999999996, 'yuv.min=', -32.661060000000006)
('yuv.max=', 251.02799999999999, 'yuv.min=', -29.315040000000003)
('yuv.max=', 247.07599999999996, 'yuv.min=', -49.32074999999999)
('yuv.max=', 250.42299999999997, 'yuv.min=', -58.318110000000004)
('yuv.max=', 251.98499999999999, 'yuv.min=', -55.489050000000006)
('yuv.max=', 197.37799999999999, 'yuv.min=', -54.856980000000007)
('yuv.max=', 255.0, 'yuv.min=', -29.085509999999996)
('yuv.max=', 212.12900000000002, 'yuv.min=', -34.135400000000004)
('yuv.max=', 215.98899999999998, 'yuv.min=', -51.850879999999982)
('yuv.max=', 253.81499999999997, 'yuv.min=', -34.377859999999998)
('yuv.max=', 185.84299999999996, 'yuv.min=', -20.135229999999989)
('yuv.max=', 255.0, 'yuv.min=', -6.2051899999999875)
('yuv.max=', 179.036, 'yuv.min=', -22.780309999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', -20.12028999999999)
('yuv.max=', 241.33099999999999, 'yuv.min=', -30.050890000000003)
('yuv.max=', 202.23299999999998, 'yuv.min=', -23.910299999999992)
('yuv.max=', 187.19, 'yuv.min=', -17.123539999999998)
('yuv.max=', 255.0, 'yuv.min=', -8.3306600000000088)
('yuv.max=', 223.07099999999997, 'yuv.min=', -41.185489999999994)
('yuv.max=', 252.50499999999997, 'yuv.min=', -27.470409999999998)
('yuv.max=', 246.96100000000001, 'yuv.min=', -21.250279999999989)
('yuv.max=', 251.142, 'yuv.min=', -25.840369999999989)
('yuv.max=', 247.39099999999996, 'yuv.min=', -13.31504)
('yuv.max=', 240.67999999999998, 'yuv.min=', -26.589829999999999)
('yuv.max=', 255.0, 'yuv.min=', -17.279470000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -50.3553)
('yuv.max=', 255.0, 'yuv.min=', -35.865449999999996)
('yuv.max=', 219.57299999999998, 'yuv.min=', -15.460069999999988)
('yuv.max=', 205.74799999999999, 'yuv.min=', -26.90022999999999)
('yuv.max=', 205.42999999999998, 'yuv.min=', -41.416699999999999)
('yuv.max=', 253.68999999999997, 'yuv.min=', -12.821759999999998)
('yuv.max=', 238.62999999999997, 'yuv.min=', -25.625409999999984)
('yuv.max=', 147.63399999999999, 'yuv.min=', -36.435629999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', -20.79515)
('yuv.max=', 247.21599999999998, 'yuv.min=', -65.71535999999999)
('yuv.max=', 211.03900000000002, 'yuv.min=', -21.880219999999991)
('yuv.max=', 231.316, 'yuv.min=', -39.216610000000003)
('yuv.max=', 236.86900000000003, 'yuv.min=', -25.682230000000001)
('yuv.max=', 221.93599999999998, 'yuv.min=', -54.355699999999992)
('yuv.max=', 251.41300000000001, 'yuv.min=', -20.51711000000001)
('yuv.max=', 206.13900000000001, 'yuv.min=', -49.385079999999974)
('yuv.max=', 230.21299999999999, 'yuv.min=', -32.845749999999995)
('yuv.max=', 255.0, 'yuv.min=', -24.825329999999997)
('yuv.max=', 217.85299999999995, 'yuv.min=', -43.799349999999997)
('yuv.max=', 234.33699999999999, 'yuv.min=', -23.405679999999997)
('yuv.max=', 230.27099999999999, 'yuv.min=', -30.390790000000003)
('yuv.max=', 254.54400000000001, 'yuv.min=', -12.7797)
('yuv.max=', 224.37899999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 248.35900000000001, 'yuv.min=', -24.250579999999985)
('yuv.max=', 254.70099999999999, 'yuv.min=', -33.150239999999997)
('yuv.max=', 173.78899999999999, 'yuv.min=', -19.761000000000003)
('yuv.max=', 244.97800000000001, 'yuv.min=', -36.780479999999997)
('yuv.max=', 248.364, 'yuv.min=', -110.18043999999999)
('yuv.max=', 180.24600000000001, 'yuv.min=', -27.730189999999997)
('yuv.max=', 252.09899999999999, 'yuv.min=', -23.710279999999994)
('yuv.max=', 253.29900000000001, 'yuv.min=', -36.654639999999993)
('yuv.max=', 226.13099999999997, 'yuv.min=', -33.88476)
('yuv.max=', 250.929, 'yuv.min=', -53.136069999999989)
('yuv.max=', 205.42699999999999, 'yuv.min=', -27.615239999999993)
('yuv.max=', 228.21499999999997, 'yuv.min=', -32.990469999999988)
('yuv.max=', 255.0, 'yuv.min=', -7.3949399999999965)
('yuv.max=', 253.518, 'yuv.min=', -27.180749999999989)
('yuv.max=', 233.11799999999999, 'yuv.min=', -25.377520000000001)
('yuv.max=', 238.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.756, 'yuv.min=', -23.105450000000005)
('yuv.max=', 234.505, 'yuv.min=', -62.150679999999994)
('yuv.max=', 251.90699999999995, 'yuv.min=', -47.120530000000002)
('yuv.max=', 210.41899999999998, 'yuv.min=', -32.800820000000002)
('yuv.max=', 226.98100000000002, 'yuv.min=', -32.703980000000001)
('yuv.max=', 228.447, 'yuv.min=', -37.897060000000003)
('yuv.max=', 241.39499999999998, 'yuv.min=', -50.280599999999993)
('yuv.max=', 225.797, 'yuv.min=', -30.705179999999984)
('yuv.max=', 201.86199999999997, 'yuv.min=', -23.195289999999996)
('yuv.max=', 231.60499999999999, 'yuv.min=', -32.805390000000003)
('yuv.max=', 228.07399999999998, 'yuv.min=', -18.635079999999999)
('yuv.max=', 255.0, 'yuv.min=', -55.031509999999997)
('yuv.max=', 245.59100000000001, 'yuv.min=', -25.880619999999993)
('yuv.max=', 230.499, 'yuv.min=', -16.598800000000004)
('yuv.max=', 216.00099999999998, 'yuv.min=', -66.046080000000003)
('yuv.max=', 242.50999999999996, 'yuv.min=', -61.120699999999999)
('yuv.max=', 235.41199999999998, 'yuv.min=', -33.624979999999994)
('yuv.max=', 211.875, 'yuv.min=', -21.135329999999989)
('yuv.max=', 240.733, 'yuv.min=', -12.544239999999995)
('yuv.max=', 224.63, 'yuv.min=', -25.080539999999996)
('yuv.max=', 245.41499999999999, 'yuv.min=', -37.346400000000003)
('yuv.max=', 244.05799999999996, 'yuv.min=', -13.344619999999999)
('yuv.max=', 229.00399999999999, 'yuv.min=', -30.446350000000002)
('yuv.max=', 253.0, 'yuv.min=', -17.990199999999998)
('yuv.max=', 253.185, 'yuv.min=', -13.18713)
('yuv.max=', 255.0, 'yuv.min=', -49.821259999999995)
('yuv.max=', 252.17400000000001, 'yuv.min=', -13.568719999999999)
('yuv.max=', 229.62899999999999, 'yuv.min=', -52.364639999999994)
('yuv.max=', 222.58799999999999, 'yuv.min=', -46.00090999999999)
('yuv.max=', 249.75700000000001, 'yuv.min=', -32.174210000000009)
('yuv.max=', 255.0, 'yuv.min=', -60.552040000000005)
('yuv.max=', 250.21699999999998, 'yuv.min=', -23.310239999999997)
('yuv.max=', 248.14599999999999, 'yuv.min=', -13.000069999999997)
('yuv.max=', 255.0, 'yuv.min=', -26.200159999999993)
('yuv.max=', 186.66399999999999, 'yuv.min=', -65.685839999999999)
('yuv.max=', 253.886, 'yuv.min=', -50.110460000000003)
('yuv.max=', 204.399, 'yuv.min=', -77.800399999999996)
('yuv.max=', 240.81900000000002, 'yuv.min=', -45.50542999999999)
('yuv.max=', 254.47300000000001, 'yuv.min=', -29.358059999999998)
('yuv.max=', 204.59799999999998, 'yuv.min=', -30.445399999999992)
('yuv.max=', 225.21699999999998, 'yuv.min=', -23.117339999999999)
('yuv.max=', 248.071, 'yuv.min=', -31.608150000000006)
('yuv.max=', 255.0, 'yuv.min=', -12.810420000000001)
('yuv.max=', 251.09199999999998, 'yuv.min=', -31.790349999999997)
('yuv.max=', 173.45600000000002, 'yuv.min=', -47.481549999999999)
('yuv.max=', 241.60999999999999, 'yuv.min=', -44.176299999999998)
('yuv.max=', 232.73399999999998, 'yuv.min=', -66.296600000000012)
('yuv.max=', 233.15299999999999, 'yuv.min=', -10.925169999999994)
('yuv.max=', 238.625, 'yuv.min=', -48.03555999999999)
('yuv.max=', 240.065, 'yuv.min=', -51.655429999999996)
('yuv.max=', 237.452, 'yuv.min=', -53.270530000000001)
('yuv.max=', 237.01999999999998, 'yuv.min=', -30.47527999999998)
('yuv.max=', 211.45399999999998, 'yuv.min=', -27.770439999999983)
('yuv.max=', 238.714, 'yuv.min=', -49.680540000000001)
('yuv.max=', 253.505, 'yuv.min=', -24.310339999999993)
('yuv.max=', 207.65199999999996, 'yuv.min=', -17.590989999999998)
('yuv.max=', 232.19599999999997, 'yuv.min=', -19.313950000000002)
('yuv.max=', 242.39999999999998, 'yuv.min=', -26.223019999999998)
('yuv.max=', 225.167, 'yuv.min=', -17.849939999999997)
('yuv.max=', 153.54399999999998, 'yuv.min=', -45.290469999999985)
('yuv.max=', 223.47499999999999, 'yuv.min=', -7.5569500000000005)
('yuv.max=', 241.56999999999999, 'yuv.min=', -72.820639999999997)
('yuv.max=', 227.048, 'yuv.min=', -42.686870000000006)
('yuv.max=', 247.53799999999998, 'yuv.min=', -31.44923)
('yuv.max=', 225.06099999999998, 'yuv.min=', -32.87551999999998)
('yuv.max=', 210.233, 'yuv.min=', -24.740259999999999)
('yuv.max=', 198.23599999999999, 'yuv.min=', -29.553310000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -17.00329)
('yuv.max=', 255.0, 'yuv.min=', -14.282879999999999)
('yuv.max=', 255.0, 'yuv.min=', -34.402870000000007)
('yuv.max=', 187.51499999999999, 'yuv.min=', -20.686070000000001)
('yuv.max=', 224.785, 'yuv.min=', -27.395709999999987)
('yuv.max=', 200.559, 'yuv.min=', -34.915430000000001)
('yuv.max=', 183.27699999999999, 'yuv.min=', -41.795919999999988)
('yuv.max=', 250.245, 'yuv.min=', -8.8265400000000014)
('yuv.max=', 238.511, 'yuv.min=', -79.861350000000002)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 197.756, 'yuv.min=', -27.236849999999997)
('yuv.max=', 213.65299999999999, 'yuv.min=', -10.140029999999994)
('yuv.max=', 243.70099999999999, 'yuv.min=', -36.080409999999986)
('yuv.max=', 251.44499999999996, 'yuv.min=', -89.568089999999998)
('yuv.max=', 255.0, 'yuv.min=', -10.09774)
('yuv.max=', 205.625, 'yuv.min=', -99.335769999999997)
('yuv.max=', 246.35900000000001, 'yuv.min=', -40.554910000000007)
('yuv.max=', 243.42699999999999, 'yuv.min=', -33.665229999999987)
('yuv.max=', 223.92099999999999, 'yuv.min=', -40.300340000000006)
('yuv.max=', 231.14399999999998, 'yuv.min=', -96.925809999999998)
('yuv.max=', 236.374, 'yuv.min=', -24.650620000000004)
('yuv.max=', 237.47999999999996, 'yuv.min=', -31.045459999999988)
('yuv.max=', 226.45899999999997, 'yuv.min=', -20.680099999999978)
('yuv.max=', 181.07399999999998, 'yuv.min=', -16.620820000000002)
('yuv.max=', 242.99799999999999, 'yuv.min=', -35.892189999999999)
('yuv.max=', 192.05699999999999, 'yuv.min=', -64.034890000000004)
('yuv.max=', 224.327, 'yuv.min=', -26.910729999999997)
('yuv.max=', 172.72499999999997, 'yuv.min=', -89.857669999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 249.27699999999999, 'yuv.min=', -34.865349999999992)
('yuv.max=', 193.19799999999998, 'yuv.min=', -46.115859999999998)
('yuv.max=', 247.43000000000001, 'yuv.min=', -33.635350000000003)
('yuv.max=', 239.29300000000001, 'yuv.min=', -8.2986599999999981)
('yuv.max=', 236.07299999999998, 'yuv.min=', -17.960319999999996)
('yuv.max=', 255.0, 'yuv.min=', -6.7351199999999949)
('yuv.max=', 193.06799999999998, 'yuv.min=', 0.25978000000000634)
('yuv.max=', 201.71899999999999, 'yuv.min=', -33.190489999999983)
('yuv.max=', 236.68899999999999, 'yuv.min=', -68.738320000000002)
('yuv.max=', 172.83700000000002, 'yuv.min=', -39.721470000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -70.571029999999993)
('yuv.max=', 249.017, 'yuv.min=', -52.371739999999996)
('yuv.max=', 234.815, 'yuv.min=', -29.645319999999987)
('yuv.max=', 245.989, 'yuv.min=', -53.570559999999993)
('yuv.max=', 237.33100000000002, 'yuv.min=', -35.625250000000008)
('yuv.max=', 225.13100000000003, 'yuv.min=', -11.20308)
('yuv.max=', 255.0, 'yuv.min=', -35.755069999999989)
('yuv.max=', 255.0, 'yuv.min=', -25.128780000000003)
('yuv.max=', 203.364, 'yuv.min=', -23.365429999999989)
('yuv.max=', 250.65199999999999, 'yuv.min=', -30.19509)
('yuv.max=', 236.245, 'yuv.min=', -35.550479999999993)
('yuv.max=', 250.20199999999997, 'yuv.min=', -8.5819000000000045)
('yuv.max=', 220.86199999999999, 'yuv.min=', -32.605369999999979)
('yuv.max=', 167.428, 'yuv.min=', -24.280459999999998)
('yuv.max=', 221.80500000000001, 'yuv.min=', -28.210729999999998)
('yuv.max=', 228.40899999999996, 'yuv.min=', -40.217500000000008)
('yuv.max=', 255.0, 'yuv.min=', -79.540819999999997)
('yuv.max=', 184.785, 'yuv.min=', -31.47537999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', -3.7966200000000043)
('yuv.max=', 225.83199999999999, 'yuv.min=', -43.560419999999993)
('yuv.max=', 253.68999999999997, 'yuv.min=', -39.000209999999981)
('yuv.max=', 228.55900000000003, 'yuv.min=', -34.965359999999997)
('yuv.max=', 180.048, 'yuv.min=', -33.335319999999996)
('yuv.max=', 253.82599999999996, 'yuv.min=', -31.601880000000001)
('yuv.max=', 150.76999999999998, 'yuv.min=', -0.88248000000000104)
('yuv.max=', 210.33699999999999, 'yuv.min=', -71.050339999999991)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.54399999999998, 'yuv.min=', -38.129330000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.786630000000002)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.812349999999999)
('yuv.max=', 251.279, 'yuv.min=', -29.036059999999999)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.85300000000001, 'yuv.min=', -27.460039999999996)
('yuv.max=', 249.83599999999998, 'yuv.min=', -59.750439999999998)
('yuv.max=', 253.505, 'yuv.min=', -18.305169999999997)
('yuv.max=', 222.58599999999998, 'yuv.min=', -22.725119999999986)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 253.0, 'yuv.min=', -30.590229999999995)
('yuv.max=', 248.989, 'yuv.min=', -13.029949999999994)
('yuv.max=', 255.0, 'yuv.min=', -52.432049999999997)
('yuv.max=', 175.34699999999998, 'yuv.min=', -69.460549999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.415219999999991)
('yuv.max=', 221.14999999999998, 'yuv.min=', -46.820499999999988)
('yuv.max=', 240.28299999999999, 'yuv.min=', -22.450399999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.355089999999979)
('yuv.max=', 251.13499999999999, 'yuv.min=', -91.595979999999983)
('yuv.max=', 254.886, 'yuv.min=', -33.035290000000003)
('yuv.max=', 248.124, 'yuv.min=', -23.495319999999992)
('yuv.max=', 251.27700000000002, 'yuv.min=', -45.750269999999993)
('yuv.max=', 253.17399999999998, 'yuv.min=', -43.075309999999988)
('yuv.max=', 182.46399999999997, 'yuv.min=', -45.275529999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.240750000000006)
('yuv.max=', 252.13099999999997, 'yuv.min=', -23.510259999999988)
('yuv.max=', 220.11399999999998, 'yuv.min=', -13.672010000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 213.94999999999999, 'yuv.min=', -40.025620000000004)
('yuv.max=', 228.554, 'yuv.min=', -16.890089999999997)
('yuv.max=', 231.30100000000002, 'yuv.min=', -16.515360000000001)
('yuv.max=', 251.84299999999996, 'yuv.min=', -33.250250000000001)
('yuv.max=', 242.649, 'yuv.min=', -9.4654299999999978)
('yuv.max=', 177.80699999999999, 'yuv.min=', -20.260549999999995)
('yuv.max=', 245.167, 'yuv.min=', -28.345189999999999)
('yuv.max=', 235.809, 'yuv.min=', -30.960389999999993)
('yuv.max=', 245.745, 'yuv.min=', -54.581029999999991)
('yuv.max=', 249.01999999999998, 'yuv.min=', -48.251860000000001)
('yuv.max=', 250.71099999999998, 'yuv.min=', -30.751900000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.725219999999997)
('yuv.max=', 229.38499999999999, 'yuv.min=', -28.774319999999996)
('yuv.max=', 244.928, 'yuv.min=', -39.480749999999993)
('yuv.max=', 255.0, 'yuv.min=', -32.435710000000014)
('yuv.max=', 239.23099999999997, 'yuv.min=', -59.287330000000011)
('yuv.max=', 250.22800000000001, 'yuv.min=', -34.810159999999996)
('yuv.max=', 225.07900000000001, 'yuv.min=', -34.690639999999995)
('yuv.max=', 197.13699999999997, 'yuv.min=', -46.890629999999994)
('yuv.max=', 213.10499999999999, 'yuv.min=', -61.396920000000001)
('yuv.max=', 239.131, 'yuv.min=', -65.71535999999999)
('yuv.max=', 215.041, 'yuv.min=', -12.374709999999993)
('yuv.max=', 255.0, 'yuv.min=', -35.880389999999991)
('yuv.max=', 223.62799999999999, 'yuv.min=', -37.880589999999991)
('yuv.max=', 214.11099999999999, 'yuv.min=', -37.331149999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -57.271440000000005)
('yuv.max=', 255.0, 'yuv.min=', -54.564859999999989)
('yuv.max=', 248.684, 'yuv.min=', -23.71027999999999)
('yuv.max=', 227.63999999999999, 'yuv.min=', -19.835199999999997)
('yuv.max=', 200.55499999999998, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 225.167, 'yuv.min=', -27.425589999999985)
('yuv.max=', 255.0, 'yuv.min=', -23.525199999999991)
('yuv.max=', 229.72900000000001, 'yuv.min=', -42.000509999999991)
('yuv.max=', 204.941, 'yuv.min=', -13.083960000000005)
('yuv.max=', 227.80799999999999, 'yuv.min=', -20.350189999999998)
('yuv.max=', 234.23099999999999, 'yuv.min=', -42.905169999999998)
('yuv.max=', 251.78899999999999, 'yuv.min=', -35.940149999999996)
('yuv.max=', 202.95699999999999, 'yuv.min=', -34.862459999999999)
('yuv.max=', 176.52799999999999, 'yuv.min=', -49.305809999999994)
('yuv.max=', 144.83499999999998, 'yuv.min=', -42.844179999999994)
('yuv.max=', 229.99399999999997, 'yuv.min=', -50.040329999999997)
('yuv.max=', 253.13099999999997, 'yuv.min=', -17.602340000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 177.53699999999998, 'yuv.min=', -24.540240000000004)
('yuv.max=', 241.74200000000002, 'yuv.min=', -23.095279999999995)
('yuv.max=', 240.148, 'yuv.min=', -54.515469999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.590129999999991)
('yuv.max=', 166.97499999999999, 'yuv.min=', -24.795449999999985)
('yuv.max=', 219.25300000000001, 'yuv.min=', -15.245109999999997)
('yuv.max=', 233.69499999999999, 'yuv.min=', -15.720699999999994)
('yuv.max=', 246.49399999999997, 'yuv.min=', -26.744970000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -38.200129999999987)
('yuv.max=', 227.27099999999999, 'yuv.min=', -15.711180000000002)
('yuv.max=', 228.29899999999998, 'yuv.min=', -61.18421)
('yuv.max=', 238.04399999999998, 'yuv.min=', -12.700039999999994)
('yuv.max=', 241.06, 'yuv.min=', -22.08024)
('yuv.max=', 253.16300000000001, 'yuv.min=', -43.776790000000005)
('yuv.max=', 211.054, 'yuv.min=', -38.389779999999995)
('yuv.max=', 251.34199999999996, 'yuv.min=', -22.495219999999989)
('yuv.max=', 180.96499999999997, 'yuv.min=', -36.610339999999994)
('yuv.max=', 249.98400000000001, 'yuv.min=', -47.434370000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.22799999999998, 'yuv.min=', -9.0239499999999992)
('yuv.max=', 255.0, 'yuv.min=', -23.093630000000001)
('yuv.max=', 236.327, 'yuv.min=', -25.08905)
('yuv.max=', 242.07100000000003, 'yuv.min=', -24.725320000000007)
('yuv.max=', 255.0, 'yuv.min=', -33.589299999999994)
('yuv.max=', 219.696, 'yuv.min=', -32.775509999999997)
('yuv.max=', 228.94399999999999, 'yuv.min=', -12.425319999999989)
('yuv.max=', 196.56899999999999, 'yuv.min=', -74.814809999999994)
('yuv.max=', 198.94, 'yuv.min=', -5.5360699999999952)
('yuv.max=', 196.95099999999999, 'yuv.min=', -46.345759999999999)
('yuv.max=', 201.03200000000001, 'yuv.min=', -53.955659999999995)
('yuv.max=', 177.30200000000002, 'yuv.min=', -28.530269999999991)
('yuv.max=', 201.87700000000001, 'yuv.min=', -39.734250000000003)
('yuv.max=', 240.13099999999997, 'yuv.min=', -4.068950000000001)
('yuv.max=', 209.37899999999999, 'yuv.min=', -44.360499999999988)
('yuv.max=', 255.0, 'yuv.min=', -18.386420000000001)
('yuv.max=', 239.86899999999997, 'yuv.min=', -25.578710000000008)
('yuv.max=', 249.27600000000001, 'yuv.min=', -51.13485)
('yuv.max=', 248.113, 'yuv.min=', -66.870659999999987)
('yuv.max=', 216.262, 'yuv.min=', -7.1212000000000018)
('yuv.max=', 209.309, 'yuv.min=', -51.025490000000005)
('yuv.max=', 180.131, 'yuv.min=', -5.8092100000000002)
('yuv.max=', 237.40399999999997, 'yuv.min=', -74.83578)
('yuv.max=', 231.33499999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 254.29899999999995, 'yuv.min=', -70.090489999999988)
('yuv.max=', 227.434, 'yuv.min=', -18.794779999999999)
('yuv.max=', 242.18899999999999, 'yuv.min=', -21.525829999999999)
('yuv.max=', 227.339, 'yuv.min=', -24.915970000000002)
('yuv.max=', 240.70799999999997, 'yuv.min=', -41.060169999999999)
('yuv.max=', 172.66799999999998, 'yuv.min=', -40.202330000000003)
('yuv.max=', 247.768, 'yuv.min=', -50.69896)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.790479999999992)
('yuv.max=', 216.01499999999999, 'yuv.min=', -28.686089999999993)
('yuv.max=', 255.0, 'yuv.min=', -16.83784)
('yuv.max=', 255.0, 'yuv.min=', -53.670569999999998)
('yuv.max=', 245.49900000000002, 'yuv.min=', -54.660299999999992)
('yuv.max=', 252.35299999999998, 'yuv.min=', -18.009709999999995)
('yuv.max=', 237.762, 'yuv.min=', -64.040499999999994)
('yuv.max=', 204.18599999999998, 'yuv.min=', -27.07036999999999)
('yuv.max=', 215.18899999999996, 'yuv.min=', -63.11052999999999)
('yuv.max=', 210.11600000000001, 'yuv.min=', -26.080639999999995)
('yuv.max=', 239.40199999999999, 'yuv.min=', -30.575289999999985)
('yuv.max=', 255.0, 'yuv.min=', -34.054899999999996)
('yuv.max=', 194.761, 'yuv.min=', -45.92040999999999)
('yuv.max=', 222.70400000000001, 'yuv.min=', -44.890429999999995)
('yuv.max=', 235.18299999999999, 'yuv.min=', -36.660250000000005)
('yuv.max=', 188.43499999999997, 'yuv.min=', -25.910499999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.975159999999995)
('yuv.max=', 200.84700000000001, 'yuv.min=', -34.846410000000006)
('yuv.max=', 229.60399999999998, 'yuv.min=', -31.650130000000011)
('yuv.max=', 254.77200000000002, 'yuv.min=', -16.588990000000003)
('yuv.max=', 240.869, 'yuv.min=', -85.850589999999997)
('yuv.max=', 206.16800000000001, 'yuv.min=', -38.873090000000005)
('yuv.max=', 212.71799999999999, 'yuv.min=', -61.101189999999988)
('yuv.max=', 232.96299999999999, 'yuv.min=', -34.884860000000003)
('yuv.max=', 233.017, 'yuv.min=', -27.430159999999997)
('yuv.max=', 247.22799999999998, 'yuv.min=', -19.079939999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.480509999999997)
('yuv.max=', 232.55099999999999, 'yuv.min=', -55.603479999999998)
('yuv.max=', 199.73699999999999, 'yuv.min=', -51.005010000000013)
('yuv.max=', 233.56899999999999, 'yuv.min=', -36.710349999999991)
('yuv.max=', 254.40199999999999, 'yuv.min=', -32.045559999999995)
('yuv.max=', 195.15199999999999, 'yuv.min=', -18.589480000000002)
('yuv.max=', 244.249, 'yuv.min=', -21.024949999999986)
('yuv.max=', 239.55200000000002, 'yuv.min=', -58.820469999999986)
('yuv.max=', 239.66299999999998, 'yuv.min=', -46.305509999999998)
('yuv.max=', 254.017, 'yuv.min=', -25.422780000000003)
('yuv.max=', 168.62599999999998, 'yuv.min=', -4.9469899999999996)
('yuv.max=', 210.05799999999999, 'yuv.min=', -59.969030000000004)
('yuv.max=', 251.58699999999996, 'yuv.min=', -55.700649999999996)
('yuv.max=', 249.31999999999999, 'yuv.min=', -30.690240000000003)
('yuv.max=', 222.58499999999998, 'yuv.min=', -39.127849999999995)
('yuv.max=', 255.0, 'yuv.min=', -62.099360000000004)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.55500000000001, 'yuv.min=', -10.457390000000004)
('yuv.max=', 179.10299999999998, 'yuv.min=', -38.195559999999986)
('yuv.max=', 254.77200000000002, 'yuv.min=', -22.395209999999985)
('yuv.max=', 222.03299999999999, 'yuv.min=', -29.368620000000004)
('yuv.max=', 255.0, 'yuv.min=', -55.985739999999993)
('yuv.max=', 213.72499999999999, 'yuv.min=', -61.520739999999989)
('yuv.max=', 185.61499999999998, 'yuv.min=', -43.385019999999997)
('yuv.max=', 253.185, 'yuv.min=', -22.473209999999995)
('yuv.max=', 230.15300000000002, 'yuv.min=', -19.430589999999992)
('yuv.max=', 245.69599999999997, 'yuv.min=', -35.456230000000005)
('yuv.max=', 252.42999999999998, 'yuv.min=', -23.510360000000002)
('yuv.max=', 236.86899999999997, 'yuv.min=', -16.260149999999996)
('yuv.max=', 254.10300000000001, 'yuv.min=', -60.355350000000008)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 220.25999999999999, 'yuv.min=', -46.135369999999995)
('yuv.max=', 220.63, 'yuv.min=', -11.922780000000003)
('yuv.max=', 227.80900000000003, 'yuv.min=', -13.932710000000007)
('yuv.max=', 254.70099999999999, 'yuv.min=', -20.505389999999988)
('yuv.max=', 232.53999999999999, 'yuv.min=', -31.69068)
('yuv.max=', 252.10499999999996, 'yuv.min=', -93.675449999999984)
('yuv.max=', 223.316, 'yuv.min=', -16.630309999999994)
('yuv.max=', 253.071, 'yuv.min=', -19.405279999999994)
('yuv.max=', 186.327, 'yuv.min=', -32.590429999999998)
('yuv.max=', 250.83599999999998, 'yuv.min=', -32.580059999999989)
('yuv.max=', 216.43899999999999, 'yuv.min=', -20.06053)
('yuv.max=', 250.34799999999996, 'yuv.min=', -19.209589999999999)
('yuv.max=', 255.0, 'yuv.min=', -6.25535)
('yuv.max=', 255.0, 'yuv.min=', -30.930509999999991)
('yuv.max=', 238.43299999999999, 'yuv.min=', -9.3404799999999977)
('yuv.max=', 244.05000000000001, 'yuv.min=', -26.615499999999997)
('yuv.max=', 234.56800000000001, 'yuv.min=', -9.4642899999999912)
('yuv.max=', 198.27099999999999, 'yuv.min=', -12.755230000000001)
('yuv.max=', 226.02999999999997, 'yuv.min=', -34.60557)
('yuv.max=', 254.54400000000001, 'yuv.min=', -14.69062000000001)
('yuv.max=', 220.64699999999999, 'yuv.min=', -12.937430000000003)
('yuv.max=', 239.863, 'yuv.min=', -8.3860100000000024)
('yuv.max=', 233.929, 'yuv.min=', -8.2890300000000039)
('yuv.max=', 243.0, 'yuv.min=', -19.060429999999993)
('yuv.max=', 253.17600000000002, 'yuv.min=', -61.480489999999989)
('yuv.max=', 170.63200000000001, 'yuv.min=', -33.111280000000008)
('yuv.max=', 174.37799999999999, 'yuv.min=', -25.114989999999999)
('yuv.max=', 238.06499999999997, 'yuv.min=', -14.60023)
('yuv.max=', 247.07300000000001, 'yuv.min=', -20.790479999999992)
('yuv.max=', 209.70399999999995, 'yuv.min=', -10.341970000000003)
('yuv.max=', 219.27699999999999, 'yuv.min=', -33.060599999999987)
('yuv.max=', 255.0, 'yuv.min=', -81.283969999999997)
('yuv.max=', 211.10299999999995, 'yuv.min=', -74.781900000000007)
('yuv.max=', 200.22899999999998, 'yuv.min=', -24.225269999999991)
('yuv.max=', 224.077, 'yuv.min=', -15.715279999999989)
('yuv.max=', 220.22799999999998, 'yuv.min=', -18.860409999999995)
('yuv.max=', 228.46000000000001, 'yuv.min=', -23.568830000000005)
('yuv.max=', 241.11799999999999, 'yuv.min=', -40.915339999999986)
('yuv.max=', 234.86799999999997, 'yuv.min=', -34.735459999999996)
('yuv.max=', 222.52699999999999, 'yuv.min=', -12.510389999999996)
('yuv.max=', 254.29899999999995, 'yuv.min=', -15.32560999999999)
('yuv.max=', 178.70899999999997, 'yuv.min=', -30.00057)
('yuv.max=', 255.0, 'yuv.min=', -73.250559999999993)
('yuv.max=', 246.18900000000002, 'yuv.min=', -61.080449999999999)
('yuv.max=', 255.0, 'yuv.min=', -15.460070000000007)
('yuv.max=', 242.70099999999999, 'yuv.min=', -63.835909999999998)
('yuv.max=', 242.22800000000001, 'yuv.min=', -12.390899999999998)
('yuv.max=', 181.76599999999999, 'yuv.min=', -54.554489999999994)
('yuv.max=', 243.13499999999999, 'yuv.min=', -14.43526)
('yuv.max=', 248.327, 'yuv.min=', -22.860750000000003)
('yuv.max=', 226.97299999999998, 'yuv.min=', -38.540409999999994)
('yuv.max=', 251.142, 'yuv.min=', -29.945349999999998)
('yuv.max=', 245.233, 'yuv.min=', -33.380139999999997)
('yuv.max=', 249.17399999999998, 'yuv.min=', -29.902100000000004)
('yuv.max=', 255.0, 'yuv.min=', -30.385639999999995)
('yuv.max=', 217.40299999999999, 'yuv.min=', -87.21380000000002)
('yuv.max=', 229.018, 'yuv.min=', -70.046769999999995)
('yuv.max=', 233.18900000000002, 'yuv.min=', -77.715329999999994)
('yuv.max=', 155.078, 'yuv.min=', -37.165579999999991)
('yuv.max=', 232.75799999999998, 'yuv.min=', -17.490149999999989)
('yuv.max=', 236.303, 'yuv.min=', -25.673340000000003)
('yuv.max=', 213.245, 'yuv.min=', -19.235139999999994)
('yuv.max=', 233.03199999999998, 'yuv.min=', -50.170219999999993)
('yuv.max=', 161.70999999999998, 'yuv.min=', -48.750569999999996)
('yuv.max=', 253.41299999999998, 'yuv.min=', -28.170390000000005)
('yuv.max=', 252.935, 'yuv.min=', -29.944110000000002)
('yuv.max=', 241.04699999999997, 'yuv.min=', -66.12236)
('yuv.max=', 250.80399999999997, 'yuv.min=', -29.845339999999993)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -28.975070000000009)
('yuv.max=', 226.47299999999998, 'yuv.min=', -21.81965000000001)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 246.41199999999998, 'yuv.min=', -35.610240000000005)
('yuv.max=', 237.37700000000001, 'yuv.min=', -26.669810000000005)
('yuv.max=', 242.58899999999997, 'yuv.min=', -73.251169999999988)
('yuv.max=', 242.48399999999998, 'yuv.min=', -72.650499999999994)
('yuv.max=', 241.869, 'yuv.min=', -16.315339999999996)
('yuv.max=', 194.297, 'yuv.min=', -45.308389999999996)
('yuv.max=', 198.10499999999999, 'yuv.min=', -47.560819999999993)
('yuv.max=', 254.70099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 196.42899999999997, 'yuv.min=', -18.033239999999999)
('yuv.max=', 217.19300000000001, 'yuv.min=', -62.48227)
('yuv.max=', 243.989, 'yuv.min=', -6.2500099999999961)
('yuv.max=', 228.16999999999999, 'yuv.min=', -23.699740000000006)
('yuv.max=', 209.095, 'yuv.min=', -36.940249999999999)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 237.79199999999997, 'yuv.min=', -47.050399999999996)
('yuv.max=', 219.31, 'yuv.min=', -14.995699999999999)
('yuv.max=', 224.08199999999997, 'yuv.min=', -21.553300000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 239.262, 'yuv.min=', -40.92577)
('yuv.max=', 216.44499999999999, 'yuv.min=', -29.379739999999991)
('yuv.max=', 232.81799999999998, 'yuv.min=', -95.08896)
('yuv.max=', 152.22399999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 236.74599999999998, 'yuv.min=', -19.320209999999989)
('yuv.max=', 251.76599999999999, 'yuv.min=', -101.99578999999999)
('yuv.max=', 246.77799999999996, 'yuv.min=', -34.824740000000006)
('yuv.max=', 247.90099999999998, 'yuv.min=', -18.020080000000004)
('yuv.max=', 234.12800000000001, 'yuv.min=', -46.071039999999996)
('yuv.max=', 224.69000000000003, 'yuv.min=', -8.217290000000002)
('yuv.max=', 223.57599999999999, 'yuv.min=', -36.540209999999995)
('yuv.max=', 239.40000000000001, 'yuv.min=', -90.295850000000002)
('yuv.max=', 228.41499999999999, 'yuv.min=', -34.846069999999997)
('yuv.max=', 248.04900000000001, 'yuv.min=', -28.926060000000007)
('yuv.max=', 244.518, 'yuv.min=', -22.020440000000004)
('yuv.max=', 251.21299999999999, 'yuv.min=', -49.950689999999994)
('yuv.max=', 253.46199999999999, 'yuv.min=', -20.250179999999997)
('yuv.max=', 251.15699999999998, 'yuv.min=', -8.2800899999999995)
('yuv.max=', 255.0, 'yuv.min=', -33.190489999999997)
('yuv.max=', 194.74999999999997, 'yuv.min=', -38.280630000000002)
('yuv.max=', 241.35399999999998, 'yuv.min=', -22.615290000000002)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999998)
('yuv.max=', 220.45599999999999, 'yuv.min=', -15.545139999999996)
('yuv.max=', 226.238, 'yuv.min=', -32.375469999999993)
('yuv.max=', 245.983, 'yuv.min=', -18.152900000000002)
('yuv.max=', 251.71100000000001, 'yuv.min=', -53.81539999999999)
('yuv.max=', 244.982, 'yuv.min=', -69.560559999999995)
('yuv.max=', 244.74399999999997, 'yuv.min=', -39.433660000000003)
('yuv.max=', 224.06100000000001, 'yuv.min=', -47.175719999999984)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -53.966029999999989)
('yuv.max=', 208.96600000000001, 'yuv.min=', -3.0301799999999943)
('yuv.max=', 254.40199999999999, 'yuv.min=', -31.005209999999995)
('yuv.max=', 250.94599999999997, 'yuv.min=', -23.180349999999986)
('yuv.max=', 232.37200000000001, 'yuv.min=', -61.20085000000001)
('yuv.max=', 235.60900000000001, 'yuv.min=', -6.505219999999996)
('yuv.max=', 250.34200000000001, 'yuv.min=', -39.020300000000006)
('yuv.max=', 236.31299999999999, 'yuv.min=', -57.715789999999998)
('yuv.max=', 214.28199999999998, 'yuv.min=', -25.385139999999996)
('yuv.max=', 185.05099999999999, 'yuv.min=', -29.915469999999988)
('yuv.max=', 246.80399999999997, 'yuv.min=', -39.395679999999999)
('yuv.max=', 212.047, 'yuv.min=', -16.730179999999997)
('yuv.max=', 227.762, 'yuv.min=', -32.720319999999987)
('yuv.max=', 235.03699999999998, 'yuv.min=', -80.930589999999995)
('yuv.max=', 253.21699999999998, 'yuv.min=', -29.375169999999997)
('yuv.max=', 240.92599999999999, 'yuv.min=', -52.125599999999984)
('yuv.max=', 255.0, 'yuv.min=', -24.555179999999993)
('yuv.max=', 244.84099999999998, 'yuv.min=', -9.8951899999999959)
('yuv.max=', 251.16800000000001, 'yuv.min=', -27.315209999999986)
('yuv.max=', 233.63499999999999, 'yuv.min=', -33.950319999999998)
('yuv.max=', 253.376, 'yuv.min=', -41.879759999999997)
('yuv.max=', 223.78299999999999, 'yuv.min=', -42.645389999999992)
('yuv.max=', 205.369, 'yuv.min=', -55.230479999999986)
('yuv.max=', 255.0, 'yuv.min=', -32.950219999999987)
('yuv.max=', 206.17499999999998, 'yuv.min=', -6.7234800000000021)
('yuv.max=', 255.0, 'yuv.min=', -12.507250000000003)
('yuv.max=', 240.00499999999997, 'yuv.min=', -18.178840000000008)
('yuv.max=', 212.74899999999997, 'yuv.min=', -32.985900000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -18.005139999999997)
('yuv.max=', 213.70499999999998, 'yuv.min=', -60.824649999999991)
('yuv.max=', 249.85399999999998, 'yuv.min=', -2.3301000000000158)
('yuv.max=', 242.184, 'yuv.min=', -19.913690000000003)
('yuv.max=', 247.88600000000002, 'yuv.min=', -14.974959999999996)
('yuv.max=', 255.0, 'yuv.min=', -21.613799999999998)
('yuv.max=', 245.96099999999998, 'yuv.min=', -23.710449999999994)
('yuv.max=', 199.37299999999999, 'yuv.min=', -33.850309999999993)
('yuv.max=', 226.89399999999998, 'yuv.min=', -29.830399999999994)
('yuv.max=', 224.10299999999998, 'yuv.min=', -16.026160000000004)
('yuv.max=', 239.64099999999996, 'yuv.min=', -37.580559999999991)
('yuv.max=', 251.15699999999998, 'yuv.min=', -17.040800000000008)
('yuv.max=', 121.03400000000001, 'yuv.min=', -38.425460000000001)
('yuv.max=', 247.952, 'yuv.min=', -72.89533999999999)
('yuv.max=', 255.0, 'yuv.min=', -74.776510000000002)
('yuv.max=', 245.08799999999999, 'yuv.min=', -21.499280000000002)
('yuv.max=', 237.30999999999997, 'yuv.min=', -14.785399999999999)
('yuv.max=', 157.38399999999999, 'yuv.min=', -25.770240000000001)
('yuv.max=', 233.95299999999997, 'yuv.min=', -18.21208)
('yuv.max=', 158.83899999999997, 'yuv.min=', -50.432699999999997)
('yuv.max=', 241.94699999999997, 'yuv.min=', -36.131450000000001)
('yuv.max=', 237.19199999999998, 'yuv.min=', -36.606700000000004)
('yuv.max=', 173.27899999999997, 'yuv.min=', -36.550579999999997)
('yuv.max=', 255.0, 'yuv.min=', -29.400439999999996)
('yuv.max=', 251.77199999999999, 'yuv.min=', -83.02042999999999)
('yuv.max=', 240.0, 'yuv.min=', -39.740529999999993)
('yuv.max=', 223.09899999999996, 'yuv.min=', -23.024160000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 225.26400000000001, 'yuv.min=', -63.970369999999996)
('yuv.max=', 205.11499999999998, 'yuv.min=', -49.970199999999991)
('yuv.max=', 209.88799999999998, 'yuv.min=', -86.446079999999995)
('yuv.max=', 244.87599999999998, 'yuv.min=', -26.201930000000008)
('yuv.max=', 240.08599999999998, 'yuv.min=', -34.25034999999999)
('yuv.max=', 250.255, 'yuv.min=', -20.980129999999992)
('yuv.max=', 254.202, 'yuv.min=', -38.971159999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 242.57900000000001, 'yuv.min=', -29.209240000000001)
('yuv.max=', 207.429, 'yuv.min=', -39.881420000000006)
('yuv.max=', 253.86000000000001, 'yuv.min=', -46.404289999999996)
('yuv.max=', 248.32599999999999, 'yuv.min=', -33.08402000000001)
('yuv.max=', 239.64799999999997, 'yuv.min=', -22.507860000000001)
('yuv.max=', 230.21699999999998, 'yuv.min=', -31.652850000000001)
('yuv.max=', 236.32900000000001, 'yuv.min=', -31.779979999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -27.740559999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -44.175419999999995)
('yuv.max=', 218.0, 'yuv.min=', -12.65954)
('yuv.max=', 253.80399999999997, 'yuv.min=', -45.905469999999994)
('yuv.max=', 228.196, 'yuv.min=', -78.151049999999998)
('yuv.max=', 200.58599999999998, 'yuv.min=', -37.035689999999995)
('yuv.max=', 254.28799999999998, 'yuv.min=', -21.365229999999993)
('yuv.max=', 246.31, 'yuv.min=', -14.030049999999994)
('yuv.max=', 237.97399999999996, 'yuv.min=', -49.865480000000005)
('yuv.max=', 201.94099999999997, 'yuv.min=', -45.275529999999989)
('yuv.max=', 246.815, 'yuv.min=', -35.605669999999996)
('yuv.max=', 245.191, 'yuv.min=', -34.420490000000001)
('yuv.max=', 127.15899999999999, 'yuv.min=', -39.340489999999996)
('yuv.max=', 253.40199999999996, 'yuv.min=', -24.710379999999997)
('yuv.max=', 240.411, 'yuv.min=', -54.437500000000014)
('yuv.max=', 255.0, 'yuv.min=', -9.87331)
('yuv.max=', 205.81699999999998, 'yuv.min=', -48.545250000000003)
('yuv.max=', 250.815, 'yuv.min=', -33.875619999999998)
('yuv.max=', 250.44499999999996, 'yuv.min=', -19.090309999999988)
('yuv.max=', 239.22799999999995, 'yuv.min=', -34.61142000000001)
('yuv.max=', 237.03, 'yuv.min=', -14.170309999999999)
('yuv.max=', 240.88599999999997, 'yuv.min=', -96.005559999999988)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.75299999999999, 'yuv.min=', -25.825429999999987)
('yuv.max=', 168.303, 'yuv.min=', -32.185819999999993)
('yuv.max=', 184.17400000000001, 'yuv.min=', -37.565619999999996)
('yuv.max=', 255.0, 'yuv.min=', -62.241759999999992)
('yuv.max=', 211.68199999999999, 'yuv.min=', -11.655119999999993)
('yuv.max=', 246.32900000000001, 'yuv.min=', -36.385009999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', -76.826040000000006)
('yuv.max=', 255.0, 'yuv.min=', -14.970389999999998)
('yuv.max=', 253.99999999999997, 'yuv.min=', -38.230670000000003)
('yuv.max=', 222.798, 'yuv.min=', -18.054270000000002)
('yuv.max=', 253.40199999999996, 'yuv.min=', -12.940310000000007)
('yuv.max=', 240.78699999999998, 'yuv.min=', -50.080579999999998)
('yuv.max=', 185.94799999999998, 'yuv.min=', -26.000139999999995)
('yuv.max=', 237.18799999999999, 'yuv.min=', -46.429599999999986)
('yuv.max=', 250.94599999999997, 'yuv.min=', -15.35549)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.92699999999999, 'yuv.min=', -92.865560000000002)
('yuv.max=', 255.0, 'yuv.min=', -36.080410000000001)
('yuv.max=', 206.56299999999999, 'yuv.min=', -30.345390000000002)
('yuv.max=', 245.18399999999997, 'yuv.min=', -33.050229999999999)
('yuv.max=', 201.149, 'yuv.min=', -27.870449999999998)
('yuv.max=', 199.24299999999999, 'yuv.min=', -12.805490000000006)
('yuv.max=', 245.03199999999998, 'yuv.min=', -17.690169999999988)
('yuv.max=', 245.815, 'yuv.min=', -65.551019999999994)
('yuv.max=', 247.56899999999996, 'yuv.min=', -33.172030000000007)
('yuv.max=', 222.06199999999998, 'yuv.min=', -52.070409999999995)
('yuv.max=', 198.07399999999998, 'yuv.min=', -19.22552000000001)
('yuv.max=', 252.68599999999998, 'yuv.min=', -23.61027)
('yuv.max=', 210.29299999999998, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 238.05700000000002, 'yuv.min=', -22.850439999999985)
('yuv.max=', 252.57199999999997, 'yuv.min=', -31.013190000000009)
('yuv.max=', 254.11399999999998, 'yuv.min=', -31.145469999999992)
('yuv.max=', 254.40199999999999, 'yuv.min=', -85.050510000000003)
('yuv.max=', 226.20799999999997, 'yuv.min=', -23.995369999999998)
('yuv.max=', 199.89399999999998, 'yuv.min=', -66.960299999999989)
('yuv.max=', 255.0, 'yuv.min=', -40.68544)
('yuv.max=', 154.529, 'yuv.min=', -22.505589999999987)
('yuv.max=', 251.77199999999999, 'yuv.min=', -28.097280000000001)
('yuv.max=', 240.66799999999995, 'yuv.min=', -27.188880000000001)
('yuv.max=', 248.02199999999999, 'yuv.min=', -16.3751)
('yuv.max=', 215.619, 'yuv.min=', -16.430289999999999)
('yuv.max=', 246.10300000000001, 'yuv.min=', -24.985099999999992)
('yuv.max=', 196.52799999999999, 'yuv.min=', -60.150479999999988)
('yuv.max=', 193.82999999999998, 'yuv.min=', -30.575289999999988)
('yuv.max=', 255.0, 'yuv.min=', -31.630579999999995)
('yuv.max=', 224.13999999999999, 'yuv.min=', -12.110349999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', -23.770039999999991)
('yuv.max=', 218.59699999999998, 'yuv.min=', -33.182010000000005)
('yuv.max=', 248.42400000000001, 'yuv.min=', -34.750399999999985)
('yuv.max=', 214.928, 'yuv.min=', -10.969989999999985)
('yuv.max=', 161.47900000000001, 'yuv.min=', -48.92071)
('yuv.max=', 144.251, 'yuv.min=', -51.72099)
('yuv.max=', 224.33099999999996, 'yuv.min=', -20.277610000000006)
('yuv.max=', 229.065, 'yuv.min=', -38.185189999999992)
('yuv.max=', 97.0, 'yuv.min=', -3.2899599999999993)
('yuv.max=', 249.93899999999999, 'yuv.min=', -21.646489999999996)
('yuv.max=', 231.29300000000001, 'yuv.min=', -9.9101299999999917)
('yuv.max=', 227.93899999999999, 'yuv.min=', -18.520129999999991)
('yuv.max=', 215.93199999999999, 'yuv.min=', -35.855079999999987)
('yuv.max=', 208.404, 'yuv.min=', -55.915609999999994)
('yuv.max=', 255.0, 'yuv.min=', -5.9823599999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.3503199999999964)
('yuv.max=', 233.62099999999998, 'yuv.min=', -35.095249999999993)
('yuv.max=', 255.0, 'yuv.min=', -23.350489999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.20199999999997, 'yuv.min=', -18.037589999999994)
('yuv.max=', 208.17699999999999, 'yuv.min=', -44.800789999999992)
('yuv.max=', 181.422, 'yuv.min=', -18.36036)
('yuv.max=', 232.73999999999998, 'yuv.min=', -25.509699999999999)
('yuv.max=', 247.90800000000002, 'yuv.min=', -20.070899999999998)
('yuv.max=', 238.12899999999999, 'yuv.min=', -29.770639999999993)
('yuv.max=', 255.0, 'yuv.min=', -42.884420000000006)
('yuv.max=', 252.61899999999997, 'yuv.min=', -34.720519999999993)
('yuv.max=', 209.76700000000002, 'yuv.min=', -50.295540000000003)
('yuv.max=', 255.0, 'yuv.min=', -61.266040000000004)
('yuv.max=', 227.77000000000001, 'yuv.min=', -39.264940000000003)
('yuv.max=', 243.01399999999998, 'yuv.min=', -28.289999999999996)
('yuv.max=', 233.95299999999997, 'yuv.min=', -21.896100000000001)
('yuv.max=', 182.166, 'yuv.min=', -17.117680000000004)
('yuv.max=', 200.28399999999999, 'yuv.min=', -59.98980000000001)
('yuv.max=', 209.62199999999999, 'yuv.min=', -37.282860000000007)
('yuv.max=', 235.79699999999997, 'yuv.min=', -15.785409999999997)
('yuv.max=', 255.0, 'yuv.min=', -12.211280000000002)
('yuv.max=', 221.99399999999997, 'yuv.min=', -17.77524)
('yuv.max=', 205.12099999999998, 'yuv.min=', -36.995439999999995)
('yuv.max=', 216.08099999999999, 'yuv.min=', -32.455969999999994)
('yuv.max=', 245.95699999999999, 'yuv.min=', -37.800089999999997)
('yuv.max=', 253.70099999999996, 'yuv.min=', -28.715350000000004)
('yuv.max=', 252.64099999999996, 'yuv.min=', -12.765599999999996)
('yuv.max=', 254.886, 'yuv.min=', -81.119779999999992)
('yuv.max=', 255.0, 'yuv.min=', -9.9250699999999981)
('yuv.max=', 248.91800000000001, 'yuv.min=', -16.530299999999993)
('yuv.max=', 230.86199999999999, 'yuv.min=', -34.25034999999999)
('yuv.max=', 213.161, 'yuv.min=', -24.283989999999999)
('yuv.max=', 250.565, 'yuv.min=', -53.485489999999992)
('yuv.max=', 227.87300000000002, 'yuv.min=', -42.574210000000008)
('yuv.max=', 246.64099999999999, 'yuv.min=', -32.190860000000001)
('yuv.max=', 186.46699999999998, 'yuv.min=', -28.630279999999999)
('yuv.max=', 175.26799999999997, 'yuv.min=', -35.329580000000007)
('yuv.max=', 238.18499999999997, 'yuv.min=', -20.185980000000004)
('yuv.max=', 252.06, 'yuv.min=', -25.470209999999994)
('yuv.max=', 242.744, 'yuv.min=', -18.435059999999989)
('yuv.max=', 233.33500000000001, 'yuv.min=', -89.470460000000003)
('yuv.max=', 222.65599999999998, 'yuv.min=', -21.710789999999996)
('yuv.max=', 237.28799999999998, 'yuv.min=', -37.825399999999988)
('yuv.max=', 255.0, 'yuv.min=', -35.550479999999993)
('yuv.max=', 244.797, 'yuv.min=', -30.954270000000001)
('yuv.max=', 239.89999999999998, 'yuv.min=', -43.745499999999993)
('yuv.max=', 217.06, 'yuv.min=', -32.275459999999988)
('yuv.max=', 226.20000000000002, 'yuv.min=', -56.54097999999999)
('yuv.max=', 228.62, 'yuv.min=', -40.240579999999994)
('yuv.max=', 194.00299999999999, 'yuv.min=', -39.701660000000004)
('yuv.max=', 252.935, 'yuv.min=', -36.235609999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -43.915639999999996)
('yuv.max=', 244.86899999999997, 'yuv.min=', -23.980429999999991)
('yuv.max=', 191.32399999999998, 'yuv.min=', -24.595429999999993)
('yuv.max=', 253.52699999999999, 'yuv.min=', -38.660870000000003)
('yuv.max=', 254.43000000000001, 'yuv.min=', -26.512409999999999)
('yuv.max=', 242.45000000000002, 'yuv.min=', -22.35038999999999)
('yuv.max=', 240.374, 'yuv.min=', -24.958770000000005)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.195489999999999)
('yuv.max=', 248.929, 'yuv.min=', -16.877440000000004)
('yuv.max=', 197.79300000000001, 'yuv.min=', -24.325279999999996)
('yuv.max=', 250.00199999999998, 'yuv.min=', -60.317240000000012)
('yuv.max=', 245.45499999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 249.66199999999998, 'yuv.min=', -14.996719999999996)
('yuv.max=', 174.92499999999998, 'yuv.min=', -8.9801599999999961)
('yuv.max=', 255.0, 'yuv.min=', -56.726749999999996)
('yuv.max=', 190.31399999999999, 'yuv.min=', -75.895639999999986)
('yuv.max=', 248.69, 'yuv.min=', -22.795249999999996)
('yuv.max=', 205.02499999999998, 'yuv.min=', -30.872399999999995)
('yuv.max=', 250.66899999999998, 'yuv.min=', -55.275299999999987)
('yuv.max=', 232.114, 'yuv.min=', -60.765479999999982)
('yuv.max=', 221.33799999999999, 'yuv.min=', -6.4201499999999854)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.97549999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -25.795549999999992)
('yuv.max=', 227.38499999999999, 'yuv.min=', -65.115299999999991)
('yuv.max=', 226.10400000000001, 'yuv.min=', -28.745229999999989)
('yuv.max=', 211.65600000000001, 'yuv.min=', -35.664199999999994)
('yuv.max=', 210.0, 'yuv.min=', -8.8871300000000062)
('yuv.max=', 254.245, 'yuv.min=', -43.274750000000004)
('yuv.max=', 245.50899999999999, 'yuv.min=', -38.385210000000001)
('yuv.max=', 251.70699999999999, 'yuv.min=', -56.805329999999998)
('yuv.max=', 222.03799999999998, 'yuv.min=', -17.230659999999993)
('yuv.max=', 249.91800000000001, 'yuv.min=', -24.78507999999999)
('yuv.max=', 224.71600000000001, 'yuv.min=', -37.880589999999991)
('yuv.max=', 199.61699999999999, 'yuv.min=', -34.520499999999998)
('yuv.max=', 141.15699999999998, 'yuv.min=', -6.5500399999999885)
('yuv.max=', 244.62, 'yuv.min=', -36.475880000000004)
('yuv.max=', 217.87999999999997, 'yuv.min=', -31.110850000000006)
('yuv.max=', 235.90499999999997, 'yuv.min=', -29.05236)
('yuv.max=', 245.46499999999997, 'yuv.min=', -54.955759999999998)
('yuv.max=', 232.76799999999997, 'yuv.min=', -57.527420000000014)
('yuv.max=', 245.25899999999999, 'yuv.min=', -69.757499999999993)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.69, 'yuv.min=', -20.648970000000002)
('yuv.max=', 237.17199999999997, 'yuv.min=', -52.082520000000009)
('yuv.max=', 249.529, 'yuv.min=', -41.885559999999998)
('yuv.max=', 184.19, 'yuv.min=', -7.6455799999999847)
('yuv.max=', 245.15700000000001, 'yuv.min=', -12.825359999999991)
('yuv.max=', 249.96699999999998, 'yuv.min=', -42.140769999999996)
('yuv.max=', 237.78099999999998, 'yuv.min=', -71.865359999999995)
('yuv.max=', 239.35900000000001, 'yuv.min=', -46.156880000000001)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 185.434, 'yuv.min=', -38.095549999999989)
('yuv.max=', 199.95399999999998, 'yuv.min=', -27.325170000000004)
('yuv.max=', 237.97199999999998, 'yuv.min=', -37.625379999999993)
('yuv.max=', 229.23999999999998, 'yuv.min=', -26.35535999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.030249999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', -41.300439999999988)
('yuv.max=', 251.60900000000001, 'yuv.min=', -48.105689999999989)
('yuv.max=', 248.99999999999997, 'yuv.min=', -26.567969999999999)
('yuv.max=', 251.45599999999996, 'yuv.min=', -14.07471000000001)
('yuv.max=', 236.22799999999998, 'yuv.min=', -24.580489999999998)
('yuv.max=', 251.75199999999998, 'yuv.min=', -49.159750000000003)
('yuv.max=', 222.178, 'yuv.min=', -34.480249999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -44.075409999999991)
('yuv.max=', 243.36999999999998, 'yuv.min=', -91.155689999999993)
('yuv.max=', 255.0, 'yuv.min=', -12.395439999999994)
('yuv.max=', 236.80599999999998, 'yuv.min=', -11.045960000000001)
('yuv.max=', 243.22800000000001, 'yuv.min=', -37.250649999999993)
('yuv.max=', 247.33699999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 250.08199999999997, 'yuv.min=', -40.039060000000006)
('yuv.max=', 229.12900000000002, 'yuv.min=', -16.94527999999999)
('yuv.max=', 232.91, 'yuv.min=', -102.48461)
('yuv.max=', 255.0, 'yuv.min=', -33.869519999999994)
('yuv.max=', 215.47299999999998, 'yuv.min=', -20.43561)
('yuv.max=', 255.0, 'yuv.min=', -7.8501699999999968)
('yuv.max=', 201.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -31.975429999999999)
('yuv.max=', 237.74599999999998, 'yuv.min=', -56.320219999999985)
('yuv.max=', 239.65599999999998, 'yuv.min=', -65.876819999999995)
('yuv.max=', 237.114, 'yuv.min=', -12.199989999999994)
('yuv.max=', 255.0, 'yuv.min=', -27.897580000000001)
('yuv.max=', 247.58199999999997, 'yuv.min=', -46.568399999999997)
('yuv.max=', 175.17599999999999, 'yuv.min=', -24.795449999999999)
('yuv.max=', 254.316, 'yuv.min=', -20.948299999999996)
('yuv.max=', 178.815, 'yuv.min=', -7.1949199999999962)
('yuv.max=', 254.47300000000001, 'yuv.min=', -61.544030000000014)
('yuv.max=', 254.11399999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 236.90099999999998, 'yuv.min=', -35.19422999999999)
('yuv.max=', 218.298, 'yuv.min=', -22.710179999999994)
('yuv.max=', 247.58699999999999, 'yuv.min=', -32.975529999999992)
('yuv.max=', 243.96099999999998, 'yuv.min=', -58.92342)
('yuv.max=', 255.0, 'yuv.min=', -79.245360000000005)
('yuv.max=', 255.0, 'yuv.min=', -57.342320000000015)
('yuv.max=', 254.40199999999999, 'yuv.min=', -40.375039999999998)
('yuv.max=', 255.0, 'yuv.min=', -26.616500000000006)
('yuv.max=', 251.14599999999996, 'yuv.min=', -19.78107)
('yuv.max=', 245.09200000000001, 'yuv.min=', -16.319909999999993)
('yuv.max=', 248.57599999999999, 'yuv.min=', -21.95701)
('yuv.max=', 217.18000000000001, 'yuv.min=', -95.709890000000001)
('yuv.max=', 249.673, 'yuv.min=', -35.950519999999997)
('yuv.max=', 255.0, 'yuv.min=', -43.830570000000002)
('yuv.max=', 236.04099999999997, 'yuv.min=', -38.529160000000005)
('yuv.max=', 250.0, 'yuv.min=', -35.908379999999994)
('yuv.max=', 250.86899999999997, 'yuv.min=', -53.821770000000001)
('yuv.max=', 210.47900000000001, 'yuv.min=', -32.792090000000002)
('yuv.max=', 251.02099999999999, 'yuv.min=', -31.36042999999999)
('yuv.max=', 255.0, 'yuv.min=', -45.112640000000006)
('yuv.max=', 196.22200000000001, 'yuv.min=', -73.169299999999993)
('yuv.max=', 129.33599999999998, 'yuv.min=', -31.00063999999999)
('yuv.max=', 248.71699999999998, 'yuv.min=', -68.400689999999997)
('yuv.max=', 162.15399999999997, 'yuv.min=', -15.330180000000002)
('yuv.max=', 227.10400000000001, 'yuv.min=', -27.340520000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.52591)
('yuv.max=', 102.75699999999999, 'yuv.min=', -90.040639999999982)
('yuv.max=', 241.59099999999998, 'yuv.min=', -30.945449999999987)
('yuv.max=', 228.09100000000001, 'yuv.min=', -39.700279999999992)
('yuv.max=', 251.04900000000001, 'yuv.min=', -15.660089999999993)
('yuv.max=', 252.196, 'yuv.min=', -17.175179999999994)
('yuv.max=', 239.80399999999997, 'yuv.min=', -22.380269999999989)
('yuv.max=', 245.886, 'yuv.min=', -18.222329999999999)
('yuv.max=', 220.96899999999999, 'yuv.min=', -24.901260000000001)
('yuv.max=', 226.39400000000001, 'yuv.min=', -22.260749999999994)
('yuv.max=', 225.78599999999997, 'yuv.min=', -77.421099999999996)
('yuv.max=', 255.0, 'yuv.min=', -29.315410000000004)
('yuv.max=', 255.0, 'yuv.min=', -41.145240000000001)
('yuv.max=', 251.85300000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 218.59399999999997, 'yuv.min=', -36.550410000000007)
('yuv.max=', 255.0, 'yuv.min=', -23.250479999999985)
('yuv.max=', 202.286, 'yuv.min=', -23.759249999999994)
('yuv.max=', 255.0, 'yuv.min=', -3.3393200000000007)
('yuv.max=', 205.0, 'yuv.min=', -9.3951399999999978)
('yuv.max=', 220.56999999999999, 'yuv.min=', -17.433239999999998)
('yuv.max=', 255.0, 'yuv.min=', -52.300309999999996)
('yuv.max=', 255.0, 'yuv.min=', -13.540369999999989)
('yuv.max=', 252.38000000000002, 'yuv.min=', -68.28573999999999)
('yuv.max=', 209.48899999999998, 'yuv.min=', -56.132469999999998)
('yuv.max=', 232.78199999999998, 'yuv.min=', -34.32808)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.141330000000004)
('yuv.max=', 212.13999999999999, 'yuv.min=', -29.240709999999993)
('yuv.max=', 237.142, 'yuv.min=', -38.181600000000003)
('yuv.max=', 230.43000000000001, 'yuv.min=', -84.586100000000002)
('yuv.max=', 216.02100000000002, 'yuv.min=', -23.510259999999995)
('yuv.max=', 167.58599999999998, 'yuv.min=', -15.601689999999998)
('yuv.max=', 239.40999999999997, 'yuv.min=', -52.790900000000008)
('yuv.max=', 252.27699999999999, 'yuv.min=', -89.115239999999986)
('yuv.max=', 229.929, 'yuv.min=', -10.840099999999996)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.779849999999982)
('yuv.max=', 255.0, 'yuv.min=', -26.719719999999995)
('yuv.max=', 248.322, 'yuv.min=', -44.899569999999997)
('yuv.max=', 245.13799999999998, 'yuv.min=', -67.015320000000003)
('yuv.max=', 247.06, 'yuv.min=', -56.388249999999999)
('yuv.max=', 241.73999999999998, 'yuv.min=', -38.650309999999998)
('yuv.max=', 204.989, 'yuv.min=', -14.996919999999996)
('yuv.max=', 253.84299999999996, 'yuv.min=', -28.385439999999996)
('yuv.max=', 248.381, 'yuv.min=', -29.630379999999999)
('yuv.max=', 238.42999999999995, 'yuv.min=', -34.158949999999997)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 200.60199999999998, 'yuv.min=', -20.920370000000002)
('yuv.max=', 210.24300000000002, 'yuv.min=', -32.975529999999978)
('yuv.max=', 194.327, 'yuv.min=', -32.175449999999984)
('yuv.max=', 233.428, 'yuv.min=', -14.118620000000007)
('yuv.max=', 224.85199999999998, 'yuv.min=', -20.936659999999989)
('yuv.max=', 195.50299999999999, 'yuv.min=', -12.855239999999998)
('yuv.max=', 181.386, 'yuv.min=', -33.905499999999989)
('yuv.max=', 250.72, 'yuv.min=', -28.065190000000001)
('yuv.max=', 233.05599999999998, 'yuv.min=', -9.954970000000003)
('yuv.max=', 219.387, 'yuv.min=', -44.535209999999992)
('yuv.max=', 243.82399999999998, 'yuv.min=', -33.75480000000001)
('yuv.max=', 248.47300000000001, 'yuv.min=', -58.560689999999987)
('yuv.max=', 193.44200000000001, 'yuv.min=', -30.945449999999987)
('yuv.max=', 202.91399999999999, 'yuv.min=', -40.785449999999997)
('yuv.max=', 177.19800000000001, 'yuv.min=', -10.480309999999996)
('yuv.max=', 241.095, 'yuv.min=', -45.412670000000006)
('yuv.max=', 255.0, 'yuv.min=', -3.0451199999999972)
('yuv.max=', 222.80099999999999, 'yuv.min=', -56.745570000000001)
('yuv.max=', 235.32099999999997, 'yuv.min=', -18.076090000000004)
('yuv.max=', 202.65199999999999, 'yuv.min=', -33.602320000000006)
('yuv.max=', 181.61799999999999, 'yuv.min=', -23.180349999999997)
('yuv.max=', 171.53200000000001, 'yuv.min=', -18.890289999999997)
('yuv.max=', 176.83000000000001, 'yuv.min=', -11.455099999999991)
('yuv.max=', 234.19999999999999, 'yuv.min=', -37.689760000000007)
('yuv.max=', 255.0, 'yuv.min=', -20.060529999999993)
('yuv.max=', 255.0, 'yuv.min=', -26.204729999999994)
('yuv.max=', 255.0, 'yuv.min=', -37.264299999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 240.71199999999999, 'yuv.min=', -40.655560000000001)
('yuv.max=', 252.10300000000001, 'yuv.min=', -38.083380000000005)
('yuv.max=', 184.16499999999999, 'yuv.min=', -13.515059999999995)
('yuv.max=', 211.345, 'yuv.min=', -100.55569000000001)
('yuv.max=', 230.464, 'yuv.min=', -32.920339999999996)
('yuv.max=', 219.70099999999999, 'yuv.min=', -26.741950000000006)
('yuv.max=', 255.0, 'yuv.min=', -52.940619999999996)
('yuv.max=', 251.71800000000002, 'yuv.min=', -21.047059999999998)
('yuv.max=', 233.69, 'yuv.min=', -24.710379999999986)
('yuv.max=', 200.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 193.88200000000001, 'yuv.min=', -40.055499999999995)
('yuv.max=', 230.39500000000001, 'yuv.min=', -31.390309999999996)
('yuv.max=', 243.989, 'yuv.min=', -21.765330000000002)
('yuv.max=', 183.73499999999999, 'yuv.min=', -32.385839999999995)
('yuv.max=', 236.32799999999997, 'yuv.min=', -47.045829999999988)
('yuv.max=', 239.69, 'yuv.min=', -23.210229999999996)
('yuv.max=', 198.31399999999999, 'yuv.min=', -28.055529999999994)
('yuv.max=', 235.68000000000001, 'yuv.min=', -73.485199999999992)
('yuv.max=', 255.0, 'yuv.min=', -8.0214600000000011)
('yuv.max=', 255.0, 'yuv.min=', -20.991760000000003)
('yuv.max=', 237.72899999999998, 'yuv.min=', -37.355229999999985)
('yuv.max=', 253.97400000000002, 'yuv.min=', -85.414869999999993)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 172.32499999999999, 'yuv.min=', -8.8249599999999937)
('yuv.max=', 196.84300000000002, 'yuv.min=', -3.6049299999999986)
('yuv.max=', 253.505, 'yuv.min=', -6.9650200000000027)
('yuv.max=', 208.76899999999998, 'yuv.min=', -55.985739999999993)
('yuv.max=', 239.797, 'yuv.min=', -50.633929999999999)
('yuv.max=', 194.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.52199999999999, 'yuv.min=', -27.145069999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.072850000000003)
('yuv.max=', 250.131, 'yuv.min=', -24.441799999999997)
('yuv.max=', 207.642, 'yuv.min=', -35.380340000000004)
('yuv.max=', 255.0, 'yuv.min=', -45.620570000000001)
('yuv.max=', 237.77199999999999, 'yuv.min=', -7.4056899999999999)
('yuv.max=', 213.745, 'yuv.min=', -45.473650000000006)
('yuv.max=', 227.48400000000001, 'yuv.min=', -57.300809999999998)
('yuv.max=', 225.482, 'yuv.min=', -18.011130000000001)
('yuv.max=', 235.608, 'yuv.min=', -28.839650000000002)
('yuv.max=', 224.90699999999998, 'yuv.min=', -22.735489999999995)
('yuv.max=', 188.44499999999999, 'yuv.min=', -26.055329999999987)
('yuv.max=', 217.79799999999997, 'yuv.min=', -37.116619999999998)
('yuv.max=', 255.0, 'yuv.min=', -25.640349999999994)
('yuv.max=', 251.41300000000001, 'yuv.min=', -32.690439999999981)
('yuv.max=', 249.85399999999998, 'yuv.min=', -19.089599999999997)
('yuv.max=', 255.0, 'yuv.min=', -27.025549999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.350589999999997)
('yuv.max=', 255.0, 'yuv.min=', -8.8801500000000004)
('yuv.max=', 245.78100000000001, 'yuv.min=', -26.63008)
('yuv.max=', 254.886, 'yuv.min=', -66.815469999999991)
('yuv.max=', 233.13200000000001, 'yuv.min=', -18.59025999999999)
('yuv.max=', 247.46599999999998, 'yuv.min=', -30.000539999999997)
('yuv.max=', 225.97800000000001, 'yuv.min=', -34.765339999999995)
('yuv.max=', 255.0, 'yuv.min=', -43.749300000000012)
('yuv.max=', 206.65899999999999, 'yuv.min=', -63.108640000000008)
('yuv.max=', 239.88399999999999, 'yuv.min=', -97.66167999999999)
('yuv.max=', 242.874, 'yuv.min=', -60.684979999999996)
('yuv.max=', 224.89699999999999, 'yuv.min=', -58.820469999999986)
('yuv.max=', 194.94199999999998, 'yuv.min=', -18.669070000000005)
('yuv.max=', 233.03099999999998, 'yuv.min=', -65.550820000000002)
('yuv.max=', 252.114, 'yuv.min=', -13.055259999999993)
('yuv.max=', 252.935, 'yuv.min=', -24.540240000000004)
('yuv.max=', 244.72899999999998, 'yuv.min=', -24.168109999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 220.78700000000001, 'yuv.min=', -30.484979999999997)
('yuv.max=', 243.35899999999998, 'yuv.min=', -43.370769999999993)
('yuv.max=', 254.18499999999997, 'yuv.min=', -24.932120000000005)
('yuv.max=', 251.52700000000002, 'yuv.min=', -25.54033999999999)
('yuv.max=', 234.67999999999998, 'yuv.min=', -28.055529999999997)
('yuv.max=', 242.75, 'yuv.min=', -18.305169999999986)
('yuv.max=', 255.0, 'yuv.min=', -51.459979999999995)
('yuv.max=', 247.33799999999999, 'yuv.min=', -58.305479999999996)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.06399999999999, 'yuv.min=', -24.040189999999996)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 205.99899999999997, 'yuv.min=', -72.263640000000009)
('yuv.max=', 228.34199999999998, 'yuv.min=', -7.3501200000000004)
('yuv.max=', 249.64699999999999, 'yuv.min=', -13.25352)
('yuv.max=', 201.13599999999997, 'yuv.min=', -55.488910000000018)
('yuv.max=', 218.36699999999999, 'yuv.min=', -64.029170000000008)
('yuv.max=', 237.13499999999996, 'yuv.min=', -14.900259999999992)
('yuv.max=', 248.40899999999999, 'yuv.min=', -7.4260400000000146)
('yuv.max=', 235.46299999999999, 'yuv.min=', -29.809659999999987)
('yuv.max=', 243.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 224.68299999999999, 'yuv.min=', -13.200089999999996)
('yuv.max=', 245.43999999999997, 'yuv.min=', -55.947990000000004)
('yuv.max=', 253.58699999999999, 'yuv.min=', -20.53526999999999)
('yuv.max=', 235.262, 'yuv.min=', -23.655089999999998)
('yuv.max=', 227.54299999999995, 'yuv.min=', -25.640349999999991)
('yuv.max=', 243.75400000000002, 'yuv.min=', -26.490669999999994)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 138.67400000000001, 'yuv.min=', -14.900259999999999)
('yuv.max=', 211.89999999999998, 'yuv.min=', -30.030419999999989)
('yuv.max=', 217.059, 'yuv.min=', -40.100319999999996)
('yuv.max=', 252.309, 'yuv.min=', -43.86045)
('yuv.max=', 228.27699999999996, 'yuv.min=', -22.125059999999998)
('yuv.max=', 253.36999999999998, 'yuv.min=', -13.37727000000001)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.929, 'yuv.min=', -30.403489999999998)
('yuv.max=', 225.744, 'yuv.min=', -44.912090000000006)
('yuv.max=', 255.0, 'yuv.min=', -21.725019999999986)
('yuv.max=', 187.17999999999998, 'yuv.min=', -16.015309999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.060980000000015)
('yuv.max=', 241.17599999999999, 'yuv.min=', -62.373280000000001)
('yuv.max=', 248.51599999999996, 'yuv.min=', -47.065339999999992)
('yuv.max=', 227.03199999999998, 'yuv.min=', -51.370339999999992)
('yuv.max=', 233.821, 'yuv.min=', -21.253630000000005)
('yuv.max=', 227.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 206.41300000000001, 'yuv.min=', -71.44144)
('yuv.max=', 255.0, 'yuv.min=', -13.379280000000001)
('yuv.max=', 250.39099999999999, 'yuv.min=', -18.520129999999998)
('yuv.max=', 236.41, 'yuv.min=', -35.155470000000008)
('yuv.max=', 251.70099999999996, 'yuv.min=', -43.675370000000001)
('yuv.max=', 206.97, 'yuv.min=', -31.120159999999998)
('yuv.max=', 237.142, 'yuv.min=', -55.225909999999985)
('yuv.max=', 225.72999999999999, 'yuv.min=', -34.21249000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.276910000000008)
('yuv.max=', 236.84699999999998, 'yuv.min=', -19.939279999999997)
('yuv.max=', 159.86599999999999, 'yuv.min=', -35.060799999999986)
('yuv.max=', 255.0, 'yuv.min=', -53.614280000000008)
('yuv.max=', 223.95699999999999, 'yuv.min=', -48.0505)
('yuv.max=', 252.11599999999999, 'yuv.min=', -62.289770000000004)
('yuv.max=', 255.0, 'yuv.min=', -38.100119999999983)
('yuv.max=', 231.23599999999996, 'yuv.min=', -33.32038)
('yuv.max=', 232.99600000000001, 'yuv.min=', -26.455369999999995)
('yuv.max=', 220.97, 'yuv.min=', -14.770369999999996)
('yuv.max=', 246.51000000000002, 'yuv.min=', -49.243240000000014)
('yuv.max=', 236.36600000000001, 'yuv.min=', -54.17062)
('yuv.max=', 239.61899999999997, 'yuv.min=', -38.039580000000008)
('yuv.max=', 221.81099999999998, 'yuv.min=', -41.830369999999995)
('yuv.max=', 212.40899999999999, 'yuv.min=', -17.660289999999989)
('yuv.max=', 253.19100000000003, 'yuv.min=', -58.143460000000012)
('yuv.max=', 215.625, 'yuv.min=', -48.140139999999995)
('yuv.max=', 229.285, 'yuv.min=', -29.499820000000003)
('yuv.max=', 184.952, 'yuv.min=', -33.290499999999994)
('yuv.max=', 165.24299999999999, 'yuv.min=', -24.090809999999998)
('yuv.max=', 251.755, 'yuv.min=', -37.585129999999992)
('yuv.max=', 234.46099999999998, 'yuv.min=', -16.892440000000008)
('yuv.max=', 248.46599999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 136.13999999999999, 'yuv.min=', -7.9499400000000016)
('yuv.max=', 255.0, 'yuv.min=', -6.5661700000000032)
('yuv.max=', 248.95699999999999, 'yuv.min=', -31.090279999999989)
('yuv.max=', 211.14999999999998, 'yuv.min=', -21.905529999999995)
('yuv.max=', 252.22999999999996, 'yuv.min=', -32.916300000000007)
('yuv.max=', 227.755, 'yuv.min=', -26.785440000000008)
('yuv.max=', 216.35199999999998, 'yuv.min=', -14.430089999999993)
('yuv.max=', 253.404, 'yuv.min=', -37.242220000000003)
('yuv.max=', 162.90099999999998, 'yuv.min=', -8.735870000000002)
('yuv.max=', 213.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.06, 'yuv.min=', -48.550550000000001)
('yuv.max=', 198.19499999999999, 'yuv.min=', -24.280459999999991)
('yuv.max=', 250.73299999999998, 'yuv.min=', -59.565359999999991)
('yuv.max=', 252.91799999999998, 'yuv.min=', -21.850339999999992)
('yuv.max=', 254.47300000000001, 'yuv.min=', -32.505359999999996)
('yuv.max=', 253.29900000000001, 'yuv.min=', -54.870689999999996)
('yuv.max=', 238.11599999999999, 'yuv.min=', -56.055890000000005)
('yuv.max=', 225.98599999999999, 'yuv.min=', -37.380539999999982)
('yuv.max=', 203.11599999999999, 'yuv.min=', -52.709300000000006)
('yuv.max=', 210.21399999999997, 'yuv.min=', -55.865620000000007)
('yuv.max=', 221.685, 'yuv.min=', -35.350459999999991)
('yuv.max=', 192.637, 'yuv.min=', -30.630479999999981)
('yuv.max=', 248.10900000000001, 'yuv.min=', -36.210299999999997)
('yuv.max=', 232.024, 'yuv.min=', -21.427000000000007)
('yuv.max=', 241.28799999999998, 'yuv.min=', -26.674899999999987)
('yuv.max=', 157.583, 'yuv.min=', -36.550579999999997)
('yuv.max=', 195.05199999999999, 'yuv.min=', -13.662229999999997)
('yuv.max=', 255.0, 'yuv.min=', -76.555459999999997)
('yuv.max=', 248.61600000000001, 'yuv.min=', -55.805450000000008)
('yuv.max=', 244.86799999999999, 'yuv.min=', -28.56594999999999)
('yuv.max=', 208.28200000000001, 'yuv.min=', -24.42528999999999)
('yuv.max=', 190.18799999999999, 'yuv.min=', -25.370199999999993)
('yuv.max=', 232.20400000000001, 'yuv.min=', -23.010209999999994)
('yuv.max=', 220.452, 'yuv.min=', -15.475090000000009)
('yuv.max=', 253.505, 'yuv.min=', -13.87027999999999)
('yuv.max=', 253.82599999999996, 'yuv.min=', -27.89246)
('yuv.max=', 232.25699999999998, 'yuv.min=', -51.725559999999987)
('yuv.max=', 190.88, 'yuv.min=', -59.96893)
('yuv.max=', 250.63, 'yuv.min=', -51.314139999999995)
('yuv.max=', 243.52699999999999, 'yuv.min=', -10.125089999999993)
('yuv.max=', 215.86199999999999, 'yuv.min=', -76.585589999999996)
('yuv.max=', 244.398, 'yuv.min=', -57.790489999999991)
('yuv.max=', 210.16499999999999, 'yuv.min=', -29.590129999999995)
('yuv.max=', 220.80399999999997, 'yuv.min=', -48.165449999999986)
('yuv.max=', 236.69399999999999, 'yuv.min=', -48.66686)
('yuv.max=', 241.04200000000003, 'yuv.min=', -17.545339999999996)
('yuv.max=', 188.328, 'yuv.min=', -29.248199999999997)
('yuv.max=', 248.0, 'yuv.min=', -13.170209999999994)
('yuv.max=', 226.85500000000002, 'yuv.min=', -29.930409999999995)
('yuv.max=', 255.0, 'yuv.min=', -57.451490000000007)
('yuv.max=', 239.58700000000002, 'yuv.min=', -74.395540000000011)
('yuv.max=', 250.42299999999997, 'yuv.min=', -29.405049999999992)
('yuv.max=', 248.71799999999999, 'yuv.min=', -12.0701)
('yuv.max=', 168.54500000000002, 'yuv.min=', -44.103129999999993)
('yuv.max=', 248.75900000000001, 'yuv.min=', -29.220340000000004)
('yuv.max=', 251.65799999999999, 'yuv.min=', -30.770739999999996)
('yuv.max=', 255.0, 'yuv.min=', -36.981589999999997)
('yuv.max=', 243.62599999999998, 'yuv.min=', -82.754850000000005)
('yuv.max=', 165.97899999999998, 'yuv.min=', -26.702500000000001)
('yuv.max=', 251.22799999999998, 'yuv.min=', -6.2500099999999872)
('yuv.max=', 252.80399999999997, 'yuv.min=', -15.684670000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', -2.4682500000000012)
('yuv.max=', 243.21999999999997, 'yuv.min=', -30.408289999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.440259999999995)
('yuv.max=', 214.077, 'yuv.min=', -38.856390000000005)
('yuv.max=', 243.28799999999998, 'yuv.min=', -26.155339999999995)
('yuv.max=', 252.02099999999996, 'yuv.min=', -76.180729999999997)
('yuv.max=', 255.0, 'yuv.min=', -82.190469999999991)
('yuv.max=', 240.71199999999999, 'yuv.min=', -14.84507)
('yuv.max=', 216.19, 'yuv.min=', -35.101060000000004)
('yuv.max=', 206.78399999999999, 'yuv.min=', -45.947080000000014)
('yuv.max=', 254.65800000000002, 'yuv.min=', -41.723320000000001)
('yuv.max=', 254.316, 'yuv.min=', -67.64542999999999)
('yuv.max=', 180.88799999999998, 'yuv.min=', -43.428770000000007)
('yuv.max=', 181.22799999999998, 'yuv.min=', -14.53979)
('yuv.max=', 189.64899999999997, 'yuv.min=', -23.835599999999996)
('yuv.max=', 250.86199999999997, 'yuv.min=', -49.500029999999995)
('yuv.max=', 247.03199999999998, 'yuv.min=', -17.280680000000004)
('yuv.max=', 221.70499999999998, 'yuv.min=', -16.96022)
('yuv.max=', 255.0, 'yuv.min=', -3.2750199999999987)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -11.742729999999998)
('yuv.max=', 236.27800000000002, 'yuv.min=', -7.7647499999999994)
('yuv.max=', 239.69399999999999, 'yuv.min=', -14.445029999999988)
('yuv.max=', 218.988, 'yuv.min=', -21.25028)
('yuv.max=', 196.31199999999998, 'yuv.min=', -25.329949999999997)
('yuv.max=', 249.47800000000001, 'yuv.min=', -21.980229999999999)
('yuv.max=', 249.89099999999999, 'yuv.min=', -24.853640000000002)
('yuv.max=', 194.59399999999999, 'yuv.min=', -34.665329999999997)
('yuv.max=', 253.0, 'yuv.min=', -17.305070000000001)
('yuv.max=', 244.316, 'yuv.min=', -16.32594000000001)
('yuv.max=', 243.523, 'yuv.min=', -30.370700000000003)
('yuv.max=', 255.0, 'yuv.min=', -15.425619999999997)
('yuv.max=', 201.13899999999998, 'yuv.min=', -16.488730000000007)
('yuv.max=', 207.61000000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 112.28299999999999, 'yuv.min=', -15.885169999999995)
('yuv.max=', 254.202, 'yuv.min=', -24.910399999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.028369999999995)
('yuv.max=', 224.53699999999998, 'yuv.min=', -82.005389999999991)
('yuv.max=', 227.61499999999998, 'yuv.min=', -27.15618000000001)
('yuv.max=', 169.32399999999998, 'yuv.min=', -49.020719999999983)
('yuv.max=', 253.29900000000001, 'yuv.min=', -76.385319999999979)
('yuv.max=', 239.83799999999999, 'yuv.min=', -46.79061999999999)
('yuv.max=', 244.81700000000001, 'yuv.min=', -44.546370000000003)
('yuv.max=', 199.13299999999998, 'yuv.min=', -26.825529999999986)
('yuv.max=', 165.61599999999999, 'yuv.min=', -3.4003399999999857)
('yuv.max=', 232.21699999999998, 'yuv.min=', -15.804919999999994)
('yuv.max=', 252.22999999999996, 'yuv.min=', -35.220569999999988)
('yuv.max=', 177.55799999999999, 'yuv.min=', -15.760099999999987)
('yuv.max=', 248.32999999999998, 'yuv.min=', -54.160249999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.555109999999996)
('yuv.max=', 198.09299999999999, 'yuv.min=', -23.765469999999993)
('yuv.max=', 245.744, 'yuv.min=', -37.800089999999997)
('yuv.max=', 222.80500000000001, 'yuv.min=', -21.732040000000012)
('yuv.max=', 231.21700000000001, 'yuv.min=', -60.394170000000003)
('yuv.max=', 209.38, 'yuv.min=', -36.389579999999995)
('yuv.max=', 237.69799999999995, 'yuv.min=', -36.410319999999999)
('yuv.max=', 238.09999999999999, 'yuv.min=', -39.95548999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', -22.387790000000003)
('yuv.max=', 240.89399999999998, 'yuv.min=', -17.023219999999995)
('yuv.max=', 225.96100000000001, 'yuv.min=', -15.260049999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.490119999999983)
('yuv.max=', 241.82599999999996, 'yuv.min=', -38.355329999999995)
('yuv.max=', 250.03899999999999, 'yuv.min=', -71.550389999999993)
('yuv.max=', 239.87199999999996, 'yuv.min=', -17.690169999999995)
('yuv.max=', 248.0, 'yuv.min=', -35.650489999999991)
('yuv.max=', 230.22799999999998, 'yuv.min=', -52.180790000000002)
('yuv.max=', 240.755, 'yuv.min=', -4.8050499999999925)
('yuv.max=', 225.63700000000003, 'yuv.min=', -24.436530000000001)
('yuv.max=', 243.81100000000001, 'yuv.min=', -29.743519999999997)
('yuv.max=', 240.11299999999997, 'yuv.min=', -59.005549999999999)
('yuv.max=', 250.26199999999997, 'yuv.min=', -30.848420000000004)
('yuv.max=', 230.64699999999996, 'yuv.min=', -97.536000000000001)
('yuv.max=', 249.07099999999997, 'yuv.min=', -17.454960000000007)
('yuv.max=', 231.0, 'yuv.min=', -26.625509999999995)
('yuv.max=', 216.04799999999997, 'yuv.min=', -31.150000000000013)
('yuv.max=', 236.66799999999998, 'yuv.min=', -30.920139999999989)
('yuv.max=', 250.815, 'yuv.min=', -25.345969999999994)
('yuv.max=', 249.14999999999998, 'yuv.min=', -43.930340000000001)
('yuv.max=', 216.44899999999998, 'yuv.min=', -28.285429999999995)
('yuv.max=', 202.381, 'yuv.min=', -71.065279999999987)
('yuv.max=', 233.07500000000002, 'yuv.min=', -23.550509999999999)
('yuv.max=', 241.97900000000001, 'yuv.min=', -27.699900000000007)
('yuv.max=', 193.90200000000002, 'yuv.min=', -36.920739999999995)
('yuv.max=', 245.376, 'yuv.min=', -78.144440000000003)
('yuv.max=', 252.58699999999999, 'yuv.min=', -22.829039999999996)
('yuv.max=', 239.55299999999997, 'yuv.min=', -21.068569999999998)
('yuv.max=', 252.10300000000001, 'yuv.min=', -48.965530000000001)
('yuv.max=', 159.44499999999996, 'yuv.min=', -16.736000000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.4834400000000016)
('yuv.max=', 246.35900000000001, 'yuv.min=', -32.088909999999998)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 199.49299999999999, 'yuv.min=', -9.3756299999999957)
('yuv.max=', 247.852, 'yuv.min=', -45.433670000000006)
('yuv.max=', 251.50500000000002, 'yuv.min=', -63.910609999999991)
('yuv.max=', 243.583, 'yuv.min=', -23.438829999999999)
('yuv.max=', 247.893, 'yuv.min=', -29.100449999999991)
('yuv.max=', 255.0, 'yuv.min=', -58.420429999999982)
('yuv.max=', 231.43000000000001, 'yuv.min=', -82.101089999999999)
('yuv.max=', 251.03799999999998, 'yuv.min=', -62.955329999999989)
('yuv.max=', 255.0, 'yuv.min=', -63.544880000000013)
('yuv.max=', 156.55799999999999, 'yuv.min=', -41.360199999999992)
('yuv.max=', 246.26999999999998, 'yuv.min=', -37.302740000000007)
('yuv.max=', 250.501, 'yuv.min=', -90.544029999999978)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 225.24099999999999, 'yuv.min=', -26.885289999999994)
('yuv.max=', 176.364, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.96099999999998, 'yuv.min=', -31.630579999999995)
('yuv.max=', 252.93999999999997, 'yuv.min=', -19.710599999999999)
('yuv.max=', 255.0, 'yuv.min=', -61.540249999999993)
('yuv.max=', 207.554, 'yuv.min=', -21.05827)
('yuv.max=', 250.03200000000001, 'yuv.min=', -50.310479999999984)
('yuv.max=', 154.88900000000001, 'yuv.min=', -26.655389999999997)
('yuv.max=', 228.80199999999999, 'yuv.min=', -62.020789999999991)
('yuv.max=', 255.0, 'yuv.min=', -33.410019999999989)
('yuv.max=', 246.042, 'yuv.min=', -55.805229999999995)
('yuv.max=', 173.44099999999997, 'yuv.min=', -8.6745900000000056)
('yuv.max=', 209.82699999999997, 'yuv.min=', -70.385950000000008)
('yuv.max=', 235.72800000000001, 'yuv.min=', -57.180059999999997)
('yuv.max=', 248.00999999999999, 'yuv.min=', -51.535910000000001)
('yuv.max=', 248.869, 'yuv.min=', -56.000679999999988)
('yuv.max=', 234.20599999999996, 'yuv.min=', -44.350130000000007)
('yuv.max=', 238.39599999999999, 'yuv.min=', -22.460769999999989)
('yuv.max=', 251.72199999999998, 'yuv.min=', -53.340659999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 243.63200000000001, 'yuv.min=', -38.640419999999992)
('yuv.max=', 220.91, 'yuv.min=', -80.330529999999996)
('yuv.max=', 240.0, 'yuv.min=', -46.250320000000002)
('yuv.max=', 221.28800000000001, 'yuv.min=', -21.06519999999999)
('yuv.max=', 230.57199999999997, 'yuv.min=', -48.125199999999992)
('yuv.max=', 237.17500000000001, 'yuv.min=', -32.650189999999995)
('yuv.max=', 230.13099999999997, 'yuv.min=', -18.835099999999997)
('yuv.max=', 243.40100000000001, 'yuv.min=', -54.485589999999988)
('yuv.max=', 229.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.84299999999999, 'yuv.min=', -7.8564700000000016)
('yuv.max=', 178.0, 'yuv.min=', -14.729890000000001)
('yuv.max=', 243.34599999999998, 'yuv.min=', -43.31557999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', -7.9949999999999974)
('yuv.max=', 132.42499999999998, 'yuv.min=', -25.335749999999994)
('yuv.max=', 242.92499999999998, 'yuv.min=', -24.940279999999994)
('yuv.max=', 238.53800000000001, 'yuv.min=', -23.45008)
('yuv.max=', 255.0, 'yuv.min=', -21.286039999999996)
('yuv.max=', 239.78799999999998, 'yuv.min=', -45.570989999999995)
('yuv.max=', 248.99999999999997, 'yuv.min=', -53.400419999999997)
('yuv.max=', 204.03399999999999, 'yuv.min=', -27.440529999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -30.56035)
('yuv.max=', 146.797, 'yuv.min=', -50.250719999999994)
('yuv.max=', 150.84099999999998, 'yuv.min=', -98.073429999999988)
('yuv.max=', 247.08800000000002, 'yuv.min=', -36.732150000000004)
('yuv.max=', 234.75899999999999, 'yuv.min=', -36.375950000000003)
('yuv.max=', 243.31599999999997, 'yuv.min=', -40.224460000000008)
('yuv.max=', 233.24199999999999, 'yuv.min=', -33.124929999999999)
('yuv.max=', 187.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.41800000000001, 'yuv.min=', -24.294120000000007)
('yuv.max=', 197.602, 'yuv.min=', -19.204340000000002)
('yuv.max=', 227.71099999999998, 'yuv.min=', -61.580499999999994)
('yuv.max=', 255.0, 'yuv.min=', -17.121539999999996)
('yuv.max=', 220.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.0, 'yuv.min=', -46.865319999999997)
('yuv.max=', 238.36199999999999, 'yuv.min=', -32.685869999999994)
('yuv.max=', 210.62499999999997, 'yuv.min=', -38.371350000000007)
('yuv.max=', 255.0, 'yuv.min=', -59.206560000000017)
('yuv.max=', 204.19999999999999, 'yuv.min=', -22.680299999999988)
('yuv.max=', 189.15000000000001, 'yuv.min=', -37.770840000000007)
('yuv.max=', 233.11399999999998, 'yuv.min=', -10.0702)
('yuv.max=', 254.886, 'yuv.min=', -27.586950000000005)
('yuv.max=', 235.22299999999998, 'yuv.min=', -20.080039999999986)
('yuv.max=', 251.30500000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 241.71799999999996, 'yuv.min=', -29.825220000000002)
('yuv.max=', 230.79799999999997, 'yuv.min=', -44.426190000000005)
('yuv.max=', 255.0, 'yuv.min=', -10.364379999999997)
('yuv.max=', 241.68399999999997, 'yuv.min=', -35.935579999999995)
('yuv.max=', 184.30099999999999, 'yuv.min=', -47.63064)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 237.72199999999998, 'yuv.min=', -21.265220000000003)
('yuv.max=', 238.43099999999998, 'yuv.min=', -89.125609999999995)
('yuv.max=', 247.36399999999998, 'yuv.min=', -18.864979999999996)
('yuv.max=', 202.935, 'yuv.min=', -26.910599999999999)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 171.94399999999999, 'yuv.min=', -28.18364)
('yuv.max=', 236.67599999999999, 'yuv.min=', -42.52006999999999)
('yuv.max=', 255.0, 'yuv.min=', -35.810259999999985)
('yuv.max=', 251.393, 'yuv.min=', -19.545539999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', -13.370229999999996)
('yuv.max=', 250.47299999999998, 'yuv.min=', -17.560279999999988)
('yuv.max=', 246.512, 'yuv.min=', -18.185649999999995)
('yuv.max=', 217.684, 'yuv.min=', -49.37473)
('yuv.max=', 228.34800000000001, 'yuv.min=', -26.04327)
('yuv.max=', 236.85600000000002, 'yuv.min=', -8.2925699999999978)
('yuv.max=', 243.52699999999999, 'yuv.min=', -25.655289999999994)
('yuv.max=', 249.20799999999997, 'yuv.min=', -34.935479999999998)
('yuv.max=', 251.54399999999998, 'yuv.min=', -58.860720000000001)
('yuv.max=', 253.0, 'yuv.min=', -15.379349999999999)
('yuv.max=', 242.88799999999998, 'yuv.min=', -24.856289999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -30.114740000000012)
('yuv.max=', 139.28699999999998, 'yuv.min=', -20.42032)
('yuv.max=', 245.727, 'yuv.min=', -39.495689999999989)
('yuv.max=', 237.88799999999998, 'yuv.min=', -17.645349999999993)
('yuv.max=', 245.76499999999999, 'yuv.min=', -46.72587)
('yuv.max=', 231.435, 'yuv.min=', -22.866860000000003)
('yuv.max=', 243.82999999999998, 'yuv.min=', -30.13043)
('yuv.max=', 250.02099999999999, 'yuv.min=', -29.59926999999999)
('yuv.max=', 230.732, 'yuv.min=', -47.950489999999995)
('yuv.max=', 199.535, 'yuv.min=', -33.620409999999985)
('yuv.max=', 241.447, 'yuv.min=', -16.13138)
('yuv.max=', 255.0, 'yuv.min=', -38.150739999999992)
('yuv.max=', 202.20699999999997, 'yuv.min=', -27.840570000000003)
('yuv.max=', 243.536, 'yuv.min=', -35.951309999999999)
('yuv.max=', 189.37200000000001, 'yuv.min=', -34.277369999999998)
('yuv.max=', 187.14899999999997, 'yuv.min=', -21.557720000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -35.350459999999998)
('yuv.max=', 252.64099999999996, 'yuv.min=', -33.385939999999998)
('yuv.max=', 255.0, 'yuv.min=', -58.170859999999998)
('yuv.max=', 233.82599999999999, 'yuv.min=', -64.065809999999999)
('yuv.max=', 250.40599999999998, 'yuv.min=', -25.927000000000007)
('yuv.max=', 255.0, 'yuv.min=', -25.640350000000002)
('yuv.max=', 247.57099999999997, 'yuv.min=', -67.685679999999991)
('yuv.max=', 254.886, 'yuv.min=', -83.29007)
('yuv.max=', 210.71100000000001, 'yuv.min=', -17.482240000000001)
('yuv.max=', 253.07700000000003, 'yuv.min=', -52.055189999999996)
('yuv.max=', 182.36600000000001, 'yuv.min=', -17.960319999999989)
('yuv.max=', 243.56999999999999, 'yuv.min=', -56.175389999999993)
('yuv.max=', 243.29800000000003, 'yuv.min=', -38.240379999999988)
('yuv.max=', 243.16099999999997, 'yuv.min=', -35.065369999999987)
('yuv.max=', 255.0, 'yuv.min=', -22.554979999999997)
('yuv.max=', 250.0, 'yuv.min=', -0.61499999999998778)
('yuv.max=', 222.84699999999998, 'yuv.min=', -38.665729999999996)
('yuv.max=', 234.17599999999999, 'yuv.min=', -41.771529999999991)
('yuv.max=', 250.53699999999998, 'yuv.min=', -31.120159999999988)
('yuv.max=', 243.33499999999998, 'yuv.min=', -28.692120000000003)
('yuv.max=', 254.06, 'yuv.min=', -21.120389999999993)
('yuv.max=', 220.25499999999997, 'yuv.min=', -32.920339999999996)
('yuv.max=', 169.35999999999999, 'yuv.min=', -39.510629999999992)
('yuv.max=', 238.23899999999998, 'yuv.min=', -36.55514999999999)
('yuv.max=', 246.06, 'yuv.min=', -27.385339999999996)
('yuv.max=', 250.27099999999999, 'yuv.min=', -26.11051999999999)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 221.37699999999998, 'yuv.min=', -40.151560000000003)
('yuv.max=', 255.0, 'yuv.min=', -28.911280000000001)
('yuv.max=', 238.24199999999999, 'yuv.min=', -57.151409999999991)
('yuv.max=', 241.369, 'yuv.min=', -31.655889999999999)
('yuv.max=', 253.97400000000002, 'yuv.min=', -20.838770000000004)
('yuv.max=', 231.56299999999999, 'yuv.min=', -27.14506999999999)
('yuv.max=', 235.256, 'yuv.min=', -17.89575)
('yuv.max=', 239.86899999999997, 'yuv.min=', -35.282309999999995)
('yuv.max=', 246.84599999999998, 'yuv.min=', -19.940320000000003)
('yuv.max=', 248.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.15699999999998, 'yuv.min=', -23.205300000000005)
('yuv.max=', 253.84299999999996, 'yuv.min=', -27.924470000000003)
('yuv.max=', 219.47799999999998, 'yuv.min=', -47.720589999999994)
('yuv.max=', 249.56499999999997, 'yuv.min=', -9.4951499999999953)
('yuv.max=', 247.06199999999998, 'yuv.min=', -72.372879999999995)
('yuv.max=', 237.05999999999997, 'yuv.min=', -76.913740000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.778060000000011)
('yuv.max=', 254.70099999999999, 'yuv.min=', -12.020250000000004)
('yuv.max=', 215.25999999999999, 'yuv.min=', -25.670229999999986)
('yuv.max=', 250.77199999999996, 'yuv.min=', -32.415379999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.411560000000001)
('yuv.max=', 246.00799999999995, 'yuv.min=', -30.12496999999999)
('yuv.max=', 236.87799999999999, 'yuv.min=', -51.070309999999992)
('yuv.max=', 248.99999999999997, 'yuv.min=', -13.185149999999993)
('yuv.max=', 226.08800000000002, 'yuv.min=', -39.906099999999995)
('yuv.max=', 234.185, 'yuv.min=', -44.830669999999998)
('yuv.max=', 217.97200000000001, 'yuv.min=', -19.935209999999998)
('yuv.max=', 234.08899999999997, 'yuv.min=', -74.700089999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -22.520529999999997)
('yuv.max=', 255.0, 'yuv.min=', -20.003800000000002)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 203.15699999999998, 'yuv.min=', -20.050159999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.4672899999999913)
('yuv.max=', 246.15299999999999, 'yuv.min=', -47.549160000000001)
('yuv.max=', 255.0, 'yuv.min=', -102.29958999999999)
('yuv.max=', 236.364, 'yuv.min=', -10.825159999999997)
('yuv.max=', 204.07299999999998, 'yuv.min=', -21.725019999999997)
('yuv.max=', 217.76899999999998, 'yuv.min=', -12.910429999999995)
('yuv.max=', 255.0, 'yuv.min=', -8.3800999999999917)
('yuv.max=', 246.03399999999999, 'yuv.min=', -19.12018999999998)
('yuv.max=', 231.78, 'yuv.min=', -50.580629999999999)
('yuv.max=', 211.39500000000001, 'yuv.min=', -41.477430000000005)
('yuv.max=', 247.83599999999998, 'yuv.min=', -23.859679999999997)
('yuv.max=', 243.99999999999997, 'yuv.min=', -74.080519999999993)
('yuv.max=', 236.41399999999999, 'yuv.min=', -37.090879999999999)
('yuv.max=', 246.49299999999999, 'yuv.min=', -40.301060000000007)
('yuv.max=', 251.60599999999999, 'yuv.min=', -59.173440000000014)
('yuv.max=', 240.38300000000001, 'yuv.min=', -36.93835)
('yuv.max=', 191.11599999999999, 'yuv.min=', -14.254740000000002)
('yuv.max=', 250.76099999999997, 'yuv.min=', -45.984740000000002)
('yuv.max=', 243.91399999999999, 'yuv.min=', -25.955319999999979)
('yuv.max=', 244.38299999999998, 'yuv.min=', -82.035269999999997)
('yuv.max=', 143.14400000000001, 'yuv.min=', -14.270319999999991)
('yuv.max=', 216.84299999999999, 'yuv.min=', -23.965489999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -38.14036999999999)
('yuv.max=', 242.97800000000001, 'yuv.min=', -35.065369999999987)
('yuv.max=', 152.81699999999998, 'yuv.min=', -19.705309999999997)
('yuv.max=', 196.37, 'yuv.min=', -55.973930000000003)
('yuv.max=', 255.0, 'yuv.min=', -2.530129999999998)
('yuv.max=', 245.64099999999999, 'yuv.min=', -12.725349999999999)
('yuv.max=', 236.75699999999998, 'yuv.min=', -106.53947000000001)
('yuv.max=', 255.0, 'yuv.min=', -59.615079999999999)
('yuv.max=', 209.00300000000001, 'yuv.min=', -40.040559999999992)
('yuv.max=', 228.05799999999999, 'yuv.min=', -30.215499999999984)
('yuv.max=', 255.0, 'yuv.min=', -18.07517)
('yuv.max=', 248.58100000000002, 'yuv.min=', -70.813829999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 237.32299999999998, 'yuv.min=', -44.490389999999991)
('yuv.max=', 254.202, 'yuv.min=', -23.733560000000004)
('yuv.max=', 213.733, 'yuv.min=', -31.570310000000003)
('yuv.max=', 219.84700000000001, 'yuv.min=', -10.478809999999996)
('yuv.max=', 255.0, 'yuv.min=', -47.450439999999993)
('yuv.max=', 255.0, 'yuv.min=', -29.908230000000003)
('yuv.max=', 236.44300000000001, 'yuv.min=', -36.109060000000007)
('yuv.max=', 197.15100000000001, 'yuv.min=', -36.110289999999999)
('yuv.max=', 237.10499999999999, 'yuv.min=', -57.120299999999986)
('yuv.max=', 221.62, 'yuv.min=', -16.830329999999996)
('yuv.max=', 255.0, 'yuv.min=', -4.6199699999999808)
('yuv.max=', 232.62099999999998, 'yuv.min=', -19.486999999999995)
('yuv.max=', 255.0, 'yuv.min=', -12.90006)
('yuv.max=', 234.08799999999997, 'yuv.min=', -58.100889999999993)
('yuv.max=', 165.988, 'yuv.min=', -42.85069)
('yuv.max=', 242.89699999999999, 'yuv.min=', -11.514279999999999)
('yuv.max=', 220.447, 'yuv.min=', -31.902220000000003)
('yuv.max=', 215.012, 'yuv.min=', -80.968139999999991)
('yuv.max=', 177.35900000000001, 'yuv.min=', -36.620710000000003)
('yuv.max=', 180.46600000000001, 'yuv.min=', -41.455640000000002)
('yuv.max=', 248.56, 'yuv.min=', -28.266570000000002)
('yuv.max=', 251.733, 'yuv.min=', -11.495349999999988)
('yuv.max=', 210.38499999999999, 'yuv.min=', -18.675510000000006)
('yuv.max=', 244.137, 'yuv.min=', -53.460179999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.728379999999998)
('yuv.max=', 250.68999999999997, 'yuv.min=', -11.644749999999997)
('yuv.max=', 207.23500000000001, 'yuv.min=', -20.855130000000003)
('yuv.max=', 240.44999999999999, 'yuv.min=', -32.73669000000001)
('yuv.max=', 165.43199999999999, 'yuv.min=', -30.560349999999993)
('yuv.max=', 239.00599999999997, 'yuv.min=', -26.400179999999995)
('yuv.max=', 254.54400000000001, 'yuv.min=', -16.675129999999996)
('yuv.max=', 247.79999999999998, 'yuv.min=', -36.617449999999998)
('yuv.max=', 241.11899999999997, 'yuv.min=', -23.563309999999998)
('yuv.max=', 252.66899999999998, 'yuv.min=', -66.525220000000004)
('yuv.max=', 252.27699999999999, 'yuv.min=', -109.48036999999999)
('yuv.max=', 239.499, 'yuv.min=', -32.34102)
('yuv.max=', 232.53100000000001, 'yuv.min=', -35.226470000000006)
('yuv.max=', 226.17600000000002, 'yuv.min=', -79.840849999999989)
('yuv.max=', 242.61400000000003, 'yuv.min=', -16.119689999999999)
('yuv.max=', 253.47299999999998, 'yuv.min=', -74.722620000000006)
('yuv.max=', 126.76199999999999, 'yuv.min=', -4.5329699999999988)
('yuv.max=', 251.03199999999995, 'yuv.min=', -25.764760000000006)
('yuv.max=', 253.97400000000002, 'yuv.min=', -39.286770000000004)
('yuv.max=', 254.886, 'yuv.min=', -84.09066)
('yuv.max=', 234.74199999999999, 'yuv.min=', -31.760469999999998)
('yuv.max=', 255.0, 'yuv.min=', -54.023039999999995)
('yuv.max=', 242.55700000000002, 'yuv.min=', -27.615240000000004)
('yuv.max=', 248.245, 'yuv.min=', -25.280559999999998)
('yuv.max=', 220.29700000000003, 'yuv.min=', -72.105629999999991)
('yuv.max=', 247.83099999999996, 'yuv.min=', -70.100859999999997)
('yuv.max=', 238.03199999999998, 'yuv.min=', -20.755800000000001)
('yuv.max=', 247.84299999999999, 'yuv.min=', -28.880919999999996)
('yuv.max=', 246.11399999999998, 'yuv.min=', -43.55585)
('yuv.max=', 241.07899999999998, 'yuv.min=', -55.309030000000007)
('yuv.max=', 215.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 155.67100000000002, 'yuv.min=', -6.1051800000000007)
('yuv.max=', 212.38200000000001, 'yuv.min=', -23.585540000000002)
('yuv.max=', 210.131, 'yuv.min=', -24.240209999999983)
('yuv.max=', 213.83199999999999, 'yuv.min=', -21.050260000000005)
('yuv.max=', 254.77200000000002, 'yuv.min=', -26.277809999999999)
('yuv.max=', 227.59899999999996, 'yuv.min=', -34.982530000000011)
('yuv.max=', 125.336, 'yuv.min=', -19.161800000000003)
('yuv.max=', 231.20299999999997, 'yuv.min=', -24.325279999999985)
('yuv.max=', 155.17999999999998, 'yuv.min=', -19.105249999999987)
('yuv.max=', 241.22799999999998, 'yuv.min=', -33.820429999999988)
('yuv.max=', 250.84300000000002, 'yuv.min=', -29.493730000000006)
('yuv.max=', 248.26599999999996, 'yuv.min=', -23.606820000000006)
('yuv.max=', 215.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 214.71599999999998, 'yuv.min=', -21.23077)
('yuv.max=', 242.58100000000002, 'yuv.min=', -14.940509999999986)
('yuv.max=', 232.95899999999997, 'yuv.min=', -24.180449999999986)
('yuv.max=', 244.142, 'yuv.min=', -41.955689999999997)
('yuv.max=', 206.71499999999997, 'yuv.min=', -65.201250000000002)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.184, 'yuv.min=', -37.527250000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.810189999999995)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 232.12899999999999, 'yuv.min=', -12.355189999999993)
('yuv.max=', 206.68699999999998, 'yuv.min=', -37.665629999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 189.33700000000002, 'yuv.min=', -13.231849999999998)
('yuv.max=', 245.387, 'yuv.min=', -57.560589999999991)
('yuv.max=', 218.185, 'yuv.min=', -61.108580000000003)
('yuv.max=', 181.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 248.261, 'yuv.min=', -26.240410000000001)
('yuv.max=', 234.85699999999997, 'yuv.min=', -58.735399999999998)
('yuv.max=', 248.54800000000003, 'yuv.min=', -43.7455)
('yuv.max=', 224.03, 'yuv.min=', -62.415990000000001)
('yuv.max=', 245.75299999999999, 'yuv.min=', -27.366080000000004)
('yuv.max=', 198.49200000000002, 'yuv.min=', -30.660359999999987)
('yuv.max=', 231.70299999999997, 'yuv.min=', -23.910299999999989)
('yuv.max=', 232.50700000000001, 'yuv.min=', -61.095389999999995)
('yuv.max=', 216.79799999999997, 'yuv.min=', -11.670059999999996)
('yuv.max=', 251.91799999999998, 'yuv.min=', -14.75667)
('yuv.max=', 237.82299999999998, 'yuv.min=', -17.145299999999999)
('yuv.max=', 242.87299999999999, 'yuv.min=', -13.509690000000003)
('yuv.max=', 216.542, 'yuv.min=', -55.550109999999997)
('yuv.max=', 237.25, 'yuv.min=', -80.875399999999999)
('yuv.max=', 225.16799999999998, 'yuv.min=', -47.950489999999988)
('yuv.max=', 252.309, 'yuv.min=', -77.225650000000002)
('yuv.max=', 217.58999999999997, 'yuv.min=', -51.840509999999995)
('yuv.max=', 201.99099999999999, 'yuv.min=', -20.639849999999988)
('yuv.max=', 236.77599999999998, 'yuv.min=', -13.540369999999999)
('yuv.max=', 217.23799999999997, 'yuv.min=', -17.430390000000003)
('yuv.max=', 255.0, 'yuv.min=', -25.127739999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -57.656030000000001)
('yuv.max=', 248.84299999999999, 'yuv.min=', -31.965959999999999)
('yuv.max=', 254.886, 'yuv.min=', -41.130299999999991)
('yuv.max=', 235.66, 'yuv.min=', -29.154410000000006)
('yuv.max=', 255.0, 'yuv.min=', -36.016870000000004)
('yuv.max=', 254.65800000000002, 'yuv.min=', -9.1717300000000019)
('yuv.max=', 217.499, 'yuv.min=', -39.255419999999994)
('yuv.max=', 255.0, 'yuv.min=', -12.770169999999998)
('yuv.max=', 195.57899999999998, 'yuv.min=', -32.78998)
('yuv.max=', 250.99999999999997, 'yuv.min=', -26.625510000000002)
('yuv.max=', 249.815, 'yuv.min=', -22.45176)
('yuv.max=', 244.38600000000002, 'yuv.min=', -21.323630000000001)
('yuv.max=', 235.79499999999996, 'yuv.min=', -39.270359999999997)
('yuv.max=', 216.70000000000002, 'yuv.min=', -42.512700000000002)
('yuv.max=', 243.309, 'yuv.min=', -35.614109999999989)
('yuv.max=', 230.41199999999998, 'yuv.min=', -21.180149999999998)
('yuv.max=', 255.0, 'yuv.min=', -50.71602)
('yuv.max=', 252.03399999999996, 'yuv.min=', -32.130629999999989)
('yuv.max=', 255.0, 'yuv.min=', -16.860209999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -19.250079999999986)
('yuv.max=', 240.184, 'yuv.min=', -66.140709999999999)
('yuv.max=', 252.309, 'yuv.min=', -38.18061999999999)
('yuv.max=', 236.92599999999999, 'yuv.min=', -48.40440000000001)
('yuv.max=', 205.40099999999998, 'yuv.min=', -19.45599)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 234.39999999999998, 'yuv.min=', -55.785719999999998)
('yuv.max=', 253.64700000000002, 'yuv.min=', -43.545479999999984)
('yuv.max=', 156.09399999999999, 'yuv.min=', -29.930410000000002)
('yuv.max=', 247.65800000000002, 'yuv.min=', -11.721049999999998)
('yuv.max=', 237.79699999999997, 'yuv.min=', -17.776130000000002)
('yuv.max=', 245.58799999999999, 'yuv.min=', -4.5264099999999985)
('yuv.max=', 234.38300000000001, 'yuv.min=', -66.831019999999995)
('yuv.max=', 208.82400000000001, 'yuv.min=', -32.460539999999995)
('yuv.max=', 251.24499999999995, 'yuv.min=', -29.039450000000006)
('yuv.max=', 213.39099999999996, 'yuv.min=', -49.565589999999993)
('yuv.max=', 215.33399999999997, 'yuv.min=', -56.590150000000001)
('yuv.max=', 209.16, 'yuv.min=', -15.557770000000003)
('yuv.max=', 250.16999999999999, 'yuv.min=', -31.760050000000007)
('yuv.max=', 245.077, 'yuv.min=', -43.37077)
('yuv.max=', 187.453, 'yuv.min=', -48.687180000000012)
('yuv.max=', 200.29599999999996, 'yuv.min=', -16.775139999999993)
('yuv.max=', 241.61099999999999, 'yuv.min=', -24.827420000000011)
('yuv.max=', 234.99999999999997, 'yuv.min=', -74.035699999999991)
('yuv.max=', 237.21599999999998, 'yuv.min=', -30.220069999999993)
('yuv.max=', 179.52699999999999, 'yuv.min=', -34.960789999999989)
('yuv.max=', 246.77199999999999, 'yuv.min=', -46.519350000000003)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 242.61899999999997, 'yuv.min=', -43.960459999999991)
('yuv.max=', 238.84699999999998, 'yuv.min=', -42.486010000000007)
('yuv.max=', 240.91800000000001, 'yuv.min=', -46.950389999999992)
('yuv.max=', 209.17100000000002, 'yuv.min=', -53.240649999999988)
('yuv.max=', 195.55099999999999, 'yuv.min=', -16.745259999999998)
('yuv.max=', 208.542, 'yuv.min=', -10.340049999999991)
('yuv.max=', 152.30799999999999, 'yuv.min=', -70.893909999999991)
('yuv.max=', 255.0, 'yuv.min=', -30.784110000000005)
('yuv.max=', 184.36999999999998, 'yuv.min=', -50.450739999999996)
('yuv.max=', 236.92699999999996, 'yuv.min=', -33.018850000000015)
('yuv.max=', 189.40100000000001, 'yuv.min=', -29.013000000000005)
('yuv.max=', 232.09900000000002, 'yuv.min=', -15.730220000000001)
('yuv.max=', 228.91399999999999, 'yuv.min=', -35.929290000000002)
('yuv.max=', 217.298, 'yuv.min=', -22.320509999999992)
('yuv.max=', 246.56899999999999, 'yuv.min=', -30.205130000000004)
('yuv.max=', 253.14199999999997, 'yuv.min=', -26.985299999999999)
('yuv.max=', 255.0, 'yuv.min=', -5.1200199999999967)
('yuv.max=', 245.43199999999999, 'yuv.min=', -39.80028999999999)
('yuv.max=', 217.71499999999997, 'yuv.min=', -24.325279999999992)
('yuv.max=', 255.0, 'yuv.min=', -22.924769999999999)
('yuv.max=', 207.63800000000001, 'yuv.min=', -45.535309999999988)
('yuv.max=', 255.0, 'yuv.min=', -56.075379999999996)
('yuv.max=', 203.05499999999998, 'yuv.min=', -37.350659999999998)
('yuv.max=', 124.80500000000001, 'yuv.min=', -19.950149999999994)
('yuv.max=', 242.37399999999997, 'yuv.min=', -34.290599999999991)
('yuv.max=', 255.0, 'yuv.min=', -19.794949999999986)
('yuv.max=', 226.90399999999997, 'yuv.min=', -58.017980000000009)
('yuv.max=', 227.036, 'yuv.min=', -41.608890000000002)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 243.88199999999998, 'yuv.min=', -55.27073)
('yuv.max=', 212.232, 'yuv.min=', -57.635289999999998)
('yuv.max=', 251.27700000000002, 'yuv.min=', -28.184930000000008)
('yuv.max=', 237.0, 'yuv.min=', -5.3050999999999995)
('yuv.max=', 231.20599999999999, 'yuv.min=', -45.810029999999998)
('yuv.max=', 238.392, 'yuv.min=', -18.730519999999984)
('yuv.max=', 230.51999999999998, 'yuv.min=', -14.991879999999998)
('yuv.max=', 250.91799999999998, 'yuv.min=', -80.975409999999997)
('yuv.max=', 182.245, 'yuv.min=', -7.5351999999999908)
('yuv.max=', 230.423, 'yuv.min=', -16.015309999999999)
('yuv.max=', 236.14600000000002, 'yuv.min=', -27.015179999999994)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 142.80199999999999, 'yuv.min=', -16.751759999999997)
('yuv.max=', 255.0, 'yuv.min=', -72.775819999999996)
('yuv.max=', 255.0, 'yuv.min=', -94.860629999999986)
('yuv.max=', 220.21699999999998, 'yuv.min=', -40.570489999999992)
('yuv.max=', 229.88599999999997, 'yuv.min=', -41.305009999999982)
('yuv.max=', 243.67099999999996, 'yuv.min=', -20.075920000000004)
('yuv.max=', 247.52499999999998, 'yuv.min=', -21.610070000000007)
('yuv.max=', 235.74000000000001, 'yuv.min=', -28.769680000000008)
('yuv.max=', 243.30500000000001, 'yuv.min=', -26.043660000000003)
('yuv.max=', 253.0, 'yuv.min=', -36.260919999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.78994999999999)
('yuv.max=', 255.0, 'yuv.min=', -28.717800000000004)
('yuv.max=', 244.92700000000002, 'yuv.min=', -46.774510000000006)
('yuv.max=', 173.81200000000001, 'yuv.min=', -32.115690000000001)
('yuv.max=', 245.91800000000001, 'yuv.min=', -10.669959999999993)
('yuv.max=', 255.0, 'yuv.min=', -30.479849999999999)
('yuv.max=', 189.07699999999997, 'yuv.min=', -30.615539999999999)
('yuv.max=', 164.59199999999998, 'yuv.min=', -25.955319999999997)
('yuv.max=', 227.46699999999998, 'yuv.min=', -79.681079999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.280359999999998)
('yuv.max=', 247.14599999999999, 'yuv.min=', -30.740859999999994)
('yuv.max=', 248.57599999999999, 'yuv.min=', -25.204620000000002)
('yuv.max=', 249.70099999999999, 'yuv.min=', -15.748350000000002)
('yuv.max=', 252.53299999999999, 'yuv.min=', -35.665430000000001)
('yuv.max=', 255.0, 'yuv.min=', -13.385169999999988)
('yuv.max=', 253.202, 'yuv.min=', -40.530239999999999)
('yuv.max=', 233.387, 'yuv.min=', -30.064160000000001)
('yuv.max=', 245.387, 'yuv.min=', -24.409350000000007)
('yuv.max=', 173.10699999999997, 'yuv.min=', -23.19529)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.98899999999998, 'yuv.min=', -104.08563000000001)
('yuv.max=', 194.322, 'yuv.min=', -25.74418)
('yuv.max=', 234.50099999999998, 'yuv.min=', -50.065639999999988)
('yuv.max=', 253.0, 'yuv.min=', -44.890429999999981)
('yuv.max=', 219.17400000000001, 'yuv.min=', -20.165109999999991)
('yuv.max=', 254.35900000000001, 'yuv.min=', -38.140370000000004)
('yuv.max=', 216.96199999999999, 'yuv.min=', -23.438370000000013)
('yuv.max=', 225.733, 'yuv.min=', -22.850439999999999)
('yuv.max=', 229.86099999999999, 'yuv.min=', -39.570389999999996)
('yuv.max=', 245.98999999999998, 'yuv.min=', -40.025619999999989)
('yuv.max=', 246.17400000000001, 'yuv.min=', -37.765639999999991)
('yuv.max=', 248.28799999999995, 'yuv.min=', -15.575019999999995)
('yuv.max=', 247.10299999999998, 'yuv.min=', -37.240279999999998)
('yuv.max=', 249.804, 'yuv.min=', -19.651189999999993)
('yuv.max=', 236.79099999999997, 'yuv.min=', -42.140769999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 156.964, 'yuv.min=', -6.2902599999999822)
('yuv.max=', 177.47599999999997, 'yuv.min=', -65.400389999999987)
('yuv.max=', 158.92399999999998, 'yuv.min=', -4.945309999999985)
('yuv.max=', 255.0, 'yuv.min=', -26.038350000000001)
('yuv.max=', 255.0, 'yuv.min=', -18.211810000000007)
('yuv.max=', 226.279, 'yuv.min=', -46.990639999999999)
('yuv.max=', 152.982, 'yuv.min=', -25.525400000000001)
('yuv.max=', 199.71700000000001, 'yuv.min=', -26.940480000000001)
('yuv.max=', 252.93999999999997, 'yuv.min=', -48.405719999999988)
('yuv.max=', 255.0, 'yuv.min=', -3.7302499999999963)
('yuv.max=', 226.89399999999998, 'yuv.min=', -60.265429999999995)
('yuv.max=', 157.90600000000001, 'yuv.min=', -0.78513999999998774)
('yuv.max=', 246.31, 'yuv.min=', -43.717280000000002)
('yuv.max=', 255.0, 'yuv.min=', -20.304379999999995)
('yuv.max=', 253.39099999999999, 'yuv.min=', -46.50553)
('yuv.max=', 250.22800000000001, 'yuv.min=', -33.135299999999994)
('yuv.max=', 231.49899999999997, 'yuv.min=', -23.029609999999998)
('yuv.max=', 225.96199999999996, 'yuv.min=', -41.415390000000002)
('yuv.max=', 247.0, 'yuv.min=', -41.586999999999996)
('yuv.max=', 225.32399999999998, 'yuv.min=', -33.999849999999995)
('yuv.max=', 243.92000000000002, 'yuv.min=', -41.625779999999992)
('yuv.max=', 171.679, 'yuv.min=', -37.140270000000001)
('yuv.max=', 250.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 249.744, 'yuv.min=', -32.360529999999997)
('yuv.max=', 255.0, 'yuv.min=', -13.644949999999969)
('yuv.max=', 144.48099999999999, 'yuv.min=', -51.310580000000002)
('yuv.max=', 227.41400000000002, 'yuv.min=', -29.975230000000003)
('yuv.max=', 226.39099999999996, 'yuv.min=', -22.610169999999993)
('yuv.max=', 233.98700000000002, 'yuv.min=', -28.215299999999992)
('yuv.max=', 244.97300000000001, 'yuv.min=', -42.685639999999992)
('yuv.max=', 240.92699999999999, 'yuv.min=', -40.86014999999999)
('yuv.max=', 196.38299999999998, 'yuv.min=', -38.279140000000005)
('yuv.max=', 229.18499999999997, 'yuv.min=', -18.730519999999999)
('yuv.max=', 243.15299999999999, 'yuv.min=', -21.563890000000001)
('yuv.max=', 250.131, 'yuv.min=', -14.997420000000002)
('yuv.max=', 238.61199999999999, 'yuv.min=', -22.065300000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', -25.890989999999999)
('yuv.max=', 255.0, 'yuv.min=', -69.205339999999978)
('yuv.max=', 187.511, 'yuv.min=', -24.795449999999995)
('yuv.max=', 237.61799999999999, 'yuv.min=', -84.620589999999993)
('yuv.max=', 252.60399999999998, 'yuv.min=', -42.255719999999997)
('yuv.max=', 219.72499999999997, 'yuv.min=', -75.170259999999985)
('yuv.max=', 238.43799999999999, 'yuv.min=', -31.875419999999991)
('yuv.max=', 209.904, 'yuv.min=', -55.641570000000002)
('yuv.max=', 247.78899999999999, 'yuv.min=', -42.14820000000001)
('yuv.max=', 243.04300000000001, 'yuv.min=', -58.400919999999992)
('yuv.max=', 212.93599999999998, 'yuv.min=', -46.916630000000005)
('yuv.max=', 215.227, 'yuv.min=', -68.70071999999999)
('yuv.max=', 242.22800000000001, 'yuv.min=', -14.930139999999998)
('yuv.max=', 255.0, 'yuv.min=', -32.284419999999997)
('yuv.max=', 254.316, 'yuv.min=', -25.591989999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', -8.1572200000000024)
('yuv.max=', 253.80399999999997, 'yuv.min=', -86.412320000000008)
('yuv.max=', 231.44699999999997, 'yuv.min=', -22.684869999999989)
('yuv.max=', 202.91, 'yuv.min=', -34.005510000000001)
('yuv.max=', 252.50499999999997, 'yuv.min=', -36.480450000000005)
('yuv.max=', 225.31, 'yuv.min=', -9.5250299999999974)
('yuv.max=', 228.36799999999999, 'yuv.min=', -32.805389999999996)
('yuv.max=', 248.86500000000001, 'yuv.min=', -65.429039999999986)
('yuv.max=', 253.505, 'yuv.min=', -97.840190000000007)
('yuv.max=', 223.435, 'yuv.min=', -19.620239999999992)
('yuv.max=', 205.60499999999999, 'yuv.min=', -59.575729999999993)
('yuv.max=', 245.04900000000001, 'yuv.min=', -24.510359999999995)
('yuv.max=', 255.0, 'yuv.min=', -49.520769999999992)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.250449999999994)
('yuv.max=', 211.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 239.56500000000003, 'yuv.min=', -73.420699999999997)
('yuv.max=', 251.71100000000001, 'yuv.min=', -42.334989999999991)
('yuv.max=', 255.0, 'yuv.min=', -83.126239999999996)
('yuv.max=', 247.09899999999999, 'yuv.min=', -66.60051)
('yuv.max=', 228.929, 'yuv.min=', -7.0949099999999952)
('yuv.max=', 234.70799999999997, 'yuv.min=', -35.425159999999998)
('yuv.max=', 255.0, 'yuv.min=', -56.590029999999992)
('yuv.max=', 255.0, 'yuv.min=', -45.886010000000006)
('yuv.max=', 232.94800000000001, 'yuv.min=', -60.329400000000007)
('yuv.max=', 249.77199999999999, 'yuv.min=', -29.730389999999986)
('yuv.max=', 255.0, 'yuv.min=', -39.985369999999996)
('yuv.max=', 182.137, 'yuv.min=', -17.075169999999986)
('yuv.max=', 232.44999999999999, 'yuv.min=', -22.850439999999995)
('yuv.max=', 209.79599999999996, 'yuv.min=', -32.445599999999999)
('yuv.max=', 185.83199999999999, 'yuv.min=', -18.594839999999998)
('yuv.max=', 185.624, 'yuv.min=', -26.140400000000003)
('yuv.max=', 250.76099999999997, 'yuv.min=', -48.780449999999995)
('yuv.max=', 241.89199999999997, 'yuv.min=', -30.575289999999999)
('yuv.max=', 215.39099999999999, 'yuv.min=', -22.565349999999981)
('yuv.max=', 245.93899999999999, 'yuv.min=', -30.492070000000005)
('yuv.max=', 253.65799999999999, 'yuv.min=', -26.884)
('yuv.max=', 246.95599999999999, 'yuv.min=', -21.269920000000003)
('yuv.max=', 217.16999999999996, 'yuv.min=', -18.522379999999998)
('yuv.max=', 252.65199999999999, 'yuv.min=', -18.290229999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.830229999999986)
('yuv.max=', 231.92000000000002, 'yuv.min=', -14.330079999999997)
('yuv.max=', 255.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 223.74499999999998, 'yuv.min=', -29.41541999999999)
('yuv.max=', 183.51299999999998, 'yuv.min=', -25.580589999999994)
('yuv.max=', 245.78399999999999, 'yuv.min=', -64.279949999999999)
('yuv.max=', 255.0, 'yuv.min=', -19.377570000000002)
('yuv.max=', 126.68999999999998, 'yuv.min=', -22.080239999999989)
('yuv.max=', 248.89599999999999, 'yuv.min=', -17.56485)
('yuv.max=', 228.87100000000001, 'yuv.min=', -9.2750199999999978)
('yuv.max=', 255.0, 'yuv.min=', -6.7399199999999979)
('yuv.max=', 249.916, 'yuv.min=', -28.845239999999997)
('yuv.max=', 237.82899999999998, 'yuv.min=', -25.455269999999999)
('yuv.max=', 250.77199999999996, 'yuv.min=', -27.285330000000002)
('yuv.max=', 160.77099999999999, 'yuv.min=', -76.601950000000002)
('yuv.max=', 234.77599999999995, 'yuv.min=', -16.676630000000003)
('yuv.max=', 187.52699999999999, 'yuv.min=', -64.781480000000002)
('yuv.max=', 224.613, 'yuv.min=', -17.476839999999999)
('yuv.max=', 248.53800000000001, 'yuv.min=', -15.100279999999991)
('yuv.max=', 248.59799999999998, 'yuv.min=', -87.080590000000001)
('yuv.max=', 252.85999999999999, 'yuv.min=', -76.285970000000006)
('yuv.max=', 253.72899999999996, 'yuv.min=', -13.66113)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 209.84299999999999, 'yuv.min=', -22.216080000000002)
('yuv.max=', 109.88999999999999, 'yuv.min=', -40.640619999999998)
('yuv.max=', 238.77600000000001, 'yuv.min=', -33.402120000000011)
('yuv.max=', 200.06200000000001, 'yuv.min=', -40.640619999999991)
('yuv.max=', 255.0, 'yuv.min=', -62.955329999999989)
('yuv.max=', 234.78599999999997, 'yuv.min=', -41.515399999999985)
('yuv.max=', 236.59099999999998, 'yuv.min=', -25.12535999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -34.490619999999993)
('yuv.max=', 250.541, 'yuv.min=', -27.046689999999998)
('yuv.max=', 160.761, 'yuv.min=', -9.7108500000000006)
('yuv.max=', 210.96099999999998, 'yuv.min=', -24.855209999999992)
('yuv.max=', 244.35900000000001, 'yuv.min=', -14.915199999999988)
('yuv.max=', 224.25400000000002, 'yuv.min=', -31.743780000000008)
('yuv.max=', 235.041, 'yuv.min=', -24.888590000000004)
('yuv.max=', 235.50099999999998, 'yuv.min=', -40.873170000000016)
('yuv.max=', 249.39599999999999, 'yuv.min=', -24.777940000000005)
('yuv.max=', 203.57999999999998, 'yuv.min=', -32.115160000000003)
('yuv.max=', 255.0, 'yuv.min=', -13.300099999999995)
('yuv.max=', 245.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.07899999999998, 'yuv.min=', -45.380109999999988)
('yuv.max=', 248.81, 'yuv.min=', -81.169600000000017)
('yuv.max=', 171.34700000000001, 'yuv.min=', -24.69086999999999)
('yuv.max=', 228.75799999999998, 'yuv.min=', -25.181899999999999)
('yuv.max=', 151.24599999999998, 'yuv.min=', -23.666829999999997)
('yuv.max=', 243.24299999999999, 'yuv.min=', -17.875249999999991)
('yuv.max=', 255.0, 'yuv.min=', -3.2899599999999936)
('yuv.max=', 182.21999999999997, 'yuv.min=', -24.395409999999991)
('yuv.max=', 244.64099999999996, 'yuv.min=', -41.93038)
('yuv.max=', 241.869, 'yuv.min=', -26.90014)
('yuv.max=', 254.70099999999999, 'yuv.min=', -21.657550000000001)
('yuv.max=', 233.96799999999999, 'yuv.min=', -28.196840000000002)
('yuv.max=', 240.98599999999996, 'yuv.min=', -67.266330000000011)
('yuv.max=', 218.114, 'yuv.min=', -18.920169999999995)
('yuv.max=', 239.03799999999998, 'yuv.min=', -30.030420000000003)
('yuv.max=', 251.55499999999998, 'yuv.min=', -18.147749999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', -43.243650000000002)
('yuv.max=', 254.65800000000002, 'yuv.min=', -15.296990000000005)
('yuv.max=', 243.71899999999999, 'yuv.min=', -39.384330000000006)
('yuv.max=', 230.14599999999996, 'yuv.min=', -78.240689999999987)
('yuv.max=', 173.96100000000001, 'yuv.min=', -38.910569999999993)
('yuv.max=', 173.334, 'yuv.min=', -19.809210000000004)
('yuv.max=', 255.0, 'yuv.min=', -16.728850000000008)
('yuv.max=', 249.16200000000001, 'yuv.min=', -45.720389999999995)
('yuv.max=', 244.97300000000001, 'yuv.min=', -16.645249999999997)
('yuv.max=', 207.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -83.465289999999996)
('yuv.max=', 255.0, 'yuv.min=', -27.41065)
('yuv.max=', 255.0, 'yuv.min=', -15.315239999999985)
('yuv.max=', 254.886, 'yuv.min=', -83.85687999999999)
('yuv.max=', 239.78700000000001, 'yuv.min=', -24.010309999999993)
('yuv.max=', 173.96800000000002, 'yuv.min=', -26.715149999999984)
('yuv.max=', 250.21600000000001, 'yuv.min=', -19.880019999999984)
('yuv.max=', 229.58699999999999, 'yuv.min=', -55.279869999999995)
('yuv.max=', 205.006, 'yuv.min=', -67.590239999999994)
('yuv.max=', 247.28800000000001, 'yuv.min=', -20.80659)
('yuv.max=', 238.05000000000001, 'yuv.min=', -24.92013)
('yuv.max=', 215.96899999999999, 'yuv.min=', -17.260249999999985)
('yuv.max=', 242.75500000000002, 'yuv.min=', -23.341869999999997)
('yuv.max=', 254.11399999999998, 'yuv.min=', -20.35482)
('yuv.max=', 255.0, 'yuv.min=', -45.871470000000002)
('yuv.max=', 244.01900000000001, 'yuv.min=', -43.553930000000008)
('yuv.max=', 255.0, 'yuv.min=', -10.625139999999993)
('yuv.max=', 255.0, 'yuv.min=', -20.511589999999998)
('yuv.max=', 242.411, 'yuv.min=', -25.25524999999999)
('yuv.max=', 252.61899999999997, 'yuv.min=', -38.649909999999991)
('yuv.max=', 242.43099999999995, 'yuv.min=', -33.754869999999997)
('yuv.max=', 177.75899999999999, 'yuv.min=', -23.270430000000001)
('yuv.max=', 245.24299999999999, 'yuv.min=', -54.615479999999991)
('yuv.max=', 234.03200000000001, 'yuv.min=', -43.80525999999999)
('yuv.max=', 190.38099999999997, 'yuv.min=', -30.560349999999985)
('yuv.max=', 176.23299999999998, 'yuv.min=', -25.319350000000004)
('yuv.max=', 248.131, 'yuv.min=', -24.986960000000003)
('yuv.max=', 234.82900000000001, 'yuv.min=', -51.925579999999997)
('yuv.max=', 225.28800000000001, 'yuv.min=', -27.455469999999991)
('yuv.max=', 254.245, 'yuv.min=', -8.9950999999999937)
('yuv.max=', 254.77200000000002, 'yuv.min=', -23.123209999999997)
('yuv.max=', 254.41299999999995, 'yuv.min=', -27.21976999999999)
('yuv.max=', 255.0, 'yuv.min=', -39.897530000000003)
('yuv.max=', 242.86199999999997, 'yuv.min=', -28.330249999999992)
('yuv.max=', 238.46299999999997, 'yuv.min=', -59.69248000000001)
('yuv.max=', 219.70699999999999, 'yuv.min=', -88.784099999999995)
('yuv.max=', 240.01099999999997, 'yuv.min=', -24.670320000000004)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 195.011, 'yuv.min=', -10.665389999999999)
('yuv.max=', 255.0, 'yuv.min=', -12.555210000000002)
('yuv.max=', 245.18099999999998, 'yuv.min=', -79.060630000000003)
('yuv.max=', 245.27599999999998, 'yuv.min=', -92.83214000000001)
('yuv.max=', 215.63200000000001, 'yuv.min=', -39.01057999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', -12.210359999999998)
('yuv.max=', 236.43299999999999, 'yuv.min=', -31.060399999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.675329999999988)
('yuv.max=', 253.21699999999998, 'yuv.min=', -72.46584)
('yuv.max=', 247.47199999999995, 'yuv.min=', -60.250489999999999)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.5650799999999805)
('yuv.max=', 247.48299999999995, 'yuv.min=', -42.460309999999993)
('yuv.max=', 255.0, 'yuv.min=', -45.215769999999992)
('yuv.max=', 253.99999999999997, 'yuv.min=', -90.635990000000007)
('yuv.max=', 255.0, 'yuv.min=', -42.225839999999991)
('yuv.max=', 172.30500000000001, 'yuv.min=', -10.249470000000002)
('yuv.max=', 247.07500000000002, 'yuv.min=', -50.010449999999999)
('yuv.max=', 238.761, 'yuv.min=', -29.66272)
('yuv.max=', 248.929, 'yuv.min=', -11.219700000000003)
('yuv.max=', 201.05799999999999, 'yuv.min=', -6.5350999999999893)
('yuv.max=', 251.66800000000001, 'yuv.min=', -76.978349999999992)
('yuv.max=', 243.66300000000001, 'yuv.min=', -25.438879999999997)
('yuv.max=', 253.10299999999998, 'yuv.min=', -37.565619999999996)
('yuv.max=', 193.83199999999999, 'yuv.min=', -35.840139999999991)
('yuv.max=', 249.49499999999998, 'yuv.min=', -32.609780000000001)
('yuv.max=', 223.81799999999998, 'yuv.min=', -72.345899999999986)
('yuv.max=', 255.0, 'yuv.min=', -45.409989999999993)
('yuv.max=', 206.64799999999997, 'yuv.min=', -42.530439999999984)
('yuv.max=', 234.57999999999998, 'yuv.min=', -34.635449999999992)
('yuv.max=', 253.54399999999998, 'yuv.min=', -37.821029999999993)
('yuv.max=', 214.84099999999998, 'yuv.min=', -30.045359999999992)
('yuv.max=', 192.976, 'yuv.min=', -15.915299999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', -8.0800699999999921)
('yuv.max=', 233.05799999999999, 'yuv.min=', -27.020069999999993)
('yuv.max=', 243.99999999999997, 'yuv.min=', -20.349250000000001)
('yuv.max=', 254.10300000000001, 'yuv.min=', -28.006790000000006)
('yuv.max=', 255.0, 'yuv.min=', -38.845890000000011)
('yuv.max=', 213.11700000000002, 'yuv.min=', -53.75564)
('yuv.max=', 204.40199999999999, 'yuv.min=', -9.6125499999999988)
('yuv.max=', 255.0, 'yuv.min=', -12.955249999999996)
('yuv.max=', 241.21699999999998, 'yuv.min=', -121.58035)
('yuv.max=', 204.50299999999999, 'yuv.min=', -23.826409999999999)
('yuv.max=', 229.607, 'yuv.min=', -22.436060000000001)
('yuv.max=', 253.0, 'yuv.min=', -13.415049999999994)
('yuv.max=', 254.41299999999995, 'yuv.min=', -39.446299999999994)
('yuv.max=', 241.92199999999997, 'yuv.min=', -48.480419999999995)
('yuv.max=', 226.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -52.305329999999998)
('yuv.max=', 254.886, 'yuv.min=', -43.715620000000001)
('yuv.max=', 222.15800000000002, 'yuv.min=', -42.770709999999994)
('yuv.max=', 229.65799999999996, 'yuv.min=', -19.579989999999995)
('yuv.max=', 215.0, 'yuv.min=', -38.725490000000001)
('yuv.max=', 184.804, 'yuv.min=', -17.428630000000005)
('yuv.max=', 248.02399999999997, 'yuv.min=', -41.585529999999991)
('yuv.max=', 203.785, 'yuv.min=', -9.3100699999999996)
('yuv.max=', 252.97800000000001, 'yuv.min=', -21.24822)
('yuv.max=', 255.0, 'yuv.min=', -29.675199999999997)
('yuv.max=', 200.30099999999999, 'yuv.min=', -49.135669999999983)
('yuv.max=', 221.12699999999998, 'yuv.min=', -25.970259999999989)
('yuv.max=', 220.071, 'yuv.min=', -20.835299999999989)
('yuv.max=', 253.80399999999997, 'yuv.min=', -47.110159999999993)
('yuv.max=', 247.95699999999999, 'yuv.min=', -25.324890000000003)
('yuv.max=', 195.41, 'yuv.min=', -38.065669999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 219.75, 'yuv.min=', -43.085679999999982)
('yuv.max=', 252.0, 'yuv.min=', -8.495049999999992)
('yuv.max=', 246.59799999999998, 'yuv.min=', -22.050359999999994)
('yuv.max=', 224.29499999999999, 'yuv.min=', -70.32495999999999)
('yuv.max=', 255.0, 'yuv.min=', -9.895190000000003)
('yuv.max=', 246.34799999999998, 'yuv.min=', -54.100489999999994)
('yuv.max=', 245.61500000000001, 'yuv.min=', -19.474540000000001)
('yuv.max=', 255.0, 'yuv.min=', -29.900529999999996)
('yuv.max=', 221.82499999999999, 'yuv.min=', -32.441750000000006)
('yuv.max=', 224.35299999999995, 'yuv.min=', -14.270319999999998)
('yuv.max=', 231.011, 'yuv.min=', -23.965489999999992)
('yuv.max=', 182.46299999999999, 'yuv.min=', -37.640319999999996)
('yuv.max=', 235.667, 'yuv.min=', -30.959589999999999)
('yuv.max=', 248.0, 'yuv.min=', -10.775769999999998)
('yuv.max=', 199.77499999999998, 'yuv.min=', -37.375969999999995)
('yuv.max=', 201.61600000000001, 'yuv.min=', -19.320209999999982)
('yuv.max=', 216.477, 'yuv.min=', -65.685479999999984)
('yuv.max=', 220.93799999999996, 'yuv.min=', -17.880670000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -86.591930000000005)
('yuv.max=', 250.10299999999998, 'yuv.min=', -46.210069999999995)
('yuv.max=', 252.90699999999998, 'yuv.min=', -20.150169999999996)
('yuv.max=', 250.24899999999997, 'yuv.min=', -46.000590000000003)
('yuv.max=', 221.63399999999999, 'yuv.min=', -27.98997)
('yuv.max=', 255.0, 'yuv.min=', -37.909040000000005)
('yuv.max=', 248.35900000000001, 'yuv.min=', -13.78716)
('yuv.max=', 251.755, 'yuv.min=', -24.609510000000007)
('yuv.max=', 235.15700000000001, 'yuv.min=', -58.905539999999988)
('yuv.max=', 249.41299999999998, 'yuv.min=', -22.46077)
('yuv.max=', 255.0, 'yuv.min=', -26.774109999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -35.002389999999991)
('yuv.max=', 240.03499999999997, 'yuv.min=', -25.607889999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.93291)
('yuv.max=', 223.69499999999999, 'yuv.min=', -12.140229999999997)
('yuv.max=', 250.94599999999997, 'yuv.min=', -44.130599999999994)
('yuv.max=', 228.71599999999998, 'yuv.min=', -23.694680000000005)
('yuv.max=', 217.32599999999999, 'yuv.min=', -34.780279999999983)
('yuv.max=', 186.64699999999999, 'yuv.min=', -19.504430000000003)
('yuv.max=', 227.18799999999999, 'yuv.min=', -62.982949999999995)
('yuv.max=', 213.374, 'yuv.min=', -22.605599999999992)
('yuv.max=', 245.69000000000003, 'yuv.min=', -15.975060000000001)
('yuv.max=', 219.85999999999999, 'yuv.min=', -28.948969999999999)
('yuv.max=', 213.58199999999999, 'yuv.min=', -63.583759999999998)
('yuv.max=', 218.25599999999997, 'yuv.min=', -22.78031)
('yuv.max=', 245.376, 'yuv.min=', -18.579889999999992)
('yuv.max=', 251.381, 'yuv.min=', -41.100380000000008)
('yuv.max=', 254.43000000000001, 'yuv.min=', -41.485519999999994)
('yuv.max=', 254.40199999999999, 'yuv.min=', -34.935479999999991)
('yuv.max=', 255.0, 'yuv.min=', -11.080369999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 233.089, 'yuv.min=', -42.585629999999988)
('yuv.max=', 212.25799999999998, 'yuv.min=', -44.745599999999996)
('yuv.max=', 255.0, 'yuv.min=', -40.870519999999992)
('yuv.max=', 255.0, 'yuv.min=', -51.609910000000006)
('yuv.max=', 217.12200000000001, 'yuv.min=', -55.755839999999999)
('yuv.max=', 238.34, 'yuv.min=', -17.145299999999988)
('yuv.max=', 206.70299999999997, 'yuv.min=', -26.353780000000015)
('yuv.max=', 253.35899999999998, 'yuv.min=', -33.624190000000006)
('yuv.max=', 219.96100000000001, 'yuv.min=', -18.805219999999998)
('yuv.max=', 221.15700000000001, 'yuv.min=', -18.590260000000001)
('yuv.max=', 240.88999999999999, 'yuv.min=', -45.090839999999993)
('yuv.max=', 211.27099999999999, 'yuv.min=', -47.080280000000002)
('yuv.max=', 253.505, 'yuv.min=', -19.505289999999995)
('yuv.max=', 249.131, 'yuv.min=', -6.5339399999999976)
('yuv.max=', 254.131, 'yuv.min=', -18.560379999999999)
('yuv.max=', 186.99499999999998, 'yuv.min=', -24.08595)
('yuv.max=', 186.90100000000001, 'yuv.min=', -33.450269999999989)
('yuv.max=', 191.96599999999998, 'yuv.min=', -70.950249999999997)
('yuv.max=', 255.0, 'yuv.min=', -33.430759999999992)
('yuv.max=', 237.41300000000001, 'yuv.min=', -46.241139999999994)
('yuv.max=', 204.28799999999998, 'yuv.min=', -4.9523399999999924)
('yuv.max=', 245.04300000000001, 'yuv.min=', -22.125059999999998)
('yuv.max=', 152.77199999999999, 'yuv.min=', -2.0317399999999992)
('yuv.max=', 240.62099999999998, 'yuv.min=', -76.477339999999998)
('yuv.max=', 183.292, 'yuv.min=', -33.935379999999995)
('yuv.max=', 214.85400000000001, 'yuv.min=', -22.189799999999998)
('yuv.max=', 255.0, 'yuv.min=', -11.640179999999997)
('yuv.max=', 244.41499999999999, 'yuv.min=', -28.103550000000006)
('yuv.max=', 252.42999999999998, 'yuv.min=', -39.853640000000006)
('yuv.max=', 179.23599999999999, 'yuv.min=', -49.480519999999999)
('yuv.max=', 196.22499999999997, 'yuv.min=', -45.790519999999987)
('yuv.max=', 238.61399999999998, 'yuv.min=', -88.580739999999992)
('yuv.max=', 252.47900000000001, 'yuv.min=', -55.554920000000003)
('yuv.max=', 237.03399999999999, 'yuv.min=', -20.740009999999998)
('yuv.max=', 221.64599999999999, 'yuv.min=', -18.315539999999999)
('yuv.max=', 231.15799999999999, 'yuv.min=', -46.820499999999988)
('yuv.max=', 159.36000000000001, 'yuv.min=', -30.13043)
('yuv.max=', 246.77600000000001, 'yuv.min=', -34.790940000000006)
('yuv.max=', 199.88499999999996, 'yuv.min=', -19.780009999999997)
('yuv.max=', 187.614, 'yuv.min=', -35.675799999999995)
('yuv.max=', 200.357, 'yuv.min=', -33.776739999999997)
('yuv.max=', 255.0, 'yuv.min=', -10.778420000000004)
('yuv.max=', 249.04300000000001, 'yuv.min=', -18.168999999999997)
('yuv.max=', 183.499, 'yuv.min=', -14.355389999999996)
('yuv.max=', 197.43699999999998, 'yuv.min=', -68.580969999999994)
('yuv.max=', 244.732, 'yuv.min=', -56.320219999999978)
('yuv.max=', 238.0, 'yuv.min=', -10.027080000000002)
('yuv.max=', 248.34399999999999, 'yuv.min=', -17.05651000000001)
('yuv.max=', 179.04299999999998, 'yuv.min=', -35.590590000000006)
('yuv.max=', 241.27799999999996, 'yuv.min=', -80.115569999999991)
('yuv.max=', 255.0, 'yuv.min=', -20.220300000000002)
('yuv.max=', 233.21099999999998, 'yuv.min=', -44.71443)
('yuv.max=', 254.70099999999999, 'yuv.min=', -58.960729999999984)
('yuv.max=', 255.0, 'yuv.min=', -43.820690000000006)
('yuv.max=', 209.24700000000001, 'yuv.min=', -9.6951699999999938)
('yuv.max=', 171.16299999999998, 'yuv.min=', -57.11433000000001)
('yuv.max=', 250.34200000000001, 'yuv.min=', -24.256939999999997)
('yuv.max=', 241.702, 'yuv.min=', -28.517230000000012)
('yuv.max=', 218.10699999999997, 'yuv.min=', -24.14751)
('yuv.max=', 204.61399999999998, 'yuv.min=', -22.180249999999987)
('yuv.max=', 228.67600000000002, 'yuv.min=', -18.120089999999994)
('yuv.max=', 210.40200000000002, 'yuv.min=', -5.8051499999999976)
('yuv.max=', 245.42299999999997, 'yuv.min=', -41.930379999999992)
('yuv.max=', 247.20700000000002, 'yuv.min=', -17.334290000000003)
('yuv.max=', 196.52999999999997, 'yuv.min=', -87.544960000000003)
('yuv.max=', 255.0, 'yuv.min=', -76.460019999999986)
('yuv.max=', 168.27599999999998, 'yuv.min=', -54.970699999999979)
('yuv.max=', 178.39599999999999, 'yuv.min=', -27.915270000000003)
('yuv.max=', 207.35899999999998, 'yuv.min=', -21.395110000000003)
('yuv.max=', 205.92899999999997, 'yuv.min=', -8.4950499999999973)
('yuv.max=', 202.56399999999999, 'yuv.min=', -15.852490000000003)
('yuv.max=', 204.67099999999999, 'yuv.min=', -24.740260000000003)
('yuv.max=', 221.66399999999999, 'yuv.min=', -20.958370000000002)
('yuv.max=', 224.85999999999996, 'yuv.min=', -102.03785999999999)
('yuv.max=', 247.07300000000001, 'yuv.min=', -59.050369999999987)
('yuv.max=', 214.75, 'yuv.min=', -21.67887)
('yuv.max=', 254.77200000000002, 'yuv.min=', -28.400379999999995)
('yuv.max=', 238.88899999999998, 'yuv.min=', -77.545189999999991)
('yuv.max=', 203.89699999999999, 'yuv.min=', -23.547809999999998)
('yuv.max=', 197.78799999999998, 'yuv.min=', -24.525299999999994)
('yuv.max=', 243.47299999999998, 'yuv.min=', -66.930419999999998)
('yuv.max=', 244.40099999999995, 'yuv.min=', -48.769030000000008)
('yuv.max=', 255.0, 'yuv.min=', -1.7151099999999975)
('yuv.max=', 237.57499999999999, 'yuv.min=', -23.020579999999995)
('yuv.max=', 252.07099999999997, 'yuv.min=', -22.120490000000004)
('yuv.max=', 253.50099999999998, 'yuv.min=', -5.7648999999999955)
('yuv.max=', 206.14699999999999, 'yuv.min=', -26.500189999999993)
('yuv.max=', 241.59799999999996, 'yuv.min=', -26.970359999999992)
('yuv.max=', 255.0, 'yuv.min=', -24.025249999999993)
('yuv.max=', 251.27700000000002, 'yuv.min=', -20.705409999999986)
('yuv.max=', 235.20399999999998, 'yuv.min=', -89.185369999999992)
('yuv.max=', 234.37, 'yuv.min=', -24.810389999999995)
('yuv.max=', 220.20099999999999, 'yuv.min=', -23.18034999999999)
('yuv.max=', 172.08100000000002, 'yuv.min=', -53.840709999999987)
('yuv.max=', 206.86800000000002, 'yuv.min=', -28.055800000000005)
('yuv.max=', 219.68699999999998, 'yuv.min=', -34.681910000000002)
('yuv.max=', 249.125, 'yuv.min=', -7.4650699999999919)
('yuv.max=', 255.0, 'yuv.min=', -50.320849999999993)
('yuv.max=', 254.316, 'yuv.min=', -21.913359999999997)
('yuv.max=', 221.292, 'yuv.min=', -70.798359999999988)
('yuv.max=', 235.15300000000002, 'yuv.min=', -36.195359999999994)
('yuv.max=', 204.15799999999999, 'yuv.min=', -22.796120000000002)
('yuv.max=', 251.08799999999999, 'yuv.min=', -25.75988000000001)
('yuv.max=', 230.70599999999999, 'yuv.min=', -42.651020000000003)
('yuv.max=', 248.71199999999999, 'yuv.min=', -41.605039999999988)
('yuv.max=', 184.94799999999998, 'yuv.min=', -25.410449999999997)
('yuv.max=', 255.0, 'yuv.min=', -7.3052999999999972)
('yuv.max=', 251.52700000000002, 'yuv.min=', -24.555179999999993)
('yuv.max=', 220.65199999999999, 'yuv.min=', -13.221040000000002)
('yuv.max=', 233.34999999999999, 'yuv.min=', -59.384849999999993)
('yuv.max=', 255.0, 'yuv.min=', -4.8377499999999998)
('yuv.max=', 242.87099999999998, 'yuv.min=', -59.827750000000002)
('yuv.max=', 210.14099999999999, 'yuv.min=', -48.980469999999983)
('yuv.max=', 245.51999999999998, 'yuv.min=', -25.490949999999998)
('yuv.max=', 218.399, 'yuv.min=', -6.4238900000000001)
('yuv.max=', 233.13399999999999, 'yuv.min=', -20.675620000000002)
('yuv.max=', 255.0, 'yuv.min=', -17.530399999999997)
('yuv.max=', 235.69799999999998, 'yuv.min=', -46.175619999999995)
('yuv.max=', 255.0, 'yuv.min=', -47.24584999999999)
('yuv.max=', 208.846, 'yuv.min=', -48.3551)
('yuv.max=', 255.0, 'yuv.min=', -24.691850000000002)
('yuv.max=', 254.886, 'yuv.min=', -30.981949999999998)
('yuv.max=', 255.0, 'yuv.min=', -35.101019999999991)
('yuv.max=', 246.95700000000002, 'yuv.min=', -19.684570000000001)
('yuv.max=', 255.0, 'yuv.min=', -27.200259999999997)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 241.95099999999999, 'yuv.min=', -79.25703)
('yuv.max=', 234.47199999999998, 'yuv.min=', -20.261259999999993)
('yuv.max=', 217.785, 'yuv.min=', -23.235539999999993)
('yuv.max=', 228.16699999999997, 'yuv.min=', -28.015279999999994)
('yuv.max=', 251.50099999999998, 'yuv.min=', -47.535509999999988)
('yuv.max=', 253.11399999999998, 'yuv.min=', -26.970359999999996)
('yuv.max=', 247.846, 'yuv.min=', -95.375619999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.435250000000003)
('yuv.max=', 233.005, 'yuv.min=', -23.150469999999995)
('yuv.max=', 228.27500000000001, 'yuv.min=', -25.476430000000015)
('yuv.max=', 172.96099999999998, 'yuv.min=', -15.689969999999994)
('yuv.max=', 233.59699999999998, 'yuv.min=', -33.990569999999998)
('yuv.max=', 246.28800000000001, 'yuv.min=', -22.314709999999998)
('yuv.max=', 246.19999999999999, 'yuv.min=', -58.976939999999999)
('yuv.max=', 189.232, 'yuv.min=', -18.475310000000004)
('yuv.max=', 255.0, 'yuv.min=', -21.191590000000001)
('yuv.max=', 223.417, 'yuv.min=', -22.865379999999998)
('yuv.max=', 240.36799999999999, 'yuv.min=', -65.713619999999992)
('yuv.max=', 169.86599999999999, 'yuv.min=', -27.270389999999999)
('yuv.max=', 255.0, 'yuv.min=', -51.613829999999993)
('yuv.max=', 238.095, 'yuv.min=', -35.81026)
('yuv.max=', 209.667, 'yuv.min=', -27.340520000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', -96.234229999999982)
('yuv.max=', 215.13200000000001, 'yuv.min=', -32.773960000000002)
('yuv.max=', 253.22799999999998, 'yuv.min=', -21.084270000000011)
('yuv.max=', 244.505, 'yuv.min=', -29.815460000000005)
('yuv.max=', 252.608, 'yuv.min=', -35.225139999999989)
('yuv.max=', 250.99999999999997, 'yuv.min=', -7.2803599999999982)
('yuv.max=', 224.38999999999999, 'yuv.min=', -37.470179999999999)
('yuv.max=', 203.72399999999999, 'yuv.min=', -37.035740000000004)
('yuv.max=', 209.71600000000001, 'yuv.min=', -30.185620000000004)
('yuv.max=', 220.642, 'yuv.min=', -33.715849999999989)
('yuv.max=', 250.02199999999999, 'yuv.min=', -14.157439999999994)
('yuv.max=', 255.0, 'yuv.min=', -30.566310000000001)
('yuv.max=', 239.38, 'yuv.min=', -51.657920000000004)
('yuv.max=', 240.071, 'yuv.min=', -71.620519999999999)
('yuv.max=', 249.857, 'yuv.min=', -59.48942000000001)
('yuv.max=', 233.25700000000001, 'yuv.min=', -20.571380000000005)
('yuv.max=', 245.04399999999998, 'yuv.min=', -31.139610000000008)
('yuv.max=', 255.0, 'yuv.min=', -2.6145100000000099)
('yuv.max=', 245.90399999999997, 'yuv.min=', -25.729989999999987)
('yuv.max=', 249.696, 'yuv.min=', -22.16530999999998)
('yuv.max=', 164.114, 'yuv.min=', -5.4752399999999994)
('yuv.max=', 249.87, 'yuv.min=', -29.490119999999987)
('yuv.max=', 253.52699999999999, 'yuv.min=', -0.50004999999999988)
('yuv.max=', 213.005, 'yuv.min=', -23.232390000000006)
('yuv.max=', 255.0, 'yuv.min=', -23.995369999999998)
('yuv.max=', 145.626, 'yuv.min=', -38.463760000000008)
('yuv.max=', 255.0, 'yuv.min=', -35.150439999999996)
('yuv.max=', 240.58999999999997, 'yuv.min=', -37.149619999999999)
('yuv.max=', 232.22800000000001, 'yuv.min=', -12.46828)
('yuv.max=', 247.12499999999997, 'yuv.min=', -47.280299999999997)
('yuv.max=', 255.0, 'yuv.min=', -17.015409999999996)
('yuv.max=', 242.797, 'yuv.min=', -33.875640000000004)
('yuv.max=', 245.10299999999998, 'yuv.min=', -19.620239999999988)
('yuv.max=', 249.56099999999998, 'yuv.min=', -16.042970000000004)
('yuv.max=', 248.66900000000001, 'yuv.min=', -28.885489999999994)
('yuv.max=', 255.0, 'yuv.min=', -29.315409999999996)
('yuv.max=', 216.74000000000001, 'yuv.min=', -22.050359999999994)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.0, 'yuv.min=', -74.095459999999989)
('yuv.max=', 248.22800000000001, 'yuv.min=', -23.401189999999996)
('yuv.max=', 226.22799999999998, 'yuv.min=', -24.270300000000006)
('yuv.max=', 240.95699999999999, 'yuv.min=', -9.154200000000003)
('yuv.max=', 255.0, 'yuv.min=', -22.366070000000001)
('yuv.max=', 224.04300000000001, 'yuv.min=', -36.295369999999991)
('yuv.max=', 254.28799999999998, 'yuv.min=', -95.605519999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', -67.570729999999998)
('yuv.max=', 243.322, 'yuv.min=', -33.413160000000005)
('yuv.max=', 249.70099999999999, 'yuv.min=', -18.463710000000003)
('yuv.max=', 186.43099999999998, 'yuv.min=', -28.381710000000005)
('yuv.max=', 239.57599999999999, 'yuv.min=', -36.601250000000007)
('yuv.max=', 222.51599999999996, 'yuv.min=', -27.055429999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', -42.80059)
('yuv.max=', 248.98299999999998, 'yuv.min=', -72.805700000000002)
('yuv.max=', 239.79399999999998, 'yuv.min=', -29.015379999999986)
('yuv.max=', 250.0, 'yuv.min=', -3.4899800000000001)
('yuv.max=', 248.93899999999996, 'yuv.min=', -21.080139999999989)
('yuv.max=', 238.125, 'yuv.min=', -74.111239999999995)
('yuv.max=', 181.68000000000001, 'yuv.min=', -26.780709999999992)
('yuv.max=', 176.47200000000001, 'yuv.min=', -17.075169999999993)
('yuv.max=', 239.00999999999999, 'yuv.min=', -30.830499999999994)
('yuv.max=', 255.0, 'yuv.min=', -18.490539999999999)
('yuv.max=', 164.94799999999998, 'yuv.min=', -55.125900000000001)
('yuv.max=', 209.04899999999998, 'yuv.min=', -23.980429999999988)
('yuv.max=', 253.29900000000001, 'yuv.min=', -28.955619999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 251.58699999999996, 'yuv.min=', -27.825629999999997)
('yuv.max=', 253.77199999999999, 'yuv.min=', -96.674959999999999)
('yuv.max=', 250.08099999999996, 'yuv.min=', -21.248320000000003)
('yuv.max=', 253.21699999999998, 'yuv.min=', -30.920139999999993)
('yuv.max=', 252.34199999999998, 'yuv.min=', -35.465409999999991)
('yuv.max=', 254.18499999999997, 'yuv.min=', -50.181930000000008)
('yuv.max=', 167.09099999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 228.54600000000002, 'yuv.min=', -8.580120000000008)
('yuv.max=', 235.77999999999997, 'yuv.min=', -18.327090000000002)
('yuv.max=', 253.46199999999999, 'yuv.min=', -15.330179999999999)
('yuv.max=', 255.0, 'yuv.min=', -16.890089999999997)
('yuv.max=', 216.971, 'yuv.min=', -39.825599999999994)
('yuv.max=', 252.70699999999999, 'yuv.min=', -54.360269999999979)
('yuv.max=', 175.55399999999997, 'yuv.min=', -42.630449999999996)
('yuv.max=', 201.089, 'yuv.min=', -24.795449999999995)
('yuv.max=', 227.899, 'yuv.min=', -26.795649999999995)
('yuv.max=', 243.988, 'yuv.min=', -30.464909999999996)
('yuv.max=', 239.15899999999999, 'yuv.min=', -41.825799999999994)
('yuv.max=', 255.0, 'yuv.min=', -25.813270000000006)
('yuv.max=', 226.899, 'yuv.min=', -26.043440000000004)
('yuv.max=', 172.11600000000001, 'yuv.min=', -27.434620000000002)
('yuv.max=', 255.0, 'yuv.min=', -27.485349999999997)
('yuv.max=', 251.626, 'yuv.min=', -17.470639999999996)
('yuv.max=', 253.80399999999997, 'yuv.min=', -71.956229999999991)
('yuv.max=', 245.00699999999998, 'yuv.min=', -38.240379999999988)
('yuv.max=', 255.0, 'yuv.min=', -19.690369999999994)
('yuv.max=', 245.77199999999999, 'yuv.min=', -57.975569999999991)
('yuv.max=', 203.12200000000001, 'yuv.min=', -36.150539999999999)
('yuv.max=', 255.0, 'yuv.min=', -11.492910000000002)
('yuv.max=', 249.43000000000001, 'yuv.min=', -16.200389999999999)
('yuv.max=', 224.0, 'yuv.min=', -23.976700000000001)
('yuv.max=', 228.52199999999996, 'yuv.min=', -25.346080000000001)
('yuv.max=', 243.42999999999998, 'yuv.min=', -3.9225100000000097)
('yuv.max=', 252.0, 'yuv.min=', -24.33803)
('yuv.max=', 253.14199999999997, 'yuv.min=', -48.365469999999995)
('yuv.max=', 176.74799999999999, 'yuv.min=', -12.955249999999994)
('yuv.max=', 255.0, 'yuv.min=', -15.416290000000004)
('yuv.max=', 255.0, 'yuv.min=', -5.387430000000009)
('yuv.max=', 255.0, 'yuv.min=', -17.675229999999992)
('yuv.max=', 255.0, 'yuv.min=', -27.603260000000002)
('yuv.max=', 245.59699999999998, 'yuv.min=', -14.218749999999998)
('yuv.max=', 174.97299999999998, 'yuv.min=', -71.160719999999998)
('yuv.max=', 223.07499999999999, 'yuv.min=', -27.485349999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -46.203720000000004)
('yuv.max=', 231.54999999999998, 'yuv.min=', -15.100279999999994)
('yuv.max=', 229.87299999999996, 'yuv.min=', -24.910399999999996)
('yuv.max=', 247.172, 'yuv.min=', -14.124960000000002)
('yuv.max=', 254.35900000000001, 'yuv.min=', -43.282669999999996)
('yuv.max=', 246.98500000000001, 'yuv.min=', -32.97719)
('yuv.max=', 250.51499999999999, 'yuv.min=', -53.89009999999999)
('yuv.max=', 244.065, 'yuv.min=', -55.296039999999998)
('yuv.max=', 168.83699999999999, 'yuv.min=', -45.969799999999999)
('yuv.max=', 248.422, 'yuv.min=', -27.059999999999988)
('yuv.max=', 255.0, 'yuv.min=', -6.9799600000000019)
('yuv.max=', 221.21899999999999, 'yuv.min=', -32.849589999999999)
('yuv.max=', 232.0, 'yuv.min=', -7.7501599999999904)
('yuv.max=', 253.52699999999999, 'yuv.min=', -63.750839999999997)
('yuv.max=', 245.93799999999999, 'yuv.min=', -45.014070000000011)
('yuv.max=', 239.44499999999999, 'yuv.min=', -47.460809999999995)
('yuv.max=', 255.0, 'yuv.min=', -30.154509999999998)
('yuv.max=', 240.79499999999996, 'yuv.min=', -28.815359999999995)
('yuv.max=', 251.10299999999998, 'yuv.min=', -14.215129999999995)
('yuv.max=', 246.11299999999997, 'yuv.min=', -66.291460000000015)
('yuv.max=', 255.0, 'yuv.min=', -17.07517)
('yuv.max=', 209.886, 'yuv.min=', -51.794220000000003)
('yuv.max=', 217.34399999999999, 'yuv.min=', -10.995299999999986)
('yuv.max=', 255.0, 'yuv.min=', -18.049959999999992)
('yuv.max=', 238.53100000000001, 'yuv.min=', -17.345319999999997)
('yuv.max=', 244.58700000000002, 'yuv.min=', -15.415249999999995)
('yuv.max=', 252.761, 'yuv.min=', -26.870349999999998)
('yuv.max=', 234.80199999999999, 'yuv.min=', -45.000809999999994)
('yuv.max=', 239.096, 'yuv.min=', -51.00018)
('yuv.max=', 203.06299999999999, 'yuv.min=', -24.23564)
('yuv.max=', 235.87099999999995, 'yuv.min=', -24.320709999999981)
('yuv.max=', 246.869, 'yuv.min=', -69.300779999999989)
('yuv.max=', 237.899, 'yuv.min=', -37.843290000000003)
('yuv.max=', 254.41299999999995, 'yuv.min=', -16.370529999999992)
('yuv.max=', 236.291, 'yuv.min=', -43.330519999999993)
('yuv.max=', 253.81499999999997, 'yuv.min=', -27.940359999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.338939999999997)
('yuv.max=', 194.16399999999999, 'yuv.min=', -25.400079999999999)
('yuv.max=', 241.39299999999997, 'yuv.min=', -30.65579)
('yuv.max=', 251.71100000000001, 'yuv.min=', -28.889319999999998)
('yuv.max=', 164.46499999999997, 'yuv.min=', -35.831000000000003)
('yuv.max=', 226.583, 'yuv.min=', -37.350660000000005)
('yuv.max=', 229.245, 'yuv.min=', -26.359719999999996)
('yuv.max=', 175.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -25.350689999999993)
('yuv.max=', 253.63200000000001, 'yuv.min=', -62.095489999999998)
('yuv.max=', 220.40899999999999, 'yuv.min=', -37.347310000000007)
('yuv.max=', 238.34199999999998, 'yuv.min=', -24.321329999999996)
('yuv.max=', 227.75899999999999, 'yuv.min=', -22.835499999999996)
('yuv.max=', 232.40000000000001, 'yuv.min=', -40.588880000000003)
('yuv.max=', 228.30999999999997, 'yuv.min=', -15.330179999999999)
('yuv.max=', 227.99299999999999, 'yuv.min=', -25.979330000000001)
('yuv.max=', 252.114, 'yuv.min=', -21.630670000000002)
('yuv.max=', 235.142, 'yuv.min=', -12.014909999999999)
('yuv.max=', 214.09500000000003, 'yuv.min=', -49.825369999999992)
('yuv.max=', 214.97800000000001, 'yuv.min=', -27.404849999999993)
('yuv.max=', 232.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 216.65199999999999, 'yuv.min=', -23.725219999999986)
('yuv.max=', 236.27800000000002, 'yuv.min=', -13.835679999999996)
('yuv.max=', 193.80999999999997, 'yuv.min=', -70.160619999999994)
('yuv.max=', 223.83799999999999, 'yuv.min=', -19.905329999999985)
('yuv.max=', 229.00399999999999, 'yuv.min=', -26.855409999999996)
('yuv.max=', 238.97899999999998, 'yuv.min=', -54.209459999999993)
('yuv.max=', 225.285, 'yuv.min=', -26.669560000000004)
('yuv.max=', 247.19999999999999, 'yuv.min=', -42.900599999999997)
('yuv.max=', 255.0, 'yuv.min=', -23.020579999999985)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 244.70100000000002, 'yuv.min=', -25.37019999999999)
('yuv.max=', 251.755, 'yuv.min=', -10.940109999999992)
('yuv.max=', 171.66, 'yuv.min=', -26.825530000000001)
('yuv.max=', 255.0, 'yuv.min=', -40.070439999999991)
('yuv.max=', 249.03899999999999, 'yuv.min=', -45.385720000000006)
('yuv.max=', 237.56899999999999, 'yuv.min=', -29.400479999999995)
('yuv.max=', 253.02799999999996, 'yuv.min=', -51.021419999999999)
('yuv.max=', 238.36599999999999, 'yuv.min=', -29.27562)
('yuv.max=', 251.62099999999998, 'yuv.min=', -27.410649999999997)
('yuv.max=', 254.43000000000001, 'yuv.min=', -10.746290000000002)
('yuv.max=', 238.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 251.381, 'yuv.min=', -22.55574)
('yuv.max=', 254.10300000000001, 'yuv.min=', -12.663830000000004)
('yuv.max=', 228.96699999999998, 'yuv.min=', -50.530009999999997)
('yuv.max=', 255.0, 'yuv.min=', -44.955039999999997)
('yuv.max=', 211.25200000000001, 'yuv.min=', -16.703199999999995)
('yuv.max=', 234.815, 'yuv.min=', -37.200720000000004)
('yuv.max=', 254.10300000000001, 'yuv.min=', -34.284440000000011)
('yuv.max=', 246.49399999999997, 'yuv.min=', -48.255089999999996)
('yuv.max=', 244.03199999999998, 'yuv.min=', -6.0499899999999975)
('yuv.max=', 208.22699999999998, 'yuv.min=', -19.835600000000007)
('yuv.max=', 233.52499999999998, 'yuv.min=', -12.070099999999989)
('yuv.max=', 254.11399999999998, 'yuv.min=', -65.686570000000003)
('yuv.max=', 233.72899999999998, 'yuv.min=', -80.430539999999993)
('yuv.max=', 255.0, 'yuv.min=', -5.3752299999999895)
('yuv.max=', 248.86000000000001, 'yuv.min=', -15.345119999999998)
('yuv.max=', 255.0, 'yuv.min=', -41.255619999999979)
('yuv.max=', 207.29999999999998, 'yuv.min=', -53.760209999999994)
('yuv.max=', 249.11799999999999, 'yuv.min=', -44.104250000000015)
('yuv.max=', 244.29499999999999, 'yuv.min=', -19.776420000000009)
('yuv.max=', 250.99999999999997, 'yuv.min=', -64.350899999999996)
('yuv.max=', 255.0, 'yuv.min=', -8.8043900000000122)
('yuv.max=', 255.0, 'yuv.min=', -38.888779999999997)
('yuv.max=', 197.761, 'yuv.min=', -19.375399999999988)
('yuv.max=', 194.94899999999998, 'yuv.min=', -22.280259999999995)
('yuv.max=', 255.0, 'yuv.min=', -31.252000000000002)
('yuv.max=', 181.90699999999998, 'yuv.min=', -39.525569999999995)
('yuv.max=', 250.51499999999999, 'yuv.min=', -19.335149999999999)
('yuv.max=', 247.35799999999998, 'yuv.min=', -29.925839999999997)
('yuv.max=', 227.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.52599999999998, 'yuv.min=', -33.30543999999999)
('yuv.max=', 255.0, 'yuv.min=', -20.565149999999981)
('yuv.max=', 255.0, 'yuv.min=', -20.520330000000001)
('yuv.max=', 223.596, 'yuv.min=', -33.226030000000009)
('yuv.max=', 228.755, 'yuv.min=', -24.588960000000004)
('yuv.max=', 168.20599999999999, 'yuv.min=', -5.5350000000000001)
('yuv.max=', 218.27500000000001, 'yuv.min=', -25.87482)
('yuv.max=', 212.48399999999998, 'yuv.min=', -30.375269999999997)
('yuv.max=', 253.11999999999998, 'yuv.min=', -4.3521300000000167)
('yuv.max=', 248.08000000000001, 'yuv.min=', -32.120899999999992)
('yuv.max=', 209.76399999999998, 'yuv.min=', -99.285509999999988)
('yuv.max=', 208.69299999999998, 'yuv.min=', -30.136399999999995)
('yuv.max=', 241.45599999999999, 'yuv.min=', -21.111670000000004)
('yuv.max=', 252.70099999999999, 'yuv.min=', -49.995509999999996)
('yuv.max=', 144.83000000000001, 'yuv.min=', -11.614869999999991)
('yuv.max=', 255.0, 'yuv.min=', -34.722680000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.785109999999987)
('yuv.max=', 242.52200000000002, 'yuv.min=', -13.440359999999995)
('yuv.max=', 235.25599999999997, 'yuv.min=', -61.358939999999997)
('yuv.max=', 240.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 252.114, 'yuv.min=', -26.940479999999997)
('yuv.max=', 246.42999999999998, 'yuv.min=', -32.905399999999986)
('yuv.max=', 230.72999999999999, 'yuv.min=', -34.335419999999985)
('yuv.max=', 226.0, 'yuv.min=', -7.8420200000000015)
('yuv.max=', 239.10699999999997, 'yuv.min=', -93.115640000000013)
('yuv.max=', 229.887, 'yuv.min=', -41.084650000000011)
('yuv.max=', 217.35199999999998, 'yuv.min=', -36.565519999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.729459999999996)
('yuv.max=', 241.47300000000001, 'yuv.min=', -42.040759999999992)
('yuv.max=', 251.48300000000003, 'yuv.min=', -39.055399999999999)
('yuv.max=', 205.89999999999998, 'yuv.min=', -34.545810000000003)
('yuv.max=', 249.20699999999999, 'yuv.min=', -4.679230000000004)
('yuv.max=', 255.0, 'yuv.min=', -13.258359999999996)
('yuv.max=', 255.0, 'yuv.min=', -22.376289999999997)
('yuv.max=', 216.04999999999998, 'yuv.min=', -27.841349999999998)
('yuv.max=', 248.36599999999999, 'yuv.min=', -12.555210000000002)
('yuv.max=', 212.91499999999999, 'yuv.min=', -56.205269999999999)
('yuv.max=', 205.81899999999996, 'yuv.min=', -94.780129999999986)
('yuv.max=', 255.0, 'yuv.min=', -15.875049999999991)
('yuv.max=', 208.905, 'yuv.min=', -30.975329999999982)
('yuv.max=', 227.21499999999997, 'yuv.min=', -74.185099999999991)
('yuv.max=', 250.08099999999999, 'yuv.min=', -56.330590000000001)
('yuv.max=', 247.61899999999997, 'yuv.min=', -18.527230000000003)
('yuv.max=', 225.11199999999999, 'yuv.min=', -6.250009999999997)
('yuv.max=', 231.31899999999999, 'yuv.min=', -15.370429999999988)
('yuv.max=', 255.0, 'yuv.min=', -22.654989999999994)
('yuv.max=', 224.72199999999998, 'yuv.min=', -14.24044)
('yuv.max=', 252.22799999999998, 'yuv.min=', -12.09225)
('yuv.max=', 217.78899999999999, 'yuv.min=', -41.897189999999995)
('yuv.max=', 251.59799999999998, 'yuv.min=', -30.965410000000002)
('yuv.max=', 234.09899999999999, 'yuv.min=', -26.970359999999996)
('yuv.max=', 250.28799999999998, 'yuv.min=', -52.580829999999992)
('yuv.max=', 230.39400000000001, 'yuv.min=', -23.722280000000001)
('yuv.max=', 243.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.65800000000002, 'yuv.min=', -20.479060000000004)
('yuv.max=', 249.505, 'yuv.min=', -51.032199999999996)
('yuv.max=', 207.62799999999999, 'yuv.min=', -27.77043999999999)
('yuv.max=', 196.58699999999999, 'yuv.min=', -27.134699999999984)
('yuv.max=', 251.41199999999998, 'yuv.min=', -56.945589999999996)
('yuv.max=', 211.28799999999998, 'yuv.min=', -33.535339999999991)
('yuv.max=', 219.756, 'yuv.min=', -15.449250000000003)
('yuv.max=', 246.77699999999999, 'yuv.min=', -49.691780000000008)
('yuv.max=', 236.83199999999999, 'yuv.min=', -10.037960000000002)
('yuv.max=', 226.97800000000001, 'yuv.min=', -19.479979999999998)
('yuv.max=', 249.17399999999998, 'yuv.min=', -36.135600000000004)
('yuv.max=', 190.90999999999997, 'yuv.min=', -7.5844000000000023)
('yuv.max=', 237.61600000000001, 'yuv.min=', -60.573650000000001)
('yuv.max=', 255.0, 'yuv.min=', -20.980719999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', -27.739590000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', -44.020219999999995)
('yuv.max=', 248.262, 'yuv.min=', -28.817720000000001)
('yuv.max=', 223.83699999999999, 'yuv.min=', -35.735559999999992)
('yuv.max=', 248.809, 'yuv.min=', -13.170209999999997)
('yuv.max=', 255.0, 'yuv.min=', -15.000269999999997)
('yuv.max=', 254.65800000000002, 'yuv.min=', -13.315039999999996)
('yuv.max=', 218.71199999999999, 'yuv.min=', -36.180419999999991)
('yuv.max=', 237.96299999999997, 'yuv.min=', -50.644450000000006)
('yuv.max=', 255.0, 'yuv.min=', -84.700839999999999)
('yuv.max=', 221.49799999999999, 'yuv.min=', -34.185820000000007)
('yuv.max=', 237.267, 'yuv.min=', -55.055769999999995)
('yuv.max=', 212.70699999999999, 'yuv.min=', -20.811630000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', -28.745229999999999)
('yuv.max=', 198.989, 'yuv.min=', -30.590229999999991)
('yuv.max=', 185.98699999999999, 'yuv.min=', -37.776200000000003)
('yuv.max=', 252.42999999999998, 'yuv.min=', -34.160709999999987)
('yuv.max=', 254.40199999999999, 'yuv.min=', -14.129480000000001)
('yuv.max=', 255.0, 'yuv.min=', -21.058120000000002)
('yuv.max=', 214.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 161.74600000000001, 'yuv.min=', -45.750269999999993)
('yuv.max=', 217.87200000000001, 'yuv.min=', -38.510530000000003)
('yuv.max=', 237.715, 'yuv.min=', -60.235549999999989)
('yuv.max=', 149.59099999999998, 'yuv.min=', -8.0106399999999987)
('yuv.max=', 232.071, 'yuv.min=', -34.420489999999994)
('yuv.max=', 254.07099999999997, 'yuv.min=', -40.753109999999992)
('yuv.max=', 255.0, 'yuv.min=', -2.4674200000000042)
('yuv.max=', 227.27099999999999, 'yuv.min=', -35.165379999999985)
('yuv.max=', 243.66800000000001, 'yuv.min=', -48.03555999999999)
('yuv.max=', 234.25, 'yuv.min=', -26.285229999999995)
('yuv.max=', 255.0, 'yuv.min=', -21.105449999999987)
('yuv.max=', 117.136, 'yuv.min=', -56.16442)
('yuv.max=', 202.21299999999999, 'yuv.min=', -43.510500000000008)
('yuv.max=', 206.11799999999999, 'yuv.min=', -15.459190000000007)
('yuv.max=', 221.31999999999999, 'yuv.min=', -36.510329999999996)
('yuv.max=', 234.88799999999998, 'yuv.min=', -28.485449999999997)
('yuv.max=', 229.44899999999996, 'yuv.min=', -25.525399999999987)
('yuv.max=', 209.161, 'yuv.min=', -54.296030000000002)
('yuv.max=', 252.45799999999997, 'yuv.min=', -38.94267)
('yuv.max=', 251.02199999999996, 'yuv.min=', -44.453030000000012)
('yuv.max=', 227.91399999999999, 'yuv.min=', -16.090710000000005)
('yuv.max=', 246.58399999999997, 'yuv.min=', -34.82809000000001)
('yuv.max=', 232.09799999999998, 'yuv.min=', -43.560419999999993)
('yuv.max=', 254.77200000000002, 'yuv.min=', -44.875489999999999)
('yuv.max=', 238.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 247.63, 'yuv.min=', -36.075839999999985)
('yuv.max=', 249.18499999999997, 'yuv.min=', -93.486670000000004)
('yuv.max=', 225.285, 'yuv.min=', -29.552850000000014)
('yuv.max=', 247.499, 'yuv.min=', -50.490820000000014)
('yuv.max=', 238.0, 'yuv.min=', -35.025120000000001)
('yuv.max=', 183.286, 'yuv.min=', -24.610369999999996)
('yuv.max=', 228.80599999999998, 'yuv.min=', -16.315809999999999)
('yuv.max=', 255.0, 'yuv.min=', -33.675599999999996)
('yuv.max=', 249.52699999999999, 'yuv.min=', -22.120490000000004)
('yuv.max=', 255.0, 'yuv.min=', -8.0501900000000006)
('yuv.max=', 203.94999999999999, 'yuv.min=', -24.589170000000006)
('yuv.max=', 240.62599999999998, 'yuv.min=', -45.565130000000011)
('yuv.max=', 251.71199999999999, 'yuv.min=', -22.035419999999998)
('yuv.max=', 233.73399999999998, 'yuv.min=', -23.365429999999989)
('yuv.max=', 223.71199999999999, 'yuv.min=', -30.38073)
('yuv.max=', 253.41299999999998, 'yuv.min=', -44.757670000000012)
('yuv.max=', 231.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 200.30799999999999, 'yuv.min=', -57.175489999999996)
('yuv.max=', 254.06, 'yuv.min=', -29.479749999999996)
('yuv.max=', 196.81799999999998, 'yuv.min=', -34.120459999999994)
('yuv.max=', 255.0, 'yuv.min=', -23.912179999999999)
('yuv.max=', 255.0, 'yuv.min=', -25.985199999999988)
('yuv.max=', 192.976, 'yuv.min=', -25.955319999999997)
('yuv.max=', 244.05999999999997, 'yuv.min=', -12.800049999999995)
('yuv.max=', 166.86500000000001, 'yuv.min=', -35.035489999999989)
('yuv.max=', 254.77200000000002, 'yuv.min=', -24.710380000000001)
('yuv.max=', 233.54300000000001, 'yuv.min=', -35.920639999999992)
('yuv.max=', 235.52099999999999, 'yuv.min=', -17.330380000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.410150000000002)
('yuv.max=', 253.81499999999997, 'yuv.min=', -10.614850000000011)
('yuv.max=', 248.37399999999997, 'yuv.min=', -46.575659999999985)
('yuv.max=', 251.64299999999997, 'yuv.min=', -52.125599999999991)
('yuv.max=', 236.29899999999998, 'yuv.min=', -22.980329999999991)
('yuv.max=', 179.59699999999998, 'yuv.min=', -21.335349999999998)
('yuv.max=', 204.91999999999999, 'yuv.min=', -39.555449999999993)
('yuv.max=', 241.85600000000002, 'yuv.min=', -20.659750000000006)
('yuv.max=', 236.30199999999999, 'yuv.min=', -21.395110000000003)
('yuv.max=', 226.81499999999997, 'yuv.min=', -18.21552999999999)
('yuv.max=', 210.55500000000001, 'yuv.min=', -24.625309999999992)
('yuv.max=', 243.09, 'yuv.min=', -68.250059999999991)
('yuv.max=', 251.21299999999999, 'yuv.min=', -24.35058999999999)
('yuv.max=', 250.08099999999999, 'yuv.min=', -80.830579999999998)
('yuv.max=', 197.86199999999997, 'yuv.min=', -53.712899999999998)
('yuv.max=', 222.97199999999995, 'yuv.min=', -47.29524)
('yuv.max=', 243.733, 'yuv.min=', -20.820359999999994)
('yuv.max=', 225.39199999999997, 'yuv.min=', -16.960219999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -19.787390000000002)
('yuv.max=', 218.233, 'yuv.min=', -34.645820000000001)
('yuv.max=', 236.64099999999999, 'yuv.min=', -26.44781)
('yuv.max=', 253.989, 'yuv.min=', -69.820339999999987)
('yuv.max=', 252.63, 'yuv.min=', -15.875049999999998)
('yuv.max=', 164.31200000000001, 'yuv.min=', -42.355729999999994)
('yuv.max=', 250.66299999999998, 'yuv.min=', -24.395409999999991)
('yuv.max=', 254.245, 'yuv.min=', -7.3501199999999862)
('yuv.max=', 212.249, 'yuv.min=', -30.475279999999991)
('yuv.max=', 246.15699999999998, 'yuv.min=', -28.785479999999996)
('yuv.max=', 252.679, 'yuv.min=', -31.080530000000003)
('yuv.max=', 203.73099999999999, 'yuv.min=', -59.590669999999989)
('yuv.max=', 209.88800000000001, 'yuv.min=', -34.620509999999996)
('yuv.max=', 225.16999999999999, 'yuv.min=', -31.835169999999998)
('yuv.max=', 219.61699999999999, 'yuv.min=', -32.590429999999991)
('yuv.max=', 243.05999999999997, 'yuv.min=', -25.83793)
('yuv.max=', 209.97199999999998, 'yuv.min=', -38.695609999999995)
('yuv.max=', 212.28599999999997, 'yuv.min=', -36.566860000000005)
('yuv.max=', 191.36299999999997, 'yuv.min=', -67.162390000000002)
('yuv.max=', 255.0, 'yuv.min=', -47.480319999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 224.72399999999999, 'yuv.min=', -31.545509999999993)
('yuv.max=', 224.69999999999999, 'yuv.min=', -34.56532)
('yuv.max=', 254.40199999999999, 'yuv.min=', -39.170349999999999)
('yuv.max=', 176.43299999999999, 'yuv.min=', -29.400479999999998)
('yuv.max=', 252.0, 'yuv.min=', -19.650119999999998)
('yuv.max=', 239.51599999999996, 'yuv.min=', -39.870419999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', -39.580759999999998)
('yuv.max=', 255.0, 'yuv.min=', -51.498949999999994)
('yuv.max=', 245.56999999999999, 'yuv.min=', -15.449169999999995)
('yuv.max=', 237.24899999999997, 'yuv.min=', -30.460339999999984)
('yuv.max=', 176.39699999999999, 'yuv.min=', -44.700779999999995)
('yuv.max=', 238.83099999999999, 'yuv.min=', -41.800489999999996)
('yuv.max=', 203.947, 'yuv.min=', -70.100940000000008)
('yuv.max=', 199.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 247.41200000000001, 'yuv.min=', -39.78534999999998)
('yuv.max=', 238.81899999999999, 'yuv.min=', -27.910699999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.290769999999995)
('yuv.max=', 190.86099999999999, 'yuv.min=', -24.980529999999998)
('yuv.max=', 239.76999999999998, 'yuv.min=', -59.890699999999988)
('yuv.max=', 196.25, 'yuv.min=', -42.500559999999993)
('yuv.max=', 238.25200000000001, 'yuv.min=', -27.65549)
('yuv.max=', 210.27799999999996, 'yuv.min=', -39.319450000000003)
('yuv.max=', 240.684, 'yuv.min=', -30.630479999999999)
('yuv.max=', 231.67599999999999, 'yuv.min=', -23.67002999999999)
('yuv.max=', 234.078, 'yuv.min=', -26.625509999999998)
('yuv.max=', 227.01699999999997, 'yuv.min=', -22.598860000000002)
('yuv.max=', 197.34399999999999, 'yuv.min=', -13.355289999999982)
('yuv.max=', 220.51400000000001, 'yuv.min=', -30.408900000000003)
('yuv.max=', 253.42999999999998, 'yuv.min=', -34.880289999999988)
('yuv.max=', 213.328, 'yuv.min=', -21.665259999999993)
('yuv.max=', 242.70099999999999, 'yuv.min=', -15.54514)
('yuv.max=', 253.23899999999998, 'yuv.min=', -16.010170000000002)
('yuv.max=', 208.214, 'yuv.min=', -20.120289999999983)
('yuv.max=', 229.68999999999997, 'yuv.min=', -23.410249999999984)
('yuv.max=', 247.52700000000002, 'yuv.min=', -19.660489999999999)
('yuv.max=', 237.857, 'yuv.min=', -22.395209999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', -27.875019999999992)
('yuv.max=', 241.18899999999999, 'yuv.min=', -48.625249999999994)
('yuv.max=', 248.10299999999998, 'yuv.min=', -32.185819999999993)
('yuv.max=', 253.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 236.34099999999998, 'yuv.min=', -32.550179999999997)
('yuv.max=', 245.24200000000002, 'yuv.min=', -46.432780000000001)
('yuv.max=', 205.89599999999999, 'yuv.min=', -95.268470000000008)
('yuv.max=', 218.68199999999999, 'yuv.min=', -43.254750000000001)
('yuv.max=', 181.83699999999999, 'yuv.min=', -85.845489999999984)
('yuv.max=', 159.00299999999999, 'yuv.min=', -41.624050000000004)
('yuv.max=', 251.24499999999995, 'yuv.min=', -50.061040000000013)
('yuv.max=', 192.488, 'yuv.min=', -61.535679999999985)
('yuv.max=', 210.71499999999997, 'yuv.min=', -60.42653)
('yuv.max=', 240.10499999999999, 'yuv.min=', -23.870049999999992)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 245.548, 'yuv.min=', -30.890259999999991)
('yuv.max=', 251.45599999999996, 'yuv.min=', -26.41554)
('yuv.max=', 242.79299999999998, 'yuv.min=', -27.309409999999986)
('yuv.max=', 252.08799999999999, 'yuv.min=', -60.241879999999995)
('yuv.max=', 241.792, 'yuv.min=', -58.31004999999999)
('yuv.max=', 193.34300000000002, 'yuv.min=', -16.730319999999999)
('yuv.max=', 234.89599999999999, 'yuv.min=', -23.525199999999991)
('yuv.max=', 171.18899999999999, 'yuv.min=', -53.785520000000005)
('yuv.max=', 247.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.559, 'yuv.min=', -5.5200599999999831)
('yuv.max=', 246.011, 'yuv.min=', -39.315179999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', -16.215329999999991)
('yuv.max=', 232.76599999999996, 'yuv.min=', -20.665159999999986)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.886, 'yuv.min=', -40.395779999999995)
('yuv.max=', 255.0, 'yuv.min=', -7.7432600000000029)
('yuv.max=', 239.54599999999999, 'yuv.min=', -28.84629)
('yuv.max=', 245.60799999999998, 'yuv.min=', -15.174979999999993)
('yuv.max=', 243.74399999999997, 'yuv.min=', -57.339829999999992)
('yuv.max=', 231.71899999999999, 'yuv.min=', -37.48054999999998)
('yuv.max=', 182.97800000000001, 'yuv.min=', -20.090409999999995)
('yuv.max=', 255.0, 'yuv.min=', -20.517880000000002)
('yuv.max=', 253.20599999999999, 'yuv.min=', -43.778509999999997)
('yuv.max=', 238.47899999999998, 'yuv.min=', -58.679100000000005)
('yuv.max=', 227.16300000000001, 'yuv.min=', -31.345489999999995)
('yuv.max=', 217.25199999999998, 'yuv.min=', -6.1072300000000013)
('yuv.max=', 228.31399999999996, 'yuv.min=', -7.4267700000000048)
('yuv.max=', 248.60399999999998, 'yuv.min=', -40.604939999999999)
('yuv.max=', 203.20599999999999, 'yuv.min=', -50.459879999999984)
('yuv.max=', 203.012, 'yuv.min=', -30.015479999999997)
('yuv.max=', 248.21499999999997, 'yuv.min=', -14.118510000000001)
('yuv.max=', 245.65099999999998, 'yuv.min=', -51.864640000000009)
('yuv.max=', 174.34800000000001, 'yuv.min=', -14.185249999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -72.695319999999995)
('yuv.max=', 211.47299999999998, 'yuv.min=', -39.464579999999998)
('yuv.max=', 249.06399999999996, 'yuv.min=', -28.800419999999999)
('yuv.max=', 180.41399999999999, 'yuv.min=', -12.495450000000002)
('yuv.max=', 247.803, 'yuv.min=', -20.473890000000004)
('yuv.max=', 180.59100000000001, 'yuv.min=', -7.0500899999999955)
('yuv.max=', 255.0, 'yuv.min=', -3.6899999999999995)
('yuv.max=', 208.91300000000001, 'yuv.min=', -25.48058)
('yuv.max=', 248.81099999999998, 'yuv.min=', -15.916760000000011)
('yuv.max=', 255.0, 'yuv.min=', -22.908950000000004)
('yuv.max=', 230.81900000000002, 'yuv.min=', -52.480819999999987)
('yuv.max=', 221.64100000000002, 'yuv.min=', -10.11014999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', -32.175449999999991)
('yuv.max=', 197.054, 'yuv.min=', -11.440159999999993)
('yuv.max=', 245.29900000000001, 'yuv.min=', -45.660629999999998)
('yuv.max=', 192.90300000000002, 'yuv.min=', -19.744390000000006)
('yuv.max=', 189.93299999999999, 'yuv.min=', -10.410179999999992)
('yuv.max=', 225.96799999999999, 'yuv.min=', -8.4502299999999959)
('yuv.max=', 202.09399999999999, 'yuv.min=', -46.580229999999986)
('yuv.max=', 249.929, 'yuv.min=', -36.610339999999994)
('yuv.max=', 255.0, 'yuv.min=', -32.750199999999992)
('yuv.max=', 255.0, 'yuv.min=', -58.671019999999999)
('yuv.max=', 195.892, 'yuv.min=', -12.670159999999996)
('yuv.max=', 224.21299999999999, 'yuv.min=', -20.820359999999997)
('yuv.max=', 176.88999999999999, 'yuv.min=', -12.885119999999986)
('yuv.max=', 248.161, 'yuv.min=', -25.455500000000004)
('yuv.max=', 191.81900000000002, 'yuv.min=', -72.990780000000001)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999995)
('yuv.max=', 248.65799999999999, 'yuv.min=', -12.540269999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', -30.985699999999998)
('yuv.max=', 231.53100000000001, 'yuv.min=', -31.120159999999998)
('yuv.max=', 241.416, 'yuv.min=', -45.920409999999976)
('yuv.max=', 168.86399999999998, 'yuv.min=', -10.755029999999994)
('yuv.max=', 209.41499999999999, 'yuv.min=', -21.595130000000001)
('yuv.max=', 248.46099999999998, 'yuv.min=', -104.73507999999998)
('yuv.max=', 228.61099999999999, 'yuv.min=', -12.080420000000004)
('yuv.max=', 183.54300000000001, 'yuv.min=', -55.096019999999996)
('yuv.max=', 242.98499999999999, 'yuv.min=', -16.015410000000003)
('yuv.max=', 250.43399999999997, 'yuv.min=', -23.925239999999992)
('yuv.max=', 233.286, 'yuv.min=', -31.360429999999997)
('yuv.max=', 232.58699999999999, 'yuv.min=', -25.755299999999988)
('yuv.max=', 242.78699999999998, 'yuv.min=', -32.375469999999993)
('yuv.max=', 180.06400000000002, 'yuv.min=', -39.01057999999999)
('yuv.max=', 221.553, 'yuv.min=', -49.410389999999985)
('yuv.max=', 240.70699999999999, 'yuv.min=', -17.505089999999996)
('yuv.max=', 173.48999999999998, 'yuv.min=', -83.403649999999999)
('yuv.max=', 225.376, 'yuv.min=', -25.862750000000013)
('yuv.max=', 255.0, 'yuv.min=', -14.359959999999997)
('yuv.max=', 244.28799999999998, 'yuv.min=', -34.071539999999999)
('yuv.max=', 151.642, 'yuv.min=', -22.06529999999999)
('yuv.max=', 246.47800000000001, 'yuv.min=', -57.160550000000001)
('yuv.max=', 251.74000000000001, 'yuv.min=', -18.375780000000002)
('yuv.max=', 234.47199999999995, 'yuv.min=', -23.395309999999995)
('yuv.max=', 255.0, 'yuv.min=', -9.1100499999999851)
('yuv.max=', 217.22800000000001, 'yuv.min=', -15.300299999999996)
('yuv.max=', 249.71699999999998, 'yuv.min=', -28.355559999999997)
('yuv.max=', 249.47299999999998, 'yuv.min=', -47.609210000000004)
('yuv.max=', 229.33699999999999, 'yuv.min=', -30.9117)
('yuv.max=', 220.489, 'yuv.min=', -40.055499999999981)
('yuv.max=', 250.35899999999998, 'yuv.min=', -14.630109999999981)
('yuv.max=', 218.13199999999998, 'yuv.min=', -42.434999999999995)
('yuv.max=', 248.82699999999997, 'yuv.min=', -38.42513000000001)
('yuv.max=', 235.51500000000001, 'yuv.min=', -21.860709999999987)
('yuv.max=', 254.10300000000001, 'yuv.min=', -99.328770000000006)
('yuv.max=', 160.21600000000001, 'yuv.min=', -24.995469999999987)
('yuv.max=', 251.64299999999997, 'yuv.min=', -48.480419999999988)
('yuv.max=', 251.97800000000001, 'yuv.min=', -47.750469999999993)
('yuv.max=', 169.02099999999999, 'yuv.min=', -76.840549999999993)
('yuv.max=', 251.97800000000001, 'yuv.min=', -21.780209999999993)
('yuv.max=', 209.46899999999999, 'yuv.min=', -22.44642000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.640149999999995)
('yuv.max=', 187.33699999999999, 'yuv.min=', -14.445029999999997)
('yuv.max=', 252.31, 'yuv.min=', -19.095379999999995)
('yuv.max=', 243.815, 'yuv.min=', -18.839669999999991)
('yuv.max=', 238.19199999999998, 'yuv.min=', -20.124470000000002)
('yuv.max=', 234.39099999999999, 'yuv.min=', -29.379149999999996)
('yuv.max=', 253.13099999999997, 'yuv.min=', -20.235239999999994)
('yuv.max=', 246.13599999999997, 'yuv.min=', -20.963790000000003)
('yuv.max=', 228.02599999999998, 'yuv.min=', -12.702179999999998)
('yuv.max=', 211.31400000000002, 'yuv.min=', -37.026150000000001)
('yuv.max=', 240.63, 'yuv.min=', -36.524110000000007)
('yuv.max=', 247.202, 'yuv.min=', -17.490149999999986)
('yuv.max=', 185.464, 'yuv.min=', -24.410350000000001)
('yuv.max=', 253.20599999999999, 'yuv.min=', -38.850630000000002)
('yuv.max=', 255.0, 'yuv.min=', -14.200189999999992)
('yuv.max=', 253.41299999999998, 'yuv.min=', -14.532429999999998)
('yuv.max=', 255.0, 'yuv.min=', -27.730189999999993)
('yuv.max=', 167.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 226.95500000000001, 'yuv.min=', -19.320209999999989)
('yuv.max=', 240.71099999999998, 'yuv.min=', -24.84027)
('yuv.max=', 199.80099999999999, 'yuv.min=', -11.971260000000001)
('yuv.max=', 255.0, 'yuv.min=', -23.781269999999999)
('yuv.max=', 222.71799999999999, 'yuv.min=', -46.933819999999997)
('yuv.max=', 242.48399999999998, 'yuv.min=', -28.515329999999992)
('yuv.max=', 226.767, 'yuv.min=', -25.670229999999989)
('yuv.max=', 253.0, 'yuv.min=', -0.51498999999999739)
('yuv.max=', 231.505, 'yuv.min=', -13.385169999999988)
('yuv.max=', 194.90000000000001, 'yuv.min=', -27.084530000000001)
('yuv.max=', 255.0, 'yuv.min=', -28.665959999999998)
('yuv.max=', 245.57699999999997, 'yuv.min=', -24.85521)
('yuv.max=', 247.90099999999998, 'yuv.min=', -49.505829999999989)
('yuv.max=', 255.0, 'yuv.min=', -27.329689999999999)
('yuv.max=', 184.214, 'yuv.min=', -38.850809999999996)
('yuv.max=', 244.886, 'yuv.min=', -41.870449999999991)
('yuv.max=', 253.31599999999997, 'yuv.min=', -52.724429999999998)
('yuv.max=', 214.46599999999998, 'yuv.min=', -36.941479999999999)
('yuv.max=', 227.57599999999996, 'yuv.min=', -50.865719999999996)
('yuv.max=', 243.44499999999999, 'yuv.min=', -15.400309999999998)
('yuv.max=', 253.185, 'yuv.min=', -114.04057999999999)
('yuv.max=', 233.67099999999999, 'yuv.min=', -39.310609999999997)
('yuv.max=', 167.60799999999998, 'yuv.min=', -24.24905)
('yuv.max=', 251.04299999999998, 'yuv.min=', -57.805429999999987)
('yuv.max=', 198.93699999999998, 'yuv.min=', -42.050350000000009)
('yuv.max=', 239.161, 'yuv.min=', -22.402939999999994)
('yuv.max=', 255.0, 'yuv.min=', -44.490389999999998)
('yuv.max=', 255.0, 'yuv.min=', -28.999209999999987)
('yuv.max=', 249.61799999999999, 'yuv.min=', -59.214709999999997)
('yuv.max=', 233.02099999999999, 'yuv.min=', -25.570219999999988)
('yuv.max=', 255.0, 'yuv.min=', -21.492699999999985)
('yuv.max=', 216.02699999999999, 'yuv.min=', -32.830699999999993)
('yuv.max=', 192.96799999999999, 'yuv.min=', -31.115590000000001)
('yuv.max=', 239.16799999999998, 'yuv.min=', -33.205429999999993)
('yuv.max=', 174.03800000000001, 'yuv.min=', -20.220299999999995)
('yuv.max=', 240.41899999999998, 'yuv.min=', -46.505529999999993)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 254.70099999999999, 'yuv.min=', -13.329920000000001)
('yuv.max=', 242.21699999999998, 'yuv.min=', -42.90634)
('yuv.max=', 245.91800000000001, 'yuv.min=', -9.7539700000000025)
('yuv.max=', 228.89599999999996, 'yuv.min=', -53.042619999999999)
('yuv.max=', 206.94, 'yuv.min=', -25.423379999999998)
('yuv.max=', 255.0, 'yuv.min=', -46.628329999999998)
('yuv.max=', 246.18399999999997, 'yuv.min=', -19.924839999999996)
('yuv.max=', 250.83599999999998, 'yuv.min=', -45.730759999999997)
('yuv.max=', 254.10300000000001, 'yuv.min=', -31.490319999999993)
('yuv.max=', 255.0, 'yuv.min=', -27.674999999999969)
('yuv.max=', 209.06399999999999, 'yuv.min=', -37.820830000000001)
('yuv.max=', 243.815, 'yuv.min=', -46.699090000000012)
('yuv.max=', 245.26099999999997, 'yuv.min=', -62.265629999999994)
('yuv.max=', 224.04999999999998, 'yuv.min=', -53.124190000000013)
('yuv.max=', 184.60599999999999, 'yuv.min=', -36.163159999999998)
('yuv.max=', 241.78399999999999, 'yuv.min=', -28.500439999999998)
('yuv.max=', 223.74399999999997, 'yuv.min=', -76.962090000000003)
('yuv.max=', 244.14599999999999, 'yuv.min=', -6.3649599999999964)
('yuv.max=', 255.0, 'yuv.min=', -102.61992999999998)
('yuv.max=', 255.0, 'yuv.min=', -34.090579999999989)
('yuv.max=', 252.03199999999998, 'yuv.min=', -98.665580000000006)
('yuv.max=', 251.77799999999999, 'yuv.min=', -22.08024)
('yuv.max=', 208.369, 'yuv.min=', -94.527410000000003)
('yuv.max=', 177.71499999999997, 'yuv.min=', -19.320209999999996)
('yuv.max=', 180.35900000000001, 'yuv.min=', -17.805119999999995)
('yuv.max=', 255.0, 'yuv.min=', -13.185150000000005)
('yuv.max=', 173.85500000000002, 'yuv.min=', -28.570519999999998)
('yuv.max=', 234.84299999999999, 'yuv.min=', -13.485179999999993)
('yuv.max=', 246.76599999999999, 'yuv.min=', -31.37536999999999)
('yuv.max=', 249.09899999999996, 'yuv.min=', -12.532440000000008)
('yuv.max=', 173.77199999999999, 'yuv.min=', -57.412620000000004)
('yuv.max=', 225.28399999999999, 'yuv.min=', -7.1268200000000093)
('yuv.max=', 230.267, 'yuv.min=', -39.370370000000001)
('yuv.max=', 239.39099999999996, 'yuv.min=', -29.345289999999999)
('yuv.max=', 246.26999999999998, 'yuv.min=', -29.075139999999998)
('yuv.max=', 162.73399999999998, 'yuv.min=', -34.710149999999992)
('yuv.max=', 248.73999999999998, 'yuv.min=', -13.404650000000004)
('yuv.max=', 243.03, 'yuv.min=', -53.385440000000003)
('yuv.max=', 161.70400000000001, 'yuv.min=', -10.789200000000001)
('yuv.max=', 251.16800000000001, 'yuv.min=', -45.715820000000001)
('yuv.max=', 237.94200000000001, 'yuv.min=', -6.1126000000000005)
('yuv.max=', 253.99999999999997, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 207.06299999999999, 'yuv.min=', -16.446790000000004)
('yuv.max=', 243.21699999999998, 'yuv.min=', -30.645419999999991)
('yuv.max=', 244.74399999999997, 'yuv.min=', -52.410689999999995)
('yuv.max=', 186.20099999999999, 'yuv.min=', -36.505759999999995)
('yuv.max=', 174.0, 'yuv.min=', -18.3064)
('yuv.max=', 247.65199999999999, 'yuv.min=', -25.150669999999991)
('yuv.max=', 247.64100000000002, 'yuv.min=', -37.89584)
('yuv.max=', 244.25899999999999, 'yuv.min=', -38.520899999999997)
('yuv.max=', 217.15600000000001, 'yuv.min=', -24.240970000000004)
('yuv.max=', 255.0, 'yuv.min=', -37.205829999999992)
('yuv.max=', 194.57599999999996, 'yuv.min=', -46.546360000000007)
('yuv.max=', 255.0, 'yuv.min=', -5.234969999999997)
('yuv.max=', 255.0, 'yuv.min=', -21.050259999999987)
('yuv.max=', 243.71199999999999, 'yuv.min=', -33.265190000000004)
('yuv.max=', 167.28700000000001, 'yuv.min=', -29.829280000000004)
('yuv.max=', 255.0, 'yuv.min=', -23.895359999999997)
('yuv.max=', 244.70100000000002, 'yuv.min=', -9.9101299999999988)
('yuv.max=', 177.661, 'yuv.min=', -151.27506)
('yuv.max=', 233.22099999999998, 'yuv.min=', -27.226589999999998)
('yuv.max=', 171.64600000000002, 'yuv.min=', -29.200459999999996)
('yuv.max=', 234.14699999999999, 'yuv.min=', -85.202629999999985)
('yuv.max=', 237.44, 'yuv.min=', -24.310699999999997)
('yuv.max=', 216.54099999999997, 'yuv.min=', -11.03426)
('yuv.max=', 230.23499999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 206.07300000000001, 'yuv.min=', -11.525229999999979)
('yuv.max=', 242.29300000000001, 'yuv.min=', -1.8956599999999995)
('yuv.max=', 255.0, 'yuv.min=', -22.165309999999998)
('yuv.max=', 252.44099999999997, 'yuv.min=', -13.215029999999985)
('yuv.max=', 233.25199999999998, 'yuv.min=', -21.535369999999997)
('yuv.max=', 119.155, 'yuv.min=', -27.070369999999997)
('yuv.max=', 251.49000000000001, 'yuv.min=', -25.155239999999992)
('yuv.max=', 242.35599999999999, 'yuv.min=', -38.048710000000007)
('yuv.max=', 179.804, 'yuv.min=', -25.659859999999998)
('yuv.max=', 176.45099999999996, 'yuv.min=', -30.529970000000006)
('yuv.max=', 209.27499999999998, 'yuv.min=', -24.417719999999999)
('yuv.max=', 203.45499999999998, 'yuv.min=', -37.525369999999995)
('yuv.max=', 230.80799999999999, 'yuv.min=', -9.7430100000000053)
('yuv.max=', 248.17399999999998, 'yuv.min=', -28.555350000000004)
('yuv.max=', 241.548, 'yuv.min=', -21.619720000000008)
('yuv.max=', 253.80399999999997, 'yuv.min=', -46.033569999999997)
('yuv.max=', 200.50899999999999, 'yuv.min=', -34.465309999999995)
('yuv.max=', 255.0, 'yuv.min=', -48.911030000000011)
('yuv.max=', 253.74600000000001, 'yuv.min=', -10.02712)
('yuv.max=', 214.71700000000001, 'yuv.min=', -37.080510000000004)
('yuv.max=', 253.25599999999997, 'yuv.min=', -27.415219999999994)
('yuv.max=', 252.17400000000001, 'yuv.min=', -20.049810000000001)
('yuv.max=', 237.92899999999997, 'yuv.min=', -96.420540000000003)
('yuv.max=', 238.20600000000002, 'yuv.min=', -14.812500000000002)
('yuv.max=', 249.886, 'yuv.min=', -14.945079999999997)
('yuv.max=', 228.12699999999998, 'yuv.min=', -38.46570999999998)
('yuv.max=', 255.0, 'yuv.min=', -30.445399999999992)
('yuv.max=', 240.47899999999998, 'yuv.min=', -39.470379999999992)
('yuv.max=', 217.98099999999999, 'yuv.min=', -49.970199999999984)
('yuv.max=', 240.071, 'yuv.min=', -43.83970999999999)
('yuv.max=', 248.74299999999999, 'yuv.min=', -24.65518999999998)
('yuv.max=', 248.37999999999997, 'yuv.min=', -55.645459999999986)
('yuv.max=', 190.399, 'yuv.min=', -36.320679999999996)
('yuv.max=', 253.77199999999999, 'yuv.min=', -6.7649999999999988)
('yuv.max=', 243.755, 'yuv.min=', -17.215429999999991)
('yuv.max=', 215.05799999999999, 'yuv.min=', -11.565479999999994)
('yuv.max=', 228.33100000000002, 'yuv.min=', -25.000039999999991)
('yuv.max=', 255.0, 'yuv.min=', -73.580469999999977)
('yuv.max=', 184.863, 'yuv.min=', -38.070239999999991)
('yuv.max=', 231.24699999999996, 'yuv.min=', -16.775139999999997)
('yuv.max=', 240.02399999999994, 'yuv.min=', -26.685269999999996)
('yuv.max=', 253.48399999999998, 'yuv.min=', -16.183980000000005)
('yuv.max=', 243.40600000000001, 'yuv.min=', -43.445469999999993)
('yuv.max=', 253.29900000000001, 'yuv.min=', -39.428689999999996)
('yuv.max=', 255.0, 'yuv.min=', -34.975430000000003)
('yuv.max=', 222.63999999999999, 'yuv.min=', -38.070239999999984)
('yuv.max=', 227.374, 'yuv.min=', -46.950389999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.25515)
('yuv.max=', 151.245, 'yuv.min=', -24.810389999999998)
('yuv.max=', 255.0, 'yuv.min=', -93.559269999999998)
('yuv.max=', 238.565, 'yuv.min=', -72.365409999999997)
('yuv.max=', 234.96100000000001, 'yuv.min=', -26.627310000000005)
('yuv.max=', 253.989, 'yuv.min=', -33.295070000000003)
('yuv.max=', 254.06, 'yuv.min=', -32.507170000000002)
('yuv.max=', 165.87699999999998, 'yuv.min=', -33.400190000000002)
('yuv.max=', 255.0, 'yuv.min=', -24.170079999999984)
('yuv.max=', 245.28100000000001, 'yuv.min=', -69.030630000000002)
('yuv.max=', 215.19299999999998, 'yuv.min=', -25.679099999999991)
('yuv.max=', 186.82999999999998, 'yuv.min=', -23.295299999999983)
('yuv.max=', 250.0, 'yuv.min=', -13.595790000000001)
('yuv.max=', 242.13999999999999, 'yuv.min=', -13.785209999999985)
('yuv.max=', 254.08800000000002, 'yuv.min=', -27.630179999999996)
('yuv.max=', 255.0, 'yuv.min=', -2.4682600000000008)
('yuv.max=', 245.798, 'yuv.min=', -35.989580000000004)
('yuv.max=', 255.0, 'yuv.min=', -9.9549499999999895)
('yuv.max=', 235.80999999999997, 'yuv.min=', -71.420500000000004)
('yuv.max=', 254.08800000000002, 'yuv.min=', -32.861330000000009)
('yuv.max=', 197.89099999999996, 'yuv.min=', -23.65052)
('yuv.max=', 207.42999999999998, 'yuv.min=', -45.150210000000001)
('yuv.max=', 197.19299999999998, 'yuv.min=', -71.729109999999991)
('yuv.max=', 231.51300000000001, 'yuv.min=', -23.535569999999996)
('yuv.max=', 253.185, 'yuv.min=', -24.140199999999986)
('yuv.max=', 248.05999999999997, 'yuv.min=', -81.330629999999985)
('yuv.max=', 254.65800000000002, 'yuv.min=', -27.530169999999998)
('yuv.max=', 252.22799999999998, 'yuv.min=', -43.619349999999997)
('yuv.max=', 230.02499999999998, 'yuv.min=', -29.489310000000003)
('yuv.max=', 227.09700000000001, 'yuv.min=', -19.390339999999998)
('yuv.max=', 218.62, 'yuv.min=', -69.070879999999988)
('yuv.max=', 241.60199999999998, 'yuv.min=', -27.068540000000009)
('yuv.max=', 215.017, 'yuv.min=', -14.199609999999996)
('yuv.max=', 247.917, 'yuv.min=', -31.209720000000001)
('yuv.max=', 198.20099999999999, 'yuv.min=', -11.510289999999996)
('yuv.max=', 217.273, 'yuv.min=', -58.665269999999985)
('yuv.max=', 225.09, 'yuv.min=', -13.705169999999995)
('yuv.max=', 246.92499999999995, 'yuv.min=', -17.575220000000002)
('yuv.max=', 255.0, 'yuv.min=', -22.74006)
('yuv.max=', 229.38200000000001, 'yuv.min=', -93.520249999999976)
('yuv.max=', 217.45600000000002, 'yuv.min=', -29.945349999999998)
('yuv.max=', 108.22799999999999, 'yuv.min=', -0.20002000000000209)
('yuv.max=', 252.99099999999999, 'yuv.min=', -50.138730000000002)
('yuv.max=', 253.53300000000002, 'yuv.min=', -34.933040000000005)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -68.351200000000006)
('yuv.max=', 210.92399999999998, 'yuv.min=', -50.829510000000013)
('yuv.max=', 255.0, 'yuv.min=', -88.297919999999991)
('yuv.max=', 252.08199999999999, 'yuv.min=', -34.800990000000006)
('yuv.max=', 229.62700000000001, 'yuv.min=', -40.760140000000007)
('yuv.max=', 249.04199999999997, 'yuv.min=', -27.530169999999998)
('yuv.max=', 235.37699999999998, 'yuv.min=', -39.395679999999999)
('yuv.max=', 241.82500000000002, 'yuv.min=', -19.688890000000008)
('yuv.max=', 253.376, 'yuv.min=', -67.152360000000016)
('yuv.max=', 255.0, 'yuv.min=', -49.463680000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -52.584370000000007)
('yuv.max=', 250.77100000000002, 'yuv.min=', -99.635799999999989)
('yuv.max=', 246.0, 'yuv.min=', -22.25494999999999)
('yuv.max=', 252.28800000000001, 'yuv.min=', -47.465379999999996)
('yuv.max=', 164.886, 'yuv.min=', -51.270329999999987)
('yuv.max=', 255.0, 'yuv.min=', -7.9988000000000028)
('yuv.max=', 249.15299999999999, 'yuv.min=', -3.9335100000000054)
('yuv.max=', 234.72299999999998, 'yuv.min=', -51.625550000000004)
('yuv.max=', 255.0, 'yuv.min=', -12.155169999999989)
('yuv.max=', 223.81799999999998, 'yuv.min=', -25.726330000000004)
('yuv.max=', 241.25299999999996, 'yuv.min=', -34.175650000000005)
('yuv.max=', 181.67099999999999, 'yuv.min=', -7.2501100000000065)
('yuv.max=', 243.12899999999999, 'yuv.min=', -34.635449999999992)
('yuv.max=', 212.23899999999998, 'yuv.min=', -31.260419999999993)
('yuv.max=', 224.39099999999999, 'yuv.min=', -38.710549999999998)
('yuv.max=', 214.053, 'yuv.min=', -33.250249999999994)
('yuv.max=', 249.16899999999995, 'yuv.min=', -38.473530000000004)
('yuv.max=', 229.25799999999998, 'yuv.min=', -45.820980000000006)
('yuv.max=', 251.09199999999998, 'yuv.min=', -57.68965)
('yuv.max=', 228.12599999999998, 'yuv.min=', -30.893830000000005)
('yuv.max=', 204.56599999999997, 'yuv.min=', -22.795249999999996)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 165.292, 'yuv.min=', -17.775239999999997)
('yuv.max=', 232.67399999999998, 'yuv.min=', -68.860489999999984)
('yuv.max=', 229.34799999999996, 'yuv.min=', -28.330249999999996)
('yuv.max=', 252.09200000000001, 'yuv.min=', -46.780249999999995)
('yuv.max=', 255.0, 'yuv.min=', -45.980169999999987)
('yuv.max=', 246.77699999999999, 'yuv.min=', -51.010549999999995)
('yuv.max=', 224.148, 'yuv.min=', -11.955149999999996)
('yuv.max=', 237.57399999999998, 'yuv.min=', -25.135729999999995)
('yuv.max=', 192.06399999999999, 'yuv.min=', -40.315280000000001)
('yuv.max=', 254.07099999999997, 'yuv.min=', -26.755399999999987)
('yuv.max=', 216.387, 'yuv.min=', -27.860079999999993)
('yuv.max=', 252.04499999999999, 'yuv.min=', -35.450469999999996)
('yuv.max=', 198.91499999999996, 'yuv.min=', -34.627499999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', -66.460250000000002)
('yuv.max=', 255.0, 'yuv.min=', -11.335579999999993)
('yuv.max=', 241.34199999999998, 'yuv.min=', -8.8801499999999987)
('yuv.max=', 199.077, 'yuv.min=', -61.369249999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.068370000000009)
('yuv.max=', 170.994, 'yuv.min=', -33.020349999999993)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 234.036, 'yuv.min=', -29.119959999999999)
('yuv.max=', 255.0, 'yuv.min=', -31.401590000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', -63.859989999999996)
('yuv.max=', 236.14799999999997, 'yuv.min=', -29.630379999999995)
('yuv.max=', 203.52199999999999, 'yuv.min=', -31.415619999999997)
('yuv.max=', 188.959, 'yuv.min=', -23.76493)
('yuv.max=', 216.82599999999999, 'yuv.min=', -51.844860000000004)
('yuv.max=', 252.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 238.21699999999998, 'yuv.min=', -37.585129999999999)
('yuv.max=', 170.69800000000001, 'yuv.min=', -18.32011)
('yuv.max=', 183.34199999999998, 'yuv.min=', -29.000439999999998)
('yuv.max=', 207.16300000000001, 'yuv.min=', -14.478659999999998)
('yuv.max=', 236.316, 'yuv.min=', -9.4100799999999971)
('yuv.max=', 207.61899999999997, 'yuv.min=', -33.320379999999993)
('yuv.max=', 239.19399999999999, 'yuv.min=', -21.380169999999993)
('yuv.max=', 254.65800000000002, 'yuv.min=', -24.757109999999997)
('yuv.max=', 245.81299999999999, 'yuv.min=', -22.828569999999999)
('yuv.max=', 255.0, 'yuv.min=', -36.685039999999972)
('yuv.max=', 231.923, 'yuv.min=', -29.13032999999999)
('yuv.max=', 251.184, 'yuv.min=', -37.970229999999987)
('yuv.max=', 252.73500000000001, 'yuv.min=', -90.966039999999978)
('yuv.max=', 220.91799999999998, 'yuv.min=', -19.867100000000001)
('yuv.max=', 242.821, 'yuv.min=', -32.535520000000005)
('yuv.max=', 246.10699999999997, 'yuv.min=', -37.070139999999995)
('yuv.max=', 231.46299999999997, 'yuv.min=', -47.840109999999996)
('yuv.max=', 206.09299999999999, 'yuv.min=', -38.529660000000007)
('yuv.max=', 222.99999999999997, 'yuv.min=', -18.12008999999999)
('yuv.max=', 255.0, 'yuv.min=', -18.200749999999999)
('yuv.max=', 228.91800000000001, 'yuv.min=', -17.615469999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.707009999999997)
('yuv.max=', 205.32900000000001, 'yuv.min=', -73.580469999999991)
('yuv.max=', 232.69300000000001, 'yuv.min=', -40.610739999999986)
('yuv.max=', 162.441, 'yuv.min=', -35.85051)
('yuv.max=', 255.0, 'yuv.min=', -27.940579999999994)
('yuv.max=', 217.53300000000002, 'yuv.min=', -39.610639999999997)
('yuv.max=', 222.624, 'yuv.min=', -76.855489999999989)
('yuv.max=', 255.0, 'yuv.min=', -19.629650000000002)
('yuv.max=', 242.75500000000002, 'yuv.min=', -19.490349999999992)
('yuv.max=', 253.52699999999999, 'yuv.min=', -14.270319999999991)
('yuv.max=', 254.77200000000002, 'yuv.min=', -15.875049999999996)
('yuv.max=', 238.12900000000002, 'yuv.min=', -44.570889999999991)
('yuv.max=', 255.0, 'yuv.min=', -39.125529999999998)
('yuv.max=', 248.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -21.090510000000002)
('yuv.max=', 222.19200000000001, 'yuv.min=', -29.945349999999991)
('yuv.max=', 242.0, 'yuv.min=', -45.965229999999991)
('yuv.max=', 245.05199999999996, 'yuv.min=', -39.94054999999998)
('yuv.max=', 253.15899999999996, 'yuv.min=', -17.497840000000004)
('yuv.max=', 255.0, 'yuv.min=', -6.0603599999999851)
('yuv.max=', 222.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 242.185, 'yuv.min=', -15.24510999999999)
('yuv.max=', 229.80199999999999, 'yuv.min=', -36.594410000000011)
('yuv.max=', 224.06799999999998, 'yuv.min=', -30.869519999999994)
('yuv.max=', 204.40099999999998, 'yuv.min=', -19.260449999999999)
('yuv.max=', 224.16199999999998, 'yuv.min=', -45.624949999999991)
('yuv.max=', 240.64099999999999, 'yuv.min=', -37.810459999999999)
('yuv.max=', 230.77199999999999, 'yuv.min=', -2.2450399999999995)
('yuv.max=', 123.81199999999998, 'yuv.min=', -3.6750599999999989)
('yuv.max=', 236.566, 'yuv.min=', -17.620039999999999)
('yuv.max=', 213.80399999999997, 'yuv.min=', -36.810359999999989)
('yuv.max=', 180.21899999999999, 'yuv.min=', -42.125829999999993)
('yuv.max=', 243.33099999999999, 'yuv.min=', -47.550449999999984)
('yuv.max=', 224.10999999999999, 'yuv.min=', -21.421880000000002)
('yuv.max=', 250.56599999999997, 'yuv.min=', -13.507780000000004)
('yuv.max=', 250.99999999999997, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 188.75299999999999, 'yuv.min=', -41.160179999999983)
('yuv.max=', 209.21900000000002, 'yuv.min=', -89.268520000000009)
('yuv.max=', 239.93999999999997, 'yuv.min=', -0.72408999999999679)
('yuv.max=', 153.11499999999998, 'yuv.min=', -18.805219999999988)
('yuv.max=', 224.102, 'yuv.min=', -30.600599999999996)
('yuv.max=', 241.17699999999996, 'yuv.min=', -33.248109999999997)
('yuv.max=', 226.12599999999998, 'yuv.min=', -24.021619999999999)
('yuv.max=', 247.86400000000003, 'yuv.min=', -55.900669999999998)
('yuv.max=', 232.47999999999996, 'yuv.min=', -63.355369999999994)
('yuv.max=', 208.285, 'yuv.min=', -42.945419999999991)
('yuv.max=', 251.37799999999999, 'yuv.min=', -29.258660000000006)
('yuv.max=', 223.54400000000001, 'yuv.min=', -5.0773899999999941)
('yuv.max=', 255.0, 'yuv.min=', -36.900739999999999)
('yuv.max=', 249.65099999999995, 'yuv.min=', -27.193539999999999)
('yuv.max=', 196.08699999999999, 'yuv.min=', -43.600669999999994)
('yuv.max=', 196.12299999999999, 'yuv.min=', -10.605629999999991)
('yuv.max=', 210.00199999999998, 'yuv.min=', -40.369239999999991)
('yuv.max=', 255.0, 'yuv.min=', -26.888730000000002)
('yuv.max=', 197.90800000000002, 'yuv.min=', -67.369979999999998)
('yuv.max=', 255.0, 'yuv.min=', -14.915199999999992)
('yuv.max=', 243.58699999999999, 'yuv.min=', -21.247330000000005)
('yuv.max=', 248.77199999999999, 'yuv.min=', -19.620239999999995)
('yuv.max=', 201.578, 'yuv.min=', -63.28273999999999)
('yuv.max=', 205.43599999999998, 'yuv.min=', -32.330649999999999)
('yuv.max=', 238.93099999999998, 'yuv.min=', -9.0175199999999904)
('yuv.max=', 202.21099999999998, 'yuv.min=', -22.33212)
('yuv.max=', 255.0, 'yuv.min=', -20.36056)
('yuv.max=', 234.32299999999998, 'yuv.min=', -32.880089999999988)
('yuv.max=', 238.89000000000001, 'yuv.min=', -18.860410000000002)
('yuv.max=', 254.06, 'yuv.min=', -86.250630000000001)
('yuv.max=', 250.47299999999998, 'yuv.min=', -56.427109999999999)
('yuv.max=', 244.28799999999998, 'yuv.min=', -9.1652399999999936)
('yuv.max=', 250.619, 'yuv.min=', -41.270559999999996)
('yuv.max=', 201.96100000000001, 'yuv.min=', -18.335049999999999)
('yuv.max=', 233.45599999999999, 'yuv.min=', -6.4350900000000095)
('yuv.max=', 255.0, 'yuv.min=', -18.352900000000002)
('yuv.max=', 193.87599999999998, 'yuv.min=', -12.946920000000002)
('yuv.max=', 200.98399999999998, 'yuv.min=', -24.525299999999984)
('yuv.max=', 226.08699999999999, 'yuv.min=', -37.416770000000007)
('yuv.max=', 248.10299999999998, 'yuv.min=', -37.701039999999992)
('yuv.max=', 252.65199999999999, 'yuv.min=', -14.887650000000001)
('yuv.max=', 246.77199999999999, 'yuv.min=', -22.338999999999995)
('yuv.max=', 235.26599999999999, 'yuv.min=', -49.56559)
('yuv.max=', 255.0, 'yuv.min=', -28.910130000000002)
('yuv.max=', 237.65100000000001, 'yuv.min=', -32.990469999999995)
('yuv.max=', 208.72800000000001, 'yuv.min=', -20.435259999999992)
('yuv.max=', 249.245, 'yuv.min=', -33.651740000000004)
('yuv.max=', 222.14599999999999, 'yuv.min=', -20.780109999999997)
('yuv.max=', 227.363, 'yuv.min=', -72.329419999999999)
('yuv.max=', 180.17099999999999, 'yuv.min=', -15.35549)
('yuv.max=', 248.798, 'yuv.min=', -32.820329999999991)
('yuv.max=', 199.47399999999999, 'yuv.min=', -50.39555)
('yuv.max=', 199.87900000000002, 'yuv.min=', -13.389159999999997)
('yuv.max=', 254.47300000000001, 'yuv.min=', -49.495459999999994)
('yuv.max=', 250.017, 'yuv.min=', -13.630009999999999)
('yuv.max=', 215.33099999999999, 'yuv.min=', -15.945179999999997)
('yuv.max=', 255.0, 'yuv.min=', -22.119530000000012)
('yuv.max=', 255.0, 'yuv.min=', -30.136980000000001)
('yuv.max=', 210.374, 'yuv.min=', -32.441200000000002)
('yuv.max=', 204.80399999999997, 'yuv.min=', -22.965389999999982)
('yuv.max=', 237.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 254.316, 'yuv.min=', -17.738499999999995)
('yuv.max=', 228.56699999999998, 'yuv.min=', -18.975359999999984)
('yuv.max=', 245.24800000000002, 'yuv.min=', -55.11553)
('yuv.max=', 248.809, 'yuv.min=', -43.65585999999999)
('yuv.max=', 255.0, 'yuv.min=', -27.700309999999995)
('yuv.max=', 210.56799999999998, 'yuv.min=', -30.94544999999999)
('yuv.max=', 199.73499999999999, 'yuv.min=', -15.70613)
('yuv.max=', 211.81900000000002, 'yuv.min=', -20.905429999999988)
('yuv.max=', 195.12900000000002, 'yuv.min=', -38.23124)
('yuv.max=', 224.73499999999999, 'yuv.min=', -32.735259999999997)
('yuv.max=', 250.66399999999999, 'yuv.min=', -92.730539999999991)
('yuv.max=', 254.47300000000001, 'yuv.min=', -27.788030000000003)
('yuv.max=', 247.51599999999999, 'yuv.min=', -30.475280000000001)
('yuv.max=', 174.78899999999999, 'yuv.min=', -9.3100699999999978)
('yuv.max=', 255.0, 'yuv.min=', -42.164810000000003)
('yuv.max=', 183.82599999999999, 'yuv.min=', -14.500219999999997)
('yuv.max=', 255.0, 'yuv.min=', -31.420189999999991)
('yuv.max=', 238.99999999999997, 'yuv.min=', -11.922590000000001)
('yuv.max=', 241.91899999999998, 'yuv.min=', -33.620409999999993)
('yuv.max=', 255.0, 'yuv.min=', -54.160190000000007)
('yuv.max=', 198.84999999999999, 'yuv.min=', -39.895729999999993)
('yuv.max=', 255.0, 'yuv.min=', -28.249749999999981)
('yuv.max=', 255.0, 'yuv.min=', -64.723169999999996)
('yuv.max=', 247.68000000000001, 'yuv.min=', -40.745199999999983)
('yuv.max=', 241.405, 'yuv.min=', -58.715889999999987)
('yuv.max=', 254.886, 'yuv.min=', -37.935400000000001)
('yuv.max=', 248.047, 'yuv.min=', -81.332899999999995)
('yuv.max=', 197.41399999999999, 'yuv.min=', -63.225480000000005)
('yuv.max=', 228.41299999999998, 'yuv.min=', -32.960589999999996)
('yuv.max=', 255.0, 'yuv.min=', -24.210329999999992)
('yuv.max=', 255.0, 'yuv.min=', -14.500219999999992)
('yuv.max=', 249.61799999999999, 'yuv.min=', -33.91006999999999)
('yuv.max=', 131.035, 'yuv.min=', -29.815460000000002)
('yuv.max=', 221.49899999999997, 'yuv.min=', -39.94006000000001)
('yuv.max=', 175.83199999999999, 'yuv.min=', -15.279870000000003)
('yuv.max=', 252.51599999999999, 'yuv.min=', -40.070439999999998)
('yuv.max=', 240.73399999999998, 'yuv.min=', -24.162760000000006)
('yuv.max=', 206.517, 'yuv.min=', -30.630479999999991)
('yuv.max=', 244.75199999999998, 'yuv.min=', -39.308130000000006)
('yuv.max=', 234.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 253.82599999999996, 'yuv.min=', -72.474559999999983)
('yuv.max=', 253.20599999999999, 'yuv.min=', -30.224890000000002)
('yuv.max=', 255.0, 'yuv.min=', -18.315770000000001)
('yuv.max=', 204.21899999999999, 'yuv.min=', -31.260420000000003)
('yuv.max=', 252.886, 'yuv.min=', -15.015209999999989)
('yuv.max=', 253.82599999999996, 'yuv.min=', -50.595569999999995)
('yuv.max=', 217.97899999999998, 'yuv.min=', -33.220369999999988)
('yuv.max=', 237.64400000000001, 'yuv.min=', -54.600539999999995)
('yuv.max=', 238.73299999999998, 'yuv.min=', -18.190219999999997)
('yuv.max=', 236.68999999999997, 'yuv.min=', -25.329799999999999)
('yuv.max=', 254.18499999999997, 'yuv.min=', -19.03603)
('yuv.max=', 246.78700000000001, 'yuv.min=', -29.470609999999997)
('yuv.max=', 254.06, 'yuv.min=', -78.310819999999993)
('yuv.max=', 246.36999999999998, 'yuv.min=', -30.130429999999997)
('yuv.max=', 245.76499999999999, 'yuv.min=', -32.290399999999984)
('yuv.max=', 232.64499999999998, 'yuv.min=', -33.990600000000001)
('yuv.max=', 249.15700000000001, 'yuv.min=', -33.790549999999996)
('yuv.max=', 246.02799999999996, 'yuv.min=', -35.544679999999993)
('yuv.max=', 251.70099999999996, 'yuv.min=', -26.91575000000001)
('yuv.max=', 255.0, 'yuv.min=', -4.9200000000000017)
('yuv.max=', 247.68999999999997, 'yuv.min=', -34.090579999999996)
('yuv.max=', 232.67199999999997, 'yuv.min=', -45.385909999999988)
('yuv.max=', 224.61000000000001, 'yuv.min=', -31.560450000000003)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 252.61899999999997, 'yuv.min=', -22.495219999999996)
('yuv.max=', 234.91, 'yuv.min=', -20.165109999999991)
('yuv.max=', 255.0, 'yuv.min=', -16.690069999999992)
('yuv.max=', 242.85299999999998, 'yuv.min=', -11.329499999999996)
('yuv.max=', 239.929, 'yuv.min=', -13.844969999999988)
('yuv.max=', 217.01499999999999, 'yuv.min=', -30.320079999999994)
('yuv.max=', 205.12100000000001, 'yuv.min=', -40.655559999999994)
('yuv.max=', 222.61499999999998, 'yuv.min=', -21.750329999999991)
('yuv.max=', 241.55199999999996, 'yuv.min=', -51.031010000000002)
('yuv.max=', 202.63399999999999, 'yuv.min=', -11.255079999999989)
('yuv.max=', 249.21599999999998, 'yuv.min=', -60.23809)
('yuv.max=', 227.11799999999999, 'yuv.min=', -48.333080000000017)
('yuv.max=', 252.22799999999998, 'yuv.min=', -18.85643)
('yuv.max=', 236.01599999999999, 'yuv.min=', -35.720619999999997)
('yuv.max=', 158.18000000000001, 'yuv.min=', -14.885320000000004)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 184.494, 'yuv.min=', -13.814609999999995)
('yuv.max=', 224.90799999999999, 'yuv.min=', -13.540370000000003)
('yuv.max=', 194.99999999999997, 'yuv.min=', -12.155170000000002)
('yuv.max=', 227.52699999999999, 'yuv.min=', -43.532090000000004)
('yuv.max=', 252.01899999999995, 'yuv.min=', -53.070509999999985)
('yuv.max=', 162.054, 'yuv.min=', -21.930839999999986)
('yuv.max=', 255.0, 'yuv.min=', -90.540689999999984)
('yuv.max=', 254.70099999999999, 'yuv.min=', -17.875250000000001)
('yuv.max=', 245.298, 'yuv.min=', -68.70071999999999)
('yuv.max=', 232.35899999999998, 'yuv.min=', -83.986760000000004)
('yuv.max=', 195.59899999999999, 'yuv.min=', -51.962910000000001)
('yuv.max=', 180.13599999999997, 'yuv.min=', -23.42518999999999)
('yuv.max=', 252.03199999999998, 'yuv.min=', -22.740059999999993)
('yuv.max=', 249.62099999999998, 'yuv.min=', -31.630579999999998)
('yuv.max=', 234.59800000000001, 'yuv.min=', -42.486090000000004)
('yuv.max=', 255.0, 'yuv.min=', -28.478060000000006)
('yuv.max=', 236.22199999999998, 'yuv.min=', -30.355759999999997)
('yuv.max=', 230.024, 'yuv.min=', -19.635530000000003)
('yuv.max=', 255.0, 'yuv.min=', -63.691079999999992)
('yuv.max=', 221.22799999999998, 'yuv.min=', -19.020179999999996)
('yuv.max=', 222.19099999999997, 'yuv.min=', -90.490069999999989)
('yuv.max=', 221.58799999999999, 'yuv.min=', -27.885390000000001)
('yuv.max=', 238.815, 'yuv.min=', -29.030319999999993)
('yuv.max=', 244.40199999999999, 'yuv.min=', -29.07513999999999)
('yuv.max=', 235.90399999999997, 'yuv.min=', -42.815529999999995)
('yuv.max=', 238.21100000000001, 'yuv.min=', -28.148730000000008)
('yuv.max=', 255.0, 'yuv.min=', -48.180859999999996)
('yuv.max=', 237.20299999999997, 'yuv.min=', -62.088510000000007)
('yuv.max=', 227.79900000000001, 'yuv.min=', -44.802329999999998)
('yuv.max=', 160.554, 'yuv.min=', -23.825229999999998)
('yuv.max=', 195.98399999999998, 'yuv.min=', -19.178000000000004)
('yuv.max=', 247.02799999999999, 'yuv.min=', -35.1355)
('yuv.max=', 236.327, 'yuv.min=', -38.262810000000002)
('yuv.max=', 233.97200000000001, 'yuv.min=', -17.305070000000004)
('yuv.max=', 243.62599999999998, 'yuv.min=', -59.87576)
('yuv.max=', 202.66799999999998, 'yuv.min=', -15.732389999999995)
('yuv.max=', 220.28800000000001, 'yuv.min=', -25.840369999999986)
('yuv.max=', 246.40199999999999, 'yuv.min=', -34.505559999999996)
('yuv.max=', 228.58699999999999, 'yuv.min=', -44.582839999999997)
('yuv.max=', 255.0, 'yuv.min=', -40.731529999999992)
('yuv.max=', 242.67299999999997, 'yuv.min=', -20.945679999999996)
('yuv.max=', 239.71399999999997, 'yuv.min=', -28.285429999999991)
('yuv.max=', 204.26399999999998, 'yuv.min=', -57.235249999999994)
('yuv.max=', 239.24099999999996, 'yuv.min=', -21.252860000000005)
('yuv.max=', 255.0, 'yuv.min=', -7.1054273576010019e-15)
('yuv.max=', 255.0, 'yuv.min=', -20.47551)
('yuv.max=', 229.76400000000001, 'yuv.min=', -32.385839999999995)
('yuv.max=', 255.0, 'yuv.min=', -36.850609999999996)
('yuv.max=', 217.33699999999999, 'yuv.min=', -21.568870000000004)
('yuv.max=', 214.49199999999996, 'yuv.min=', -29.500489999999996)
('yuv.max=', 234.62300000000002, 'yuv.min=', -54.481019999999987)
('yuv.max=', 254.43000000000001, 'yuv.min=', -21.389190000000006)
('yuv.max=', 228.185, 'yuv.min=', -16.36015999999999)
('yuv.max=', 225.26000000000002, 'yuv.min=', -33.890559999999994)
('yuv.max=', 255.0, 'yuv.min=', -38.976789999999994)
('yuv.max=', 191.38900000000001, 'yuv.min=', -17.89018999999999)
('yuv.max=', 254.316, 'yuv.min=', -15.885419999999996)
('yuv.max=', 247.75500000000002, 'yuv.min=', -46.835439999999991)
('yuv.max=', 171.44899999999998, 'yuv.min=', -38.070239999999998)
('yuv.max=', 189.35499999999999, 'yuv.min=', -21.19508999999999)
('yuv.max=', 215.892, 'yuv.min=', -45.865220000000001)
('yuv.max=', 233.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 224.74199999999999, 'yuv.min=', -38.050730000000001)
('yuv.max=', 217.64600000000002, 'yuv.min=', -19.605300000000003)
('yuv.max=', 248.99999999999997, 'yuv.min=', -7.1501000000000001)
('yuv.max=', 205.12900000000002, 'yuv.min=', -15.800349999999991)
('yuv.max=', 240.07499999999999, 'yuv.min=', -45.215769999999992)
('yuv.max=', 213.44799999999998, 'yuv.min=', -19.80341)
('yuv.max=', 238.45799999999997, 'yuv.min=', -35.920639999999992)
('yuv.max=', 255.0, 'yuv.min=', -20.850239999999996)
('yuv.max=', 186.886, 'yuv.min=', -14.696860000000001)
('yuv.max=', 210.339, 'yuv.min=', -24.525299999999994)
('yuv.max=', 176.46799999999999, 'yuv.min=', -46.960759999999986)
('yuv.max=', 251.804, 'yuv.min=', -34.131769999999996)
('yuv.max=', 209.84499999999997, 'yuv.min=', -14.800249999999998)
('yuv.max=', 241.75399999999999, 'yuv.min=', -30.575289999999981)
('yuv.max=', 254.131, 'yuv.min=', -81.621639999999999)
('yuv.max=', 255.0, 'yuv.min=', -10.955049999999989)
('yuv.max=', 250.55500000000001, 'yuv.min=', -69.575499999999991)
('yuv.max=', 255.0, 'yuv.min=', -12.389639999999988)
('yuv.max=', 248.00999999999999, 'yuv.min=', -16.345219999999998)
('yuv.max=', 250.64699999999996, 'yuv.min=', -32.675499999999992)
('yuv.max=', 248.733, 'yuv.min=', -24.940279999999994)
('yuv.max=', 237.0, 'yuv.min=', -13.470239999999993)
('yuv.max=', 168.07299999999998, 'yuv.min=', -56.31277)
('yuv.max=', 255.0, 'yuv.min=', -67.930520000000001)
('yuv.max=', 255.0, 'yuv.min=', -66.445309999999978)
('yuv.max=', 239.495, 'yuv.min=', -44.425799999999995)
('yuv.max=', 206.15999999999997, 'yuv.min=', -23.259139999999995)
('yuv.max=', 228.32399999999998, 'yuv.min=', -30.490219999999983)
('yuv.max=', 208.72299999999998, 'yuv.min=', -46.805559999999993)
('yuv.max=', 205.31900000000002, 'yuv.min=', -26.025449999999985)
('yuv.max=', 255.0, 'yuv.min=', -27.749699999999983)
('yuv.max=', 255.0, 'yuv.min=', -33.17554999999998)
('yuv.max=', 235.98899999999998, 'yuv.min=', -18.690269999999998)
('yuv.max=', 255.0, 'yuv.min=', -13.988070000000008)
('yuv.max=', 250.43399999999997, 'yuv.min=', -33.960689999999992)
('yuv.max=', 227.81899999999999, 'yuv.min=', -18.905229999999992)
('yuv.max=', 255.0, 'yuv.min=', -19.094879999999989)
('yuv.max=', 183.06999999999999, 'yuv.min=', -35.125129999999999)
('yuv.max=', 198.893, 'yuv.min=', -30.830500000000001)
('yuv.max=', 227.02799999999999, 'yuv.min=', -22.796750000000003)
('yuv.max=', 215.38800000000001, 'yuv.min=', -21.780209999999997)
('yuv.max=', 250.02800000000002, 'yuv.min=', -14.0703)
('yuv.max=', 159.87900000000002, 'yuv.min=', -16.949849999999994)
('yuv.max=', 244.499, 'yuv.min=', -8.3651599999999959)
('yuv.max=', 248.34200000000001, 'yuv.min=', -30.000539999999987)
('yuv.max=', 237.131, 'yuv.min=', -31.145469999999996)
('yuv.max=', 239.03199999999998, 'yuv.min=', -64.585369999999983)
('yuv.max=', 219.893, 'yuv.min=', -52.750970000000002)
('yuv.max=', 251.60400000000001, 'yuv.min=', -27.70030999999998)
('yuv.max=', 166.42499999999998, 'yuv.min=', -31.209389999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', -47.650459999999995)
('yuv.max=', 252.54399999999998, 'yuv.min=', -29.00043999999999)
('yuv.max=', 206.0, 'yuv.min=', -3.5527136788005009e-15)
('yuv.max=', 254.40199999999999, 'yuv.min=', -29.245279999999998)
('yuv.max=', 214.166, 'yuv.min=', -48.595369999999988)
('yuv.max=', 254.886, 'yuv.min=', -18.364109999999997)
('yuv.max=', 236.40200000000002, 'yuv.min=', -8.4801100000000034)
('yuv.max=', 236.36699999999996, 'yuv.min=', -23.290729999999996)
('yuv.max=', 245.54399999999998, 'yuv.min=', -60.605709999999988)
('yuv.max=', 193.34899999999999, 'yuv.min=', -39.429099999999998)
('yuv.max=', 236.191, 'yuv.min=', -28.638370000000005)
('yuv.max=', 233.98500000000001, 'yuv.min=', -24.225269999999995)
('yuv.max=', 204.11499999999998, 'yuv.min=', -16.960219999999996)
('yuv.max=', 252.65199999999999, 'yuv.min=', -1.1150499999999992)
('yuv.max=', 245.29300000000001, 'yuv.min=', -11.644089999999998)
('yuv.max=', 204.786, 'yuv.min=', -65.359139999999996)
('yuv.max=', 207.94299999999998, 'yuv.min=', -22.165309999999998)
('yuv.max=', 255.0, 'yuv.min=', -12.140229999999985)
('yuv.max=', 230.17499999999998, 'yuv.min=', -38.159880000000001)
('yuv.max=', 150.44200000000001, 'yuv.min=', -21.845769999999995)
('yuv.max=', 255.0, 'yuv.min=', -11.41028)
('yuv.max=', 228.14599999999999, 'yuv.min=', -28.215299999999996)
('yuv.max=', 239.30499999999995, 'yuv.min=', -36.310309999999987)
('yuv.max=', 248.93599999999998, 'yuv.min=', -37.680569999999989)
('yuv.max=', 255.0, 'yuv.min=', -18.191449999999996)
('yuv.max=', 196.74099999999999, 'yuv.min=', -22.21876)
('yuv.max=', 239.79300000000001, 'yuv.min=', -24.395409999999998)
('yuv.max=', 170.26199999999997, 'yuv.min=', -15.660089999999984)
('yuv.max=', 248.48399999999998, 'yuv.min=', -53.032440000000008)
('yuv.max=', 251.12399999999997, 'yuv.min=', -27.418160000000004)
('yuv.max=', 242.62300000000002, 'yuv.min=', -26.840469999999996)
('yuv.max=', 255.0, 'yuv.min=', -20.632580000000001)
('yuv.max=', 229.08700000000002, 'yuv.min=', -57.220309999999991)
('yuv.max=', 215.161, 'yuv.min=', -21.296720000000004)
('yuv.max=', 252.91399999999999, 'yuv.min=', -27.515280000000008)
('yuv.max=', 207.803, 'yuv.min=', -30.460339999999992)
('yuv.max=', 253.16300000000001, 'yuv.min=', -79.645399999999995)
('yuv.max=', 102.501, 'yuv.min=', -55.625949999999989)
('yuv.max=', 242.56400000000002, 'yuv.min=', -38.305939999999993)
('yuv.max=', 195.38899999999998, 'yuv.min=', -43.570789999999995)
('yuv.max=', 255.0, 'yuv.min=', -2.3264499999999977)
('yuv.max=', 190.25200000000001, 'yuv.min=', -38.520899999999997)
('yuv.max=', 255.0, 'yuv.min=', -37.710449999999994)
('yuv.max=', 250.99999999999997, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 238.98299999999998, 'yuv.min=', -10.12509)
('yuv.max=', 166.12100000000001, 'yuv.min=', -35.984520000000003)
('yuv.max=', 209.81299999999999, 'yuv.min=', -30.200559999999996)
('yuv.max=', 249.03200000000001, 'yuv.min=', -86.195439999999991)
('yuv.max=', 254.10300000000001, 'yuv.min=', -9.0951099999999929)
('yuv.max=', 218.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 196.91199999999998, 'yuv.min=', -46.769480000000001)
('yuv.max=', 250.28999999999999, 'yuv.min=', -44.090350000000001)
('yuv.max=', 245.59999999999999, 'yuv.min=', -21.772079999999999)
('yuv.max=', 241.33700000000002, 'yuv.min=', -13.922060000000002)
('yuv.max=', 200.65100000000001, 'yuv.min=', -52.161279999999991)
('yuv.max=', 246.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 244.58700000000002, 'yuv.min=', -6.0350499999999965)
('yuv.max=', 247.89599999999999, 'yuv.min=', -22.696790000000007)
('yuv.max=', 202.28200000000001, 'yuv.min=', -48.985970000000009)
('yuv.max=', 238.50800000000001, 'yuv.min=', -56.726059999999997)
('yuv.max=', 237.79300000000001, 'yuv.min=', -30.230440000000002)
('yuv.max=', 190.26300000000001, 'yuv.min=', -31.405249999999995)
('yuv.max=', 225.101, 'yuv.min=', -24.462960000000002)
('yuv.max=', 223.25599999999997, 'yuv.min=', -55.450009999999992)
('yuv.max=', 234.08499999999998, 'yuv.min=', -30.275259999999992)
('yuv.max=', 230.928, 'yuv.min=', -82.360610000000008)
('yuv.max=', 236.39299999999997, 'yuv.min=', -19.634180000000001)
('yuv.max=', 239.45599999999996, 'yuv.min=', -29.794030000000003)
('yuv.max=', 246.858, 'yuv.min=', -7.1063700000000019)
('yuv.max=', 246.02799999999996, 'yuv.min=', -83.158919999999995)
('yuv.max=', 251.42299999999997, 'yuv.min=', -39.540509999999998)
('yuv.max=', 254.08800000000002, 'yuv.min=', -21.8354)
('yuv.max=', 240.0, 'yuv.min=', -5.3290705182007514e-15)
('yuv.max=', 255.0, 'yuv.min=', -63.212269999999997)
('yuv.max=', 252.40799999999999, 'yuv.min=', -53.270529999999994)
('yuv.max=', 248.59399999999999, 'yuv.min=', -48.210269999999994)
('yuv.max=', 255.0, 'yuv.min=', -35.61023999999999)
('yuv.max=', 250.23399999999998, 'yuv.min=', -36.510329999999989)
('yuv.max=', 218.554, 'yuv.min=', -43.569760000000002)
('yuv.max=', 249.815, 'yuv.min=', -62.180559999999993)
('yuv.max=', 246.91199999999998, 'yuv.min=', -46.725059999999992)
('yuv.max=', 244.84899999999999, 'yuv.min=', -14.159939999999985)
('yuv.max=', 241.35299999999998, 'yuv.min=', -59.665369999999996)
('yuv.max=', 234.35099999999997, 'yuv.min=', -44.535209999999999)
('yuv.max=', 255.0, 'yuv.min=', -24.365529999999993)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
890', 'for batch', 6)
('GAN loss 0.8693 ', 'GAN acc 0.1953', 'Discriminator loss 0.3475', 'Discriminator accuracy 0.8438', 'Total loss: 1.2168', 'for batch', 7)
('GAN loss 0.8418 ', 'GAN acc 0.2383', 'Discriminator loss 0.3723', 'Discriminator accuracy 0.8691', 'Total loss: 1.2141', 'for batch', 8)
('GAN loss 0.8825 ', 'GAN acc 0.2188', 'Discriminator loss 0.3459', 'Discriminator accuracy 0.8613', 'Total loss: 1.2284', 'for batch', 9)
('GAN loss 0.9040 ', 'GAN acc 0.1953', 'Discriminator loss 0.3091', 'Discriminator accuracy 0.8867', 'Total loss: 1.2131', 'for batch', 10)
('GAN loss 0.8507 ', 'GAN acc 0.2461', 'Discriminator loss 0.3498', 'Discriminator accuracy 0.8789', 'Total loss: 1.2005', 'for batch', 11)
('GAN loss 0.8719 ', 'GAN acc 0.1992', 'Discriminator loss 0.3172', 'Discriminator accuracy 0.8770', 'Total loss: 1.1891', 'for batch', 12)
('GAN loss 0.9089 ', 'GAN acc 0.1445', 'Discriminator loss 0.2990', 'Discriminator accuracy 0.8848', 'Total loss: 1.2078', 'for batch', 13)
('GAN loss 0.9464 ', 'GAN acc 0.1289', 'Discriminator loss 0.2818', 'Discriminator accuracy 0.9258', 'Total loss: 1.2283', 'for batch', 14)
('GAN loss 0.9710 ', 'GAN acc 0.0977', 'Discriminator loss 0.3859', 'Discriminator accuracy 0.9316', 'Total loss: 1.3570', 'for batch', 15)
('GAN loss 0.9764 ', 'GAN acc 0.0664', 'Discriminator loss 0.3806', 'Discriminator accuracy 0.9355', 'Total loss: 1.3571', 'for batch', 16)
('GAN loss 0.9513 ', 'GAN acc 0.1172', 'Discriminator loss 0.3155', 'Discriminator accuracy 0.9375', 'Total loss: 1.2667', 'for batch', 17)
('GAN loss 0.9398 ', 'GAN acc 0.1602', 'Discriminator loss 0.3041', 'Discriminator accuracy 0.9219', 'Total loss: 1.2439', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.97932351)
('DISCRIMINATOR_Imagem FAKE=', 0.37052125)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.950836')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8796 ', 'GAN acc 0.2148', 'Discriminator loss 0.3589', 'Discriminator accuracy 0.9023', 'Total loss: 1.2385', 'for batch', 0)
('GAN loss 0.8501 ', 'GAN acc 0.2344', 'Discriminator loss 0.3204', 'Discriminator accuracy 0.8809', 'Total loss: 1.1705', 'for batch', 1)
('GAN loss 0.9036 ', 'GAN acc 0.1445', 'Discriminator loss 0.3242', 'Discriminator accuracy 0.8477', 'Total loss: 1.2278', 'for batch', 2)
('GAN loss 0.8923 ', 'GAN acc 0.1602', 'Discriminator loss 0.3463', 'Discriminator accuracy 0.8750', 'Total loss: 1.2386', 'for batch', 3)
('GAN loss 0.9766 ', 'GAN acc 0.0938', 'Discriminator loss 0.2743', 'Discriminator accuracy 0.9297', 'Total loss: 1.2508', 'for batch', 4)
('GAN loss 1.0315 ', 'GAN acc 0.0469', 'Discriminator loss 0.2990', 'Discriminator accuracy 0.9316', 'Total loss: 1.3306', 'for batch', 5)
('GAN loss 1.0455 ', 'GAN acc 0.0430', 'Discriminator loss 0.3165', 'Discriminator accuracy 0.9551', 'Total loss: 1.3621', 'for batch', 6)
('GAN loss 1.0627 ', 'GAN acc 0.0391', 'Discriminator loss 0.2926', 'Discriminator accuracy 0.9648', 'Total loss: 1.3553', 'for batch', 7)
('GAN loss 1.0311 ', 'GAN acc 0.0312', 'Discriminator loss 0.2849', 'Discriminator accuracy 0.9531', 'Total loss: 1.3160', 'for batch', 8)
('GAN loss 0.9824 ', 'GAN acc 0.0586', 'Discriminator loss 0.2774', 'Discriminator accuracy 0.9531', 'Total loss: 1.2598', 'for batch', 9)
('GAN loss 1.0308 ', 'GAN acc 0.0195', 'Discriminator loss 0.2524', 'Discriminator accuracy 0.9688', 'Total loss: 1.2832', 'for batch', 10)
('GAN loss 1.0046 ', 'GAN acc 0.0547', 'Discriminator loss 0.2825', 'Discriminator accuracy 0.9609', 'Total loss: 1.2871', 'for batch', 11)
('GAN loss 1.0110 ', 'GAN acc 0.0391', 'Discriminator loss 0.2464', 'Discriminator accuracy 0.9707', 'Total loss: 1.2574', 'for batch', 12)
('GAN loss 1.0869 ', 'GAN acc 0.0430', 'Discriminator loss 0.2373', 'Discriminator accuracy 0.9824', 'Total loss: 1.3242', 'for batch', 13)
('GAN loss 1.1132 ', 'GAN acc 0.0117', 'Discriminator loss 0.2226', 'Discriminator accuracy 0.9824', 'Total loss: 1.3359', 'for batch', 14)
('GAN loss 1.1013 ', 'GAN acc 0.0195', 'Discriminator loss 0.3061', 'Discriminator accuracy 0.9785', 'Total loss: 1.4074', 'for batch', 15)
('GAN loss 1.0735 ', 'GAN acc 0.0234', 'Discriminator loss 0.2395', 'Discriminator accuracy 0.9668', 'Total loss: 1.3130', 'for batch', 16)
('GAN loss 1.1062 ', 'GAN acc 0.0000', 'Discriminator loss 0.2678', 'Discriminator accuracy 0.9785', 'Total loss: 1.3740', 'for batch', 17)
('GAN loss 1.1368 ', 'GAN acc 0.0156', 'Discriminator loss 0.2252', 'Discriminator accuracy 0.9824', 'Total loss: 1.3621', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9822284)
('DISCRIMINATOR_Imagem FAKE=', 0.30689204)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.327657')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1536 ', 'GAN acc 0.0195', 'Discriminator loss 0.2417', 'Discriminator accuracy 0.9746', 'Total loss: 1.3952', 'for batch', 0)
('GAN loss 1.0731 ', 'GAN acc 0.0430', 'Discriminator loss 0.3059', 'Discriminator accuracy 0.9492', 'Total loss: 1.3791', 'for batch', 1)
('GAN loss 1.0259 ', 'GAN acc 0.0625', 'Discriminator loss 0.2925', 'Discriminator accuracy 0.9531', 'Total loss: 1.3184', 'for batch', 2)
('GAN loss 1.0512 ', 'GAN acc 0.0664', 'Discriminator loss 0.2606', 'Discriminator accuracy 0.9551', 'Total loss: 1.3118', 'for batch', 3)
('GAN loss 1.1217 ', 'GAN acc 0.0195', 'Discriminator loss 0.2428', 'Discriminator accuracy 0.9648', 'Total loss: 1.3644', 'for batch', 4)
('GAN loss 1.1962 ', 'GAN acc 0.0234', 'Discriminator loss 0.2542', 'Discriminator accuracy 0.9688', 'Total loss: 1.4505', 'for batch', 5)
('GAN loss 1.1964 ', 'GAN acc 0.0195', 'Discriminator loss 0.2173', 'Discriminator accuracy 0.9844', 'Total loss: 1.4137', 'for batch', 6)
('GAN loss 1.2660 ', 'GAN acc 0.0078', 'Discriminator loss 0.2832', 'Discriminator accuracy 0.9805', 'Total loss: 1.5492', 'for batch', 7)
('GAN loss 1.2875 ', 'GAN acc 0.0078', 'Discriminator loss 0.2576', 'Discriminator accuracy 0.9863', 'Total loss: 1.5451', 'for batch', 8)
('GAN loss 1.2085 ', 'GAN acc 0.0078', 'Discriminator loss 0.2636', 'Discriminator accuracy 0.9805', 'Total loss: 1.4721', 'for batch', 9)
('GAN loss 1.2056 ', 'GAN acc 0.0117', 'Discriminator loss 0.2386', 'Discriminator accuracy 0.9922', 'Total loss: 1.4443', 'for batch', 10)
('GAN loss 1.2079 ', 'GAN acc 0.0195', 'Discriminator loss 0.2216', 'Discriminator accuracy 0.9805', 'Total loss: 1.4295', 'for batch', 11)
('GAN loss 1.2725 ', 'GAN acc 0.0078', 'Discriminator loss 0.2053', 'Discriminator accuracy 0.9785', 'Total loss: 1.4778', 'for batch', 12)
('GAN loss 1.3764 ', 'GAN acc 0.0156', 'Discriminator loss 0.1937', 'Discriminator accuracy 0.9824', 'Total loss: 1.5701', 'for batch', 13)
('GAN loss 1.4185 ', 'GAN acc 0.0078', 'Discriminator loss 0.1871', 'Discriminator accuracy 0.9902', 'Total loss: 1.6056', 'for batch', 14)
('GAN loss 1.4167 ', 'GAN acc 0.0039', 'Discriminator loss 0.2132', 'Discriminator accuracy 0.9805', 'Total loss: 1.6299', 'for batch', 15)
('GAN loss 1.3425 ', 'GAN acc 0.0039', 'Discriminator loss 0.2151', 'Discriminator accuracy 0.9844', 'Total loss: 1.5576', 'for batch', 16)
('GAN loss 1.1905 ', 'GAN acc 0.0156', 'Discriminator loss 0.3034', 'Discriminator accuracy 0.9727', 'Total loss: 1.4939', 'for batch', 17)
('GAN loss 1.1616 ', 'GAN acc 0.0273', 'Discriminator loss 0.2520', 'Discriminator accuracy 0.9785', 'Total loss: 1.4136', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98755175)
('DISCRIMINATOR_Imagem FAKE=', 0.31969208)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.781340')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1782 ', 'GAN acc 0.0586', 'Discriminator loss 0.2516', 'Discriminator accuracy 0.9590', 'Total loss: 1.4299', 'for batch', 0)
('GAN loss 1.2415 ', 'GAN acc 0.0273', 'Discriminator loss 0.2273', 'Discriminator accuracy 0.9648', 'Total loss: 1.4688', 'for batch', 1)
('GAN loss 1.3399 ', 'GAN acc 0.0039', 'Discriminator loss 0.2292', 'Discriminator accuracy 0.9648', 'Total loss: 1.5691', 'for batch', 2)
('GAN loss 1.4146 ', 'GAN acc 0.0117', 'Discriminator loss 0.1910', 'Discriminator accuracy 0.9844', 'Total loss: 1.6055', 'for batch', 3)
('GAN loss 1.5456 ', 'GAN acc 0.0039', 'Discriminator loss 0.2221', 'Discriminator accuracy 0.9844', 'Total loss: 1.7677', 'for batch', 4)
('GAN loss 1.5077 ', 'GAN acc 0.0039', 'Discriminator loss 0.2525', 'Discriminator accuracy 0.9805', 'Total loss: 1.7602', 'for batch', 5)
('GAN loss 1.4861 ', 'GAN acc 0.0078', 'Discriminator loss 0.2089', 'Discriminator accuracy 0.9844', 'Total loss: 1.6949', 'for batch', 6)
('GAN loss 1.4703 ', 'GAN acc 0.0039', 'Discriminator loss 0.2066', 'Discriminator accuracy 0.9883', 'Total loss: 1.6769', 'for batch', 7)
('GAN loss 1.5388 ', 'GAN acc 0.0000', 'Discriminator loss 0.2133', 'Discriminator accuracy 0.9824', 'Total loss: 1.7522', 'for batch', 8)
('GAN loss 1.4900 ', 'GAN acc 0.0039', 'Discriminator loss 0.1684', 'Discriminator accuracy 0.9902', 'Total loss: 1.6584', 'for batch', 9)
('GAN loss 1.6046 ', 'GAN acc 0.0039', 'Discriminator loss 0.1486', 'Discriminator accuracy 0.9902', 'Total loss: 1.7532', 'for batch', 10)
('GAN loss 1.5625 ', 'GAN acc 0.0078', 'Discriminator loss 0.2092', 'Discriminator accuracy 0.9902', 'Total loss: 1.7717', 'for batch', 11)
('GAN loss 1.4464 ', 'GAN acc 0.0039', 'Discriminator loss 0.1818', 'Discriminator accuracy 0.9824', 'Total loss: 1.6282', 'for batch', 12)
('GAN loss 1.4515 ', 'GAN acc 0.0039', 'Discriminator loss 0.1643', 'Discriminator accuracy 0.9941', 'Total loss: 1.6158', 'for batch', 13)
('GAN loss 1.5074 ', 'GAN acc 0.0039', 'Discriminator loss 0.1794', 'Discriminator accuracy 0.9863', 'Total loss: 1.6869', 'for batch', 14)
('GAN loss 1.5193 ', 'GAN acc 0.0078', 'Discriminator loss 0.2093', 'Discriminator accuracy 0.9844', 'Total loss: 1.7285', 'for batch', 15)
('GAN loss 1.5214 ', 'GAN acc 0.0078', 'Discriminator loss 0.1501', 'Discriminator accuracy 0.9941', 'Total loss: 1.6715', 'for batch', 16)
('GAN loss 1.5126 ', 'GAN acc 0.0039', 'Discriminator loss 0.2321', 'Discriminator accuracy 0.9824', 'Total loss: 1.7447', 'for batch', 17)
('GAN loss 1.5146 ', 'GAN acc 0.0000', 'Discriminator loss 0.1821', 'Discriminator accuracy 0.9922', 'Total loss: 1.6967', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98276925)
('DISCRIMINATOR_Imagem FAKE=', 0.19947356)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.808906')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 1.5110 ', 'GAN acc 0.0117', 'Discriminator loss 0.1537', 'Discriminator accuracy 0.9844', 'Total loss: 1.6647', 'for batch', 0)
('GAN loss 1.5382 ', 'GAN acc 0.0000', 'Discriminator loss 0.2192', 'Discriminator accuracy 0.9824', 'Total loss: 1.7574', 'for batch', 1)
('GAN loss 1.5152 ', 'GAN acc 0.0039', 'Discriminator loss 0.1862', 'Discriminator accuracy 0.9922', 'Total loss: 1.7014', 'for batch', 2)
('GAN loss 1.4819 ', 'GAN acc 0.0039', 'Discriminator loss 0.1735', 'Discriminator accuracy 0.9902', 'Total loss: 1.6554', 'for batch', 3)
('GAN loss 1.5122 ', 'GAN acc 0.0117', 'Discriminator loss 0.1875', 'Discriminator accuracy 0.9863', 'Total loss: 1.6996', 'for batch', 4)
('GAN loss 1.5801 ', 'GAN acc 0.0000', 'Discriminator loss 0.1880', 'Discriminator accuracy 0.9844', 'Total loss: 1.7681', 'for batch', 5)
('GAN loss 1.6441 ', 'GAN acc 0.0000', 'Discriminator loss 0.1782', 'Discriminator accuracy 0.9863', 'Total loss: 1.8223', 'for batch', 6)
('GAN loss 1.7113 ', 'GAN acc 0.0039', 'Discriminator loss 0.1409', 'Discriminator accuracy 0.9922', 'Total loss: 1.8522', 'for batch', 7)
('GAN loss 1.8053 ', 'GAN acc 0.0000', 'Discriminator loss 0.1961', 'Discriminator accuracy 0.9883', 'Total loss: 2.0014', 'for batch', 8)
('GAN loss 1.7476 ', 'GAN acc 0.0000', 'Discriminator loss 0.1780', 'Discriminator accuracy 0.9902', 'Total loss: 1.9255', 'for batch', 9)
('GAN loss 1.8492 ', 'GAN acc 0.0000', 'Discriminator loss 0.1147', 'Discriminator accuracy 0.9941', 'Total loss: 1.9639', 'for batch', 10)
('GAN loss 1.8142 ', 'GAN acc 0.0000', 'Discriminator loss 0.1880', 'Discriminator accuracy 0.9902', 'Total loss: 2.0022', 'for batch', 11)
('GAN loss 1.7990 ', 'GAN acc 0.0000', 'Discriminator loss 0.1279', 'Discriminator accuracy 0.9902', 'Total loss: 1.9269', 'for batch', 12)
('GAN loss 1.8487 ', 'GAN acc 0.0000', 'Discriminator loss 0.1385', 'Discriminator accuracy 0.9902', 'Total loss: 1.9872', 'for batch', 13)
('GAN loss 1.8745 ', 'GAN acc 0.0000', 'Discriminator loss 0.1024', 'Discriminator accuracy 0.9922', 'Total loss: 1.9768', 'for batch', 14)
('GAN loss 1.8977 ', 'GAN acc 0.0000', 'Discriminator loss 0.1376', 'Discriminator accuracy 0.9922', 'Total loss: 2.0353', 'for batch', 15)
('GAN loss 1.9629 ', 'GAN acc 0.0000', 'Discriminator loss 0.1106', 'Discriminator accuracy 0.9922', 'Total loss: 2.0736', 'for batch', 16)
('GAN loss 1.7276 ', 'GAN acc 0.0000', 'Discriminator loss 0.2205', 'Discriminator accuracy 0.9805', 'Total loss: 1.9481', 'for batch', 17)
('GAN loss 1.6480 ', 'GAN acc 0.0078', 'Discriminator loss 0.1269', 'Discriminator accuracy 0.9922', 'Total loss: 1.7749', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99017853)
('DISCRIMINATOR_Imagem FAKE=', 0.18145245)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.401778')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 1.5744 ', 'GAN acc 0.0156', 'Discriminator loss 0.1299', 'Discriminator accuracy 0.9941', 'Total loss: 1.7043', 'for batch', 0)
('GAN loss 1.7400 ', 'GAN acc 0.0000', 'Discriminator loss 0.1263', 'Discriminator accuracy 0.9980', 'Total loss: 1.8663', 'for batch', 1)
('GAN loss 1.9264 ', 'GAN acc 0.0000', 'Discriminator loss 0.1384', 'Discriminator accuracy 0.9922', 'Total loss: 2.0648', 'for batch', 2)
('GAN loss 1.9483 ', 'GAN acc 0.0000', 'Discriminator loss 0.1475', 'Discriminator accuracy 0.9883', 'Total loss: 2.0958', 'for batch', 3)
('GAN loss 1.9252 ', 'GAN acc 0.0000', 'Discriminator loss 0.1308', 'Discriminator accuracy 0.9844', 'Total loss: 2.0560', 'for batch', 4)
('GAN loss 2.0266 ', 'GAN acc 0.0000', 'Discriminator loss 0.1614', 'Discriminator accuracy 0.9883', 'Total loss: 2.1880', 'for batch', 5)
('GAN loss 2.0402 ', 'GAN acc 0.0000', 'Discriminator loss 0.1333', 'Discriminator accuracy 0.9883', 'Total loss: 2.1735', 'for batch', 6)
('GAN loss 2.0657 ', 'GAN acc 0.0000', 'Discriminator loss 0.0907', 'Discriminator accuracy 0.9961', 'Total loss: 2.1565', 'for batch', 7)
('GAN loss 2.1731 ', 'GAN acc 0.0000', 'Discriminator loss 0.1391', 'Discriminator accuracy 0.9902', 'Total loss: 2.3122', 'for batch', 8)
('GAN loss 2.0432 ', 'GAN acc 0.0039', 'Discriminator loss 0.2283', 'Discriminator accuracy 0.9844', 'Total loss: 2.2715', 'for batch', 9)
('GAN loss 2.0318 ', 'GAN acc 0.0000', 'Discriminator loss 0.0903', 'Discriminator accuracy 0.9941', 'Total loss: 2.1221', 'for batch', 10)
('GAN loss 2.0784 ', 'GAN acc 0.0039', 'Discriminator loss 0.1078', 'Discriminator accuracy 0.9961', 'Total loss: 2.1863', 'for batch', 11)
('GAN loss 2.1011 ', 'GAN acc 0.0000', 'Discriminator loss 0.1132', 'Discriminator accuracy 0.9922', 'Total loss: 2.2143', 'for batch', 12)
('GAN loss 2.1432 ', 'GAN acc 0.0000', 'Discriminator loss 0.1030', 'Discriminator accuracy 0.9902', 'Total loss: 2.2462', 'for batch', 13)
('GAN loss 2.1820 ', 'GAN acc 0.0000', 'Discriminator loss 0.1135', 'Discriminator accuracy 0.9922', 'Total loss: 2.2956', 'for batch', 14)
('GAN loss 2.1836 ', 'GAN acc 0.0039', 'Discriminator loss 0.1373', 'Discriminator accuracy 0.9902', 'Total loss: 2.3209', 'for batch', 15)
('GAN loss 2.2139 ', 'GAN acc 0.0039', 'Discriminator loss 0.1130', 'Discriminator accuracy 0.9902', 'Total loss: 2.3269', 'for batch', 16)
('GAN loss 2.1949 ', 'GAN acc 0.0000', 'Discriminator loss 0.1732', 'Discriminator accuracy 0.9844', 'Total loss: 2.3682', 'for batch', 17)
('GAN loss 2.2459 ', 'GAN acc 0.0000', 'Discriminator loss 0.0929', 'Discriminator accuracy 0.9961', 'Total loss: 2.3388', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98644656)
('DISCRIMINATOR_Imagem FAKE=', 0.1073033)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.788131')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 2.3555 ', 'GAN acc 0.0000', 'Discriminator loss 0.0777', 'Discriminator accuracy 0.9961', 'Total loss: 2.4332', 'for batch', 0)
('GAN loss 2.2408 ', 'GAN acc 0.0000', 'Discriminator loss 0.0987', 'Discriminator accuracy 0.9941', 'Total loss: 2.3395', 'for batch', 1)
('GAN loss 2.3326 ', 'GAN acc 0.0000', 'Discriminator loss 0.1279', 'Discriminator accuracy 0.9941', 'Total loss: 2.4605', 'for batch', 2)
('GAN loss 2.3244 ', 'GAN acc 0.0000', 'Discriminator loss 0.0844', 'Discriminator accuracy 0.9902', 'Total loss: 2.4088', 'for batch', 3)
('GAN loss 2.4042 ', 'GAN acc 0.0000', 'Discriminator loss 0.0785', 'Discriminator accuracy 0.9941', 'Total loss: 2.4828', 'for batch', 4)
('GAN loss 2.2807 ', 'GAN acc 0.0000', 'Discriminator loss 0.0831', 'Discriminator accuracy 0.9922', 'Total loss: 2.3638', 'for batch', 5)
('GAN loss 2.1466 ', 'GAN acc 0.0000', 'Discriminator loss 0.1023', 'Discriminator accuracy 0.9961', 'Total loss: 2.2489', 'for batch', 6)
('GAN loss 2.2115 ', 'GAN acc 0.0000', 'Discriminator loss 0.0884', 'Discriminator accuracy 0.9941', 'Total loss: 2.2998', 'for batch', 7)
('GAN loss 2.4027 ', 'GAN acc 0.0000', 'Discriminator loss 0.1431', 'Discriminator accuracy 0.9883', 'Total loss: 2.5458', 'for batch', 8)
('GAN loss 2.3478 ', 'GAN acc 0.0000', 'Discriminator loss 0.0673', 'Discriminator accuracy 0.9961', 'Total loss: 2.4150', 'for batch', 9)
('GAN loss 2.4031 ', 'GAN acc 0.0078', 'Discriminator loss 0.0787', 'Discriminator accuracy 0.9961', 'Total loss: 2.4818', 'for batch', 10)
('GAN loss 2.5871 ', 'GAN acc 0.0000', 'Discriminator loss 0.0947', 'Discriminator accuracy 0.9883', 'Total loss: 2.6818', 'for batch', 11)
('GAN loss 2.5550 ', 'GAN acc 0.0117', 'Discriminator loss 0.0877', 'Discriminator accuracy 0.9863', 'Total loss: 2.6427', 'for batch', 12)
('GAN loss 2.6974 ', 'GAN acc 0.0039', 'Discriminator loss 0.0739', 'Discriminator accuracy 0.9941', 'Total loss: 2.7713', 'for batch', 13)
('GAN loss 2.7759 ', 'GAN acc 0.0000', 'Discriminator loss 0.0867', 'Discriminator accuracy 0.9941', 'Total loss: 2.8626', 'for batch', 14)
('GAN loss 2.4473 ', 'GAN acc 0.0000', 'Discriminator loss 0.1415', 'Discriminator accuracy 0.9883', 'Total loss: 2.5888', 'for batch', 15)
('GAN loss 2.4664 ', 'GAN acc 0.0000', 'Discriminator loss 0.1000', 'Discriminator accuracy 0.9902', 'Total loss: 2.5663', 'for batch', 16)
('GAN loss 2.2607 ', 'GAN acc 0.0000', 'Discriminator loss 0.1760', 'Discriminator accuracy 0.9844', 'Total loss: 2.4367', 'for batch', 17)
('GAN loss 2.2201 ', 'GAN acc 0.0039', 'Discriminator loss 0.1089', 'Discriminator accuracy 0.9941', 'Total loss: 2.3290', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98771644)
('DISCRIMINATOR_Imagem FAKE=', 0.11977692)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.347641')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 2.4495 ', 'GAN acc 0.0000', 'Discriminator loss 0.0913', 'Discriminator accuracy 0.9941', 'Total loss: 2.5409', 'for batch', 0)
('GAN loss 2.7046 ', 'GAN acc 0.0000', 'Discriminator loss 0.1138', 'Discriminator accuracy 0.9883', 'Total loss: 2.8184', 'for batch', 1)
('GAN loss 2.5999 ', 'GAN acc 0.0000', 'Discriminator loss 0.1489', 'Discriminator accuracy 0.9902', 'Total loss: 2.7488', 'for batch', 2)
('GAN loss 2.7893 ', 'GAN acc 0.0000', 'Discriminator loss 0.0644', 'Discriminator accuracy 0.9902', 'Total loss: 2.8537', 'for batch', 3)
('GAN loss 2.7564 ', 'GAN acc 0.0000', 'Discriminator loss 0.0889', 'Discriminator accuracy 0.9883', 'Total loss: 2.8452', 'for batch', 4)
('GAN loss 2.7100 ', 'GAN acc 0.0000', 'Discriminator loss 0.1189', 'Discriminator accuracy 0.9863', 'Total loss: 2.8288', 'for batch', 5)
('GAN loss 2.4779 ', 'GAN acc 0.0039', 'Discriminator loss 0.1069', 'Discriminator accuracy 0.9922', 'Total loss: 2.5848', 'for batch', 6)
('GAN loss 2.5588 ', 'GAN acc 0.0000', 'Discriminator loss 0.0697', 'Discriminator accuracy 0.9941', 'Total loss: 2.6284', 'for batch', 7)
('GAN loss 2.4624 ', 'GAN acc 0.0000', 'Discriminator loss 0.1105', 'Discriminator accuracy 0.9902', 'Total loss: 2.5729', 'for batch', 8)
('GAN loss 2.6795 ', 'GAN acc 0.0000', 'Discriminator loss 0.0541', 'Discriminator accuracy 1.0000', 'Total loss: 2.7336', 'for batch', 9)
('GAN loss 2.9348 ', 'GAN acc 0.0000', 'Discriminator loss 0.0609', 'Discriminator accuracy 0.9961', 'Total loss: 2.9957', 'for batch', 10)
('GAN loss 2.8358 ', 'GAN acc 0.0000', 'Discriminator loss 0.0721', 'Discriminator accuracy 0.9961', 'Total loss: 2.9079', 'for batch', 11)
('GAN loss 2.9493 ', 'GAN acc 0.0000', 'Discriminator loss 0.0550', 'Discriminator accuracy 0.9941', 'Total loss: 3.0043', 'for batch', 12)
('GAN loss 3.1062 ', 'GAN acc 0.0000', 'Discriminator loss 0.0500', 'Discriminator accuracy 0.9961', 'Total loss: 3.1562', 'for batch', 13)
('GAN loss 3.0959 ', 'GAN acc 0.0000', 'Discriminator loss 0.0606', 'Discriminator accuracy 0.9922', 'Total loss: 3.1566', 'for batch', 14)
('GAN loss 3.0296 ', 'GAN acc 0.0000', 'Discriminator loss 0.0808', 'Discriminator accuracy 0.9941', 'Total loss: 3.1104', 'for batch', 15)
('GAN loss 3.1866 ', 'GAN acc 0.0000', 'Discriminator loss 0.0537', 'Discriminator accuracy 0.9922', 'Total loss: 3.2404', 'for batch', 16)
('GAN loss 2.9785 ', 'GAN acc 0.0000', 'Discriminator loss 0.1104', 'Discriminator accuracy 0.9883', 'Total loss: 3.0888', 'for batch', 17)
('GAN loss 2.7998 ', 'GAN acc 0.0000', 'Discriminator loss 0.0709', 'Discriminator accuracy 0.9961', 'Total loss: 2.8707', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98744321)
('DISCRIMINATOR_Imagem FAKE=', 0.039017957)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.727502')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 2.9483 ', 'GAN acc 0.0000', 'Discriminator loss 0.0456', 'Discriminator accuracy 0.9980', 'Total loss: 2.9939', 'for batch', 0)
('GAN loss 2.8227 ', 'GAN acc 0.0000', 'Discriminator loss 0.0797', 'Discriminator accuracy 0.9961', 'Total loss: 2.9024', 'for batch', 1)
('GAN loss 2.6494 ', 'GAN acc 0.0000', 'Discriminator loss 0.0758', 'Discriminator accuracy 0.9941', 'Total loss: 2.7252', 'for batch', 2)
('GAN loss 2.6589 ', 'GAN acc 0.0000', 'Discriminator loss 0.0751', 'Discriminator accuracy 0.9941', 'Total loss: 2.7339', 'for batch', 3)
('GAN loss 2.8374 ', 'GAN acc 0.0000', 'Discriminator loss 0.0814', 'Discriminator accuracy 0.9902', 'Total loss: 2.9188', 'for batch', 4)
('GAN loss 2.7356 ', 'GAN acc 0.0000', 'Discriminator loss 0.0696', 'Discriminator accuracy 0.9902', 'Total loss: 2.8053', 'for batch', 5)
('GAN loss 2.7663 ', 'GAN acc 0.0000', 'Discriminator loss 0.0821', 'Discriminator accuracy 0.9883', 'Total loss: 2.8484', 'for batch', 6)
('GAN loss 3.0251 ', 'GAN acc 0.0000', 'Discriminator loss 0.0960', 'Discriminator accuracy 0.9941', 'Total loss: 3.1212', 'for batch', 7)
('GAN loss 3.1089 ', 'GAN acc 0.0000', 'Discriminator loss 0.0708', 'Discriminator accuracy 0.9902', 'Total loss: 3.1797', 'for batch', 8)
('GAN loss 3.0716 ', 'GAN acc 0.0000', 'Discriminator loss 0.0504', 'Discriminator accuracy 0.9961', 'Total loss: 3.1220', 'for batch', 9)
('GAN loss 3.3010 ', 'GAN acc 0.0000', 'Discriminator loss 0.0433', 'Discriminator accuracy 0.9961', 'Total loss: 3.3443', 'for batch', 10)
('GAN loss 3.4120 ', 'GAN acc 0.0000', 'Discriminator loss 0.0622', 'Discriminator accuracy 0.9961', 'Total loss: 3.4742', 'for batch', 11)
('GAN loss 3.3692 ', 'GAN acc 0.0000', 'Discriminator loss 0.0804', 'Discriminator accuracy 0.9883', 'Total loss: 3.4495', 'for batch', 12)
('GAN loss 3.2509 ', 'GAN acc 0.0000', 'Discriminator loss 0.0405', 'Discriminator accuracy 0.9961', 'Total loss: 3.2913', 'for batch', 13)
('GAN loss 3.3411 ', 'GAN acc 0.0000', 'Discriminator loss 0.0383', 'Discriminator accuracy 0.9922', 'Total loss: 3.3794', 'for batch', 14)
('GAN loss 3.2487 ', 'GAN acc 0.0000', 'Discriminator loss 0.0454', 'Discriminator accuracy 0.9941', 'Total loss: 3.2941', 'for batch', 15)
('GAN loss 3.3200 ', 'GAN acc 0.0000', 'Discriminator loss 0.0452', 'Discriminator accuracy 0.9922', 'Total loss: 3.3652', 'for batch', 16)
('GAN loss 3.2465 ', 'GAN acc 0.0000', 'Discriminator loss 0.0625', 'Discriminator accuracy 0.9902', 'Total loss: 3.3089', 'for batch', 17)
('GAN loss 3.1955 ', 'GAN acc 0.0000', 'Discriminator loss 0.0463', 'Discriminator accuracy 0.9961', 'Total loss: 3.2418', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98814672)
('DISCRIMINATOR_Imagem FAKE=', 0.030368682)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.306476')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 3.3346 ', 'GAN acc 0.0000', 'Discriminator loss 0.0363', 'Discriminator accuracy 0.9980', 'Total loss: 3.3709', 'for batch', 0)
('GAN loss 3.1603 ', 'GAN acc 0.0000', 'Discriminator loss 0.0704', 'Discriminator accuracy 0.9922', 'Total loss: 3.2307', 'for batch', 1)
('GAN loss 2.9863 ', 'GAN acc 0.0000', 'Discriminator loss 0.0607', 'Discriminator accuracy 0.9922', 'Total loss: 3.0470', 'for batch', 2)
('GAN loss 3.0055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0620', 'Discriminator accuracy 0.9961', 'Total loss: 3.0675', 'for batch', 3)
('GAN loss 3.1939 ', 'GAN acc 0.0000', 'Discriminator loss 0.0526', 'Discriminator accuracy 0.9941', 'Total loss: 3.2465', 'for batch', 4)
('GAN loss 3.4409 ', 'GAN acc 0.0000', 'Discriminator loss 0.0729', 'Discriminator accuracy 0.9961', 'Total loss: 3.5138', 'for batch', 5)
('GAN loss 3.2622 ', 'GAN acc 0.0000', 'Discriminator loss 0.0870', 'Discriminator accuracy 0.9863', 'Total loss: 3.3493', 'for batch', 6)
('GAN loss 3.3135 ', 'GAN acc 0.0000', 'Discriminator loss 0.0522', 'Discriminator accuracy 0.9941', 'Total loss: 3.3658', 'for batch', 7)
('GAN loss 3.2415 ', 'GAN acc 0.0000', 'Discriminator loss 0.0826', 'Discriminator accuracy 0.9902', 'Total loss: 3.3241', 'for batch', 8)
('GAN loss 3.2332 ', 'GAN acc 0.0000', 'Discriminator loss 0.0463', 'Discriminator accuracy 0.9961', 'Total loss: 3.2795', 'for batch', 9)
('GAN loss 3.3479 ', 'GAN acc 0.0000', 'Discriminator loss 0.0521', 'Discriminator accuracy 0.9961', 'Total loss: 3.3999', 'for batch', 10)
('GAN loss 3.3475 ', 'GAN acc 0.0000', 'Discriminator loss 0.0888', 'Discriminator accuracy 0.9922', 'Total loss: 3.4363', 'for batch', 11)
('GAN loss 3.5802 ', 'GAN acc 0.0000', 'Discriminator loss 0.0440', 'Discriminator accuracy 0.9961', 'Total loss: 3.6242', 'for batch', 12)
('GAN loss 3.7308 ', 'GAN acc 0.0000', 'Discriminator loss 0.0407', 'Discriminator accuracy 0.9941', 'Total loss: 3.7714', 'for batch', 13)
('GAN loss 3.8169 ', 'GAN acc 0.0000', 'Discriminator loss 0.0206', 'Discriminator accuracy 0.9980', 'Total loss: 3.8374', 'for batch', 14)
('GAN loss 3.9101 ', 'GAN acc 0.0000', 'Discriminator loss 0.0349', 'Discriminator accuracy 0.9941', 'Total loss: 3.9450', 'for batch', 15)
('GAN loss 3.7990 ', 'GAN acc 0.0000', 'Discriminator loss 0.0554', 'Discriminator accuracy 0.9922', 'Total loss: 3.8544', 'for batch', 16)
('GAN loss 3.2855 ', 'GAN acc 0.0000', 'Discriminator loss 0.1043', 'Discriminator accuracy 0.9863', 'Total loss: 3.3899', 'for batch', 17)
('GAN loss 3.1742 ', 'GAN acc 0.0000', 'Discriminator loss 0.0330', 'Discriminator accuracy 0.9980', 'Total loss: 3.2072', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98992753)
('DISCRIMINATOR_Imagem FAKE=', 0.036362257)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.840119')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 3.1756 ', 'GAN acc 0.0000', 'Discriminator loss 0.0414', 'Discriminator accuracy 0.9961', 'Total loss: 3.2170', 'for batch', 0)
('GAN loss 3.2520 ', 'GAN acc 0.0039', 'Discriminator loss 0.0353', 'Discriminator accuracy 0.9980', 'Total loss: 3.2872', 'for batch', 1)
('GAN loss 3.3691 ', 'GAN acc 0.0000', 'Discriminator loss 0.0350', 'Discriminator accuracy 0.9980', 'Total loss: 3.4041', 'for batch', 2)
('GAN loss 3.4076 ', 'GAN acc 0.0000', 'Discriminator loss 0.0544', 'Discriminator accuracy 0.9922', 'Total loss: 3.4620', 'for batch', 3)
('GAN loss 3.5087 ', 'GAN acc 0.0000', 'Discriminator loss 0.0476', 'Discriminator accuracy 0.9941', 'Total loss: 3.5563', 'for batch', 4)
('GAN loss 3.7112 ', 'GAN acc 0.0000', 'Discriminator loss 0.0626', 'Discriminator accuracy 0.9941', 'Total loss: 3.7738', 'for batch', 5)
('GAN loss 3.5329 ', 'GAN acc 0.0000', 'Discriminator loss 0.0656', 'Discriminator accuracy 0.9902', 'Total loss: 3.5986', 'for batch', 6)
('GAN loss 3.5398 ', 'GAN acc 0.0000', 'Discriminator loss 0.0417', 'Discriminator accuracy 0.9941', 'Total loss: 3.5815', 'for batch', 7)
('GAN loss 3.6457 ', 'GAN acc 0.0000', 'Discriminator loss 0.0394', 'Discriminator accuracy 0.9941', 'Total loss: 3.6851', 'for batch', 8)
('GAN loss 3.5132 ', 'GAN acc 0.0000', 'Discriminator loss 0.0384', 'Discriminator accuracy 0.9980', 'Total loss: 3.5516', 'for batch', 9)
('GAN loss 3.4322 ', 'GAN acc 0.0000', 'Discriminator loss 0.0338', 'Discriminator accuracy 0.9961', 'Total loss: 3.4660', 'for batch', 10)
('GAN loss 3.5429 ', 'GAN acc 0.0000', 'Discriminator loss 0.0276', 'Discriminator accuracy 0.9980', 'Total loss: 3.5704', 'for batch', 11)
('GAN loss 3.7270 ', 'GAN acc 0.0000', 'Discriminator loss 0.0377', 'Discriminator accuracy 0.9961', 'Total loss: 3.7648', 'for batch', 12)
('GAN loss 3.8815 ', 'GAN acc 0.0000', 'Discriminator loss 0.0358', 'Discriminator accuracy 0.9961', 'Total loss: 3.9173', 'for batch', 13)
('GAN loss 4.0905 ', 'GAN acc 0.0000', 'Discriminator loss 0.0174', 'Discriminator accuracy 0.9961', 'Total loss: 4.1079', 'for batch', 14)
('GAN loss 4.2026 ', 'GAN acc 0.0000', 'Discriminator loss 0.0333', 'Discriminator accuracy 0.9961', 'Total loss: 4.2360', 'for batch', 15)
('GAN loss 4.2124 ', 'GAN acc 0.0000', 'Discriminator loss 0.0375', 'Discriminator accuracy 0.9941', 'Total loss: 4.2499', 'for batch', 16)
('GAN loss 3.8728 ', 'GAN acc 0.0000', 'Discriminator loss 0.0461', 'Discriminator accuracy 0.9922', 'Total loss: 3.9189', 'for batch', 17)
('GAN loss 3.6620 ', 'GAN acc 0.0000', 'Discriminator loss 0.0266', 'Discriminator accuracy 0.9980', 'Total loss: 3.6886', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99086148)
('DISCRIMINATOR_Imagem FAKE=', 0.020234821)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.264126')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 3.4711 ', 'GAN acc 0.0000', 'Discriminator loss 0.0300', 'Discriminator accuracy 0.9961', 'Total loss: 3.5011', 'for batch', 0)
('GAN loss 3.6199 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9961', 'Total loss: 3.6514', 'for batch', 1)
('GAN loss 3.5198 ', 'GAN acc 0.0000', 'Discriminator loss 0.0349', 'Discriminator accuracy 0.9961', 'Total loss: 3.5547', 'for batch', 2)
('GAN loss 3.6655 ', 'GAN acc 0.0000', 'Discriminator loss 0.0396', 'Discriminator accuracy 0.9961', 'Total loss: 3.7051', 'for batch', 3)
('GAN loss 3.4067 ', 'GAN acc 0.0000', 'Discriminator loss 0.0601', 'Discriminator accuracy 0.9922', 'Total loss: 3.4668', 'for batch', 4)
('GAN loss 3.3959 ', 'GAN acc 0.0039', 'Discriminator loss 0.0255', 'Discriminator accuracy 1.0000', 'Total loss: 3.4214', 'for batch', 5)
('GAN loss 3.4903 ', 'GAN acc 0.0000', 'Discriminator loss 0.0369', 'Discriminator accuracy 0.9961', 'Total loss: 3.5272', 'for batch', 6)
('GAN loss 3.5473 ', 'GAN acc 0.0000', 'Discriminator loss 0.0497', 'Discriminator accuracy 0.9941', 'Total loss: 3.5969', 'for batch', 7)
('GAN loss 3.7934 ', 'GAN acc 0.0000', 'Discriminator loss 0.0482', 'Discriminator accuracy 0.9941', 'Total loss: 3.8415', 'for batch', 8)
('GAN loss 3.9357 ', 'GAN acc 0.0000', 'Discriminator loss 0.0186', 'Discriminator accuracy 1.0000', 'Total loss: 3.9543', 'for batch', 9)
('GAN loss 4.2268 ', 'GAN acc 0.0000', 'Discriminator loss 0.0279', 'Discriminator accuracy 0.9961', 'Total loss: 4.2547', 'for batch', 10)
('GAN loss 4.2826 ', 'GAN acc 0.0000', 'Discriminator loss 0.0130', 'Discriminator accuracy 0.9980', 'Total loss: 4.2956', 'for batch', 11)
('GAN loss 4.3973 ', 'GAN acc 0.0000', 'Discriminator loss 0.0485', 'Discriminator accuracy 0.9922', 'Total loss: 4.4458', 'for batch', 12)
('GAN loss 4.4060 ', 'GAN acc 0.0000', 'Discriminator loss 0.0303', 'Discriminator accuracy 0.9961', 'Total loss: 4.4363', 'for batch', 13)
('GAN loss 4.2279 ', 'GAN acc 0.0000', 'Discriminator loss 0.0176', 'Discriminator accuracy 0.9941', 'Total loss: 4.2455', 'for batch', 14)
('GAN loss 4.1968 ', 'GAN acc 0.0000', 'Discriminator loss 0.0322', 'Discriminator accuracy 0.9961', 'Total loss: 4.2290', 'for batch', 15)
('GAN loss 4.3425 ', 'GAN acc 0.0000', 'Discriminator loss 0.0294', 'Discriminator accuracy 0.9961', 'Total loss: 4.3719', 'for batch', 16)
('GAN loss 4.3627 ', 'GAN acc 0.0000', 'Discriminator loss 0.0343', 'Discriminator accuracy 0.9941', 'Total loss: 4.3970', 'for batch', 17)
('GAN loss 4.4937 ', 'GAN acc 0.0000', 'Discriminator loss 0.0194', 'Discriminator accuracy 0.9980', 'Total loss: 4.5130', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99058372)
('DISCRIMINATOR_Imagem FAKE=', 0.0092802132)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.742693')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 4.4463 ', 'GAN acc 0.0000', 'Discriminator loss 0.0194', 'Discriminator accuracy 0.9980', 'Total loss: 4.4657', 'for batch', 0)
('GAN loss 4.3424 ', 'GAN acc 0.0000', 'Discriminator loss 0.0370', 'Discriminator accuracy 0.9961', 'Total loss: 4.3795', 'for batch', 1)
('GAN loss 4.0584 ', 'GAN acc 0.0000', 'Discriminator loss 0.0580', 'Discriminator accuracy 0.9941', 'Total loss: 4.1164', 'for batch', 2)
('GAN loss 4.1252 ', 'GAN acc 0.0000', 'Discriminator loss 0.0375', 'Discriminator accuracy 0.9941', 'Total loss: 4.1627', 'for batch', 3)
('GAN loss 4.1248 ', 'GAN acc 0.0000', 'Discriminator loss 0.0346', 'Discriminator accuracy 0.9941', 'Total loss: 4.1595', 'for batch', 4)
('GAN loss 3.9481 ', 'GAN acc 0.0000', 'Discriminator loss 0.0333', 'Discriminator accuracy 0.9961', 'Total loss: 3.9814', 'for batch', 5)
('GAN loss 3.7288 ', 'GAN acc 0.0000', 'Discriminator loss 0.0349', 'Discriminator accuracy 0.9941', 'Total loss: 3.7637', 'for batch', 6)
('GAN loss 3.7651 ', 'GAN acc 0.0000', 'Discriminator loss 0.0398', 'Discriminator accuracy 0.9961', 'Total loss: 3.8050', 'for batch', 7)
('GAN loss 3.6833 ', 'GAN acc 0.0000', 'Discriminator loss 0.0692', 'Discriminator accuracy 0.9922', 'Total loss: 3.7525', 'for batch', 8)
('GAN loss 3.7131 ', 'GAN acc 0.0000', 'Discriminator loss 0.0182', 'Discriminator accuracy 1.0000', 'Total loss: 3.7312', 'for batch', 9)
('GAN loss 3.8736 ', 'GAN acc 0.0000', 'Discriminator loss 0.0316', 'Discriminator accuracy 0.9961', 'Total loss: 3.9052', 'for batch', 10)
('GAN loss 3.9989 ', 'GAN acc 0.0000', 'Discriminator loss 0.0297', 'Discriminator accuracy 0.9961', 'Total loss: 4.0286', 'for batch', 11)
('GAN loss 4.0865 ', 'GAN acc 0.0000', 'Discriminator loss 0.0338', 'Discriminator accuracy 0.9961', 'Total loss: 4.1204', 'for batch', 12)
('GAN loss 4.2513 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9961', 'Total loss: 4.2829', 'for batch', 13)
('GAN loss 4.3000 ', 'GAN acc 0.0000', 'Discriminator loss 0.0143', 'Discriminator accuracy 0.9980', 'Total loss: 4.3143', 'for batch', 14)
('GAN loss 4.4477 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9961', 'Total loss: 4.4792', 'for batch', 15)
('GAN loss 4.2559 ', 'GAN acc 0.0000', 'Discriminator loss 0.0338', 'Discriminator accuracy 0.9961', 'Total loss: 4.2897', 'for batch', 16)
('GAN loss 4.4621 ', 'GAN acc 0.0000', 'Discriminator loss 0.0344', 'Discriminator accuracy 0.9941', 'Total loss: 4.4966', 'for batch', 17)
('GAN loss 4.5636 ', 'GAN acc 0.0000', 'Discriminator loss 0.0211', 'Discriminator accuracy 0.9980', 'Total loss: 4.5847', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98979628)
('DISCRIMINATOR_Imagem FAKE=', 0.009165667)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.315150')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 4.1589 ', 'GAN acc 0.0000', 'Discriminator loss 0.0453', 'Discriminator accuracy 0.9941', 'Total loss: 4.2042', 'for batch', 0)
('GAN loss 3.9079 ', 'GAN acc 0.0000', 'Discriminator loss 0.0481', 'Discriminator accuracy 0.9941', 'Total loss: 3.9560', 'for batch', 1)
('GAN loss 3.9502 ', 'GAN acc 0.0000', 'Discriminator loss 0.0265', 'Discriminator accuracy 0.9980', 'Total loss: 3.9767', 'for batch', 2)
('GAN loss 4.1055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0364', 'Discriminator accuracy 0.9961', 'Total loss: 4.1419', 'for batch', 3)
('GAN loss 4.3759 ', 'GAN acc 0.0000', 'Discriminator loss 0.0365', 'Discriminator accuracy 0.9941', 'Total loss: 4.4124', 'for batch', 4)
('GAN loss 4.4050 ', 'GAN acc 0.0000', 'Discriminator loss 0.0275', 'Discriminator accuracy 0.9941', 'Total loss: 4.4324', 'for batch', 5)
('GAN loss 4.3612 ', 'GAN acc 0.0000', 'Discriminator loss 0.0355', 'Discriminator accuracy 0.9961', 'Total loss: 4.3966', 'for batch', 6)
('GAN loss 4.3925 ', 'GAN acc 0.0000', 'Discriminator loss 0.0323', 'Discriminator accuracy 0.9961', 'Total loss: 4.4248', 'for batch', 7)
('GAN loss 4.5011 ', 'GAN acc 0.0000', 'Discriminator loss 0.0847', 'Discriminator accuracy 0.9883', 'Total loss: 4.5858', 'for batch', 8)
('GAN loss 4.4837 ', 'GAN acc 0.0000', 'Discriminator loss 0.0112', 'Discriminator accuracy 0.9980', 'Total loss: 4.4949', 'for batch', 9)
('GAN loss 4.5987 ', 'GAN acc 0.0000', 'Discriminator loss 0.0295', 'Discriminator accuracy 0.9961', 'Total loss: 4.6282', 'for batch', 10)
('GAN loss 4.8523 ', 'GAN acc 0.0000', 'Discriminator loss 0.0133', 'Discriminator accuracy 0.9980', 'Total loss: 4.8656', 'for batch', 11)
('GAN loss 4.8295 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 4.8569', 'for batch', 12)
('GAN loss 5.0545 ', 'GAN acc 0.0000', 'Discriminator loss 0.0253', 'Discriminator accuracy 0.9961', 'Total loss: 5.0798', 'for batch', 13)
('GAN loss 4.9293 ', 'GAN acc 0.0000', 'Discriminator loss 0.0290', 'Discriminator accuracy 0.9961', 'Total loss: 4.9583', 'for batch', 14)
('GAN loss 5.0262 ', 'GAN acc 0.0000', 'Discriminator loss 0.0252', 'Discriminator accuracy 0.9961', 'Total loss: 5.0514', 'for batch', 15)
('GAN loss 5.0128 ', 'GAN acc 0.0000', 'Discriminator loss 0.0293', 'Discriminator accuracy 0.9961', 'Total loss: 5.0421', 'for batch', 16)
('GAN loss 5.1565 ', 'GAN acc 0.0000', 'Discriminator loss 0.0635', 'Discriminator accuracy 0.9922', 'Total loss: 5.2200', 'for batch', 17)
('GAN loss 5.1330 ', 'GAN acc 0.0000', 'Discriminator loss 0.0166', 'Discriminator accuracy 0.9980', 'Total loss: 5.1497', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98925525)
('DISCRIMINATOR_Imagem FAKE=', 0.0042548436)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.727822')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2906 ', 'GAN acc 0.0000', 'Discriminator loss 0.0468', 'Discriminator accuracy 0.9961', 'Total loss: 5.3374', 'for batch', 0)
('GAN loss 4.8322 ', 'GAN acc 0.0000', 'Discriminator loss 0.0146', 'Discriminator accuracy 0.9941', 'Total loss: 4.8468', 'for batch', 1)
('GAN loss 4.7525 ', 'GAN acc 0.0000', 'Discriminator loss 0.0172', 'Discriminator accuracy 0.9980', 'Total loss: 4.7697', 'for batch', 2)
('GAN loss 4.5687 ', 'GAN acc 0.0000', 'Discriminator loss 0.0264', 'Discriminator accuracy 0.9961', 'Total loss: 4.5952', 'for batch', 3)
('GAN loss 4.7521 ', 'GAN acc 0.0000', 'Discriminator loss 0.0299', 'Discriminator accuracy 0.9941', 'Total loss: 4.7820', 'for batch', 4)
('GAN loss 4.2116 ', 'GAN acc 0.0000', 'Discriminator loss 0.0390', 'Discriminator accuracy 0.9961', 'Total loss: 4.2506', 'for batch', 5)
('GAN loss 4.2887 ', 'GAN acc 0.0000', 'Discriminator loss 0.0222', 'Discriminator accuracy 0.9980', 'Total loss: 4.3109', 'for batch', 6)
('GAN loss 4.3690 ', 'GAN acc 0.0000', 'Discriminator loss 0.0331', 'Discriminator accuracy 0.9961', 'Total loss: 4.4021', 'for batch', 7)
('GAN loss 4.4663 ', 'GAN acc 0.0000', 'Discriminator loss 0.0362', 'Discriminator accuracy 0.9941', 'Total loss: 4.5025', 'for batch', 8)
('GAN loss 4.5711 ', 'GAN acc 0.0000', 'Discriminator loss 0.0098', 'Discriminator accuracy 1.0000', 'Total loss: 4.5809', 'for batch', 9)
('GAN loss 4.6730 ', 'GAN acc 0.0000', 'Discriminator loss 0.0227', 'Discriminator accuracy 0.9961', 'Total loss: 4.6956', 'for batch', 10)
('GAN loss 4.9270 ', 'GAN acc 0.0000', 'Discriminator loss 0.0097', 'Discriminator accuracy 0.9980', 'Total loss: 4.9366', 'for batch', 11)
('GAN loss 5.1663 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9961', 'Total loss: 5.1942', 'for batch', 12)
('GAN loss 5.1490 ', 'GAN acc 0.0000', 'Discriminator loss 0.0246', 'Discriminator accuracy 0.9961', 'Total loss: 5.1736', 'for batch', 13)
('GAN loss 5.1748 ', 'GAN acc 0.0000', 'Discriminator loss 0.0086', 'Discriminator accuracy 0.9980', 'Total loss: 5.1834', 'for batch', 14)
('GAN loss 5.0726 ', 'GAN acc 0.0000', 'Discriminator loss 0.0241', 'Discriminator accuracy 0.9961', 'Total loss: 5.0967', 'for batch', 15)
('GAN loss 5.1072 ', 'GAN acc 0.0000', 'Discriminator loss 0.0292', 'Discriminator accuracy 0.9941', 'Total loss: 5.1365', 'for batch', 16)
('GAN loss 5.1733 ', 'GAN acc 0.0000', 'Discriminator loss 0.0934', 'Discriminator accuracy 0.9902', 'Total loss: 5.2667', 'for batch', 17)
('GAN loss 5.0649 ', 'GAN acc 0.0000', 'Discriminator loss 0.0140', 'Discriminator accuracy 0.9980', 'Total loss: 5.0789', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98966277)
('DISCRIMINATOR_Imagem FAKE=', 0.0040574274)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.267052')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2646 ', 'GAN acc 0.0000', 'Discriminator loss 0.0147', 'Discriminator accuracy 0.9980', 'Total loss: 5.2792', 'for batch', 0)
('GAN loss 5.0349 ', 'GAN acc 0.0000', 'Discriminator loss 0.0402', 'Discriminator accuracy 0.9941', 'Total loss: 5.0751', 'for batch', 1)
('GAN loss 4.6862 ', 'GAN acc 0.0000', 'Discriminator loss 0.0657', 'Discriminator accuracy 0.9922', 'Total loss: 4.7518', 'for batch', 2)
('GAN loss 4.5551 ', 'GAN acc 0.0000', 'Discriminator loss 0.0271', 'Discriminator accuracy 0.9961', 'Total loss: 4.5822', 'for batch', 3)
('GAN loss 4.4526 ', 'GAN acc 0.0000', 'Discriminator loss 0.0330', 'Discriminator accuracy 0.9941', 'Total loss: 4.4856', 'for batch', 4)
('GAN loss 4.4468 ', 'GAN acc 0.0000', 'Discriminator loss 0.0128', 'Discriminator accuracy 0.9980', 'Total loss: 4.4596', 'for batch', 5)
('GAN loss 4.6659 ', 'GAN acc 0.0000', 'Discriminator loss 0.0214', 'Discriminator accuracy 0.9980', 'Total loss: 4.6873', 'for batch', 6)
('GAN loss 4.6124 ', 'GAN acc 0.0000', 'Discriminator loss 0.0279', 'Discriminator accuracy 0.9961', 'Total loss: 4.6403', 'for batch', 7)
('GAN loss 4.7283 ', 'GAN acc 0.0000', 'Discriminator loss 0.0386', 'Discriminator accuracy 0.9941', 'Total loss: 4.7669', 'for batch', 8)
('GAN loss 4.7261 ', 'GAN acc 0.0000', 'Discriminator loss 0.0074', 'Discriminator accuracy 1.0000', 'Total loss: 4.7335', 'for batch', 9)
('GAN loss 4.7031 ', 'GAN acc 0.0000', 'Discriminator loss 0.0246', 'Discriminator accuracy 0.9961', 'Total loss: 4.7277', 'for batch', 10)
('GAN loss 4.5389 ', 'GAN acc 0.0000', 'Discriminator loss 0.0154', 'Discriminator accuracy 0.9980', 'Total loss: 4.5543', 'for batch', 11)
('GAN loss 4.4856 ', 'GAN acc 0.0000', 'Discriminator loss 0.0321', 'Discriminator accuracy 0.9961', 'Total loss: 4.5177', 'for batch', 12)
('GAN loss 4.4291 ', 'GAN acc 0.0000', 'Discriminator loss 0.0313', 'Discriminator accuracy 0.9961', 'Total loss: 4.4604', 'for batch', 13)
('GAN loss 4.4447 ', 'GAN acc 0.0078', 'Discriminator loss 0.0162', 'Discriminator accuracy 0.9980', 'Total loss: 4.4609', 'for batch', 14)
('GAN loss 4.5646 ', 'GAN acc 0.0039', 'Discriminator loss 0.0370', 'Discriminator accuracy 0.9941', 'Total loss: 4.6016', 'for batch', 15)
('GAN loss 4.6172 ', 'GAN acc 0.0000', 'Discriminator loss 0.0312', 'Discriminator accuracy 0.9941', 'Total loss: 4.6484', 'for batch', 16)
('GAN loss 4.8366 ', 'GAN acc 0.0000', 'Discriminator loss 0.0401', 'Discriminator accuracy 0.9941', 'Total loss: 4.8766', 'for batch', 17)
('GAN loss 4.9117 ', 'GAN acc 0.0000', 'Discriminator loss 0.0257', 'Discriminator accuracy 0.9961', 'Total loss: 4.9374', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98917079)
('DISCRIMINATOR_Imagem FAKE=', 0.010544065)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.719263')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 4.9939 ', 'GAN acc 0.0039', 'Discriminator loss 0.0576', 'Discriminator accuracy 0.9941', 'Total loss: 5.0514', 'for batch', 0)
('GAN loss 4.4907 ', 'GAN acc 0.0000', 'Discriminator loss 0.0356', 'Discriminator accuracy 0.9922', 'Total loss: 4.5263', 'for batch', 1)
('GAN loss 3.3218 ', 'GAN acc 0.0117', 'Discriminator loss 0.0506', 'Discriminator accuracy 0.9941', 'Total loss: 3.3724', 'for batch', 2)
('GAN loss 4.2341 ', 'GAN acc 0.0000', 'Discriminator loss 0.1153', 'Discriminator accuracy 0.9668', 'Total loss: 4.3494', 'for batch', 3)
('GAN loss 5.1426 ', 'GAN acc 0.0000', 'Discriminator loss 0.0480', 'Discriminator accuracy 0.9922', 'Total loss: 5.1906', 'for batch', 4)
('GAN loss 5.1268 ', 'GAN acc 0.0000', 'Discriminator loss 0.0749', 'Discriminator accuracy 0.9902', 'Total loss: 5.2018', 'for batch', 5)
('GAN loss 4.7268 ', 'GAN acc 0.0000', 'Discriminator loss 0.0767', 'Discriminator accuracy 0.9922', 'Total loss: 4.8034', 'for batch', 6)
('GAN loss 4.5660 ', 'GAN acc 0.0000', 'Discriminator loss 0.0353', 'Discriminator accuracy 0.9961', 'Total loss: 4.6013', 'for batch', 7)
('GAN loss 4.5046 ', 'GAN acc 0.0000', 'Discriminator loss 0.0513', 'Discriminator accuracy 0.9922', 'Total loss: 4.5559', 'for batch', 8)
('GAN loss 4.5864 ', 'GAN acc 0.0039', 'Discriminator loss 0.0223', 'Discriminator accuracy 0.9980', 'Total loss: 4.6088', 'for batch', 9)
('GAN loss 4.5967 ', 'GAN acc 0.0000', 'Discriminator loss 0.0333', 'Discriminator accuracy 0.9961', 'Total loss: 4.6300', 'for batch', 10)
('GAN loss 4.9176 ', 'GAN acc 0.0000', 'Discriminator loss 0.0777', 'Discriminator accuracy 0.9941', 'Total loss: 4.9953', 'for batch', 11)
('GAN loss 5.1849 ', 'GAN acc 0.0000', 'Discriminator loss 0.0443', 'Discriminator accuracy 0.9941', 'Total loss: 5.2292', 'for batch', 12)
('GAN loss 4.9501 ', 'GAN acc 0.0000', 'Discriminator loss 0.0350', 'Discriminator accuracy 0.9941', 'Total loss: 4.9851', 'for batch', 13)
('GAN loss 5.0318 ', 'GAN acc 0.0000', 'Discriminator loss 0.0262', 'Discriminator accuracy 0.9961', 'Total loss: 5.0580', 'for batch', 14)
('GAN loss 4.8273 ', 'GAN acc 0.0000', 'Discriminator loss 0.0354', 'Discriminator accuracy 0.9941', 'Total loss: 4.8627', 'for batch', 15)
('GAN loss 4.7944 ', 'GAN acc 0.0000', 'Discriminator loss 0.0373', 'Discriminator accuracy 0.9941', 'Total loss: 4.8317', 'for batch', 16)
('GAN loss 4.9866 ', 'GAN acc 0.0000', 'Discriminator loss 0.0373', 'Discriminator accuracy 0.9941', 'Total loss: 5.0239', 'for batch', 17)
('GAN loss 4.8836 ', 'GAN acc 0.0000', 'Discriminator loss 0.0188', 'Discriminator accuracy 0.9980', 'Total loss: 4.9024', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98874253)
('DISCRIMINATOR_Imagem FAKE=', 0.0049114074)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.280020')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 4.9018 ', 'GAN acc 0.0000', 'Discriminator loss 0.0175', 'Discriminator accuracy 0.9980', 'Total loss: 4.9194', 'for batch', 0)
('GAN loss 5.0908 ', 'GAN acc 0.0000', 'Discriminator loss 0.0467', 'Discriminator accuracy 0.9961', 'Total loss: 5.1376', 'for batch', 1)
('GAN loss 5.2433 ', 'GAN acc 0.0000', 'Discriminator loss 0.0815', 'Discriminator accuracy 0.9941', 'Total loss: 5.3249', 'for batch', 2)
('GAN loss 5.5080 ', 'GAN acc 0.0000', 'Discriminator loss 0.0292', 'Discriminator accuracy 0.9941', 'Total loss: 5.5371', 'for batch', 3)
('GAN loss 5.3690 ', 'GAN acc 0.0000', 'Discriminator loss 0.0404', 'Discriminator accuracy 0.9941', 'Total loss: 5.4094', 'for batch', 4)
('GAN loss 5.2699 ', 'GAN acc 0.0000', 'Discriminator loss 0.0527', 'Discriminator accuracy 0.9941', 'Total loss: 5.3226', 'for batch', 5)
('GAN loss 4.7335 ', 'GAN acc 0.0000', 'Discriminator loss 0.0732', 'Discriminator accuracy 0.9922', 'Total loss: 4.8067', 'for batch', 6)
('GAN loss 4.0433 ', 'GAN acc 0.0039', 'Discriminator loss 0.0494', 'Discriminator accuracy 0.9922', 'Total loss: 4.0927', 'for batch', 7)
('GAN loss 4.0612 ', 'GAN acc 0.0000', 'Discriminator loss 0.0477', 'Discriminator accuracy 0.9941', 'Total loss: 4.1090', 'for batch', 8)
('GAN loss 3.9286 ', 'GAN acc 0.0000', 'Discriminator loss 0.0200', 'Discriminator accuracy 0.9980', 'Total loss: 3.9486', 'for batch', 9)
('GAN loss 3.9778 ', 'GAN acc 0.0000', 'Discriminator loss 0.0427', 'Discriminator accuracy 0.9961', 'Total loss: 4.0205', 'for batch', 10)
('GAN loss 4.3231 ', 'GAN acc 0.0000', 'Discriminator loss 0.0217', 'Discriminator accuracy 0.9980', 'Total loss: 4.3448', 'for batch', 11)
('GAN loss 4.6595 ', 'GAN acc 0.0000', 'Discriminator loss 0.0386', 'Discriminator accuracy 0.9941', 'Total loss: 4.6981', 'for batch', 12)
('GAN loss 4.8754 ', 'GAN acc 0.0000', 'Discriminator loss 0.0311', 'Discriminator accuracy 0.9961', 'Total loss: 4.9065', 'for batch', 13)
('GAN loss 5.2713 ', 'GAN acc 0.0000', 'Discriminator loss 0.0081', 'Discriminator accuracy 1.0000', 'Total loss: 5.2794', 'for batch', 14)
('GAN loss 5.4135 ', 'GAN acc 0.0000', 'Discriminator loss 0.0295', 'Discriminator accuracy 0.9941', 'Total loss: 5.4430', 'for batch', 15)
('GAN loss 5.1870 ', 'GAN acc 0.0000', 'Discriminator loss 0.0535', 'Discriminator accuracy 0.9922', 'Total loss: 5.2405', 'for batch', 16)
('GAN loss 4.0069 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 0.9902', 'Total loss: 4.0679', 'for batch', 17)
('GAN loss 3.6503 ', 'GAN acc 0.0039', 'Discriminator loss 0.0358', 'Discriminator accuracy 0.9980', 'Total loss: 3.6861', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9928273)
('DISCRIMINATOR_Imagem FAKE=', 0.017635101)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.717977')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 4.1158 ', 'GAN acc 0.0000', 'Discriminator loss 0.0446', 'Discriminator accuracy 0.9961', 'Total loss: 4.1604', 'for batch', 0)
('GAN loss 3.4475 ', 'GAN acc 0.0000', 'Discriminator loss 0.0640', 'Discriminator accuracy 0.9922', 'Total loss: 3.5115', 'for batch', 1)
('GAN loss 3.8398 ', 'GAN acc 0.0000', 'Discriminator loss 0.0490', 'Discriminator accuracy 0.9941', 'Total loss: 3.8888', 'for batch', 2)
('GAN loss 4.4269 ', 'GAN acc 0.0000', 'Discriminator loss 0.0494', 'Discriminator accuracy 0.9941', 'Total loss: 4.4763', 'for batch', 3)
('GAN loss 5.0248 ', 'GAN acc 0.0000', 'Discriminator loss 0.0391', 'Discriminator accuracy 0.9941', 'Total loss: 5.0639', 'for batch', 4)
('GAN loss 5.3078 ', 'GAN acc 0.0000', 'Discriminator loss 0.0132', 'Discriminator accuracy 0.9961', 'Total loss: 5.3210', 'for batch', 5)
('GAN loss 4.8406 ', 'GAN acc 0.0000', 'Discriminator loss 0.0489', 'Discriminator accuracy 0.9922', 'Total loss: 4.8895', 'for batch', 6)
('GAN loss 5.0080 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9961', 'Total loss: 5.0394', 'for batch', 7)
('GAN loss 5.1153 ', 'GAN acc 0.0000', 'Discriminator loss 0.0415', 'Discriminator accuracy 0.9941', 'Total loss: 5.1569', 'for batch', 8)
('GAN loss 5.3758 ', 'GAN acc 0.0000', 'Discriminator loss 0.0068', 'Discriminator accuracy 1.0000', 'Total loss: 5.3826', 'for batch', 9)
('GAN loss 5.3403 ', 'GAN acc 0.0000', 'Discriminator loss 0.0264', 'Discriminator accuracy 0.9961', 'Total loss: 5.3667', 'for batch', 10)
('GAN loss 5.2691 ', 'GAN acc 0.0000', 'Discriminator loss 0.0106', 'Discriminator accuracy 0.9961', 'Total loss: 5.2797', 'for batch', 11)
('GAN loss 5.3075 ', 'GAN acc 0.0000', 'Discriminator loss 0.0338', 'Discriminator accuracy 0.9941', 'Total loss: 5.3412', 'for batch', 12)
('GAN loss 5.4138 ', 'GAN acc 0.0000', 'Discriminator loss 0.0263', 'Discriminator accuracy 0.9961', 'Total loss: 5.4401', 'for batch', 13)
('GAN loss 5.4141 ', 'GAN acc 0.0000', 'Discriminator loss 0.0109', 'Discriminator accuracy 0.9941', 'Total loss: 5.4249', 'for batch', 14)
('GAN loss 5.6114 ', 'GAN acc 0.0000', 'Discriminator loss 0.0578', 'Discriminator accuracy 0.9941', 'Total loss: 5.6692', 'for batch', 15)
('GAN loss 5.4719 ', 'GAN acc 0.0000', 'Discriminator loss 0.0429', 'Discriminator accuracy 0.9941', 'Total loss: 5.5148', 'for batch', 16)
('GAN loss 5.4489 ', 'GAN acc 0.0000', 'Discriminator loss 0.0333', 'Discriminator accuracy 0.9941', 'Total loss: 5.4823', 'for batch', 17)
('GAN loss 5.6279 ', 'GAN acc 0.0000', 'Discriminator loss 0.0182', 'Discriminator accuracy 0.9980', 'Total loss: 5.6462', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99040341)
('DISCRIMINATOR_Imagem FAKE=', 0.0022501645)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.278541')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 5.6091 ', 'GAN acc 0.0000', 'Discriminator loss 0.0159', 'Discriminator accuracy 0.9980', 'Total loss: 5.6249', 'for batch', 0)
('GAN loss 5.6954 ', 'GAN acc 0.0000', 'Discriminator loss 0.0229', 'Discriminator accuracy 0.9961', 'Total loss: 5.7183', 'for batch', 1)
('GAN loss 5.3580 ', 'GAN acc 0.0000', 'Discriminator loss 0.0191', 'Discriminator accuracy 0.9961', 'Total loss: 5.3771', 'for batch', 2)
('GAN loss 5.4129 ', 'GAN acc 0.0000', 'Discriminator loss 0.0289', 'Discriminator accuracy 0.9961', 'Total loss: 5.4418', 'for batch', 3)
('GAN loss 5.3848 ', 'GAN acc 0.0000', 'Discriminator loss 0.0313', 'Discriminator accuracy 0.9941', 'Total loss: 5.4160', 'for batch', 4)
('GAN loss 5.3515 ', 'GAN acc 0.0000', 'Discriminator loss 0.0345', 'Discriminator accuracy 0.9961', 'Total loss: 5.3860', 'for batch', 5)
('GAN loss 4.9631 ', 'GAN acc 0.0000', 'Discriminator loss 0.0263', 'Discriminator accuracy 0.9941', 'Total loss: 4.9893', 'for batch', 6)
('GAN loss 4.9005 ', 'GAN acc 0.0000', 'Discriminator loss 0.0325', 'Discriminator accuracy 0.9961', 'Total loss: 4.9330', 'for batch', 7)
('GAN loss 5.1808 ', 'GAN acc 0.0000', 'Discriminator loss 0.0333', 'Discriminator accuracy 0.9941', 'Total loss: 5.2141', 'for batch', 8)
('GAN loss 5.4156 ', 'GAN acc 0.0000', 'Discriminator loss 0.0057', 'Discriminator accuracy 1.0000', 'Total loss: 5.4213', 'for batch', 9)
('GAN loss 5.6293 ', 'GAN acc 0.0000', 'Discriminator loss 0.0250', 'Discriminator accuracy 0.9961', 'Total loss: 5.6543', 'for batch', 10)
('GAN loss 5.7240 ', 'GAN acc 0.0000', 'Discriminator loss 0.0045', 'Discriminator accuracy 1.0000', 'Total loss: 5.7284', 'for batch', 11)
('GAN loss 5.9202 ', 'GAN acc 0.0000', 'Discriminator loss 0.0282', 'Discriminator accuracy 0.9961', 'Total loss: 5.9484', 'for batch', 12)
('GAN loss 5.5417 ', 'GAN acc 0.0000', 'Discriminator loss 0.0278', 'Discriminator accuracy 0.9941', 'Total loss: 5.5696', 'for batch', 13)
('GAN loss 5.2931 ', 'GAN acc 0.0000', 'Discriminator loss 0.0104', 'Discriminator accuracy 0.9961', 'Total loss: 5.3035', 'for batch', 14)
('GAN loss 4.4183 ', 'GAN acc 0.0000', 'Discriminator loss 0.0443', 'Discriminator accuracy 0.9941', 'Total loss: 4.4626', 'for batch', 15)
('GAN loss 4.0784 ', 'GAN acc 0.0000', 'Discriminator loss 0.0367', 'Discriminator accuracy 0.9961', 'Total loss: 4.1152', 'for batch', 16)
('GAN loss 4.2019 ', 'GAN acc 0.0000', 'Discriminator loss 0.0447', 'Discriminator accuracy 0.9922', 'Total loss: 4.2466', 'for batch', 17)
('GAN loss 4.5685 ', 'GAN acc 0.0000', 'Discriminator loss 0.0301', 'Discriminator accuracy 0.9980', 'Total loss: 4.5986', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99322438)
('DISCRIMINATOR_Imagem FAKE=', 0.00525863)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.837933')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 4.9700 ', 'GAN acc 0.0000', 'Discriminator loss 0.0241', 'Discriminator accuracy 0.9980', 'Total loss: 4.9941', 'for batch', 0)
('GAN loss 5.4739 ', 'GAN acc 0.0000', 'Discriminator loss 0.0087', 'Discriminator accuracy 0.9980', 'Total loss: 5.4827', 'for batch', 1)
('GAN loss 5.6669 ', 'GAN acc 0.0000', 'Discriminator loss 0.0163', 'Discriminator accuracy 0.9980', 'Total loss: 5.6832', 'for batch', 2)
('GAN loss 5.9764 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9961', 'Total loss: 6.0047', 'for batch', 3)
('GAN loss 5.9913 ', 'GAN acc 0.0000', 'Discriminator loss 0.0297', 'Discriminator accuracy 0.9941', 'Total loss: 6.0210', 'for batch', 4)
('GAN loss 5.7500 ', 'GAN acc 0.0000', 'Discriminator loss 0.0470', 'Discriminator accuracy 0.9941', 'Total loss: 5.7970', 'for batch', 5)
('GAN loss 5.3672 ', 'GAN acc 0.0000', 'Discriminator loss 0.0379', 'Discriminator accuracy 0.9922', 'Total loss: 5.4051', 'for batch', 6)
('GAN loss 5.1513 ', 'GAN acc 0.0000', 'Discriminator loss 0.0249', 'Discriminator accuracy 0.9961', 'Total loss: 5.1762', 'for batch', 7)
('GAN loss 5.1513 ', 'GAN acc 0.0000', 'Discriminator loss 0.0322', 'Discriminator accuracy 0.9941', 'Total loss: 5.1835', 'for batch', 8)
('GAN loss 5.3446 ', 'GAN acc 0.0000', 'Discriminator loss 0.0058', 'Discriminator accuracy 1.0000', 'Total loss: 5.3504', 'for batch', 9)
('GAN loss 5.1406 ', 'GAN acc 0.0000', 'Discriminator loss 0.0249', 'Discriminator accuracy 0.9961', 'Total loss: 5.1655', 'for batch', 10)
('GAN loss 5.2225 ', 'GAN acc 0.0000', 'Discriminator loss 0.0084', 'Discriminator accuracy 0.9980', 'Total loss: 5.2310', 'for batch', 11)
('GAN loss 5.5644 ', 'GAN acc 0.0000', 'Discriminator loss 0.0287', 'Discriminator accuracy 0.9961', 'Total loss: 5.5931', 'for batch', 12)
('GAN loss 5.5076 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.5350', 'for batch', 13)
('GAN loss 5.5223 ', 'GAN acc 0.0000', 'Discriminator loss 0.0045', 'Discriminator accuracy 1.0000', 'Total loss: 5.5268', 'for batch', 14)
('GAN loss 5.6457 ', 'GAN acc 0.0000', 'Discriminator loss 0.0254', 'Discriminator accuracy 0.9961', 'Total loss: 5.6711', 'for batch', 15)
('GAN loss 5.5794 ', 'GAN acc 0.0000', 'Discriminator loss 0.0245', 'Discriminator accuracy 0.9961', 'Total loss: 5.6039', 'for batch', 16)
('GAN loss 5.6634 ', 'GAN acc 0.0000', 'Discriminator loss 0.0316', 'Discriminator accuracy 0.9941', 'Total loss: 5.6950', 'for batch', 17)
('GAN loss 5.4859 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.5006', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99119216)
('DISCRIMINATOR_Imagem FAKE=', 0.0029931741)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.263549')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 5.3644 ', 'GAN acc 0.0000', 'Discriminator loss 0.0145', 'Discriminator accuracy 0.9980', 'Total loss: 5.3789', 'for batch', 0)
('GAN loss 5.2893 ', 'GAN acc 0.0000', 'Discriminator loss 0.0392', 'Discriminator accuracy 0.9961', 'Total loss: 5.3286', 'for batch', 1)
('GAN loss 5.2803 ', 'GAN acc 0.0000', 'Discriminator loss 0.0475', 'Discriminator accuracy 0.9961', 'Total loss: 5.3278', 'for batch', 2)
('GAN loss 5.3343 ', 'GAN acc 0.0000', 'Discriminator loss 0.0249', 'Discriminator accuracy 0.9961', 'Total loss: 5.3591', 'for batch', 3)
('GAN loss 5.2241 ', 'GAN acc 0.0000', 'Discriminator loss 0.0292', 'Discriminator accuracy 0.9941', 'Total loss: 5.2533', 'for batch', 4)
('GAN loss 4.7477 ', 'GAN acc 0.0000', 'Discriminator loss 0.0403', 'Discriminator accuracy 0.9941', 'Total loss: 4.7879', 'for batch', 5)
('GAN loss 4.1860 ', 'GAN acc 0.0000', 'Discriminator loss 0.0316', 'Discriminator accuracy 0.9922', 'Total loss: 4.2176', 'for batch', 6)
('GAN loss 3.7760 ', 'GAN acc 0.0000', 'Discriminator loss 0.0354', 'Discriminator accuracy 0.9961', 'Total loss: 3.8114', 'for batch', 7)
('GAN loss 3.8393 ', 'GAN acc 0.0000', 'Discriminator loss 0.0434', 'Discriminator accuracy 0.9941', 'Total loss: 3.8827', 'for batch', 8)
('GAN loss 3.8981 ', 'GAN acc 0.0000', 'Discriminator loss 0.0218', 'Discriminator accuracy 1.0000', 'Total loss: 3.9199', 'for batch', 9)
('GAN loss 4.2762 ', 'GAN acc 0.0000', 'Discriminator loss 0.0348', 'Discriminator accuracy 0.9961', 'Total loss: 4.3109', 'for batch', 10)
('GAN loss 4.3137 ', 'GAN acc 0.0000', 'Discriminator loss 0.0278', 'Discriminator accuracy 0.9980', 'Total loss: 4.3415', 'for batch', 11)
('GAN loss 4.4636 ', 'GAN acc 0.0000', 'Discriminator loss 0.0332', 'Discriminator accuracy 0.9961', 'Total loss: 4.4968', 'for batch', 12)
('GAN loss 4.5370 ', 'GAN acc 0.0000', 'Discriminator loss 0.0332', 'Discriminator accuracy 0.9961', 'Total loss: 4.5702', 'for batch', 13)
('GAN loss 4.7086 ', 'GAN acc 0.0000', 'Discriminator loss 0.0113', 'Discriminator accuracy 0.9980', 'Total loss: 4.7199', 'for batch', 14)
('GAN loss 4.6985 ', 'GAN acc 0.0000', 'Discriminator loss 0.0332', 'Discriminator accuracy 0.9941', 'Total loss: 4.7317', 'for batch', 15)
('GAN loss 4.7223 ', 'GAN acc 0.0000', 'Discriminator loss 0.0287', 'Discriminator accuracy 0.9961', 'Total loss: 4.7511', 'for batch', 16)
('GAN loss 4.8090 ', 'GAN acc 0.0000', 'Discriminator loss 0.0383', 'Discriminator accuracy 0.9922', 'Total loss: 4.8473', 'for batch', 17)
('GAN loss 4.8432 ', 'GAN acc 0.0000', 'Discriminator loss 0.0182', 'Discriminator accuracy 0.9980', 'Total loss: 4.8614', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99175841)
('DISCRIMINATOR_Imagem FAKE=', 0.0071443082)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.755513')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 4.4566 ', 'GAN acc 0.0000', 'Discriminator loss 0.0266', 'Discriminator accuracy 0.9961', 'Total loss: 4.4832', 'for batch', 0)
('GAN loss 4.4503 ', 'GAN acc 0.0000', 'Discriminator loss 0.0103', 'Discriminator accuracy 0.9980', 'Total loss: 4.4607', 'for batch', 1)
('GAN loss 4.3530 ', 'GAN acc 0.0000', 'Discriminator loss 0.0229', 'Discriminator accuracy 0.9980', 'Total loss: 4.3759', 'for batch', 2)
('GAN loss 4.4076 ', 'GAN acc 0.0000', 'Discriminator loss 0.0326', 'Discriminator accuracy 0.9961', 'Total loss: 4.4402', 'for batch', 3)
('GAN loss 4.4241 ', 'GAN acc 0.0000', 'Discriminator loss 0.0423', 'Discriminator accuracy 0.9941', 'Total loss: 4.4664', 'for batch', 4)
('GAN loss 4.4782 ', 'GAN acc 0.0000', 'Discriminator loss 0.0129', 'Discriminator accuracy 0.9980', 'Total loss: 4.4910', 'for batch', 5)
('GAN loss 4.2232 ', 'GAN acc 0.0000', 'Discriminator loss 0.0284', 'Discriminator accuracy 0.9961', 'Total loss: 4.2515', 'for batch', 6)
('GAN loss 4.2451 ', 'GAN acc 0.0000', 'Discriminator loss 0.0361', 'Discriminator accuracy 0.9961', 'Total loss: 4.2812', 'for batch', 7)
('GAN loss 4.5707 ', 'GAN acc 0.0000', 'Discriminator loss 0.0456', 'Discriminator accuracy 0.9941', 'Total loss: 4.6163', 'for batch', 8)
('GAN loss 4.7120 ', 'GAN acc 0.0000', 'Discriminator loss 0.0111', 'Discriminator accuracy 1.0000', 'Total loss: 4.7231', 'for batch', 9)
('GAN loss 4.9533 ', 'GAN acc 0.0000', 'Discriminator loss 0.0262', 'Discriminator accuracy 0.9961', 'Total loss: 4.9795', 'for batch', 10)
('GAN loss 5.0610 ', 'GAN acc 0.0000', 'Discriminator loss 0.0082', 'Discriminator accuracy 0.9980', 'Total loss: 5.0692', 'for batch', 11)
('GAN loss 5.2438 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.2712', 'for batch', 12)
('GAN loss 5.2559 ', 'GAN acc 0.0000', 'Discriminator loss 0.0303', 'Discriminator accuracy 0.9961', 'Total loss: 5.2862', 'for batch', 13)
('GAN loss 5.3425 ', 'GAN acc 0.0000', 'Discriminator loss 0.0090', 'Discriminator accuracy 0.9980', 'Total loss: 5.3515', 'for batch', 14)
('GAN loss 5.3273 ', 'GAN acc 0.0000', 'Discriminator loss 0.0272', 'Discriminator accuracy 0.9961', 'Total loss: 5.3545', 'for batch', 15)
('GAN loss 5.3775 ', 'GAN acc 0.0000', 'Discriminator loss 0.0328', 'Discriminator accuracy 0.9941', 'Total loss: 5.4102', 'for batch', 16)
('GAN loss 5.4025 ', 'GAN acc 0.0000', 'Discriminator loss 0.0367', 'Discriminator accuracy 0.9941', 'Total loss: 5.4392', 'for batch', 17)
('GAN loss 5.3688 ', 'GAN acc 0.0000', 'Discriminator loss 0.0174', 'Discriminator accuracy 0.9980', 'Total loss: 5.3862', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9930284)
('DISCRIMINATOR_Imagem FAKE=', 0.0031833616)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.256700')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 5.4339 ', 'GAN acc 0.0000', 'Discriminator loss 0.0149', 'Discriminator accuracy 0.9980', 'Total loss: 5.4488', 'for batch', 0)
('GAN loss 5.5116 ', 'GAN acc 0.0000', 'Discriminator loss 0.0129', 'Discriminator accuracy 0.9980', 'Total loss: 5.5245', 'for batch', 1)
('GAN loss 5.4830 ', 'GAN acc 0.0000', 'Discriminator loss 0.0144', 'Discriminator accuracy 0.9980', 'Total loss: 5.4974', 'for batch', 2)
('GAN loss 5.6031 ', 'GAN acc 0.0000', 'Discriminator loss 0.0259', 'Discriminator accuracy 0.9941', 'Total loss: 5.6290', 'for batch', 3)
('GAN loss 5.5941 ', 'GAN acc 0.0000', 'Discriminator loss 0.0284', 'Discriminator accuracy 0.9941', 'Total loss: 5.6224', 'for batch', 4)
('GAN loss 5.4911 ', 'GAN acc 0.0000', 'Discriminator loss 0.0035', 'Discriminator accuracy 1.0000', 'Total loss: 5.4946', 'for batch', 5)
('GAN loss 5.4393 ', 'GAN acc 0.0000', 'Discriminator loss 0.0292', 'Discriminator accuracy 0.9961', 'Total loss: 5.4685', 'for batch', 6)
('GAN loss 5.4383 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9961', 'Total loss: 5.4666', 'for batch', 7)
('GAN loss 5.3265 ', 'GAN acc 0.0000', 'Discriminator loss 0.0393', 'Discriminator accuracy 0.9941', 'Total loss: 5.3658', 'for batch', 8)
('GAN loss 5.3322 ', 'GAN acc 0.0000', 'Discriminator loss 0.0037', 'Discriminator accuracy 1.0000', 'Total loss: 5.3359', 'for batch', 9)
('GAN loss 5.3397 ', 'GAN acc 0.0000', 'Discriminator loss 0.0257', 'Discriminator accuracy 0.9961', 'Total loss: 5.3654', 'for batch', 10)
('GAN loss 5.3141 ', 'GAN acc 0.0000', 'Discriminator loss 0.0069', 'Discriminator accuracy 0.9980', 'Total loss: 5.3209', 'for batch', 11)
('GAN loss 5.3743 ', 'GAN acc 0.0000', 'Discriminator loss 0.0305', 'Discriminator accuracy 0.9961', 'Total loss: 5.4048', 'for batch', 12)
('GAN loss 5.4119 ', 'GAN acc 0.0000', 'Discriminator loss 0.0289', 'Discriminator accuracy 0.9961', 'Total loss: 5.4408', 'for batch', 13)
('GAN loss 5.3963 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 1.0000', 'Total loss: 5.4001', 'for batch', 14)
('GAN loss 5.4305 ', 'GAN acc 0.0000', 'Discriminator loss 0.0272', 'Discriminator accuracy 0.9961', 'Total loss: 5.4577', 'for batch', 15)
('GAN loss 5.3445 ', 'GAN acc 0.0000', 'Discriminator loss 0.0289', 'Discriminator accuracy 0.9961', 'Total loss: 5.3734', 'for batch', 16)
('GAN loss 5.1928 ', 'GAN acc 0.0000', 'Discriminator loss 0.0435', 'Discriminator accuracy 0.9922', 'Total loss: 5.2363', 'for batch', 17)
('GAN loss 5.2548 ', 'GAN acc 0.0000', 'Discriminator loss 0.0161', 'Discriminator accuracy 0.9980', 'Total loss: 5.2709', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99243939)
('DISCRIMINATOR_Imagem FAKE=', 0.003594955)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.806631')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2093 ', 'GAN acc 0.0000', 'Discriminator loss 0.0164', 'Discriminator accuracy 0.9980', 'Total loss: 5.2257', 'for batch', 0)
('GAN loss 5.4619 ', 'GAN acc 0.0000', 'Discriminator loss 0.0056', 'Discriminator accuracy 0.9980', 'Total loss: 5.4675', 'for batch', 1)
('GAN loss 5.2458 ', 'GAN acc 0.0000', 'Discriminator loss 0.0144', 'Discriminator accuracy 0.9980', 'Total loss: 5.2602', 'for batch', 2)
('GAN loss 5.4055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0250', 'Discriminator accuracy 0.9961', 'Total loss: 5.4304', 'for batch', 3)
('GAN loss 5.4126 ', 'GAN acc 0.0000', 'Discriminator loss 0.0311', 'Discriminator accuracy 0.9941', 'Total loss: 5.4436', 'for batch', 4)
('GAN loss 5.3913 ', 'GAN acc 0.0000', 'Discriminator loss 0.0124', 'Discriminator accuracy 0.9980', 'Total loss: 5.4037', 'for batch', 5)
('GAN loss 5.1530 ', 'GAN acc 0.0000', 'Discriminator loss 0.0209', 'Discriminator accuracy 0.9941', 'Total loss: 5.1739', 'for batch', 6)
('GAN loss 5.1555 ', 'GAN acc 0.0000', 'Discriminator loss 0.0345', 'Discriminator accuracy 0.9941', 'Total loss: 5.1899', 'for batch', 7)
('GAN loss 5.1513 ', 'GAN acc 0.0000', 'Discriminator loss 0.0360', 'Discriminator accuracy 0.9941', 'Total loss: 5.1873', 'for batch', 8)
('GAN loss 5.1239 ', 'GAN acc 0.0000', 'Discriminator loss 0.0057', 'Discriminator accuracy 1.0000', 'Total loss: 5.1297', 'for batch', 9)
('GAN loss 5.2469 ', 'GAN acc 0.0000', 'Discriminator loss 0.0221', 'Discriminator accuracy 0.9961', 'Total loss: 5.2691', 'for batch', 10)
('GAN loss 5.5088 ', 'GAN acc 0.0000', 'Discriminator loss 0.0107', 'Discriminator accuracy 0.9980', 'Total loss: 5.5195', 'for batch', 11)
('GAN loss 5.4310 ', 'GAN acc 0.0000', 'Discriminator loss 0.0306', 'Discriminator accuracy 0.9941', 'Total loss: 5.4616', 'for batch', 12)
('GAN loss 5.4020 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9961', 'Total loss: 5.4302', 'for batch', 13)
('GAN loss 5.5659 ', 'GAN acc 0.0000', 'Discriminator loss 0.0076', 'Discriminator accuracy 0.9980', 'Total loss: 5.5734', 'for batch', 14)
('GAN loss 5.6023 ', 'GAN acc 0.0000', 'Discriminator loss 0.0284', 'Discriminator accuracy 0.9961', 'Total loss: 5.6307', 'for batch', 15)
('GAN loss 5.5843 ', 'GAN acc 0.0000', 'Discriminator loss 0.0428', 'Discriminator accuracy 0.9941', 'Total loss: 5.6271', 'for batch', 16)
('GAN loss 5.4072 ', 'GAN acc 0.0000', 'Discriminator loss 0.0337', 'Discriminator accuracy 0.9922', 'Total loss: 5.4409', 'for batch', 17)
('GAN loss 5.3692 ', 'GAN acc 0.0000', 'Discriminator loss 0.0156', 'Discriminator accuracy 0.9980', 'Total loss: 5.3848', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99217504)
('DISCRIMINATOR_Imagem FAKE=', 0.0034237339)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.759360')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 4.7883 ', 'GAN acc 0.0000', 'Discriminator loss 0.0347', 'Discriminator accuracy 0.9961', 'Total loss: 4.8230', 'for batch', 0)
('GAN loss 4.7983 ', 'GAN acc 0.0000', 'Discriminator loss 0.0077', 'Discriminator accuracy 1.0000', 'Total loss: 4.8060', 'for batch', 1)
('GAN loss 4.7686 ', 'GAN acc 0.0000', 'Discriminator loss 0.0202', 'Discriminator accuracy 0.9980', 'Total loss: 4.7889', 'for batch', 2)
('GAN loss 4.7346 ', 'GAN acc 0.0000', 'Discriminator loss 0.0343', 'Discriminator accuracy 0.9961', 'Total loss: 4.7689', 'for batch', 3)
('GAN loss 4.9636 ', 'GAN acc 0.0000', 'Discriminator loss 0.0350', 'Discriminator accuracy 0.9941', 'Total loss: 4.9985', 'for batch', 4)
('GAN loss 5.0945 ', 'GAN acc 0.0000', 'Discriminator loss 0.0125', 'Discriminator accuracy 0.9961', 'Total loss: 5.1070', 'for batch', 5)
('GAN loss 5.1105 ', 'GAN acc 0.0000', 'Discriminator loss 0.0202', 'Discriminator accuracy 0.9980', 'Total loss: 5.1307', 'for batch', 6)
('GAN loss 5.2661 ', 'GAN acc 0.0000', 'Discriminator loss 0.0281', 'Discriminator accuracy 0.9961', 'Total loss: 5.2942', 'for batch', 7)
('GAN loss 5.6044 ', 'GAN acc 0.0000', 'Discriminator loss 0.0412', 'Discriminator accuracy 0.9941', 'Total loss: 5.6456', 'for batch', 8)
('GAN loss 5.5605 ', 'GAN acc 0.0000', 'Discriminator loss 0.0045', 'Discriminator accuracy 1.0000', 'Total loss: 5.5649', 'for batch', 9)
('GAN loss 5.6684 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.6932', 'for batch', 10)
('GAN loss 5.8869 ', 'GAN acc 0.0000', 'Discriminator loss 0.0050', 'Discriminator accuracy 0.9980', 'Total loss: 5.8919', 'for batch', 11)
('GAN loss 5.8531 ', 'GAN acc 0.0000', 'Discriminator loss 0.0275', 'Discriminator accuracy 0.9961', 'Total loss: 5.8806', 'for batch', 12)
('GAN loss 5.8314 ', 'GAN acc 0.0000', 'Discriminator loss 0.0302', 'Discriminator accuracy 0.9941', 'Total loss: 5.8616', 'for batch', 13)
('GAN loss 5.7135 ', 'GAN acc 0.0000', 'Discriminator loss 0.0049', 'Discriminator accuracy 0.9980', 'Total loss: 5.7184', 'for batch', 14)
('GAN loss 5.8172 ', 'GAN acc 0.0000', 'Discriminator loss 0.0240', 'Discriminator accuracy 0.9961', 'Total loss: 5.8412', 'for batch', 15)
('GAN loss 5.8862 ', 'GAN acc 0.0000', 'Discriminator loss 0.0275', 'Discriminator accuracy 0.9961', 'Total loss: 5.9136', 'for batch', 16)
('GAN loss 4.6846 ', 'GAN acc 0.0000', 'Discriminator loss 0.0450', 'Discriminator accuracy 0.9922', 'Total loss: 4.7296', 'for batch', 17)
('GAN loss 4.4911 ', 'GAN acc 0.0000', 'Discriminator loss 0.0199', 'Discriminator accuracy 0.9980', 'Total loss: 4.5110', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99526232)
('DISCRIMINATOR_Imagem FAKE=', 0.010329343)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.309454')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 4.3392 ', 'GAN acc 0.0039', 'Discriminator loss 0.0314', 'Discriminator accuracy 0.9980', 'Total loss: 4.3706', 'for batch', 0)
('GAN loss 4.8446 ', 'GAN acc 0.0000', 'Discriminator loss 0.0190', 'Discriminator accuracy 0.9980', 'Total loss: 4.8636', 'for batch', 1)
('GAN loss 5.1529 ', 'GAN acc 0.0000', 'Discriminator loss 0.0206', 'Discriminator accuracy 0.9980', 'Total loss: 5.1735', 'for batch', 2)
('GAN loss 5.3919 ', 'GAN acc 0.0000', 'Discriminator loss 0.0305', 'Discriminator accuracy 0.9961', 'Total loss: 5.4224', 'for batch', 3)
('GAN loss 5.7161 ', 'GAN acc 0.0000', 'Discriminator loss 0.0286', 'Discriminator accuracy 0.9941', 'Total loss: 5.7447', 'for batch', 4)
('GAN loss 5.6398 ', 'GAN acc 0.0000', 'Discriminator loss 0.0385', 'Discriminator accuracy 0.9961', 'Total loss: 5.6783', 'for batch', 5)
('GAN loss 5.7973 ', 'GAN acc 0.0000', 'Discriminator loss 0.0158', 'Discriminator accuracy 0.9980', 'Total loss: 5.8131', 'for batch', 6)
('GAN loss 5.6592 ', 'GAN acc 0.0000', 'Discriminator loss 0.0262', 'Discriminator accuracy 0.9961', 'Total loss: 5.6854', 'for batch', 7)
('GAN loss 5.8171 ', 'GAN acc 0.0000', 'Discriminator loss 0.0400', 'Discriminator accuracy 0.9941', 'Total loss: 5.8571', 'for batch', 8)
('GAN loss 5.8919 ', 'GAN acc 0.0000', 'Discriminator loss 0.0029', 'Discriminator accuracy 1.0000', 'Total loss: 5.8949', 'for batch', 9)
('GAN loss 5.8298 ', 'GAN acc 0.0000', 'Discriminator loss 0.0208', 'Discriminator accuracy 0.9961', 'Total loss: 5.8505', 'for batch', 10)
('GAN loss 5.7836 ', 'GAN acc 0.0000', 'Discriminator loss 0.0417', 'Discriminator accuracy 0.9961', 'Total loss: 5.8253', 'for batch', 11)
('GAN loss 5.5467 ', 'GAN acc 0.0000', 'Discriminator loss 0.0347', 'Discriminator accuracy 0.9922', 'Total loss: 5.5814', 'for batch', 12)
('GAN loss 5.4590 ', 'GAN acc 0.0000', 'Discriminator loss 0.0288', 'Discriminator accuracy 0.9961', 'Total loss: 5.4879', 'for batch', 13)
('GAN loss 5.5432 ', 'GAN acc 0.0000', 'Discriminator loss 0.0044', 'Discriminator accuracy 1.0000', 'Total loss: 5.5477', 'for batch', 14)
('GAN loss 5.6357 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9961', 'Total loss: 5.6637', 'for batch', 15)
('GAN loss 5.6975 ', 'GAN acc 0.0000', 'Discriminator loss 0.0251', 'Discriminator accuracy 0.9961', 'Total loss: 5.7226', 'for batch', 16)
('GAN loss 5.7428 ', 'GAN acc 0.0000', 'Discriminator loss 0.0270', 'Discriminator accuracy 0.9941', 'Total loss: 5.7698', 'for batch', 17)
('GAN loss 5.9191 ', 'GAN acc 0.0000', 'Discriminator loss 0.0167', 'Discriminator accuracy 0.9980', 'Total loss: 5.9358', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99223644)
('DISCRIMINATOR_Imagem FAKE=', 0.001762235)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.740950')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 5.8789 ', 'GAN acc 0.0000', 'Discriminator loss 0.0133', 'Discriminator accuracy 0.9980', 'Total loss: 5.8923', 'for batch', 0)
('GAN loss 5.9963 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 0.9980', 'Total loss: 6.0002', 'for batch', 1)
('GAN loss 5.9486 ', 'GAN acc 0.0000', 'Discriminator loss 0.0134', 'Discriminator accuracy 0.9980', 'Total loss: 5.9620', 'for batch', 2)
('GAN loss 5.2907 ', 'GAN acc 0.0000', 'Discriminator loss 0.0528', 'Discriminator accuracy 0.9922', 'Total loss: 5.3435', 'for batch', 3)
('GAN loss 5.1376 ', 'GAN acc 0.0000', 'Discriminator loss 0.0369', 'Discriminator accuracy 0.9941', 'Total loss: 5.1744', 'for batch', 4)
('GAN loss 5.1744 ', 'GAN acc 0.0000', 'Discriminator loss 0.0056', 'Discriminator accuracy 1.0000', 'Total loss: 5.1800', 'for batch', 5)
('GAN loss 4.9860 ', 'GAN acc 0.0000', 'Discriminator loss 0.0209', 'Discriminator accuracy 0.9961', 'Total loss: 5.0069', 'for batch', 6)
('GAN loss 5.1301 ', 'GAN acc 0.0000', 'Discriminator loss 0.0308', 'Discriminator accuracy 0.9961', 'Total loss: 5.1609', 'for batch', 7)
('GAN loss 5.2249 ', 'GAN acc 0.0000', 'Discriminator loss 0.0370', 'Discriminator accuracy 0.9941', 'Total loss: 5.2619', 'for batch', 8)
('GAN loss 5.4575 ', 'GAN acc 0.0000', 'Discriminator loss 0.0047', 'Discriminator accuracy 1.0000', 'Total loss: 5.4623', 'for batch', 9)
('GAN loss 5.5192 ', 'GAN acc 0.0000', 'Discriminator loss 0.0224', 'Discriminator accuracy 0.9961', 'Total loss: 5.5416', 'for batch', 10)
('GAN loss 5.7363 ', 'GAN acc 0.0000', 'Discriminator loss 0.0077', 'Discriminator accuracy 0.9980', 'Total loss: 5.7440', 'for batch', 11)
('GAN loss 5.9170 ', 'GAN acc 0.0000', 'Discriminator loss 0.0269', 'Discriminator accuracy 0.9961', 'Total loss: 5.9438', 'for batch', 12)
('GAN loss 5.8899 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9961', 'Total loss: 5.9165', 'for batch', 13)
('GAN loss 5.9666 ', 'GAN acc 0.0000', 'Discriminator loss 0.0094', 'Discriminator accuracy 0.9980', 'Total loss: 5.9760', 'for batch', 14)
('GAN loss 5.9867 ', 'GAN acc 0.0000', 'Discriminator loss 0.0234', 'Discriminator accuracy 0.9961', 'Total loss: 6.0100', 'for batch', 15)
('GAN loss 5.9874 ', 'GAN acc 0.0000', 'Discriminator loss 0.0245', 'Discriminator accuracy 0.9961', 'Total loss: 6.0119', 'for batch', 16)
('GAN loss 6.0565 ', 'GAN acc 0.0000', 'Discriminator loss 0.0323', 'Discriminator accuracy 0.9941', 'Total loss: 6.0888', 'for batch', 17)
('GAN loss 5.8482 ', 'GAN acc 0.0000', 'Discriminator loss 0.0145', 'Discriminator accuracy 0.9980', 'Total loss: 5.8627', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99262559)
('DISCRIMINATOR_Imagem FAKE=', 0.0016556295)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.257784')
----------------------------------
('Epoch', 34, 'of', 50)
('Number of batches', 19)
('GAN loss 6.0185 ', 'GAN acc 0.0000', 'Discriminator loss 0.0154', 'Discriminator accuracy 0.9980', 'Total loss: 6.0339', 'for batch', 0)
('GAN loss 6.0784 ', 'GAN acc 0.0000', 'Discriminator loss 0.0025', 'Discriminator accuracy 1.0000', 'Total loss: 6.0809', 'for batch', 1)
('GAN loss 5.6931 ', 'GAN acc 0.0000', 'Discriminator loss 0.0229', 'Discriminator accuracy 0.9961', 'Total loss: 5.7160', 'for batch', 2)
('GAN loss 5.5424 ', 'GAN acc 0.0000', 'Discriminator loss 0.0282', 'Discriminator accuracy 0.9961', 'Total loss: 5.5706', 'for batch', 3)
('GAN loss 5.5186 ', 'GAN acc 0.0000', 'Discriminator loss 0.0344', 'Discriminator accuracy 0.9922', 'Total loss: 5.5529', 'for batch', 4)
('GAN loss 5.4414 ', 'GAN acc 0.0000', 'Discriminator loss 0.0040', 'Discriminator accuracy 1.0000', 'Total loss: 5.4454', 'for batch', 5)
('GAN loss 5.2757 ', 'GAN acc 0.0000', 'Discriminator loss 0.0261', 'Discriminator accuracy 0.9961', 'Total loss: 5.3018', 'for batch', 6)
('GAN loss 5.2819 ', 'GAN acc 0.0000', 'Discriminator loss 0.0285', 'Discriminator accuracy 0.9961', 'Total loss: 5.3104', 'for batch', 7)
('GAN loss 5.2941 ', 'GAN acc 0.0000', 'Discriminator loss 0.0381', 'Discriminator accuracy 0.9941', 'Total loss: 5.3323', 'for batch', 8)
('GAN loss 5.2756 ', 'GAN acc 0.0000', 'Discriminator loss 0.0043', 'Discriminator accuracy 1.0000', 'Total loss: 5.2799', 'for batch', 9)
('GAN loss 5.3706 ', 'GAN acc 0.0000', 'Discriminator loss 0.0225', 'Discriminator accuracy 0.9961', 'Total loss: 5.3931', 'for batch', 10)
('GAN loss 5.1594 ', 'GAN acc 0.0000', 'Discriminator loss 0.0223', 'Discriminator accuracy 0.9961', 'Total loss: 5.1817', 'for batch', 11)
('GAN loss 5.1707 ', 'GAN acc 0.0000', 'Discriminator loss 0.0290', 'Discriminator accuracy 0.9961', 'Total loss: 5.1997', 'for batch', 12)
('GAN loss 5.1450 ', 'GAN acc 0.0000', 'Discriminator loss 0.0265', 'Discriminator accuracy 0.9961', 'Total loss: 5.1715', 'for batch', 13)
('GAN loss 5.3057 ', 'GAN acc 0.0000', 'Discriminator loss 0.0044', 'Discriminator accuracy 1.0000', 'Total loss: 5.3101', 'for batch', 14)
('GAN loss 5.6020 ', 'GAN acc 0.0000', 'Discriminator loss 0.0253', 'Discriminator accuracy 0.9961', 'Total loss: 5.6273', 'for batch', 15)
('GAN loss 5.4760 ', 'GAN acc 0.0000', 'Discriminator loss 0.0317', 'Discriminator accuracy 0.9941', 'Total loss: 5.5076', 'for batch', 16)
('GAN loss 5.4310 ', 'GAN acc 0.0000', 'Discriminator loss 0.0268', 'Discriminator accuracy 0.9941', 'Total loss: 5.4578', 'for batch', 17)
('GAN loss 5.5685 ', 'GAN acc 0.0000', 'Discriminator loss 0.0133', 'Discriminator accuracy 0.9980', 'Total loss: 5.5818', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99357617)
('DISCRIMINATOR_Imagem FAKE=', 0.0027132302)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.734569')
----------------------------------
('Epoch', 35, 'of', 50)
('Number of batches', 19)
('GAN loss 5.5723 ', 'GAN acc 0.0000', 'Discriminator loss 0.0164', 'Discriminator accuracy 0.9980', 'Total loss: 5.5887', 'for batch', 0)
('GAN loss 5.7342 ', 'GAN acc 0.0000', 'Discriminator loss 0.0070', 'Discriminator accuracy 0.9980', 'Total loss: 5.7412', 'for batch', 1)
('GAN loss 5.8224 ', 'GAN acc 0.0000', 'Discriminator loss 0.0136', 'Discriminator accuracy 0.9980', 'Total loss: 5.8359', 'for batch', 2)
('GAN loss 5.9017 ', 'GAN acc 0.0000', 'Discriminator loss 0.0241', 'Discriminator accuracy 0.9961', 'Total loss: 5.9258', 'for batch', 3)
('GAN loss 5.8167 ', 'GAN acc 0.0000', 'Discriminator loss 0.0290', 'Discriminator accuracy 0.9941', 'Total loss: 5.8458', 'for batch', 4)
('GAN loss 5.5731 ', 'GAN acc 0.0000', 'Discriminator loss 0.0130', 'Discriminator accuracy 0.9961', 'Total loss: 5.5860', 'for batch', 5)
('GAN loss 5.4981 ', 'GAN acc 0.0000', 'Discriminator loss 0.0162', 'Discriminator accuracy 0.9980', 'Total loss: 5.5143', 'for batch', 6)
('GAN loss 5.5916 ', 'GAN acc 0.0000', 'Discriminator loss 0.0247', 'Discriminator accuracy 0.9961', 'Total loss: 5.6163', 'for batch', 7)
('GAN loss 5.3553 ', 'GAN acc 0.0000', 'Discriminator loss 0.0348', 'Discriminator accuracy 0.9941', 'Total loss: 5.3901', 'for batch', 8)
('GAN loss 5.5202 ', 'GAN acc 0.0000', 'Discriminator loss 0.0037', 'Discriminator accuracy 1.0000', 'Total loss: 5.5239', 'for batch', 9)
('GAN loss 5.4253 ', 'GAN acc 0.0000', 'Discriminator loss 0.0212', 'Discriminator accuracy 0.9961', 'Total loss: 5.4464', 'for batch', 10)
('GAN loss 5.4830 ', 'GAN acc 0.0000', 'Discriminator loss 0.0053', 'Discriminator accuracy 0.9980', 'Total loss: 5.4884', 'for batch', 11)
('GAN loss 5.5746 ', 'GAN acc 0.0000', 'Discriminator loss 0.0229', 'Discriminator accuracy 0.9961', 'Total loss: 5.5975', 'for batch', 12)
('GAN loss 5.4161 ', 'GAN acc 0.0000', 'Discriminator loss 0.0271', 'Discriminator accuracy 0.9961', 'Total loss: 5.4432', 'for batch', 13)
('GAN loss 5.4200 ', 'GAN acc 0.0000', 'Discriminator loss 0.0030', 'Discriminator accuracy 1.0000', 'Total loss: 5.4230', 'for batch', 14)
('GAN loss 5.3847 ', 'GAN acc 0.0000', 'Discriminator loss 0.0245', 'Discriminator accuracy 0.9961', 'Total loss: 5.4092', 'for batch', 15)
('GAN loss 5.3229 ', 'GAN acc 0.0000', 'Discriminator loss 0.0240', 'Discriminator accuracy 0.9961', 'Total loss: 5.3469', 'for batch', 16)
('GAN loss 5.3833 ', 'GAN acc 0.0000', 'Discriminator loss 0.0273', 'Discriminator accuracy 0.9941', 'Total loss: 5.4106', 'for batch', 17)
('GAN loss 5.3662 ', 'GAN acc 0.0000', 'Discriminator loss 0.0146', 'Discriminator accuracy 0.9980', 'Total loss: 5.3809', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99309611)
('DISCRIMINATOR_Imagem FAKE=', 0.0036666922)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.324316')
----------------------------------
('Epoch', 36, 'of', 50)
('Number of batches', 19)
('GAN loss 5.3841 ', 'GAN acc 0.0000', 'Discriminator loss 0.0150', 'Discriminator accuracy 0.9980', 'Total loss: 5.3991', 'for batch', 0)
('GAN loss 5.0722 ', 'GAN acc 0.0000', 'Discriminator loss 0.0119', 'Discriminator accuracy 0.9961', 'Total loss: 5.0841', 'for batch', 1)
('GAN loss 5.0091 ', 'GAN acc 0.0000', 'Discriminator loss 0.0149', 'Discriminator accuracy 0.9980', 'Total loss: 5.0240', 'for batch', 2)
('GAN loss 4.8670 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9961', 'Total loss: 4.8925', 'for batch', 3)
('GAN loss 4.6641 ', 'GAN acc 0.0000', 'Discriminator loss 0.0281', 'Discriminator accuracy 0.9941', 'Total loss: 4.6922', 'for batch', 4)
('GAN loss 4.4676 ', 'GAN acc 0.0000', 'Discriminator loss 0.0113', 'Discriminator accuracy 0.9980', 'Total loss: 4.4789', 'for batch', 5)
('GAN loss 4.4032 ', 'GAN acc 0.0000', 'Discriminator loss 0.0302', 'Discriminator accuracy 0.9961', 'Total loss: 4.4334', 'for batch', 6)
('GAN loss 4.3658 ', 'GAN acc 0.0000', 'Discriminator loss 0.0316', 'Discriminator accuracy 0.9961', 'Total loss: 4.3975', 'for batch', 7)
('GAN loss 4.3662 ', 'GAN acc 0.0000', 'Discriminator loss 0.0339', 'Discriminator accuracy 0.9941', 'Total loss: 4.4002', 'for batch', 8)
('GAN loss 4.3781 ', 'GAN acc 0.0000', 'Discriminator loss 0.0093', 'Discriminator accuracy 1.0000', 'Total loss: 4.3874', 'for batch', 9)
('GAN loss 4.4365 ', 'GAN acc 0.0000', 'Discriminator loss 0.0253', 'Discriminator accuracy 0.9961', 'Total loss: 4.4619', 'for batch', 10)
('GAN loss 4.4946 ', 'GAN acc 0.0000', 'Discriminator loss 0.0146', 'Discriminator accuracy 0.9980', 'Total loss: 4.5092', 'for batch', 11)
('GAN loss 4.6534 ', 'GAN acc 0.0000', 'Discriminator loss 0.0306', 'Discriminator accuracy 0.9961', 'Total loss: 4.6840', 'for batch', 12)
('GAN loss 4.7431 ', 'GAN acc 0.0000', 'Discriminator loss 0.0279', 'Discriminator accuracy 0.9961', 'Total loss: 4.7710', 'for batch', 13)
('GAN loss 4.7602 ', 'GAN acc 0.0000', 'Discriminator loss 0.0081', 'Discriminator accuracy 0.9980', 'Total loss: 4.7684', 'for batch', 14)
('GAN loss 4.7830 ', 'GAN acc 0.0000', 'Discriminator loss 0.0277', 'Discriminator accuracy 0.9961', 'Total loss: 4.8107', 'for batch', 15)
('GAN loss 4.8116 ', 'GAN acc 0.0000', 'Discriminator loss 0.0284', 'Discriminator accuracy 0.9961', 'Total loss: 4.8401', 'for batch', 16)
('GAN loss 5.0254 ', 'GAN acc 0.0000', 'Discriminator loss 0.0289', 'Discriminator accuracy 0.9941', 'Total loss: 5.0543', 'for batch', 17)
('GAN loss 4.9828 ', 'GAN acc 0.0000', 'Discriminator loss 0.0170', 'Discriminator accuracy 0.9980', 'Total loss: 4.9998', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99415058)
('DISCRIMINATOR_Imagem FAKE=', 0.005748)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.742147')
----------------------------------
('Epoch', 37, 'of', 50)
('Number of batches', 19)
('GAN loss 4.8690 ', 'GAN acc 0.0000', 'Discriminator loss 0.0172', 'Discriminator accuracy 0.9980', 'Total loss: 4.8863', 'for batch', 0)
('GAN loss 5.0787 ', 'GAN acc 0.0000', 'Discriminator loss 0.0073', 'Discriminator accuracy 0.9980', 'Total loss: 5.0861', 'for batch', 1)
('GAN loss 5.1048 ', 'GAN acc 0.0000', 'Discriminator loss 0.0163', 'Discriminator accuracy 0.9980', 'Total loss: 5.1210', 'for batch', 2)
('GAN loss 5.1670 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.1945', 'for batch', 3)
('GAN loss 5.0817 ', 'GAN acc 0.0000', 'Discriminator loss 0.0316', 'Discriminator accuracy 0.9941', 'Total loss: 5.1133', 'for batch', 4)
('GAN loss 5.0227 ', 'GAN acc 0.0000', 'Discriminator loss 0.0214', 'Discriminator accuracy 0.9941', 'Total loss: 5.0440', 'for batch', 5)
('GAN loss 4.7802 ', 'GAN acc 0.0000', 'Discriminator loss 0.0317', 'Discriminator accuracy 0.9941', 'Total loss: 4.8119', 'for batch', 6)
('GAN loss 4.6578 ', 'GAN acc 0.0000', 'Discriminator loss 0.0326', 'Discriminator accuracy 0.9941', 'Total loss: 4.6904', 'for batch', 7)
('GAN loss 4.5802 ', 'GAN acc 0.0000', 'Discriminator loss 0.0386', 'Discriminator accuracy 0.9941', 'Total loss: 4.6188', 'for batch', 8)
('GAN loss 4.6663 ', 'GAN acc 0.0000', 'Discriminator loss 0.0070', 'Discriminator accuracy 1.0000', 'Total loss: 4.6732', 'for batch', 9)
('GAN loss 4.7266 ', 'GAN acc 0.0000', 'Discriminator loss 0.0202', 'Discriminator accuracy 0.9961', 'Total loss: 4.7468', 'for batch', 10)
('GAN loss 4.8420 ', 'GAN acc 0.0000', 'Discriminator loss 0.0076', 'Discriminator accuracy 0.9980', 'Total loss: 4.8496', 'for batch', 11)
('GAN loss 4.7918 ', 'GAN acc 0.0000', 'Discriminator loss 0.0278', 'Discriminator accuracy 0.9961', 'Total loss: 4.8196', 'for batch', 12)
('GAN loss 4.9206 ', 'GAN acc 0.0000', 'Discriminator loss 0.0286', 'Discriminator accuracy 0.9961', 'Total loss: 4.9492', 'for batch', 13)
('GAN loss 5.0255 ', 'GAN acc 0.0000', 'Discriminator loss 0.0053', 'Discriminator accuracy 1.0000', 'Total loss: 5.0309', 'for batch', 14)
('GAN loss 5.0569 ', 'GAN acc 0.0000', 'Discriminator loss 0.0242', 'Discriminator accuracy 0.9961', 'Total loss: 5.0811', 'for batch', 15)
('GAN loss 5.0413 ', 'GAN acc 0.0000', 'Discriminator loss 0.0292', 'Discriminator accuracy 0.9961', 'Total loss: 5.0705', 'for batch', 16)
('GAN loss 5.0638 ', 'GAN acc 0.0000', 'Discriminator loss 0.0322', 'Discriminator accuracy 0.9941', 'Total loss: 5.0960', 'for batch', 17)
('GAN loss 5.0524 ', 'GAN acc 0.0000', 'Discriminator loss 0.0155', 'Discriminator accuracy 0.9980', 'Total loss: 5.0679', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99481505)
('DISCRIMINATOR_Imagem FAKE=', 0.0045787059)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.372323')
----------------------------------
('Epoch', 38, 'of', 50)
('Number of batches', 19)
('GAN loss 5.0839 ', 'GAN acc 0.0000', 'Discriminator loss 0.0140', 'Discriminator accuracy 0.9980', 'Total loss: 5.0979', 'for batch', 0)
('GAN loss 5.1722 ', 'GAN acc 0.0000', 'Discriminator loss 0.0083', 'Discriminator accuracy 0.9980', 'Total loss: 5.1806', 'for batch', 1)
('GAN loss 5.1763 ', 'GAN acc 0.0000', 'Discriminator loss 0.0154', 'Discriminator accuracy 0.9980', 'Total loss: 5.1917', 'for batch', 2)
('GAN loss 5.1816 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9961', 'Total loss: 5.2095', 'for batch', 3)
('GAN loss 5.0819 ', 'GAN acc 0.0000', 'Discriminator loss 0.0342', 'Discriminator accuracy 0.9941', 'Total loss: 5.1160', 'for batch', 4)
('GAN loss 5.1415 ', 'GAN acc 0.0000', 'Discriminator loss 0.0070', 'Discriminator accuracy 0.9980', 'Total loss: 5.1484', 'for batch', 5)
('GAN loss 5.0869 ', 'GAN acc 0.0000', 'Discriminator loss 0.0221', 'Discriminator accuracy 0.9961', 'Total loss: 5.1090', 'for batch', 6)
('GAN loss 5.1044 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9961', 'Total loss: 5.1311', 'for batch', 7)
('GAN loss 5.0500 ', 'GAN acc 0.0000', 'Discriminator loss 0.0359', 'Discriminator accuracy 0.9941', 'Total loss: 5.0859', 'for batch', 8)
('GAN loss 5.0984 ', 'GAN acc 0.0000', 'Discriminator loss 0.0045', 'Discriminator accuracy 1.0000', 'Total loss: 5.1029', 'for batch', 9)
('GAN loss 5.1687 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.1936', 'for batch', 10)
('GAN loss 5.1764 ', 'GAN acc 0.0000', 'Discriminator loss 0.0122', 'Discriminator accuracy 0.9980', 'Total loss: 5.1886', 'for batch', 11)
('GAN loss 5.2205 ', 'GAN acc 0.0000', 'Discriminator loss 0.0282', 'Discriminator accuracy 0.9961', 'Total loss: 5.2486', 'for batch', 12)
('GAN loss 5.1930 ', 'GAN acc 0.0000', 'Discriminator loss 0.0278', 'Discriminator accuracy 0.9961', 'Total loss: 5.2208', 'for batch', 13)
('GAN loss 5.2393 ', 'GAN acc 0.0000', 'Discriminator loss 0.0069', 'Discriminator accuracy 0.9980', 'Total loss: 5.2462', 'for batch', 14)
('GAN loss 5.2669 ', 'GAN acc 0.0000', 'Discriminator loss 0.0282', 'Discriminator accuracy 0.9961', 'Total loss: 5.2951', 'for batch', 15)
('GAN loss 5.2208 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9961', 'Total loss: 5.2488', 'for batch', 16)
('GAN loss 5.3503 ', 'GAN acc 0.0000', 'Discriminator loss 0.0304', 'Discriminator accuracy 0.9941', 'Total loss: 5.3808', 'for batch', 17)
('GAN loss 5.3389 ', 'GAN acc 0.0000', 'Discriminator loss 0.0156', 'Discriminator accuracy 0.9980', 'Total loss: 5.3545', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99388492)
('DISCRIMINATOR_Imagem FAKE=', 0.0035575456)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.750910')
----------------------------------
('Epoch', 39, 'of', 50)
('Number of batches', 19)
('GAN loss 5.4303 ', 'GAN acc 0.0000', 'Discriminator loss 0.0140', 'Discriminator accuracy 0.9980', 'Total loss: 5.4443', 'for batch', 0)
('GAN loss 5.5013 ', 'GAN acc 0.0000', 'Discriminator loss 0.0093', 'Discriminator accuracy 0.9980', 'Total loss: 5.5106', 'for batch', 1)
('GAN loss 5.3281 ', 'GAN acc 0.0000', 'Discriminator loss 0.0250', 'Discriminator accuracy 0.9961', 'Total loss: 5.3531', 'for batch', 2)
('GAN loss 5.2449 ', 'GAN acc 0.0000', 'Discriminator loss 0.0269', 'Discriminator accuracy 0.9961', 'Total loss: 5.2717', 'for batch', 3)
('GAN loss 5.2163 ', 'GAN acc 0.0000', 'Discriminator loss 0.0351', 'Discriminator accuracy 0.9941', 'Total loss: 5.2515', 'for batch', 4)
('GAN loss 5.1484 ', 'GAN acc 0.0000', 'Discriminator loss 0.0085', 'Discriminator accuracy 0.9980', 'Total loss: 5.1570', 'for batch', 5)
('GAN loss 5.0909 ', 'GAN acc 0.0000', 'Discriminator loss 0.0166', 'Discriminator accuracy 0.9980', 'Total loss: 5.1075', 'for batch', 6)
('GAN loss 5.1819 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9961', 'Total loss: 5.2101', 'for batch', 7)
('GAN loss 5.2123 ', 'GAN acc 0.0000', 'Discriminator loss 0.0345', 'Discriminator accuracy 0.9941', 'Total loss: 5.2467', 'for batch', 8)
('GAN loss 5.1980 ', 'GAN acc 0.0000', 'Discriminator loss 0.0037', 'Discriminator accuracy 1.0000', 'Total loss: 5.2017', 'for batch', 9)
('GAN loss 5.3195 ', 'GAN acc 0.0000', 'Discriminator loss 0.0214', 'Discriminator accuracy 0.9961', 'Total loss: 5.3409', 'for batch', 10)
('GAN loss 5.2373 ', 'GAN acc 0.0000', 'Discriminator loss 0.0094', 'Discriminator accuracy 0.9980', 'Total loss: 5.2467', 'for batch', 11)
('GAN loss 5.2479 ', 'GAN acc 0.0000', 'Discriminator loss 0.0258', 'Discriminator accuracy 0.9961', 'Total loss: 5.2737', 'for batch', 12)
('GAN loss 5.2840 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.3088', 'for batch', 13)
('GAN loss 5.3806 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 1.0000', 'Total loss: 5.3844', 'for batch', 14)
('GAN loss 5.2910 ', 'GAN acc 0.0000', 'Discriminator loss 0.0263', 'Discriminator accuracy 0.9961', 'Total loss: 5.3173', 'for batch', 15)
('GAN loss 5.3686 ', 'GAN acc 0.0000', 'Discriminator loss 0.0263', 'Discriminator accuracy 0.9961', 'Total loss: 5.3949', 'for batch', 16)
('GAN loss 5.3607 ', 'GAN acc 0.0000', 'Discriminator loss 0.0306', 'Discriminator accuracy 0.9941', 'Total loss: 5.3913', 'for batch', 17)
('GAN loss 5.2741 ', 'GAN acc 0.0000', 'Discriminator loss 0.0151', 'Discriminator accuracy 0.9980', 'Total loss: 5.2892', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99392068)
('DISCRIMINATOR_Imagem FAKE=', 0.0042145438)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.270933')
----------------------------------
('Epoch', 40, 'of', 50)
('Number of batches', 19)
('GAN loss 5.3480 ', 'GAN acc 0.0000', 'Discriminator loss 0.0174', 'Discriminator accuracy 0.9961', 'Total loss: 5.3654', 'for batch', 0)
('GAN loss 5.3444 ', 'GAN acc 0.0000', 'Discriminator loss 0.0072', 'Discriminator accuracy 0.9980', 'Total loss: 5.3516', 'for batch', 1)
('GAN loss 5.2714 ', 'GAN acc 0.0000', 'Discriminator loss 0.0136', 'Discriminator accuracy 0.9980', 'Total loss: 5.2849', 'for batch', 2)
('GAN loss 5.2772 ', 'GAN acc 0.0000', 'Discriminator loss 0.0214', 'Discriminator accuracy 0.9961', 'Total loss: 5.2986', 'for batch', 3)
('GAN loss 5.1938 ', 'GAN acc 0.0000', 'Discriminator loss 0.0303', 'Discriminator accuracy 0.9941', 'Total loss: 5.2241', 'for batch', 4)
('GAN loss 5.1918 ', 'GAN acc 0.0000', 'Discriminator loss 0.0249', 'Discriminator accuracy 0.9961', 'Total loss: 5.2167', 'for batch', 5)
('GAN loss 5.1946 ', 'GAN acc 0.0000', 'Discriminator loss 0.0141', 'Discriminator accuracy 0.9980', 'Total loss: 5.2086', 'for batch', 6)
('GAN loss 5.2158 ', 'GAN acc 0.0000', 'Discriminator loss 0.0265', 'Discriminator accuracy 0.9961', 'Total loss: 5.2423', 'for batch', 7)
('GAN loss 5.2115 ', 'GAN acc 0.0000', 'Discriminator loss 0.0301', 'Discriminator accuracy 0.9941', 'Total loss: 5.2417', 'for batch', 8)
('GAN loss 5.1799 ', 'GAN acc 0.0000', 'Discriminator loss 0.0037', 'Discriminator accuracy 1.0000', 'Total loss: 5.1836', 'for batch', 9)
('GAN loss 5.2264 ', 'GAN acc 0.0000', 'Discriminator loss 0.0201', 'Discriminator accuracy 0.9961', 'Total loss: 5.2465', 'for batch', 10)
('GAN loss 5.2192 ', 'GAN acc 0.0000', 'Discriminator loss 0.0067', 'Discriminator accuracy 0.9980', 'Total loss: 5.2259', 'for batch', 11)
('GAN loss 5.3027 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9961', 'Total loss: 5.3283', 'for batch', 12)
('GAN loss 5.2464 ', 'GAN acc 0.0000', 'Discriminator loss 0.0256', 'Discriminator accuracy 0.9961', 'Total loss: 5.2721', 'for batch', 13)
('GAN loss 5.3829 ', 'GAN acc 0.0000', 'Discriminator loss 0.0040', 'Discriminator accuracy 1.0000', 'Total loss: 5.3869', 'for batch', 14)
('GAN loss 5.2728 ', 'GAN acc 0.0000', 'Discriminator loss 0.0272', 'Discriminator accuracy 0.9961', 'Total loss: 5.3000', 'for batch', 15)
('GAN loss 5.3330 ', 'GAN acc 0.0000', 'Discriminator loss 0.0242', 'Discriminator accuracy 0.9961', 'Total loss: 5.3572', 'for batch', 16)
('GAN loss 5.3911 ', 'GAN acc 0.0000', 'Discriminator loss 0.0254', 'Discriminator accuracy 0.9961', 'Total loss: 5.4165', 'for batch', 17)
('GAN loss 5.3273 ', 'GAN acc 0.0000', 'Discriminator loss 0.0131', 'Discriminator accuracy 0.9980', 'Total loss: 5.3404', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99473757)
('DISCRIMINATOR_Imagem FAKE=', 0.0041595753)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.754758')
----------------------------------
('Epoch', 41, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2927 ', 'GAN acc 0.0000', 'Discriminator loss 0.0144', 'Discriminator accuracy 0.9980', 'Total loss: 5.3072', 'for batch', 0)
('GAN loss 5.4463 ', 'GAN acc 0.0000', 'Discriminator loss 0.0040', 'Discriminator accuracy 1.0000', 'Total loss: 5.4503', 'for batch', 1)
('GAN loss 5.3920 ', 'GAN acc 0.0000', 'Discriminator loss 0.0150', 'Discriminator accuracy 0.9980', 'Total loss: 5.4070', 'for batch', 2)
('GAN loss 5.3966 ', 'GAN acc 0.0000', 'Discriminator loss 0.0240', 'Discriminator accuracy 0.9961', 'Total loss: 5.4206', 'for batch', 3)
('GAN loss 5.4066 ', 'GAN acc 0.0000', 'Discriminator loss 0.0240', 'Discriminator accuracy 0.9941', 'Total loss: 5.4306', 'for batch', 4)
('GAN loss 5.4705 ', 'GAN acc 0.0000', 'Discriminator loss 0.0054', 'Discriminator accuracy 0.9980', 'Total loss: 5.4759', 'for batch', 5)
('GAN loss 5.4250 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.4398', 'for batch', 6)
('GAN loss 5.5666 ', 'GAN acc 0.0000', 'Discriminator loss 0.0243', 'Discriminator accuracy 0.9961', 'Total loss: 5.5909', 'for batch', 7)
('GAN loss 5.4397 ', 'GAN acc 0.0000', 'Discriminator loss 0.0271', 'Discriminator accuracy 0.9941', 'Total loss: 5.4668', 'for batch', 8)
('GAN loss 5.4012 ', 'GAN acc 0.0000', 'Discriminator loss 0.0033', 'Discriminator accuracy 1.0000', 'Total loss: 5.4045', 'for batch', 9)
('GAN loss 5.3167 ', 'GAN acc 0.0000', 'Discriminator loss 0.0164', 'Discriminator accuracy 0.9961', 'Total loss: 5.3331', 'for batch', 10)
('GAN loss 5.3308 ', 'GAN acc 0.0000', 'Discriminator loss 0.0091', 'Discriminator accuracy 0.9980', 'Total loss: 5.3400', 'for batch', 11)
('GAN loss 5.3309 ', 'GAN acc 0.0000', 'Discriminator loss 0.0270', 'Discriminator accuracy 0.9961', 'Total loss: 5.3579', 'for batch', 12)
('GAN loss 5.2915 ', 'GAN acc 0.0000', 'Discriminator loss 0.0243', 'Discriminator accuracy 0.9961', 'Total loss: 5.3158', 'for batch', 13)
('GAN loss 5.4223 ', 'GAN acc 0.0000', 'Discriminator loss 0.0032', 'Discriminator accuracy 1.0000', 'Total loss: 5.4255', 'for batch', 14)
('GAN loss 5.3640 ', 'GAN acc 0.0000', 'Discriminator loss 0.0275', 'Discriminator accuracy 0.9961', 'Total loss: 5.3915', 'for batch', 15)
('GAN loss 5.4459 ', 'GAN acc 0.0000', 'Discriminator loss 0.0276', 'Discriminator accuracy 0.9961', 'Total loss: 5.4735', 'for batch', 16)
('GAN loss 5.4256 ', 'GAN acc 0.0000', 'Discriminator loss 0.0297', 'Discriminator accuracy 0.9941', 'Total loss: 5.4553', 'for batch', 17)
('GAN loss 5.3396 ', 'GAN acc 0.0000', 'Discriminator loss 0.0143', 'Discriminator accuracy 0.9980', 'Total loss: 5.3539', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99473244)
('DISCRIMINATOR_Imagem FAKE=', 0.003935731)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.275731')
----------------------------------
('Epoch', 42, 'of', 50)
('Number of batches', 19)
('GAN loss 5.4311 ', 'GAN acc 0.0000', 'Discriminator loss 0.0152', 'Discriminator accuracy 0.9980', 'Total loss: 5.4462', 'for batch', 0)
('GAN loss 5.3205 ', 'GAN acc 0.0000', 'Discriminator loss 0.0071', 'Discriminator accuracy 0.9980', 'Total loss: 5.3276', 'for batch', 1)
('GAN loss 5.4193 ', 'GAN acc 0.0000', 'Discriminator loss 0.0151', 'Discriminator accuracy 0.9980', 'Total loss: 5.4343', 'for batch', 2)
('GAN loss 5.4090 ', 'GAN acc 0.0000', 'Discriminator loss 0.0257', 'Discriminator accuracy 0.9961', 'Total loss: 5.4347', 'for batch', 3)
('GAN loss 5.4480 ', 'GAN acc 0.0000', 'Discriminator loss 0.0295', 'Discriminator accuracy 0.9941', 'Total loss: 5.4776', 'for batch', 4)
('GAN loss 5.3996 ', 'GAN acc 0.0000', 'Discriminator loss 0.0098', 'Discriminator accuracy 0.9980', 'Total loss: 5.4095', 'for batch', 5)
('GAN loss 5.3925 ', 'GAN acc 0.0000', 'Discriminator loss 0.0159', 'Discriminator accuracy 0.9980', 'Total loss: 5.4085', 'for batch', 6)
('GAN loss 5.3727 ', 'GAN acc 0.0000', 'Discriminator loss 0.0260', 'Discriminator accuracy 0.9961', 'Total loss: 5.3987', 'for batch', 7)
('GAN loss 5.4159 ', 'GAN acc 0.0000', 'Discriminator loss 0.0361', 'Discriminator accuracy 0.9941', 'Total loss: 5.4520', 'for batch', 8)
('GAN loss 5.3486 ', 'GAN acc 0.0000', 'Discriminator loss 0.0032', 'Discriminator accuracy 1.0000', 'Total loss: 5.3518', 'for batch', 9)
('GAN loss 5.4116 ', 'GAN acc 0.0000', 'Discriminator loss 0.0205', 'Discriminator accuracy 0.9961', 'Total loss: 5.4321', 'for batch', 10)
('GAN loss 5.3784 ', 'GAN acc 0.0000', 'Discriminator loss 0.0096', 'Discriminator accuracy 0.9980', 'Total loss: 5.3880', 'for batch', 11)
('GAN loss 5.3687 ', 'GAN acc 0.0000', 'Discriminator loss 0.0258', 'Discriminator accuracy 0.9961', 'Total loss: 5.3945', 'for batch', 12)
('GAN loss 5.2769 ', 'GAN acc 0.0000', 'Discriminator loss 0.0247', 'Discriminator accuracy 0.9961', 'Total loss: 5.3016', 'for batch', 13)
('GAN loss 5.3996 ', 'GAN acc 0.0000', 'Discriminator loss 0.0030', 'Discriminator accuracy 1.0000', 'Total loss: 5.4026', 'for batch', 14)
('GAN loss 5.3099 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.3373', 'for batch', 15)
('GAN loss 5.2401 ', 'GAN acc 0.0000', 'Discriminator loss 0.0264', 'Discriminator accuracy 0.9961', 'Total loss: 5.2665', 'for batch', 16)
('GAN loss 5.2712 ', 'GAN acc 0.0000', 'Discriminator loss 0.0336', 'Discriminator accuracy 0.9941', 'Total loss: 5.3049', 'for batch', 17)
('GAN loss 5.1590 ', 'GAN acc 0.0000', 'Discriminator loss 0.0139', 'Discriminator accuracy 0.9980', 'Total loss: 5.1729', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.994923)
('DISCRIMINATOR_Imagem FAKE=', 0.0051490413)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.742454')
----------------------------------
('Epoch', 43, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2037 ', 'GAN acc 0.0000', 'Discriminator loss 0.0141', 'Discriminator accuracy 0.9980', 'Total loss: 5.2178', 'for batch', 0)
('GAN loss 5.2477 ', 'GAN acc 0.0000', 'Discriminator loss 0.0036', 'Discriminator accuracy 1.0000', 'Total loss: 5.2513', 'for batch', 1)
('GAN loss 5.1937 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.2085', 'for batch', 2)
('GAN loss 5.2651 ', 'GAN acc 0.0000', 'Discriminator loss 0.0256', 'Discriminator accuracy 0.9961', 'Total loss: 5.2906', 'for batch', 3)
('GAN loss 5.2120 ', 'GAN acc 0.0000', 'Discriminator loss 0.0329', 'Discriminator accuracy 0.9941', 'Total loss: 5.2449', 'for batch', 4)
('GAN loss 5.1978 ', 'GAN acc 0.0000', 'Discriminator loss 0.0039', 'Discriminator accuracy 1.0000', 'Total loss: 5.2017', 'for batch', 5)
('GAN loss 5.2568 ', 'GAN acc 0.0000', 'Discriminator loss 0.0144', 'Discriminator accuracy 0.9980', 'Total loss: 5.2712', 'for batch', 6)
('GAN loss 5.2330 ', 'GAN acc 0.0000', 'Discriminator loss 0.0276', 'Discriminator accuracy 0.9961', 'Total loss: 5.2606', 'for batch', 7)
('GAN loss 5.3146 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9941', 'Total loss: 5.3413', 'for batch', 8)
('GAN loss 5.2654 ', 'GAN acc 0.0000', 'Discriminator loss 0.0032', 'Discriminator accuracy 1.0000', 'Total loss: 5.2686', 'for batch', 9)
('GAN loss 5.2057 ', 'GAN acc 0.0000', 'Discriminator loss 0.0213', 'Discriminator accuracy 0.9961', 'Total loss: 5.2270', 'for batch', 10)
('GAN loss 5.2186 ', 'GAN acc 0.0000', 'Discriminator loss 0.0070', 'Discriminator accuracy 0.9980', 'Total loss: 5.2256', 'for batch', 11)
('GAN loss 5.2733 ', 'GAN acc 0.0000', 'Discriminator loss 0.0257', 'Discriminator accuracy 0.9961', 'Total loss: 5.2990', 'for batch', 12)
('GAN loss 5.2596 ', 'GAN acc 0.0000', 'Discriminator loss 0.0275', 'Discriminator accuracy 0.9961', 'Total loss: 5.2872', 'for batch', 13)
('GAN loss 5.3836 ', 'GAN acc 0.0000', 'Discriminator loss 0.0031', 'Discriminator accuracy 1.0000', 'Total loss: 5.3867', 'for batch', 14)
('GAN loss 5.2944 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9961', 'Total loss: 5.3199', 'for batch', 15)
('GAN loss 5.3104 ', 'GAN acc 0.0000', 'Discriminator loss 0.0288', 'Discriminator accuracy 0.9961', 'Total loss: 5.3392', 'for batch', 16)
('GAN loss 5.3052 ', 'GAN acc 0.0000', 'Discriminator loss 0.0290', 'Discriminator accuracy 0.9941', 'Total loss: 5.3341', 'for batch', 17)
('GAN loss 5.3133 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.3282', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99483556)
('DISCRIMINATOR_Imagem FAKE=', 0.0051860493)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.488157')
----------------------------------
('Epoch', 44, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2711 ', 'GAN acc 0.0000', 'Discriminator loss 0.0151', 'Discriminator accuracy 0.9980', 'Total loss: 5.2863', 'for batch', 0)
('GAN loss 5.2457 ', 'GAN acc 0.0000', 'Discriminator loss 0.0079', 'Discriminator accuracy 0.9980', 'Total loss: 5.2535', 'for batch', 1)
('GAN loss 5.3202 ', 'GAN acc 0.0000', 'Discriminator loss 0.0136', 'Discriminator accuracy 0.9980', 'Total loss: 5.3338', 'for batch', 2)
('GAN loss 5.3267 ', 'GAN acc 0.0000', 'Discriminator loss 0.0222', 'Discriminator accuracy 0.9961', 'Total loss: 5.3489', 'for batch', 3)
('GAN loss 5.3011 ', 'GAN acc 0.0000', 'Discriminator loss 0.0290', 'Discriminator accuracy 0.9941', 'Total loss: 5.3301', 'for batch', 4)
('GAN loss 5.2800 ', 'GAN acc 0.0000', 'Discriminator loss 0.0081', 'Discriminator accuracy 0.9980', 'Total loss: 5.2881', 'for batch', 5)
('GAN loss 5.2628 ', 'GAN acc 0.0000', 'Discriminator loss 0.0150', 'Discriminator accuracy 0.9980', 'Total loss: 5.2779', 'for batch', 6)
('GAN loss 5.2411 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9961', 'Total loss: 5.2694', 'for batch', 7)
('GAN loss 5.2060 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9941', 'Total loss: 5.2375', 'for batch', 8)
('GAN loss 5.1905 ', 'GAN acc 0.0000', 'Discriminator loss 0.0036', 'Discriminator accuracy 1.0000', 'Total loss: 5.1941', 'for batch', 9)
('GAN loss 5.1180 ', 'GAN acc 0.0000', 'Discriminator loss 0.0165', 'Discriminator accuracy 0.9961', 'Total loss: 5.1344', 'for batch', 10)
('GAN loss 5.1813 ', 'GAN acc 0.0000', 'Discriminator loss 0.0057', 'Discriminator accuracy 0.9980', 'Total loss: 5.1870', 'for batch', 11)
('GAN loss 5.2397 ', 'GAN acc 0.0000', 'Discriminator loss 0.0242', 'Discriminator accuracy 0.9961', 'Total loss: 5.2639', 'for batch', 12)
('GAN loss 5.1575 ', 'GAN acc 0.0000', 'Discriminator loss 0.0282', 'Discriminator accuracy 0.9961', 'Total loss: 5.1857', 'for batch', 13)
('GAN loss 5.2014 ', 'GAN acc 0.0000', 'Discriminator loss 0.0035', 'Discriminator accuracy 1.0000', 'Total loss: 5.2049', 'for batch', 14)
('GAN loss 5.2318 ', 'GAN acc 0.0000', 'Discriminator loss 0.0252', 'Discriminator accuracy 0.9961', 'Total loss: 5.2569', 'for batch', 15)
('GAN loss 5.1791 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.2065', 'for batch', 16)
('GAN loss 5.2553 ', 'GAN acc 0.0000', 'Discriminator loss 0.0264', 'Discriminator accuracy 0.9941', 'Total loss: 5.2817', 'for batch', 17)
('GAN loss 5.2467 ', 'GAN acc 0.0000', 'Discriminator loss 0.0136', 'Discriminator accuracy 0.9980', 'Total loss: 5.2603', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99495232)
('DISCRIMINATOR_Imagem FAKE=', 0.0060732127)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.723335')
----------------------------------
('Epoch', 45, 'of', 50)
('Number of batches', 19)
('GAN loss 5.1806 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.1954', 'for batch', 0)
('GAN loss 5.2022 ', 'GAN acc 0.0000', 'Discriminator loss 0.0049', 'Discriminator accuracy 0.9980', 'Total loss: 5.2071', 'for batch', 1)
('GAN loss 5.2561 ', 'GAN acc 0.0000', 'Discriminator loss 0.0157', 'Discriminator accuracy 0.9980', 'Total loss: 5.2718', 'for batch', 2)
('GAN loss 5.2487 ', 'GAN acc 0.0000', 'Discriminator loss 0.0252', 'Discriminator accuracy 0.9961', 'Total loss: 5.2739', 'for batch', 3)
('GAN loss 5.2219 ', 'GAN acc 0.0000', 'Discriminator loss 0.0291', 'Discriminator accuracy 0.9941', 'Total loss: 5.2511', 'for batch', 4)
('GAN loss 5.2177 ', 'GAN acc 0.0000', 'Discriminator loss 0.0053', 'Discriminator accuracy 0.9980', 'Total loss: 5.2230', 'for batch', 5)
('GAN loss 5.2178 ', 'GAN acc 0.0000', 'Discriminator loss 0.0149', 'Discriminator accuracy 0.9980', 'Total loss: 5.2327', 'for batch', 6)
('GAN loss 5.2430 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9961', 'Total loss: 5.2704', 'for batch', 7)
('GAN loss 5.2462 ', 'GAN acc 0.0000', 'Discriminator loss 0.0375', 'Discriminator accuracy 0.9941', 'Total loss: 5.2837', 'for batch', 8)
('GAN loss 5.2319 ', 'GAN acc 0.0000', 'Discriminator loss 0.0032', 'Discriminator accuracy 1.0000', 'Total loss: 5.2351', 'for batch', 9)
('GAN loss 5.2366 ', 'GAN acc 0.0000', 'Discriminator loss 0.0188', 'Discriminator accuracy 0.9961', 'Total loss: 5.2554', 'for batch', 10)
('GAN loss 5.2333 ', 'GAN acc 0.0000', 'Discriminator loss 0.0044', 'Discriminator accuracy 1.0000', 'Total loss: 5.2377', 'for batch', 11)
('GAN loss 5.2454 ', 'GAN acc 0.0000', 'Discriminator loss 0.0254', 'Discriminator accuracy 0.9961', 'Total loss: 5.2708', 'for batch', 12)
('GAN loss 5.3072 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.3321', 'for batch', 13)
('GAN loss 5.2910 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 1.0000', 'Total loss: 5.2948', 'for batch', 14)
('GAN loss 5.3024 ', 'GAN acc 0.0000', 'Discriminator loss 0.0265', 'Discriminator accuracy 0.9961', 'Total loss: 5.3289', 'for batch', 15)
('GAN loss 5.2103 ', 'GAN acc 0.0000', 'Discriminator loss 0.0253', 'Discriminator accuracy 0.9961', 'Total loss: 5.2356', 'for batch', 16)
('GAN loss 5.2235 ', 'GAN acc 0.0000', 'Discriminator loss 0.0293', 'Discriminator accuracy 0.9941', 'Total loss: 5.2528', 'for batch', 17)
('GAN loss 5.2464 ', 'GAN acc 0.0000', 'Discriminator loss 0.0138', 'Discriminator accuracy 0.9980', 'Total loss: 5.2602', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99510598)
('DISCRIMINATOR_Imagem FAKE=', 0.0057465774)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.350829')
----------------------------------
('Epoch', 46, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2817 ', 'GAN acc 0.0000', 'Discriminator loss 0.0137', 'Discriminator accuracy 0.9980', 'Total loss: 5.2953', 'for batch', 0)
('GAN loss 5.2409 ', 'GAN acc 0.0000', 'Discriminator loss 0.0049', 'Discriminator accuracy 0.9980', 'Total loss: 5.2459', 'for batch', 1)
('GAN loss 5.2199 ', 'GAN acc 0.0000', 'Discriminator loss 0.0150', 'Discriminator accuracy 0.9980', 'Total loss: 5.2349', 'for batch', 2)
('GAN loss 5.2312 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9961', 'Total loss: 5.2568', 'for batch', 3)
('GAN loss 5.1430 ', 'GAN acc 0.0000', 'Discriminator loss 0.0375', 'Discriminator accuracy 0.9922', 'Total loss: 5.1805', 'for batch', 4)
('GAN loss 5.1837 ', 'GAN acc 0.0000', 'Discriminator loss 0.0035', 'Discriminator accuracy 1.0000', 'Total loss: 5.1872', 'for batch', 5)
('GAN loss 5.1189 ', 'GAN acc 0.0000', 'Discriminator loss 0.0135', 'Discriminator accuracy 0.9980', 'Total loss: 5.1324', 'for batch', 6)
('GAN loss 5.2406 ', 'GAN acc 0.0000', 'Discriminator loss 0.0211', 'Discriminator accuracy 0.9961', 'Total loss: 5.2617', 'for batch', 7)
('GAN loss 5.1458 ', 'GAN acc 0.0000', 'Discriminator loss 0.0304', 'Discriminator accuracy 0.9941', 'Total loss: 5.1762', 'for batch', 8)
('GAN loss 5.1694 ', 'GAN acc 0.0000', 'Discriminator loss 0.0033', 'Discriminator accuracy 1.0000', 'Total loss: 5.1727', 'for batch', 9)
('GAN loss 5.2233 ', 'GAN acc 0.0000', 'Discriminator loss 0.0188', 'Discriminator accuracy 0.9961', 'Total loss: 5.2420', 'for batch', 10)
('GAN loss 5.2585 ', 'GAN acc 0.0000', 'Discriminator loss 0.0089', 'Discriminator accuracy 0.9980', 'Total loss: 5.2674', 'for batch', 11)
('GAN loss 5.1554 ', 'GAN acc 0.0000', 'Discriminator loss 0.0232', 'Discriminator accuracy 0.9961', 'Total loss: 5.1787', 'for batch', 12)
('GAN loss 5.1891 ', 'GAN acc 0.0000', 'Discriminator loss 0.0254', 'Discriminator accuracy 0.9961', 'Total loss: 5.2145', 'for batch', 13)
('GAN loss 5.1894 ', 'GAN acc 0.0000', 'Discriminator loss 0.0034', 'Discriminator accuracy 1.0000', 'Total loss: 5.1928', 'for batch', 14)
('GAN loss 5.2030 ', 'GAN acc 0.0000', 'Discriminator loss 0.0234', 'Discriminator accuracy 0.9961', 'Total loss: 5.2264', 'for batch', 15)
('GAN loss 5.2137 ', 'GAN acc 0.0000', 'Discriminator loss 0.0250', 'Discriminator accuracy 0.9961', 'Total loss: 5.2388', 'for batch', 16)
('GAN loss 5.2661 ', 'GAN acc 0.0000', 'Discriminator loss 0.0315', 'Discriminator accuracy 0.9941', 'Total loss: 5.2976', 'for batch', 17)
('GAN loss 5.2169 ', 'GAN acc 0.0000', 'Discriminator loss 0.0126', 'Discriminator accuracy 0.9980', 'Total loss: 5.2295', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99541807)
('DISCRIMINATOR_Imagem FAKE=', 0.0058393106)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.712352')
----------------------------------
('Epoch', 47, 'of', 50)
('Number of batches', 19)
('GAN loss 5.2514 ', 'GAN acc 0.0000', 'Discriminator loss 0.0146', 'Discriminator accuracy 0.9980', 'Total loss: 5.2660', 'for batch', 0)
('GAN loss 5.1728 ', 'GAN acc 0.0000', 'Discriminator loss 0.0036', 'Discriminator accuracy 1.0000', 'Total loss: 5.1764', 'for batch', 1)
('GAN loss 5.1639 ', 'GAN acc 0.0000', 'Discriminator loss 0.0153', 'Discriminator accuracy 0.9980', 'Total loss: 5.1792', 'for batch', 2)
('GAN loss 5.1867 ', 'GAN acc 0.0000', 'Discriminator loss 0.0226', 'Discriminator accuracy 0.9961', 'Total loss: 5.2094', 'for batch', 3)
('GAN loss 5.1056 ', 'GAN acc 0.0000', 'Discriminator loss 0.0302', 'Discriminator accuracy 0.9941', 'Total loss: 5.1358', 'for batch', 4)
('GAN loss 5.1347 ', 'GAN acc 0.0000', 'Discriminator loss 0.0036', 'Discriminator accuracy 1.0000', 'Total loss: 5.1383', 'for batch', 5)
('GAN loss 5.0967 ', 'GAN acc 0.0000', 'Discriminator loss 0.0150', 'Discriminator accuracy 0.9980', 'Total loss: 5.1117', 'for batch', 6)
('GAN loss 5.0787 ', 'GAN acc 0.0000', 'Discriminator loss 0.0239', 'Discriminator accuracy 0.9961', 'Total loss: 5.1026', 'for batch', 7)
('GAN loss 5.1269 ', 'GAN acc 0.0000', 'Discriminator loss 0.0310', 'Discriminator accuracy 0.9941', 'Total loss: 5.1580', 'for batch', 8)
('GAN loss 5.1910 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 1.0000', 'Total loss: 5.1948', 'for batch', 9)
('GAN loss 5.0976 ', 'GAN acc 0.0000', 'Discriminator loss 0.0201', 'Discriminator accuracy 0.9961', 'Total loss: 5.1176', 'for batch', 10)
('GAN loss 5.1191 ', 'GAN acc 0.0000', 'Discriminator loss 0.0047', 'Discriminator accuracy 1.0000', 'Total loss: 5.1238', 'for batch', 11)
('GAN loss 5.1588 ', 'GAN acc 0.0000', 'Discriminator loss 0.0277', 'Discriminator accuracy 0.9961', 'Total loss: 5.1864', 'for batch', 12)
('GAN loss 5.1541 ', 'GAN acc 0.0000', 'Discriminator loss 0.0260', 'Discriminator accuracy 0.9961', 'Total loss: 5.1801', 'for batch', 13)
('GAN loss 5.1610 ', 'GAN acc 0.0000', 'Discriminator loss 0.0034', 'Discriminator accuracy 1.0000', 'Total loss: 5.1645', 'for batch', 14)
('GAN loss 5.1161 ', 'GAN acc 0.0000', 'Discriminator loss 0.0239', 'Discriminator accuracy 0.9961', 'Total loss: 5.1400', 'for batch', 15)
('GAN loss 5.2037 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9961', 'Total loss: 5.2304', 'for batch', 16)
('GAN loss 5.1449 ', 'GAN acc 0.0000', 'Discriminator loss 0.0324', 'Discriminator accuracy 0.9941', 'Total loss: 5.1773', 'for batch', 17)
('GAN loss 5.1761 ', 'GAN acc 0.0000', 'Discriminator loss 0.0148', 'Discriminator accuracy 0.9980', 'Total loss: 5.1909', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99540871)
('DISCRIMINATOR_Imagem FAKE=', 0.0065466985)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.296831')
----------------------------------
('Epoch', 48, 'of', 50)
('Number of batches', 19)
('GAN loss 5.1820 ', 'GAN acc 0.0000', 'Discriminator loss 0.0143', 'Discriminator accuracy 0.9980', 'Total loss: 5.1963', 'for batch', 0)
('GAN loss 5.2747 ', 'GAN acc 0.0000', 'Discriminator loss 0.0066', 'Discriminator accuracy 0.9980', 'Total loss: 5.2813', 'for batch', 1)
('GAN loss 5.1684 ', 'GAN acc 0.0000', 'Discriminator loss 0.0152', 'Discriminator accuracy 0.9980', 'Total loss: 5.1836', 'for batch', 2)
('GAN loss 5.2376 ', 'GAN acc 0.0000', 'Discriminator loss 0.0243', 'Discriminator accuracy 0.9961', 'Total loss: 5.2619', 'for batch', 3)
('GAN loss 5.2018 ', 'GAN acc 0.0000', 'Discriminator loss 0.0238', 'Discriminator accuracy 0.9922', 'Total loss: 5.2256', 'for batch', 4)
('GAN loss 5.1944 ', 'GAN acc 0.0000', 'Discriminator loss 0.0033', 'Discriminator accuracy 1.0000', 'Total loss: 5.1977', 'for batch', 5)
('GAN loss 5.2399 ', 'GAN acc 0.0000', 'Discriminator loss 0.0147', 'Discriminator accuracy 0.9980', 'Total loss: 5.2545', 'for batch', 6)
('GAN loss 5.1951 ', 'GAN acc 0.0000', 'Discriminator loss 0.0283', 'Discriminator accuracy 0.9941', 'Total loss: 5.2234', 'for batch', 7)
('GAN loss 5.2145 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9941', 'Total loss: 5.2412', 'for batch', 8)
('GAN loss 5.2289 ', 'GAN acc 0.0000', 'Discriminator loss 0.0034', 'Discriminator accuracy 1.0000', 'Total loss: 5.2323', 'for batch', 9)
('GAN loss 5.2261 ', 'GAN acc 0.0000', 'Discriminator loss 0.0173', 'Discriminator accuracy 0.9961', 'Total loss: 5.2434', 'for batch', 10)
('GAN loss 5.1522 ', 'GAN acc 0.0000', 'Discriminator loss 0.0088', 'Discriminator accuracy 0.9980', 'Total loss: 5.1610', 'for batch', 11)
('GAN loss 5.2447 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.2695', 'for batch', 12)
('GAN loss 5.1113 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9961', 'Total loss: 5.1381', 'for batch', 13)
('GAN loss 5.1243 ', 'GAN acc 0.0000', 'Discriminator loss 0.0035', 'Discriminator accuracy 1.0000', 'Total loss: 5.1278', 'for batch', 14)
('GAN loss 5.0478 ', 'GAN acc 0.0000', 'Discriminator loss 0.0269', 'Discriminator accuracy 0.9961', 'Total loss: 5.0747', 'for batch', 15)
('GAN loss 5.1066 ', 'GAN acc 0.0000', 'Discriminator loss 0.0258', 'Discriminator accuracy 0.9961', 'Total loss: 5.1324', 'for batch', 16)
('GAN loss 5.0394 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9941', 'Total loss: 5.0673', 'for batch', 17)
('GAN loss 5.0050 ', 'GAN acc 0.0000', 'Discriminator loss 0.0139', 'Discriminator accuracy 0.9980', 'Total loss: 5.0189', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99552101)
('DISCRIMINATOR_Imagem FAKE=', 0.0061702072)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.774790')
----------------------------------
('Epoch', 49, 'of', 50)
('Number of batches', 19)
('GAN loss 4.9749 ', 'GAN acc 0.0000', 'Discriminator loss 0.0145', 'Discriminator accuracy 0.9980', 'Total loss: 4.9894', 'for batch', 0)
('GAN loss 5.0772 ', 'GAN acc 0.0000', 'Discriminator loss 0.0041', 'Discriminator accuracy 1.0000', 'Total loss: 5.0813', 'for batch', 1)
('GAN loss 5.0585 ', 'GAN acc 0.0000', 'Discriminator loss 0.0156', 'Discriminator accuracy 0.9980', 'Total loss: 5.0741', 'for batch', 2)
('GAN loss 5.1099 ', 'GAN acc 0.0000', 'Discriminator loss 0.0263', 'Discriminator accuracy 0.9961', 'Total loss: 5.1362', 'for batch', 3)
('GAN loss 5.0779 ', 'GAN acc 0.0000', 'Discriminator loss 0.0274', 'Discriminator accuracy 0.9941', 'Total loss: 5.1053', 'for batch', 4)
('GAN loss 5.1926 ', 'GAN acc 0.0000', 'Discriminator loss 0.0039', 'Discriminator accuracy 1.0000', 'Total loss: 5.1965', 'for batch', 5)
('GAN loss 5.0695 ', 'GAN acc 0.0000', 'Discriminator loss 0.0151', 'Discriminator accuracy 0.9980', 'Total loss: 5.0846', 'for batch', 6)
('GAN loss 5.1820 ', 'GAN acc 0.0000', 'Discriminator loss 0.0248', 'Discriminator accuracy 0.9961', 'Total loss: 5.2068', 'for batch', 7)
('GAN loss 5.1024 ', 'GAN acc 0.0000', 'Discriminator loss 0.0305', 'Discriminator accuracy 0.9941', 'Total loss: 5.1329', 'for batch', 8)
('GAN loss 5.1172 ', 'GAN acc 0.0000', 'Discriminator loss 0.0038', 'Discriminator accuracy 1.0000', 'Total loss: 5.1210', 'for batch', 9)
('GAN loss 5.1156 ', 'GAN acc 0.0000', 'Discriminator loss 0.0210', 'Discriminator accuracy 0.9961', 'Total loss: 5.1365', 'for batch', 10)
('GAN loss 5.1449 ', 'GAN acc 0.0000', 'Discriminator loss 0.0085', 'Discriminator accuracy 0.9980', 'Total loss: 5.1535', 'for batch', 11)
('GAN loss 5.1250 ', 'GAN acc 0.0000', 'Discriminator loss 0.0238', 'Discriminator accuracy 0.9961', 'Total loss: 5.1489', 'for batch', 12)
('GAN loss 5.0824 ', 'GAN acc 0.0000', 'Discriminator loss 0.0258', 'Discriminator accuracy 0.9961', 'Total loss: 5.1082', 'for batch', 13)
('GAN loss 5.1513 ', 'GAN acc 0.0000', 'Discriminator loss 0.0037', 'Discriminator accuracy 1.0000', 'Total loss: 5.1549', 'for batch', 14)
('GAN loss 5.1280 ', 'GAN acc 0.0000', 'Discriminator loss 0.0254', 'Discriminator accuracy 0.9961', 'Total loss: 5.1534', 'for batch', 15)
('GAN loss 5.1284 ', 'GAN acc 0.0000', 'Discriminator loss 0.0236', 'Discriminator accuracy 0.9961', 'Total loss: 5.1520', 'for batch', 16)
('GAN loss 5.1980 ', 'GAN acc 0.0000', 'Discriminator loss 0.0280', 'Discriminator accuracy 0.9941', 'Total loss: 5.2260', 'for batch', 17)
('GAN loss 5.1379 ', 'GAN acc 0.0000', 'Discriminator loss 0.0130', 'Discriminator accuracy 0.9980', 'Total loss: 5.1509', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99536663)
('DISCRIMINATOR_Imagem FAKE=', 0.0056865569)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.249940')
----------------------------------
('Epoch', 50, 'of', 50)
('Number of batches', 19)
('GAN loss 5.1527 ', 'GAN acc 0.0000', 'Discriminator loss 0.0168', 'Discriminator accuracy 0.9961', 'Total loss: 5.1695', 'for batch', 0)
('GAN loss 5.1484 ', 'GAN acc 0.0000', 'Discriminator loss 0.0060', 'Discriminator accuracy 0.9980', 'Total loss: 5.1544', 'for batch', 1)
('GAN loss 5.1723 ', 'GAN acc 0.0000', 'Discriminator loss 0.0143', 'Discriminator accuracy 0.9980', 'Total loss: 5.1866', 'for batch', 2)
('GAN loss 5.2275 ', 'GAN acc 0.0000', 'Discriminator loss 0.0244', 'Discriminator accuracy 0.9961', 'Total loss: 5.2519', 'for batch', 3)
('GAN loss 5.1710 ', 'GAN acc 0.0000', 'Discriminator loss 0.0244', 'Discriminator accuracy 0.9961', 'Total loss: 5.1954', 'for batch', 4)
('GAN loss 5.2155 ', 'GAN acc 0.0000', 'Discriminator loss 0.0034', 'Discriminator accuracy 1.0000', 'Total loss: 5.2189', 'for batch', 5)
('GAN loss 5.1594 ', 'GAN acc 0.0000', 'Discriminator loss 0.0144', 'Discriminator accuracy 0.9980', 'Total loss: 5.1738', 'for batch', 6)
('GAN loss 5.2987 ', 'GAN acc 0.0000', 'Discriminator loss 0.0242', 'Discriminator accuracy 0.9961', 'Total loss: 5.3229', 'for batch', 7)
('GAN loss 5.3040 ', 'GAN acc 0.0000', 'Discriminator loss 0.0319', 'Discriminator accuracy 0.9941', 'Total loss: 5.3358', 'for batch', 8)
('GAN loss 5.2267 ', 'GAN acc 0.0000', 'Discriminator loss 0.0033', 'Discriminator accuracy 1.0000', 'Total loss: 5.2300', 'for batch', 9)
('GAN loss 5.1602 ', 'GAN acc 0.0000', 'Discriminator loss 0.0179', 'Discriminator accuracy 0.9961', 'Total loss: 5.1781', 'for batch', 10)
('GAN loss 5.2313 ', 'GAN acc 0.0000', 'Discriminator loss 0.0060', 'Discriminator accuracy 0.9980', 'Total loss: 5.2373', 'for batch', 11)
('GAN loss 5.2583 ', 'GAN acc 0.0000', 'Discriminator loss 0.0267', 'Discriminator accuracy 0.9961', 'Total loss: 5.2850', 'for batch', 12)
('GAN loss 5.3013 ', 'GAN acc 0.0000', 'Discriminator loss 0.0227', 'Discriminator accuracy 0.9961', 'Total loss: 5.3240', 'for batch', 13)
('GAN loss 5.2661 ', 'GAN acc 0.0000', 'Discriminator loss 0.0036', 'Discriminator accuracy 1.0000', 'Total loss: 5.2697', 'for batch', 14)
('GAN loss 5.2509 ', 'GAN acc 0.0000', 'Discriminator loss 0.0251', 'Discriminator accuracy 0.9961', 'Total loss: 5.2760', 'for batch', 15)
('GAN loss 5.3055 ', 'GAN acc 0.0000', 'Discriminator loss 0.0245', 'Discriminator accuracy 0.9961', 'Total loss: 5.3300', 'for batch', 16)
('GAN loss 5.3190 ', 'GAN acc 0.0000', 'Discriminator loss 0.0257', 'Discriminator accuracy 0.9941', 'Total loss: 5.3447', 'for batch', 17)
('GAN loss 5.2517 ', 'GAN acc 0.0000', 'Discriminator loss 0.0147', 'Discriminator accuracy 0.9980', 'Total loss: 5.2664', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99539495)
('DISCRIMINATOR_Imagem FAKE=', 0.0050713741)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.757498')
----------------------------------
End of training
Saving histograms
----------------------------------
('Total samples = ', 5000, ' Batch size =', 256, ' Epochs = ', 50)
('Generator loss 5.2517 ', 'Discriminator loss 0.0147', 'Total: 5.2664')
----------------------------------
---DISCRIMINATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_14 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_3[0][0]      
____________________________________________________________________________________________________
leakyrelu_14 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_14[0][0]           
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_14[0][0]               
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 32, 8, 8)      4640        dropout_6[0][0]                  
____________________________________________________________________________________________________
leakyrelu_15 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_15[0][0]           
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_15[0][0]               
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 64, 4, 4)      18496       dropout_7[0][0]                  
____________________________________________________________________________________________________
leakyrelu_16 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_16[0][0]               
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 128, 2, 2)     73856       dropout_8[0][0]                  
____________________________________________________________________________________________________
leakyrelu_17 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_17[0][0]           
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_17[0][0]               
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 512)           0           dropout_9[0][0]                  
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 256)           131328      flatten_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_18 (LeakyReLU)         (None, 256)           0           dense_3[0][0]                    
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 256)           0           leakyrelu_18[0][0]               
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 1)             257         dropout_10[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
None
----------------------------------
---GENERATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_18 (Convolution2D) (None, 32, 32, 32)    320         convolution2d_input_4[0][0]      
____________________________________________________________________________________________________
leakyrelu_19 (LeakyReLU)         (None, 32, 32, 32)    0           convolution2d_18[0][0]           
____________________________________________________________________________________________________
convolution2d_19 (Convolution2D) (None, 64, 32, 32)    18496       leakyrelu_19[0][0]               
____________________________________________________________________________________________________
batchnormalization_8 (BatchNormal(None, 64, 32, 32)    128         convolution2d_19[0][0]           
____________________________________________________________________________________________________
leakyrelu_20 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_8[0][0]       
____________________________________________________________________________________________________
convolution2d_20 (Convolution2D) (None, 128, 32, 32)   73856       leakyrelu_20[0][0]               
____________________________________________________________________________________________________
batchnormalization_9 (BatchNormal(None, 128, 32, 32)   256         convolution2d_20[0][0]           
____________________________________________________________________________________________________
leakyrelu_21 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_9[0][0]       
____________________________________________________________________________________________________
convolution2d_21 (Convolution2D) (None, 256, 32, 32)   295168      leakyrelu_21[0][0]               
____________________________________________________________________________________________________
batchnormalization_10 (BatchNorma(None, 256, 32, 32)   512         convolution2d_21[0][0]           
____________________________________________________________________________________________________
leakyrelu_22 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_10[0][0]      
____________________________________________________________________________________________________
convolution2d_22 (Convolution2D) (None, 256, 32, 32)   590080      leakyrelu_22[0][0]               
____________________________________________________________________________________________________
batchnormalization_11 (BatchNorma(None, 256, 32, 32)   512         convolution2d_22[0][0]           
____________________________________________________________________________________________________
leakyrelu_23 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_11[0][0]      
____________________________________________________________________________________________________
convolution2d_23 (Convolution2D) (None, 128, 32, 32)   295040      leakyrelu_23[0][0]               
____________________________________________________________________________________________________
batchnormalization_12 (BatchNorma(None, 128, 32, 32)   256         convolution2d_23[0][0]           
____________________________________________________________________________________________________
leakyrelu_24 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_12[0][0]      
____________________________________________________________________________________________________
convolution2d_24 (Convolution2D) (None, 64, 32, 32)    73792       leakyrelu_24[0][0]               
____________________________________________________________________________________________________
batchnormalization_13 (BatchNorma(None, 64, 32, 32)    128         convolution2d_24[0][0]           
____________________________________________________________________________________________________
leakyrelu_25 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_13[0][0]      
____________________________________________________________________________________________________
convolution2d_25 (Convolution2D) (None, 32, 32, 32)    18464       leakyrelu_25[0][0]               
____________________________________________________________________________________________________
batchnormalization_14 (BatchNorma(None, 32, 32, 32)    64          convolution2d_25[0][0]           
____________________________________________________________________________________________________
leakyrelu_26 (LeakyReLU)         (None, 32, 32, 32)    0           batchnormalization_14[0][0]      
____________________________________________________________________________________________________
convolution2d_26 (Convolution2D) (None, 2, 32, 32)     578         leakyrelu_26[0][0]               
____________________________________________________________________________________________________
lambda_2 (Lambda)                (None, 2, 32, 32)     0           convolution2d_26[0][0]           
====================================================================================================
Total params: 1367650
____________________________________________________________________________________________________
None
----------------------------------
---GAN---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_5 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_4 (Sequential)        (None, 1)             0           lambda_2[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
None
----------------------------------
('Training with dataset based on class - ', 'bird', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_8 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_7 (Sequential)        (None, 1)             0           lambda_3[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_27 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_5[0][0]      
____________________________________________________________________________________________________
leakyrelu_27 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_27[0][0]           
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 16, 16, 16)    0           leakyrelu_27[0][0]               
____________________________________________________________________________________________________
convolution2d_28 (Convolution2D) (None, 32, 8, 8)      4640        dropout_11[0][0]                 
____________________________________________________________________________________________________
leakyrelu_28 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_28[0][0]           
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 32, 8, 8)      0           leakyrelu_28[0][0]               
____________________________________________________________________________________________________
convolution2d_29 (Convolution2D) (None, 64, 4, 4)      18496       dropout_12[0][0]                 
____________________________________________________________________________________________________
leakyrelu_29 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_29[0][0]           
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 64, 4, 4)      0           leakyrelu_29[0][0]               
____________________________________________________________________________________________________
convolution2d_30 (Convolution2D) (None, 128, 2, 2)     73856       dropout_13[0][0]                 
____________________________________________________________________________________________________
leakyrelu_30 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_30[0][0]           
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 128, 2, 2)     0           leakyrelu_30[0][0]               
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 512)           0           dropout_14[0][0]                 
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 256)           131328      flatten_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_31 (LeakyReLU)         (None, 256)           0           dense_5[0][0]                    
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 256)           0           leakyrelu_31[0][0]               
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 1)             257         dropout_15[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.3310 ', 'GAN acc 0.9141', 'Discriminator loss 1.1073', 'Discriminator accuracy 0.4707', 'Total loss: 1.4383', 'for batch', 0)
('GAN loss 0.2328 ', 'GAN acc 0.9609', 'Discriminator loss 1.2489', 'Discriminator accuracy 0.4629', 'Total loss: 1.4817', 'for batch', 1)
('GAN loss 0.2671 ', 'GAN acc 0.9570', 'Discriminator loss 1.2381', 'Discriminator accuracy 0.4805', 'Total loss: 1.5052', 'for batch', 2)
('GAN loss 0.3733 ', 'GAN acc 0.8672', 'Discriminator loss 1.1869', 'Discriminator accuracy 0.4941', 'Total loss: 1.5602', 'for batch', 3)
('GAN loss 0.5009 ', 'GAN acc 0.7773', 'Discriminator loss 0.9841', 'Discriminator accuracy 0.5117', 'Total loss: 1.4850', 'for batch', 4)
('GAN loss 0.5134 ', 'GAN acc 0.7344', 'Discriminator loss 1.0695', 'Discriminator accuracy 0.5352', 'Total loss: 1.5829', 'for batch', 5)
('GAN loss 0.5510 ', 'GAN acc 0.7539', 'Discriminator loss 0.8331', 'Discriminator accuracy 0.5742', 'Total loss: 1.3840', 'for batch', 6)
('GAN loss 0.5998 ', 'GAN acc 0.6758', 'Discriminator loss 0.7646', 'Discriminator accuracy 0.5723', 'Total loss: 1.3645', 'for batch', 7)
('GAN loss 0.6102 ', 'GAN acc 0.6641', 'Discriminator loss 0.7125', 'Discriminator accuracy 0.6270', 'Total loss: 1.3227', 'for batch', 8)
('GAN loss 0.6014 ', 'GAN acc 0.6797', 'Discriminator loss 0.6028', 'Discriminator accuracy 0.6309', 'Total loss: 1.2042', 'for batch', 9)
('GAN loss 0.7425 ', 'GAN acc 0.5508', 'Discriminator loss 0.5474', 'Discriminator accuracy 0.6465', 'Total loss: 1.2900', 'for batch', 10)
('GAN loss 0.6791 ', 'GAN acc 0.5898', 'Discriminator loss 0.5591', 'Discriminator accuracy 0.6309', 'Total loss: 1.2382', 'for batch', 11)
('GAN loss 0.7498 ', 'GAN acc 0.4648', 'Discriminator loss 0.5299', 'Discriminator accuracy 0.6562', 'Total loss: 1.2796', 'for batch', 12)
('GAN loss 0.7352 ', 'GAN acc 0.5156', 'Discriminator loss 0.5710', 'Discriminator accuracy 0.6777', 'Total loss: 1.3062', 'for batch', 13)
('GAN loss 0.7184 ', 'GAN acc 0.5430', 'Discriminator loss 0.5285', 'Discriminator accuracy 0.6895', 'Total loss: 1.2469', 'for batch', 14)
('GAN loss 0.7387 ', 'GAN acc 0.4727', 'Discriminator loss 0.4949', 'Discriminator accuracy 0.6816', 'Total loss: 1.2336', 'for batch', 15)
('GAN loss 0.7722 ', 'GAN acc 0.4844', 'Discriminator loss 0.4626', 'Discriminator accuracy 0.6836', 'Total loss: 1.2348', 'for batch', 16)
('GAN loss 0.7757 ', 'GAN acc 0.4844', 'Discriminator loss 0.5602', 'Discriminator accuracy 0.7207', 'Total loss: 1.3359', 'for batch', 17)
('GAN loss 0.7379 ', 'GAN acc 0.4844', 'Discriminator loss 0.5083', 'Discriminator accuracy 0.6973', 'Total loss: 1.2462', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96065164)
('DISCRIMINATOR_Imagem FAKE=', 0.48972613)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.545286')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6847 ', 'GAN acc 0.5742', 'Discriminator loss 0.5342', 'Discriminator accuracy 0.6738', 'Total loss: 1.2189', 'for batch', 0)
('GAN loss 0.6820 ', 'GAN acc 0.5703', 'Discriminator loss 0.6141', 'Discriminator accuracy 0.6465', 'Total loss: 1.2961', 'for batch', 1)
('GAN loss 0.6760 ', 'GAN acc 0.5664', 'Discriminator loss 0.5328', 'Discriminator accuracy 0.6582', 'Total loss: 1.2088', 'for batch', 2)
('GAN loss 0.6622 ', 'GAN acc 0.6055', 'Discriminator loss 0.6626', 'Discriminator accuracy 0.6348', 'Total loss: 1.3248', 'for batch', 3)
('GAN loss 0.6413 ', 'GAN acc 0.6211', 'Discriminator loss 0.4850', 'Discriminator accuracy 0.6504', 'Total loss: 1.1263', 'for batch', 4)
('GAN loss 0.6553 ', 'GAN acc 0.6289', 'Discriminator loss 0.4890', 'Discriminator accuracy 0.6426', 'Total loss: 1.1443', 'for batch', 5)
('GAN loss 0.6628 ', 'GAN acc 0.5938', 'Discriminator loss 0.6120', 'Discriminator accuracy 0.6465', 'Total loss: 1.2747', 'for batch', 6)
('GAN loss 0.7159 ', 'GAN acc 0.5859', 'Discriminator loss 0.5393', 'Discriminator accuracy 0.6172', 'Total loss: 1.2552', 'for batch', 7)
('GAN loss 0.7803 ', 'GAN acc 0.4453', 'Discriminator loss 0.4480', 'Discriminator accuracy 0.6914', 'Total loss: 1.2282', 'for batch', 8)
('GAN loss 0.7942 ', 'GAN acc 0.4062', 'Discriminator loss 0.4567', 'Discriminator accuracy 0.7207', 'Total loss: 1.2509', 'for batch', 9)
('GAN loss 0.9392 ', 'GAN acc 0.2734', 'Discriminator loss 0.3915', 'Discriminator accuracy 0.7695', 'Total loss: 1.3306', 'for batch', 10)
('GAN loss 0.8390 ', 'GAN acc 0.3320', 'Discriminator loss 0.4527', 'Discriminator accuracy 0.8203', 'Total loss: 1.2917', 'for batch', 11)
('GAN loss 0.7768 ', 'GAN acc 0.4180', 'Discriminator loss 0.4425', 'Discriminator accuracy 0.8242', 'Total loss: 1.2193', 'for batch', 12)
('GAN loss 0.7027 ', 'GAN acc 0.4922', 'Discriminator loss 0.6204', 'Discriminator accuracy 0.7598', 'Total loss: 1.3230', 'for batch', 13)
('GAN loss 0.6714 ', 'GAN acc 0.5938', 'Discriminator loss 0.4323', 'Discriminator accuracy 0.7266', 'Total loss: 1.1037', 'for batch', 14)
('GAN loss 0.6816 ', 'GAN acc 0.5352', 'Discriminator loss 0.4141', 'Discriminator accuracy 0.7031', 'Total loss: 1.0957', 'for batch', 15)
('GAN loss 0.6946 ', 'GAN acc 0.5664', 'Discriminator loss 0.4715', 'Discriminator accuracy 0.6934', 'Total loss: 1.1661', 'for batch', 16)
('GAN loss 0.6879 ', 'GAN acc 0.5508', 'Discriminator loss 0.4945', 'Discriminator accuracy 0.6406', 'Total loss: 1.1824', 'for batch', 17)
('GAN loss 0.6872 ', 'GAN acc 0.5547', 'Discriminator loss 0.4656', 'Discriminator accuracy 0.6680', 'Total loss: 1.1528', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96852797)
('DISCRIMINATOR_Imagem FAKE=', 0.48234814)
('Discriminator trained', 6, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.111633')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7912 ', 'GAN acc 0.4102', 'Discriminator loss 0.3967', 'Discriminator accuracy 0.7051', 'Total loss: 1.1880', 'for batch', 0)
('GAN loss 0.7538 ', 'GAN acc 0.4336', 'Discriminator loss 0.5496', 'Discriminator accuracy 0.7637', 'Total loss: 1.3034', 'for batch', 1)
('GAN loss 0.6879 ', 'GAN acc 0.5469', 'Discriminator loss 0.4898', 'Discriminator accuracy 0.7012', 'Total loss: 1.1777', 'for batch', 2)
('GAN loss 0.7142 ', 'GAN acc 0.5312', 'Discriminator loss 0.4205', 'Discriminator accuracy 0.7363', 'Total loss: 1.1347', 'for batch', 3)
('GAN loss 0.7124 ', 'GAN acc 0.5078', 'Discriminator loss 0.4327', 'Discriminator accuracy 0.7109', 'Total loss: 1.1450', 'for batch', 4)
('GAN loss 0.7106 ', 'GAN acc 0.4688', 'Discriminator loss 0.4249', 'Discriminator accuracy 0.7246', 'Total loss: 1.1355', 'for batch', 5)
('GAN loss 0.8063 ', 'GAN acc 0.3633', 'Discriminator loss 0.3992', 'Discriminator accuracy 0.7227', 'Total loss: 1.2055', 'for batch', 6)
('GAN loss 0.8789 ', 'GAN acc 0.2344', 'Discriminator loss 0.3968', 'Discriminator accuracy 0.8105', 'Total loss: 1.2757', 'for batch', 7)
('GAN loss 0.8451 ', 'GAN acc 0.2383', 'Discriminator loss 0.3646', 'Discriminator accuracy 0.8301', 'Total loss: 1.2097', 'for batch', 8)
('GAN loss 0.8957 ', 'GAN acc 0.2031', 'Discriminator loss 0.3450', 'Discriminator accuracy 0.8555', 'Total loss: 1.2407', 'for batch', 9)
('GAN loss 0.8972 ', 'GAN acc 0.1797', 'Discriminator loss 0.3670', 'Discriminator accuracy 0.8320', 'Total loss: 1.2642', 'for batch', 10)
('GAN loss 0.7667 ', 'GAN acc 0.3398', 'Discriminator loss 0.4588', 'Discriminator accuracy 0.8086', 'Total loss: 1.2255', 'for batch', 11)
('GAN loss 0.7337 ', 'GAN acc 0.4297', 'Discriminator loss 0.4457', 'Discriminator accuracy 0.7793', 'Total loss: 1.1794', 'for batch', 12)
('GAN loss 0.7409 ', 'GAN acc 0.3672', 'Discriminator loss 0.4226', 'Discriminator accuracy 0.7363', 'Total loss: 1.1635', 'for batch', 13)
('GAN loss 0.7392 ', 'GAN acc 0.4258', 'Discriminator loss 0.4801', 'Discriminator accuracy 0.7227', 'Total loss: 1.2193', 'for batch', 14)
('GAN loss 0.7610 ', 'GAN acc 0.4023', 'Discriminator loss 0.3806', 'Discriminator accuracy 0.7461', 'Total loss: 1.1416', 'for batch', 15)
('GAN loss 0.8208 ', 'GAN acc 0.3125', 'Discriminator loss 0.3879', 'Discriminator accuracy 0.7812', 'Total loss: 1.2087', 'for batch', 16)
('GAN loss 0.8483 ', 'GAN acc 0.2383', 'Discriminator loss 0.4484', 'Discriminator accuracy 0.8047', 'Total loss: 1.2967', 'for batch', 17)
('GAN loss 0.9381 ', 'GAN acc 0.1602', 'Discriminator loss 0.3988', 'Discriminator accuracy 0.8379', 'Total loss: 1.3369', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.96936524)
('DISCRIMINATOR_Imagem FAKE=', 0.40717834)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.662292')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9837 ', 'GAN acc 0.0820', 'Discriminator loss 0.3592', 'Discriminator accuracy 0.8672', 'Total loss: 1.3429', 'for batch', 0)
('GAN loss 0.8383 ', 'GAN acc 0.2969', 'Discriminator loss 0.3945', 'Discriminator accuracy 0.8594', 'Total loss: 1.2327', 'for batch', 1)
('GAN loss 0.7019 ', 'GAN acc 0.5000', 'Discriminator loss 0.4423', 'Discriminator accuracy 0.7500', 'Total loss: 1.1442', 'for batch', 2)
('GAN loss 0.7097 ', 'GAN acc 0.4961', 'Discriminator loss 0.4737', 'Discriminator accuracy 0.6973', 'Total loss: 1.1834', 'for batch', 3)
('GAN loss 0.8037 ', 'GAN acc 0.3203', 'Discriminator loss 0.3741', 'Discriminator accuracy 0.7539', 'Total loss: 1.1778', 'for batch', 4)
('GAN loss 0.9189 ', 'GAN acc 0.2109', 'Discriminator loss 0.3767', 'Discriminator accuracy 0.7910', 'Total loss: 1.2956', 'for batch', 5)
('GAN loss 1.0139 ', 'GAN acc 0.1328', 'Discriminator loss 0.3384', 'Discriminator accuracy 0.8730', 'Total loss: 1.3523', 'for batch', 6)
('GAN loss 1.0375 ', 'GAN acc 0.0859', 'Discriminator loss 0.3692', 'Discriminator accuracy 0.9082', 'Total loss: 1.4066', 'for batch', 7)
('GAN loss 0.9631 ', 'GAN acc 0.1016', 'Discriminator loss 0.3151', 'Discriminator accuracy 0.9395', 'Total loss: 1.2782', 'for batch', 8)
('GAN loss 0.9287 ', 'GAN acc 0.0625', 'Discriminator loss 0.3556', 'Discriminator accuracy 0.9199', 'Total loss: 1.2843', 'for batch', 9)
('GAN loss 0.9189 ', 'GAN acc 0.1055', 'Discriminator loss 0.3270', 'Discriminator accuracy 0.9375', 'Total loss: 1.2460', 'for batch', 10)
('GAN loss 0.8890 ', 'GAN acc 0.0898', 'Discriminator loss 0.3560', 'Discriminator accuracy 0.9492', 'Total loss: 1.2450', 'for batch', 11)
('GAN loss 0.8658 ', 'GAN acc 0.1055', 'Discriminator loss 0.3938', 'Discriminator accuracy 0.9355', 'Total loss: 1.2597', 'for batch', 12)
('GAN loss 0.8328 ', 'GAN acc 0.1719', 'Discriminator loss 0.3480', 'Discriminator accuracy 0.9082', 'Total loss: 1.1808', 'for batch', 13)
('GAN loss 0.8262 ', 'GAN acc 0.1836', 'Discriminator loss 0.3601', 'Discriminator accuracy 0.8672', 'Total loss: 1.1863', 'for batch', 14)
('GAN loss 0.8152 ', 'GAN acc 0.2148', 'Discriminator loss 0.3523', 'Discriminator accuracy 0.8359', 'Total loss: 1.1675', 'for batch', 15)
('GAN loss 0.8468 ', 'GAN acc 0.1797', 'Discriminator loss 0.3160', 'Discriminator accuracy 0.8691', 'Total loss: 1.1628', 'for batch', 16)
('GAN loss 0.8848 ', 'GAN acc 0.1523', 'Discriminator loss 0.3566', 'Discriminator accuracy 0.8691', 'Total loss: 1.2414', 'for batch', 17)
('GAN loss 0.8747 ', 'GAN acc 0.1797', 'Discriminator loss 0.3415', 'Discriminator accuracy 0.9062', 'Total loss: 1.2162', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98377419)
('DISCRIMINATOR_Imagem FAKE=', 0.41289335)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.204001')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8489 ', 'GAN acc 0.1836', 'Discriminator loss 0.3144', 'Discriminator accuracy 0.8906', 'Total loss: 1.1634', 'for batch', 0)
('GAN loss 0.9218 ', 'GAN acc 0.1172', 'Discriminator loss 0.2962', 'Discriminator accuracy 0.8945', 'Total loss: 1.2180', 'for batch', 1)
('GAN loss 0.9807 ', 'GAN acc 0.0898', 'Discriminator loss 0.3310', 'Discriminator accuracy 0.9023', 'Total loss: 1.3117', 'for batch', 2)
('GAN loss 0.9999 ', 'GAN acc 0.0664', 'Discriminator loss 0.3498', 'Discriminator accuracy 0.9336', 'Total loss: 1.3497', 'for batch', 3)
('GAN loss 1.0114 ', 'GAN acc 0.0508', 'Discriminator loss 0.2835', 'Discriminator accuracy 0.9512', 'Total loss: 1.2949', 'for batch', 4)
('GAN loss 1.0327 ', 'GAN acc 0.0312', 'Discriminator loss 0.2538', 'Discriminator accuracy 0.9688', 'Total loss: 1.2865', 'for batch', 5)
('GAN loss 1.0591 ', 'GAN acc 0.0117', 'Discriminator loss 0.2701', 'Discriminator accuracy 0.9707', 'Total loss: 1.3293', 'for batch', 6)
('GAN loss 1.0327 ', 'GAN acc 0.0039', 'Discriminator loss 0.2615', 'Discriminator accuracy 0.9805', 'Total loss: 1.2943', 'for batch', 7)
('GAN loss 1.0645 ', 'GAN acc 0.0195', 'Discriminator loss 0.2329', 'Discriminator accuracy 0.9883', 'Total loss: 1.2973', 'for batch', 8)
('GAN loss 1.0550 ', 'GAN acc 0.0078', 'Discriminator loss 0.2373', 'Discriminator accuracy 0.9883', 'Total loss: 1.2923', 'for batch', 9)
('GAN loss 1.0876 ', 'GAN acc 0.0078', 'Discriminator loss 0.2674', 'Discriminator accuracy 0.9883', 'Total loss: 1.3550', 'for batch', 10)
('GAN loss 1.0978 ', 'GAN acc 0.0117', 'Discriminator loss 0.2970', 'Discriminator accuracy 0.9746', 'Total loss: 1.3948', 'for batch', 11)
('GAN loss 1.0870 ', 'GAN acc 0.0117', 'Discriminator loss 0.2956', 'Discriminator accuracy 0.9844', 'Total loss: 1.3827', 'for batch', 12)
('GAN loss 1.0741 ', 'GAN acc 0.0039', 'Discriminator loss 0.2918', 'Discriminator accuracy 0.9805', 'Total loss: 1.3659', 'for batch', 13)
('GAN loss 1.0407 ', 'GAN acc 0.0000', 'Discriminator loss 0.2514', 'Discriminator accuracy 0.9941', 'Total loss: 1.2920', 'for batch', 14)
('GAN loss 1.0318 ', 'GAN acc 0.0078', 'Discriminator loss 0.2486', 'Discriminator accuracy 0.9883', 'Total loss: 1.2803', 'for batch', 15)
('GAN loss 1.0373 ', 'GAN acc 0.0078', 'Discriminator loss 0.2301', 'Discriminator accuracy 0.9863', 'Total loss: 1.2674', 'for batch', 16)
('GAN loss 1.0665 ', 'GAN acc 0.0117', 'Discriminator loss 0.2627', 'Discriminator accuracy 0.9766', 'Total loss: 1.3292', 'for batch', 17)
('GAN loss 1.1091 ', 'GAN acc 0.0117', 'Discriminator loss 0.2740', 'Discriminator accuracy 0.9766', 'Total loss: 1.3831', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98371369)
('DISCRIMINATOR_Imagem FAKE=', 0.34382826)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.671720')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1054 ', 'GAN acc 0.0078', 'Discriminator loss 0.2681', 'Discriminator accuracy 0.9785', 'Total loss: 1.3735', 'for batch', 0)
('GAN loss 1.0632 ', 'GAN acc 0.0352', 'Discriminator loss 0.2736', 'Discriminator accuracy 0.9707', 'Total loss: 1.3368', 'for batch', 1)
('GAN loss 1.0925 ', 'GAN acc 0.0820', 'Discriminator loss 0.2849', 'Discriminator accuracy 0.9102', 'Total loss: 1.3774', 'for batch', 2)
('GAN loss 1.0906 ', 'GAN acc 0.1055', 'Discriminator loss 0.4506', 'Discriminator accuracy 0.8730', 'Total loss: 1.5412', 'for batch', 3)
('GAN loss 1.2248 ', 'GAN acc 0.0938', 'Discriminator loss 0.2685', 'Discriminator accuracy 0.9199', 'Total loss: 1.4933', 'for batch', 4)
('GAN loss 1.2870 ', 'GAN acc 0.0352', 'Discriminator loss 0.2515', 'Discriminator accuracy 0.9512', 'Total loss: 1.5385', 'for batch', 5)
('GAN loss 1.2963 ', 'GAN acc 0.0078', 'Discriminator loss 0.2009', 'Discriminator accuracy 0.9785', 'Total loss: 1.4972', 'for batch', 6)
('GAN loss 1.2824 ', 'GAN acc 0.0117', 'Discriminator loss 0.3336', 'Discriminator accuracy 0.9844', 'Total loss: 1.6160', 'for batch', 7)
('GAN loss 1.2177 ', 'GAN acc 0.0117', 'Discriminator loss 0.2430', 'Discriminator accuracy 0.9844', 'Total loss: 1.4608', 'for batch', 8)
('GAN loss 1.1876 ', 'GAN acc 0.0078', 'Discriminator loss 0.2179', 'Discriminator accuracy 0.9863', 'Total loss: 1.4056', 'for batch', 9)
('GAN loss 1.2188 ', 'GAN acc 0.0039', 'Discriminator loss 0.2262', 'Discriminator accuracy 0.9824', 'Total loss: 1.4450', 'for batch', 10)
('GAN loss 1.2674 ', 'GAN acc 0.0039', 'Discriminator loss 0.2845', 'Discriminator accuracy 0.9863', 'Total loss: 1.5518', 'for batch', 11)
('GAN loss 1.2595 ', 'GAN acc 0.0039', 'Discriminator loss 0.2261', 'Discriminator accuracy 0.9883', 'Total loss: 1.4856', 'for batch', 12)
('GAN loss 1.2788 ', 'GAN acc 0.0039', 'Discriminator loss 0.3092', 'Discriminator accuracy 0.9805', 'Total loss: 1.5880', 'for batch', 13)
('GAN loss 1.2496 ', 'GAN acc 0.0117', 'Discriminator loss 0.1925', 'Discriminator accuracy 0.9902', 'Total loss: 1.4421', 'for batch', 14)
('GAN loss 1.2724 ', 'GAN acc 0.0039', 'Discriminator loss 0.2477', 'Discriminator accuracy 0.9824', 'Total loss: 1.5201', 'for batch', 15)
('GAN loss 1.3013 ', 'GAN acc 0.0078', 'Discriminator loss 0.2138', 'Discriminator accuracy 0.9824', 'Total loss: 1.5151', 'for batch', 16)
('GAN loss 1.3135 ', 'GAN acc 0.0117', 'Discriminator loss 0.2653', 'Discriminator accuracy 0.9785', 'Total loss: 1.5787', 'for batch', 17)
('GAN loss 1.3170 ', 'GAN acc 0.0156', 'Discriminator loss 0.2616', 'Discriminator accuracy 0.9766', 'Total loss: 1.5787', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98004442)
('DISCRIMINATOR_Imagem FAKE=', 0.28488508)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.299259')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 1.3865 ', 'GAN acc 0.0078', 'Discriminator loss 0.1893', 'Discriminator accuracy 0.9824', 'Total loss: 1.5758', 'for batch', 0)
('GAN loss 1.4829 ', 'GAN acc 0.0078', 'Discriminator loss 0.1676', 'Discriminator accuracy 0.9941', 'Total loss: 1.6505', 'for batch', 1)
('GAN loss 1.4799 ', 'GAN acc 0.0000', 'Discriminator loss 0.2561', 'Discriminator accuracy 0.9766', 'Total loss: 1.7360', 'for batch', 2)
('GAN loss 1.3562 ', 'GAN acc 0.0000', 'Discriminator loss 0.3063', 'Discriminator accuracy 0.9746', 'Total loss: 1.6625', 'for batch', 3)
('GAN loss 1.3782 ', 'GAN acc 0.0078', 'Discriminator loss 0.1705', 'Discriminator accuracy 0.9863', 'Total loss: 1.5488', 'for batch', 4)
('GAN loss 1.4032 ', 'GAN acc 0.0039', 'Discriminator loss 0.2264', 'Discriminator accuracy 0.9863', 'Total loss: 1.6295', 'for batch', 5)
('GAN loss 1.4352 ', 'GAN acc 0.0117', 'Discriminator loss 0.1703', 'Discriminator accuracy 0.9844', 'Total loss: 1.6055', 'for batch', 6)
('GAN loss 1.4990 ', 'GAN acc 0.0039', 'Discriminator loss 0.2019', 'Discriminator accuracy 0.9883', 'Total loss: 1.7008', 'for batch', 7)
('GAN loss 1.5084 ', 'GAN acc 0.0039', 'Discriminator loss 0.1418', 'Discriminator accuracy 1.0000', 'Total loss: 1.6502', 'for batch', 8)
('GAN loss 1.5896 ', 'GAN acc 0.0000', 'Discriminator loss 0.1346', 'Discriminator accuracy 1.0000', 'Total loss: 1.7242', 'for batch', 9)
('GAN loss 1.6743 ', 'GAN acc 0.0000', 'Discriminator loss 0.1639', 'Discriminator accuracy 0.9961', 'Total loss: 1.8382', 'for batch', 10)
('GAN loss 1.6046 ', 'GAN acc 0.0000', 'Discriminator loss 0.2116', 'Discriminator accuracy 0.9844', 'Total loss: 1.8163', 'for batch', 11)
('GAN loss 1.6235 ', 'GAN acc 0.0000', 'Discriminator loss 0.1499', 'Discriminator accuracy 0.9961', 'Total loss: 1.7733', 'for batch', 12)
('GAN loss 1.5605 ', 'GAN acc 0.0000', 'Discriminator loss 0.2279', 'Discriminator accuracy 0.9863', 'Total loss: 1.7884', 'for batch', 13)
('GAN loss 1.5175 ', 'GAN acc 0.0039', 'Discriminator loss 0.1455', 'Discriminator accuracy 0.9941', 'Total loss: 1.6629', 'for batch', 14)
('GAN loss 1.4280 ', 'GAN acc 0.0117', 'Discriminator loss 0.1899', 'Discriminator accuracy 0.9844', 'Total loss: 1.6179', 'for batch', 15)
('GAN loss 1.4468 ', 'GAN acc 0.0234', 'Discriminator loss 0.1702', 'Discriminator accuracy 0.9766', 'Total loss: 1.6170', 'for batch', 16)
('GAN loss 1.4695 ', 'GAN acc 0.0430', 'Discriminator loss 0.2169', 'Discriminator accuracy 0.9551', 'Total loss: 1.6864', 'for batch', 17)
('GAN loss 1.7098 ', 'GAN acc 0.0078', 'Discriminator loss 0.1771', 'Discriminator accuracy 0.9707', 'Total loss: 1.8869', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98242384)
('DISCRIMINATOR_Imagem FAKE=', 0.23038217)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.820467')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 1.7762 ', 'GAN acc 0.0078', 'Discriminator loss 0.1801', 'Discriminator accuracy 0.9883', 'Total loss: 1.9563', 'for batch', 0)
('GAN loss 1.7755 ', 'GAN acc 0.0000', 'Discriminator loss 0.1411', 'Discriminator accuracy 0.9883', 'Total loss: 1.9166', 'for batch', 1)
('GAN loss 1.8444 ', 'GAN acc 0.0000', 'Discriminator loss 0.1782', 'Discriminator accuracy 0.9824', 'Total loss: 2.0226', 'for batch', 2)
('GAN loss 1.8509 ', 'GAN acc 0.0000', 'Discriminator loss 0.2997', 'Discriminator accuracy 0.9805', 'Total loss: 2.1506', 'for batch', 3)
('GAN loss 1.7874 ', 'GAN acc 0.0000', 'Discriminator loss 0.1834', 'Discriminator accuracy 0.9824', 'Total loss: 1.9708', 'for batch', 4)
('GAN loss 1.7793 ', 'GAN acc 0.0000', 'Discriminator loss 0.1722', 'Discriminator accuracy 0.9883', 'Total loss: 1.9515', 'for batch', 5)
('GAN loss 1.7169 ', 'GAN acc 0.0039', 'Discriminator loss 0.1748', 'Discriminator accuracy 0.9844', 'Total loss: 1.8917', 'for batch', 6)
('GAN loss 1.7643 ', 'GAN acc 0.0000', 'Discriminator loss 0.1630', 'Discriminator accuracy 0.9941', 'Total loss: 1.9273', 'for batch', 7)
('GAN loss 1.8180 ', 'GAN acc 0.0000', 'Discriminator loss 0.1232', 'Discriminator accuracy 0.9980', 'Total loss: 1.9413', 'for batch', 8)
('GAN loss 2.0718 ', 'GAN acc 0.0039', 'Discriminator loss 0.1121', 'Discriminator accuracy 0.9961', 'Total loss: 2.1839', 'for batch', 9)
('GAN loss 2.1531 ', 'GAN acc 0.0000', 'Discriminator loss 0.1519', 'Discriminator accuracy 0.9902', 'Total loss: 2.3050', 'for batch', 10)
('GAN loss 2.1511 ', 'GAN acc 0.0000', 'Discriminator loss 0.1685', 'Discriminator accuracy 0.9883', 'Total loss: 2.3196', 'for batch', 11)
('GAN loss 2.1453 ', 'GAN acc 0.0000', 'Discriminator loss 0.1244', 'Discriminator accuracy 0.9902', 'Total loss: 2.2697', 'for batch', 12)
('GAN loss 2.1405 ', 'GAN acc 0.0000', 'Discriminator loss 0.1166', 'Discriminator accuracy 0.9980', 'Total loss: 2.2571', 'for batch', 13)
('GAN loss 2.0495 ', 'GAN acc 0.0000', 'Discriminator loss 0.1534', 'Discriminator accuracy 0.9922', 'Total loss: 2.2029', 'for batch', 14)
('GAN loss 2.1275 ', 'GAN acc 0.0000', 'Discriminator loss 0.0975', 'Discriminator accuracy 0.9941', 'Total loss: 2.2250', 'for batch', 15)
('GAN loss 2.2531 ', 'GAN acc 0.0000', 'Discriminator loss 0.0773', 'Discriminator accuracy 0.9961', 'Total loss: 2.3304', 'for batch', 16)
('GAN loss 2.2129 ', 'GAN acc 0.0000', 'Discriminator loss 0.1587', 'Discriminator accuracy 0.9883', 'Total loss: 2.3716', 'for batch', 17)
('GAN loss 2.1562 ', 'GAN acc 0.0000', 'Discriminator loss 0.0843', 'Discriminator accuracy 0.9980', 'Total loss: 2.2404', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9863829)
('DISCRIMINATOR_Imagem FAKE=', 0.11575659)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.363192')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 2.3233 ', 'GAN acc 0.0000', 'Discriminator loss 0.1102', 'Discriminator accuracy 0.9941', 'Total loss: 2.4334', 'for batch', 0)
('GAN loss 2.5936 ', 'GAN acc 0.0000', 'Discriminator loss 0.1090', 'Discriminator accuracy 0.9922', 'Total loss: 2.7026', 'for batch', 1)
('GAN loss 2.5160 ', 'GAN acc 0.0000', 'Discriminator loss 0.1372', 'Discriminator accuracy 0.9766', 'Total loss: 2.6532', 'for batch', 2)
('GAN loss 2.5142 ', 'GAN acc 0.0000', 'Discriminator loss 0.1035', 'Discriminator accuracy 0.9844', 'Total loss: 2.6176', 'for batch', 3)
('GAN loss 2.4972 ', 'GAN acc 0.0000', 'Discriminator loss 0.0890', 'Discriminator accuracy 0.9883', 'Total loss: 2.5862', 'for batch', 4)
('GAN loss 2.4986 ', 'GAN acc 0.0000', 'Discriminator loss 0.0815', 'Discriminator accuracy 0.9941', 'Total loss: 2.5801', 'for batch', 5)
('GAN loss 2.5919 ', 'GAN acc 0.0000', 'Discriminator loss 0.0967', 'Discriminator accuracy 0.9941', 'Total loss: 2.6886', 'for batch', 6)
('GAN loss 2.4393 ', 'GAN acc 0.0000', 'Discriminator loss 0.0610', 'Discriminator accuracy 1.0000', 'Total loss: 2.5003', 'for batch', 7)
('GAN loss 2.4161 ', 'GAN acc 0.0000', 'Discriminator loss 0.0961', 'Discriminator accuracy 0.9941', 'Total loss: 2.5122', 'for batch', 8)
('GAN loss 2.5001 ', 'GAN acc 0.0000', 'Discriminator loss 0.0662', 'Discriminator accuracy 1.0000', 'Total loss: 2.5663', 'for batch', 9)
('GAN loss 2.5449 ', 'GAN acc 0.0000', 'Discriminator loss 0.1238', 'Discriminator accuracy 0.9922', 'Total loss: 2.6688', 'for batch', 10)
('GAN loss 2.5391 ', 'GAN acc 0.0000', 'Discriminator loss 0.1107', 'Discriminator accuracy 0.9902', 'Total loss: 2.6497', 'for batch', 11)
('GAN loss 2.3882 ', 'GAN acc 0.0039', 'Discriminator loss 0.1343', 'Discriminator accuracy 0.9902', 'Total loss: 2.5225', 'for batch', 12)
('GAN loss 2.4127 ', 'GAN acc 0.0195', 'Discriminator loss 0.1509', 'Discriminator accuracy 0.9766', 'Total loss: 2.5636', 'for batch', 13)
('GAN loss 2.5775 ', 'GAN acc 0.0273', 'Discriminator loss 0.1648', 'Discriminator accuracy 0.9531', 'Total loss: 2.7423', 'for batch', 14)
('GAN loss 2.9736 ', 'GAN acc 0.0000', 'Discriminator loss 0.1187', 'Discriminator accuracy 0.9844', 'Total loss: 3.0923', 'for batch', 15)
('GAN loss 3.3961 ', 'GAN acc 0.0000', 'Discriminator loss 0.0949', 'Discriminator accuracy 0.9922', 'Total loss: 3.4911', 'for batch', 16)
('GAN loss 3.4380 ', 'GAN acc 0.0000', 'Discriminator loss 0.1909', 'Discriminator accuracy 0.9863', 'Total loss: 3.6289', 'for batch', 17)
('GAN loss 3.3386 ', 'GAN acc 0.0000', 'Discriminator loss 0.1281', 'Discriminator accuracy 0.9902', 'Total loss: 3.4666', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.97333026)
('DISCRIMINATOR_Imagem FAKE=', 0.059572976)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.700119')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 3.4762 ', 'GAN acc 0.0000', 'Discriminator loss 0.0432', 'Discriminator accuracy 0.9961', 'Total loss: 3.5193', 'for batch', 0)
('GAN loss 3.1889 ', 'GAN acc 0.0000', 'Discriminator loss 0.0593', 'Discriminator accuracy 0.9922', 'Total loss: 3.2482', 'for batch', 1)
('GAN loss 2.6955 ', 'GAN acc 0.0000', 'Discriminator loss 0.1249', 'Discriminator accuracy 0.9766', 'Total loss: 2.8204', 'for batch', 2)
('GAN loss 2.2821 ', 'GAN acc 0.0234', 'Discriminator loss 0.1773', 'Discriminator accuracy 0.9785', 'Total loss: 2.4595', 'for batch', 3)
('GAN loss 2.6174 ', 'GAN acc 0.0000', 'Discriminator loss 0.1249', 'Discriminator accuracy 0.9688', 'Total loss: 2.7423', 'for batch', 4)
('GAN loss 3.0906 ', 'GAN acc 0.0000', 'Discriminator loss 0.1053', 'Discriminator accuracy 0.9902', 'Total loss: 3.1959', 'for batch', 5)
('GAN loss 3.6507 ', 'GAN acc 0.0000', 'Discriminator loss 0.0536', 'Discriminator accuracy 0.9941', 'Total loss: 3.7043', 'for batch', 6)
('GAN loss 3.4185 ', 'GAN acc 0.0000', 'Discriminator loss 0.1015', 'Discriminator accuracy 0.9902', 'Total loss: 3.5200', 'for batch', 7)
('GAN loss 3.0475 ', 'GAN acc 0.0000', 'Discriminator loss 0.0618', 'Discriminator accuracy 0.9941', 'Total loss: 3.1093', 'for batch', 8)
('GAN loss 2.8285 ', 'GAN acc 0.0000', 'Discriminator loss 0.0710', 'Discriminator accuracy 0.9980', 'Total loss: 2.8995', 'for batch', 9)
('GAN loss 2.7088 ', 'GAN acc 0.0000', 'Discriminator loss 0.0778', 'Discriminator accuracy 0.9961', 'Total loss: 2.7866', 'for batch', 10)
('GAN loss 2.4809 ', 'GAN acc 0.0000', 'Discriminator loss 0.1075', 'Discriminator accuracy 0.9902', 'Total loss: 2.5884', 'for batch', 11)
('GAN loss 2.4250 ', 'GAN acc 0.0000', 'Discriminator loss 0.0715', 'Discriminator accuracy 0.9961', 'Total loss: 2.4964', 'for batch', 12)
('GAN loss 2.4008 ', 'GAN acc 0.0000', 'Discriminator loss 0.1317', 'Discriminator accuracy 0.9941', 'Total loss: 2.5325', 'for batch', 13)
('GAN loss 2.4537 ', 'GAN acc 0.0000', 'Discriminator loss 0.0771', 'Discriminator accuracy 0.9961', 'Total loss: 2.5308', 'for batch', 14)
('GAN loss 2.5250 ', 'GAN acc 0.0000', 'Discriminator loss 0.1148', 'Discriminator accuracy 0.9961', 'Total loss: 2.6398', 'for batch', 15)
('GAN loss 2.6616 ', 'GAN acc 0.0000', 'Discriminator loss 0.0578', 'Discriminator accuracy 0.9980', 'Total loss: 2.7194', 'for batch', 16)
('GAN loss 2.6299 ', 'GAN acc 0.0000', 'Discriminator loss 0.0831', 'Discriminator accuracy 0.9941', 'Total loss: 2.7131', 'for batch', 17)
('GAN loss 2.6387 ', 'GAN acc 0.0000', 'Discriminator loss 0.0867', 'Discriminator accuracy 0.9961', 'Total loss: 2.7253', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99143469)
('DISCRIMINATOR_Imagem FAKE=', 0.083621234)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.831293')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 2.7368 ', 'GAN acc 0.0000', 'Discriminator loss 0.0664', 'Discriminator accuracy 0.9961', 'Total loss: 2.8032', 'for batch', 0)
('GAN loss 2.9035 ', 'GAN acc 0.0000', 'Discriminator loss 0.0570', 'Discriminator accuracy 0.9961', 'Total loss: 2.9605', 'for batch', 1)
('GAN loss 2.8909 ', 'GAN acc 0.0000', 'Discriminator loss 0.1131', 'Discriminator accuracy 0.9844', 'Total loss: 3.0040', 'for batch', 2)
('GAN loss 2.7859 ', 'GAN acc 0.0000', 'Discriminator loss 0.1393', 'Discriminator accuracy 0.9863', 'Total loss: 2.9252', 'for batch', 3)
('GAN loss 2.8761 ', 'GAN acc 0.0000', 'Discriminator loss 0.0783', 'Discriminator accuracy 0.9922', 'Total loss: 2.9543', 'for batch', 4)
('GAN loss 2.7116 ', 'GAN acc 0.0000', 'Discriminator loss 0.0638', 'Discriminator accuracy 0.9961', 'Total loss: 2.7754', 'for batch', 5)
('GAN loss 3.0278 ', 'GAN acc 0.0000', 'Discriminator loss 0.0561', 'Discriminator accuracy 0.9980', 'Total loss: 3.0839', 'for batch', 6)
('GAN loss 3.3375 ', 'GAN acc 0.0000', 'Discriminator loss 0.0456', 'Discriminator accuracy 0.9980', 'Total loss: 3.3831', 'for batch', 7)
('GAN loss 3.5956 ', 'GAN acc 0.0000', 'Discriminator loss 0.0361', 'Discriminator accuracy 1.0000', 'Total loss: 3.6317', 'for batch', 8)
('GAN loss 3.7927 ', 'GAN acc 0.0000', 'Discriminator loss 0.0286', 'Discriminator accuracy 1.0000', 'Total loss: 3.8213', 'for batch', 9)
('GAN loss 3.9037 ', 'GAN acc 0.0000', 'Discriminator loss 0.0416', 'Discriminator accuracy 0.9941', 'Total loss: 3.9453', 'for batch', 10)
('GAN loss 3.5300 ', 'GAN acc 0.0000', 'Discriminator loss 0.0624', 'Discriminator accuracy 0.9941', 'Total loss: 3.5924', 'for batch', 11)
('GAN loss 3.2840 ', 'GAN acc 0.0000', 'Discriminator loss 0.0746', 'Discriminator accuracy 0.9941', 'Total loss: 3.3586', 'for batch', 12)
('GAN loss 3.5646 ', 'GAN acc 0.0000', 'Discriminator loss 0.0720', 'Discriminator accuracy 0.9961', 'Total loss: 3.6366', 'for batch', 13)
('GAN loss 3.9643 ', 'GAN acc 0.0000', 'Discriminator loss 0.0564', 'Discriminator accuracy 0.9980', 'Total loss: 4.0207', 'for batch', 14)
('GAN loss 3.8833 ', 'GAN acc 0.0000', 'Discriminator loss 0.0559', 'Discriminator accuracy 0.9961', 'Total loss: 3.9392', 'for batch', 15)
('GAN loss 3.9542 ', 'GAN acc 0.0000', 'Discriminator loss 0.0271', 'Discriminator accuracy 0.9980', 'Total loss: 3.9812', 'for batch', 16)
('GAN loss 3.5012 ', 'GAN acc 0.0000', 'Discriminator loss 0.0707', 'Discriminator accuracy 0.9941', 'Total loss: 3.5719', 'for batch', 17)
('GAN loss 3.5888 ', 'GAN acc 0.0000', 'Discriminator loss 0.0348', 'Discriminator accuracy 0.9980', 'Total loss: 3.6236', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98959243)
('DISCRIMINATOR_Imagem FAKE=', 0.035247393)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.340037')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 3.9796 ', 'GAN acc 0.0000', 'Discriminator loss 0.0426', 'Discriminator accuracy 0.9961', 'Total loss: 4.0222', 'for batch', 0)
('GAN loss 4.2217 ', 'GAN acc 0.0000', 'Discriminator loss 0.0348', 'Discriminator accuracy 0.9961', 'Total loss: 4.2565', 'for batch', 1)
('GAN loss 4.4340 ', 'GAN acc 0.0000', 'Discriminator loss 0.1161', 'Discriminator accuracy 0.9824', 'Total loss: 4.5501', 'for batch', 2)
('GAN loss 4.0878 ', 'GAN acc 0.0000', 'Discriminator loss 0.1007', 'Discriminator accuracy 0.9863', 'Total loss: 4.1885', 'for batch', 3)
('GAN loss 3.8877 ', 'GAN acc 0.0000', 'Discriminator loss 0.0562', 'Discriminator accuracy 0.9922', 'Total loss: 3.9439', 'for batch', 4)
('GAN loss 3.5749 ', 'GAN acc 0.0000', 'Discriminator loss 0.0467', 'Discriminator accuracy 0.9941', 'Total loss: 3.6216', 'for batch', 5)
('GAN loss 3.3760 ', 'GAN acc 0.0000', 'Discriminator loss 0.0710', 'Discriminator accuracy 0.9941', 'Total loss: 3.4469', 'for batch', 6)
('GAN loss 3.4548 ', 'GAN acc 0.0078', 'Discriminator loss 0.0290', 'Discriminator accuracy 1.0000', 'Total loss: 3.4838', 'for batch', 7)
('GAN loss 3.6599 ', 'GAN acc 0.0000', 'Discriminator loss 0.0323', 'Discriminator accuracy 0.9961', 'Total loss: 3.6921', 'for batch', 8)
('GAN loss 3.7003 ', 'GAN acc 0.0039', 'Discriminator loss 0.0240', 'Discriminator accuracy 1.0000', 'Total loss: 3.7243', 'for batch', 9)
('GAN loss 3.7435 ', 'GAN acc 0.0039', 'Discriminator loss 0.0729', 'Discriminator accuracy 0.9902', 'Total loss: 3.8164', 'for batch', 10)
('GAN loss 3.9305 ', 'GAN acc 0.0039', 'Discriminator loss 0.1018', 'Discriminator accuracy 0.9844', 'Total loss: 4.0323', 'for batch', 11)
('GAN loss 4.4930 ', 'GAN acc 0.0039', 'Discriminator loss 0.0385', 'Discriminator accuracy 0.9922', 'Total loss: 4.5315', 'for batch', 12)
('GAN loss 4.4766 ', 'GAN acc 0.0000', 'Discriminator loss 0.0988', 'Discriminator accuracy 0.9902', 'Total loss: 4.5754', 'for batch', 13)
('GAN loss 4.3773 ', 'GAN acc 0.0039', 'Discriminator loss 0.0794', 'Discriminator accuracy 0.9863', 'Total loss: 4.4567', 'for batch', 14)
('GAN loss 4.5631 ', 'GAN acc 0.0000', 'Discriminator loss 0.0185', 'Discriminator accuracy 0.9980', 'Total loss: 4.5816', 'for batch', 15)
('GAN loss 4.6238 ', 'GAN acc 0.0000', 'Discriminator loss 0.0287', 'Discriminator accuracy 0.9941', 'Total loss: 4.6525', 'for batch', 16)
('GAN loss 4.1917 ', 'GAN acc 0.0000', 'Discriminator loss 0.1489', 'Discriminator accuracy 0.9863', 'Total loss: 4.3406', 'for batch', 17)
('GAN loss 4.0933 ', 'GAN acc 0.0000', 'Discriminator loss 0.0670', 'Discriminator accuracy 0.9883', 'Total loss: 4.1603', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98854226)
('DISCRIMINATOR_Imagem FAKE=', 0.032248344)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.766990')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 4.3891 ', 'GAN acc 0.0000', 'Discriminator loss 0.0491', 'Discriminator accuracy 0.9922', 'Total loss: 4.4382', 'for batch', 0)
('GAN loss 4.3658 ', 'GAN acc 0.0000', 'Discriminator loss 0.0482', 'Discriminator accuracy 0.9922', 'Total loss: 4.4140', 'for batch', 1)
('GAN loss 4.7901 ', 'GAN acc 0.0039', 'Discriminator loss 0.1236', 'Discriminator accuracy 0.9844', 'Total loss: 4.9136', 'for batch', 2)
('GAN loss 4.4096 ', 'GAN acc 0.0000', 'Discriminator loss 0.0886', 'Discriminator accuracy 0.9883', 'Total loss: 4.4983', 'for batch', 3)
('GAN loss 4.1166 ', 'GAN acc 0.0078', 'Discriminator loss 0.1090', 'Discriminator accuracy 0.9863', 'Total loss: 4.2256', 'for batch', 4)
('GAN loss 4.3988 ', 'GAN acc 0.0000', 'Discriminator loss 0.0276', 'Discriminator accuracy 0.9961', 'Total loss: 4.4264', 'for batch', 5)
('GAN loss 4.7052 ', 'GAN acc 0.0000', 'Discriminator loss 0.0350', 'Discriminator accuracy 0.9902', 'Total loss: 4.7403', 'for batch', 6)
('GAN loss 3.8604 ', 'GAN acc 0.0000', 'Discriminator loss 0.0617', 'Discriminator accuracy 0.9922', 'Total loss: 3.9221', 'for batch', 7)
('GAN loss 3.9105 ', 'GAN acc 0.0039', 'Discriminator loss 0.0291', 'Discriminator accuracy 0.9922', 'Total loss: 3.9396', 'for batch', 8)
('GAN loss 4.4776 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9980', 'Total loss: 4.5031', 'for batch', 9)
('GAN loss 4.8446 ', 'GAN acc 0.0000', 'Discriminator loss 0.0596', 'Discriminator accuracy 0.9941', 'Total loss: 4.9042', 'for batch', 10)
('GAN loss 3.9574 ', 'GAN acc 0.0000', 'Discriminator loss 0.0623', 'Discriminator accuracy 0.9883', 'Total loss: 4.0197', 'for batch', 11)
('GAN loss 3.6485 ', 'GAN acc 0.0039', 'Discriminator loss 0.0324', 'Discriminator accuracy 0.9980', 'Total loss: 3.6809', 'for batch', 12)
('GAN loss 4.1507 ', 'GAN acc 0.0039', 'Discriminator loss 0.0437', 'Discriminator accuracy 0.9902', 'Total loss: 4.1944', 'for batch', 13)
('GAN loss 4.7050 ', 'GAN acc 0.0000', 'Discriminator loss 0.0375', 'Discriminator accuracy 0.9922', 'Total loss: 4.7425', 'for batch', 14)
('GAN loss 4.9768 ', 'GAN acc 0.0000', 'Discriminator loss 0.0670', 'Discriminator accuracy 0.9961', 'Total loss: 5.0438', 'for batch', 15)
('GAN loss 5.4114 ', 'GAN acc 0.0000', 'Discriminator loss 0.0155', 'Discriminator accuracy 0.9980', 'Total loss: 5.4269', 'for batch', 16)
('GAN loss 4.4748 ', 'GAN acc 0.0000', 'Discriminator loss 0.0483', 'Discriminator accuracy 0.9941', 'Total loss: 4.5230', 'for batch', 17)
('GAN loss 4.1792 ', 'GAN acc 0.0000', 'Discriminator loss 0.0552', 'Discriminator accuracy 0.9961', 'Total loss: 4.2344', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.9901498)
('DISCRIMINATOR_Imagem FAKE=', 0.022985706)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.285010')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 4.3794 ', 'GAN acc 0.0000', 'Discriminator loss 0.0697', 'Discriminator accuracy 0.9941', 'Total loss: 4.4491', 'for batch', 0)
('GAN loss 3.9809 ', 'GAN acc 0.0000', 'Discriminator loss 0.0490', 'Discriminator accuracy 0.9941', 'Total loss: 4.0299', 'for batch', 1)
('GAN loss 4.0521 ', 'GAN acc 0.0000', 'Discriminator loss 0.1301', 'Discriminator accuracy 0.9824', 'Total loss: 4.1822', 'for batch', 2)
('GAN loss 3.9492 ', 'GAN acc 0.0000', 'Discriminator loss 0.1337', 'Discriminator accuracy 0.9883', 'Total loss: 4.0829', 'for batch', 3)
('GAN loss 3.1177 ', 'GAN acc 0.0039', 'Discriminator loss 0.0992', 'Discriminator accuracy 0.9883', 'Total loss: 3.2169', 'for batch', 4)
('GAN loss 3.5697 ', 'GAN acc 0.0039', 'Discriminator loss 0.0652', 'Discriminator accuracy 0.9883', 'Total loss: 3.6350', 'for batch', 5)
('GAN loss 4.0706 ', 'GAN acc 0.0000', 'Discriminator loss 0.0759', 'Discriminator accuracy 0.9902', 'Total loss: 4.1465', 'for batch', 6)
('GAN loss 4.6720 ', 'GAN acc 0.0000', 'Discriminator loss 0.0483', 'Discriminator accuracy 0.9980', 'Total loss: 4.7203', 'for batch', 7)
('GAN loss 5.1414 ', 'GAN acc 0.0000', 'Discriminator loss 0.0142', 'Discriminator accuracy 0.9980', 'Total loss: 5.1556', 'for batch', 8)
('GAN loss 5.1460 ', 'GAN acc 0.0000', 'Discriminator loss 0.0176', 'Discriminator accuracy 0.9980', 'Total loss: 5.1637', 'for batch', 9)
('GAN loss 4.7828 ', 'GAN acc 0.0000', 'Discriminator loss 0.0718', 'Discriminator accuracy 0.9922', 'Total loss: 4.8546', 'for batch', 10)
('GAN loss 3.6523 ', 'GAN acc 0.0000', 'Discriminator loss 0.1755', 'Discriminator accuracy 0.9863', 'Total loss: 3.8278', 'for batch', 11)
('GAN loss 3.3041 ', 'GAN acc 0.0000', 'Discriminator loss 0.0469', 'Discriminator accuracy 0.9980', 'Total loss: 3.3510', 'for batch', 12)
('GAN loss 3.6140 ', 'GAN acc 0.0039', 'Discriminator loss 0.0779', 'Discriminator accuracy 0.9941', 'Total loss: 3.6918', 'for batch', 13)
('GAN loss 3.6613 ', 'GAN acc 0.0039', 'Discriminator loss 0.0708', 'Discriminator accuracy 0.9961', 'Total loss: 3.7321', 'for batch', 14)
('GAN loss 3.2123 ', 'GAN acc 0.0078', 'Discriminator loss 0.0833', 'Discriminator accuracy 0.9922', 'Total loss: 3.2956', 'for batch', 15)
('GAN loss 3.5010 ', 'GAN acc 0.0039', 'Discriminator loss 0.0557', 'Discriminator accuracy 0.9922', 'Total loss: 3.5567', 'for batch', 16)
('GAN loss 4.1796 ', 'GAN acc 0.0039', 'Discriminator loss 0.0511', 'Discriminator accuracy 0.9941', 'Total loss: 4.2306', 'for batch', 17)
('GAN loss 4.9661 ', 'GAN acc 0.0000', 'Discriminator loss 0.0615', 'Discriminator accuracy 0.9961', 'Total loss: 5.0276', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.99108827)
('DISCRIMINATOR_Imagem FAKE=', 0.01095541)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.745054')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 5.4436 ', 'GAN acc 0.0000', 'Discriminator loss 0.0347', 'Discriminator accuracy 0.9961', 'Total loss: 5.4783', 'for batch', 0)
('GAN loss 5.3872 ', 'GAN acc 0.0000', 'Discriminator loss 0.0368', 'Discriminator accuracy 0.9941', 'Total loss: 5.4240', 'for batch', 1)
('GAN loss 5.2324 ', 'GAN acc 0.0000', 'Discriminator loss 0.1336', 'Discriminator accuracy 0.9805', 'Total loss: 5.3660', 'for batch', 2)
('GAN loss 3.4551 ', 'GAN acc 0.0039', 'Discriminator loss 0.1153', 'Discriminator accuracy 0.9844', 'Total loss: 3.5704', 'for batch', 3)
('GAN loss 3.3971 ', 'GAN acc 0.0352', 'Discriminator loss 0.1160', 'Discriminator accuracy 0.9707', 'Total loss: 3.5130', 'for batch', 4)
('GAN loss 4.5653 ', 'GAN acc 0.0039', 'Discriminator loss 0.0865', 'Discriminator accuracy 0.9648', 'Total loss: 4.6518', 'for batch', 5)
('GAN loss 5.4429 ', 'GAN acc 0.0000', 'Discriminator loss 0.0410', 'Discriminator accuracy 0.9941', 'Total loss: 5.4839', 'for batch', 6)
('GAN loss 5.9611 ', 'GAN acc 0.0000', 'Discriminator loss 0.0285', 'Discriminator accuracy 0.9980', 'Total loss: 5.9896', 'for batch', 7)
('GAN loss 5.8305 ', 'GAN acc 0.0000', 'Discriminator loss 0.0044', 'Discriminator accuracy 1.0000', 'Total loss: 5.8349', 'for batch', 8)
('GAN loss 4.2999 ', 'GAN acc 0.0000', 'Discriminator loss 0.0303', 'Discriminator accuracy 0.9980', 'Total loss: 4.3303', 'for batch', 9)
('GAN loss 3.1343 ', 'GAN acc 0.0820', 'Discriminator loss 0.0588', 'Discriminator accuracy 0.9902', 'Total loss: 3.1931', 'for batch', 10)
('GAN loss 4.3257 ', 'GAN acc 0.0117', 'Discriminator loss 0.1025', 'Discriminator accuracy 0.9609', 'Total loss: 4.4283', 'for batch', 11)
('GAN loss 5.7443 ', 'GAN acc 0.0000', 'Discriminator loss 0.0431', 'Discriminator accuracy 0.9863', 'Total loss: 5.7874', 'for batch', 12)
('GAN loss 5.6100 ', 'GAN acc 0.0000', 'Discriminator loss 0.0579', 'Discriminator accuracy 0.9922', 'Total loss: 5.6679', 'for batch', 13)
('GAN loss 5.2875 ', 'GAN acc 0.0000', 'Discriminator loss 0.0682', 'Discriminator accuracy 0.9941', 'Total loss: 5.3557', 'for batch', 14)
('GAN loss 4.9180 ', 'GAN acc 0.0000', 'Discriminator loss 0.0382', 'Discriminator accuracy 0.9980', 'Total loss: 4.9562', 'for batch', 15)
('GAN loss 4.8797 ', 'GAN acc 0.0000', 'Discriminator loss 0.0224', 'Discriminator accuracy 0.9980', 'Total loss: 4.9021', 'for batch', 16)
('GAN loss 4.8940 ', 'GAN acc 0.0000', 'Discriminator loss 0.0255', 'Discriminator accuracy 0.9980', 'Total loss: 4.9195', 'for batch', 17)
('GAN loss 5.1228 ', 'GAN acc 0.0000', 'Discriminator loss 0.0271', 'Discriminator accuracy 0.9980', 'Total loss: 5.1499', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.98875165)
('DISCRIMINATOR_Imagem FAKE=', 0.0099663287)
('Discriminator trained', 0, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.292271')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 5.4505 ', 'GAN acc 0.0000', 'Discriminator loss 0.0946', 'Discriminator accuracy 0.9922', 'Total loss: 5.5452', 'for batch', 0)
('GAN loss 5.5516 ', 'GAN acc 0.0000', 'Discriminator loss 0.0350', 'Discriminator accuracy 0.9941', 'Total loss: 5.5866', 'for batch', 1)
('GAN loss 5.2716 ', 'GAN acc 0.0000', 'Discriminator loss 0.1027', 'Discriminator accuracy 0.9844', 'Total loss: 5.3743', 'for batch', 2)
('GAN loss 4.4518 ', 'GAN acc 0.0000', 'Discriminator loss 0.2137', 'Discriminator accuracy 0.9824', 'Total loss: 4.6656', 'for batch', 3)
('GAN loss 3.9998 ', 'GAN acc 0.0039', 'Discriminator loss 0.0656', 'Discriminator accuracy 0.9922', 'Total loss: 4.0654', 'for batch', 4)
('GAN loss 4.0335 ', 'GAN acc 0.0039', 'Discriminator loss 0.0334', 'Discriminator accuracy 0.9961', 'Total loss: 4.0669', 'for batch', 5)
('GAN loss 3.4940 ', 'GAN acc 0.0078', 'Discriminator loss 0.0653', 'Discriminator accuracy 0.9941', 'Total loss: 3.5593', 'for batch', 6)
('GAN loss 3.9674 ', 'GAN acc 0.0000', 'Discriminator loss 0.0511', 'Discriminator accuracy 0.9883', 'Total loss: 4.0185', 'for batch', 7)
('GAN loss 4.3599 ', 'GAN acc 0.0039', 'Discriminator loss 0.0341', 'Discriminator accuracy 0.9922', 'Total loss: 4.3940', 'for batch', 8)
('GAN loss 4.9736 ', 'GAN acc 0.0000', 'Discriminator loss 0.0124', 'Discriminator accuracy 1.0000', 'Total loss: 4.9860', 'for batch', 9)
('GAN loss 5.2049 ', 'GAN acc 0.0000', 'Discriminator loss 0.0232', 'Discriminator accuracy 0.9980', 'Total loss: 5.2281', 'for batch', 10)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7490 ', 'GAN acc 0.5039', 'Discriminator loss 0.7460', 'Discriminator accuracy 0.4980', 'Total loss: 1.4950', 'for batch', 0)
('GAN loss 0.6940 ', 'GAN acc 0.5391', 'Discriminator loss 0.7709', 'Discriminator accuracy 0.5039', 'Total loss: 1.4649', 'for batch', 1)
('GAN loss 0.7790 ', 'GAN acc 0.5078', 'Discriminator loss 0.8003', 'Discriminator accuracy 0.4844', 'Total loss: 1.5793', 'for batch', 2)
('GAN loss 0.8850 ', 'GAN acc 0.3672', 'Discriminator loss 0.7548', 'Discriminator accuracy 0.5332', 'Total loss: 1.6398', 'for batch', 3)
('GAN loss 0.7840 ', 'GAN acc 0.4336', 'Discriminator loss 0.7691', 'Discriminator accuracy 0.4746', 'Total loss: 1.5531', 'for batch', 4)
('GAN loss 0.7417 ', 'GAN acc 0.5156', 'Discriminator loss 0.7762', 'Discriminator accuracy 0.4863', 'Total loss: 1.5179', 'for batch', 5)
('GAN loss 0.7622 ', 'GAN acc 0.4609', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.5410', 'Total loss: 1.4652', 'for batch', 6)
('GAN loss 0.8374 ', 'GAN acc 0.3594', 'Discriminator loss 0.7190', 'Discriminator accuracy 0.5195', 'Total loss: 1.5564', 'for batch', 7)
('GAN loss 0.8355 ', 'GAN acc 0.3672', 'Discriminator loss 0.7268', 'Discriminator accuracy 0.5527', 'Total loss: 1.5624', 'for batch', 8)
('GAN loss 0.9053 ', 'GAN acc 0.3164', 'Discriminator loss 0.7146', 'Discriminator accuracy 0.5391', 'Total loss: 1.6200', 'for batch', 9)
('GAN loss 1.0078 ', 'GAN acc 0.2578', 'Discriminator loss 0.6627', 'Discriminator accuracy 0.5957', 'Total loss: 1.6705', 'for batch', 10)
('GAN loss 1.0010 ', 'GAN acc 0.2383', 'Discriminator loss 0.6662', 'Discriminator accuracy 0.6172', 'Total loss: 1.6672', 'for batch', 11)
('GAN loss 0.9861 ', 'GAN acc 0.2539', 'Discriminator loss 0.5985', 'Discriminator accuracy 0.7070', 'Total loss: 1.5846', 'for batch', 12)
('GAN loss 1.0591 ', 'GAN acc 0.1953', 'Discriminator loss 0.5988', 'Discriminator accuracy 0.7207', 'Total loss: 1.6579', 'for batch', 13)
('GAN loss 1.1358 ', 'GAN acc 0.1719', 'Discriminator loss 0.5966', 'Discriminator accuracy 0.6992', 'Total loss: 1.7325', 'for batch', 14)
('GAN loss 1.1223 ', 'GAN acc 0.1523', 'Discriminator loss 0.6449', 'Discriminator accuracy 0.6523', 'Total loss: 1.7671', 'for batch', 15)
('GAN loss 1.1341 ', 'GAN acc 0.1836', 'Discriminator loss 0.6185', 'Discriminator accuracy 0.6445', 'Total loss: 1.7526', 'for batch', 16)
('GAN loss 1.0812 ', 'GAN acc 0.2070', 'Discriminator loss 0.5879', 'Discriminator accuracy 0.6914', 'Total loss: 1.6691', 'for batch', 17)
('GAN loss 1.1429 ', 'GAN acc 0.1992', 'Discriminator loss 0.5873', 'Discriminator accuracy 0.7070', 'Total loss: 1.7302', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.80167174)
('DISCRIMINATOR_Imagem FAKE=', 0.65670741)
('Discriminator trained', 14, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:44.822052')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1501 ', 'GAN acc 0.1914', 'Discriminator loss 0.5954', 'Discriminator accuracy 0.7051', 'Total loss: 1.7455', 'for batch', 0)
('GAN loss 1.2659 ', 'GAN acc 0.1523', 'Discriminator loss 0.5899', 'Discriminator accuracy 0.6758', 'Total loss: 1.8558', 'for batch', 1)
('GAN loss 1.2876 ', 'GAN acc 0.1523', 'Discriminator loss 0.5445', 'Discriminator accuracy 0.7363', 'Total loss: 1.8321', 'for batch', 2)
('GAN loss 1.1941 ', 'GAN acc 0.2070', 'Discriminator loss 0.5666', 'Discriminator accuracy 0.6973', 'Total loss: 1.7607', 'for batch', 3)
('GAN loss 1.1326 ', 'GAN acc 0.2266', 'Discriminator loss 0.5611', 'Discriminator accuracy 0.7344', 'Total loss: 1.6938', 'for batch', 4)
('GAN loss 1.2375 ', 'GAN acc 0.1562', 'Discriminator loss 0.5688', 'Discriminator accuracy 0.7012', 'Total loss: 1.8063', 'for batch', 5)
('GAN loss 1.3844 ', 'GAN acc 0.1250', 'Discriminator loss 0.5594', 'Discriminator accuracy 0.7227', 'Total loss: 1.9438', 'for batch', 6)
('GAN loss 1.4265 ', 'GAN acc 0.1016', 'Discriminator loss 0.5563', 'Discriminator accuracy 0.7109', 'Total loss: 1.9828', 'for batch', 7)
('GAN loss 1.2628 ', 'GAN acc 0.1875', 'Discriminator loss 0.5116', 'Discriminator accuracy 0.7637', 'Total loss: 1.7744', 'for batch', 8)
('GAN loss 1.3542 ', 'GAN acc 0.1289', 'Discriminator loss 0.5651', 'Discriminator accuracy 0.7324', 'Total loss: 1.9193', 'for batch', 9)
('GAN loss 1.4033 ', 'GAN acc 0.1406', 'Discriminator loss 0.5525', 'Discriminator accuracy 0.6992', 'Total loss: 1.9558', 'for batch', 10)
('GAN loss 1.3355 ', 'GAN acc 0.1641', 'Discriminator loss 0.5841', 'Discriminator accuracy 0.6758', 'Total loss: 1.9196', 'for batch', 11)
('GAN loss 1.2629 ', 'GAN acc 0.1602', 'Discriminator loss 0.5717', 'Discriminator accuracy 0.6719', 'Total loss: 1.8346', 'for batch', 12)
('GAN loss 1.3872 ', 'GAN acc 0.1328', 'Discriminator loss 0.5409', 'Discriminator accuracy 0.7539', 'Total loss: 1.9281', 'for batch', 13)
('GAN loss 1.2290 ', 'GAN acc 0.1914', 'Discriminator loss 0.5364', 'Discriminator accuracy 0.7402', 'Total loss: 1.7654', 'for batch', 14)
('GAN loss 1.4883 ', 'GAN acc 0.1016', 'Discriminator loss 0.7405', 'Discriminator accuracy 0.5684', 'Total loss: 2.2288', 'for batch', 15)
('GAN loss 1.2409 ', 'GAN acc 0.1523', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.5469', 'Total loss: 1.9385', 'for batch', 16)
('GAN loss 0.9347 ', 'GAN acc 0.3086', 'Discriminator loss 0.6692', 'Discriminator accuracy 0.5762', 'Total loss: 1.6039', 'for batch', 17)
('GAN loss 0.9333 ', 'GAN acc 0.2969', 'Discriminator loss 0.6225', 'Discriminator accuracy 0.6758', 'Total loss: 1.5558', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.86292851)
('DISCRIMINATOR_Imagem FAKE=', 0.81778169)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.808608')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1463 ', 'GAN acc 0.1953', 'Discriminator loss 0.6749', 'Discriminator accuracy 0.5918', 'Total loss: 1.8211', 'for batch', 0)
('GAN loss 1.3561 ', 'GAN acc 0.0898', 'Discriminator loss 0.6354', 'Discriminator accuracy 0.6270', 'Total loss: 1.9915', 'for batch', 1)
('GAN loss 1.2185 ', 'GAN acc 0.1641', 'Discriminator loss 0.6158', 'Discriminator accuracy 0.6309', 'Total loss: 1.8343', 'for batch', 2)
('GAN loss 1.0960 ', 'GAN acc 0.1992', 'Discriminator loss 0.5891', 'Discriminator accuracy 0.6641', 'Total loss: 1.6851', 'for batch', 3)
('GAN loss 1.1377 ', 'GAN acc 0.2422', 'Discriminator loss 0.5920', 'Discriminator accuracy 0.6895', 'Total loss: 1.7298', 'for batch', 4)
('GAN loss 1.2134 ', 'GAN acc 0.2031', 'Discriminator loss 0.6093', 'Discriminator accuracy 0.6680', 'Total loss: 1.8228', 'for batch', 5)
('GAN loss 1.0926 ', 'GAN acc 0.2266', 'Discriminator loss 0.6279', 'Discriminator accuracy 0.6016', 'Total loss: 1.7205', 'for batch', 6)
('GAN loss 1.0079 ', 'GAN acc 0.2812', 'Discriminator loss 0.6631', 'Discriminator accuracy 0.5781', 'Total loss: 1.6710', 'for batch', 7)
('GAN loss 0.9113 ', 'GAN acc 0.3164', 'Discriminator loss 0.6556', 'Discriminator accuracy 0.5801', 'Total loss: 1.5669', 'for batch', 8)
('GAN loss 0.8789 ', 'GAN acc 0.3594', 'Discriminator loss 0.6864', 'Discriminator accuracy 0.5547', 'Total loss: 1.5653', 'for batch', 9)
('GAN loss 0.9182 ', 'GAN acc 0.3008', 'Discriminator loss 0.6696', 'Discriminator accuracy 0.5820', 'Total loss: 1.5878', 'for batch', 10)
('GAN loss 0.8331 ', 'GAN acc 0.4102', 'Discriminator loss 0.6813', 'Discriminator accuracy 0.5547', 'Total loss: 1.5145', 'for batch', 11)
('GAN loss 0.9038 ', 'GAN acc 0.3320', 'Discriminator loss 0.6635', 'Discriminator accuracy 0.5781', 'Total loss: 1.5673', 'for batch', 12)
('GAN loss 0.8860 ', 'GAN acc 0.3555', 'Discriminator loss 0.6454', 'Discriminator accuracy 0.6094', 'Total loss: 1.5314', 'for batch', 13)
('GAN loss 0.8679 ', 'GAN acc 0.3789', 'Discriminator loss 0.6507', 'Discriminator accuracy 0.6152', 'Total loss: 1.5186', 'for batch', 14)
('GAN loss 0.8540 ', 'GAN acc 0.3789', 'Discriminator loss 0.6513', 'Discriminator accuracy 0.6113', 'Total loss: 1.5054', 'for batch', 15)
('GAN loss 0.8015 ', 'GAN acc 0.4062', 'Discriminator loss 0.6583', 'Discriminator accuracy 0.5938', 'Total loss: 1.4598', 'for batch', 16)
('GAN loss 0.8595 ', 'GAN acc 0.3555', 'Discriminator loss 0.6567', 'Discriminator accuracy 0.6094', 'Total loss: 1.5162', 'for batch', 17)
('GAN loss 0.8009 ', 'GAN acc 0.4688', 'Discriminator loss 0.6595', 'Discriminator accuracy 0.6250', 'Total loss: 1.4604', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.84026688)
('DISCRIMINATOR_Imagem FAKE=', 0.7829144)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.439026')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7656 ', 'GAN acc 0.4609', 'Discriminator loss 0.6594', 'Discriminator accuracy 0.6094', 'Total loss: 1.4250', 'for batch', 0)
('GAN loss 0.7967 ', 'GAN acc 0.4102', 'Discriminator loss 0.6519', 'Discriminator accuracy 0.6289', 'Total loss: 1.4487', 'for batch', 1)
('GAN loss 0.7912 ', 'GAN acc 0.4688', 'Discriminator loss 0.6557', 'Discriminator accuracy 0.5918', 'Total loss: 1.4469', 'for batch', 2)
('GAN loss 0.7457 ', 'GAN acc 0.4844', 'Discriminator loss 0.6740', 'Discriminator accuracy 0.5898', 'Total loss: 1.4197', 'for batch', 3)
('GAN loss 0.7273 ', 'GAN acc 0.5000', 'Discriminator loss 0.6650', 'Discriminator accuracy 0.6094', 'Total loss: 1.3923', 'for batch', 4)
('GAN loss 0.7056 ', 'GAN acc 0.5625', 'Discriminator loss 0.6803', 'Discriminator accuracy 0.5801', 'Total loss: 1.3859', 'for batch', 5)
('GAN loss 0.7457 ', 'GAN acc 0.5000', 'Discriminator loss 0.6705', 'Discriminator accuracy 0.5820', 'Total loss: 1.4162', 'for batch', 6)
('GAN loss 0.7112 ', 'GAN acc 0.5430', 'Discriminator loss 0.6689', 'Discriminator accuracy 0.5742', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.7052 ', 'GAN acc 0.5508', 'Discriminator loss 0.6544', 'Discriminator accuracy 0.5977', 'Total loss: 1.3595', 'for batch', 8)
('GAN loss 0.6761 ', 'GAN acc 0.5898', 'Discriminator loss 0.6791', 'Discriminator accuracy 0.5703', 'Total loss: 1.3551', 'for batch', 9)
('GAN loss 0.7028 ', 'GAN acc 0.5508', 'Discriminator loss 0.6716', 'Discriminator accuracy 0.5879', 'Total loss: 1.3744', 'for batch', 10)
('GAN loss 0.6695 ', 'GAN acc 0.6328', 'Discriminator loss 0.6741', 'Discriminator accuracy 0.5664', 'Total loss: 1.3436', 'for batch', 11)
('GAN loss 0.6637 ', 'GAN acc 0.6172', 'Discriminator loss 0.6831', 'Discriminator accuracy 0.5586', 'Total loss: 1.3468', 'for batch', 12)
('GAN loss 0.7039 ', 'GAN acc 0.5430', 'Discriminator loss 0.6793', 'Discriminator accuracy 0.5703', 'Total loss: 1.3831', 'for batch', 13)
('GAN loss 0.6799 ', 'GAN acc 0.6250', 'Discriminator loss 0.6763', 'Discriminator accuracy 0.5703', 'Total loss: 1.3563', 'for batch', 14)
('GAN loss 0.6702 ', 'GAN acc 0.6484', 'Discriminator loss 0.6874', 'Discriminator accuracy 0.5527', 'Total loss: 1.3575', 'for batch', 15)
('GAN loss 0.6933 ', 'GAN acc 0.5586', 'Discriminator loss 0.6633', 'Discriminator accuracy 0.5957', 'Total loss: 1.3566', 'for batch', 16)
('GAN loss 0.6878 ', 'GAN acc 0.6133', 'Discriminator loss 0.6744', 'Discriminator accuracy 0.5645', 'Total loss: 1.3622', 'for batch', 17)
('GAN loss 0.7279 ', 'GAN acc 0.4961', 'Discriminator loss 0.6609', 'Discriminator accuracy 0.5996', 'Total loss: 1.3888', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.82937503)
('DISCRIMINATOR_Imagem FAKE=', 0.77788883)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.079327')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7227 ', 'GAN acc 0.5273', 'Discriminator loss 0.6704', 'Discriminator accuracy 0.5684', 'Total loss: 1.3930', 'for batch', 0)
('GAN loss 0.7397 ', 'GAN acc 0.5078', 'Discriminator loss 0.6746', 'Discriminator accuracy 0.5879', 'Total loss: 1.4143', 'for batch', 1)
('GAN loss 0.7205 ', 'GAN acc 0.5195', 'Discriminator loss 0.6790', 'Discriminator accuracy 0.5742', 'Total loss: 1.3995', 'for batch', 2)
('GAN loss 0.6960 ', 'GAN acc 0.5703', 'Discriminator loss 0.6858', 'Discriminator accuracy 0.5273', 'Total loss: 1.3818', 'for batch', 3)
('GAN loss 0.6673 ', 'GAN acc 0.6133', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.5254', 'Total loss: 1.3680', 'for batch', 4)
('GAN loss 0.6671 ', 'GAN acc 0.5977', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5391', 'Total loss: 1.3621', 'for batch', 5)
('GAN loss 0.6941 ', 'GAN acc 0.5898', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5293', 'Total loss: 1.3849', 'for batch', 6)
('GAN loss 0.7092 ', 'GAN acc 0.5391', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.5215', 'Total loss: 1.4089', 'for batch', 7)
('GAN loss 0.6818 ', 'GAN acc 0.6250', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5352', 'Total loss: 1.3832', 'for batch', 8)
('GAN loss 0.6643 ', 'GAN acc 0.6172', 'Discriminator loss 0.7055', 'Discriminator accuracy 0.5234', 'Total loss: 1.3698', 'for batch', 9)
('GAN loss 0.6889 ', 'GAN acc 0.5469', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.5371', 'Total loss: 1.3924', 'for batch', 10)
('GAN loss 0.6858 ', 'GAN acc 0.5586', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.5273', 'Total loss: 1.3871', 'for batch', 11)
('GAN loss 0.6839 ', 'GAN acc 0.5742', 'Discriminator loss 0.6847', 'Discriminator accuracy 0.5527', 'Total loss: 1.3686', 'for batch', 12)
('GAN loss 0.7040 ', 'GAN acc 0.5234', 'Discriminator loss 0.7089', 'Discriminator accuracy 0.4766', 'Total loss: 1.4130', 'for batch', 13)
('GAN loss 0.6741 ', 'GAN acc 0.5859', 'Discriminator loss 0.7083', 'Discriminator accuracy 0.4844', 'Total loss: 1.3824', 'for batch', 14)
('GAN loss 0.6691 ', 'GAN acc 0.5977', 'Discriminator loss 0.7096', 'Discriminator accuracy 0.5078', 'Total loss: 1.3787', 'for batch', 15)
('GAN loss 0.6813 ', 'GAN acc 0.5977', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.5312', 'Total loss: 1.3828', 'for batch', 16)
('GAN loss 0.6867 ', 'GAN acc 0.5664', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.5254', 'Total loss: 1.3859', 'for batch', 17)
('GAN loss 0.6776 ', 'GAN acc 0.5742', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5293', 'Total loss: 1.3744', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.75431567)
('DISCRIMINATOR_Imagem FAKE=', 0.74156606)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.617110')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6810 ', 'GAN acc 0.5469', 'Discriminator loss 0.7030', 'Discriminator accuracy 0.5273', 'Total loss: 1.3840', 'for batch', 0)
('GAN loss 0.7026 ', 'GAN acc 0.5352', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5020', 'Total loss: 1.4009', 'for batch', 1)
('GAN loss 0.6760 ', 'GAN acc 0.5898', 'Discriminator loss 0.7100', 'Discriminator accuracy 0.4766', 'Total loss: 1.3861', 'for batch', 2)
('GAN loss 0.6689 ', 'GAN acc 0.5859', 'Discriminator loss 0.7109', 'Discriminator accuracy 0.4844', 'Total loss: 1.3798', 'for batch', 3)
('GAN loss 0.6553 ', 'GAN acc 0.6680', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.5020', 'Total loss: 1.3582', 'for batch', 4)
('GAN loss 0.6863 ', 'GAN acc 0.5391', 'Discriminator loss 0.7110', 'Discriminator accuracy 0.4824', 'Total loss: 1.3974', 'for batch', 5)
('GAN loss 0.6902 ', 'GAN acc 0.5430', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4961', 'Total loss: 1.3882', 'for batch', 6)
('GAN loss 0.6954 ', 'GAN acc 0.5273', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4902', 'Total loss: 1.4001', 'for batch', 7)
('GAN loss 0.6868 ', 'GAN acc 0.5625', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5410', 'Total loss: 1.3773', 'for batch', 8)
('GAN loss 0.6777 ', 'GAN acc 0.6211', 'Discriminator loss 0.7176', 'Discriminator accuracy 0.4707', 'Total loss: 1.3953', 'for batch', 9)
('GAN loss 0.7036 ', 'GAN acc 0.5195', 'Discriminator loss 0.7087', 'Discriminator accuracy 0.4863', 'Total loss: 1.4122', 'for batch', 10)
('GAN loss 0.6919 ', 'GAN acc 0.5391', 'Discriminator loss 0.7158', 'Discriminator accuracy 0.4453', 'Total loss: 1.4077', 'for batch', 11)
('GAN loss 0.6879 ', 'GAN acc 0.5117', 'Discriminator loss 0.7146', 'Discriminator accuracy 0.4609', 'Total loss: 1.4025', 'for batch', 12)
('GAN loss 0.6789 ', 'GAN acc 0.5664', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.5098', 'Total loss: 1.3841', 'for batch', 13)
('GAN loss 0.6833 ', 'GAN acc 0.5469', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4883', 'Total loss: 1.3833', 'for batch', 14)
('GAN loss 0.6959 ', 'GAN acc 0.4961', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4688', 'Total loss: 1.4025', 'for batch', 15)
('GAN loss 0.7064 ', 'GAN acc 0.4609', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5312', 'Total loss: 1.4046', 'for batch', 16)
('GAN loss 0.6871 ', 'GAN acc 0.5391', 'Discriminator loss 0.7108', 'Discriminator accuracy 0.4648', 'Total loss: 1.3979', 'for batch', 17)
('GAN loss 0.6836 ', 'GAN acc 0.5664', 'Discriminator loss 0.7055', 'Discriminator accuracy 0.5039', 'Total loss: 1.3891', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.68471056)
('DISCRIMINATOR_Imagem FAKE=', 0.68753445)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.132711')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6901 ', 'GAN acc 0.5625', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.5078', 'Total loss: 1.3880', 'for batch', 0)
('GAN loss 0.6805 ', 'GAN acc 0.5938', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.5273', 'Total loss: 1.3815', 'for batch', 1)
('GAN loss 0.6989 ', 'GAN acc 0.4883', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4785', 'Total loss: 1.4005', 'for batch', 2)
('GAN loss 0.6845 ', 'GAN acc 0.5859', 'Discriminator loss 0.7046', 'Discriminator accuracy 0.4785', 'Total loss: 1.3890', 'for batch', 3)
('GAN loss 0.6906 ', 'GAN acc 0.5156', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.5078', 'Total loss: 1.3896', 'for batch', 4)
('GAN loss 0.6975 ', 'GAN acc 0.5352', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.5156', 'Total loss: 1.4008', 'for batch', 5)
('GAN loss 0.6854 ', 'GAN acc 0.5352', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4844', 'Total loss: 1.3832', 'for batch', 6)
('GAN loss 0.6884 ', 'GAN acc 0.5117', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4863', 'Total loss: 1.3906', 'for batch', 7)
('GAN loss 0.6965 ', 'GAN acc 0.5117', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5078', 'Total loss: 1.3957', 'for batch', 8)
('GAN loss 0.7066 ', 'GAN acc 0.4766', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4883', 'Total loss: 1.4132', 'for batch', 9)
('GAN loss 0.6951 ', 'GAN acc 0.5234', 'Discriminator loss 0.7034', 'Discriminator accuracy 0.4863', 'Total loss: 1.3985', 'for batch', 10)
('GAN loss 0.6899 ', 'GAN acc 0.5234', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5078', 'Total loss: 1.3874', 'for batch', 11)
('GAN loss 0.6814 ', 'GAN acc 0.5781', 'Discriminator loss 0.7070', 'Discriminator accuracy 0.4941', 'Total loss: 1.3884', 'for batch', 12)
('GAN loss 0.6856 ', 'GAN acc 0.5234', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4766', 'Total loss: 1.3903', 'for batch', 13)
('GAN loss 0.6887 ', 'GAN acc 0.5664', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.5156', 'Total loss: 1.3876', 'for batch', 14)
('GAN loss 0.7061 ', 'GAN acc 0.5234', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4707', 'Total loss: 1.4058', 'for batch', 15)
('GAN loss 0.7115 ', 'GAN acc 0.4648', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4844', 'Total loss: 1.4162', 'for batch', 16)
('GAN loss 0.7069 ', 'GAN acc 0.4883', 'Discriminator loss 0.7083', 'Discriminator accuracy 0.4707', 'Total loss: 1.4152', 'for batch', 17)
('GAN loss 0.6996 ', 'GAN acc 0.4531', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.4883', 'Total loss: 1.4047', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.63786733)
('DISCRIMINATOR_Imagem FAKE=', 0.64081442)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.645603')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6921 ', 'GAN acc 0.5234', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.4863', 'Total loss: 1.3980', 'for batch', 0)
('GAN loss 0.6972 ', 'GAN acc 0.5312', 'Discriminator loss 0.7060', 'Discriminator accuracy 0.4785', 'Total loss: 1.4033', 'for batch', 1)
('GAN loss 0.6911 ', 'GAN acc 0.5469', 'Discriminator loss 0.7026', 'Discriminator accuracy 0.4805', 'Total loss: 1.3937', 'for batch', 2)
('GAN loss 0.6799 ', 'GAN acc 0.5664', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4980', 'Total loss: 1.3773', 'for batch', 3)
('GAN loss 0.6777 ', 'GAN acc 0.5586', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3726', 'for batch', 4)
('GAN loss 0.6743 ', 'GAN acc 0.6211', 'Discriminator loss 0.7064', 'Discriminator accuracy 0.4805', 'Total loss: 1.3807', 'for batch', 5)
('GAN loss 0.6725 ', 'GAN acc 0.6016', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4941', 'Total loss: 1.3712', 'for batch', 6)
('GAN loss 0.6814 ', 'GAN acc 0.5859', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5137', 'Total loss: 1.3730', 'for batch', 7)
('GAN loss 0.6792 ', 'GAN acc 0.6094', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4805', 'Total loss: 1.3795', 'for batch', 8)
('GAN loss 0.6918 ', 'GAN acc 0.5039', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4922', 'Total loss: 1.3950', 'for batch', 9)
('GAN loss 0.6963 ', 'GAN acc 0.5117', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4961', 'Total loss: 1.3948', 'for batch', 10)
('GAN loss 0.6933 ', 'GAN acc 0.5195', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.4668', 'Total loss: 1.3975', 'for batch', 11)
('GAN loss 0.6967 ', 'GAN acc 0.5117', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4785', 'Total loss: 1.3984', 'for batch', 12)
('GAN loss 0.6823 ', 'GAN acc 0.5859', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4785', 'Total loss: 1.3839', 'for batch', 13)
('GAN loss 0.6851 ', 'GAN acc 0.5508', 'Discriminator loss 0.7098', 'Discriminator accuracy 0.4648', 'Total loss: 1.3948', 'for batch', 14)
('GAN loss 0.6831 ', 'GAN acc 0.5703', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5020', 'Total loss: 1.3789', 'for batch', 15)
('GAN loss 0.6988 ', 'GAN acc 0.5195', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4961', 'Total loss: 1.3974', 'for batch', 16)
('GAN loss 0.6820 ', 'GAN acc 0.6055', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4863', 'Total loss: 1.3859', 'for batch', 17)
('GAN loss 0.6881 ', 'GAN acc 0.5273', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5059', 'Total loss: 1.3851', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.60966098)
('DISCRIMINATOR_Imagem FAKE=', 0.61287183)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.159239')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6874 ', 'GAN acc 0.5352', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4980', 'Total loss: 1.3888', 'for batch', 0)
('GAN loss 0.6973 ', 'GAN acc 0.5078', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4746', 'Total loss: 1.4002', 'for batch', 1)
('GAN loss 0.7077 ', 'GAN acc 0.4492', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5078', 'Total loss: 1.4035', 'for batch', 2)
('GAN loss 0.6845 ', 'GAN acc 0.5742', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4766', 'Total loss: 1.3866', 'for batch', 3)
('GAN loss 0.6841 ', 'GAN acc 0.5742', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5156', 'Total loss: 1.3791', 'for batch', 4)
('GAN loss 0.6933 ', 'GAN acc 0.5039', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4570', 'Total loss: 1.3966', 'for batch', 5)
('GAN loss 0.6798 ', 'GAN acc 0.5898', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5039', 'Total loss: 1.3751', 'for batch', 6)
('GAN loss 0.6899 ', 'GAN acc 0.5352', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5039', 'Total loss: 1.3858', 'for batch', 7)
('GAN loss 0.6886 ', 'GAN acc 0.5352', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.5078', 'Total loss: 1.3878', 'for batch', 8)
('GAN loss 0.7017 ', 'GAN acc 0.4844', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5137', 'Total loss: 1.3964', 'for batch', 9)
('GAN loss 0.7014 ', 'GAN acc 0.4609', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4922', 'Total loss: 1.3992', 'for batch', 10)
('GAN loss 0.6980 ', 'GAN acc 0.5352', 'Discriminator loss 0.7072', 'Discriminator accuracy 0.4609', 'Total loss: 1.4052', 'for batch', 11)
('GAN loss 0.6819 ', 'GAN acc 0.5859', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.4629', 'Total loss: 1.3863', 'for batch', 12)
('GAN loss 0.6794 ', 'GAN acc 0.5703', 'Discriminator loss 0.7050', 'Discriminator accuracy 0.4727', 'Total loss: 1.3844', 'for batch', 13)
('GAN loss 0.6864 ', 'GAN acc 0.5664', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4766', 'Total loss: 1.3862', 'for batch', 14)
('GAN loss 0.6961 ', 'GAN acc 0.4922', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4805', 'Total loss: 1.3918', 'for batch', 15)
('GAN loss 0.7012 ', 'GAN acc 0.5117', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5156', 'Total loss: 1.3962', 'for batch', 16)
('GAN loss 0.6931 ', 'GAN acc 0.5312', 'Discriminator loss 0.7040', 'Discriminator accuracy 0.4688', 'Total loss: 1.3971', 'for batch', 17)
('GAN loss 0.6947 ', 'GAN acc 0.5156', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4844', 'Total loss: 1.3943', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58564293)
('DISCRIMINATOR_Imagem FAKE=', 0.5866037)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.668958')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6868 ', 'GAN acc 0.5430', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.5000', 'Total loss: 1.3893', 'for batch', 0)
('GAN loss 0.6820 ', 'GAN acc 0.5859', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.4688', 'Total loss: 1.3863', 'for batch', 1)
('GAN loss 0.6787 ', 'GAN acc 0.5938', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4629', 'Total loss: 1.3808', 'for batch', 2)
('GAN loss 0.6761 ', 'GAN acc 0.6094', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4883', 'Total loss: 1.3771', 'for batch', 3)
('GAN loss 0.6838 ', 'GAN acc 0.5898', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4785', 'Total loss: 1.3807', 'for batch', 4)
('GAN loss 0.6748 ', 'GAN acc 0.6133', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5078', 'Total loss: 1.3701', 'for batch', 5)
('GAN loss 0.6713 ', 'GAN acc 0.6367', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5156', 'Total loss: 1.3649', 'for batch', 6)
('GAN loss 0.6799 ', 'GAN acc 0.5703', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4941', 'Total loss: 1.3785', 'for batch', 7)
('GAN loss 0.6842 ', 'GAN acc 0.5625', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5156', 'Total loss: 1.3777', 'for batch', 8)
('GAN loss 0.6897 ', 'GAN acc 0.5156', 'Discriminator loss 0.7057', 'Discriminator accuracy 0.4355', 'Total loss: 1.3953', 'for batch', 9)
('GAN loss 0.6879 ', 'GAN acc 0.5312', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5137', 'Total loss: 1.3836', 'for batch', 10)
('GAN loss 0.6931 ', 'GAN acc 0.5156', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5215', 'Total loss: 1.3893', 'for batch', 11)
('GAN loss 0.6785 ', 'GAN acc 0.5898', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3720', 'for batch', 12)
('GAN loss 0.6931 ', 'GAN acc 0.5352', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4922', 'Total loss: 1.3911', 'for batch', 13)
('GAN loss 0.6840 ', 'GAN acc 0.6016', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5098', 'Total loss: 1.3771', 'for batch', 14)
('GAN loss 0.6989 ', 'GAN acc 0.4766', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4746', 'Total loss: 1.3959', 'for batch', 15)
('GAN loss 0.6994 ', 'GAN acc 0.4688', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5312', 'Total loss: 1.3916', 'for batch', 16)
('GAN loss 0.7081 ', 'GAN acc 0.4453', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4824', 'Total loss: 1.4085', 'for batch', 17)
('GAN loss 0.7113 ', 'GAN acc 0.4375', 'Discriminator loss 0.7068', 'Discriminator accuracy 0.4492', 'Total loss: 1.4182', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56777883)
('DISCRIMINATOR_Imagem FAKE=', 0.56937677)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.197286')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6996 ', 'GAN acc 0.4570', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3947', 'for batch', 0)
('GAN loss 0.6972 ', 'GAN acc 0.5078', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4727', 'Total loss: 1.3975', 'for batch', 1)
('GAN loss 0.7002 ', 'GAN acc 0.4492', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4824', 'Total loss: 1.3989', 'for batch', 2)
('GAN loss 0.6925 ', 'GAN acc 0.5234', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4844', 'Total loss: 1.3934', 'for batch', 3)
('GAN loss 0.6785 ', 'GAN acc 0.6016', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4844', 'Total loss: 1.3758', 'for batch', 4)
('GAN loss 0.6764 ', 'GAN acc 0.6367', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5273', 'Total loss: 1.3709', 'for batch', 5)
('GAN loss 0.6783 ', 'GAN acc 0.6211', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4727', 'Total loss: 1.3754', 'for batch', 6)
('GAN loss 0.6779 ', 'GAN acc 0.6211', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5078', 'Total loss: 1.3736', 'for batch', 7)
('GAN loss 0.6872 ', 'GAN acc 0.5859', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4980', 'Total loss: 1.3825', 'for batch', 8)
('GAN loss 0.6821 ', 'GAN acc 0.5938', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4688', 'Total loss: 1.3801', 'for batch', 9)
('GAN loss 0.6820 ', 'GAN acc 0.5977', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4707', 'Total loss: 1.3826', 'for batch', 10)
('GAN loss 0.6940 ', 'GAN acc 0.5039', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4922', 'Total loss: 1.3951', 'for batch', 11)
('GAN loss 0.7009 ', 'GAN acc 0.4258', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5156', 'Total loss: 1.3958', 'for batch', 12)
('GAN loss 0.7045 ', 'GAN acc 0.4805', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.5039', 'Total loss: 1.4022', 'for batch', 13)
('GAN loss 0.6996 ', 'GAN acc 0.4883', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4570', 'Total loss: 1.4006', 'for batch', 14)
('GAN loss 0.7004 ', 'GAN acc 0.4922', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5078', 'Total loss: 1.3972', 'for batch', 15)
('GAN loss 0.7008 ', 'GAN acc 0.4648', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4824', 'Total loss: 1.4000', 'for batch', 16)
('GAN loss 0.6962 ', 'GAN acc 0.4961', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4805', 'Total loss: 1.3984', 'for batch', 17)
('GAN loss 0.6878 ', 'GAN acc 0.5703', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5234', 'Total loss: 1.3833', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5621205)
('DISCRIMINATOR_Imagem FAKE=', 0.56238145)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.671028')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6898 ', 'GAN acc 0.5508', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5000', 'Total loss: 1.3863', 'for batch', 0)
('GAN loss 0.6820 ', 'GAN acc 0.5781', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4746', 'Total loss: 1.3788', 'for batch', 1)
('GAN loss 0.6854 ', 'GAN acc 0.6016', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4766', 'Total loss: 1.3877', 'for batch', 2)
('GAN loss 0.6792 ', 'GAN acc 0.6055', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4727', 'Total loss: 1.3776', 'for batch', 3)
('GAN loss 0.6802 ', 'GAN acc 0.5977', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4707', 'Total loss: 1.3810', 'for batch', 4)
('GAN loss 0.6799 ', 'GAN acc 0.5742', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4902', 'Total loss: 1.3774', 'for batch', 5)
('GAN loss 0.6789 ', 'GAN acc 0.5898', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5000', 'Total loss: 1.3722', 'for batch', 6)
('GAN loss 0.6817 ', 'GAN acc 0.6250', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4844', 'Total loss: 1.3787', 'for batch', 7)
('GAN loss 0.6884 ', 'GAN acc 0.5312', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4922', 'Total loss: 1.3854', 'for batch', 8)
('GAN loss 0.6829 ', 'GAN acc 0.5859', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4492', 'Total loss: 1.3843', 'for batch', 9)
('GAN loss 0.6971 ', 'GAN acc 0.4727', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4922', 'Total loss: 1.3930', 'for batch', 10)
('GAN loss 0.6906 ', 'GAN acc 0.5352', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4766', 'Total loss: 1.3862', 'for batch', 11)
('GAN loss 0.6838 ', 'GAN acc 0.5820', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4766', 'Total loss: 1.3818', 'for batch', 12)
('GAN loss 0.6871 ', 'GAN acc 0.5547', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4961', 'Total loss: 1.3862', 'for batch', 13)
('GAN loss 0.6906 ', 'GAN acc 0.5625', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4688', 'Total loss: 1.3897', 'for batch', 14)
('GAN loss 0.6864 ', 'GAN acc 0.5820', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3805', 'for batch', 15)
('GAN loss 0.6910 ', 'GAN acc 0.5117', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5020', 'Total loss: 1.3862', 'for batch', 16)
('GAN loss 0.6965 ', 'GAN acc 0.5000', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4863', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.6967 ', 'GAN acc 0.4961', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4805', 'Total loss: 1.3952', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54936111)
('DISCRIMINATOR_Imagem FAKE=', 0.55011046)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.725052')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6988 ', 'GAN acc 0.4883', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5000', 'Total loss: 1.3962', 'for batch', 0)
('GAN loss 0.7026 ', 'GAN acc 0.4648', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5137', 'Total loss: 1.3972', 'for batch', 1)
('GAN loss 0.6991 ', 'GAN acc 0.4609', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4766', 'Total loss: 1.3944', 'for batch', 2)
('GAN loss 0.6944 ', 'GAN acc 0.5273', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4805', 'Total loss: 1.3920', 'for batch', 3)
('GAN loss 0.6831 ', 'GAN acc 0.5820', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4492', 'Total loss: 1.3834', 'for batch', 4)
('GAN loss 0.6786 ', 'GAN acc 0.6094', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4863', 'Total loss: 1.3755', 'for batch', 5)
('GAN loss 0.6770 ', 'GAN acc 0.6250', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4512', 'Total loss: 1.3808', 'for batch', 6)
('GAN loss 0.6809 ', 'GAN acc 0.5742', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3740', 'for batch', 7)
('GAN loss 0.6814 ', 'GAN acc 0.5938', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5176', 'Total loss: 1.3752', 'for batch', 8)
('GAN loss 0.6856 ', 'GAN acc 0.5234', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4961', 'Total loss: 1.3796', 'for batch', 9)
('GAN loss 0.6889 ', 'GAN acc 0.5430', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5195', 'Total loss: 1.3792', 'for batch', 10)
('GAN loss 0.6961 ', 'GAN acc 0.4922', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4551', 'Total loss: 1.3969', 'for batch', 11)
('GAN loss 0.6893 ', 'GAN acc 0.5703', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4922', 'Total loss: 1.3839', 'for batch', 12)
('GAN loss 0.6894 ', 'GAN acc 0.5352', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3825', 'for batch', 13)
('GAN loss 0.6882 ', 'GAN acc 0.5469', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4590', 'Total loss: 1.3871', 'for batch', 14)
('GAN loss 0.6971 ', 'GAN acc 0.4609', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4902', 'Total loss: 1.3931', 'for batch', 15)
('GAN loss 0.7077 ', 'GAN acc 0.4414', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5117', 'Total loss: 1.4020', 'for batch', 16)
('GAN loss 0.6920 ', 'GAN acc 0.5039', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5059', 'Total loss: 1.3846', 'for batch', 17)
('GAN loss 0.7005 ', 'GAN acc 0.4609', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4688', 'Total loss: 1.4005', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54777855)
('DISCRIMINATOR_Imagem FAKE=', 0.5480901)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.245498')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7001 ', 'GAN acc 0.5039', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5371', 'Total loss: 1.3929', 'for batch', 0)
('GAN loss 0.6961 ', 'GAN acc 0.4844', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5293', 'Total loss: 1.3900', 'for batch', 1)
('GAN loss 0.6939 ', 'GAN acc 0.4805', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5020', 'Total loss: 1.3876', 'for batch', 2)
('GAN loss 0.6830 ', 'GAN acc 0.5859', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4961', 'Total loss: 1.3778', 'for batch', 3)
('GAN loss 0.6852 ', 'GAN acc 0.5781', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4336', 'Total loss: 1.3858', 'for batch', 4)
('GAN loss 0.6772 ', 'GAN acc 0.6328', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4961', 'Total loss: 1.3726', 'for batch', 5)
('GAN loss 0.6788 ', 'GAN acc 0.6211', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4941', 'Total loss: 1.3736', 'for batch', 6)
('GAN loss 0.6796 ', 'GAN acc 0.6250', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5039', 'Total loss: 1.3731', 'for batch', 7)
('GAN loss 0.6771 ', 'GAN acc 0.6328', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5117', 'Total loss: 1.3699', 'for batch', 8)
('GAN loss 0.6784 ', 'GAN acc 0.6289', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5000', 'Total loss: 1.3753', 'for batch', 9)
('GAN loss 0.6884 ', 'GAN acc 0.5391', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5059', 'Total loss: 1.3831', 'for batch', 10)
('GAN loss 0.6979 ', 'GAN acc 0.4844', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4883', 'Total loss: 1.3966', 'for batch', 11)
('GAN loss 0.6926 ', 'GAN acc 0.5195', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5176', 'Total loss: 1.3868', 'for batch', 12)
('GAN loss 0.6981 ', 'GAN acc 0.4961', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4453', 'Total loss: 1.3993', 'for batch', 13)
('GAN loss 0.6937 ', 'GAN acc 0.5234', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4785', 'Total loss: 1.3921', 'for batch', 14)
('GAN loss 0.7139 ', 'GAN acc 0.3945', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5059', 'Total loss: 1.4103', 'for batch', 15)
('GAN loss 0.7019 ', 'GAN acc 0.4492', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5371', 'Total loss: 1.3964', 'for batch', 16)
('GAN loss 0.7042 ', 'GAN acc 0.4258', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5098', 'Total loss: 1.3992', 'for batch', 17)
('GAN loss 0.7062 ', 'GAN acc 0.4414', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4980', 'Total loss: 1.4017', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53962672)
('DISCRIMINATOR_Imagem FAKE=', 0.54047364)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.752515')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7010 ', 'GAN acc 0.4648', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4648', 'Total loss: 1.3991', 'for batch', 0)
('GAN loss 0.7021 ', 'GAN acc 0.4102', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5000', 'Total loss: 1.3986', 'for batch', 1)
('GAN loss 0.6943 ', 'GAN acc 0.5000', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5195', 'Total loss: 1.3896', 'for batch', 2)
('GAN loss 0.6984 ', 'GAN acc 0.4492', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5156', 'Total loss: 1.3888', 'for batch', 3)
('GAN loss 0.6867 ', 'GAN acc 0.5586', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4961', 'Total loss: 1.3833', 'for batch', 4)
('GAN loss 0.6767 ', 'GAN acc 0.6445', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4824', 'Total loss: 1.3738', 'for batch', 5)
('GAN loss 0.6746 ', 'GAN acc 0.6172', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4785', 'Total loss: 1.3705', 'for batch', 6)
('GAN loss 0.6739 ', 'GAN acc 0.6523', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3678', 'for batch', 7)
('GAN loss 0.6709 ', 'GAN acc 0.6836', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5156', 'Total loss: 1.3650', 'for batch', 8)
('GAN loss 0.6724 ', 'GAN acc 0.6602', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4902', 'Total loss: 1.3690', 'for batch', 9)
('GAN loss 0.6836 ', 'GAN acc 0.5586', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4844', 'Total loss: 1.3830', 'for batch', 10)
('GAN loss 0.6842 ', 'GAN acc 0.6016', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5137', 'Total loss: 1.3753', 'for batch', 11)
('GAN loss 0.6888 ', 'GAN acc 0.5625', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4766', 'Total loss: 1.3845', 'for batch', 12)
('GAN loss 0.6897 ', 'GAN acc 0.5508', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5117', 'Total loss: 1.3836', 'for batch', 13)
('GAN loss 0.6926 ', 'GAN acc 0.5273', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5039', 'Total loss: 1.3862', 'for batch', 14)
('GAN loss 0.6988 ', 'GAN acc 0.4883', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4922', 'Total loss: 1.3961', 'for batch', 15)
('GAN loss 0.6982 ', 'GAN acc 0.4883', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4941', 'Total loss: 1.3957', 'for batch', 16)
('GAN loss 0.7040 ', 'GAN acc 0.4414', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5117', 'Total loss: 1.3998', 'for batch', 17)
('GAN loss 0.7055 ', 'GAN acc 0.4297', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4844', 'Total loss: 1.4013', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53413552)
('DISCRIMINATOR_Imagem FAKE=', 0.53434771)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.281089')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7033 ', 'GAN acc 0.4102', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5371', 'Total loss: 1.3935', 'for batch', 0)
('GAN loss 0.7038 ', 'GAN acc 0.4570', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4941', 'Total loss: 1.3978', 'for batch', 1)
('GAN loss 0.6979 ', 'GAN acc 0.5039', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4668', 'Total loss: 1.3975', 'for batch', 2)
('GAN loss 0.6939 ', 'GAN acc 0.5078', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5059', 'Total loss: 1.3874', 'for batch', 3)
('GAN loss 0.6887 ', 'GAN acc 0.5703', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5098', 'Total loss: 1.3834', 'for batch', 4)
('GAN loss 0.6840 ', 'GAN acc 0.5664', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5215', 'Total loss: 1.3773', 'for batch', 5)
('GAN loss 0.6832 ', 'GAN acc 0.5859', 'Discriminator loss 0.6894', 'Discriminator accuracy 0.5449', 'Total loss: 1.3727', 'for batch', 6)
('GAN loss 0.6790 ', 'GAN acc 0.5859', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4922', 'Total loss: 1.3756', 'for batch', 7)
('GAN loss 0.6756 ', 'GAN acc 0.6523', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4688', 'Total loss: 1.3714', 'for batch', 8)
('GAN loss 0.6711 ', 'GAN acc 0.7031', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4863', 'Total loss: 1.3705', 'for batch', 9)
('GAN loss 0.6730 ', 'GAN acc 0.6836', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5176', 'Total loss: 1.3626', 'for batch', 10)
('GAN loss 0.6854 ', 'GAN acc 0.5742', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4922', 'Total loss: 1.3810', 'for batch', 11)
('GAN loss 0.6830 ', 'GAN acc 0.5938', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5098', 'Total loss: 1.3791', 'for batch', 12)
('GAN loss 0.6848 ', 'GAN acc 0.5859', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4590', 'Total loss: 1.3843', 'for batch', 13)
('GAN loss 0.6963 ', 'GAN acc 0.5117', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4883', 'Total loss: 1.3910', 'for batch', 14)
('GAN loss 0.6958 ', 'GAN acc 0.4922', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5059', 'Total loss: 1.3884', 'for batch', 15)
('GAN loss 0.7038 ', 'GAN acc 0.4336', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5254', 'Total loss: 1.3976', 'for batch', 16)
('GAN loss 0.7036 ', 'GAN acc 0.4258', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5137', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.7035 ', 'GAN acc 0.4688', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4922', 'Total loss: 1.3979', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52832621)
('DISCRIMINATOR_Imagem FAKE=', 0.52874917)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.710028')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7020 ', 'GAN acc 0.4180', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5098', 'Total loss: 1.3941', 'for batch', 0)
('GAN loss 0.7058 ', 'GAN acc 0.4258', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5195', 'Total loss: 1.4006', 'for batch', 1)
('GAN loss 0.7022 ', 'GAN acc 0.4766', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5020', 'Total loss: 1.3956', 'for batch', 2)
('GAN loss 0.6906 ', 'GAN acc 0.5508', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5059', 'Total loss: 1.3854', 'for batch', 3)
('GAN loss 0.6878 ', 'GAN acc 0.5469', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4805', 'Total loss: 1.3846', 'for batch', 4)
('GAN loss 0.6845 ', 'GAN acc 0.6055', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4707', 'Total loss: 1.3834', 'for batch', 5)
('GAN loss 0.6810 ', 'GAN acc 0.6094', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5000', 'Total loss: 1.3724', 'for batch', 6)
('GAN loss 0.6734 ', 'GAN acc 0.6680', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5000', 'Total loss: 1.3706', 'for batch', 7)
('GAN loss 0.6765 ', 'GAN acc 0.6641', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5195', 'Total loss: 1.3658', 'for batch', 8)
('GAN loss 0.6747 ', 'GAN acc 0.6641', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4473', 'Total loss: 1.3732', 'for batch', 9)
('GAN loss 0.6729 ', 'GAN acc 0.6797', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5195', 'Total loss: 1.3671', 'for batch', 10)
('GAN loss 0.6891 ', 'GAN acc 0.5625', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4609', 'Total loss: 1.3868', 'for batch', 11)
('GAN loss 0.6849 ', 'GAN acc 0.5430', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4980', 'Total loss: 1.3789', 'for batch', 12)
('GAN loss 0.6930 ', 'GAN acc 0.5117', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4961', 'Total loss: 1.3878', 'for batch', 13)
('GAN loss 0.6985 ', 'GAN acc 0.4766', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.4961', 'Total loss: 1.3897', 'for batch', 14)
('GAN loss 0.7104 ', 'GAN acc 0.3359', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.4062', 'for batch', 15)
('GAN loss 0.7032 ', 'GAN acc 0.4375', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4746', 'Total loss: 1.4011', 'for batch', 16)
('GAN loss 0.7057 ', 'GAN acc 0.4102', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4941', 'Total loss: 1.3982', 'for batch', 17)
('GAN loss 0.7018 ', 'GAN acc 0.4375', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5020', 'Total loss: 1.3959', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52424401)
('DISCRIMINATOR_Imagem FAKE=', 0.5245713)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.250076')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7028 ', 'GAN acc 0.4219', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5000', 'Total loss: 1.3982', 'for batch', 0)
('GAN loss 0.7026 ', 'GAN acc 0.4141', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5039', 'Total loss: 1.3952', 'for batch', 1)
('GAN loss 0.7019 ', 'GAN acc 0.4531', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5137', 'Total loss: 1.3953', 'for batch', 2)
('GAN loss 0.6894 ', 'GAN acc 0.5547', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5391', 'Total loss: 1.3814', 'for batch', 3)
('GAN loss 0.6848 ', 'GAN acc 0.5781', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4824', 'Total loss: 1.3829', 'for batch', 4)
('GAN loss 0.6822 ', 'GAN acc 0.6094', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5176', 'Total loss: 1.3744', 'for batch', 5)
('GAN loss 0.6727 ', 'GAN acc 0.6875', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5137', 'Total loss: 1.3646', 'for batch', 6)
('GAN loss 0.6741 ', 'GAN acc 0.6562', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5195', 'Total loss: 1.3669', 'for batch', 7)
('GAN loss 0.6778 ', 'GAN acc 0.6484', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5156', 'Total loss: 1.3684', 'for batch', 8)
('GAN loss 0.6749 ', 'GAN acc 0.6914', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5020', 'Total loss: 1.3672', 'for batch', 9)
('GAN loss 0.6835 ', 'GAN acc 0.6016', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4863', 'Total loss: 1.3788', 'for batch', 10)
('GAN loss 0.6863 ', 'GAN acc 0.5781', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5098', 'Total loss: 1.3800', 'for batch', 11)
('GAN loss 0.6881 ', 'GAN acc 0.5391', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5117', 'Total loss: 1.3822', 'for batch', 12)
('GAN loss 0.6929 ', 'GAN acc 0.5195', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5234', 'Total loss: 1.3864', 'for batch', 13)
('GAN loss 0.6982 ', 'GAN acc 0.4492', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4980', 'Total loss: 1.3924', 'for batch', 14)
('GAN loss 0.7035 ', 'GAN acc 0.4375', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5391', 'Total loss: 1.3967', 'for batch', 15)
('GAN loss 0.7082 ', 'GAN acc 0.3945', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5000', 'Total loss: 1.4035', 'for batch', 16)
('GAN loss 0.7019 ', 'GAN acc 0.4805', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5234', 'Total loss: 1.3924', 'for batch', 17)
('GAN loss 0.7029 ', 'GAN acc 0.4023', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5039', 'Total loss: 1.3973', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52263671)
('DISCRIMINATOR_Imagem FAKE=', 0.52386796)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.698346')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7007 ', 'GAN acc 0.4453', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4902', 'Total loss: 1.3944', 'for batch', 0)
('GAN loss 0.7037 ', 'GAN acc 0.4375', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.6955 ', 'GAN acc 0.4844', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4648', 'Total loss: 1.3930', 'for batch', 2)
('GAN loss 0.6940 ', 'GAN acc 0.4922', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5020', 'Total loss: 1.3860', 'for batch', 3)
('GAN loss 0.6847 ', 'GAN acc 0.5859', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4688', 'Total loss: 1.3820', 'for batch', 4)
('GAN loss 0.6816 ', 'GAN acc 0.6211', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5156', 'Total loss: 1.3738', 'for batch', 5)
('GAN loss 0.6786 ', 'GAN acc 0.6406', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3722', 'for batch', 6)
('GAN loss 0.6804 ', 'GAN acc 0.6133', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4531', 'Total loss: 1.3806', 'for batch', 7)
('GAN loss 0.6746 ', 'GAN acc 0.6602', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5137', 'Total loss: 1.3677', 'for batch', 8)
('GAN loss 0.6859 ', 'GAN acc 0.5859', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5137', 'Total loss: 1.3812', 'for batch', 9)
('GAN loss 0.6929 ', 'GAN acc 0.5352', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5156', 'Total loss: 1.3871', 'for batch', 10)
('GAN loss 0.6895 ', 'GAN acc 0.5469', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4844', 'Total loss: 1.3875', 'for batch', 11)
('GAN loss 0.6887 ', 'GAN acc 0.5391', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5430', 'Total loss: 1.3813', 'for batch', 12)
('GAN loss 0.6963 ', 'GAN acc 0.4648', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5176', 'Total loss: 1.3889', 'for batch', 13)
('GAN loss 0.6996 ', 'GAN acc 0.4883', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5117', 'Total loss: 1.3904', 'for batch', 14)
('GAN loss 0.6953 ', 'GAN acc 0.4570', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5020', 'Total loss: 1.3912', 'for batch', 15)
('GAN loss 0.7034 ', 'GAN acc 0.4219', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4844', 'Total loss: 1.3993', 'for batch', 16)
('GAN loss 0.7020 ', 'GAN acc 0.3945', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4590', 'Total loss: 1.3985', 'for batch', 17)
('GAN loss 0.7029 ', 'GAN acc 0.4062', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4707', 'Total loss: 1.3979', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52358258)
('DISCRIMINATOR_Imagem FAKE=', 0.52391332)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.232073')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6942 ', 'GAN acc 0.5117', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5000', 'Total loss: 1.3899', 'for batch', 0)
('GAN loss 0.7042 ', 'GAN acc 0.4023', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4648', 'Total loss: 1.4038', 'for batch', 1)
('GAN loss 0.7041 ', 'GAN acc 0.3984', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4961', 'Total loss: 1.3991', 'for batch', 2)
('GAN loss 0.6948 ', 'GAN acc 0.5117', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4961', 'Total loss: 1.3877', 'for batch', 3)
('GAN loss 0.6952 ', 'GAN acc 0.5039', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5352', 'Total loss: 1.3879', 'for batch', 4)
('GAN loss 0.6907 ', 'GAN acc 0.5312', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4980', 'Total loss: 1.3876', 'for batch', 5)
('GAN loss 0.6840 ', 'GAN acc 0.5938', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4844', 'Total loss: 1.3803', 'for batch', 6)
('GAN loss 0.6840 ', 'GAN acc 0.5820', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4844', 'Total loss: 1.3779', 'for batch', 7)
('GAN loss 0.6799 ', 'GAN acc 0.6719', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4980', 'Total loss: 1.3726', 'for batch', 8)
('GAN loss 0.6765 ', 'GAN acc 0.6797', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4746', 'Total loss: 1.3739', 'for batch', 9)
('GAN loss 0.6862 ', 'GAN acc 0.5859', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5000', 'Total loss: 1.3785', 'for batch', 10)
('GAN loss 0.6895 ', 'GAN acc 0.5469', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4961', 'Total loss: 1.3827', 'for batch', 11)
('GAN loss 0.6917 ', 'GAN acc 0.5586', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4727', 'Total loss: 1.3877', 'for batch', 12)
('GAN loss 0.6913 ', 'GAN acc 0.5586', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5098', 'Total loss: 1.3846', 'for batch', 13)
('GAN loss 0.6908 ', 'GAN acc 0.5469', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4980', 'Total loss: 1.3851', 'for batch', 14)
('GAN loss 0.6879 ', 'GAN acc 0.5703', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4727', 'Total loss: 1.3843', 'for batch', 15)
('GAN loss 0.6934 ', 'GAN acc 0.5078', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5098', 'Total loss: 1.3868', 'for batch', 16)
('GAN loss 0.6995 ', 'GAN acc 0.4570', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4883', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.6956 ', 'GAN acc 0.4883', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4785', 'Total loss: 1.3923', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51845604)
('DISCRIMINATOR_Imagem FAKE=', 0.51916224)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.717379')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7003 ', 'GAN acc 0.4531', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5293', 'Total loss: 1.3930', 'for batch', 0)
('GAN loss 0.6959 ', 'GAN acc 0.4883', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5098', 'Total loss: 1.3900', 'for batch', 1)
('GAN loss 0.6948 ', 'GAN acc 0.5156', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5176', 'Total loss: 1.3888', 'for batch', 2)
('GAN loss 0.6876 ', 'GAN acc 0.5430', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5039', 'Total loss: 1.3823', 'for batch', 3)
('GAN loss 0.6887 ', 'GAN acc 0.5273', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4668', 'Total loss: 1.3850', 'for batch', 4)
('GAN loss 0.6850 ', 'GAN acc 0.5781', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4629', 'Total loss: 1.3823', 'for batch', 5)
('GAN loss 0.6852 ', 'GAN acc 0.5781', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4844', 'Total loss: 1.3819', 'for batch', 6)
('GAN loss 0.6859 ', 'GAN acc 0.5977', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4961', 'Total loss: 1.3812', 'for batch', 7)
('GAN loss 0.6814 ', 'GAN acc 0.6094', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4863', 'Total loss: 1.3759', 'for batch', 8)
('GAN loss 0.6846 ', 'GAN acc 0.5664', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5195', 'Total loss: 1.3755', 'for batch', 9)
('GAN loss 0.6869 ', 'GAN acc 0.5664', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4980', 'Total loss: 1.3817', 'for batch', 10)
('GAN loss 0.6884 ', 'GAN acc 0.5703', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4688', 'Total loss: 1.3849', 'for batch', 11)
('GAN loss 0.6868 ', 'GAN acc 0.5977', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4980', 'Total loss: 1.3814', 'for batch', 12)
('GAN loss 0.6974 ', 'GAN acc 0.4336', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3902', 'for batch', 13)
('GAN loss 0.6948 ', 'GAN acc 0.5000', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4668', 'Total loss: 1.3911', 'for batch', 14)
('GAN loss 0.6992 ', 'GAN acc 0.4336', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5000', 'Total loss: 1.3928', 'for batch', 15)
('GAN loss 0.7010 ', 'GAN acc 0.4453', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5039', 'Total loss: 1.3970', 'for batch', 16)
('GAN loss 0.7001 ', 'GAN acc 0.4492', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5000', 'Total loss: 1.3924', 'for batch', 17)
('GAN loss 0.7039 ', 'GAN acc 0.4336', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4883', 'Total loss: 1.4003', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51409692)
('DISCRIMINATOR_Imagem FAKE=', 0.51479417)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.217738')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6988 ', 'GAN acc 0.4922', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4746', 'Total loss: 1.3977', 'for batch', 0)
('GAN loss 0.6984 ', 'GAN acc 0.4492', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5059', 'Total loss: 1.3928', 'for batch', 1)
('GAN loss 0.6958 ', 'GAN acc 0.5000', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5156', 'Total loss: 1.3874', 'for batch', 2)
('GAN loss 0.6903 ', 'GAN acc 0.5273', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5117', 'Total loss: 1.3848', 'for batch', 3)
('GAN loss 0.6905 ', 'GAN acc 0.5430', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4863', 'Total loss: 1.3842', 'for batch', 4)
('GAN loss 0.6868 ', 'GAN acc 0.5742', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4668', 'Total loss: 1.3848', 'for batch', 5)
('GAN loss 0.6842 ', 'GAN acc 0.5938', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4785', 'Total loss: 1.3810', 'for batch', 6)
('GAN loss 0.6798 ', 'GAN acc 0.6562', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4727', 'Total loss: 1.3773', 'for batch', 7)
('GAN loss 0.6817 ', 'GAN acc 0.5898', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4922', 'Total loss: 1.3754', 'for batch', 8)
('GAN loss 0.6800 ', 'GAN acc 0.6367', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4824', 'Total loss: 1.3743', 'for batch', 9)
('GAN loss 0.6829 ', 'GAN acc 0.5898', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5020', 'Total loss: 1.3789', 'for batch', 10)
('GAN loss 0.6819 ', 'GAN acc 0.6328', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5020', 'Total loss: 1.3749', 'for batch', 11)
('GAN loss 0.6884 ', 'GAN acc 0.6250', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3829', 'for batch', 12)
('GAN loss 0.6954 ', 'GAN acc 0.4648', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3888', 'for batch', 13)
('GAN loss 0.6987 ', 'GAN acc 0.4609', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5117', 'Total loss: 1.3904', 'for batch', 14)
('GAN loss 0.7050 ', 'GAN acc 0.3984', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5000', 'Total loss: 1.3970', 'for batch', 15)
('GAN loss 0.7050 ', 'GAN acc 0.3633', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.4000', 'for batch', 16)
('GAN loss 0.7089 ', 'GAN acc 0.3633', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4922', 'Total loss: 1.4020', 'for batch', 17)
('GAN loss 0.7054 ', 'GAN acc 0.3984', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4707', 'Total loss: 1.4003', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51309997)
('DISCRIMINATOR_Imagem FAKE=', 0.51309997)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.739515')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6996 ', 'GAN acc 0.4297', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4727', 'Total loss: 1.3952', 'for batch', 0)
('GAN loss 0.7036 ', 'GAN acc 0.4062', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4629', 'Total loss: 1.3970', 'for batch', 1)
('GAN loss 0.7017 ', 'GAN acc 0.4219', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4844', 'Total loss: 1.3959', 'for batch', 2)
('GAN loss 0.6975 ', 'GAN acc 0.4648', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5078', 'Total loss: 1.3908', 'for batch', 3)
('GAN loss 0.6933 ', 'GAN acc 0.5156', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5117', 'Total loss: 1.3869', 'for batch', 4)
('GAN loss 0.6877 ', 'GAN acc 0.5820', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4492', 'Total loss: 1.3856', 'for batch', 5)
('GAN loss 0.6819 ', 'GAN acc 0.6445', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4863', 'Total loss: 1.3779', 'for batch', 6)
('GAN loss 0.6815 ', 'GAN acc 0.6367', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4902', 'Total loss: 1.3791', 'for batch', 7)
('GAN loss 0.6815 ', 'GAN acc 0.6484', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3768', 'for batch', 8)
('GAN loss 0.6790 ', 'GAN acc 0.6211', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5020', 'Total loss: 1.3725', 'for batch', 9)
('GAN loss 0.6763 ', 'GAN acc 0.6797', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4902', 'Total loss: 1.3734', 'for batch', 10)
('GAN loss 0.6807 ', 'GAN acc 0.6641', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4473', 'Total loss: 1.3785', 'for batch', 11)
('GAN loss 0.6844 ', 'GAN acc 0.5859', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5117', 'Total loss: 1.3786', 'for batch', 12)
('GAN loss 0.6834 ', 'GAN acc 0.6133', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4551', 'Total loss: 1.3804', 'for batch', 13)
('GAN loss 0.6900 ', 'GAN acc 0.5469', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5195', 'Total loss: 1.3823', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.5000', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4844', 'Total loss: 1.3880', 'for batch', 15)
('GAN loss 0.6964 ', 'GAN acc 0.4805', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4961', 'Total loss: 1.3912', 'for batch', 16)
('GAN loss 0.6979 ', 'GAN acc 0.4727', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4844', 'Total loss: 1.3934', 'for batch', 17)
('GAN loss 0.6972 ', 'GAN acc 0.4648', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5176', 'Total loss: 1.3903', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51621312)
('DISCRIMINATOR_Imagem FAKE=', 0.51629394)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.303187')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6959 ', 'GAN acc 0.4883', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5176', 'Total loss: 1.3885', 'for batch', 0)
('GAN loss 0.7007 ', 'GAN acc 0.4219', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5117', 'Total loss: 1.3951', 'for batch', 1)
('GAN loss 0.6908 ', 'GAN acc 0.5312', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4707', 'Total loss: 1.3882', 'for batch', 2)
('GAN loss 0.6925 ', 'GAN acc 0.5156', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5215', 'Total loss: 1.3855', 'for batch', 3)
('GAN loss 0.6911 ', 'GAN acc 0.5000', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5273', 'Total loss: 1.3847', 'for batch', 4)
('GAN loss 0.6855 ', 'GAN acc 0.5898', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5098', 'Total loss: 1.3804', 'for batch', 5)
('GAN loss 0.6852 ', 'GAN acc 0.6133', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4746', 'Total loss: 1.3823', 'for batch', 6)
('GAN loss 0.6806 ', 'GAN acc 0.6484', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4727', 'Total loss: 1.3790', 'for batch', 7)
('GAN loss 0.6809 ', 'GAN acc 0.6211', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4746', 'Total loss: 1.3761', 'for batch', 8)
('GAN loss 0.6825 ', 'GAN acc 0.6211', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4961', 'Total loss: 1.3751', 'for batch', 9)
('GAN loss 0.6828 ', 'GAN acc 0.6289', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4844', 'Total loss: 1.3769', 'for batch', 10)
('GAN loss 0.6858 ', 'GAN acc 0.5742', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4609', 'Total loss: 1.3814', 'for batch', 11)
('GAN loss 0.6943 ', 'GAN acc 0.4922', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4844', 'Total loss: 1.3894', 'for batch', 12)
('GAN loss 0.6898 ', 'GAN acc 0.5547', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5293', 'Total loss: 1.3812', 'for batch', 13)
('GAN loss 0.6934 ', 'GAN acc 0.4883', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4844', 'Total loss: 1.3873', 'for batch', 14)
('GAN loss 0.6952 ', 'GAN acc 0.4961', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4961', 'Total loss: 1.3895', 'for batch', 15)
('GAN loss 0.6977 ', 'GAN acc 0.4531', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5098', 'Total loss: 1.3930', 'for batch', 16)
('GAN loss 0.7027 ', 'GAN acc 0.4102', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4883', 'Total loss: 1.3966', 'for batch', 17)
('GAN loss 0.7033 ', 'GAN acc 0.3984', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5020', 'Total loss: 1.3963', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51424521)
('DISCRIMINATOR_Imagem FAKE=', 0.51411557)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.704947')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7043 ', 'GAN acc 0.4102', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4746', 'Total loss: 1.4003', 'for batch', 0)
('GAN loss 0.7080 ', 'GAN acc 0.3789', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4961', 'Total loss: 1.4023', 'for batch', 1)
('GAN loss 0.6969 ', 'GAN acc 0.4922', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5430', 'Total loss: 1.3893', 'for batch', 2)
('GAN loss 0.6970 ', 'GAN acc 0.4648', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5352', 'Total loss: 1.3902', 'for batch', 3)
('GAN loss 0.6894 ', 'GAN acc 0.5586', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3848', 'for batch', 4)
('GAN loss 0.6920 ', 'GAN acc 0.5273', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5020', 'Total loss: 1.3852', 'for batch', 5)
('GAN loss 0.6859 ', 'GAN acc 0.5977', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5176', 'Total loss: 1.3780', 'for batch', 6)
('GAN loss 0.6817 ', 'GAN acc 0.6289', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5137', 'Total loss: 1.3747', 'for batch', 7)
('GAN loss 0.6807 ', 'GAN acc 0.6562', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3739', 'for batch', 8)
('GAN loss 0.6810 ', 'GAN acc 0.6445', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5020', 'Total loss: 1.3729', 'for batch', 9)
('GAN loss 0.6791 ', 'GAN acc 0.6289', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4824', 'Total loss: 1.3747', 'for batch', 10)
('GAN loss 0.6804 ', 'GAN acc 0.6172', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5195', 'Total loss: 1.3719', 'for batch', 11)
('GAN loss 0.6845 ', 'GAN acc 0.6406', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4902', 'Total loss: 1.3774', 'for batch', 12)
('GAN loss 0.6852 ', 'GAN acc 0.6172', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4941', 'Total loss: 1.3778', 'for batch', 13)
('GAN loss 0.6932 ', 'GAN acc 0.5078', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5039', 'Total loss: 1.3876', 'for batch', 14)
('GAN loss 0.6946 ', 'GAN acc 0.5039', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5000', 'Total loss: 1.3884', 'for batch', 15)
('GAN loss 0.7041 ', 'GAN acc 0.4023', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4844', 'Total loss: 1.3984', 'for batch', 16)
('GAN loss 0.7064 ', 'GAN acc 0.3945', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5117', 'Total loss: 1.4010', 'for batch', 17)
('GAN loss 0.7049 ', 'GAN acc 0.4258', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4746', 'Total loss: 1.3990', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51324195)
('DISCRIMINATOR_Imagem FAKE=', 0.51303864)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.215371')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7028 ', 'GAN acc 0.3906', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5664', 'Total loss: 1.3936', 'for batch', 0)
('GAN loss 0.7025 ', 'GAN acc 0.4297', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5000', 'Total loss: 1.3966', 'for batch', 1)
('GAN loss 0.6960 ', 'GAN acc 0.5000', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5293', 'Total loss: 1.3888', 'for batch', 2)
('GAN loss 0.6915 ', 'GAN acc 0.5469', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5234', 'Total loss: 1.3860', 'for batch', 3)
('GAN loss 0.6938 ', 'GAN acc 0.5039', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4766', 'Total loss: 1.3905', 'for batch', 4)
('GAN loss 0.6885 ', 'GAN acc 0.5391', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4531', 'Total loss: 1.3854', 'for batch', 5)
('GAN loss 0.6825 ', 'GAN acc 0.6445', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5117', 'Total loss: 1.3752', 'for batch', 6)
('GAN loss 0.6848 ', 'GAN acc 0.6172', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5332', 'Total loss: 1.3783', 'for batch', 7)
('GAN loss 0.6871 ', 'GAN acc 0.5664', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5312', 'Total loss: 1.3790', 'for batch', 8)
('GAN loss 0.6822 ', 'GAN acc 0.6250', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4902', 'Total loss: 1.3776', 'for batch', 9)
('GAN loss 0.6894 ', 'GAN acc 0.5469', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5273', 'Total loss: 1.3810', 'for batch', 10)
('GAN loss 0.6864 ', 'GAN acc 0.5547', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4883', 'Total loss: 1.3807', 'for batch', 11)
('GAN loss 0.6912 ', 'GAN acc 0.5117', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4980', 'Total loss: 1.3856', 'for batch', 12)
('GAN loss 0.6934 ', 'GAN acc 0.4688', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4941', 'Total loss: 1.3878', 'for batch', 13)
('GAN loss 0.6972 ', 'GAN acc 0.4531', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5059', 'Total loss: 1.3909', 'for batch', 14)
('GAN loss 0.7025 ', 'GAN acc 0.4375', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5117', 'Total loss: 1.3954', 'for batch', 15)
('GAN loss 0.7010 ', 'GAN acc 0.4297', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5020', 'Total loss: 1.3957', 'for batch', 16)
('GAN loss 0.7013 ', 'GAN acc 0.4297', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4805', 'Total loss: 1.3940', 'for batch', 17)
('GAN loss 0.7048 ', 'GAN acc 0.3984', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5020', 'Total loss: 1.3990', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51332253)
('DISCRIMINATOR_Imagem FAKE=', 0.51340419)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.720409')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6979 ', 'GAN acc 0.4805', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4922', 'Total loss: 1.3911', 'for batch', 0)
('GAN loss 0.7050 ', 'GAN acc 0.3867', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5098', 'Total loss: 1.3977', 'for batch', 1)
('GAN loss 0.7029 ', 'GAN acc 0.3867', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4512', 'Total loss: 1.4006', 'for batch', 2)
('GAN loss 0.6991 ', 'GAN acc 0.4570', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4551', 'Total loss: 1.3969', 'for batch', 3)
('GAN loss 0.6918 ', 'GAN acc 0.5000', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4941', 'Total loss: 1.3859', 'for batch', 4)
('GAN loss 0.6908 ', 'GAN acc 0.5547', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4844', 'Total loss: 1.3851', 'for batch', 5)
('GAN loss 0.6819 ', 'GAN acc 0.6406', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4922', 'Total loss: 1.3759', 'for batch', 6)
('GAN loss 0.6809 ', 'GAN acc 0.6484', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.3757', 'for batch', 7)
('GAN loss 0.6825 ', 'GAN acc 0.6211', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4980', 'Total loss: 1.3759', 'for batch', 8)
('GAN loss 0.6784 ', 'GAN acc 0.6523', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5137', 'Total loss: 1.3719', 'for batch', 9)
('GAN loss 0.6817 ', 'GAN acc 0.6172', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5332', 'Total loss: 1.3749', 'for batch', 10)
('GAN loss 0.6840 ', 'GAN acc 0.5898', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4707', 'Total loss: 1.3787', 'for batch', 11)
('GAN loss 0.6917 ', 'GAN acc 0.5273', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4727', 'Total loss: 1.3887', 'for batch', 12)
('GAN loss 0.6974 ', 'GAN acc 0.4883', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4668', 'Total loss: 1.3935', 'for batch', 13)
('GAN loss 0.7010 ', 'GAN acc 0.4531', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4883', 'Total loss: 1.3968', 'for batch', 14)
('GAN loss 0.7082 ', 'GAN acc 0.3438', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5195', 'Total loss: 1.4001', 'for batch', 15)
('GAN loss 0.7088 ', 'GAN acc 0.3633', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4648', 'Total loss: 1.4042', 'for batch', 16)
('GAN loss 0.7097 ', 'GAN acc 0.3086', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4883', 'Total loss: 1.4059', 'for batch', 17)
('GAN loss 0.7050 ', 'GAN acc 0.3867', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5137', 'Total loss: 1.3973', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51119787)
('DISCRIMINATOR_Imagem FAKE=', 0.51116002)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.192973')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7004 ', 'GAN acc 0.4297', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5078', 'Total loss: 1.3940', 'for batch', 0)
('GAN loss 0.7043 ', 'GAN acc 0.4414', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4531', 'Total loss: 1.4018', 'for batch', 1)
('GAN loss 0.6956 ', 'GAN acc 0.4727', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4492', 'Total loss: 1.3925', 'for batch', 2)
('GAN loss 0.6908 ', 'GAN acc 0.5430', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4805', 'Total loss: 1.3875', 'for batch', 3)
('GAN loss 0.6869 ', 'GAN acc 0.6133', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.3810', 'for batch', 4)
('GAN loss 0.6825 ', 'GAN acc 0.6328', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5156', 'Total loss: 1.3749', 'for batch', 5)
('GAN loss 0.6796 ', 'GAN acc 0.6562', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4824', 'Total loss: 1.3721', 'for batch', 6)
('GAN loss 0.6742 ', 'GAN acc 0.7188', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4961', 'Total loss: 1.3673', 'for batch', 7)
('GAN loss 0.6812 ', 'GAN acc 0.6641', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4355', 'Total loss: 1.3790', 'for batch', 8)
('GAN loss 0.6809 ', 'GAN acc 0.6680', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4609', 'Total loss: 1.3744', 'for batch', 9)
('GAN loss 0.6855 ', 'GAN acc 0.5898', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5371', 'Total loss: 1.3771', 'for batch', 10)
('GAN loss 0.6873 ', 'GAN acc 0.5938', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4863', 'Total loss: 1.3833', 'for batch', 11)
('GAN loss 0.6846 ', 'GAN acc 0.5977', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3796', 'for batch', 12)
('GAN loss 0.6938 ', 'GAN acc 0.4883', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5137', 'Total loss: 1.3860', 'for batch', 13)
('GAN loss 0.6947 ', 'GAN acc 0.5117', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5000', 'Total loss: 1.3869', 'for batch', 14)
('GAN loss 0.7000 ', 'GAN acc 0.4336', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5020', 'Total loss: 1.3927', 'for batch', 15)
('GAN loss 0.7074 ', 'GAN acc 0.3516', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5195', 'Total loss: 1.4003', 'for batch', 16)
('GAN loss 0.7107 ', 'GAN acc 0.3086', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5156', 'Total loss: 1.4050', 'for batch', 17)
('GAN loss 0.7111 ', 'GAN acc 0.3398', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4668', 'Total loss: 1.4074', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50906181)
('DISCRIMINATOR_Imagem FAKE=', 0.50885862)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.736670')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7105 ', 'GAN acc 0.3047', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5020', 'Total loss: 1.4029', 'for batch', 0)
('GAN loss 0.7090 ', 'GAN acc 0.3359', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4668', 'Total loss: 1.4039', 'for batch', 1)
('GAN loss 0.7017 ', 'GAN acc 0.3945', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5039', 'Total loss: 1.3969', 'for batch', 2)
('GAN loss 0.6946 ', 'GAN acc 0.4688', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4883', 'Total loss: 1.3884', 'for batch', 3)
('GAN loss 0.6943 ', 'GAN acc 0.4727', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5059', 'Total loss: 1.3893', 'for batch', 4)
('GAN loss 0.6840 ', 'GAN acc 0.6680', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4551', 'Total loss: 1.3794', 'for batch', 5)
('GAN loss 0.6818 ', 'GAN acc 0.6602', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3778', 'for batch', 6)
('GAN loss 0.6798 ', 'GAN acc 0.6289', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5059', 'Total loss: 1.3718', 'for batch', 7)
('GAN loss 0.6771 ', 'GAN acc 0.6836', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4922', 'Total loss: 1.3706', 'for batch', 8)
('GAN loss 0.6729 ', 'GAN acc 0.7266', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5449', 'Total loss: 1.3653', 'for batch', 9)
('GAN loss 0.6729 ', 'GAN acc 0.7148', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3668', 'for batch', 10)
('GAN loss 0.6781 ', 'GAN acc 0.6953', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4629', 'Total loss: 1.3762', 'for batch', 11)
('GAN loss 0.6827 ', 'GAN acc 0.6289', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5000', 'Total loss: 1.3758', 'for batch', 12)
('GAN loss 0.6864 ', 'GAN acc 0.5781', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4941', 'Total loss: 1.3801', 'for batch', 13)
('GAN loss 0.6909 ', 'GAN acc 0.5508', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4980', 'Total loss: 1.3854', 'for batch', 14)
('GAN loss 0.6932 ', 'GAN acc 0.5312', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4824', 'Total loss: 1.3874', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.4922', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4883', 'Total loss: 1.3926', 'for batch', 16)
('GAN loss 0.7048 ', 'GAN acc 0.4141', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4727', 'Total loss: 1.4019', 'for batch', 17)
('GAN loss 0.7026 ', 'GAN acc 0.3750', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5020', 'Total loss: 1.3960', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50805986)
('DISCRIMINATOR_Imagem FAKE=', 0.50817335)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.251170')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7092 ', 'GAN acc 0.3672', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4941', 'Total loss: 1.4043', 'for batch', 0)
('GAN loss 0.7049 ', 'GAN acc 0.4062', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5059', 'Total loss: 1.3980', 'for batch', 1)
('GAN loss 0.7019 ', 'GAN acc 0.4180', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4609', 'Total loss: 1.3986', 'for batch', 2)
('GAN loss 0.6991 ', 'GAN acc 0.3984', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5215', 'Total loss: 1.3922', 'for batch', 3)
('GAN loss 0.6941 ', 'GAN acc 0.5352', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4961', 'Total loss: 1.3882', 'for batch', 4)
('GAN loss 0.6947 ', 'GAN acc 0.5000', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4863', 'Total loss: 1.3902', 'for batch', 5)
('GAN loss 0.6862 ', 'GAN acc 0.6055', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4707', 'Total loss: 1.3834', 'for batch', 6)
('GAN loss 0.6840 ', 'GAN acc 0.6055', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5391', 'Total loss: 1.3735', 'for batch', 7)
('GAN loss 0.6879 ', 'GAN acc 0.5781', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5293', 'Total loss: 1.3799', 'for batch', 8)
('GAN loss 0.6847 ', 'GAN acc 0.6055', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4902', 'Total loss: 1.3789', 'for batch', 9)
('GAN loss 0.6859 ', 'GAN acc 0.5898', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5098', 'Total loss: 1.3789', 'for batch', 10)
('GAN loss 0.6856 ', 'GAN acc 0.5586', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4844', 'Total loss: 1.3810', 'for batch', 11)
('GAN loss 0.6887 ', 'GAN acc 0.5820', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.4980', 'Total loss: 1.3811', 'for batch', 12)
('GAN loss 0.6864 ', 'GAN acc 0.6016', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3809', 'for batch', 13)
('GAN loss 0.6922 ', 'GAN acc 0.5234', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5176', 'Total loss: 1.3832', 'for batch', 14)
('GAN loss 0.6951 ', 'GAN acc 0.4844', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4629', 'Total loss: 1.3937', 'for batch', 15)
('GAN loss 0.7006 ', 'GAN acc 0.4062', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5137', 'Total loss: 1.3932', 'for batch', 16)
('GAN loss 0.7091 ', 'GAN acc 0.3398', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4668', 'Total loss: 1.4062', 'for batch', 17)
('GAN loss 0.7077 ', 'GAN acc 0.3281', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5137', 'Total loss: 1.4013', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50777912)
('DISCRIMINATOR_Imagem FAKE=', 0.50813746)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.698901')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7060 ', 'GAN acc 0.3633', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4727', 'Total loss: 1.3999', 'for batch', 0)
('GAN loss 0.7068 ', 'GAN acc 0.3359', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4824', 'Total loss: 1.4011', 'for batch', 1)
('GAN loss 0.7020 ', 'GAN acc 0.3945', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4785', 'Total loss: 1.3972', 'for batch', 2)
('GAN loss 0.6981 ', 'GAN acc 0.4531', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4746', 'Total loss: 1.3939', 'for batch', 3)
('GAN loss 0.6946 ', 'GAN acc 0.4727', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4707', 'Total loss: 1.3906', 'for batch', 4)
('GAN loss 0.6925 ', 'GAN acc 0.5391', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5020', 'Total loss: 1.3857', 'for batch', 5)
('GAN loss 0.6889 ', 'GAN acc 0.5742', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4941', 'Total loss: 1.3826', 'for batch', 6)
('GAN loss 0.6856 ', 'GAN acc 0.6172', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3791', 'for batch', 7)
('GAN loss 0.6818 ', 'GAN acc 0.6406', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3746', 'for batch', 8)
('GAN loss 0.6820 ', 'GAN acc 0.6875', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4785', 'Total loss: 1.3768', 'for batch', 9)
('GAN loss 0.6833 ', 'GAN acc 0.6367', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5273', 'Total loss: 1.3765', 'for batch', 10)
('GAN loss 0.6815 ', 'GAN acc 0.6562', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4746', 'Total loss: 1.3749', 'for batch', 11)
('GAN loss 0.6822 ', 'GAN acc 0.6055', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4980', 'Total loss: 1.3760', 'for batch', 12)
('GAN loss 0.6857 ', 'GAN acc 0.6172', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.4941', 'Total loss: 1.3779', 'for batch', 13)
('GAN loss 0.6852 ', 'GAN acc 0.6172', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4961', 'Total loss: 1.3801', 'for batch', 14)
('GAN loss 0.6937 ', 'GAN acc 0.5234', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3882', 'for batch', 15)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7490 ', 'GAN acc 0.5039', 'Discriminator loss 0.7460', 'Discriminator accuracy 0.4980', 'Total loss: 1.4950', 'for batch', 0)
('GAN loss 0.6940 ', 'GAN acc 0.5391', 'Discriminator loss 0.7709', 'Discriminator accuracy 0.5039', 'Total loss: 1.4649', 'for batch', 1)
('GAN loss 0.7790 ', 'GAN acc 0.5078', 'Discriminator loss 0.8003', 'Discriminator accuracy 0.4844', 'Total loss: 1.5793', 'for batch', 2)
('GAN loss 0.8832 ', 'GAN acc 0.3711', 'Discriminator loss 0.7552', 'Discriminator accuracy 0.5312', 'Total loss: 1.6383', 'for batch', 3)
('GAN loss 0.7878 ', 'GAN acc 0.4453', 'Discriminator loss 0.7697', 'Discriminator accuracy 0.4668', 'Total loss: 1.5575', 'for batch', 4)
('GAN loss 0.7441 ', 'GAN acc 0.4922', 'Discriminator loss 0.7761', 'Discriminator accuracy 0.4746', 'Total loss: 1.5202', 'for batch', 5)
('GAN loss 0.7396 ', 'GAN acc 0.4844', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.5430', 'Total loss: 1.4454', 'for batch', 6)
('GAN loss 0.8439 ', 'GAN acc 0.3906', 'Discriminator loss 0.7158', 'Discriminator accuracy 0.5332', 'Total loss: 1.5597', 'for batch', 7)
('GAN loss 0.8166 ', 'GAN acc 0.3984', 'Discriminator loss 0.7283', 'Discriminator accuracy 0.5410', 'Total loss: 1.5449', 'for batch', 8)
('GAN loss 0.9473 ', 'GAN acc 0.2734', 'Discriminator loss 0.7182', 'Discriminator accuracy 0.5371', 'Total loss: 1.6654', 'for batch', 9)
('GAN loss 1.0350 ', 'GAN acc 0.2305', 'Discriminator loss 0.6572', 'Discriminator accuracy 0.6172', 'Total loss: 1.6922', 'for batch', 10)
('GAN loss 1.0665 ', 'GAN acc 0.2031', 'Discriminator loss 0.6669', 'Discriminator accuracy 0.6094', 'Total loss: 1.7334', 'for batch', 11)
('GAN loss 0.9720 ', 'GAN acc 0.2500', 'Discriminator loss 0.6017', 'Discriminator accuracy 0.6992', 'Total loss: 1.5737', 'for batch', 12)
('GAN loss 1.0372 ', 'GAN acc 0.2109', 'Discriminator loss 0.6178', 'Discriminator accuracy 0.6934', 'Total loss: 1.6550', 'for batch', 13)
('GAN loss 1.0630 ', 'GAN acc 0.2109', 'Discriminator loss 0.6103', 'Discriminator accuracy 0.6777', 'Total loss: 1.6732', 'for batch', 14)
('GAN loss 1.1024 ', 'GAN acc 0.1953', 'Discriminator loss 0.6177', 'Discriminator accuracy 0.6738', 'Total loss: 1.7201', 'for batch', 15)
('GAN loss 1.1221 ', 'GAN acc 0.1758', 'Discriminator loss 0.6084', 'Discriminator accuracy 0.6777', 'Total loss: 1.7304', 'for batch', 16)
('GAN loss 1.1560 ', 'GAN acc 0.1680', 'Discriminator loss 0.5857', 'Discriminator accuracy 0.6973', 'Total loss: 1.7417', 'for batch', 17)
('GAN loss 1.2191 ', 'GAN acc 0.1484', 'Discriminator loss 0.5609', 'Discriminator accuracy 0.7188', 'Total loss: 1.7800', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.7975474)
('DISCRIMINATOR_Imagem FAKE=', 0.60868871)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.435172')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1780 ', 'GAN acc 0.1641', 'Discriminator loss 0.5437', 'Discriminator accuracy 0.7441', 'Total loss: 1.7217', 'for batch', 0)
('GAN loss 1.2890 ', 'GAN acc 0.1367', 'Discriminator loss 0.5688', 'Discriminator accuracy 0.7363', 'Total loss: 1.8578', 'for batch', 1)
('GAN loss 1.4491 ', 'GAN acc 0.0859', 'Discriminator loss 0.5293', 'Discriminator accuracy 0.7695', 'Total loss: 1.9784', 'for batch', 2)
('GAN loss 1.1980 ', 'GAN acc 0.2109', 'Discriminator loss 0.5509', 'Discriminator accuracy 0.7051', 'Total loss: 1.7489', 'for batch', 3)
('GAN loss 1.1720 ', 'GAN acc 0.1953', 'Discriminator loss 0.5824', 'Discriminator accuracy 0.6953', 'Total loss: 1.7544', 'for batch', 4)
('GAN loss 1.1782 ', 'GAN acc 0.1797', 'Discriminator loss 0.5957', 'Discriminator accuracy 0.6602', 'Total loss: 1.7739', 'for batch', 5)
('GAN loss 1.3445 ', 'GAN acc 0.1406', 'Discriminator loss 0.5857', 'Discriminator accuracy 0.7109', 'Total loss: 1.9302', 'for batch', 6)
('GAN loss 1.3043 ', 'GAN acc 0.1211', 'Discriminator loss 0.5785', 'Discriminator accuracy 0.6738', 'Total loss: 1.8828', 'for batch', 7)
('GAN loss 1.1553 ', 'GAN acc 0.1992', 'Discriminator loss 0.5378', 'Discriminator accuracy 0.7402', 'Total loss: 1.6931', 'for batch', 8)
('GAN loss 1.3415 ', 'GAN acc 0.1328', 'Discriminator loss 0.5774', 'Discriminator accuracy 0.7090', 'Total loss: 1.9189', 'for batch', 9)
('GAN loss 1.3229 ', 'GAN acc 0.1562', 'Discriminator loss 0.5517', 'Discriminator accuracy 0.7012', 'Total loss: 1.8746', 'for batch', 10)
('GAN loss 1.2780 ', 'GAN acc 0.1719', 'Discriminator loss 0.5870', 'Discriminator accuracy 0.6816', 'Total loss: 1.8650', 'for batch', 11)
('GAN loss 1.3012 ', 'GAN acc 0.1445', 'Discriminator loss 0.6070', 'Discriminator accuracy 0.6406', 'Total loss: 1.9082', 'for batch', 12)
('GAN loss 1.4021 ', 'GAN acc 0.1367', 'Discriminator loss 0.6650', 'Discriminator accuracy 0.6289', 'Total loss: 2.0671', 'for batch', 13)
('GAN loss 1.1530 ', 'GAN acc 0.1875', 'Discriminator loss 0.6575', 'Discriminator accuracy 0.5840', 'Total loss: 1.8105', 'for batch', 14)
('GAN loss 1.0159 ', 'GAN acc 0.2695', 'Discriminator loss 0.6498', 'Discriminator accuracy 0.6367', 'Total loss: 1.6657', 'for batch', 15)
('GAN loss 1.1329 ', 'GAN acc 0.1836', 'Discriminator loss 0.6444', 'Discriminator accuracy 0.6484', 'Total loss: 1.7773', 'for batch', 16)
('GAN loss 1.1409 ', 'GAN acc 0.1797', 'Discriminator loss 0.6556', 'Discriminator accuracy 0.5938', 'Total loss: 1.7965', 'for batch', 17)
('GAN loss 1.0229 ', 'GAN acc 0.2539', 'Discriminator loss 0.6393', 'Discriminator accuracy 0.6074', 'Total loss: 1.6622', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.84555906)
('DISCRIMINATOR_Imagem FAKE=', 0.79224694)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.037935')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9988 ', 'GAN acc 0.2617', 'Discriminator loss 0.6662', 'Discriminator accuracy 0.5918', 'Total loss: 1.6651', 'for batch', 0)
('GAN loss 1.1148 ', 'GAN acc 0.1953', 'Discriminator loss 0.6558', 'Discriminator accuracy 0.6055', 'Total loss: 1.7705', 'for batch', 1)
('GAN loss 1.0940 ', 'GAN acc 0.2266', 'Discriminator loss 0.6336', 'Discriminator accuracy 0.6133', 'Total loss: 1.7276', 'for batch', 2)
('GAN loss 0.9780 ', 'GAN acc 0.3086', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.5879', 'Total loss: 1.6304', 'for batch', 3)
('GAN loss 0.9957 ', 'GAN acc 0.3242', 'Discriminator loss 0.6490', 'Discriminator accuracy 0.6035', 'Total loss: 1.6447', 'for batch', 4)
('GAN loss 0.9482 ', 'GAN acc 0.3633', 'Discriminator loss 0.6469', 'Discriminator accuracy 0.6113', 'Total loss: 1.5950', 'for batch', 5)
('GAN loss 0.9182 ', 'GAN acc 0.3438', 'Discriminator loss 0.6388', 'Discriminator accuracy 0.6152', 'Total loss: 1.5570', 'for batch', 6)
('GAN loss 1.0316 ', 'GAN acc 0.2656', 'Discriminator loss 0.6604', 'Discriminator accuracy 0.6152', 'Total loss: 1.6920', 'for batch', 7)
('GAN loss 1.0290 ', 'GAN acc 0.2422', 'Discriminator loss 0.6431', 'Discriminator accuracy 0.5859', 'Total loss: 1.6721', 'for batch', 8)
('GAN loss 0.9660 ', 'GAN acc 0.3008', 'Discriminator loss 0.6832', 'Discriminator accuracy 0.5332', 'Total loss: 1.6492', 'for batch', 9)
('GAN loss 0.9157 ', 'GAN acc 0.2969', 'Discriminator loss 0.6686', 'Discriminator accuracy 0.5781', 'Total loss: 1.5843', 'for batch', 10)
('GAN loss 0.8031 ', 'GAN acc 0.4609', 'Discriminator loss 0.6884', 'Discriminator accuracy 0.5410', 'Total loss: 1.4915', 'for batch', 11)
('GAN loss 0.8249 ', 'GAN acc 0.4258', 'Discriminator loss 0.6803', 'Discriminator accuracy 0.5547', 'Total loss: 1.5052', 'for batch', 12)
('GAN loss 0.8204 ', 'GAN acc 0.3867', 'Discriminator loss 0.6603', 'Discriminator accuracy 0.5918', 'Total loss: 1.4807', 'for batch', 13)
('GAN loss 0.8104 ', 'GAN acc 0.4297', 'Discriminator loss 0.6629', 'Discriminator accuracy 0.5938', 'Total loss: 1.4733', 'for batch', 14)
('GAN loss 0.8084 ', 'GAN acc 0.4219', 'Discriminator loss 0.6774', 'Discriminator accuracy 0.5605', 'Total loss: 1.4858', 'for batch', 15)
('GAN loss 0.7757 ', 'GAN acc 0.4180', 'Discriminator loss 0.6812', 'Discriminator accuracy 0.5664', 'Total loss: 1.4570', 'for batch', 16)
('GAN loss 0.8055 ', 'GAN acc 0.3945', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5371', 'Total loss: 1.4965', 'for batch', 17)
('GAN loss 0.7408 ', 'GAN acc 0.5000', 'Discriminator loss 0.6820', 'Discriminator accuracy 0.5723', 'Total loss: 1.4229', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.81604558)
('DISCRIMINATOR_Imagem FAKE=', 0.78189403)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.633415')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7230 ', 'GAN acc 0.5352', 'Discriminator loss 0.6897', 'Discriminator accuracy 0.5547', 'Total loss: 1.4127', 'for batch', 0)
('GAN loss 0.7143 ', 'GAN acc 0.5039', 'Discriminator loss 0.6832', 'Discriminator accuracy 0.5898', 'Total loss: 1.3975', 'for batch', 1)
('GAN loss 0.7293 ', 'GAN acc 0.5391', 'Discriminator loss 0.6856', 'Discriminator accuracy 0.5547', 'Total loss: 1.4149', 'for batch', 2)
('GAN loss 0.6805 ', 'GAN acc 0.5977', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.5332', 'Total loss: 1.3811', 'for batch', 3)
('GAN loss 0.6659 ', 'GAN acc 0.5938', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5605', 'Total loss: 1.3597', 'for batch', 4)
('GAN loss 0.6380 ', 'GAN acc 0.6641', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.5391', 'Total loss: 1.3401', 'for batch', 5)
('GAN loss 0.6534 ', 'GAN acc 0.6562', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5391', 'Total loss: 1.3480', 'for batch', 6)
('GAN loss 0.6446 ', 'GAN acc 0.6680', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5352', 'Total loss: 1.3370', 'for batch', 7)
('GAN loss 0.6582 ', 'GAN acc 0.6289', 'Discriminator loss 0.6857', 'Discriminator accuracy 0.5254', 'Total loss: 1.3439', 'for batch', 8)
('GAN loss 0.6490 ', 'GAN acc 0.6445', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5137', 'Total loss: 1.3451', 'for batch', 9)
('GAN loss 0.6606 ', 'GAN acc 0.6172', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5215', 'Total loss: 1.3540', 'for batch', 10)
('GAN loss 0.6546 ', 'GAN acc 0.6797', 'Discriminator loss 0.6864', 'Discriminator accuracy 0.5176', 'Total loss: 1.3410', 'for batch', 11)
('GAN loss 0.6442 ', 'GAN acc 0.6484', 'Discriminator loss 0.7045', 'Discriminator accuracy 0.5117', 'Total loss: 1.3487', 'for batch', 12)
('GAN loss 0.6770 ', 'GAN acc 0.5781', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.5137', 'Total loss: 1.3751', 'for batch', 13)
('GAN loss 0.6490 ', 'GAN acc 0.6523', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.5020', 'Total loss: 1.3502', 'for batch', 14)
('GAN loss 0.6473 ', 'GAN acc 0.6719', 'Discriminator loss 0.7040', 'Discriminator accuracy 0.5000', 'Total loss: 1.3513', 'for batch', 15)
('GAN loss 0.6516 ', 'GAN acc 0.6484', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.4941', 'Total loss: 1.3429', 'for batch', 16)
('GAN loss 0.6403 ', 'GAN acc 0.6875', 'Discriminator loss 0.7073', 'Discriminator accuracy 0.4805', 'Total loss: 1.3476', 'for batch', 17)
('GAN loss 0.6631 ', 'GAN acc 0.6172', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.5293', 'Total loss: 1.3643', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.77190661)
('DISCRIMINATOR_Imagem FAKE=', 0.75100958)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.243841')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6622 ', 'GAN acc 0.6523', 'Discriminator loss 0.7066', 'Discriminator accuracy 0.5020', 'Total loss: 1.3687', 'for batch', 0)
('GAN loss 0.6735 ', 'GAN acc 0.5977', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.5293', 'Total loss: 1.3756', 'for batch', 1)
('GAN loss 0.6591 ', 'GAN acc 0.6250', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.4980', 'Total loss: 1.3626', 'for batch', 2)
('GAN loss 0.6462 ', 'GAN acc 0.6641', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4883', 'Total loss: 1.3435', 'for batch', 3)
('GAN loss 0.6237 ', 'GAN acc 0.7344', 'Discriminator loss 0.7130', 'Discriminator accuracy 0.4863', 'Total loss: 1.3367', 'for batch', 4)
('GAN loss 0.6236 ', 'GAN acc 0.7148', 'Discriminator loss 0.7080', 'Discriminator accuracy 0.5098', 'Total loss: 1.3317', 'for batch', 5)
('GAN loss 0.6497 ', 'GAN acc 0.6758', 'Discriminator loss 0.7061', 'Discriminator accuracy 0.4980', 'Total loss: 1.3558', 'for batch', 6)
('GAN loss 0.6772 ', 'GAN acc 0.6094', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.4941', 'Total loss: 1.3823', 'for batch', 7)
('GAN loss 0.6722 ', 'GAN acc 0.6133', 'Discriminator loss 0.7081', 'Discriminator accuracy 0.5234', 'Total loss: 1.3803', 'for batch', 8)
('GAN loss 0.6791 ', 'GAN acc 0.5586', 'Discriminator loss 0.7109', 'Discriminator accuracy 0.4980', 'Total loss: 1.3900', 'for batch', 9)
('GAN loss 0.6910 ', 'GAN acc 0.4961', 'Discriminator loss 0.7068', 'Discriminator accuracy 0.5059', 'Total loss: 1.3978', 'for batch', 10)
('GAN loss 0.6757 ', 'GAN acc 0.5625', 'Discriminator loss 0.7026', 'Discriminator accuracy 0.5039', 'Total loss: 1.3784', 'for batch', 11)
('GAN loss 0.6633 ', 'GAN acc 0.6328', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5156', 'Total loss: 1.3580', 'for batch', 12)
('GAN loss 0.6801 ', 'GAN acc 0.5820', 'Discriminator loss 0.7131', 'Discriminator accuracy 0.4551', 'Total loss: 1.3932', 'for batch', 13)
('GAN loss 0.6618 ', 'GAN acc 0.6289', 'Discriminator loss 0.7123', 'Discriminator accuracy 0.4707', 'Total loss: 1.3741', 'for batch', 14)
('GAN loss 0.6660 ', 'GAN acc 0.6016', 'Discriminator loss 0.7097', 'Discriminator accuracy 0.4805', 'Total loss: 1.3757', 'for batch', 15)
('GAN loss 0.6720 ', 'GAN acc 0.6211', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.5020', 'Total loss: 1.3756', 'for batch', 16)
('GAN loss 0.6756 ', 'GAN acc 0.6016', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.5098', 'Total loss: 1.3785', 'for batch', 17)
('GAN loss 0.6654 ', 'GAN acc 0.5977', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.5156', 'Total loss: 1.3659', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.69800156)
('DISCRIMINATOR_Imagem FAKE=', 0.69007081)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.718246')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6773 ', 'GAN acc 0.5664', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.5312', 'Total loss: 1.3788', 'for batch', 0)
('GAN loss 0.6872 ', 'GAN acc 0.5469', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4570', 'Total loss: 1.3888', 'for batch', 1)
('GAN loss 0.6724 ', 'GAN acc 0.5898', 'Discriminator loss 0.7061', 'Discriminator accuracy 0.4766', 'Total loss: 1.3785', 'for batch', 2)
('GAN loss 0.6698 ', 'GAN acc 0.6016', 'Discriminator loss 0.7116', 'Discriminator accuracy 0.4492', 'Total loss: 1.3815', 'for batch', 3)
('GAN loss 0.6533 ', 'GAN acc 0.6758', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5000', 'Total loss: 1.3547', 'for batch', 4)
('GAN loss 0.6719 ', 'GAN acc 0.6016', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.4863', 'Total loss: 1.3778', 'for batch', 5)
('GAN loss 0.6660 ', 'GAN acc 0.6172', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4961', 'Total loss: 1.3634', 'for batch', 6)
('GAN loss 0.6704 ', 'GAN acc 0.6055', 'Discriminator loss 0.7049', 'Discriminator accuracy 0.4688', 'Total loss: 1.3753', 'for batch', 7)
('GAN loss 0.6759 ', 'GAN acc 0.5859', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5293', 'Total loss: 1.3687', 'for batch', 8)
('GAN loss 0.6775 ', 'GAN acc 0.6172', 'Discriminator loss 0.7123', 'Discriminator accuracy 0.4492', 'Total loss: 1.3898', 'for batch', 9)
('GAN loss 0.6905 ', 'GAN acc 0.5469', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4746', 'Total loss: 1.3934', 'for batch', 10)
('GAN loss 0.6881 ', 'GAN acc 0.5352', 'Discriminator loss 0.7122', 'Discriminator accuracy 0.4395', 'Total loss: 1.4004', 'for batch', 11)
('GAN loss 0.6875 ', 'GAN acc 0.5625', 'Discriminator loss 0.7081', 'Discriminator accuracy 0.4785', 'Total loss: 1.3956', 'for batch', 12)
('GAN loss 0.6672 ', 'GAN acc 0.6133', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4961', 'Total loss: 1.3632', 'for batch', 13)
('GAN loss 0.6688 ', 'GAN acc 0.6211', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4941', 'Total loss: 1.3661', 'for batch', 14)
('GAN loss 0.6787 ', 'GAN acc 0.5469', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.5000', 'Total loss: 1.3805', 'for batch', 15)
('GAN loss 0.6894 ', 'GAN acc 0.5352', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5078', 'Total loss: 1.3859', 'for batch', 16)
('GAN loss 0.6851 ', 'GAN acc 0.5664', 'Discriminator loss 0.7063', 'Discriminator accuracy 0.4688', 'Total loss: 1.3915', 'for batch', 17)
('GAN loss 0.6794 ', 'GAN acc 0.5742', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4980', 'Total loss: 1.3795', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.64248693)
('DISCRIMINATOR_Imagem FAKE=', 0.64190441)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.233625')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6896 ', 'GAN acc 0.5469', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4980', 'Total loss: 1.3844', 'for batch', 0)
('GAN loss 0.6784 ', 'GAN acc 0.5938', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5156', 'Total loss: 1.3767', 'for batch', 1)
('GAN loss 0.6875 ', 'GAN acc 0.5273', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4922', 'Total loss: 1.3844', 'for batch', 2)
('GAN loss 0.6782 ', 'GAN acc 0.6328', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4727', 'Total loss: 1.3815', 'for batch', 3)
('GAN loss 0.6774 ', 'GAN acc 0.5820', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4824', 'Total loss: 1.3777', 'for batch', 4)
('GAN loss 0.6855 ', 'GAN acc 0.5547', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.5254', 'Total loss: 1.3856', 'for batch', 5)
('GAN loss 0.6740 ', 'GAN acc 0.5742', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4805', 'Total loss: 1.3720', 'for batch', 6)
('GAN loss 0.6846 ', 'GAN acc 0.5469', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4863', 'Total loss: 1.3843', 'for batch', 7)
('GAN loss 0.6919 ', 'GAN acc 0.5391', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5059', 'Total loss: 1.3872', 'for batch', 8)
('GAN loss 0.7029 ', 'GAN acc 0.4688', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4746', 'Total loss: 1.4043', 'for batch', 9)
('GAN loss 0.6929 ', 'GAN acc 0.5430', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5000', 'Total loss: 1.3938', 'for batch', 10)
('GAN loss 0.6907 ', 'GAN acc 0.5039', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5215', 'Total loss: 1.3849', 'for batch', 11)
('GAN loss 0.6782 ', 'GAN acc 0.6133', 'Discriminator loss 0.7026', 'Discriminator accuracy 0.5176', 'Total loss: 1.3808', 'for batch', 12)
('GAN loss 0.6817 ', 'GAN acc 0.5547', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4766', 'Total loss: 1.3850', 'for batch', 13)
('GAN loss 0.6914 ', 'GAN acc 0.5469', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5332', 'Total loss: 1.3858', 'for batch', 14)
('GAN loss 0.7063 ', 'GAN acc 0.4922', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4727', 'Total loss: 1.4057', 'for batch', 15)
('GAN loss 0.7056 ', 'GAN acc 0.4883', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4727', 'Total loss: 1.4066', 'for batch', 16)
('GAN loss 0.7101 ', 'GAN acc 0.4570', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.4980', 'Total loss: 1.4143', 'for batch', 17)
('GAN loss 0.7010 ', 'GAN acc 0.4609', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5020', 'Total loss: 1.4024', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.60642844)
('DISCRIMINATOR_Imagem FAKE=', 0.6067732)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.749207')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5156', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4902', 'Total loss: 1.3986', 'for batch', 0)
('GAN loss 0.6972 ', 'GAN acc 0.5156', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4707', 'Total loss: 1.4003', 'for batch', 1)
('GAN loss 0.6926 ', 'GAN acc 0.5000', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4883', 'Total loss: 1.3931', 'for batch', 2)
('GAN loss 0.6770 ', 'GAN acc 0.5742', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5098', 'Total loss: 1.3709', 'for batch', 3)
('GAN loss 0.6787 ', 'GAN acc 0.5820', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4922', 'Total loss: 1.3710', 'for batch', 4)
('GAN loss 0.6744 ', 'GAN acc 0.5977', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.4785', 'Total loss: 1.3771', 'for batch', 5)
('GAN loss 0.6748 ', 'GAN acc 0.5625', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4941', 'Total loss: 1.3705', 'for batch', 6)
('GAN loss 0.6787 ', 'GAN acc 0.5664', 'Discriminator loss 0.6892', 'Discriminator accuracy 0.5234', 'Total loss: 1.3679', 'for batch', 7)
('GAN loss 0.6789 ', 'GAN acc 0.5898', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4766', 'Total loss: 1.3776', 'for batch', 8)
('GAN loss 0.6895 ', 'GAN acc 0.5234', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.5059', 'Total loss: 1.3872', 'for batch', 9)
('GAN loss 0.6941 ', 'GAN acc 0.5234', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4902', 'Total loss: 1.3923', 'for batch', 10)
('GAN loss 0.6970 ', 'GAN acc 0.5000', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4883', 'Total loss: 1.3971', 'for batch', 11)
('GAN loss 0.6999 ', 'GAN acc 0.4883', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4844', 'Total loss: 1.4003', 'for batch', 12)
('GAN loss 0.6888 ', 'GAN acc 0.5430', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5039', 'Total loss: 1.3859', 'for batch', 13)
('GAN loss 0.6889 ', 'GAN acc 0.5234', 'Discriminator loss 0.7076', 'Discriminator accuracy 0.4688', 'Total loss: 1.3965', 'for batch', 14)
('GAN loss 0.6860 ', 'GAN acc 0.5820', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4766', 'Total loss: 1.3820', 'for batch', 15)
('GAN loss 0.6982 ', 'GAN acc 0.5117', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5059', 'Total loss: 1.3955', 'for batch', 16)
('GAN loss 0.6868 ', 'GAN acc 0.5742', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.4766', 'Total loss: 1.3896', 'for batch', 17)
('GAN loss 0.6906 ', 'GAN acc 0.5352', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5293', 'Total loss: 1.3834', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58693576)
('DISCRIMINATOR_Imagem FAKE=', 0.5887267)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.272675')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6895 ', 'GAN acc 0.5195', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4941', 'Total loss: 1.3899', 'for batch', 0)
('GAN loss 0.6920 ', 'GAN acc 0.5195', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4883', 'Total loss: 1.3901', 'for batch', 1)
('GAN loss 0.7066 ', 'GAN acc 0.4453', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5371', 'Total loss: 1.3992', 'for batch', 2)
('GAN loss 0.6832 ', 'GAN acc 0.5625', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4824', 'Total loss: 1.3827', 'for batch', 3)
('GAN loss 0.6861 ', 'GAN acc 0.5742', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3800', 'for batch', 4)
('GAN loss 0.6969 ', 'GAN acc 0.5156', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4688', 'Total loss: 1.3983', 'for batch', 5)
('GAN loss 0.6859 ', 'GAN acc 0.5742', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5039', 'Total loss: 1.3806', 'for batch', 6)
('GAN loss 0.6924 ', 'GAN acc 0.5234', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3864', 'for batch', 7)
('GAN loss 0.6897 ', 'GAN acc 0.5273', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4961', 'Total loss: 1.3888', 'for batch', 8)
('GAN loss 0.7022 ', 'GAN acc 0.4648', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5098', 'Total loss: 1.3959', 'for batch', 9)
('GAN loss 0.6983 ', 'GAN acc 0.4805', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.5000', 'Total loss: 1.3959', 'for batch', 10)
('GAN loss 0.7005 ', 'GAN acc 0.4805', 'Discriminator loss 0.7052', 'Discriminator accuracy 0.4590', 'Total loss: 1.4057', 'for batch', 11)
('GAN loss 0.6847 ', 'GAN acc 0.5586', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4707', 'Total loss: 1.3885', 'for batch', 12)
('GAN loss 0.6820 ', 'GAN acc 0.5703', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.4668', 'Total loss: 1.3862', 'for batch', 13)
('GAN loss 0.6856 ', 'GAN acc 0.5703', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4805', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.6996 ', 'GAN acc 0.4648', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5098', 'Total loss: 1.3947', 'for batch', 15)
('GAN loss 0.6998 ', 'GAN acc 0.4961', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5117', 'Total loss: 1.3949', 'for batch', 16)
('GAN loss 0.6982 ', 'GAN acc 0.4961', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4805', 'Total loss: 1.3991', 'for batch', 17)
('GAN loss 0.6992 ', 'GAN acc 0.4844', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4922', 'Total loss: 1.3956', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56906176)
('DISCRIMINATOR_Imagem FAKE=', 0.57058567)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.770304')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6908 ', 'GAN acc 0.5039', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.5020', 'Total loss: 1.3918', 'for batch', 0)
('GAN loss 0.6889 ', 'GAN acc 0.5391', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4805', 'Total loss: 1.3920', 'for batch', 1)
('GAN loss 0.6848 ', 'GAN acc 0.5859', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4766', 'Total loss: 1.3844', 'for batch', 2)
('GAN loss 0.6825 ', 'GAN acc 0.6094', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.5039', 'Total loss: 1.3836', 'for batch', 3)
('GAN loss 0.6860 ', 'GAN acc 0.5586', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4727', 'Total loss: 1.3841', 'for batch', 4)
('GAN loss 0.6838 ', 'GAN acc 0.5547', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5137', 'Total loss: 1.3761', 'for batch', 5)
('GAN loss 0.6760 ', 'GAN acc 0.5977', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5117', 'Total loss: 1.3688', 'for batch', 6)
('GAN loss 0.6846 ', 'GAN acc 0.5508', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4941', 'Total loss: 1.3836', 'for batch', 7)
('GAN loss 0.6855 ', 'GAN acc 0.5234', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5273', 'Total loss: 1.3780', 'for batch', 8)
('GAN loss 0.6922 ', 'GAN acc 0.5391', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4453', 'Total loss: 1.3954', 'for batch', 9)
('GAN loss 0.6890 ', 'GAN acc 0.5156', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5078', 'Total loss: 1.3828', 'for batch', 10)
('GAN loss 0.6990 ', 'GAN acc 0.5078', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5254', 'Total loss: 1.3949', 'for batch', 11)
('GAN loss 0.6860 ', 'GAN acc 0.5547', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4941', 'Total loss: 1.3803', 'for batch', 12)
('GAN loss 0.7003 ', 'GAN acc 0.4648', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4961', 'Total loss: 1.3966', 'for batch', 13)
('GAN loss 0.6927 ', 'GAN acc 0.5508', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5273', 'Total loss: 1.3833', 'for batch', 14)
('GAN loss 0.7045 ', 'GAN acc 0.4570', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4844', 'Total loss: 1.4020', 'for batch', 15)
('GAN loss 0.7016 ', 'GAN acc 0.4375', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5234', 'Total loss: 1.3927', 'for batch', 16)
('GAN loss 0.7081 ', 'GAN acc 0.4180', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4766', 'Total loss: 1.4101', 'for batch', 17)
('GAN loss 0.7074 ', 'GAN acc 0.4453', 'Discriminator loss 0.7046', 'Discriminator accuracy 0.4395', 'Total loss: 1.4119', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55614156)
('DISCRIMINATOR_Imagem FAKE=', 0.5562042)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.316233')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6943 ', 'GAN acc 0.4688', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4766', 'Total loss: 1.3915', 'for batch', 0)
('GAN loss 0.6954 ', 'GAN acc 0.5156', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4785', 'Total loss: 1.3947', 'for batch', 1)
('GAN loss 0.7000 ', 'GAN acc 0.4453', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4766', 'Total loss: 1.3995', 'for batch', 2)
('GAN loss 0.6944 ', 'GAN acc 0.5469', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4824', 'Total loss: 1.3933', 'for batch', 3)
('GAN loss 0.6852 ', 'GAN acc 0.5859', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5254', 'Total loss: 1.3790', 'for batch', 4)
('GAN loss 0.6809 ', 'GAN acc 0.6055', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5195', 'Total loss: 1.3746', 'for batch', 5)
('GAN loss 0.6817 ', 'GAN acc 0.5781', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4805', 'Total loss: 1.3783', 'for batch', 6)
('GAN loss 0.6794 ', 'GAN acc 0.5742', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5078', 'Total loss: 1.3762', 'for batch', 7)
('GAN loss 0.6856 ', 'GAN acc 0.5898', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5117', 'Total loss: 1.3817', 'for batch', 8)
('GAN loss 0.6817 ', 'GAN acc 0.5820', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4824', 'Total loss: 1.3764', 'for batch', 9)
('GAN loss 0.6817 ', 'GAN acc 0.5820', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4727', 'Total loss: 1.3828', 'for batch', 10)
('GAN loss 0.6957 ', 'GAN acc 0.4883', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4766', 'Total loss: 1.3976', 'for batch', 11)
('GAN loss 0.7002 ', 'GAN acc 0.4805', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5176', 'Total loss: 1.3933', 'for batch', 12)
('GAN loss 0.7084 ', 'GAN acc 0.4453', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5098', 'Total loss: 1.4044', 'for batch', 13)
('GAN loss 0.7056 ', 'GAN acc 0.4375', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4707', 'Total loss: 1.4062', 'for batch', 14)
('GAN loss 0.7076 ', 'GAN acc 0.4492', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4941', 'Total loss: 1.4063', 'for batch', 15)
('GAN loss 0.7086 ', 'GAN acc 0.4414', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4688', 'Total loss: 1.4081', 'for batch', 16)
('GAN loss 0.7044 ', 'GAN acc 0.4375', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4961', 'Total loss: 1.4040', 'for batch', 17)
('GAN loss 0.6948 ', 'GAN acc 0.5039', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5332', 'Total loss: 1.3886', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54867005)
('DISCRIMINATOR_Imagem FAKE=', 0.5491091)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.749080')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6941 ', 'GAN acc 0.5078', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5078', 'Total loss: 1.3901', 'for batch', 0)
('GAN loss 0.6881 ', 'GAN acc 0.5469', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5117', 'Total loss: 1.3815', 'for batch', 1)
('GAN loss 0.6918 ', 'GAN acc 0.5469', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.4609', 'Total loss: 1.3943', 'for batch', 2)
('GAN loss 0.6855 ', 'GAN acc 0.5547', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4805', 'Total loss: 1.3828', 'for batch', 3)
('GAN loss 0.6845 ', 'GAN acc 0.5820', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4707', 'Total loss: 1.3832', 'for batch', 4)
('GAN loss 0.6800 ', 'GAN acc 0.6094', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4961', 'Total loss: 1.3749', 'for batch', 5)
('GAN loss 0.6809 ', 'GAN acc 0.5703', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5371', 'Total loss: 1.3728', 'for batch', 6)
('GAN loss 0.6835 ', 'GAN acc 0.6172', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4863', 'Total loss: 1.3800', 'for batch', 7)
('GAN loss 0.6873 ', 'GAN acc 0.5625', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4785', 'Total loss: 1.3843', 'for batch', 8)
('GAN loss 0.6842 ', 'GAN acc 0.5977', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4609', 'Total loss: 1.3841', 'for batch', 9)
('GAN loss 0.6963 ', 'GAN acc 0.4961', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3927', 'for batch', 10)
('GAN loss 0.6915 ', 'GAN acc 0.5352', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5117', 'Total loss: 1.3877', 'for batch', 11)
('GAN loss 0.6872 ', 'GAN acc 0.5547', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4961', 'Total loss: 1.3839', 'for batch', 12)
('GAN loss 0.6894 ', 'GAN acc 0.5195', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4629', 'Total loss: 1.3913', 'for batch', 13)
('GAN loss 0.6964 ', 'GAN acc 0.4766', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4707', 'Total loss: 1.3963', 'for batch', 14)
('GAN loss 0.6888 ', 'GAN acc 0.5625', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5098', 'Total loss: 1.3812', 'for batch', 15)
('GAN loss 0.6913 ', 'GAN acc 0.5078', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5059', 'Total loss: 1.3877', 'for batch', 16)
('GAN loss 0.7001 ', 'GAN acc 0.4453', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4785', 'Total loss: 1.3997', 'for batch', 17)
('GAN loss 0.6959 ', 'GAN acc 0.5156', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5117', 'Total loss: 1.3934', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54224044)
('DISCRIMINATOR_Imagem FAKE=', 0.54171389)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.780777')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6956 ', 'GAN acc 0.5078', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4980', 'Total loss: 1.3923', 'for batch', 0)
('GAN loss 0.7021 ', 'GAN acc 0.4375', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5098', 'Total loss: 1.3964', 'for batch', 1)
('GAN loss 0.6975 ', 'GAN acc 0.4648', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4941', 'Total loss: 1.3926', 'for batch', 2)
('GAN loss 0.6922 ', 'GAN acc 0.5391', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4883', 'Total loss: 1.3901', 'for batch', 3)
('GAN loss 0.6853 ', 'GAN acc 0.5586', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4355', 'Total loss: 1.3864', 'for batch', 4)
('GAN loss 0.6825 ', 'GAN acc 0.5898', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4902', 'Total loss: 1.3769', 'for batch', 5)
('GAN loss 0.6753 ', 'GAN acc 0.6406', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.4395', 'Total loss: 1.3797', 'for batch', 6)
('GAN loss 0.6781 ', 'GAN acc 0.5938', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5117', 'Total loss: 1.3717', 'for batch', 7)
('GAN loss 0.6818 ', 'GAN acc 0.5742', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5195', 'Total loss: 1.3751', 'for batch', 8)
('GAN loss 0.6840 ', 'GAN acc 0.5625', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5312', 'Total loss: 1.3778', 'for batch', 9)
('GAN loss 0.6845 ', 'GAN acc 0.5859', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4961', 'Total loss: 1.3773', 'for batch', 10)
('GAN loss 0.6947 ', 'GAN acc 0.5156', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4570', 'Total loss: 1.3936', 'for batch', 11)
('GAN loss 0.6896 ', 'GAN acc 0.5547', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3825', 'for batch', 12)
('GAN loss 0.6909 ', 'GAN acc 0.5625', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5020', 'Total loss: 1.3839', 'for batch', 13)
('GAN loss 0.6915 ', 'GAN acc 0.5352', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4688', 'Total loss: 1.3912', 'for batch', 14)
('GAN loss 0.7040 ', 'GAN acc 0.4336', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4902', 'Total loss: 1.3999', 'for batch', 15)
('GAN loss 0.7116 ', 'GAN acc 0.3984', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4766', 'Total loss: 1.4090', 'for batch', 16)
('GAN loss 0.7009 ', 'GAN acc 0.4688', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5020', 'Total loss: 1.3932', 'for batch', 17)
('GAN loss 0.7087 ', 'GAN acc 0.4023', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4707', 'Total loss: 1.4084', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53705579)
('DISCRIMINATOR_Imagem FAKE=', 0.53731561)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.338005')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7002 ', 'GAN acc 0.4766', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5234', 'Total loss: 1.3945', 'for batch', 0)
('GAN loss 0.6972 ', 'GAN acc 0.4961', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5117', 'Total loss: 1.3917', 'for batch', 1)
('GAN loss 0.6959 ', 'GAN acc 0.4883', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5098', 'Total loss: 1.3902', 'for batch', 2)
('GAN loss 0.6878 ', 'GAN acc 0.5742', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5000', 'Total loss: 1.3831', 'for batch', 3)
('GAN loss 0.6861 ', 'GAN acc 0.5781', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4453', 'Total loss: 1.3860', 'for batch', 4)
('GAN loss 0.6817 ', 'GAN acc 0.5859', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4785', 'Total loss: 1.3767', 'for batch', 5)
('GAN loss 0.6804 ', 'GAN acc 0.5820', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4688', 'Total loss: 1.3767', 'for batch', 6)
('GAN loss 0.6829 ', 'GAN acc 0.6094', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4941', 'Total loss: 1.3770', 'for batch', 7)
('GAN loss 0.6772 ', 'GAN acc 0.6406', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3713', 'for batch', 8)
('GAN loss 0.6765 ', 'GAN acc 0.6680', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5000', 'Total loss: 1.3733', 'for batch', 9)
('GAN loss 0.6884 ', 'GAN acc 0.5352', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5000', 'Total loss: 1.3829', 'for batch', 10)
('GAN loss 0.6934 ', 'GAN acc 0.4766', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4824', 'Total loss: 1.3926', 'for batch', 11)
('GAN loss 0.6901 ', 'GAN acc 0.5234', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5039', 'Total loss: 1.3835', 'for batch', 12)
('GAN loss 0.6977 ', 'GAN acc 0.4727', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4473', 'Total loss: 1.3992', 'for batch', 13)
('GAN loss 0.6949 ', 'GAN acc 0.5352', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5098', 'Total loss: 1.3918', 'for batch', 14)
('GAN loss 0.7154 ', 'GAN acc 0.3320', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4980', 'Total loss: 1.4118', 'for batch', 15)
('GAN loss 0.7026 ', 'GAN acc 0.4805', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5020', 'Total loss: 1.3970', 'for batch', 16)
('GAN loss 0.7037 ', 'GAN acc 0.4219', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3977', 'for batch', 17)
('GAN loss 0.7054 ', 'GAN acc 0.4336', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4824', 'Total loss: 1.4018', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53414845)
('DISCRIMINATOR_Imagem FAKE=', 0.53396505)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.840919')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7016 ', 'GAN acc 0.4492', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4785', 'Total loss: 1.3993', 'for batch', 0)
('GAN loss 0.7017 ', 'GAN acc 0.4414', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4980', 'Total loss: 1.3978', 'for batch', 1)
('GAN loss 0.6936 ', 'GAN acc 0.5234', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4824', 'Total loss: 1.3893', 'for batch', 2)
('GAN loss 0.6973 ', 'GAN acc 0.4688', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5156', 'Total loss: 1.3890', 'for batch', 3)
('GAN loss 0.6873 ', 'GAN acc 0.5664', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4902', 'Total loss: 1.3830', 'for batch', 4)
('GAN loss 0.6790 ', 'GAN acc 0.6367', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4727', 'Total loss: 1.3745', 'for batch', 5)
('GAN loss 0.6753 ', 'GAN acc 0.6562', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3693', 'for batch', 6)
('GAN loss 0.6751 ', 'GAN acc 0.6484', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5059', 'Total loss: 1.3689', 'for batch', 7)
('GAN loss 0.6727 ', 'GAN acc 0.6641', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4922', 'Total loss: 1.3675', 'for batch', 8)
('GAN loss 0.6763 ', 'GAN acc 0.6328', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5176', 'Total loss: 1.3724', 'for batch', 9)
('GAN loss 0.6827 ', 'GAN acc 0.5703', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4629', 'Total loss: 1.3814', 'for batch', 10)
('GAN loss 0.6853 ', 'GAN acc 0.5820', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5059', 'Total loss: 1.3769', 'for batch', 11)
('GAN loss 0.6896 ', 'GAN acc 0.5391', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4785', 'Total loss: 1.3866', 'for batch', 12)
('GAN loss 0.6888 ', 'GAN acc 0.5469', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5273', 'Total loss: 1.3819', 'for batch', 13)
('GAN loss 0.6902 ', 'GAN acc 0.5195', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5156', 'Total loss: 1.3826', 'for batch', 14)
('GAN loss 0.6975 ', 'GAN acc 0.4883', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4785', 'Total loss: 1.3941', 'for batch', 15)
('GAN loss 0.7019 ', 'GAN acc 0.4492', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5000', 'Total loss: 1.4000', 'for batch', 16)
('GAN loss 0.7086 ', 'GAN acc 0.4062', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4844', 'Total loss: 1.4063', 'for batch', 17)
('GAN loss 0.7087 ', 'GAN acc 0.3750', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4863', 'Total loss: 1.4043', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52743191)
('DISCRIMINATOR_Imagem FAKE=', 0.52778774)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.240431')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7042 ', 'GAN acc 0.3984', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5215', 'Total loss: 1.3937', 'for batch', 0)
('GAN loss 0.7037 ', 'GAN acc 0.4531', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4941', 'Total loss: 1.3976', 'for batch', 1)
('GAN loss 0.7010 ', 'GAN acc 0.4727', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5195', 'Total loss: 1.3983', 'for batch', 2)
('GAN loss 0.6952 ', 'GAN acc 0.5117', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5176', 'Total loss: 1.3882', 'for batch', 3)
('GAN loss 0.6894 ', 'GAN acc 0.5547', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3847', 'for batch', 4)
('GAN loss 0.6850 ', 'GAN acc 0.5781', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5234', 'Total loss: 1.3783', 'for batch', 5)
('GAN loss 0.6841 ', 'GAN acc 0.5820', 'Discriminator loss 0.6898', 'Discriminator accuracy 0.5352', 'Total loss: 1.3739', 'for batch', 6)
('GAN loss 0.6798 ', 'GAN acc 0.6133', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5059', 'Total loss: 1.3756', 'for batch', 7)
('GAN loss 0.6791 ', 'GAN acc 0.5898', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3749', 'for batch', 8)
('GAN loss 0.6735 ', 'GAN acc 0.6797', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4805', 'Total loss: 1.3724', 'for batch', 9)
('GAN loss 0.6749 ', 'GAN acc 0.6719', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5234', 'Total loss: 1.3656', 'for batch', 10)
('GAN loss 0.6859 ', 'GAN acc 0.6133', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4961', 'Total loss: 1.3813', 'for batch', 11)
('GAN loss 0.6867 ', 'GAN acc 0.5859', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4746', 'Total loss: 1.3846', 'for batch', 12)
('GAN loss 0.6864 ', 'GAN acc 0.5625', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4727', 'Total loss: 1.3840', 'for batch', 13)
('GAN loss 0.6975 ', 'GAN acc 0.4922', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4785', 'Total loss: 1.3915', 'for batch', 14)
('GAN loss 0.6954 ', 'GAN acc 0.4961', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5273', 'Total loss: 1.3879', 'for batch', 15)
('GAN loss 0.7060 ', 'GAN acc 0.4062', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5312', 'Total loss: 1.4013', 'for batch', 16)
('GAN loss 0.7027 ', 'GAN acc 0.4258', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4980', 'Total loss: 1.3960', 'for batch', 17)
('GAN loss 0.7070 ', 'GAN acc 0.4414', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5117', 'Total loss: 1.4013', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52368492)
('DISCRIMINATOR_Imagem FAKE=', 0.52468443)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.735930')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7018 ', 'GAN acc 0.4219', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5117', 'Total loss: 1.3955', 'for batch', 0)
('GAN loss 0.7091 ', 'GAN acc 0.3750', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5215', 'Total loss: 1.4038', 'for batch', 1)
('GAN loss 0.7091 ', 'GAN acc 0.4023', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5137', 'Total loss: 1.4028', 'for batch', 2)
('GAN loss 0.6968 ', 'GAN acc 0.4922', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3915', 'for batch', 3)
('GAN loss 0.6948 ', 'GAN acc 0.4844', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4902', 'Total loss: 1.3904', 'for batch', 4)
('GAN loss 0.6915 ', 'GAN acc 0.5000', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4277', 'Total loss: 1.3920', 'for batch', 5)
('GAN loss 0.6848 ', 'GAN acc 0.5820', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4922', 'Total loss: 1.3777', 'for batch', 6)
('GAN loss 0.6792 ', 'GAN acc 0.6250', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4922', 'Total loss: 1.3763', 'for batch', 7)
('GAN loss 0.6805 ', 'GAN acc 0.6484', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5273', 'Total loss: 1.3718', 'for batch', 8)
('GAN loss 0.6793 ', 'GAN acc 0.6523', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4863', 'Total loss: 1.3763', 'for batch', 9)
('GAN loss 0.6722 ', 'GAN acc 0.7109', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3672', 'for batch', 10)
('GAN loss 0.6886 ', 'GAN acc 0.5703', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4590', 'Total loss: 1.3864', 'for batch', 11)
('GAN loss 0.6838 ', 'GAN acc 0.5508', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5078', 'Total loss: 1.3780', 'for batch', 12)
('GAN loss 0.6881 ', 'GAN acc 0.5703', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5020', 'Total loss: 1.3821', 'for batch', 13)
('GAN loss 0.6911 ', 'GAN acc 0.5625', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5078', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.7026 ', 'GAN acc 0.4336', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4707', 'Total loss: 1.3994', 'for batch', 15)
('GAN loss 0.6966 ', 'GAN acc 0.5000', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4922', 'Total loss: 1.3940', 'for batch', 16)
('GAN loss 0.7049 ', 'GAN acc 0.3867', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5234', 'Total loss: 1.3966', 'for batch', 17)
('GAN loss 0.7012 ', 'GAN acc 0.4609', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4922', 'Total loss: 1.3953', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52182198)
('DISCRIMINATOR_Imagem FAKE=', 0.52215993)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.349006')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7066 ', 'GAN acc 0.4102', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5234', 'Total loss: 1.4025', 'for batch', 0)
('GAN loss 0.7066 ', 'GAN acc 0.3867', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5117', 'Total loss: 1.3994', 'for batch', 1)
('GAN loss 0.7099 ', 'GAN acc 0.3828', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5195', 'Total loss: 1.4025', 'for batch', 2)
('GAN loss 0.6968 ', 'GAN acc 0.4727', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5254', 'Total loss: 1.3887', 'for batch', 3)
('GAN loss 0.6937 ', 'GAN acc 0.5039', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4609', 'Total loss: 1.3904', 'for batch', 4)
('GAN loss 0.6908 ', 'GAN acc 0.5508', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5176', 'Total loss: 1.3811', 'for batch', 5)
('GAN loss 0.6830 ', 'GAN acc 0.6094', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5117', 'Total loss: 1.3750', 'for batch', 6)
('GAN loss 0.6811 ', 'GAN acc 0.6016', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5215', 'Total loss: 1.3732', 'for batch', 7)
('GAN loss 0.6822 ', 'GAN acc 0.6328', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5273', 'Total loss: 1.3737', 'for batch', 8)
('GAN loss 0.6790 ', 'GAN acc 0.6367', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5117', 'Total loss: 1.3722', 'for batch', 9)
('GAN loss 0.6819 ', 'GAN acc 0.5898', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4980', 'Total loss: 1.3763', 'for batch', 10)
('GAN loss 0.6838 ', 'GAN acc 0.6055', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4941', 'Total loss: 1.3788', 'for batch', 11)
('GAN loss 0.6841 ', 'GAN acc 0.5703', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5059', 'Total loss: 1.3777', 'for batch', 12)
('GAN loss 0.6902 ', 'GAN acc 0.5312', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4863', 'Total loss: 1.3857', 'for batch', 13)
('GAN loss 0.6930 ', 'GAN acc 0.5000', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5039', 'Total loss: 1.3879', 'for batch', 14)
('GAN loss 0.7050 ', 'GAN acc 0.4141', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5000', 'Total loss: 1.3982', 'for batch', 15)
('GAN loss 0.7072 ', 'GAN acc 0.3945', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4980', 'Total loss: 1.4000', 'for batch', 16)
('GAN loss 0.6990 ', 'GAN acc 0.4766', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5234', 'Total loss: 1.3900', 'for batch', 17)
('GAN loss 0.7018 ', 'GAN acc 0.4492', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4883', 'Total loss: 1.3949', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52013117)
('DISCRIMINATOR_Imagem FAKE=', 0.52079916)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.685371')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6991 ', 'GAN acc 0.4688', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3920', 'for batch', 0)
('GAN loss 0.7020 ', 'GAN acc 0.4375', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5078', 'Total loss: 1.3956', 'for batch', 1)
('GAN loss 0.6952 ', 'GAN acc 0.4961', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4746', 'Total loss: 1.3930', 'for batch', 2)
('GAN loss 0.6939 ', 'GAN acc 0.5195', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5156', 'Total loss: 1.3854', 'for batch', 3)
('GAN loss 0.6873 ', 'GAN acc 0.5586', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4844', 'Total loss: 1.3840', 'for batch', 4)
('GAN loss 0.6843 ', 'GAN acc 0.5859', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5098', 'Total loss: 1.3762', 'for batch', 5)
('GAN loss 0.6837 ', 'GAN acc 0.6094', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4824', 'Total loss: 1.3779', 'for batch', 6)
('GAN loss 0.6815 ', 'GAN acc 0.6133', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4590', 'Total loss: 1.3794', 'for batch', 7)
('GAN loss 0.6785 ', 'GAN acc 0.6406', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5176', 'Total loss: 1.3710', 'for batch', 8)
('GAN loss 0.6838 ', 'GAN acc 0.5898', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5195', 'Total loss: 1.3772', 'for batch', 9)
('GAN loss 0.6894 ', 'GAN acc 0.5742', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4941', 'Total loss: 1.3835', 'for batch', 10)
('GAN loss 0.6869 ', 'GAN acc 0.5469', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4922', 'Total loss: 1.3851', 'for batch', 11)
('GAN loss 0.6871 ', 'GAN acc 0.5547', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5098', 'Total loss: 1.3811', 'for batch', 12)
('GAN loss 0.6940 ', 'GAN acc 0.4922', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5254', 'Total loss: 1.3872', 'for batch', 13)
('GAN loss 0.6960 ', 'GAN acc 0.4883', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5254', 'Total loss: 1.3864', 'for batch', 14)
('GAN loss 0.6946 ', 'GAN acc 0.4805', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4707', 'Total loss: 1.3902', 'for batch', 15)
('GAN loss 0.7035 ', 'GAN acc 0.4219', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4805', 'Total loss: 1.3993', 'for batch', 16)
('GAN loss 0.7043 ', 'GAN acc 0.3867', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4688', 'Total loss: 1.4021', 'for batch', 17)
('GAN loss 0.7055 ', 'GAN acc 0.3789', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4883', 'Total loss: 1.3982', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5190258)
('DISCRIMINATOR_Imagem FAKE=', 0.5197615)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.215469')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7005 ', 'GAN acc 0.4531', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5000', 'Total loss: 1.3970', 'for batch', 0)
('GAN loss 0.7078 ', 'GAN acc 0.3750', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4727', 'Total loss: 1.4072', 'for batch', 1)
('GAN loss 0.7071 ', 'GAN acc 0.3984', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5195', 'Total loss: 1.4021', 'for batch', 2)
('GAN loss 0.6981 ', 'GAN acc 0.4648', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5039', 'Total loss: 1.3902', 'for batch', 3)
('GAN loss 0.6970 ', 'GAN acc 0.4922', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5273', 'Total loss: 1.3905', 'for batch', 4)
('GAN loss 0.6929 ', 'GAN acc 0.4883', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4707', 'Total loss: 1.3898', 'for batch', 5)
('GAN loss 0.6868 ', 'GAN acc 0.5977', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4980', 'Total loss: 1.3819', 'for batch', 6)
('GAN loss 0.6854 ', 'GAN acc 0.5977', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4727', 'Total loss: 1.3785', 'for batch', 7)
('GAN loss 0.6823 ', 'GAN acc 0.6484', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4844', 'Total loss: 1.3753', 'for batch', 8)
('GAN loss 0.6790 ', 'GAN acc 0.6406', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4941', 'Total loss: 1.3746', 'for batch', 9)
('GAN loss 0.6839 ', 'GAN acc 0.5977', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5000', 'Total loss: 1.3767', 'for batch', 10)
('GAN loss 0.6892 ', 'GAN acc 0.5664', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5137', 'Total loss: 1.3821', 'for batch', 11)
('GAN loss 0.6867 ', 'GAN acc 0.5938', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4824', 'Total loss: 1.3821', 'for batch', 12)
('GAN loss 0.6906 ', 'GAN acc 0.5703', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5137', 'Total loss: 1.3847', 'for batch', 13)
('GAN loss 0.6892 ', 'GAN acc 0.5508', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5273', 'Total loss: 1.3829', 'for batch', 14)
('GAN loss 0.6858 ', 'GAN acc 0.5703', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4688', 'Total loss: 1.3823', 'for batch', 15)
('GAN loss 0.6895 ', 'GAN acc 0.5430', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5156', 'Total loss: 1.3812', 'for batch', 16)
('GAN loss 0.6975 ', 'GAN acc 0.4531', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5000', 'Total loss: 1.3936', 'for batch', 17)
('GAN loss 0.6978 ', 'GAN acc 0.4453', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4727', 'Total loss: 1.3951', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51602942)
('DISCRIMINATOR_Imagem FAKE=', 0.51723218)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.779167')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7011 ', 'GAN acc 0.4492', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5020', 'Total loss: 1.3942', 'for batch', 0)
('GAN loss 0.7000 ', 'GAN acc 0.4570', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4844', 'Total loss: 1.3948', 'for batch', 1)
('GAN loss 0.6968 ', 'GAN acc 0.4609', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5215', 'Total loss: 1.3909', 'for batch', 2)
('GAN loss 0.6942 ', 'GAN acc 0.5273', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4922', 'Total loss: 1.3878', 'for batch', 3)
('GAN loss 0.6957 ', 'GAN acc 0.4570', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4785', 'Total loss: 1.3918', 'for batch', 4)
('GAN loss 0.6937 ', 'GAN acc 0.4844', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4570', 'Total loss: 1.3917', 'for batch', 5)
('GAN loss 0.6940 ', 'GAN acc 0.5078', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4727', 'Total loss: 1.3898', 'for batch', 6)
('GAN loss 0.6937 ', 'GAN acc 0.5273', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5078', 'Total loss: 1.3886', 'for batch', 7)
('GAN loss 0.6871 ', 'GAN acc 0.5547', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4883', 'Total loss: 1.3814', 'for batch', 8)
('GAN loss 0.6882 ', 'GAN acc 0.5664', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.4941', 'Total loss: 1.3798', 'for batch', 9)
('GAN loss 0.6887 ', 'GAN acc 0.5508', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4883', 'Total loss: 1.3843', 'for batch', 10)
('GAN loss 0.6872 ', 'GAN acc 0.5586', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4570', 'Total loss: 1.3822', 'for batch', 11)
('GAN loss 0.6855 ', 'GAN acc 0.5977', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4941', 'Total loss: 1.3809', 'for batch', 12)
('GAN loss 0.6955 ', 'GAN acc 0.4688', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5000', 'Total loss: 1.3883', 'for batch', 13)
('GAN loss 0.6934 ', 'GAN acc 0.5039', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4570', 'Total loss: 1.3896', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.5078', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5020', 'Total loss: 1.3862', 'for batch', 15)
('GAN loss 0.6958 ', 'GAN acc 0.5000', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4863', 'Total loss: 1.3913', 'for batch', 16)
('GAN loss 0.6968 ', 'GAN acc 0.4570', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4844', 'Total loss: 1.3903', 'for batch', 17)
('GAN loss 0.7034 ', 'GAN acc 0.4180', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5020', 'Total loss: 1.4000', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5146842)
('DISCRIMINATOR_Imagem FAKE=', 0.51536757)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.279700')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6991 ', 'GAN acc 0.4844', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4805', 'Total loss: 1.3971', 'for batch', 0)
('GAN loss 0.7017 ', 'GAN acc 0.3867', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5020', 'Total loss: 1.3947', 'for batch', 1)
('GAN loss 0.6985 ', 'GAN acc 0.4727', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5352', 'Total loss: 1.3894', 'for batch', 2)
('GAN loss 0.6942 ', 'GAN acc 0.4609', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4902', 'Total loss: 1.3883', 'for batch', 3)
('GAN loss 0.6907 ', 'GAN acc 0.5508', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5078', 'Total loss: 1.3834', 'for batch', 4)
('GAN loss 0.6909 ', 'GAN acc 0.5039', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4863', 'Total loss: 1.3875', 'for batch', 5)
('GAN loss 0.6884 ', 'GAN acc 0.5586', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4629', 'Total loss: 1.3864', 'for batch', 6)
('GAN loss 0.6816 ', 'GAN acc 0.6367', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4258', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6833 ', 'GAN acc 0.5898', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5039', 'Total loss: 1.3758', 'for batch', 8)
('GAN loss 0.6809 ', 'GAN acc 0.6484', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4805', 'Total loss: 1.3742', 'for batch', 9)
('GAN loss 0.6808 ', 'GAN acc 0.6211', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3762', 'for batch', 10)
('GAN loss 0.6826 ', 'GAN acc 0.5977', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5098', 'Total loss: 1.3752', 'for batch', 11)
('GAN loss 0.6883 ', 'GAN acc 0.5664', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5156', 'Total loss: 1.3815', 'for batch', 12)
('GAN loss 0.6897 ', 'GAN acc 0.5117', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5039', 'Total loss: 1.3833', 'for batch', 13)
('GAN loss 0.6967 ', 'GAN acc 0.4766', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5195', 'Total loss: 1.3881', 'for batch', 14)
('GAN loss 0.7041 ', 'GAN acc 0.3984', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5059', 'Total loss: 1.3977', 'for batch', 15)
('GAN loss 0.7033 ', 'GAN acc 0.4023', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4863', 'Total loss: 1.3977', 'for batch', 16)
('GAN loss 0.7065 ', 'GAN acc 0.3516', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4805', 'Total loss: 1.4018', 'for batch', 17)
('GAN loss 0.7055 ', 'GAN acc 0.4062', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4883', 'Total loss: 1.4004', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51106179)
('DISCRIMINATOR_Imagem FAKE=', 0.51181263)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.736867')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7023 ', 'GAN acc 0.4297', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4922', 'Total loss: 1.3978', 'for batch', 0)
('GAN loss 0.7035 ', 'GAN acc 0.4180', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4727', 'Total loss: 1.3979', 'for batch', 1)
('GAN loss 0.7041 ', 'GAN acc 0.3984', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4902', 'Total loss: 1.3983', 'for batch', 2)
('GAN loss 0.6999 ', 'GAN acc 0.4531', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5195', 'Total loss: 1.3929', 'for batch', 3)
('GAN loss 0.6984 ', 'GAN acc 0.4414', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5156', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6932 ', 'GAN acc 0.5156', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4863', 'Total loss: 1.3904', 'for batch', 5)
('GAN loss 0.6881 ', 'GAN acc 0.5781', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.3836', 'for batch', 6)
('GAN loss 0.6854 ', 'GAN acc 0.6055', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4824', 'Total loss: 1.3826', 'for batch', 7)
('GAN loss 0.6841 ', 'GAN acc 0.6211', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4961', 'Total loss: 1.3791', 'for batch', 8)
('GAN loss 0.6788 ', 'GAN acc 0.6836', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4883', 'Total loss: 1.3732', 'for batch', 9)
('GAN loss 0.6752 ', 'GAN acc 0.6680', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4922', 'Total loss: 1.3715', 'for batch', 10)
('GAN loss 0.6771 ', 'GAN acc 0.6953', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4668', 'Total loss: 1.3750', 'for batch', 11)
('GAN loss 0.6803 ', 'GAN acc 0.6367', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4883', 'Total loss: 1.3748', 'for batch', 12)
('GAN loss 0.6791 ', 'GAN acc 0.6562', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4883', 'Total loss: 1.3764', 'for batch', 13)
('GAN loss 0.6852 ', 'GAN acc 0.5938', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5254', 'Total loss: 1.3786', 'for batch', 14)
('GAN loss 0.6903 ', 'GAN acc 0.5195', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5176', 'Total loss: 1.3848', 'for batch', 15)
('GAN loss 0.6957 ', 'GAN acc 0.4609', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5039', 'Total loss: 1.3907', 'for batch', 16)
('GAN loss 0.6971 ', 'GAN acc 0.4648', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4922', 'Total loss: 1.3924', 'for batch', 17)
('GAN loss 0.6978 ', 'GAN acc 0.4688', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.4980', 'Total loss: 1.3901', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51278704)
('DISCRIMINATOR_Imagem FAKE=', 0.5128755)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.201767')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6955 ', 'GAN acc 0.4805', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4883', 'Total loss: 1.3899', 'for batch', 0)
('GAN loss 0.7018 ', 'GAN acc 0.4141', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4766', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.6948 ', 'GAN acc 0.4922', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4785', 'Total loss: 1.3921', 'for batch', 2)
('GAN loss 0.6966 ', 'GAN acc 0.4766', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5195', 'Total loss: 1.3895', 'for batch', 3)
('GAN loss 0.6966 ', 'GAN acc 0.5000', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5156', 'Total loss: 1.3897', 'for batch', 4)
('GAN loss 0.6915 ', 'GAN acc 0.5117', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5098', 'Total loss: 1.3857', 'for batch', 5)
('GAN loss 0.6896 ', 'GAN acc 0.5547', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4941', 'Total loss: 1.3870', 'for batch', 6)
('GAN loss 0.6877 ', 'GAN acc 0.5664', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4863', 'Total loss: 1.3850', 'for batch', 7)
('GAN loss 0.6862 ', 'GAN acc 0.5938', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4883', 'Total loss: 1.3811', 'for batch', 8)
('GAN loss 0.6863 ', 'GAN acc 0.5703', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5059', 'Total loss: 1.3791', 'for batch', 9)
('GAN loss 0.6853 ', 'GAN acc 0.5742', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3784', 'for batch', 10)
('GAN loss 0.6853 ', 'GAN acc 0.5977', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4785', 'Total loss: 1.3803', 'for batch', 11)
('GAN loss 0.6927 ', 'GAN acc 0.4883', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4785', 'Total loss: 1.3883', 'for batch', 12)
('GAN loss 0.6883 ', 'GAN acc 0.5547', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5371', 'Total loss: 1.3796', 'for batch', 13)
('GAN loss 0.6903 ', 'GAN acc 0.5117', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4922', 'Total loss: 1.3848', 'for batch', 14)
('GAN loss 0.6943 ', 'GAN acc 0.4883', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5137', 'Total loss: 1.3889', 'for batch', 15)
('GAN loss 0.6944 ', 'GAN acc 0.4648', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3893', 'for batch', 16)
('GAN loss 0.7005 ', 'GAN acc 0.4219', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4551', 'Total loss: 1.3965', 'for batch', 17)
('GAN loss 0.7006 ', 'GAN acc 0.4531', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5039', 'Total loss: 1.3949', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51079476)
('DISCRIMINATOR_Imagem FAKE=', 0.51103413)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.759327')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7003 ', 'GAN acc 0.4297', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4824', 'Total loss: 1.3961', 'for batch', 0)
('GAN loss 0.7055 ', 'GAN acc 0.3945', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5156', 'Total loss: 1.3990', 'for batch', 1)
('GAN loss 0.6987 ', 'GAN acc 0.3984', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5039', 'Total loss: 1.3927', 'for batch', 2)
('GAN loss 0.6986 ', 'GAN acc 0.4492', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5391', 'Total loss: 1.3920', 'for batch', 3)
('GAN loss 0.6933 ', 'GAN acc 0.5117', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4961', 'Total loss: 1.3886', 'for batch', 4)
('GAN loss 0.6946 ', 'GAN acc 0.4961', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4961', 'Total loss: 1.3876', 'for batch', 5)
('GAN loss 0.6880 ', 'GAN acc 0.5703', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5020', 'Total loss: 1.3808', 'for batch', 6)
('GAN loss 0.6840 ', 'GAN acc 0.6133', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5332', 'Total loss: 1.3759', 'for batch', 7)
('GAN loss 0.6864 ', 'GAN acc 0.5898', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5020', 'Total loss: 1.3809', 'for batch', 8)
('GAN loss 0.6875 ', 'GAN acc 0.5703', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5332', 'Total loss: 1.3796', 'for batch', 9)
('GAN loss 0.6827 ', 'GAN acc 0.6133', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5039', 'Total loss: 1.3767', 'for batch', 10)
('GAN loss 0.6829 ', 'GAN acc 0.6211', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5059', 'Total loss: 1.3756', 'for batch', 11)
('GAN loss 0.6857 ', 'GAN acc 0.5938', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5020', 'Total loss: 1.3798', 'for batch', 12)
('GAN loss 0.6862 ', 'GAN acc 0.6094', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4570', 'Total loss: 1.3807', 'for batch', 13)
('GAN loss 0.6889 ', 'GAN acc 0.5547', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3822', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.5430', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5176', 'Total loss: 1.3845', 'for batch', 15)
('GAN loss 0.6961 ', 'GAN acc 0.5117', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4844', 'Total loss: 1.3898', 'for batch', 16)
('GAN loss 0.7018 ', 'GAN acc 0.4023', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4863', 'Total loss: 1.3964', 'for batch', 17)
('GAN loss 0.7003 ', 'GAN acc 0.4531', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4883', 'Total loss: 1.3946', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5097996)
('DISCRIMINATOR_Imagem FAKE=', 0.51042122)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.271195')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6998 ', 'GAN acc 0.4258', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5605', 'Total loss: 1.3904', 'for batch', 0)
('GAN loss 0.7003 ', 'GAN acc 0.4297', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4805', 'Total loss: 1.3966', 'for batch', 1)
('GAN loss 0.6947 ', 'GAN acc 0.5039', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5469', 'Total loss: 1.3870', 'for batch', 2)
('GAN loss 0.6936 ', 'GAN acc 0.4570', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5059', 'Total loss: 1.3878', 'for batch', 3)
('GAN loss 0.6970 ', 'GAN acc 0.4297', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4883', 'Total loss: 1.3936', 'for batch', 4)
('GAN loss 0.6936 ', 'GAN acc 0.5195', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4707', 'Total loss: 1.3895', 'for batch', 5)
('GAN loss 0.6886 ', 'GAN acc 0.5742', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5020', 'Total loss: 1.3807', 'for batch', 6)
('GAN loss 0.6931 ', 'GAN acc 0.5078', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5176', 'Total loss: 1.3875', 'for batch', 7)
('GAN loss 0.6917 ', 'GAN acc 0.5391', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5137', 'Total loss: 1.3833', 'for batch', 8)
('GAN loss 0.6925 ', 'GAN acc 0.5078', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4961', 'Total loss: 1.3874', 'for batch', 9)
('GAN loss 0.6967 ', 'GAN acc 0.4648', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5137', 'Total loss: 1.3886', 'for batch', 10)
('GAN loss 0.6894 ', 'GAN acc 0.5312', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4785', 'Total loss: 1.3829', 'for batch', 11)
('GAN loss 0.6922 ', 'GAN acc 0.5195', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4902', 'Total loss: 1.3868', 'for batch', 12)
('GAN loss 0.6889 ', 'GAN acc 0.5586', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5195', 'Total loss: 1.3825', 'for batch', 13)
('GAN loss 0.6916 ', 'GAN acc 0.5352', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5020', 'Total loss: 1.3849', 'for batch', 14)
('GAN loss 0.6951 ', 'GAN acc 0.4648', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5059', 'Total loss: 1.3872', 'for batch', 15)
('GAN loss 0.6938 ', 'GAN acc 0.5000', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4844', 'Total loss: 1.3877', 'for batch', 16)
('GAN loss 0.6937 ', 'GAN acc 0.5352', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4863', 'Total loss: 1.3876', 'for batch', 17)
('GAN loss 0.6983 ', 'GAN acc 0.4648', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5117', 'Total loss: 1.3926', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51107001)
('DISCRIMINATOR_Imagem FAKE=', 0.51160413)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.729377')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5273', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4824', 'Total loss: 1.3885', 'for batch', 0)
('GAN loss 0.7003 ', 'GAN acc 0.4453', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3936', 'for batch', 1)
('GAN loss 0.7020 ', 'GAN acc 0.4102', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4492', 'Total loss: 1.3991', 'for batch', 2)
('GAN loss 0.6998 ', 'GAN acc 0.4180', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4766', 'Total loss: 1.3966', 'for batch', 3)
('GAN loss 0.6971 ', 'GAN acc 0.4297', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4805', 'Total loss: 1.3914', 'for batch', 4)
('GAN loss 0.6965 ', 'GAN acc 0.4570', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5215', 'Total loss: 1.3887', 'for batch', 5)
('GAN loss 0.6902 ', 'GAN acc 0.5469', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4883', 'Total loss: 1.3832', 'for batch', 6)
('GAN loss 0.6866 ', 'GAN acc 0.5742', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5215', 'Total loss: 1.3806', 'for batch', 7)
('GAN loss 0.6866 ', 'GAN acc 0.5664', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4980', 'Total loss: 1.3798', 'for batch', 8)
('GAN loss 0.6843 ', 'GAN acc 0.6094', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4922', 'Total loss: 1.3777', 'for batch', 9)
('GAN loss 0.6856 ', 'GAN acc 0.6016', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3794', 'for batch', 10)
('GAN loss 0.6869 ', 'GAN acc 0.6055', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4473', 'Total loss: 1.3817', 'for batch', 11)
('GAN loss 0.6939 ', 'GAN acc 0.5039', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4688', 'Total loss: 1.3900', 'for batch', 12)
('GAN loss 0.6976 ', 'GAN acc 0.4531', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4980', 'Total loss: 1.3923', 'for batch', 13)
('GAN loss 0.7018 ', 'GAN acc 0.4336', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4863', 'Total loss: 1.3974', 'for batch', 14)
('GAN loss 0.7080 ', 'GAN acc 0.3750', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5215', 'Total loss: 1.4002', 'for batch', 15)
('GAN loss 0.7086 ', 'GAN acc 0.3477', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4492', 'Total loss: 1.4052', 'for batch', 16)
('GAN loss 0.7108 ', 'GAN acc 0.2891', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4902', 'Total loss: 1.4067', 'for batch', 17)
('GAN loss 0.7056 ', 'GAN acc 0.3906', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5156', 'Total loss: 1.3978', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50914979)
('DISCRIMINATOR_Imagem FAKE=', 0.50875604)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.254550')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7036 ', 'GAN acc 0.3867', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5156', 'Total loss: 1.3975', 'for batch', 0)
('GAN loss 0.7055 ', 'GAN acc 0.3906', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4766', 'Total loss: 1.4021', 'for batch', 1)
('GAN loss 0.7000 ', 'GAN acc 0.4258', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4531', 'Total loss: 1.3976', 'for batch', 2)
('GAN loss 0.6974 ', 'GAN acc 0.4531', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4824', 'Total loss: 1.3942', 'for batch', 3)
('GAN loss 0.6917 ', 'GAN acc 0.5469', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4824', 'Total loss: 1.3863', 'for batch', 4)
('GAN loss 0.6907 ', 'GAN acc 0.5742', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3836', 'for batch', 5)
('GAN loss 0.6838 ', 'GAN acc 0.6328', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5215', 'Total loss: 1.3753', 'for batch', 6)
('GAN loss 0.6777 ', 'GAN acc 0.6953', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3715', 'for batch', 7)
('GAN loss 0.6832 ', 'GAN acc 0.6602', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4707', 'Total loss: 1.3786', 'for batch', 8)
('GAN loss 0.6841 ', 'GAN acc 0.6133', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4668', 'Total loss: 1.3781', 'for batch', 9)
('GAN loss 0.6833 ', 'GAN acc 0.6211', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5332', 'Total loss: 1.3749', 'for batch', 10)
('GAN loss 0.6867 ', 'GAN acc 0.5898', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4902', 'Total loss: 1.3823', 'for batch', 11)
('GAN loss 0.6813 ', 'GAN acc 0.6172', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4863', 'Total loss: 1.3750', 'for batch', 12)
('GAN loss 0.6891 ', 'GAN acc 0.5625', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5156', 'Total loss: 1.3814', 'for batch', 13)
('GAN loss 0.6890 ', 'GAN acc 0.5781', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.4980', 'Total loss: 1.3803', 'for batch', 14)
('GAN loss 0.6920 ', 'GAN acc 0.5234', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5371', 'Total loss: 1.3841', 'for batch', 15)
('GAN loss 0.6994 ', 'GAN acc 0.4531', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5059', 'Total loss: 1.3936', 'for batch', 16)
('GAN loss 0.7053 ', 'GAN acc 0.3672', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4941', 'Total loss: 1.4012', 'for batch', 17)
('GAN loss 0.7070 ', 'GAN acc 0.3555', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4746', 'Total loss: 1.4031', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50965655)
('DISCRIMINATOR_Imagem FAKE=', 0.50963932)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.828659')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7084 ', 'GAN acc 0.3164', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5215', 'Total loss: 1.3997', 'for batch', 0)
('GAN loss 0.7093 ', 'GAN acc 0.3242', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5078', 'Total loss: 1.4030', 'for batch', 1)
('GAN loss 0.7044 ', 'GAN acc 0.3594', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5195', 'Total loss: 1.3987', 'for batch', 2)
('GAN loss 0.7016 ', 'GAN acc 0.4141', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5020', 'Total loss: 1.3960', 'for batch', 3)
('GAN loss 0.7012 ', 'GAN acc 0.4062', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4863', 'Total loss: 1.3951', 'for batch', 4)
('GAN loss 0.6928 ', 'GAN acc 0.5039', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3881', 'for batch', 5)
('GAN loss 0.6890 ', 'GAN acc 0.5664', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4668', 'Total loss: 1.3856', 'for batch', 6)
('GAN loss 0.6865 ', 'GAN acc 0.5859', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5039', 'Total loss: 1.3793', 'for batch', 7)
('GAN loss 0.6818 ', 'GAN acc 0.6328', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4922', 'Total loss: 1.3751', 'for batch', 8)
('GAN loss 0.6759 ', 'GAN acc 0.7070', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5430', 'Total loss: 1.3676', 'for batch', 9)
('GAN loss 0.6763 ', 'GAN acc 0.7031', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5176', 'Total loss: 1.3690', 'for batch', 10)
('GAN loss 0.6770 ', 'GAN acc 0.6836', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4668', 'Total loss: 1.3737', 'for batch', 11)
('GAN loss 0.6806 ', 'GAN acc 0.6406', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5156', 'Total loss: 1.3726', 'for batch', 12)
('GAN loss 0.6836 ', 'GAN acc 0.6211', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5098', 'Total loss: 1.3764', 'for batch', 13)
('GAN loss 0.6844 ', 'GAN acc 0.6367', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5020', 'Total loss: 1.3788', 'for batch', 14)
('GAN loss 0.6882 ', 'GAN acc 0.5469', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4941', 'Total loss: 1.3829', 'for batch', 15)
('GAN loss 0.6904 ', 'GAN acc 0.5469', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4941', 'Total loss: 1.3864', 'for batch', 16)
('GAN loss 0.7005 ', 'GAN acc 0.4414', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4766', 'Total loss: 1.3967', 'for batch', 17)
('GAN loss 0.6981 ', 'GAN acc 0.4062', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4902', 'Total loss: 1.3907', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50959677)
('DISCRIMINATOR_Imagem FAKE=', 0.50979167)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.291011')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7044 ', 'GAN acc 0.4102', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4980', 'Total loss: 1.3985', 'for batch', 0)
('GAN loss 0.7031 ', 'GAN acc 0.4141', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4863', 'Total loss: 1.3963', 'for batch', 1)
('GAN loss 0.7002 ', 'GAN acc 0.4141', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4355', 'Total loss: 1.3972', 'for batch', 2)
('GAN loss 0.7003 ', 'GAN acc 0.4102', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4863', 'Total loss: 1.3944', 'for batch', 3)
('GAN loss 0.6981 ', 'GAN acc 0.4688', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4824', 'Total loss: 1.3923', 'for batch', 4)
('GAN loss 0.6967 ', 'GAN acc 0.4766', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4805', 'Total loss: 1.3914', 'for batch', 5)
('GAN loss 0.6899 ', 'GAN acc 0.5391', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4336', 'Total loss: 1.3875', 'for batch', 6)
('GAN loss 0.6874 ', 'GAN acc 0.5742', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5254', 'Total loss: 1.3791', 'for batch', 7)
('GAN loss 0.6902 ', 'GAN acc 0.5391', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5156', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6887 ', 'GAN acc 0.5664', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5176', 'Total loss: 1.3827', 'for batch', 9)
('GAN loss 0.6872 ', 'GAN acc 0.5625', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4922', 'Total loss: 1.3810', 'for batch', 10)
('GAN loss 0.6850 ', 'GAN acc 0.5859', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4980', 'Total loss: 1.3800', 'for batch', 11)
('GAN loss 0.6873 ', 'GAN acc 0.5938', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5059', 'Total loss: 1.3799', 'for batch', 12)
('GAN loss 0.6869 ', 'GAN acc 0.5898', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4941', 'Total loss: 1.3824', 'for batch', 13)
('GAN loss 0.6899 ', 'GAN acc 0.5508', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5371', 'Total loss: 1.3808', 'for batch', 14)
('GAN loss 0.6930 ', 'GAN acc 0.5117', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4844', 'Total loss: 1.3901', 'for batch', 15)
('GAN loss 0.6979 ', 'GAN acc 0.4180', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5098', 'Total loss: 1.3912', 'for batch', 16)
('GAN loss 0.7056 ', 'GAN acc 0.3828', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4512', 'Total loss: 1.4029', 'for batch', 17)
('GAN loss 0.7024 ', 'GAN acc 0.4141', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4941', 'Total loss: 1.3966', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50926423)
('DISCRIMINATOR_Imagem FAKE=', 0.50979453)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.740843')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7058 ', 'GAN acc 0.3438', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4980', 'Total loss: 1.3987', 'for batch', 0)
('GAN loss 0.7079 ', 'GAN acc 0.3125', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5098', 'Total loss: 1.4015', 'for batch', 1)
('GAN loss 0.7019 ', 'GAN acc 0.3984', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4961', 'Total loss: 1.3967', 'for batch', 2)
('GAN loss 0.7004 ', 'GAN acc 0.4570', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4824', 'Total loss: 1.3957', 'for batch', 3)
('GAN loss 0.6983 ', 'GAN acc 0.4258', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4688', 'Total loss: 1.3938', 'for batch', 4)
('GAN loss 0.6954 ', 'GAN acc 0.5039', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5176', 'Total loss: 1.3895', 'for batch', 5)
('GAN loss 0.6926 ', 'GAN acc 0.4922', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4609', 'Total loss: 1.3869', 'for batch', 6)
('GAN loss 0.6899 ', 'GAN acc 0.5469', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3833', 'for batch', 7)
('GAN loss 0.6852 ', 'GAN acc 0.6094', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5273', 'Total loss: 1.3778', 'for batch', 8)
('GAN loss 0.6851 ', 'GAN acc 0.6211', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5020', 'Total loss: 1.3788', 'for batch', 9)
('GAN loss 0.6843 ', 'GAN acc 0.6172', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5020', 'Total loss: 1.3782', 'for batch', 10)
('GAN loss 0.6834 ', 'GAN acc 0.6406', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4922', 'Total loss: 1.3765', 'for batch', 11)
('GAN loss 0.6829 ', 'GAN acc 0.6133', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4844', 'Total loss: 1.3773', 'for batch', 12)
('GAN loss 0.6832 ', 'GAN acc 0.6211', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5000', 'Total loss: 1.3752', 'for batch', 13)
('GAN loss 0.6826 ', 'GAN acc 0.6367', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4668', 'Total loss: 1.3773', 'for batch', 14)
('GAN loss 0.6903 ', 'GAN acc 0.5508', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4551', 'Total loss: 1.3864', 'for batch', 15)
('GAN loss 0.6924 ', 'GAN acc 0.5391', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4688', 'Total loss: 1.3880', 'for batch', 16)
('GAN loss 0.6921 ', 'GAN acc 0.5234', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4805', 'Total loss: 1.3888', 'for batch', 17)
('GAN loss 0.6993 ', 'GAN acc 0.4375', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3924', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51069731)
('DISCRIMINATOR_Imagem FAKE=', 0.51065052)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.217448')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7026 ', 'GAN acc 0.4023', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4902', 'Total loss: 1.3960', 'for batch', 0)
('GAN loss 0.7043 ', 'GAN acc 0.3320', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4863', 'Total loss: 1.3983', 'for batch', 1)
('GAN loss 0.7049 ', 'GAN acc 0.3867', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4980', 'Total loss: 1.3998', 'for batch', 2)
('GAN loss 0.7037 ', 'GAN acc 0.3711', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5410', 'Total loss: 1.3953', 'for batch', 3)
('GAN loss 0.7009 ', 'GAN acc 0.4141', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5117', 'Total loss: 1.3934', 'for batch', 4)
('GAN loss 0.6932 ', 'GAN acc 0.5273', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4961', 'Total loss: 1.3863', 'for batch', 5)
('GAN loss 0.6935 ', 'GAN acc 0.4922', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5469', 'Total loss: 1.3853', 'for batch', 6)
('GAN loss 0.6887 ', 'GAN acc 0.5469', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5332', 'Total loss: 1.3811', 'for batch', 7)
('GAN loss 0.6898 ', 'GAN acc 0.5703', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4941', 'Total loss: 1.3849', 'for batch', 8)
('GAN loss 0.6882 ', 'GAN acc 0.5820', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3821', 'for batch', 9)
('GAN loss 0.6890 ', 'GAN acc 0.5742', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4648', 'Total loss: 1.3838', 'for batch', 10)
('GAN loss 0.6911 ', 'GAN acc 0.5430', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4922', 'Total loss: 1.3852', 'for batch', 11)
('GAN loss 0.6853 ', 'GAN acc 0.5938', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4922', 'Total loss: 1.3781', 'for batch', 12)
('GAN loss 0.6884 ', 'GAN acc 0.6055', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4922', 'Total loss: 1.3822', 'for batch', 13)
('GAN loss 0.6865 ', 'GAN acc 0.6016', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4961', 'Total loss: 1.3807', 'for batch', 14)
('GAN loss 0.6893 ', 'GAN acc 0.5742', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4727', 'Total loss: 1.3846', 'for batch', 15)
('GAN loss 0.6945 ', 'GAN acc 0.5195', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5078', 'Total loss: 1.3893', 'for batch', 16)
('GAN loss 0.6987 ', 'GAN acc 0.4492', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4824', 'Total loss: 1.3933', 'for batch', 17)
('GAN loss 0.6993 ', 'GAN acc 0.4180', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5137', 'Total loss: 1.3913', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50937897)
('DISCRIMINATOR_Imagem FAKE=', 0.50918311)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.825665')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7030 ', 'GAN acc 0.3477', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5215', 'Total loss: 1.3962', 'for batch', 0)
('GAN loss 0.7014 ', 'GAN acc 0.4023', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5156', 'Total loss: 1.3924', 'for batch', 1)
('GAN loss 0.7002 ', 'GAN acc 0.4023', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5215', 'Total loss: 1.3932', 'for batch', 2)
('GAN loss 0.7005 ', 'GAN acc 0.3984', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4902', 'Total loss: 1.3942', 'for batch', 3)
('GAN loss 0.6993 ', 'GAN acc 0.4414', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4648', 'Total loss: 1.3945', 'for batch', 4)
('GAN loss 0.6939 ', 'GAN acc 0.4727', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5254', 'Total loss: 1.3856', 'for batch', 5)
('GAN loss 0.6940 ', 'GAN acc 0.5000', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4551', 'Total loss: 1.3902', 'for batch', 6)
('GAN loss 0.6880 ', 'GAN acc 0.5664', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5176', 'Total loss: 1.3815', 'for batch', 7)
('GAN loss 0.6878 ', 'GAN acc 0.5859', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5352', 'Total loss: 1.3790', 'for batch', 8)
('GAN loss 0.6885 ', 'GAN acc 0.5898', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.3827', 'for batch', 9)
('GAN loss 0.6879 ', 'GAN acc 0.5977', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5000', 'Total loss: 1.3823', 'for batch', 10)
('GAN loss 0.6888 ', 'GAN acc 0.5664', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4746', 'Total loss: 1.3834', 'for batch', 11)
('GAN loss 0.6898 ', 'GAN acc 0.5039', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5000', 'Total loss: 1.3831', 'for batch', 12)
('GAN loss 0.6913 ', 'GAN acc 0.4922', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4766', 'Total loss: 1.3870', 'for batch', 13)
('GAN loss 0.6897 ', 'GAN acc 0.5625', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5098', 'Total loss: 1.3825', 'for batch', 14)
('GAN loss 0.6945 ', 'GAN acc 0.4766', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5664', 'Total loss: 1.3844', 'for batch', 15)
('GAN loss 0.6937 ', 'GAN acc 0.4961', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5020', 'Total loss: 1.3880', 'for batch', 16)
('GAN loss 0.6949 ', 'GAN acc 0.4844', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4551', 'Total loss: 1.3897', 'for batch', 17)
('GAN loss 0.6930 ', 'GAN acc 0.4922', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5488', 'Total loss: 1.3846', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51065111)
('DISCRIMINATOR_Imagem FAKE=', 0.51000756)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.790204')
----------------------------------
('Epoch', 34, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6937 ', 'GAN acc 0.5273', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5391', 'Total loss: 1.3857', 'for batch', 0)
('GAN loss 0.6964 ', 'GAN acc 0.4609', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5098', 'Total loss: 1.3900', 'for batch', 1)
('GAN loss 0.6930 ', 'GAN acc 0.5078', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5215', 'Total loss: 1.3865', 'for batch', 2)
('GAN loss 0.6961 ', 'GAN acc 0.4766', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5117', 'Total loss: 1.3899', 'for batch', 3)
('GAN loss 0.6914 ', 'GAN acc 0.5391', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4824', 'Total loss: 1.3871', 'for batch', 4)
('GAN loss 0.6938 ', 'GAN acc 0.5312', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4512', 'Total loss: 1.3908', 'for batch', 5)
('GAN loss 0.6900 ', 'GAN acc 0.5586', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5215', 'Total loss: 1.3819', 'for batch', 6)
('GAN loss 0.6903 ', 'GAN acc 0.5664', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4805', 'Total loss: 1.3847', 'for batch', 7)
('GAN loss 0.6916 ', 'GAN acc 0.5430', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4824', 'Total loss: 1.3859', 'for batch', 8)
('GAN loss 0.6933 ', 'GAN acc 0.4883', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4844', 'Total loss: 1.3885', 'for batch', 9)
('GAN loss 0.6929 ', 'GAN acc 0.5234', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4980', 'Total loss: 1.3872', 'for batch', 10)
('GAN loss 0.7000 ', 'GAN acc 0.3789', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4883', 'Total loss: 1.3950', 'for batch', 11)
('GAN loss 0.6940 ', 'GAN acc 0.4844', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4746', 'Total loss: 1.3897', 'for batch', 12)
('GAN loss 0.6946 ', 'GAN acc 0.4648', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5039', 'Total loss: 1.3886', 'for batch', 13)
('GAN loss 0.6960 ', 'GAN acc 0.4492', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5391', 'Total loss: 1.3883', 'for batch', 14)
('GAN loss 0.6951 ', 'GAN acc 0.4961', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4785', 'Total loss: 1.3899', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.4805', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5234', 'Total loss: 1.3885', 'for batch', 16)
('GAN loss 0.6953 ', 'GAN acc 0.5039', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4941', 'Total loss: 1.3888', 'for batch', 17)
('GAN loss 0.6963 ', 'GAN acc 0.4727', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4844', 'Total loss: 1.3896', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51072645)
('DISCRIMINATOR_Imagem FAKE=', 0.510625)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.368080')
----------------------------------
('Epoch', 35, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6935 ', 'GAN acc 0.5078', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4746', 'Total loss: 1.3879', 'for batch', 0)
('GAN loss 0.6951 ', 'GAN acc 0.4609', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4844', 'Total loss: 1.3884', 'for batch', 1)
('GAN loss 0.6936 ', 'GAN acc 0.4883', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4609', 'Total loss: 1.3890', 'for batch', 2)
('GAN loss 0.6950 ', 'GAN acc 0.4648', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4863', 'Total loss: 1.3902', 'for batch', 3)
('GAN loss 0.6902 ', 'GAN acc 0.5508', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5000', 'Total loss: 1.3836', 'for batch', 4)
('GAN loss 0.6905 ', 'GAN acc 0.5508', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4805', 'Total loss: 1.3852', 'for batch', 5)
('GAN loss 0.6870 ', 'GAN acc 0.5703', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5078', 'Total loss: 1.3808', 'for batch', 6)
('GAN loss 0.6883 ', 'GAN acc 0.6055', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5000', 'Total loss: 1.3815', 'for batch', 7)
('GAN loss 0.6917 ', 'GAN acc 0.5742', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5156', 'Total loss: 1.3832', 'for batch', 8)
('GAN loss 0.6888 ', 'GAN acc 0.5898', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5078', 'Total loss: 1.3816', 'for batch', 9)
('GAN loss 0.6907 ', 'GAN acc 0.5352', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5020', 'Total loss: 1.3839', 'for batch', 10)
('GAN loss 0.6920 ', 'GAN acc 0.5234', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5156', 'Total loss: 1.3836', 'for batch', 11)
('GAN loss 0.6940 ', 'GAN acc 0.5078', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5215', 'Total loss: 1.3862', 'for batch', 12)
('GAN loss 0.6972 ', 'GAN acc 0.4727', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5039', 'Total loss: 1.3906', 'for batch', 13)
('GAN loss 0.6987 ', 'GAN acc 0.4180', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5176', 'Total loss: 1.3908', 'for batch', 14)
('GAN loss 0.7017 ', 'GAN acc 0.4102', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5020', 'Total loss: 1.3946', 'for batch', 15)
('GAN loss 0.7050 ', 'GAN acc 0.3789', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4785', 'Total loss: 1.3990', 'for batch', 16)
('GAN loss 0.7059 ', 'GAN acc 0.3828', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5000', 'Total loss: 1.4007', 'for batch', 17)
('GAN loss 0.7073 ', 'GAN acc 0.3516', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5039', 'Total loss: 1.3992', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50921333)
('DISCRIMINATOR_Imagem FAKE=', 0.51088887)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.714302')
----------------------------------
('Epoch', 36, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7118 ', 'GAN acc 0.2930', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5059', 'Total loss: 1.4053', 'for batch', 0)
('GAN loss 0.7082 ', 'GAN acc 0.3320', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4961', 'Total loss: 1.4024', 'for batch', 1)
('GAN loss 0.7096 ', 'GAN acc 0.2578', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.4045', 'for batch', 2)
('GAN loss 0.7036 ', 'GAN acc 0.3711', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4805', 'Total loss: 1.3998', 'for batch', 3)
('GAN loss 0.7042 ', 'GAN acc 0.3750', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4648', 'Total loss: 1.3997', 'for batch', 4)
('GAN loss 0.6996 ', 'GAN acc 0.4219', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4766', 'Total loss: 1.3954', 'for batch', 5)
('GAN loss 0.6958 ', 'GAN acc 0.4688', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5098', 'Total loss: 1.3878', 'for batch', 6)
('GAN loss 0.6919 ', 'GAN acc 0.5273', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4922', 'Total loss: 1.3848', 'for batch', 7)
('GAN loss 0.6898 ', 'GAN acc 0.5352', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3832', 'for batch', 8)
('GAN loss 0.6888 ', 'GAN acc 0.5820', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5137', 'Total loss: 1.3813', 'for batch', 9)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7490 ', 'GAN acc 0.5039', 'Discriminator loss 0.7460', 'Discriminator accuracy 0.4980', 'Total loss: 1.4950', 'for batch', 0)
('GAN loss 0.6940 ', 'GAN acc 0.5391', 'Discriminator loss 0.7709', 'Discriminator accuracy 0.5039', 'Total loss: 1.4649', 'for batch', 1)
('GAN loss 0.7790 ', 'GAN acc 0.5078', 'Discriminator loss 0.8003', 'Discriminator accuracy 0.4844', 'Total loss: 1.5793', 'for batch', 2)
('GAN loss 0.8841 ', 'GAN acc 0.3672', 'Discriminator loss 0.7551', 'Discriminator accuracy 0.5312', 'Total loss: 1.6392', 'for batch', 3)
('GAN loss 0.7837 ', 'GAN acc 0.4336', 'Discriminator loss 0.7673', 'Discriminator accuracy 0.4727', 'Total loss: 1.5510', 'for batch', 4)
('GAN loss 0.7440 ', 'GAN acc 0.4727', 'Discriminator loss 0.7724', 'Discriminator accuracy 0.4883', 'Total loss: 1.5165', 'for batch', 5)
('GAN loss 0.7551 ', 'GAN acc 0.4883', 'Discriminator loss 0.7050', 'Discriminator accuracy 0.5312', 'Total loss: 1.4601', 'for batch', 6)
('GAN loss 0.8433 ', 'GAN acc 0.3438', 'Discriminator loss 0.7143', 'Discriminator accuracy 0.5352', 'Total loss: 1.5575', 'for batch', 7)
('GAN loss 0.7798 ', 'GAN acc 0.4336', 'Discriminator loss 0.7273', 'Discriminator accuracy 0.5273', 'Total loss: 1.5071', 'for batch', 8)
('GAN loss 0.9043 ', 'GAN acc 0.3008', 'Discriminator loss 0.7169', 'Discriminator accuracy 0.5449', 'Total loss: 1.6212', 'for batch', 9)
('GAN loss 0.9875 ', 'GAN acc 0.2500', 'Discriminator loss 0.6576', 'Discriminator accuracy 0.5840', 'Total loss: 1.6451', 'for batch', 10)
('GAN loss 1.0160 ', 'GAN acc 0.2500', 'Discriminator loss 0.6637', 'Discriminator accuracy 0.6191', 'Total loss: 1.6797', 'for batch', 11)
('GAN loss 1.0159 ', 'GAN acc 0.2539', 'Discriminator loss 0.5900', 'Discriminator accuracy 0.7129', 'Total loss: 1.6058', 'for batch', 12)
('GAN loss 1.0291 ', 'GAN acc 0.2266', 'Discriminator loss 0.6008', 'Discriminator accuracy 0.7207', 'Total loss: 1.6299', 'for batch', 13)
('GAN loss 1.0640 ', 'GAN acc 0.2227', 'Discriminator loss 0.5958', 'Discriminator accuracy 0.7051', 'Total loss: 1.6598', 'for batch', 14)
('GAN loss 1.1008 ', 'GAN acc 0.1875', 'Discriminator loss 0.6145', 'Discriminator accuracy 0.6836', 'Total loss: 1.7153', 'for batch', 15)
('GAN loss 1.1311 ', 'GAN acc 0.1836', 'Discriminator loss 0.6095', 'Discriminator accuracy 0.6816', 'Total loss: 1.7406', 'for batch', 16)
('GAN loss 1.1903 ', 'GAN acc 0.1484', 'Discriminator loss 0.5848', 'Discriminator accuracy 0.6992', 'Total loss: 1.7751', 'for batch', 17)
('GAN loss 1.2181 ', 'GAN acc 0.1406', 'Discriminator loss 0.5654', 'Discriminator accuracy 0.7188', 'Total loss: 1.7835', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.79983324)
('DISCRIMINATOR_Imagem FAKE=', 0.6196909)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.37635803222656, 'rgb.min=', -226.60008239746094)
('rgb.max=', 136.2657470703125, 'rgb.min=', -226.74610900878906)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.72245788574219)
('rgb.max=', 136.45791625976562, 'rgb.min=', -226.69314575195312)
('rgb.max=', 136.34544372558594, 'rgb.min=', -226.75863647460938)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.18121337890625, 'rgb.min=', -226.70826721191406)
('rgb.max=', 136.36402893066406, 'rgb.min=', -226.80795288085938)
('rgb.max=', 136.33662414550781, 'rgb.min=', -226.76876831054688)
('rgb.max=', 136.14549255371094, 'rgb.min=', -226.64231872558594)
('rgb.max=', 136.1649169921875, 'rgb.min=', -226.74053955078125)
('rgb.max=', 136.326904296875, 'rgb.min=', -226.78773498535156)
('rgb.max=', 136.28106689453125, 'rgb.min=', -226.81242370605469)
('rgb.max=', 136.26625061035156, 'rgb.min=', -226.72944641113281)
('rgb.max=', 136.20553588867188, 'rgb.min=', -226.76571655273438)
('rgb.max=', 136.219970703125, 'rgb.min=', -226.75900268554688)
('rgb.max=', 136.3084716796875, 'rgb.min=', -226.74665832519531)
('rgb.max=', 136.11453247070312, 'rgb.min=', -226.60636901855469)
('rgb.max=', 136.36453247070312, 'rgb.min=', -226.71580505371094)
('rgb.max=', 136.39930725097656, 'rgb.min=', -226.75746154785156)
('rgb.max=', 136.42498779296875, 'rgb.min=', -226.78890991210938)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.68856811523438)
('rgb.max=', 136.45489501953125, 'rgb.min=', -226.45913696289062)
('rgb.max=', 136.36459350585938, 'rgb.min=', -226.175537109375)
('rgb.max=', 136.26168823242188, 'rgb.min=', -226.74519348144531)
('rgb.max=', 136.45445251464844, 'rgb.min=', -226.75912475585938)
('rgb.max=', 136.45187377929688, 'rgb.min=', -226.81369018554688)
('rgb.max=', 136.26220703125, 'rgb.min=', -226.65634155273438)
('rgb.max=', 136.22315979003906, 'rgb.min=', -226.5789794921875)
('rgb.max=', 136.26594543457031, 'rgb.min=', -226.79319763183594)
('rgb.max=', 136.33229064941406, 'rgb.min=', -226.75390625)
('rgb.max=', 136.19589233398438, 'rgb.min=', -226.77337646484375)
('rgb.max=', 136.2938232421875, 'rgb.min=', -226.77883911132812)
('rgb.max=', 136.30557250976562, 'rgb.min=', -226.75796508789062)
('rgb.max=', 136.25627136230469, 'rgb.min=', -226.77330017089844)
('rgb.max=', 136.36363220214844, 'rgb.min=', -226.75401306152344)
('rgb.max=', 136.43142700195312, 'rgb.min=', -226.72947692871094)
('rgb.max=', 136.42796325683594, 'rgb.min=', -226.8074951171875)
('rgb.max=', 136.17251586914062, 'rgb.min=', -226.71630859375)
('rgb.max=', 136.16677856445312, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.183837890625, 'rgb.min=', -226.65403747558594)
('rgb.max=', 136.41160583496094, 'rgb.min=', -226.5992431640625)
('rgb.max=', 136.23431396484375, 'rgb.min=', -226.76495361328125)
('rgb.max=', 136.23277282714844, 'rgb.min=', -226.66976928710938)
('rgb.max=', 136.34808349609375, 'rgb.min=', -226.81280517578125)
('rgb.max=', 136.01640319824219, 'rgb.min=', -226.72634887695312)
('rgb.max=', 136.38302612304688, 'rgb.min=', -226.72970581054688)
('rgb.max=', 136.16064453125, 'rgb.min=', -226.53398132324219)
('rgb.max=', 136.26699829101562, 'rgb.min=', -226.68789672851562)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.41729736328125, 'rgb.min=', -226.79824829101562)
('rgb.max=', 136.44194030761719, 'rgb.min=', -226.75244140625)
('rgb.max=', 136.16169738769531, 'rgb.min=', -226.78396606445312)
('rgb.max=', 136.1622314453125, 'rgb.min=', -226.65628051757812)
('rgb.max=', 136.38829040527344, 'rgb.min=', -226.77812194824219)
('rgb.max=', 136.42269897460938, 'rgb.min=', -226.81369018554688)
('rgb.max=', 136.38836669921875, 'rgb.min=', -226.76914978027344)
('rgb.max=', 136.24482727050781, 'rgb.min=', -226.6439208984375)
('rgb.max=', 136.13536071777344, 'rgb.min=', -226.46687316894531)
('rgb.max=', 136.0369873046875, 'rgb.min=', -226.76385498046875)
('rgb.max=', 136.39669799804688, 'rgb.min=', -226.74641418457031)
('rgb.max=', 136.07443237304688, 'rgb.min=', -226.57293701171875)
('rgb.max=', 136.19454956054688, 'rgb.min=', -226.75883483886719)
('rgb.max=', 136.24453735351562, 'rgb.min=', -226.77633666992188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.49769592285156)
('rgb.max=', 136.29019165039062, 'rgb.min=', -226.81376647949219)
('rgb.max=', 136.04255676269531, 'rgb.min=', -226.70451354980469)
('rgb.max=', 136.21206665039062, 'rgb.min=', -226.77423095703125)
('rgb.max=', 136.39582824707031, 'rgb.min=', -226.8101806640625)
('rgb.max=', 136.38038635253906, 'rgb.min=', -226.79638671875)
('rgb.max=', 136.43270874023438, 'rgb.min=', -226.81007385253906)
('rgb.max=', 136.15509033203125, 'rgb.min=', -226.79859924316406)
('rgb.max=', 136.31961059570312, 'rgb.min=', -226.68264770507812)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81108093261719)
('rgb.max=', 136.37336730957031, 'rgb.min=', -226.61383056640625)
('rgb.max=', 136.43960571289062, 'rgb.min=', -226.81246948242188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.79060363769531)
('rgb.max=', 136.27458190917969, 'rgb.min=', -226.49169921875)
('rgb.max=', 136.121337890625, 'rgb.min=', -226.72145080566406)
('rgb.max=', 136.4405517578125, 'rgb.min=', -226.65547180175781)
('rgb.max=', 136.34226989746094, 'rgb.min=', -226.4698486328125)
('rgb.max=', 136.31413269042969, 'rgb.min=', -226.661376953125)
('rgb.max=', 136.21821594238281, 'rgb.min=', -226.54414367675781)
('rgb.max=', 136.26918029785156, 'rgb.min=', -226.71807861328125)
('rgb.max=', 136.27284240722656, 'rgb.min=', -226.80833435058594)
('rgb.max=', 136.2237548828125, 'rgb.min=', -226.81246948242188)
('rgb.max=', 136.42825317382812, 'rgb.min=', -226.68576049804688)
('rgb.max=', 136.2216796875, 'rgb.min=', -226.727783203125)
('rgb.max=', 136.43984985351562, 'rgb.min=', -226.62551879882812)
('rgb.max=', 136.00375366210938, 'rgb.min=', -226.349853515625)
('rgb.max=', 136.15298461914062, 'rgb.min=', -226.75567626953125)
('rgb.max=', 136.20205688476562, 'rgb.min=', -226.76715087890625)
('rgb.max=', 136.25836181640625, 'rgb.min=', -226.74412536621094)
('rgb.max=', 136.25318908691406, 'rgb.min=', -226.71980285644531)
('rgb.max=', 136.25477600097656, 'rgb.min=', -226.48286437988281)
('rgb.max=', 136.30908203125, 'rgb.min=', -226.66433715820312)
('rgb.max=', 136.34062194824219, 'rgb.min=', -226.68930053710938)
('rgb.max=', 136.40498352050781, 'rgb.min=', -226.81013488769531)
('rgb.max=', 136.22882080078125, 'rgb.min=', -226.7879638671875)
('rgb.max=', 136.45513916015625, 'rgb.min=', -226.60479736328125)
('rgb.max=', 136.34992980957031, 'rgb.min=', -226.76351928710938)
('rgb.max=', 136.20889282226562, 'rgb.min=', -226.78196716308594)
('rgb.max=', 136.22738647460938, 'rgb.min=', -226.63069152832031)
('rgb.max=', 136.2950439453125, 'rgb.min=', -226.60926818847656)
('rgb.max=', 136.28326416015625, 'rgb.min=', -226.63020324707031)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74200439453125)
('rgb.max=', 136.357421875, 'rgb.min=', -226.74555969238281)
('rgb.max=', 136.41619873046875, 'rgb.min=', -226.69012451171875)
('rgb.max=', 136.437744140625, 'rgb.min=', -226.779052734375)
('rgb.max=', 136.24382019042969, 'rgb.min=', -226.718994140625)
('rgb.max=', 136.40118408203125, 'rgb.min=', -226.74546813964844)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74627685546875)
('rgb.max=', 136.25738525390625, 'rgb.min=', -226.60264587402344)
('rgb.max=', 136.32601928710938, 'rgb.min=', -226.639404296875)
('rgb.max=', 136.14302062988281, 'rgb.min=', -226.68557739257812)
('rgb.max=', 136.32235717773438, 'rgb.min=', -226.73316955566406)
('rgb.max=', 136.13363647460938, 'rgb.min=', -226.80854797363281)
('rgb.max=', 136.27006530761719, 'rgb.min=', -226.68290710449219)
('rgb.max=', 136.30427551269531, 'rgb.min=', -226.72731018066406)
('rgb.max=', 136.39236450195312, 'rgb.min=', -226.51689147949219)
('rgb.max=', 136.44491577148438, 'rgb.min=', -226.814208984375)
('rgb.max=', 136.4515380859375, 'rgb.min=', -226.77900695800781)
('rgb.max=', 136.1488037109375, 'rgb.min=', -226.64344787597656)
('rgb.max=', 136.3809814453125, 'rgb.min=', -226.75601196289062)
('rgb.max=', 136.24929809570312, 'rgb.min=', -226.64390563964844)
('rgb.max=', 136.43939208984375, 'rgb.min=', -226.74992370605469)
('rgb.max=', 136.23666381835938, 'rgb.min=', -226.64726257324219)
('rgb.max=', 136.43096923828125, 'rgb.min=', -226.69529724121094)
('rgb.max=', 135.96609497070312, 'rgb.min=', -226.63723754882812)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74931335449219)
('rgb.max=', 136.40129089355469, 'rgb.min=', -226.74620056152344)
('rgb.max=', 136.15948486328125, 'rgb.min=', -226.61830139160156)
('rgb.max=', 136.33078002929688, 'rgb.min=', -226.683349609375)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.61756896972656)
('rgb.max=', 136.36250305175781, 'rgb.min=', -226.75120544433594)
('rgb.max=', 136.22865295410156, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.41378784179688, 'rgb.min=', -226.75927734375)
('rgb.max=', 136.25364685058594, 'rgb.min=', -226.6900634765625)
('rgb.max=', 136.29718017578125, 'rgb.min=', -226.80636596679688)
('rgb.max=', 136.28564453125, 'rgb.min=', -226.80905151367188)
('rgb.max=', 136.37062072753906, 'rgb.min=', -226.71157836914062)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71513366699219)
('rgb.max=', 136.12593078613281, 'rgb.min=', -226.75459289550781)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.67347717285156)
('rgb.max=', 136.28398132324219, 'rgb.min=', -226.66575622558594)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.42721557617188)
('rgb.max=', 136.25509643554688, 'rgb.min=', -226.71598815917969)
('rgb.max=', 136.44926452636719, 'rgb.min=', -226.76094055175781)
('rgb.max=', 136.43528747558594, 'rgb.min=', -226.65129089355469)
('rgb.max=', 136.34878540039062, 'rgb.min=', -226.76422119140625)
('rgb.max=', 136.18342590332031, 'rgb.min=', -226.6981201171875)
('rgb.max=', 136.30458068847656, 'rgb.min=', -226.66387939453125)
('rgb.max=', 136.35153198242188, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.3822021484375, 'rgb.min=', -226.8006591796875)
('rgb.max=', 136.30714416503906, 'rgb.min=', -226.6640625)
('rgb.max=', 136.341552734375, 'rgb.min=', -226.50436401367188)
('rgb.max=', 136.456298828125, 'rgb.min=', -226.77662658691406)
('rgb.max=', 136.37138366699219, 'rgb.min=', -226.54878234863281)
('rgb.max=', 136.21990966796875, 'rgb.min=', -226.70480346679688)
('rgb.max=', 136.13107299804688, 'rgb.min=', -226.70881652832031)
('rgb.max=', 136.1851806640625, 'rgb.min=', -226.45069885253906)
('rgb.max=', 136.37480163574219, 'rgb.min=', -226.74267578125)
('rgb.max=', 136.23825073242188, 'rgb.min=', -226.65130615234375)
('rgb.max=', 136.17570495605469, 'rgb.min=', -226.69184875488281)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71760559082031)
('rgb.max=', 136.30101013183594, 'rgb.min=', -226.68516540527344)
('rgb.max=', 136.40142822265625, 'rgb.min=', -226.79248046875)
('rgb.max=', 136.11517333984375, 'rgb.min=', -226.50286865234375)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78860473632812)
('rgb.max=', 136.37796020507812, 'rgb.min=', -226.79585266113281)
('rgb.max=', 136.2801513671875, 'rgb.min=', -226.80653381347656)
('rgb.max=', 136.4404296875, 'rgb.min=', -226.705078125)
('rgb.max=', 136.26139831542969, 'rgb.min=', -226.80018615722656)
('rgb.max=', 136.45187377929688, 'rgb.min=', -226.7593994140625)
('rgb.max=', 136.32595825195312, 'rgb.min=', -226.79170227050781)
('rgb.max=', 136.43852233886719, 'rgb.min=', -226.78521728515625)
('rgb.max=', 136.43580627441406, 'rgb.min=', -226.76109313964844)
('rgb.max=', 136.29263305664062, 'rgb.min=', -226.75787353515625)
('rgb.max=', 136.14505004882812, 'rgb.min=', -226.77751159667969)
('rgb.max=', 136.26554870605469, 'rgb.min=', -226.56298828125)
('rgb.max=', 136.32408142089844, 'rgb.min=', -226.72108459472656)
('rgb.max=', 136.43930053710938, 'rgb.min=', -226.689208984375)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.80795288085938)
('rgb.max=', 136.31277465820312, 'rgb.min=', -226.5980224609375)
('rgb.max=', 136.4002685546875, 'rgb.min=', -226.71221923828125)
('rgb.max=', 136.25544738769531, 'rgb.min=', -226.73846435546875)
('rgb.max=', 136.22087097167969, 'rgb.min=', -226.68362426757812)
('rgb.max=', 136.31787109375, 'rgb.min=', -226.56831359863281)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.32972717285156)
('rgb.max=', 136.38014221191406, 'rgb.min=', -226.72929382324219)
('rgb.max=', 136.39132690429688, 'rgb.min=', -226.81599426269531)
('rgb.max=', 135.96498107910156, 'rgb.min=', -226.58688354492188)
('rgb.max=', 136.43551635742188, 'rgb.min=', -226.38920593261719)
('rgb.max=', 136.36260986328125, 'rgb.min=', -226.61257934570312)
('rgb.max=', 136.20872497558594, 'rgb.min=', -226.73391723632812)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.45521545410156)
('rgb.max=', 136.00518798828125, 'rgb.min=', -226.45164489746094)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.76516723632812)
('rgb.max=', 136.20819091796875, 'rgb.min=', -226.75825500488281)
('rgb.max=', 136.35847473144531, 'rgb.min=', -226.64079284667969)
('rgb.max=', 136.42793273925781, 'rgb.min=', -226.75172424316406)
('rgb.max=', 136.45657348632812, 'rgb.min=', -226.81117248535156)
('rgb.max=', 136.40182495117188, 'rgb.min=', -226.79452514648438)
('rgb.max=', 136.3475341796875, 'rgb.min=', -226.70463562011719)
('rgb.max=', 136.38685607910156, 'rgb.min=', -226.79986572265625)
('rgb.max=', 136.40895080566406, 'rgb.min=', -226.80905151367188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81465148925781)
('rgb.max=', 136.26458740234375, 'rgb.min=', -226.74490356445312)
('rgb.max=', 136.45097351074219, 'rgb.min=', -226.66697692871094)
('rgb.max=', 136.38038635253906, 'rgb.min=', -226.6431884765625)
('rgb.max=', 136.39303588867188, 'rgb.min=', -226.64537048339844)
('rgb.max=', 136.34597778320312, 'rgb.min=', -226.72509765625)
('rgb.max=', 136.39154052734375, 'rgb.min=', -226.67424011230469)
('rgb.max=', 136.45489501953125, 'rgb.min=', -226.69149780273438)
('rgb.max=', 136.32901000976562, 'rgb.min=', -226.68141174316406)
('rgb.max=', 136.34828186035156, 'rgb.min=', -226.70452880859375)
('rgb.max=', 136.42744445800781, 'rgb.min=', -226.55876159667969)
('rgb.max=', 136.31509399414062, 'rgb.min=', -226.78617858886719)
('rgb.max=', 136.43803405761719, 'rgb.min=', -226.79202270507812)
('rgb.max=', 136.07962036132812, 'rgb.min=', -226.72628784179688)
('rgb.max=', 136.28128051757812, 'rgb.min=', -226.5819091796875)
('rgb.max=', 136.20436096191406, 'rgb.min=', -226.72651672363281)
('rgb.max=', 136.41580200195312, 'rgb.min=', -226.81134033203125)
('rgb.max=', 136.36727905273438, 'rgb.min=', -226.68560791015625)
('rgb.max=', 136.24911499023438, 'rgb.min=', -226.74916076660156)
('rgb.max=', 136.439208984375, 'rgb.min=', -226.51296997070312)
('rgb.max=', 136.43026733398438, 'rgb.min=', -226.71868896484375)
('rgb.max=', 136.26730346679688, 'rgb.min=', -226.595947265625)
('rgb.max=', 136.15911865234375, 'rgb.min=', -226.68557739257812)
('rgb.max=', 136.12904357910156, 'rgb.min=', -226.69082641601562)
('rgb.max=', 136.29721069335938, 'rgb.min=', -226.7774658203125)
('rgb.max=', 136.25477600097656, 'rgb.min=', -226.71159362792969)
('rgb.max=', 136.0823974609375, 'rgb.min=', -226.69793701171875)
('rgb.max=', 136.25904846191406, 'rgb.min=', -226.78489685058594)
('rgb.max=', 136.42454528808594, 'rgb.min=', -226.8155517578125)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71403503417969)
('rgb.max=', 136.34945678710938, 'rgb.min=', -226.81509399414062)
('rgb.max=', 136.45401000976562, 'rgb.min=', -226.81138610839844)
('rgb.max=', 136.43952941894531, 'rgb.min=', -226.49000549316406)
('rgb.max=', 136.45182800292969, 'rgb.min=', -226.81509399414062)
('rgb.max=', 136.44839477539062, 'rgb.min=', -226.72441101074219)
('rgb.max=', 136.37091064453125, 'rgb.min=', -226.80516052246094)
('rgb.max=', 136.10958862304688, 'rgb.min=', -226.51100158691406)
('rgb.max=', 136.32835388183594, 'rgb.min=', -226.78907775878906)
('rgb.max=', 136.37654113769531, 'rgb.min=', -226.79316711425781)
('rgb.max=', 136.44635009765625, 'rgb.min=', -226.75770568847656)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78897094726562)
('rgb.max=', 136.24404907226562, 'rgb.min=', -226.66828918457031)
('rgb.max=', 136.42051696777344, 'rgb.min=', -226.74417114257812)
('rgb.max=', 136.12005615234375, 'rgb.min=', -226.80972290039062)
('rgb.max=', 136.24740600585938, 'rgb.min=', -226.59822082519531)
('rgb.max=', 136.27679443359375, 'rgb.min=', -226.77806091308594)
('rgb.max=', 136.185546875, 'rgb.min=', -226.4990234375)
('rgb.max=', 136.36618041992188, 'rgb.min=', -226.69419860839844)
('rgb.max=', 136.30496215820312, 'rgb.min=', -226.78189086914062)
('rgb.max=', 136.30929565429688, 'rgb.min=', -226.65731811523438)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:45.175982')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1372 ', 'GAN acc 0.2227', 'Discriminator loss 0.5625', 'Discriminator accuracy 0.7246', 'Total loss: 1.6997', 'for batch', 0)
('GAN loss 1.2789 ', 'GAN acc 0.1367', 'Discriminator loss 0.5935', 'Discriminator accuracy 0.7168', 'Total loss: 1.8724', 'for batch', 1)
('GAN loss 1.3273 ', 'GAN acc 0.1094', 'Discriminator loss 0.5577', 'Discriminator accuracy 0.7070', 'Total loss: 1.8850', 'for batch', 2)
('GAN loss 1.1661 ', 'GAN acc 0.1602', 'Discriminator loss 0.5508', 'Discriminator accuracy 0.7031', 'Total loss: 1.7169', 'for batch', 3)
('GAN loss 1.1620 ', 'GAN acc 0.1680', 'Discriminator loss 0.5665', 'Discriminator accuracy 0.7461', 'Total loss: 1.7286', 'for batch', 4)
('GAN loss 1.2434 ', 'GAN acc 0.1211', 'Discriminator loss 0.5896', 'Discriminator accuracy 0.7031', 'Total loss: 1.8330', 'for batch', 5)
('GAN loss 1.3086 ', 'GAN acc 0.1367', 'Discriminator loss 0.5845', 'Discriminator accuracy 0.6855', 'Total loss: 1.8931', 'for batch', 6)
('GAN loss 1.2236 ', 'GAN acc 0.1602', 'Discriminator loss 0.5821', 'Discriminator accuracy 0.6758', 'Total loss: 1.8057', 'for batch', 7)
('GAN loss 1.1027 ', 'GAN acc 0.2109', 'Discriminator loss 0.5372', 'Discriminator accuracy 0.7500', 'Total loss: 1.6400', 'for batch', 8)
('GAN loss 1.3420 ', 'GAN acc 0.1367', 'Discriminator loss 0.5711', 'Discriminator accuracy 0.7227', 'Total loss: 1.9131', 'for batch', 9)
('GAN loss 1.3488 ', 'GAN acc 0.1289', 'Discriminator loss 0.5487', 'Discriminator accuracy 0.7109', 'Total loss: 1.8975', 'for batch', 10)
('yuv.max=', 253.886, 'yuv.min=', 2.7120000000000002)
('yuv.max=', 230.196, 'yuv.min=', 13.295)
('yuv.max=', 253.185, 'yuv.min=', 26.285)
('yuv.max=', 255.0, 'yuv.min=', 4.1309999999999993)
('yuv.max=', 249.08799999999999, 'yuv.min=', 35.169999999999995)
('yuv.max=', 241.357, 'yuv.min=', 15.662999999999998)
('yuv.max=', 253.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 227.59099999999998, 'yuv.min=', 14.238999999999999)
('yuv.max=', 255.0, 'yuv.min=', 79.728999999999985)
('yuv.max=', 212.16399999999999, 'yuv.min=', 20.800999999999998)
('yuv.max=', 161.36699999999999, 'yuv.min=', 0.0)
('yuv.max=', 251.58699999999996, 'yuv.min=', 9.3480000000000008)
('yuv.max=', 233.28899999999999, 'yuv.min=', 16.364000000000001)
('yuv.max=', 243.10299999999998, 'yuv.min=', 68.597999999999999)
('yuv.max=', 252.608, 'yuv.min=', 6.5270000000000001)
('yuv.max=', 212.26299999999998, 'yuv.min=', 51.436)
('yuv.max=', 250.99999999999997, 'yuv.min=', 22.042999999999999)
('yuv.max=', 199.32599999999999, 'yuv.min=', 12.450999999999999)
('yuv.max=', 244.84299999999999, 'yuv.min=', 23.092999999999996)
('yuv.max=', 255.0, 'yuv.min=', 39.381)
('yuv.max=', 254.77200000000002, 'yuv.min=', 36.394999999999996)
('yuv.max=', 228.33500000000001, 'yuv.min=', 62.117999999999995)
('yuv.max=', 247.29400000000001, 'yuv.min=', 8.8300000000000001)
('yuv.max=', 231.06899999999996, 'yuv.min=', 29.335000000000001)
('yuv.max=', 242.43000000000001, 'yuv.min=', 14.405999999999999)
('yuv.max=', 250.59300000000002, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 200.86199999999999, 'yuv.min=', 30.422999999999998)
('yuv.max=', 242.55199999999999, 'yuv.min=', 28.243000000000002)
('yuv.max=', 194.815, 'yuv.min=', 23.472000000000001)
('yuv.max=', 195.589, 'yuv.min=', 41.702999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 47.710999999999999)
('yuv.max=', 194.81800000000001, 'yuv.min=', 22.141999999999999)
('yuv.max=', 237.815, 'yuv.min=', 43.080999999999996)
('yuv.max=', 221.83199999999997, 'yuv.min=', 24.260000000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 248.14499999999998, 'yuv.min=', 17.818999999999999)
('yuv.max=', 230.994, 'yuv.min=', 11.968)
('yuv.max=', 216.31999999999999, 'yuv.min=', 23.436)
('yuv.max=', 255.0, 'yuv.min=', 42.841000000000001)
('yuv.max=', 248.72199999999998, 'yuv.min=', 5.1139999999999999)
('yuv.max=', 255.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 222.39699999999999, 'yuv.min=', 21.550999999999995)
('yuv.max=', 252.93999999999997, 'yuv.min=', 30.663999999999998)
('yuv.max=', 234.70499999999998, 'yuv.min=', 14.157999999999999)
('yuv.max=', 236.36799999999999, 'yuv.min=', 29.923999999999999)
('yuv.max=', 210.03699999999998, 'yuv.min=', 25.731999999999999)
('yuv.max=', 246.01599999999999, 'yuv.min=', 1.6519999999999999)
('yuv.max=', 252.71799999999996, 'yuv.min=', 17.748999999999999)
('yuv.max=', 205.90399999999997, 'yuv.min=', 15.331)
('yuv.max=', 227.33799999999999, 'yuv.min=', 15.465)
('yuv.max=', 255.0, 'yuv.min=', 6.004999999999999)
('yuv.max=', 246.90299999999996, 'yuv.min=', 24.841999999999999)
('yuv.max=', 253.14199999999997, 'yuv.min=', 21.305999999999997)
('yuv.max=', 195.929, 'yuv.min=', 22.591000000000001)
('yuv.max=', 166.94199999999998, 'yuv.min=', 23.102999999999998)
('yuv.max=', 241.78300000000002, 'yuv.min=', 22.071000000000002)
('yuv.max=', 211.70699999999999, 'yuv.min=', 31.482999999999997)
('yuv.max=', 243.94799999999998, 'yuv.min=', 49.164999999999999)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 211.92000000000002, 'yuv.min=', 24.797000000000001)
('yuv.max=', 254.886, 'yuv.min=', 2.6799999999999997)
('yuv.max=', 148.69542399999997, 'yuv.min=', 11.092000000000001)
('yuv.max=', 232.85599999999997, 'yuv.min=', 4.7119999999999997)
('yuv.max=', 242.07100000000003, 'yuv.min=', 27.450999999999997)
('yuv.max=', 255.0, 'yuv.min=', 41.282999999999994)
('yuv.max=', 171.85799999999998, 'yuv.min=', 11.945)
('yuv.max=', 188.80599999999998, 'yuv.min=', 11.287999999999998)
('yuv.max=', 217.006, 'yuv.min=', 13.316000000000001)
('yuv.max=', 251.40199999999999, 'yuv.min=', 23.298999999999999)
('yuv.max=', 193.46199999999999, 'yuv.min=', 50.502000000000002)
('yuv.max=', 244.57599999999999, 'yuv.min=', 41.580999999999996)
('yuv.max=', 254.43000000000001, 'yuv.min=', 0.0)
('yuv.max=', 247.62899999999999, 'yuv.min=', 38.528999999999996)
('yuv.max=', 238.40899999999999, 'yuv.min=', 23.305)
('yuv.max=', 255.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 234.18199999999996, 'yuv.min=', 41.141999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 240.28699999999998, 'yuv.min=', 14.902999999999999)
('yuv.max=', 249.61799999999999, 'yuv.min=', 10.326000000000001)
('yuv.max=', 244.39500000000001, 'yuv.min=', 41.725999999999999)
('yuv.max=', 220.31999999999999, 'yuv.min=', 46.737000000000002)
('yuv.max=', 255.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 216.50300000000001, 'yuv.min=', 3.3529999999999998)
('yuv.max=', 238.71700000000001, 'yuv.min=', 35.663999999999994)
('yuv.max=', 193.77200000000002, 'yuv.min=', 9.831999999999999)
('yuv.max=', 216.60199999999998, 'yuv.min=', 3.8469999999999995)
('yuv.max=', 240.87299999999999, 'yuv.min=', 14.369999999999999)
('yuv.max=', 249.929, 'yuv.min=', 14.537999999999998)
('yuv.max=', 254.58699999999999, 'yuv.min=', 0.0)
('yuv.max=', 252.54399999999998, 'yuv.min=', 52.674999999999997)
('yuv.max=', 240.81299999999999, 'yuv.min=', 35.143999999999998)
('yuv.max=', 235.24099999999999, 'yuv.min=', 16.754999999999999)
('yuv.max=', 205.71600000000001, 'yuv.min=', 39.266999999999996)
('yuv.max=', 222.88399999999999, 'yuv.min=', 28.120000000000001)
('yuv.max=', 200.66199999999998, 'yuv.min=', 47.614999999999995)
('yuv.max=', 246.84099999999998, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 228.22799999999998, 'yuv.min=', 2.222)
('yuv.max=', 255.0, 'yuv.min=', 7.7379999999999995)
('yuv.max=', 225.44800000000001, 'yuv.min=', 51.75)
('yuv.max=', 234.70600000000002, 'yuv.min=', 40.338999999999992)
('yuv.max=', 253.95699999999997, 'yuv.min=', 17.805)
('yuv.max=', 185.78299999999999, 'yuv.min=', 49.842999999999996)
('yuv.max=', 168.45600000000002, 'yuv.min=', 24.481999999999999)
('yuv.max=', 245.53899999999999, 'yuv.min=', 35.472000000000001)
('yuv.max=', 219.37899999999999, 'yuv.min=', 59.455999999999996)
('yuv.max=', 254.18499999999997, 'yuv.min=', 23.609999999999999)
('yuv.max=', 193.53100000000001, 'yuv.min=', 33.103999999999999)
('yuv.max=', 218.79399999999998, 'yuv.min=', 40.539999999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', 6.7720000000000002)
('yuv.max=', 236.721, 'yuv.min=', 12.023999999999999)
('yuv.max=', 252.37800000000001, 'yuv.min=', 18.414999999999999)
('yuv.max=', 255.0, 'yuv.min=', 34.246999999999993)
('yuv.max=', 187.93699999999998, 'yuv.min=', 23.212999999999997)
('yuv.max=', 252.91799999999998, 'yuv.min=', 0.0)
('yuv.max=', 190.06299999999999, 'yuv.min=', 13.757999999999999)
('yuv.max=', 236.29300000000001, 'yuv.min=', 30.250999999999998)
('yuv.max=', 247.67500000000001, 'yuv.min=', 23.789999999999999)
('yuv.max=', 253.59799999999998, 'yuv.min=', 15.885999999999999)
('yuv.max=', 249.392, 'yuv.min=', 18.946000000000002)
('yuv.max=', 220.94899999999998, 'yuv.min=', 27.704999999999998)
('yuv.max=', 255.0, 'yuv.min=', 65.162528000000009)
('yuv.max=', 251.29900000000001, 'yuv.min=', 4.7080000000000002)
('yuv.max=', 247.626, 'yuv.min=', 1.6839999999999999)
('yuv.max=', 238.327, 'yuv.min=', 13.728999999999999)
('yuv.max=', 198.15899999999999, 'yuv.min=', 27.891999999999999)
('yuv.max=', 172.339, 'yuv.min=', 76.878999999999991)
('yuv.max=', 246.249, 'yuv.min=', 23.084999999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', 60.908000000000001)
('yuv.max=', 223.73999999999998, 'yuv.min=', 5.2859999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.9830000000000001)
('yuv.max=', 244.98899999999998, 'yuv.min=', 37.420999999999999)
('yuv.max=', 233.03999999999999, 'yuv.min=', 7.0409999999999995)
('yuv.max=', 253.505, 'yuv.min=', 17.576999999999998)
('yuv.max=', 251.05999999999997, 'yuv.min=', 37.304000000000002)
('yuv.max=', 235.32999999999998, 'yuv.min=', 20.787999999999997)
('yuv.max=', 230.77399999999997, 'yuv.min=', 57.293999999999997)
('yuv.max=', 255.0, 'yuv.min=', 32.418999999999997)
('yuv.max=', 186.59100000000001, 'yuv.min=', 26.405999999999999)
('yuv.max=', 255.0, 'yuv.min=', 26.651)
('yuv.max=', 255.0, 'yuv.min=', 43.497)
('yuv.max=', 236.34799999999996, 'yuv.min=', 31.174999999999997)
('yuv.max=', 221.56800000000001, 'yuv.min=', 31.885999999999996)
('yuv.max=', 201.524, 'yuv.min=', 7.7159999999999993)
('yuv.max=', 237.55799999999999, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 241.92899999999997, 'yuv.min=', 75.730999999999995)
('yuv.max=', 248.73199999999997, 'yuv.min=', 26.675000000000001)
('yuv.max=', 216.495, 'yuv.min=', 5.4390000000000001)
('yuv.max=', 243.929, 'yuv.min=', 35.210000000000001)
('yuv.max=', 231.41299999999998, 'yuv.min=', 2.2279999999999998)
('yuv.max=', 251.49000000000001, 'yuv.min=', 0.93999999999999995)
('yuv.max=', 235.786, 'yuv.min=', 2.5590000000000002)
('yuv.max=', 249.142, 'yuv.min=', 0.0)
('yuv.max=', 252.75, 'yuv.min=', 15.429999999999998)
('yuv.max=', 205.631, 'yuv.min=', 38.633999999999993)
('yuv.max=', 248.99999999999997, 'yuv.min=', 1.8580000000000001)
('yuv.max=', 207.06, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 247.54400000000001, 'yuv.min=', 14.956999999999999)
('yuv.max=', 213.96499999999997, 'yuv.min=', 22.106999999999999)
('yuv.max=', 252.25599999999997, 'yuv.min=', 50.949999999999996)
('yuv.max=', 247.64100000000002, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 232.017, 'yuv.min=', 25.341999999999999)
('yuv.max=', 206.852, 'yuv.min=', 49.82)
('yuv.max=', 239.99499999999998, 'yuv.min=', 18.645)
('yuv.max=', 251.262, 'yuv.min=', 5.5049999999999999)
('yuv.max=', 243.95999999999998, 'yuv.min=', 2.4220000000000002)
('yuv.max=', 251.46699999999998, 'yuv.min=', 53.826000000000001)
('yuv.max=', 229.94999999999999, 'yuv.min=', 5.8689999999999998)
('yuv.max=', 255.0, 'yuv.min=', 6.8539999999999992)
('yuv.max=', 208.161, 'yuv.min=', 51.401999999999994)
('yuv.max=', 214.96099999999998, 'yuv.min=', 28.405999999999999)
('yuv.max=', 242.78699999999998, 'yuv.min=', 1.3419999999999999)
('yuv.max=', 241.49599999999998, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 243.99999999999997, 'yuv.min=', 5.0)
('yuv.max=', 229.07499999999996, 'yuv.min=', 68.190463999999992)
('yuv.max=', 240.99999999999997, 'yuv.min=', 35.0)
('yuv.max=', 245.35899999999998, 'yuv.min=', 22.113999999999997)
('yuv.max=', 243.929, 'yuv.min=', 19.027999999999999)
('yuv.max=', 226.26099999999997, 'yuv.min=', 12.988999999999999)
('yuv.max=', 214.98787200000001, 'yuv.min=', 24.164000000000001)
('yuv.max=', 242.34200000000001, 'yuv.min=', 31.73)
('yuv.max=', 234.0, 'yuv.min=', 10.999999999999998)
('yuv.max=', 197.53399999999999, 'yuv.min=', 92.469999999999999)
('yuv.max=', 230.82599999999999, 'yuv.min=', 39.072999999999993)
('yuv.max=', 163.93299999999999, 'yuv.min=', 19.544)
('yuv.max=', 249.452, 'yuv.min=', 26.794999999999998)
('yuv.max=', 227.69300000000001, 'yuv.min=', 33.189999999999998)
('yuv.max=', 243.72899999999998, 'yuv.min=', 12.423999999999999)
('yuv.max=', 232.98199999999997, 'yuv.min=', 66.584999999999994)
('yuv.max=', 211.0, 'yuv.min=', 9.7119999999999997)
('yuv.max=', 252.0, 'yuv.min=', 5.0)
('yuv.max=', 203.90099999999998, 'yuv.min=', 37.832999999999998)
('yuv.max=', 251.74000000000001, 'yuv.min=', 55.920999999999992)
('yuv.max=', 219.90599999999998, 'yuv.min=', 52.720999999999997)
('yuv.max=', 214.20400000000001, 'yuv.min=', 34.450000000000003)
('yuv.max=', 204.238, 'yuv.min=', 11.873000000000001)
('yuv.max=', 255.0, 'yuv.min=', 31.999999999999996)
('yuv.max=', 244.04199999999997, 'yuv.min=', 39.718000000000004)
('yuv.max=', 232.691, 'yuv.min=', 0.0)
('yuv.max=', 254.77200000000002, 'yuv.min=', 1.2990000000000002)
('yuv.max=', 236.94599999999997, 'yuv.min=', 12.669999999999998)
('yuv.max=', 214.36699999999999, 'yuv.min=', 31.032)
('yuv.max=', 213.34999999999999, 'yuv.min=', 49.390000000000001)
('yuv.max=', 218.67799999999997, 'yuv.min=', 18.907999999999998)
('yuv.max=', 221.79999999999998, 'yuv.min=', 31.512)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 251.19499999999999, 'yuv.min=', 15.738999999999999)
('yuv.max=', 185.71600000000001, 'yuv.min=', 74.0)
('yuv.max=', 239.36799999999997, 'yuv.min=', 14.342000000000001)
('yuv.max=', 205.83199999999999, 'yuv.min=', 8.0759999999999987)
('yuv.max=', 230.804, 'yuv.min=', 16.814999999999998)
('yuv.max=', 191.19999999999999, 'yuv.min=', 0.114)
('yuv.max=', 254.40199999999999, 'yuv.min=', 1.4019999999999999)
('yuv.max=', 241.74800000000002, 'yuv.min=', 23.756)
('yuv.max=', 250.30399999999997, 'yuv.min=', 24.841000000000001)
('yuv.max=', 243.25599999999997, 'yuv.min=', 5.0599999999999996)
('yuv.max=', 222.208, 'yuv.min=', 34.536999999999999)
('yuv.max=', 229.31399999999999, 'yuv.min=', 0.0)
('yuv.max=', 208.88, 'yuv.min=', 24.347999999999999)
('yuv.max=', 246.72300000000001, 'yuv.min=', 2.9349999999999996)
('yuv.max=', 215.77199999999999, 'yuv.min=', 80.378)
('yuv.max=', 241.61500000000001, 'yuv.min=', 7.1139999999999999)
('yuv.max=', 240.39099999999999, 'yuv.min=', 11.945999999999998)
('yuv.max=', 241.09343999999999, 'yuv.min=', 4.3639999999999999)
('yuv.max=', 245.02000000000001, 'yuv.min=', 9.7050000000000001)
('yuv.max=', 211.58699999999999, 'yuv.min=', 14.134999999999998)
('yuv.max=', 249.66300000000001, 'yuv.min=', 25.026)
('yuv.max=', 245.21499999999997, 'yuv.min=', 4.9509999999999996)
('yuv.max=', 170.2184, 'yuv.min=', 32.658999999999999)
('yuv.max=', 225.86199999999999, 'yuv.min=', 85.445000000000007)
('yuv.max=', 254.11399999999998, 'yuv.min=', 20.282)
('yuv.max=', 252.29899999999998, 'yuv.min=', 38.354999999999997)
('yuv.max=', 231.48799999999997, 'yuv.min=', 36.250999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 245.46600000000001, 'yuv.min=', 17.058)
('yuv.max=', 255.0, 'yuv.min=', 57.984000000000002)
('yuv.max=', 240.71199999999999, 'yuv.min=', 29.685999999999996)
('yuv.max=', 244.13800000000001, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 229.10900000000001, 'yuv.min=', 11.26)
('yuv.max=', 248.21100000000001, 'yuv.min=', 30.710000000000001)
('yuv.max=', 224.11299999999997, 'yuv.min=', 18.164999999999999)
('yuv.max=', 249.31899999999999, 'yuv.min=', 20.012)
('yuv.max=', 198.71199999999999, 'yuv.min=', 23.460000000000001)
('yuv.max=', 255.0, 'yuv.min=', 27.526999999999997)
('yuv.max=', 228.58199999999999, 'yuv.min=', 40.405999999999999)
('yuv.max=', 249.07099999999997, 'yuv.min=', 25.495999999999995)
('yuv.max=', 241.47300000000001, 'yuv.min=', 55.101999999999997)
('yuv.max=', 237.70099999999999, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 234.78300000000002, 'yuv.min=', 44.872999999999998)
('yuv.max=', 207.93799999999999, 'yuv.min=', 14.242000000000001)
('yuv.max=', 242.05399999999997, 'yuv.min=', 16.396000000000001)
('yuv.max=', 231.316, 'yuv.min=', 38.711999999999996)
('yuv.max=', 228.94499999999999, 'yuv.min=', 5.0039999999999996)
('yuv.max=', 218.30600000000001, 'yuv.min=', 0.0)
('yuv.max=', 250.71200000000002, 'yuv.min=', 0.0)
('yuv.max=', 252.72899999999998, 'yuv.min=', 28.954999999999998)
('yuv.max=', 234.11799999999999, 'yuv.min=', 40.424999999999997)
('yuv.max=', 255.0, 'yuv.min=', 30.658999999999999)
('yuv.max=', 215.34, 'yuv.min=', 47.769999999999996)
('yuv.max=', 216.19299999999998, 'yuv.min=', 5.8689999999999998)
('yuv.max=', 229.25999999999999, 'yuv.min=', 92.247519999999994)
('yuv.max=', 231.10999999999999, 'yuv.min=', 41.832384000000005)
('yuv.max=', 241.73000000000002, 'yuv.min=', 9.7919999999999998)
('yuv.max=', 177.54499999999999, 'yuv.min=', 22.268000000000001)
('yuv.max=', 255.0, 'yuv.min=', 12.864999999999998)
('yuv.max=', 247.41200000000001, 'yuv.min=', 11.647999999999998)
('yuv.max=', 235.07999999999998, 'yuv.min=', 11.533999999999999)
('yuv.max=', 209.595, 'yuv.min=', 13.574)
('yuv.max=', 242.82900000000001, 'yuv.min=', 26.905000000000001)
('yuv.max=', 190.07799999999997, 'yuv.min=', 26.042999999999999)
('yuv.max=', 251.29799999999997, 'yuv.min=', 4.2990000000000004)
('yuv.max=', 190.98599999999999, 'yuv.min=', 13.157999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 5.5979999999999999)
('yuv.max=', 238.114, 'yuv.min=', 12.712)
('yuv.max=', 252.79299999999998, 'yuv.min=', 4.4619999999999997)
('yuv.max=', 254.28799999999998, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 246.364, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 204.33199999999999, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 234.24200000000002, 'yuv.min=', 74.890000000000001)
('yuv.max=', 255.0, 'yuv.min=', 16.113999999999997)
('yuv.max=', 216.28700000000001, 'yuv.min=', 64.326999999999998)
('yuv.max=', 205.84299999999999, 'yuv.min=', 30.448999999999998)
('yuv.max=', 210.77199999999999, 'yuv.min=', 19.087999999999997)
('yuv.max=', 225.91499999999999, 'yuv.min=', 4.6950000000000003)
('yuv.max=', 205.63799999999998, 'yuv.min=', 54.143000000000001)
('yuv.max=', 255.0, 'yuv.min=', 33.271000000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', 43.034999999999997)
('yuv.max=', 247.52499999999998, 'yuv.min=', 14.593)
('yuv.max=', 253.23899999999998, 'yuv.min=', 57.865999999999993)
('yuv.max=', 244.239, 'yuv.min=', 38.613)
('yuv.max=', 250.35500000000002, 'yuv.min=', 9.0389999999999997)
('yuv.max=', 249.744, 'yuv.min=', 3.2989999999999999)
('yuv.max=', 204.33499999999998, 'yuv.min=', 26.687000000000001)
('yuv.max=', 255.0, 'yuv.min=', 44.227999999999994)
('yuv.max=', 232.78900000000002, 'yuv.min=', 35.347999999999999)
('yuv.max=', 211.61899999999997, 'yuv.min=', 7.4129999999999994)
('yuv.max=', 198.12399999999997, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 229.45199999999997, 'yuv.min=', 7.3029999999999999)
('yuv.max=', 174.15200000000002, 'yuv.min=', 8.343)
('yuv.max=', 247.16799999999998, 'yuv.min=', 18.920000000000002)
('yuv.max=', 255.0, 'yuv.min=', 58.365999999999993)
('yuv.max=', 237.62199999999999, 'yuv.min=', 15.021999999999998)
('yuv.max=', 162.93059199999999, 'yuv.min=', 22.872999999999998)
('yuv.max=', 250.19499999999999, 'yuv.min=', 36.616)
('yuv.max=', 235.25299999999999, 'yuv.min=', 2.4449999999999998)
('yuv.max=', 228.35300000000001, 'yuv.min=', 28.718)
('yuv.max=', 255.0, 'yuv.min=', 59.270999999999994)
('yuv.max=', 251.95699999999997, 'yuv.min=', 43.555)
('yuv.max=', 237.78899999999999, 'yuv.min=', 20.527999999999999)
('yuv.max=', 254.41299999999995, 'yuv.min=', 17.137696000000005)
('yuv.max=', 245.43699999999998, 'yuv.min=', 2.6909999999999998)
('yuv.max=', 222.07900000000001, 'yuv.min=', 18.82)
('yuv.max=', 251.011, 'yuv.min=', 7.0709999999999997)
('yuv.max=', 240.92899999999997, 'yuv.min=', 64.506208000000001)
('yuv.max=', 179.0, 'yuv.min=', 34.0)
('yuv.max=', 207.55199999999999, 'yuv.min=', 47.241)
('yuv.max=', 235.93300000000002, 'yuv.min=', 0.0)
('yuv.max=', 246.99299999999997, 'yuv.min=', 24.678999999999998)
('yuv.max=', 229.87499999999997, 'yuv.min=', 46.724000000000004)
('yuv.max=', 234.80099999999999, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 236.488, 'yuv.min=', 6.5049999999999999)
('yuv.max=', 228.69399999999999, 'yuv.min=', 22.125)
('yuv.max=', 238.56799999999998, 'yuv.min=', 6.968)
('yuv.max=', 254.41299999999995, 'yuv.min=', 15.826000000000001)
('yuv.max=', 240.98099999999999, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 249.33699999999999, 'yuv.min=', 34.231000000000002)
('yuv.max=', 216.786, 'yuv.min=', 37.003)
('yuv.max=', 226.26400000000001, 'yuv.min=', 32.329000000000001)
('yuv.max=', 243.77699999999999, 'yuv.min=', 48.874000000000002)
('yuv.max=', 162.036, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 229.49099999999999, 'yuv.min=', 4.8899999999999997)
('yuv.max=', 229.113, 'yuv.min=', 30.178999999999998)
('yuv.max=', 243.39099999999999, 'yuv.min=', 21.744)
('yuv.max=', 237.60899999999998, 'yuv.min=', 27.559000000000001)
('yuv.max=', 253.16300000000001, 'yuv.min=', 29.027999999999999)
('yuv.max=', 249.77199999999999, 'yuv.min=', 2.8689999999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', 11.841999999999999)
('yuv.max=', 246.69399999999996, 'yuv.min=', 55.078999999999994)
('yuv.max=', 241.869, 'yuv.min=', 2.2279999999999998)
('yuv.max=', 250.94000000000003, 'yuv.min=', 2.0819999999999999)
('yuv.max=', 242.64699999999999, 'yuv.min=', 1.4949999999999999)
('yuv.max=', 247.97, 'yuv.min=', 46.075000000000003)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 233.94799999999998, 'yuv.min=', 11.581999999999999)
('yuv.max=', 241.84300000000002, 'yuv.min=', 16.728999999999999)
('yuv.max=', 208.00700000000001, 'yuv.min=', 12.414999999999999)
('yuv.max=', 255.0, 'yuv.min=', 46.727000000000004)
('yuv.max=', 250.114, 'yuv.min=', 46.657999999999994)
('yuv.max=', 239.02699999999999, 'yuv.min=', 12.419)
('yuv.max=', 255.0, 'yuv.min=', 30.970999999999997)
('yuv.max=', 255.0, 'yuv.min=', 9.9830000000000005)
('yuv.max=', 150.23702400000002, 'yuv.min=', 44.728999999999999)
('yuv.max=', 247.57999999999998, 'yuv.min=', 9.1569999999999983)
('yuv.max=', 222.76499999999999, 'yuv.min=', 21.028000000000002)
('yuv.max=', 237.95499999999998, 'yuv.min=', 0.0)
('yuv.max=', 233.131, 'yuv.min=', 6.2450000000000001)
('yuv.max=', 237.69299999999996, 'yuv.min=', 5.7869999999999999)
('yuv.max=', 234.071, 'yuv.min=', 10.113999999999999)
('yuv.max=', 199.959, 'yuv.min=', 39.712000000000003)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 246.90699999999998, 'yuv.min=', 17.585999999999999)
('yuv.max=', 246.31, 'yuv.min=', 0.0)
('yuv.max=', 222.12799999999999, 'yuv.min=', 39.079999999999998)
('yuv.max=', 198.92364799999999, 'yuv.min=', 28.383999999999997)
('yuv.max=', 254.77200000000002, 'yuv.min=', 19.270999999999997)
('yuv.max=', 255.0, 'yuv.min=', 4.4169999999999998)
('yuv.max=', 249.316, 'yuv.min=', 6.1399999999999997)
('yuv.max=', 226.18900000000002, 'yuv.min=', 21.940000000000001)
('yuv.max=', 186.27099999999999, 'yuv.min=', 29.895)
('yuv.max=', 254.54400000000001, 'yuv.min=', 6.4299999999999997)
('yuv.max=', 254.886, 'yuv.min=', 24.966999999999999)
('yuv.max=', 253.81499999999997, 'yuv.min=', 6.0279999999999996)
('yuv.max=', 211.99099999999999, 'yuv.min=', 38.091999999999999)
('yuv.max=', 214.85399999999998, 'yuv.min=', 39.055)
('yuv.max=', 225.899, 'yuv.min=', 2.6299999999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', 6.0)
('yuv.max=', 247.0, 'yuv.min=', 31.771999999999998)
('yuv.max=', 245.64699999999996, 'yuv.min=', 29.727)
('yuv.max=', 249.35899999999998, 'yuv.min=', 0.0)
('yuv.max=', 237.20000000000002, 'yuv.min=', 8.3100000000000005)
('yuv.max=', 239.56900000000002, 'yuv.min=', 0.0)
('yuv.max=', 246.77199999999999, 'yuv.min=', 24.396000000000001)
('yuv.max=', 209.035, 'yuv.min=', 11.219000000000001)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 239.98899999999998, 'yuv.min=', 6.6619999999999999)
('yuv.max=', 244.76500000000001, 'yuv.min=', 2.3959999999999999)
('yuv.max=', 238.42400000000001, 'yuv.min=', 22.231999999999999)
('yuv.max=', 179.48499999999999, 'yuv.min=', 72.156999999999996)
('yuv.max=', 232.33737599999998, 'yuv.min=', 31.298999999999999)
('yuv.max=', 248.06399999999999, 'yuv.min=', 5.875)
('yuv.max=', 254.11399999999998, 'yuv.min=', 14.929999999999998)
('yuv.max=', 232.833, 'yuv.min=', 33.658000000000001)
('yuv.max=', 251.91799999999998, 'yuv.min=', 7.4349999999999996)
('yuv.max=', 242.999, 'yuv.min=', 25.575999999999997)
('yuv.max=', 236.78899999999999, 'yuv.min=', 44.152000000000001)
('yuv.max=', 192.13800000000001, 'yuv.min=', 14.861999999999998)
('yuv.max=', 196.535, 'yuv.min=', 8.6069999999999993)
('yuv.max=', 247.56799999999998, 'yuv.min=', 0.0)
('yuv.max=', 248.77199999999999, 'yuv.min=', 26.246000000000002)
('yuv.max=', 174.72699999999998, 'yuv.min=', 0.114)
('yuv.max=', 238.0, 'yuv.min=', 12.999999999999998)
('yuv.max=', 193.10599999999999, 'yuv.min=', 7.4450000000000003)
('yuv.max=', 207.78000000000003, 'yuv.min=', 42.530999999999999)
('yuv.max=', 255.0, 'yuv.min=', 14.483999999999998)
('yuv.max=', 252.03800000000001, 'yuv.min=', 1.4239999999999999)
('yuv.max=', 162.35599999999999, 'yuv.min=', 46.936999999999998)
('yuv.max=', 205.08099999999999, 'yuv.min=', 23.529999999999998)
('yuv.max=', 227.34099999999998, 'yuv.min=', 1.196)
('yuv.max=', 255.0, 'yuv.min=', 51.762)
('yuv.max=', 241.96899999999999, 'yuv.min=', 34.833999999999996)
('yuv.max=', 238.708, 'yuv.min=', 7.4779999999999998)
('yuv.max=', 219.529, 'yuv.min=', 31.532)
('yuv.max=', 217.16999999999999, 'yuv.min=', 5.9289999999999994)
('yuv.max=', 241.63, 'yuv.min=', 7.2609999999999992)
('yuv.max=', 200.88499999999999, 'yuv.min=', 12.999999999999998)
('yuv.max=', 245.124, 'yuv.min=', 32.666208000000012)
('yuv.max=', 254.29899999999995, 'yuv.min=', 0.0)
('yuv.max=', 245.57499999999999, 'yuv.min=', 18.119)
('yuv.max=', 248.64700000000002, 'yuv.min=', 52.275360000000006)
('yuv.max=', 255.0, 'yuv.min=', 33.528999999999996)
('yuv.max=', 246.75700000000001, 'yuv.min=', 0.0)
('yuv.max=', 253.47299999999998, 'yuv.min=', 38.119999999999997)
('yuv.max=', 211.72399999999999, 'yuv.min=', 55.837999999999994)
('yuv.max=', 255.0, 'yuv.min=', 14.764000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 245.733, 'yuv.min=', 20.109999999999999)
('yuv.max=', 150.7184, 'yuv.min=', 1.6839999999999999)
('yuv.max=', 232.148, 'yuv.min=', 3.1230000000000002)
('yuv.max=', 252.33699999999999, 'yuv.min=', 51.362999999999992)
('yuv.max=', 184.80799999999999, 'yuv.min=', 25.951999999999998)
('yuv.max=', 244.98899999999998, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 254.47300000000001, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 248.559, 'yuv.min=', 28.227999999999998)
('yuv.max=', 255.0, 'yuv.min=', 29.559000000000001)
('yuv.max=', 196.0, 'yuv.min=', 21.0)
('yuv.max=', 218.83999999999997, 'yuv.min=', 26.919296000000003)
('yuv.max=', 254.43000000000001, 'yuv.min=', 3.2989999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 14.836999999999998)
('yuv.max=', 240.12499999999997, 'yuv.min=', 39.347999999999999)
('yuv.max=', 252.58699999999999, 'yuv.min=', 8.9719999999999995)
('yuv.max=', 227.203, 'yuv.min=', 42.287999999999997)
('yuv.max=', 252.90699999999998, 'yuv.min=', 27.011000000000003)
('yuv.max=', 214.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 252.90699999999998, 'yuv.min=', 0.0)
('yuv.max=', 252.42999999999998, 'yuv.min=', 6.6259999999999994)
('yuv.max=', 255.0, 'yuv.min=', 12.57)
('yuv.max=', 244.125, 'yuv.min=', 4.1139999999999999)
('yuv.max=', 224.501, 'yuv.min=', 14.607999999999999)
('yuv.max=', 248.91800000000001, 'yuv.min=', 0.114)
('yuv.max=', 242.626, 'yuv.min=', 14.897999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 218.738, 'yuv.min=', 95.205999999999989)
('yuv.max=', 240.72299999999996, 'yuv.min=', 17.657999999999998)
('yuv.max=', 215.86399999999998, 'yuv.min=', 1.8859999999999999)
('yuv.max=', 255.0, 'yuv.min=', 37.212999999999994)
('yuv.max=', 255.0, 'yuv.min=', 48.055)
('yuv.max=', 248.52599999999998, 'yuv.min=', 60.117999999999995)
('yuv.max=', 191.036384, 'yuv.min=', 24.915999999999997)
('yuv.max=', 241.92499999999998, 'yuv.min=', 57.185000000000002)
('yuv.max=', 200.10299999999998, 'yuv.min=', 19.437999999999999)
('yuv.max=', 215.81100000000001, 'yuv.min=', 46.238144000000005)
('yuv.max=', 254.70099999999999, 'yuv.min=', 15.543999999999999)
('yuv.max=', 247.976, 'yuv.min=', 6.9830000000000005)
('yuv.max=', 255.0, 'yuv.min=', 42.734999999999999)
('yuv.max=', 249.267, 'yuv.min=', 12.544999999999998)
('yuv.max=', 219.53299999999999, 'yuv.min=', 79.885887999999994)
('yuv.max=', 245.13099999999997, 'yuv.min=', 75.706999999999994)
('yuv.max=', 205.24099999999999, 'yuv.min=', 19.227999999999998)
('yuv.max=', 210.773, 'yuv.min=', 40.332999999999998)
('yuv.max=', 255.0, 'yuv.min=', 12.881)
('yuv.max=', 243.07099999999997, 'yuv.min=', 14.841000000000001)
('yuv.max=', 221.96499999999997, 'yuv.min=', 72.74199999999999)
('yuv.max=', 255.0, 'yuv.min=', 12.999999999999998)
('yuv.max=', 213.91799999999998, 'yuv.min=', 22.202000000000002)
('yuv.max=', 255.0, 'yuv.min=', 31.068000000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', 35.042000000000002)
('yuv.max=', 255.0, 'yuv.min=', 11.709000000000001)
('yuv.max=', 233.916, 'yuv.min=', 18.195999999999998)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 253.404, 'yuv.min=', 63.432999999999993)
('yuv.max=', 243.09899999999999, 'yuv.min=', 16.248000000000001)
('yuv.max=', 228.93499999999997, 'yuv.min=', 26.234999999999999)
('yuv.max=', 224.404, 'yuv.min=', 0.0)
('yuv.max=', 202.13300000000001, 'yuv.min=', 7.0819999999999999)
('yuv.max=', 223.89299999999997, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 224.89600000000002, 'yuv.min=', 5.6029999999999998)
('yuv.max=', 248.94199999999998, 'yuv.min=', 39.716000000000001)
('yuv.max=', 220.59700000000001, 'yuv.min=', 3.9899999999999993)
('yuv.max=', 237.08100000000002, 'yuv.min=', 36.978999999999992)
('yuv.max=', 202.114, 'yuv.min=', 36.847999999999999)
('yuv.max=', 128.00000000000003, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 255.0, 'yuv.min=', 26.532999999999998)
('yuv.max=', 250.81399999999999, 'yuv.min=', 30.694999999999997)
('yuv.max=', 211.75699999999998, 'yuv.min=', 63.526000000000003)
('yuv.max=', 206.97899999999998, 'yuv.min=', 14.111999999999998)
('yuv.max=', 229.78299999999999, 'yuv.min=', 15.657999999999998)
('yuv.max=', 249.17399999999998, 'yuv.min=', 41.325999999999993)
('yuv.max=', 246.45599999999999, 'yuv.min=', 0.0)
('yuv.max=', 233.13899999999998, 'yuv.min=', 45.203999999999994)
('yuv.max=', 254.70099999999999, 'yuv.min=', 26.084999999999997)
('yuv.max=', 237.23599999999996, 'yuv.min=', 1.1400000000000001)
('yuv.max=', 249.10300000000001, 'yuv.min=', 12.141999999999999)
('yuv.max=', 253.0, 'yuv.min=', 1.7719999999999998)
('yuv.max=', 251.79299999999998, 'yuv.min=', 21.456000000000003)
('yuv.max=', 244.97800000000001, 'yuv.min=', 49.219999999999999)
('yuv.max=', 255.0, 'yuv.min=', 13.826000000000001)
('yuv.max=', 250.99999999999997, 'yuv.min=', 110.0)
('yuv.max=', 206.60599999999999, 'yuv.min=', 9.5489999999999995)
('yuv.max=', 249.995, 'yuv.min=', 34.670000000000002)
('yuv.max=', 238.95699999999997, 'yuv.min=', 41.886000000000003)
('yuv.max=', 220.91399999999999, 'yuv.min=', 12.847)
('yuv.max=', 230.80799999999999, 'yuv.min=', 13.896999999999998)
('yuv.max=', 249.02799999999999, 'yuv.min=', 48.57)
('yuv.max=', 237.62299999999999, 'yuv.min=', 33.195)
('yuv.max=', 253.20599999999999, 'yuv.min=', 6.552999999999999)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 28.425000000000001)
('yuv.max=', 251.066, 'yuv.min=', 39.223264)
('yuv.max=', 255.0, 'yuv.min=', 51.250999999999998)
('yuv.max=', 255.0, 'yuv.min=', 46.885999999999996)
('yuv.max=', 252.33099999999999, 'yuv.min=', 16.587)
('yuv.max=', 198.37599999999998, 'yuv.min=', 14.937999999999999)
('yuv.max=', 255.0, 'yuv.min=', 44.353999999999999)
('yuv.max=', 201.084, 'yuv.min=', 85.296999999999997)
('yuv.max=', 187.34399999999999, 'yuv.min=', 18.911999999999999)
('yuv.max=', 152.88092800000001, 'yuv.min=', 13.275)
('yuv.max=', 236.39400000000001, 'yuv.min=', 13.199)
('yuv.max=', 230.28999999999999, 'yuv.min=', 3.9900000000000002)
('yuv.max=', 251.98499999999999, 'yuv.min=', 14.590999999999998)
('yuv.max=', 219.05100000000002, 'yuv.min=', 14.849)
('yuv.max=', 255.0, 'yuv.min=', 62.575999999999993)
('yuv.max=', 210.595, 'yuv.min=', 34.962000000000003)
('yuv.max=', 217.417, 'yuv.min=', 4.8860000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 207.268192, 'yuv.min=', 18.102999999999998)
('yuv.max=', 233.25900000000001, 'yuv.min=', 70.632999999999996)
('yuv.max=', 220.22200000000001, 'yuv.min=', 67.869)
('yuv.max=', 244.32699999999997, 'yuv.min=', 12.304)
('yuv.max=', 241.02099999999999, 'yuv.min=', 26.226999999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', 19.282)
('yuv.max=', 252.679, 'yuv.min=', 13.517999999999999)
('yuv.max=', 248.52899999999997, 'yuv.min=', 13.391)
('yuv.max=', 248.35900000000001, 'yuv.min=', 0.0)
('yuv.max=', 238.54399999999995, 'yuv.min=', 55.972000000000001)
('yuv.max=', 242.435, 'yuv.min=', 24.925000000000001)
('yuv.max=', 212.256, 'yuv.min=', 10.766)
('yuv.max=', 255.0, 'yuv.min=', 15.042999999999999)
('yuv.max=', 255.0, 'yuv.min=', 34.010999999999996)
('yuv.max=', 252.761, 'yuv.min=', 18.444999999999997)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 238.798, 'yuv.min=', 32.228999999999999)
('yuv.max=', 175.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 254.40199999999999, 'yuv.min=', 15.461)
('yuv.max=', 167.94499999999999, 'yuv.min=', 12.988999999999999)
('yuv.max=', 198.61600000000001, 'yuv.min=', 22.658000000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', 2.9660000000000002)
('yuv.max=', 213.66200000000001, 'yuv.min=', 37.704999999999998)
('yuv.max=', 255.0, 'yuv.min=', 16.783000000000001)
('yuv.max=', 255.0, 'yuv.min=', 22.907999999999998)
('yuv.max=', 255.0, 'yuv.min=', 21.786999999999999)
('yuv.max=', 253.333, 'yuv.min=', 39.046999999999997)
('yuv.max=', 202.339, 'yuv.min=', 18.555)
('yuv.max=', 243.98299999999998, 'yuv.min=', 9.5439999999999987)
('yuv.max=', 238.47299999999998, 'yuv.min=', 66.254000000000005)
('yuv.max=', 229.0, 'yuv.min=', 83.0)
('yuv.max=', 250.87899999999996, 'yuv.min=', 3.4019999999999997)
('yuv.max=', 242.61299999999997, 'yuv.min=', 0.0)
('yuv.max=', 237.68099999999998, 'yuv.min=', 36.956999999999994)
('yuv.max=', 233.65800000000002, 'yuv.min=', 0.0)
('yuv.max=', 228.71899999999999, 'yuv.min=', 49.048999999999999)
('yuv.max=', 252.065, 'yuv.min=', 1.0429999999999999)
('yuv.max=', 247.62499999999997, 'yuv.min=', 83.638999999999996)
('yuv.max=', 210.87099999999998, 'yuv.min=', 4.0430000000000001)
('yuv.max=', 203.333, 'yuv.min=', 0.0)
('yuv.max=', 254.886, 'yuv.min=', 0.0)
('yuv.max=', 197.91800000000001, 'yuv.min=', 57.732999999999997)
('yuv.max=', 244.762, 'yuv.min=', 11.882)
('yuv.max=', 231.15299999999996, 'yuv.min=', 50.899999999999991)
('yuv.max=', 169.17494399999998, 'yuv.min=', 30.542999999999999)
('yuv.max=', 250.46199999999996, 'yuv.min=', 43.143000000000001)
('yuv.max=', 208.38999999999999, 'yuv.min=', 0.0)
('yuv.max=', 249.744, 'yuv.min=', 22.286000000000001)
('yuv.max=', 251.71100000000001, 'yuv.min=', 23.524999999999999)
('yuv.max=', 255.0, 'yuv.min=', 18.047999999999998)
('yuv.max=', 255.0, 'yuv.min=', 76.0)
('yuv.max=', 247.29900000000004, 'yuv.min=', 2.8969999999999998)
('yuv.max=', 220.941, 'yuv.min=', 24.754999999999995)
('yuv.max=', 246.85399999999998, 'yuv.min=', 33.158999999999999)
('yuv.max=', 255.0, 'yuv.min=', 2.25)
('yuv.max=', 245.63199999999998, 'yuv.min=', 36.750999999999998)
('yuv.max=', 234.03200000000001, 'yuv.min=', 2.798)
('yuv.max=', 240.97899999999998, 'yuv.min=', 22.245999999999999)
('yuv.max=', 255.0, 'yuv.min=', 34.131)
('yuv.max=', 252.93999999999997, 'yuv.min=', 35.832000000000001)
('yuv.max=', 247.92899999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 8.2279999999999998)
('yuv.max=', 157.50399999999999, 'yuv.min=', 1.8260000000000001)
('yuv.max=', 179.76999999999998, 'yuv.min=', 14.542000000000002)
('yuv.max=', 243.95699999999997, 'yuv.min=', 9.3269999999999982)
('yuv.max=', 226.976, 'yuv.min=', 28.218999999999998)
('yuv.max=', 242.58699999999999, 'yuv.min=', 26.370000000000001)
('yuv.max=', 253.72899999999996, 'yuv.min=', 6.8580000000000005)
('yuv.max=', 235.363, 'yuv.min=', 16.050999999999998)
('yuv.max=', 255.0, 'yuv.min=', 3.157)
('yuv.max=', 219.99499999999998, 'yuv.min=', 0.0)
('yuv.max=', 250.81399999999999, 'yuv.min=', 19.111999999999998)
('yuv.max=', 213.309, 'yuv.min=', 82.48299999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', 34.695)
('yuv.max=', 254.41299999999995, 'yuv.min=', 4.4849999999999994)
('yuv.max=', 181.41, 'yuv.min=', 10.700999999999999)
('yuv.max=', 186.07499999999999, 'yuv.min=', 17.721)
('yuv.max=', 239.11899999999997, 'yuv.min=', 65.024000000000001)
('yuv.max=', 224.97199999999998, 'yuv.min=', 20.318999999999999)
('yuv.max=', 255.0, 'yuv.min=', 49.063000000000002)
('yuv.max=', 157.73699999999997, 'yuv.min=', 21.358999999999998)
('yuv.max=', 214.81, 'yuv.min=', 11.909999999999998)
('yuv.max=', 203.03900000000002, 'yuv.min=', 34.103999999999999)
('yuv.max=', 237.40600000000001, 'yuv.min=', 20.832999999999998)
('yuv.max=', 185.286688, 'yuv.min=', 31.063999999999997)
('yuv.max=', 248.185, 'yuv.min=', 21.557000000000002)
('yuv.max=', 251.13099999999997, 'yuv.min=', 69.965999999999994)
('yuv.max=', 246.59399999999999, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 255.0, 'yuv.min=', 39.744352000000006)
('yuv.max=', 241.89199999999997, 'yuv.min=', 24.830000000000002)
('yuv.max=', 227.541, 'yuv.min=', 7.4519999999999991)
('yuv.max=', 251.10299999999998, 'yuv.min=', 14.771999999999998)
('yuv.max=', 215.125, 'yuv.min=', 43.662999999999997)
('yuv.max=', 206.886, 'yuv.min=', 50.423999999999999)
('yuv.max=', 228.58499999999998, 'yuv.min=', 22.811000000000003)
('yuv.max=', 205.44921600000001, 'yuv.min=', 54.469999999999999)
('yuv.max=', 204.31312, 'yuv.min=', 28.558)
('yuv.max=', 242.25499999999997, 'yuv.min=', 6.5439999999999996)
('yuv.max=', 172.886, 'yuv.min=', 7.1849999999999996)
('yuv.max=', 246.36999999999998, 'yuv.min=', 27.042999999999999)
('yuv.max=', 241.357, 'yuv.min=', 2.867)
('yuv.max=', 255.0, 'yuv.min=', 4.3589999999999991)
('yuv.max=', 249.32699999999997, 'yuv.min=', 17.290999999999997)
('yuv.max=', 229.07199999999997, 'yuv.min=', 57.859999999999992)
('yuv.max=', 250.0, 'yuv.min=', 29.952999999999999)
('yuv.max=', 248.25999999999999, 'yuv.min=', 24.970999999999997)
('yuv.max=', 240.404, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 252.42999999999998, 'yuv.min=', 2.4449999999999998)
('yuv.max=', 252.892, 'yuv.min=', 38.467999999999996)
('yuv.max=', 235.77799999999996, 'yuv.min=', 39.794015999999999)
('yuv.max=', 246.88200000000001, 'yuv.min=', 5.5989999999999993)
('yuv.max=', 207.24999999999997, 'yuv.min=', 31.742000000000001)
('yuv.max=', 238.10799999999998, 'yuv.min=', 42.856000000000002)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 201.37899999999999, 'yuv.min=', 3.2709999999999999)
('yuv.max=', 253.71799999999999, 'yuv.min=', 25.202999999999999)
('yuv.max=', 241.869, 'yuv.min=', 6.5539999999999994)
('yuv.max=', 253.0, 'yuv.min=', 17.0)
('yuv.max=', 252.636, 'yuv.min=', 10.724)
('yuv.max=', 250.78199999999998, 'yuv.min=', 44.396000000000001)
('yuv.max=', 221.09199999999998, 'yuv.min=', 5.1849999999999996)
('yuv.max=', 219.49000000000001, 'yuv.min=', 48.244999999999997)
('yuv.max=', 240.30299999999997, 'yuv.min=', 41.085000000000001)
('yuv.max=', 244.17999999999998, 'yuv.min=', 6.9889999999999999)
('yuv.max=', 245.71599999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 4.516)
('yuv.max=', 253.0, 'yuv.min=', 23.0)
('yuv.max=', 221.73999999999998, 'yuv.min=', 13.073999999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', 22.715999999999998)
('yuv.max=', 244.30700000000002, 'yuv.min=', 54.122)
('yuv.max=', 220.43499999999997, 'yuv.min=', 18.462751999999995)
('yuv.max=', 192.34700000000001, 'yuv.min=', 6.7869999999999999)
('yuv.max=', 252.03199999999998, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 210.83399999999997, 'yuv.min=', 7.0279999999999996)
('yuv.max=', 174.45399999999998, 'yuv.min=', 23.167999999999999)
('yuv.max=', 255.0, 'yuv.min=', 52.668735999999996)
('yuv.max=', 232.69, 'yuv.min=', 77.218999999999994)
('yuv.max=', 255.0, 'yuv.min=', 5.1139999999999999)
('yuv.max=', 247.47299999999998, 'yuv.min=', 3.1139999999999999)
('yuv.max=', 206.459, 'yuv.min=', 7.7719999999999994)
('yuv.max=', 255.0, 'yuv.min=', 23.788999999999998)
('yuv.max=', 209.27799999999999, 'yuv.min=', 30.936)
('yuv.max=', 251.89699999999999, 'yuv.min=', 21.268999999999998)
('yuv.max=', 248.57999999999998, 'yuv.min=', 35.153999999999996)
('yuv.max=', 238.62999999999997, 'yuv.min=', 6.6519999999999992)
('yuv.max=', 248.76499999999999, 'yuv.min=', 7.3940000000000001)
('yuv.max=', 242.58899999999997, 'yuv.min=', 76.304999999999993)
('yuv.max=', 229.24700000000001, 'yuv.min=', 9.6230000000000011)
('yuv.max=', 252.886, 'yuv.min=', 11.544)
('yuv.max=', 254.886, 'yuv.min=', 16.231999999999999)
('yuv.max=', 227.36499999999998, 'yuv.min=', 30.843999999999998)
('yuv.max=', 245.69399999999999, 'yuv.min=', 3.8209999999999997)
('yuv.max=', 253.81499999999997, 'yuv.min=', 4.1029999999999998)
('yuv.max=', 254.886, 'yuv.min=', 22.097000000000001)
('yuv.max=', 240.53299999999999, 'yuv.min=', 34.905999999999999)
('yuv.max=', 253.80399999999997, 'yuv.min=', 1.972)
('yuv.max=', 236.67699999999999, 'yuv.min=', 32.628999999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', 18.271000000000001)
('yuv.max=', 232.071, 'yuv.min=', 58.968000000000004)
('yuv.max=', 218.14099999999999, 'yuv.min=', 6.032)
('yuv.max=', 229.63, 'yuv.min=', 18.259999999999998)
('yuv.max=', 148.74323200000001, 'yuv.min=', 45.769000000000005)
('yuv.max=', 208.17499999999998, 'yuv.min=', 21.586999999999996)
('yuv.max=', 250.017, 'yuv.min=', 46.009)
('yuv.max=', 243.42499999999995, 'yuv.min=', 9.1910000000000007)
('yuv.max=', 195.28199999999998, 'yuv.min=', 16.629999999999999)
('yuv.max=', 249.733, 'yuv.min=', 11.849)
('yuv.max=', 235.69399999999999, 'yuv.min=', 36.250999999999998)
('yuv.max=', 234.78099999999998, 'yuv.min=', 28.696999999999996)
('yuv.max=', 253.76100000000002, 'yuv.min=', 15.796999999999999)
('yuv.max=', 217.821, 'yuv.min=', 49.914999999999992)
('yuv.max=', 246.809, 'yuv.min=', 8.0350000000000001)
('yuv.max=', 237.89699999999999, 'yuv.min=', 6.3590000000000009)
('yuv.max=', 255.0, 'yuv.min=', 14.83)
('yuv.max=', 252.24699999999996, 'yuv.min=', 39.050999999999995)
('yuv.max=', 255.5, 'yuv.min=', 0.0)
('yuv.max=', 237.245, 'yuv.min=', 42.002000000000002)
('yuv.max=', 253.505, 'yuv.min=', 10.457999999999998)
('yuv.max=', 195.46599999999998, 'yuv.min=', 33.466999999999999)
('yuv.max=', 254.54400000000001, 'yuv.min=', 30.359999999999999)
('yuv.max=', 255.0, 'yuv.min=', 2.1959999999999997)
('yuv.max=', 250.62299999999999, 'yuv.min=', 24.844999999999999)
('yuv.max=', 244.47300000000001, 'yuv.min=', 24.631)
('yuv.max=', 254.70099999999999, 'yuv.min=', 28.749999999999996)
('yuv.max=', 246.38700000000003, 'yuv.min=', 8.9420000000000002)
('yuv.max=', 235.82599999999999, 'yuv.min=', 3.8259999999999996)
('yuv.max=', 207.23539199999999, 'yuv.min=', 13.983000000000001)
('yuv.max=', 251.08099999999999, 'yuv.min=', 21.064999999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', 13.9)
('yuv.max=', 255.0, 'yuv.min=', 87.752479999999991)
('yuv.max=', 237.06899999999999, 'yuv.min=', 16.925000000000001)
('yuv.max=', 248.81699999999998, 'yuv.min=', 28.357999999999997)
('yuv.max=', 253.99999999999997, 'yuv.min=', 28.786999999999999)
('yuv.max=', 239.559, 'yuv.min=', 15.901)
('yuv.max=', 255.0, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 221.291, 'yuv.min=', 16.753)
('yuv.max=', 250.43499999999997, 'yuv.min=', 7.0720000000000001)
('yuv.max=', 245.29999999999998, 'yuv.min=', 1.4729999999999999)
('yuv.max=', 193.99499999999998, 'yuv.min=', 5.4189999999999996)
('yuv.max=', 228.67899999999997, 'yuv.min=', 9.1630000000000003)
('yuv.max=', 241.09899999999999, 'yuv.min=', 19.605)
('yuv.max=', 203.96399999999997, 'yuv.min=', 22.073)
('yuv.max=', 253.12499999999997, 'yuv.min=', 1.794)
('yuv.max=', 248.97900000000001, 'yuv.min=', 62.164000000000001)
('yuv.max=', 230.316, 'yuv.min=', 17.503)
('yuv.max=', 229.524, 'yuv.min=', 17.997999999999998)
('yuv.max=', 239.88099999999997, 'yuv.min=', 3.7829999999999999)
('yuv.max=', 239.20599999999996, 'yuv.min=', 62.444999999999993)
('yuv.max=', 238.17399999999998, 'yuv.min=', 4.1739999999999995)
('yuv.max=', 226.65799999999999, 'yuv.min=', 15.097)
('yuv.max=', 253.64700000000002, 'yuv.min=', 42.287999999999997)
('yuv.max=', 227.30199999999999, 'yuv.min=', 4.109)
('yuv.max=', 205.68688, 'yuv.min=', 4.7009999999999996)
('yuv.max=', 229.505, 'yuv.min=', 7.0169999999999995)
('yuv.max=', 195.83499999999998, 'yuv.min=', 8.5869999999999997)
('yuv.max=', 255.0, 'yuv.min=', 37.306999999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 237.43899999999999, 'yuv.min=', 11.602)
('yuv.max=', 255.0, 'yuv.min=', 36.923999999999992)
('yuv.max=', 225.32300000000001, 'yuv.min=', 1.516)
('yuv.max=', 170.57999999999998, 'yuv.min=', 61.552)
('yuv.max=', 247.08999999999997, 'yuv.min=', 42.480999999999995)
('yuv.max=', 187.07300000000001, 'yuv.min=', 60.170000000000002)
('yuv.max=', 242.22399999999999, 'yuv.min=', 46.975999999999999)
('yuv.max=', 239.62200000000001, 'yuv.min=', 23.620999999999999)
('yuv.max=', 250.01000000000002, 'yuv.min=', 25.109000000000002)
('yuv.max=', 206.06999999999999, 'yuv.min=', 44.826999999999998)
('yuv.max=', 244.15699999999998, 'yuv.min=', 15.497999999999998)
('yuv.max=', 229.21000000000001, 'yuv.min=', 0.64100000000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', 66.876999999999995)
('yuv.max=', 234.928, 'yuv.min=', 27.978999999999999)
('yuv.max=', 249.11600000000001, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 162.24900000000002, 'yuv.min=', 9.8149999999999995)
('yuv.max=', 255.0, 'yuv.min=', 38.341999999999999)
('yuv.max=', 252.608, 'yuv.min=', 20.220999999999997)
('yuv.max=', 246.0, 'yuv.min=', 4.6900000000000004)
('yuv.max=', 241.65100000000001, 'yuv.min=', 9.2749999999999986)
('yuv.max=', 244.40499999999997, 'yuv.min=', 1.9660000000000002)
('yuv.max=', 179.917, 'yuv.min=', 65.573999999999998)
('yuv.max=', 235.92899999999997, 'yuv.min=', 33.102999999999994)
('yuv.max=', 195.11399999999998, 'yuv.min=', 15.912999999999997)
('yuv.max=', 211.85500000000002, 'yuv.min=', 10.478)
('yuv.max=', 226.96699999999998, 'yuv.min=', 45.981999999999992)
('yuv.max=', 235.18800000000002, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 234.99999999999997, 'yuv.min=', 7.0)
('yuv.max=', 205.756, 'yuv.min=', 16.462)
('yuv.max=', 255.0, 'yuv.min=', 27.875)
('yuv.max=', 248.73199999999997, 'yuv.min=', 46.190464000000006)
('yuv.max=', 225.40000000000001, 'yuv.min=', 11.237)
('yuv.max=', 244.43899999999999, 'yuv.min=', 36.799999999999997)
('yuv.max=', 252.00999999999999, 'yuv.min=', 72.498999999999995)
('yuv.max=', 248.10899999999998, 'yuv.min=', 62.332999999999998)
('yuv.max=', 255.0, 'yuv.min=', 56.888999999999996)
('yuv.max=', 221.423, 'yuv.min=', 11.586999999999998)
('yuv.max=', 247.35499999999999, 'yuv.min=', 29.704000000000001)
('yuv.max=', 255.0, 'yuv.min=', 36.116999999999997)
('yuv.max=', 226.29599999999999, 'yuv.min=', 14.984999999999999)
('yuv.max=', 201.99999999999997, 'yuv.min=', 34.031999999999996)
('yuv.max=', 247.86499999999998, 'yuv.min=', 50.42585600000001)
('yuv.max=', 221.13399999999999, 'yuv.min=', 17.396999999999998)
('yuv.max=', 255.0, 'yuv.min=', 46.341999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 22.636999999999997)
('yuv.max=', 253.0, 'yuv.min=', 46.146000000000001)
('yuv.max=', 243.74599999999998, 'yuv.min=', 45.402999999999999)
('yuv.max=', 162.774, 'yuv.min=', 51.881)
('yuv.max=', 194.113, 'yuv.min=', 27.850999999999999)
('yuv.max=', 223.71699999999998, 'yuv.min=', 24.757000000000001)
('yuv.max=', 231.51900000000001, 'yuv.min=', 8.2599999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 5.9719999999999995)
('yuv.max=', 250.08099999999996, 'yuv.min=', 36.173000000000002)
('yuv.max=', 255.0, 'yuv.min=', 13.731)
('yuv.max=', 255.0, 'yuv.min=', 35.216999999999999)
('yuv.max=', 244.29899999999998, 'yuv.min=', 18.762)
('yuv.max=', 237.07199999999997, 'yuv.min=', 66.960999999999999)
('yuv.max=', 247.38, 'yuv.min=', 52.451999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.114)
('yuv.max=', 224.62800000000001, 'yuv.min=', 47.064999999999991)
('yuv.max=', 211.958, 'yuv.min=', 29.839000000000002)
('yuv.max=', 255.0, 'yuv.min=', 30.413999999999998)
('yuv.max=', 255.0, 'yuv.min=', 20.597000000000001)
('yuv.max=', 210.64699999999999, 'yuv.min=', 8.9009999999999998)
('yuv.max=', 242.57599999999996, 'yuv.min=', 5.5529999999999999)
('yuv.max=', 230.53800000000001, 'yuv.min=', 28.619)
('yuv.max=', 253.78899999999999, 'yuv.min=', 13.571999999999999)
('yuv.max=', 253.071, 'yuv.min=', 9.113999999999999)
('yuv.max=', 239.31599999999997, 'yuv.min=', 19.116)
('yuv.max=', 228.80500000000001, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 255.0, 'yuv.min=', 57.281999999999996)
('yuv.max=', 251.989, 'yuv.min=', 18.625999999999998)
('yuv.max=', 255.0, 'yuv.min=', 23.919999999999998)
('yuv.max=', 255.0, 'yuv.min=', 21.794)
('yuv.max=', 239.42999999999998, 'yuv.min=', 8.6469999999999985)
('yuv.max=', 234.13499999999999, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 248.309, 'yuv.min=', 13.599)
('yuv.max=', 240.505, 'yuv.min=', 14.471)
('yuv.max=', 156.01600000000002, 'yuv.min=', 2.77)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 238.49199999999999, 'yuv.min=', 48.652999999999992)
('yuv.max=', 200.453, 'yuv.min=', 3.6299999999999999)
('yuv.max=', 237.99100000000001, 'yuv.min=', 32.760999999999996)
('yuv.max=', 255.0, 'yuv.min=', 34.826000000000001)
('yuv.max=', 253.99999999999997, 'yuv.min=', 3.8859999999999997)
('yuv.max=', 247.559, 'yuv.min=', 31.951000000000001)
('yuv.max=', 221.81670399999999, 'yuv.min=', 42.157440000000001)
('yuv.max=', 229.86899999999997, 'yuv.min=', 58.802999999999997)
('yuv.max=', 255.0, 'yuv.min=', 10.985000000000001)
('yuv.max=', 217.90099999999998, 'yuv.min=', 91.527000000000001)
('yuv.max=', 233.56999999999999, 'yuv.min=', 26.130999999999997)
('yuv.max=', 234.38300000000001, 'yuv.min=', 31.946000000000002)
('yuv.max=', 215.13099999999997, 'yuv.min=', 33.089999999999996)
('yuv.max=', 247.0, 'yuv.min=', 51.999999999999993)
('yuv.max=', 222.52067199999999, 'yuv.min=', 21.294)
('yuv.max=', 254.40199999999999, 'yuv.min=', 17.966000000000001)
('yuv.max=', 141.36851200000001, 'yuv.min=', 10.733000000000001)
('yuv.max=', 249.17399999999998, 'yuv.min=', 59.98899999999999)
('yuv.max=', 248.48799999999997, 'yuv.min=', 2.6799999999999997)
('yuv.max=', 236.68599999999998, 'yuv.min=', 38.010999999999996)
('yuv.max=', 242.52200000000002, 'yuv.min=', 45.896999999999998)
('yuv.max=', 224.476, 'yuv.min=', 24.491)
('yuv.max=', 187.617952, 'yuv.min=', 23.033999999999999)
('yuv.max=', 244.50799999999998, 'yuv.min=', 32.262)
('yuv.max=', 251.626, 'yuv.min=', 17.637)
('yuv.max=', 243.17399999999998, 'yuv.min=', 40.754999999999995)
('yuv.max=', 208.02425600000001, 'yuv.min=', 27.184999999999995)
('yuv.max=', 202.06900000000002, 'yuv.min=', 44.016999999999996)
('yuv.max=', 247.37, 'yuv.min=', 32.619)
('yuv.max=', 236.73999999999998, 'yuv.min=', 38.313000000000002)
('yuv.max=', 233.71099999999998, 'yuv.min=', 28.212)
('yuv.max=', 248.22800000000001, 'yuv.min=', 16.869)
('yuv.max=', 213.67099999999999, 'yuv.min=', 17.661999999999999)
('yuv.max=', 244.95699999999999, 'yuv.min=', 9.6149999999999984)
('yuv.max=', 253.60399999999998, 'yuv.min=', 16.126999999999999)
('yuv.max=', 228.91199999999998, 'yuv.min=', 44.869)
('yuv.max=', 149.11174399999999, 'yuv.min=', 4.6239999999999997)
('yuv.max=', 205.60999999999999, 'yuv.min=', 20.893999999999998)
('yuv.max=', 224.202, 'yuv.min=', 27.725999999999999)
('yuv.max=', 250.20199999999997, 'yuv.min=', 14.423)
('yuv.max=', 253.63200000000001, 'yuv.min=', 36.433999999999997)
('yuv.max=', 206.85799999999998, 'yuv.min=', 14.764999999999999)
('yuv.max=', 168.94099999999997, 'yuv.min=', 46.960999999999999)
('yuv.max=', 240.65799999999999, 'yuv.min=', 24.382999999999999)
('yuv.max=', 224.584, 'yuv.min=', 51.775999999999996)
('yuv.max=', 241.52000000000001, 'yuv.min=', 0.0)
('yuv.max=', 168.11999999999998, 'yuv.min=', 7.6300000000000008)
('yuv.max=', 188.267, 'yuv.min=', 15.728999999999999)
('yuv.max=', 238.47299999999998, 'yuv.min=', 13.619999999999999)
('yuv.max=', 255.0, 'yuv.min=', 74.442000000000007)
('yuv.max=', 195.34799999999998, 'yuv.min=', 17.471999999999998)
('yuv.max=', 218.31999999999999, 'yuv.min=', 27.097000000000001)
('yuv.max=', 238.41299999999998, 'yuv.min=', 48.678335999999987)
('yuv.max=', 238.28999999999999, 'yuv.min=', 14.847999999999999)
('yuv.max=', 209.74099999999999, 'yuv.min=', 21.099)
('yuv.max=', 180.42499999999998, 'yuv.min=', 45.689999999999998)
('yuv.max=', 221.32499999999999, 'yuv.min=', 42.717999999999996)
('yuv.max=', 189.82499999999999, 'yuv.min=', 40.944000000000003)
('yuv.max=', 242.0, 'yuv.min=', 5.0)
('yuv.max=', 235.99999999999997, 'yuv.min=', 50.0)
('yuv.max=', 253.67500000000001, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 219.16, 'yuv.min=', 60.169999999999995)
('yuv.max=', 209.977, 'yuv.min=', 0.0)
('yuv.max=', 242.06099999999998, 'yuv.min=', 28.525000000000002)
('yuv.max=', 253.63200000000001, 'yuv.min=', 33.719999999999999)
('yuv.max=', 244.624, 'yuv.min=', 8.7469999999999999)
('yuv.max=', 203.83500000000001, 'yuv.min=', 11.215)
('yuv.max=', 211.02100000000002, 'yuv.min=', 0.0)
('yuv.max=', 228.95299999999997, 'yuv.min=', 7.9189999999999996)
('yuv.max=', 250.38200000000001, 'yuv.min=', 1.353)
('yuv.max=', 219.65299999999999, 'yuv.min=', 56.713000000000001)
('yuv.max=', 255.0, 'yuv.min=', 8.032)
('yuv.max=', 233.54199999999997, 'yuv.min=', 11.67)
('yuv.max=', 247.875, 'yuv.min=', 26.893999999999998)
('yuv.max=', 223.44599999999997, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 251.16900000000001, 'yuv.min=', 10.06)
('yuv.max=', 255.0, 'yuv.min=', 13.558999999999999)
('yuv.max=', 212.10500000000002, 'yuv.min=', 46.718000000000004)
('yuv.max=', 255.0, 'yuv.min=', 1.3419999999999999)
('yuv.max=', 168.32524800000002, 'yuv.min=', 21.010000000000002)
('yuv.max=', 255.0, 'yuv.min=', 7.0540000000000003)
('yuv.max=', 248.74299999999999, 'yuv.min=', 11.651)
('yuv.max=', 235.477, 'yuv.min=', 19.914999999999999)
('yuv.max=', 250.81100000000001, 'yuv.min=', 0.0)
('yuv.max=', 214.78899999999999, 'yuv.min=', 20.98)
('yuv.max=', 200.48299999999998, 'yuv.min=', 25.152000000000001)
('yuv.max=', 255.0, 'yuv.min=', 37.661000000000001)
('yuv.max=', 249.91699999999997, 'yuv.min=', 14.328999999999999)
('yuv.max=', 244.81500000000003, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 246.03399999999999, 'yuv.min=', 0.0)
('yuv.max=', 252.60599999999999, 'yuv.min=', 26.671999999999997)
('yuv.max=', 187.595, 'yuv.min=', 1.4729999999999999)
('yuv.max=', 212.66099999999997, 'yuv.min=', 25.910999999999998)
('yuv.max=', 232.24499999999998, 'yuv.min=', 19.342999999999996)
('yuv.max=', 213.24799999999999, 'yuv.min=', 43.245000000000005)
('yuv.max=', 185.39299999999997, 'yuv.min=', 46.733000000000004)
('yuv.max=', 167.94921600000001, 'yuv.min=', 26.651)
('yuv.max=', 249.13199999999998, 'yuv.min=', 5.9799999999999995)
('yuv.max=', 249.82599999999999, 'yuv.min=', 5.6689999999999996)
('yuv.max=', 225.852, 'yuv.min=', 41.661000000000001)
('yuv.max=', 254.316, 'yuv.min=', 11.489999999999998)
('yuv.max=', 254.41299999999995, 'yuv.min=', 77.49499999999999)
('yuv.max=', 237.45600000000002, 'yuv.min=', 31.524000000000001)
('yuv.max=', 207.32599999999999, 'yuv.min=', 34.270999999999994)
('yuv.max=', 198.34700000000001, 'yuv.min=', 34.259999999999998)
('yuv.max=', 231.14999999999998, 'yuv.min=', 28.749999999999996)
('yuv.max=', 255.0, 'yuv.min=', 20.288)
('yuv.max=', 248.66900000000001, 'yuv.min=', 27.809000000000001)
('yuv.max=', 248.815, 'yuv.min=', 21.335999999999999)
('yuv.max=', 249.125, 'yuv.min=', 0.71199999999999997)
('yuv.max=', 210.04500000000002, 'yuv.min=', 26.268000000000001)
('yuv.max=', 191.98299999999998, 'yuv.min=', 0.0)
('yuv.max=', 212.72399999999999, 'yuv.min=', 45.579999999999998)
('yuv.max=', 231.44499999999999, 'yuv.min=', 30.122)
('yuv.max=', 227.117696, 'yuv.min=', 6.8369999999999989)
('yuv.max=', 248.89699999999999, 'yuv.min=', 8.2940000000000005)
('yuv.max=', 250.02800000000002, 'yuv.min=', 55.362999999999992)
('yuv.max=', 243.54399999999998, 'yuv.min=', 0.0)
('yuv.max=', 246.886, 'yuv.min=', 106.61899999999999)
('yuv.max=', 242.83999999999997, 'yuv.min=', 0.0)
('yuv.max=', 247.28100000000001, 'yuv.min=', 67.420999999999992)
('yuv.max=', 241.94999999999999, 'yuv.min=', 45.459999999999994)
('yuv.max=', 236.11099999999999, 'yuv.min=', 6.0490000000000004)
('yuv.max=', 255.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 240.56999999999999, 'yuv.min=', 52.109151999999995)
('yuv.max=', 254.06, 'yuv.min=', 25.960999999999999)
('yuv.max=', 201.756, 'yuv.min=', 61.957999999999998)
('yuv.max=', 227.08799999999999, 'yuv.min=', 15.653)
('yuv.max=', 255.0, 'yuv.min=', 49.020999999999994)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 226.303, 'yuv.min=', 0.0)
('yuv.max=', 247.142, 'yuv.min=', 48.960000000000001)
('yuv.max=', 206.09999999999999, 'yuv.min=', 11.48)
('yuv.max=', 182.89400000000001, 'yuv.min=', 31.211999999999996)
('yuv.max=', 251.45599999999996, 'yuv.min=', 10.085999999999999)
('yuv.max=', 253.01699999999997, 'yuv.min=', 4.3170000000000002)
('yuv.max=', 150.06207999999998, 'yuv.min=', 6.2539999999999996)
('yuv.max=', 255.0, 'yuv.min=', 6.0490000000000004)
('yuv.max=', 233.95299999999997, 'yuv.min=', 10.92)
('yuv.max=', 235.25299999999999, 'yuv.min=', 7.2599999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 72.619072000000003)
('yuv.max=', 255.0, 'yuv.min=', 38.068999999999996)
('yuv.max=', 254.29899999999995, 'yuv.min=', 17.725999999999999)
('yuv.max=', 253.333, 'yuv.min=', 1.875)
('yuv.max=', 253.17399999999998, 'yuv.min=', 0.0)
('yuv.max=', 193.07999999999998, 'yuv.min=', 0.0)
('yuv.max=', 238.923, 'yuv.min=', 19.640999999999998)
('yuv.max=', 234.108, 'yuv.min=', 31.183)
('yuv.max=', 250.69999999999999, 'yuv.min=', 12.113999999999999)
('yuv.max=', 238.65899999999999, 'yuv.min=', 23.635999999999996)
('yuv.max=', 253.99999999999997, 'yuv.min=', 9.754999999999999)
('yuv.max=', 215.88599999999997, 'yuv.min=', 0.0)
('yuv.max=', 245.54199999999997, 'yuv.min=', 0.8859999999999999)
('yuv.max=', 215.73899999999998, 'yuv.min=', 44.484999999999999)
('yuv.max=', 250.90899999999999, 'yuv.min=', 7.516)
('yuv.max=', 254.40199999999999, 'yuv.min=', 2.3529999999999998)
('yuv.max=', 202.554, 'yuv.min=', 6.2990000000000004)
('yuv.max=', 255.0, 'yuv.min=', 117.68688)
('yuv.max=', 209.60499999999999, 'yuv.min=', 23.198999999999998)
('yuv.max=', 194.55700000000002, 'yuv.min=', 26.52)
('yuv.max=', 216.37699999999998, 'yuv.min=', 24.25)
('yuv.max=', 228.75299999999999, 'yuv.min=', 34.352999999999994)
('yuv.max=', 255.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 244.053, 'yuv.min=', 21.670999999999999)
('yuv.max=', 254.316, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 255.0, 'yuv.min=', 16.597999999999999)
('yuv.max=', 252.31, 'yuv.min=', 22.449000000000002)
('yuv.max=', 239.864, 'yuv.min=', 11.575999999999999)
('yuv.max=', 242.22800000000001, 'yuv.min=', 28.289000000000001)
('yuv.max=', 235.608, 'yuv.min=', 106.769184)
('yuv.max=', 246.46599999999998, 'yuv.min=', 33.330999999999996)
('yuv.max=', 207.61000000000001, 'yuv.min=', 7.9439999999999991)
('yuv.max=', 194.35899999999998, 'yuv.min=', 57.760999999999996)
('yuv.max=', 245.989, 'yuv.min=', 56.314)
('yuv.max=', 231.024, 'yuv.min=', 13.032)
('yuv.max=', 255.0, 'yuv.min=', 75.370000000000005)
('yuv.max=', 239.41499999999996, 'yuv.min=', 34.506999999999998)
('yuv.max=', 251.327, 'yuv.min=', 12.999999999999998)
('yuv.max=', 230.76600000000002, 'yuv.min=', 35.015000000000001)
('yuv.max=', 255.0, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', 17.0)
('yuv.max=', 186.69799999999998, 'yuv.min=', 21.728999999999999)
('yuv.max=', 248.142, 'yuv.min=', 17.683999999999997)
('yuv.max=', 240.30499999999998, 'yuv.min=', 32.751999999999995)
('yuv.max=', 251.90299999999999, 'yuv.min=', 10.949999999999999)
('yuv.max=', 251.07299999999998, 'yuv.min=', 15.682)
('yuv.max=', 219.886, 'yuv.min=', 38.555999999999997)
('yuv.max=', 254.08800000000002, 'yuv.min=', 16.370999999999999)
('yuv.max=', 235.94999999999999, 'yuv.min=', 3.9349999999999996)
('yuv.max=', 218.91499999999999, 'yuv.min=', 7.9829999999999997)
('yuv.max=', 206.64999999999998, 'yuv.min=', 22.216000000000001)
('yuv.max=', 211.91699999999997, 'yuv.min=', 40.680999999999997)
('yuv.max=', 254.47300000000001, 'yuv.min=', 8.5269999999999992)
('yuv.max=', 251.54399999999998, 'yuv.min=', 53.170999999999999)
('yuv.max=', 255.0, 'yuv.min=', 15.282)
('yuv.max=', 252.04899999999998, 'yuv.min=', 10.864000000000001)
('yuv.max=', 206.18700000000001, 'yuv.min=', 16.271000000000001)
('yuv.max=', 232.80500000000001, 'yuv.min=', 0.68400000000000005)
('yuv.max=', 247.762, 'yuv.min=', 5.754999999999999)
('yuv.max=', 184.655, 'yuv.min=', 9.6579999999999995)
('yuv.max=', 222.41799999999995, 'yuv.min=', 17.760999999999999)
('yuv.max=', 255.0, 'yuv.min=', 52.640999999999998)
('yuv.max=', 255.0, 'yuv.min=', 22.118000000000002)
('yuv.max=', 214.62400000000002, 'yuv.min=', 25.619)
('yuv.max=', 255.0, 'yuv.min=', 28.012999999999998)
('yuv.max=', 255.0, 'yuv.min=', 41.231999999999999)
('yuv.max=', 245.08599999999998, 'yuv.min=', 9.6280000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 237.27099999999999, 'yuv.min=', 8.9289999999999985)
('yuv.max=', 189.81200000000001, 'yuv.min=', 12.771999999999998)
('yuv.max=', 205.58099999999999, 'yuv.min=', 34.972999999999999)
('yuv.max=', 197.72900000000001, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 251.92899999999995, 'yuv.min=', 14.718)
('yuv.max=', 199.36799999999999, 'yuv.min=', 38.097999999999999)
('yuv.max=', 227.14599999999999, 'yuv.min=', 15.225)
('yuv.max=', 192.24099999999999, 'yuv.min=', 29.224999999999998)
('yuv.max=', 252.61500000000001, 'yuv.min=', 30.914999999999996)
('yuv.max=', 220.57799999999997, 'yuv.min=', 21.418999999999997)
('yuv.max=', 255.0, 'yuv.min=', 27.768000000000001)
('yuv.max=', 245.62899999999999, 'yuv.min=', 34.429000000000002)
('yuv.max=', 250.29899999999998, 'yuv.min=', 83.390999999999991)
('yuv.max=', 248.989, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 100.0)
('yuv.max=', 218.99600000000001, 'yuv.min=', 32.161999999999999)
('yuv.max=', 248.27699999999999, 'yuv.min=', 60.862000000000002)
('yuv.max=', 245.672, 'yuv.min=', 9.7349999999999994)
('yuv.max=', 242.58100000000002, 'yuv.min=', 17.82)
('yuv.max=', 240.72800000000001, 'yuv.min=', 31.284000000000002)
('yuv.max=', 255.0, 'yuv.min=', 2.093)
('yuv.max=', 248.91399999999999, 'yuv.min=', 15.218)
('yuv.max=', 254.10300000000001, 'yuv.min=', 31.021000000000001)
('yuv.max=', 237.45999999999998, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 184.113, 'yuv.min=', 15.484)
('yuv.max=', 225.82599999999996, 'yuv.min=', 31.870999999999999)
('yuv.max=', 252.65799999999999, 'yuv.min=', 7.5269999999999992)
('yuv.max=', 248.84700000000001, 'yuv.min=', 17.747999999999998)
('yuv.max=', 226.05800000000002, 'yuv.min=', 4.472999999999999)
('yuv.max=', 255.0, 'yuv.min=', 14.593999999999999)
('yuv.max=', 250.136, 'yuv.min=', 92.771999999999991)
('yuv.max=', 244.32699999999997, 'yuv.min=', 43.082000000000001)
('yuv.max=', 251.37799999999999, 'yuv.min=', 34.798000000000002)
('yuv.max=', 252.71799999999996, 'yuv.min=', 34.244999999999997)
('yuv.max=', 255.0, 'yuv.min=', 25.635999999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', 80.155999999999992)
('yuv.max=', 253.81499999999997, 'yuv.min=', 0.0)
('yuv.max=', 220.684, 'yuv.min=', 9.9049999999999994)
('yuv.max=', 248.81699999999998, 'yuv.min=', 3.4019999999999997)
('yuv.max=', 247.00200000000001, 'yuv.min=', 20.991)
('yuv.max=', 216.23699999999999, 'yuv.min=', 5.1469999999999994)
('yuv.max=', 197.899, 'yuv.min=', 30.412999999999997)
('yuv.max=', 245.07399999999998, 'yuv.min=', 34.732999999999997)
('yuv.max=', 239.19999999999999, 'yuv.min=', 11.606999999999999)
('yuv.max=', 211.73600000000002, 'yuv.min=', 9.4409999999999989)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 197.51862400000002, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 247.33099999999999, 'yuv.min=', 23.949999999999999)
('yuv.max=', 248.71199999999999, 'yuv.min=', 22.739999999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', 77.361999999999995)
('yuv.max=', 185.69299999999998, 'yuv.min=', 32.853999999999999)
('yuv.max=', 242.30200000000002, 'yuv.min=', 18.899999999999999)
('yuv.max=', 234.04900000000001, 'yuv.min=', 15.629999999999999)
('yuv.max=', 238.506, 'yuv.min=', 40.091000000000001)
('yuv.max=', 191.68100000000001, 'yuv.min=', 32.622999999999998)
('yuv.max=', 248.29899999999998, 'yuv.min=', 36.064999999999998)
('yuv.max=', 167.434, 'yuv.min=', 24.106999999999999)
('yuv.max=', 236.47800000000001, 'yuv.min=', 63.161000000000001)
('yuv.max=', 160.45099999999999, 'yuv.min=', 43.680999999999997)
('yuv.max=', 243.15699999999998, 'yuv.min=', 9.641)
('yuv.max=', 233.03699999999998, 'yuv.min=', 32.884)
('yuv.max=', 255.0, 'yuv.min=', 18.305)
('yuv.max=', 252.93999999999997, 'yuv.min=', 0.0)
('yuv.max=', 253.97400000000002, 'yuv.min=', 50.861999999999995)
('yuv.max=', 255.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 252.41899999999998, 'yuv.min=', 31.393999999999998)
('yuv.max=', 253.41900000000001, 'yuv.min=', 0.0)
('yuv.max=', 196.72199999999998, 'yuv.min=', 25.565000000000001)
('yuv.max=', 241.76499999999999, 'yuv.min=', 31.635999999999999)
('yuv.max=', 244.33100000000002, 'yuv.min=', 14.178999999999998)
('yuv.max=', 255.0, 'yuv.min=', 22.042999999999999)
('yuv.max=', 206.80599999999998, 'yuv.min=', 52.937999999999995)
('yuv.max=', 253.50099999999998, 'yuv.min=', 50.169999999999995)
('yuv.max=', 242.143, 'yuv.min=', 42.408999999999992)
('yuv.max=', 255.0, 'yuv.min=', 51.565999999999995)
('yuv.max=', 232.83399999999997, 'yuv.min=', 79.712000000000003)
('yuv.max=', 254.07099999999997, 'yuv.min=', 0.0)
('yuv.max=', 247.15299999999996, 'yuv.min=', 23.523)
('yuv.max=', 242.0, 'yuv.min=', 49.0)
('yuv.max=', 245.185, 'yuv.min=', 0.8859999999999999)
('yuv.max=', 236.74599999999998, 'yuv.min=', 20.646999999999998)
('yuv.max=', 250.505, 'yuv.min=', 13.661999999999999)
('yuv.max=', 238.41200000000001, 'yuv.min=', 70.278000000000006)
('yuv.max=', 222.45299999999997, 'yuv.min=', 23.359000000000002)
('yuv.max=', 255.0, 'yuv.min=', 41.847000000000001)
('yuv.max=', 255.0, 'yuv.min=', 30.673999999999999)
('yuv.max=', 254.886, 'yuv.min=', 8.2929999999999993)
('yuv.max=', 206.41, 'yuv.min=', 35.661999999999999)
('yuv.max=', 243.99999999999997, 'yuv.min=', 25.0)
('yuv.max=', 235.98299999999998, 'yuv.min=', 69.046999999999997)
('yuv.max=', 250.22999999999999, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 239.56599999999997, 'yuv.min=', 4.5270000000000001)
('yuv.max=', 225.49000000000001, 'yuv.min=', 6.5549999999999988)
('yuv.max=', 214.91799999999998, 'yuv.min=', 58.635000000000005)
('yuv.max=', 253.77199999999999, 'yuv.min=', 13.833)
('yuv.max=', 237.50999999999996, 'yuv.min=', 2.4950000000000001)
('yuv.max=', 241.70499999999998, 'yuv.min=', 8.9679999999999982)
('yuv.max=', 203.41799999999998, 'yuv.min=', 16.448999999999998)
('yuv.max=', 248.99999999999997, 'yuv.min=', 24.288)
('yuv.max=', 248.99999999999997, 'yuv.min=', 117.0)
('yuv.max=', 189.05600000000001, 'yuv.min=', 53.200000000000003)
('yuv.max=', 237.32799999999997, 'yuv.min=', 16.234999999999999)
('yuv.max=', 252.81499999999997, 'yuv.min=', 21.999999999999996)
('yuv.max=', 255.0, 'yuv.min=', 12.74)
('yuv.max=', 174.95499999999998, 'yuv.min=', 33.857999999999997)
('yuv.max=', 238.00899999999999, 'yuv.min=', 50.941999999999993)
('yuv.max=', 232.93899999999996, 'yuv.min=', 47.884)
('yuv.max=', 255.0, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 251.53299999999999, 'yuv.min=', 40.505000000000003)
('yuv.max=', 233.977, 'yuv.min=', 0.0)
('yuv.max=', 238.37699999999998, 'yuv.min=', 13.238)
('yuv.max=', 192.637, 'yuv.min=', 18.388999999999999)
('yuv.max=', 247.77200000000002, 'yuv.min=', 0.0)
('yuv.max=', 217.441, 'yuv.min=', 10.044)
('yuv.max=', 254.886, 'yuv.min=', 34.146000000000001)
('yuv.max=', 206.0, 'yuv.min=', 0.0)
('yuv.max=', 156.15199999999999, 'yuv.min=', 53.802)
('yuv.max=', 204.86499999999998, 'yuv.min=', 36.884999999999998)
('yuv.max=', 200.86599999999999, 'yuv.min=', 33.927)
('yuv.max=', 247.42599999999999, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 228.63999999999999, 'yuv.min=', 43.792999999999999)
('yuv.max=', 246.04900000000001, 'yuv.min=', 2.968)
('yuv.max=', 158.86699999999999, 'yuv.min=', 38.220999999999997)
('yuv.max=', 250.929, 'yuv.min=', 42.555)
('yuv.max=', 242.68999999999997, 'yuv.min=', 39.890000000000001)
('yuv.max=', 245.91800000000001, 'yuv.min=', 7.4729999999999999)
('yuv.max=', 249.28799999999998, 'yuv.min=', 12.234)
('yuv.max=', 210.357, 'yuv.min=', 0.0)
('yuv.max=', 224.31299999999999, 'yuv.min=', 15.885999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 6.0)
('yuv.max=', 245.79300000000001, 'yuv.min=', 0.0)
('yuv.max=', 229.04599999999999, 'yuv.min=', 29.987999999999996)
('yuv.max=', 250.131, 'yuv.min=', 5.2989999999999995)
('yuv.max=', 254.202, 'yuv.min=', 0.0)
('yuv.max=', 224.30500000000001, 'yuv.min=', 19.884999999999998)
('yuv.max=', 211.273, 'yuv.min=', 15.544999999999998)
('yuv.max=', 227.0, 'yuv.min=', 18.678999999999998)
('yuv.max=', 251.05999999999997, 'yuv.min=', 31.789000000000001)
('yuv.max=', 149.23702400000002, 'yuv.min=', 13.917999999999999)
('yuv.max=', 247.05899999999997, 'yuv.min=', 30.725999999999999)
('yuv.max=', 237.75399999999999, 'yuv.min=', 6.1260000000000003)
('yuv.max=', 229.47999999999999, 'yuv.min=', 60.277000000000001)
('yuv.max=', 253.95699999999997, 'yuv.min=', 37.067999999999998)
('yuv.max=', 252.0, 'yuv.min=', 55.0)
('yuv.max=', 239.84299999999999, 'yuv.min=', 28.603999999999999)
('yuv.max=', 241.16799999999998, 'yuv.min=', 50.589999999999996)
('yuv.max=', 213.63, 'yuv.min=', 52.104999999999997)
('yuv.max=', 247.441, 'yuv.min=', 24.960999999999999)
('yuv.max=', 190.35199999999998, 'yuv.min=', 29.147000000000002)
('yuv.max=', 212.66099999999997, 'yuv.min=', 29.307999999999996)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 189.14099999999999, 'yuv.min=', 12.022)
('yuv.max=', 251.28799999999998, 'yuv.min=', 37.768999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.90699999999998, 'yuv.min=', 18.206)
('yuv.max=', 225.03299999999999, 'yuv.min=', 30.991999999999997)
('yuv.max=', 251.69400000000002, 'yuv.min=', 7.0)
('yuv.max=', 231.70599999999999, 'yuv.min=', 62.229999999999997)
('yuv.max=', 252.64099999999996, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 241.49899999999997, 'yuv.min=', 37.885999999999996)
('yuv.max=', 169.755, 'yuv.min=', 19.085999999999999)
('yuv.max=', 247.33099999999999, 'yuv.min=', 15.835999999999999)
('yuv.max=', 250.501, 'yuv.min=', 12.472999999999999)
('yuv.max=', 191.774, 'yuv.min=', 11.081999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 239.25999999999999, 'yuv.min=', 37.604999999999997)
('yuv.max=', 255.0, 'yuv.min=', 72.685999999999993)
('yuv.max=', 229.63899999999998, 'yuv.min=', 13.032999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 26.015000000000001)
('yuv.max=', 232.50399999999999, 'yuv.min=', 9.6579999999999995)
('yuv.max=', 229.85099999999997, 'yuv.min=', 16.807000000000002)
('yuv.max=', 255.0, 'yuv.min=', 3.3570000000000002)
('yuv.max=', 251.57599999999999, 'yuv.min=', 73.564999999999998)
('yuv.max=', 207.273, 'yuv.min=', 8.6739999999999995)
('yuv.max=', 252.114, 'yuv.min=', 6.2429999999999994)
('yuv.max=', 196.22199999999998, 'yuv.min=', 20.412999999999997)
('yuv.max=', 252.31999999999999, 'yuv.min=', 20.309999999999999)
('yuv.max=', 255.0, 'yuv.min=', 36.734999999999999)
('yuv.max=', 229.57772799999998, 'yuv.min=', 8.5279999999999987)
('yuv.max=', 238.99999999999997, 'yuv.min=', 10.999999999999998)
('yuv.max=', 203.581312, 'yuv.min=', 2.9899999999999998)
('yuv.max=', 252.78899999999999, 'yuv.min=', 35.43)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.114)
('yuv.max=', 236.05299999999997, 'yuv.min=', 55.878999999999998)
('yuv.max=', 173.524832, 'yuv.min=', 4.8479999999999999)
('yuv.max=', 249.00200000000001, 'yuv.min=', 7.1849999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 212.80199999999996, 'yuv.min=', 3.6689999999999996)
('yuv.max=', 254.41299999999995, 'yuv.min=', 8.0860000000000003)
('yuv.max=', 188.03099999999998, 'yuv.min=', 5.2429999999999994)
('yuv.max=', 226.29399999999998, 'yuv.min=', 19.834)
('yuv.max=', 212.178, 'yuv.min=', 89.764999999999986)
('yuv.max=', 229.51499999999999, 'yuv.min=', 24.152999999999999)
('yuv.max=', 214.45599999999999, 'yuv.min=', 22.523)
('yuv.max=', 181.92899999999997, 'yuv.min=', 22.988999999999997)
('yuv.max=', 219.327, 'yuv.min=', 17.635000000000002)
('yuv.max=', 247.53700000000001, 'yuv.min=', 4.8970000000000002)
('yuv.max=', 255.0, 'yuv.min=', 69.0)
('yuv.max=', 223.78700000000001, 'yuv.min=', 23.768000000000001)
('yuv.max=', 244.18499999999997, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 181.774272, 'yuv.min=', 45.990999999999993)
('yuv.max=', 255.0, 'yuv.min=', 10.053999999999998)
('yuv.max=', 192.18099999999998, 'yuv.min=', 25.492999999999995)
('yuv.max=', 255.0, 'yuv.min=', 47.311999999999998)
('yuv.max=', 233.0, 'yuv.min=', 35.0)
('yuv.max=', 236.233, 'yuv.min=', 21.692999999999998)
('yuv.max=', 205.24299999999999, 'yuv.min=', 51.231999999999999)
('yuv.max=', 242.55699999999999, 'yuv.min=', 22.356999999999999)
('yuv.max=', 231.25899999999999, 'yuv.min=', 16.087)
('yuv.max=', 255.0, 'yuv.min=', 65.320999999999998)
('yuv.max=', 234.99399999999997, 'yuv.min=', 35.93)
('yuv.max=', 184.193568, 'yuv.min=', 7.9389999999999992)
('yuv.max=', 255.0, 'yuv.min=', 37.960999999999999)
('yuv.max=', 250.01099999999997, 'yuv.min=', 27.056999999999999)
('yuv.max=', 180.882304, 'yuv.min=', 63.742999999999995)
('yuv.max=', 243.45199999999997, 'yuv.min=', 29.543999999999997)
('yuv.max=', 253.20599999999999, 'yuv.min=', 64.231000000000009)
('yuv.max=', 203.09312, 'yuv.min=', 10.391)
('yuv.max=', 252.47299999999998, 'yuv.min=', 68.287807999999998)
('yuv.max=', 254.58699999999999, 'yuv.min=', 67.411999999999992)
('yuv.max=', 251.48399999999998, 'yuv.min=', 7.2279999999999998)
('yuv.max=', 211.66699999999997, 'yuv.min=', 15.875999999999999)
('yuv.max=', 206.07199999999997, 'yuv.min=', 94.365216000000004)
('yuv.max=', 255.0, 'yuv.min=', 16.700999999999997)
('yuv.max=', 255.0, 'yuv.min=', 11.75)
('yuv.max=', 222.41900000000001, 'yuv.min=', 39.600999999999999)
('yuv.max=', 239.36099999999999, 'yuv.min=', 66.131999999999991)
('yuv.max=', 226.17475200000001, 'yuv.min=', 67.275999999999996)
('yuv.max=', 232.08199999999997, 'yuv.min=', 15.070999999999998)
('yuv.max=', 255.0, 'yuv.min=', 31.484000000000002)
('yuv.max=', 240.49900000000002, 'yuv.min=', 39.368000000000002)
('yuv.max=', 237.13299999999998, 'yuv.min=', 33.994999999999997)
('yuv.max=', 242.19999999999999, 'yuv.min=', 51.86399999999999)
('yuv.max=', 221.41399999999999, 'yuv.min=', 53.013999999999996)
('yuv.max=', 236.49399999999997, 'yuv.min=', 28.596999999999998)
('yuv.max=', 245.33099999999996, 'yuv.min=', 0.0)
('yuv.max=', 250.01099999999997, 'yuv.min=', 5.6040000000000001)
('yuv.max=', 218.57499999999999, 'yuv.min=', 56.403999999999996)
('yuv.max=', 253.886, 'yuv.min=', 30.277000000000001)
('yuv.max=', 241.715, 'yuv.min=', 12.178000000000001)
('yuv.max=', 184.839, 'yuv.min=', 16.173999999999999)
('yuv.max=', 237.596, 'yuv.min=', 19.710999999999999)
('yuv.max=', 235.57599999999999, 'yuv.min=', 16.196000000000002)
('yuv.max=', 246.33099999999999, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 25.334999999999997)
('yuv.max=', 255.0, 'yuv.min=', 9.0489999999999995)
('yuv.max=', 248.804, 'yuv.min=', 10.348000000000001)
('yuv.max=', 199.14199999999997, 'yuv.min=', 15.353999999999999)
('yuv.max=', 221.988, 'yuv.min=', 35.842999999999996)
('yuv.max=', 234.28800000000001, 'yuv.min=', 29.517999999999997)
('yuv.max=', 210.5, 'yuv.min=', 2.6219999999999999)
('yuv.max=', 255.0, 'yuv.min=', 24.109999999999996)
('yuv.max=', 250.79300000000001, 'yuv.min=', 31.652999999999999)
('yuv.max=', 217.77299999999997, 'yuv.min=', 37.491999999999997)
('yuv.max=', 235.08299999999997, 'yuv.min=', 8.5760000000000005)
('yuv.max=', 222.04900000000001, 'yuv.min=', 8.4710000000000001)
('yuv.max=', 255.0, 'yuv.min=', 13.869)
('yuv.max=', 253.63200000000001, 'yuv.min=', 0.0)
('yuv.max=', 253.25599999999997, 'yuv.min=', 14.914)
('yuv.max=', 222.61899999999997, 'yuv.min=', 6.3188480000000027)
('yuv.max=', 253.84299999999996, 'yuv.min=', 7.9089999999999998)
('yuv.max=', 253.77199999999999, 'yuv.min=', 18.309999999999999)
('yuv.max=', 223.42799999999997, 'yuv.min=', 9.1639999999999997)
('yuv.max=', 255.0, 'yuv.min=', 6.9779999999999998)
('yuv.max=', 255.0, 'yuv.min=', 4.2069999999999999)
('yuv.max=', 247.00599999999997, 'yuv.min=', 31.579999999999998)
('yuv.max=', 225.797, 'yuv.min=', 9.2110000000000003)
('yuv.max=', 223.02399999999997, 'yuv.min=', 14.303000000000001)
('yuv.max=', 219.81999999999999, 'yuv.min=', 18.113999999999997)
('yuv.max=', 255.0, 'yuv.min=', 21.075615999999997)
('yuv.max=', 233.52699999999996, 'yuv.min=', 14.776999999999999)
('yuv.max=', 224.12299999999996, 'yuv.min=', 24.114000000000001)
('yuv.max=', 234.369, 'yuv.min=', 3.5169999999999999)
('yuv.max=', 255.0, 'yuv.min=', 5.8040000000000003)
('yuv.max=', 179.13999999999999, 'yuv.min=', 10.928999999999998)
('yuv.max=', 245.20999999999998, 'yuv.min=', 0.0)
('yuv.max=', 230.11199999999999, 'yuv.min=', 20.988)
('yuv.max=', 226.88200000000001, 'yuv.min=', 66.257000000000005)
('yuv.max=', 207.84299999999999, 'yuv.min=', 50.774000000000001)
('yuv.max=', 253.21699999999998, 'yuv.min=', 38.724000000000004)
('yuv.max=', 243.804, 'yuv.min=', 73.428999999999988)
('yuv.max=', 252.00999999999999, 'yuv.min=', 8.484)
('yuv.max=', 233.94, 'yuv.min=', 6.1679999999999993)
('yuv.max=', 248.815, 'yuv.min=', 6.2880000000000003)
('yuv.max=', 253.0, 'yuv.min=', 20.131999999999998)
('yuv.max=', 235.83999999999997, 'yuv.min=', 14.956)
('yuv.max=', 245.33999999999997, 'yuv.min=', 14.68)
('yuv.max=', 255.0, 'yuv.min=', 19.599)
('yuv.max=', 207.55399999999997, 'yuv.min=', 2.8049999999999997)
('yuv.max=', 255.0, 'yuv.min=', 45.984999999999992)
('yuv.max=', 222.34, 'yuv.min=', 31.137999999999998)
('yuv.max=', 227.81399999999999, 'yuv.min=', 58.017999999999994)
('yuv.max=', 228.11799999999999, 'yuv.min=', 42.869999999999997)
('yuv.max=', 192.10400000000001, 'yuv.min=', 28.794999999999998)
('yuv.max=', 229.16800000000001, 'yuv.min=', 10.359)
('yuv.max=', 216.43081599999999, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 255.0, 'yuv.min=', 31.988703999999998)
('yuv.max=', 236.44499999999999, 'yuv.min=', 28.552999999999997)
('yuv.max=', 174.11799999999999, 'yuv.min=', 0.0)
('yuv.max=', 220.78199999999998, 'yuv.min=', 38.523000000000003)
('yuv.max=', 201.69699999999997, 'yuv.min=', 102.01571199999999)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 240.24499999999998, 'yuv.min=', 37.902999999999999)
('yuv.max=', 224.02100000000002, 'yuv.min=', 25.044)
('yuv.max=', 252.17400000000001, 'yuv.min=', 1.353)
('yuv.max=', 236.52000000000001, 'yuv.min=', 1.1400000000000001)
('yuv.max=', 255.0, 'yuv.min=', 13.701000000000001)
('yuv.max=', 238.60799999999998, 'yuv.min=', 10.978)
('yuv.max=', 233.99099999999999, 'yuv.min=', 33.016999999999996)
('yuv.max=', 253.25599999999997, 'yuv.min=', 2.3919999999999999)
('yuv.max=', 186.19899999999998, 'yuv.min=', 23.129999999999999)
('yuv.max=', 227.38, 'yuv.min=', 57.270999999999994)
('yuv.max=', 223.00699999999998, 'yuv.min=', 0.0)
('yuv.max=', 254.40199999999999, 'yuv.min=', 25.810999999999996)
('yuv.max=', 238.53499999999997, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 245.03199999999998, 'yuv.min=', 5.4030000000000005)
('yuv.max=', 231.02599999999998, 'yuv.min=', 12.987)
('yuv.max=', 168.94300800000002, 'yuv.min=', 34.634999999999998)
('yuv.max=', 225.86199999999999, 'yuv.min=', 85.724000000000004)
('yuv.max=', 176.495, 'yuv.min=', 69.329999999999998)
('yuv.max=', 255.0, 'yuv.min=', 56.885999999999996)
('yuv.max=', 253.0, 'yuv.min=', 28.143999999999998)
('yuv.max=', 246.09700000000001, 'yuv.min=', 15.995000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 254.18499999999997, 'yuv.min=', 24.321000000000002)
('yuv.max=', 234.70299999999997, 'yuv.min=', 17.194999999999997)
('yuv.max=', 245.63, 'yuv.min=', 18.776)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 207.40299999999999, 'yuv.min=', 76.572999999999993)
('yuv.max=', 174.38499999999999, 'yuv.min=', 22.218)
('yuv.max=', 252.63, 'yuv.min=', 12.287999999999998)
('yuv.max=', 215.02599999999998, 'yuv.min=', 4.1550000000000002)
('yuv.max=', 252.608, 'yuv.min=', 1.3959999999999999)
('yuv.max=', 255.0, 'yuv.min=', 42.528999999999996)
('yuv.max=', 251.24699999999999, 'yuv.min=', 10.865)
('yuv.max=', 250.18499999999997, 'yuv.min=', 48.081000000000003)
('yuv.max=', 232.93099999999998, 'yuv.min=', 76.971999999999994)
('yuv.max=', 216.87899999999999, 'yuv.min=', 12.635999999999999)
('yuv.max=', 235.08199999999999, 'yuv.min=', 27.359000000000002)
('yuv.max=', 252.989, 'yuv.min=', 74.134999999999991)
('yuv.max=', 255.0, 'yuv.min=', 3.0489999999999995)
('yuv.max=', 245.98399999999998, 'yuv.min=', 20.701000000000001)
('yuv.max=', 238.28799999999998, 'yuv.min=', 37.169999999999995)
('yuv.max=', 239.488, 'yuv.min=', 28.894999999999996)
('yuv.max=', 252.28800000000001, 'yuv.min=', 37.267999999999994)
('yuv.max=', 199.90600000000001, 'yuv.min=', 40.791000000000004)
('yuv.max=', 242.79299999999998, 'yuv.min=', 19.228000000000002)
('yuv.max=', 207.19099999999997, 'yuv.min=', 20.567999999999998)
('yuv.max=', 210.55700000000002, 'yuv.min=', 11.401999999999999)
('yuv.max=', 255.0, 'yuv.min=', 23.597999999999999)
('yuv.max=', 243.19499999999999, 'yuv.min=', 32.530000000000001)
('yuv.max=', 246.48399999999998, 'yuv.min=', 16.478000000000002)
('yuv.max=', 239.89699999999999, 'yuv.min=', 32.606999999999999)
('yuv.max=', 178.82099999999997, 'yuv.min=', 12.700999999999999)
('yuv.max=', 225.01799999999997, 'yuv.min=', 45.02595199999999)
('yuv.max=', 255.0, 'yuv.min=', 59.503999999999998)
('yuv.max=', 255.0, 'yuv.min=', 2.2880000000000003)
('yuv.max=', 189.88999999999999, 'yuv.min=', 30.532)
('yuv.max=', 222.26399999999998, 'yuv.min=', 29.242000000000001)
('yuv.max=', 231.24899999999997, 'yuv.min=', 0.86899999999999999)
('yuv.max=', 163.60899999999998, 'yuv.min=', 21.999999999999996)
('yuv.max=', 239.09299999999996, 'yuv.min=', 56.906999999999996)
('yuv.max=', 244.89200000000002, 'yuv.min=', 33.537999999999997)
('yuv.max=', 240.28800000000001, 'yuv.min=', 57.394999999999996)
('yuv.max=', 248.59799999999998, 'yuv.min=', 15.639999999999999)
('yuv.max=', 247.28400000000002, 'yuv.min=', 13.151)
('yuv.max=', 209.727, 'yuv.min=', 3.1459999999999999)
('yuv.max=', 217.02199999999999, 'yuv.min=', 66.182000000000002)
('yuv.max=', 250.51999999999998, 'yuv.min=', 22.010999999999999)
('yuv.max=', 211.74299999999999, 'yuv.min=', 24.483999999999998)
('yuv.max=', 242.06799999999998, 'yuv.min=', 9.4030000000000005)
('yuv.max=', 255.0, 'yuv.min=', 34.247999999999998)
('yuv.max=', 229.94599999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 70.057999999999993)
('yuv.max=', 205.94499999999999, 'yuv.min=', 57.689999999999998)
('yuv.max=', 215.08600000000001, 'yuv.min=', 50.49199999999999)
('yuv.max=', 232.66200000000001, 'yuv.min=', 22.052999999999997)
('yuv.max=', 251.41199999999998, 'yuv.min=', 21.533999999999999)
('yuv.max=', 250.06399999999996, 'yuv.min=', 65.838999999999999)
('yuv.max=', 233.91499999999999, 'yuv.min=', 18.047000000000001)
('yuv.max=', 228.17475199999998, 'yuv.min=', 48.773999999999994)
('yuv.max=', 224.36799999999997, 'yuv.min=', 3.3909999999999996)
('yuv.max=', 247.34199999999998, 'yuv.min=', 0.0)
('yuv.max=', 239.44099999999997, 'yuv.min=', 82.495999999999995)
('yuv.max=', 218.006, 'yuv.min=', 18.797999999999998)
('yuv.max=', 242.82599999999999, 'yuv.min=', 16.179000000000002)
('yuv.max=', 235.90399999999997, 'yuv.min=', 37.027999999999999)
('yuv.max=', 200.05099999999999, 'yuv.min=', 28.841999999999999)
('yuv.max=', 230.85999999999999, 'yuv.min=', 29.291)
('yuv.max=', 246.93900000000002, 'yuv.min=', 7.7119999999999997)
('yuv.max=', 157.94432, 'yuv.min=', 23.443000000000001)
('yuv.max=', 251.113, 'yuv.min=', 27.840999999999998)
('yuv.max=', 172.081312, 'yuv.min=', 21.408999999999999)
('yuv.max=', 252.49200000000002, 'yuv.min=', 3.8689999999999998)
('yuv.max=', 228.09599999999998, 'yuv.min=', 32.177999999999997)
('yuv.max=', 214.042, 'yuv.min=', 0.0)
('yuv.max=', 216.50900000000001, 'yuv.min=', 8.9139999999999997)
('yuv.max=', 241.75599999999997, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 237.59799999999998, 'yuv.min=', 33.991)
('yuv.max=', 234.48099999999999, 'yuv.min=', 24.808)
('yuv.max=', 170.94399999999999, 'yuv.min=', 19.609999999999999)
('yuv.max=', 227.58999999999997, 'yuv.min=', 25.939999999999998)
('yuv.max=', 249.30099999999999, 'yuv.min=', 35.619)
('yuv.max=', 238.94999999999999, 'yuv.min=', 9.2169999999999987)
('yuv.max=', 217.64699999999999, 'yuv.min=', 31.071000000000002)
('yuv.max=', 249.733, 'yuv.min=', 22.516000000000002)
('yuv.max=', 203.46899999999999, 'yuv.min=', 26.071000000000002)
('yuv.max=', 255.0, 'yuv.min=', 32.408000000000001)
('yuv.max=', 181.749, 'yuv.min=', 14.355)
('yuv.max=', 254.40199999999999, 'yuv.min=', 25.739999999999995)
('yuv.max=', 247.548, 'yuv.min=', 36.869999999999997)
('yuv.max=', 255.0, 'yuv.min=', 15.712)
('yuv.max=', 251.79299999999998, 'yuv.min=', 36.655999999999999)
('yuv.max=', 225.642, 'yuv.min=', 37.074999999999996)
('yuv.max=', 255.0, 'yuv.min=', 62.995999999999995)
('yuv.max=', 214.97932800000001, 'yuv.min=', 30.481000000000002)
('yuv.max=', 211.85099999999997, 'yuv.min=', 58.121999999999993)
('yuv.max=', 242.821, 'yuv.min=', 8.7159999999999993)
('yuv.max=', 226.28999999999999, 'yuv.min=', 24.374000000000002)
('yuv.max=', 222.82499999999999, 'yuv.min=', 53.835000000000001)
('yuv.max=', 237.41199999999998, 'yuv.min=', 11.728999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 61.527999999999999)
('yuv.max=', 217.57899999999998, 'yuv.min=', 62.192999999999998)
('yuv.max=', 252.52699999999996, 'yuv.min=', 6.5539999999999994)
('yuv.max=', 245.49799999999999, 'yuv.min=', 23.317)
('yuv.max=', 236.18899999999999, 'yuv.min=', 60.396999999999998)
('yuv.max=', 241.63199999999998, 'yuv.min=', 50.007999999999996)
('yuv.max=', 248.21800000000002, 'yuv.min=', 10.645)
('yuv.max=', 244.85299999999998, 'yuv.min=', 17.521999999999998)
('yuv.max=', 235.63399999999999, 'yuv.min=', 39.87299999999999)
('yuv.max=', 236.04500000000002, 'yuv.min=', 33.515999999999998)
('yuv.max=', 255.0, 'yuv.min=', 14.598999999999998)
('yuv.max=', 243.99999999999997, 'yuv.min=', 43.0)
('yuv.max=', 226.48400000000001, 'yuv.min=', 57.039967999999995)
('yuv.max=', 219.21799999999999, 'yuv.min=', 2.8799999999999999)
('yuv.max=', 255.0, 'yuv.min=', 26.789000000000001)
('yuv.max=', 230.12899999999996, 'yuv.min=', 47.942999999999998)
('yuv.max=', 174.48758400000003, 'yuv.min=', 20.933999999999997)
('yuv.max=', 238.51199999999997, 'yuv.min=', 2.7719999999999998)
('yuv.max=', 236.084, 'yuv.min=', 10.004)
('yuv.max=', 253.77199999999999, 'yuv.min=', 37.570999999999998)
('yuv.max=', 201.33099999999999, 'yuv.min=', 23.68)
('yuv.max=', 248.38999999999999, 'yuv.min=', 9.4019999999999992)
('yuv.max=', 253.505, 'yuv.min=', 17.309999999999999)
('yuv.max=', 207.416, 'yuv.min=', 10.613)
('yuv.max=', 248.48799999999997, 'yuv.min=', 30.265999999999998)
('yuv.max=', 243.619, 'yuv.min=', 28.526)
('yuv.max=', 192.15600000000001, 'yuv.min=', 49.338999999999999)
('yuv.max=', 240.99999999999997, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 20.373000000000001)
('yuv.max=', 243.22800000000001, 'yuv.min=', 54.881)
('yuv.max=', 219.06999999999999, 'yuv.min=', 27.949999999999999)
('yuv.max=', 212.80399999999997, 'yuv.min=', 18.456544000000008)
('yuv.max=', 227.25299999999999, 'yuv.min=', 15.590999999999999)
('yuv.max=', 247.81699999999998, 'yuv.min=', 24.614999999999998)
('yuv.max=', 196.797, 'yuv.min=', 16.257999999999999)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 233.0, 'yuv.min=', 68.0)
('yuv.max=', 255.0, 'yuv.min=', 51.429999999999993)
('yuv.max=', 255.0, 'yuv.min=', 24.777999999999999)
('yuv.max=', 195.47699999999998, 'yuv.min=', 24.008000000000003)
('yuv.max=', 242.03699999999998, 'yuv.min=', 19.974)
('yuv.max=', 248.33099999999999, 'yuv.min=', 43.610999999999997)
('yuv.max=', 247.529, 'yuv.min=', 9.5659999999999989)
('yuv.max=', 154.48137600000001, 'yuv.min=', 0.0)
('yuv.max=', 240.37899999999999, 'yuv.min=', 38.722999999999999)
('yuv.max=', 241.20399999999998, 'yuv.min=', 44.364999999999995)
('yuv.max=', 224.99999999999997, 'yuv.min=', 26.999999999999996)
('yuv.max=', 242.26399999999995, 'yuv.min=', 66.986999999999995)
('yuv.max=', 245.684, 'yuv.min=', 25.019999999999996)
('yuv.max=', 226.62099999999998, 'yuv.min=', 11.119071999999989)
('yuv.max=', 247.68499999999997, 'yuv.min=', 21.370999999999999)
('yuv.max=', 240.38099999999997, 'yuv.min=', 19.252000000000002)
('yuv.max=', 188.13599999999997, 'yuv.min=', 0.68400000000000005)
('yuv.max=', 220.53104000000002, 'yuv.min=', 10.832999999999998)
('yuv.max=', 242.44200000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 59.890999999999998)
('yuv.max=', 243.05599999999998, 'yuv.min=', 19.611999999999998)
('yuv.max=', 234.542, 'yuv.min=', 14.946)
('yuv.max=', 247.95000000000002, 'yuv.min=', 35.888999999999996)
('yuv.max=', 196.00999999999999, 'yuv.min=', 26.802)
('yuv.max=', 242.24299999999999, 'yuv.min=', 24.587)
('yuv.max=', 248.07499999999996, 'yuv.min=', 19.307000000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', 10.766)
('yuv.max=', 242.03299999999999, 'yuv.min=', 50.735391999999997)
('yuv.max=', 236.25699999999998, 'yuv.min=', 17.689999999999998)
('yuv.max=', 212.0, 'yuv.min=', 57.902999999999992)
('yuv.max=', 255.0, 'yuv.min=', 20.895)
('yuv.max=', 253.08799999999999, 'yuv.min=', 23.047999999999998)
('yuv.max=', 250.03200000000001, 'yuv.min=', 15.866)
('yuv.max=', 255.0, 'yuv.min=', 9.3529999999999998)
('yuv.max=', 223.07099999999997, 'yuv.min=', 16.750999999999998)
('yuv.max=', 255.0, 'yuv.min=', 26.971)
('yuv.max=', 245.09100000000001, 'yuv.min=', 4.4820000000000002)
('yuv.max=', 226.05800000000002, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 40.030999999999999)
('yuv.max=', 199.35899999999998, 'yuv.min=', 24.885999999999999)
('yuv.max=', 224.85799999999998, 'yuv.min=', 53.814999999999998)
('yuv.max=', 241.334, 'yuv.min=', 29.323999999999998)
('yuv.max=', 230.06899999999996, 'yuv.min=', 41.697000000000003)
('yuv.max=', 230.37399999999997, 'yuv.min=', 70.847999999999999)
('yuv.max=', 231.28800000000001, 'yuv.min=', 1.3959999999999999)
('yuv.max=', 255.0, 'yuv.min=', 10.700999999999999)
('yuv.max=', 203.69, 'yuv.min=', 43.372999999999998)
('yuv.max=', 255.0, 'yuv.min=', 44.905999999999999)
('yuv.max=', 252.89699999999999, 'yuv.min=', 0.0)
('yuv.max=', 205.94999999999999, 'yuv.min=', 16.150000000000002)
('yuv.max=', 242.643, 'yuv.min=', 40.954000000000001)
('yuv.max=', 194.29499999999999, 'yuv.min=', 22.128999999999998)
('yuv.max=', 253.82599999999996, 'yuv.min=', 58.939999999999998)
('yuv.max=', 192.072, 'yuv.min=', 31.204999999999998)
('yuv.max=', 253.72899999999996, 'yuv.min=', 4.7839999999999998)
('yuv.max=', 255.0, 'yuv.min=', 8.9779999999999998)
('yuv.max=', 219.40799999999996, 'yuv.min=', 29.408000000000001)
('yuv.max=', 211.79900000000001, 'yuv.min=', 20.366)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 43.848999999999997)
('yuv.max=', 254.131, 'yuv.min=', 0.0)
('yuv.max=', 249.84299999999999, 'yuv.min=', 13.667)
('yuv.max=', 198.529, 'yuv.min=', 2.3529999999999998)
('yuv.max=', 255.0, 'yuv.min=', 26.999999999999996)
('yuv.max=', 194.81399999999999, 'yuv.min=', 10.716000000000001)
('yuv.max=', 192.91200000000001, 'yuv.min=', 46.841000000000001)
('yuv.max=', 150.18736000000001, 'yuv.min=', 54.231999999999992)
('yuv.max=', 243.0, 'yuv.min=', 57.918999999999997)
('yuv.max=', 251.77199999999999, 'yuv.min=', 3.9079999999999999)
('yuv.max=', 255.0, 'yuv.min=', 9.2879999999999985)
('yuv.max=', 255.0, 'yuv.min=', 1.9399999999999999)
('yuv.max=', 246.64999999999998, 'yuv.min=', 48.439999999999998)
('yuv.max=', 252.48999999999998, 'yuv.min=', 24.948)
('yuv.max=', 214.328, 'yuv.min=', 64.864999999999995)
('yuv.max=', 231.85399999999996, 'yuv.min=', 17.715999999999998)
('yuv.max=', 190.349504, 'yuv.min=', 17.314)
('yuv.max=', 209.06799999999998, 'yuv.min=', 14.534000000000001)
('yuv.max=', 217.86399999999998, 'yuv.min=', 40.514000000000003)
('yuv.max=', 232.14399999999998, 'yuv.min=', 48.265000000000001)
('yuv.max=', 183.382304, 'yuv.min=', 60.777999999999992)
('yuv.max=', 232.38399999999996, 'yuv.min=', 49.972999999999999)
('yuv.max=', 247.47099999999998, 'yuv.min=', 20.988999999999997)
('yuv.max=', 253.80399999999997, 'yuv.min=', 60.373999999999995)
('yuv.max=', 178.28799999999998, 'yuv.min=', 20.316000000000003)
('yuv.max=', 206.29399999999998, 'yuv.min=', 10.777999999999999)
('yuv.max=', 235.06, 'yuv.min=', 9.338000000000001)
('yuv.max=', 223.10199999999998, 'yuv.min=', 26.512)
('yuv.max=', 255.0, 'yuv.min=', 34.140000000000001)
('yuv.max=', 248.70099999999999, 'yuv.min=', 27.263999999999999)
('yuv.max=', 199.55705599999999, 'yuv.min=', 8.4019999999999992)
('yuv.max=', 146.19699999999997, 'yuv.min=', 24.944000000000003)
('yuv.max=', 253.70099999999996, 'yuv.min=', 12.379)
('yuv.max=', 234.03200000000001, 'yuv.min=', 0.0)
('yuv.max=', 253.52699999999999, 'yuv.min=', 5.7009999999999996)
('yuv.max=', 235.90299999999999, 'yuv.min=', 19.706)
('yuv.max=', 201.715, 'yuv.min=', 19.783999999999999)
('yuv.max=', 226.67499999999998, 'yuv.min=', 13.712)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 250.12700000000001, 'yuv.min=', 21.864999999999998)
('yuv.max=', 237.32299999999998, 'yuv.min=', 4.0919999999999996)
('yuv.max=', 249.78200000000001, 'yuv.min=', 25.672999999999998)
('yuv.max=', 249.05299999999997, 'yuv.min=', 21.477999999999998)
('yuv.max=', 241.548, 'yuv.min=', 0.114)
('yuv.max=', 239.27099999999999, 'yuv.min=', 30.573)
('yuv.max=', 255.0, 'yuv.min=', 2.4449999999999998)
('yuv.max=', 234.70400000000001, 'yuv.min=', 50.396000000000001)
('yuv.max=', 168.553472, 'yuv.min=', 3.2989999999999999)
('yuv.max=', 255.0, 'yuv.min=', 41.311999999999998)
('yuv.max=', 208.19599999999997, 'yuv.min=', 16.652999999999999)
('yuv.max=', 205.57599999999999, 'yuv.min=', 50.971999999999994)
('yuv.max=', 255.0, 'yuv.min=', 21.277000000000001)
('yuv.max=', 232.017, 'yuv.min=', 0.0)
('yuv.max=', 242.91799999999998, 'yuv.min=', 40.335000000000001)
('yuv.max=', 231.14199999999997, 'yuv.min=', 37.842999999999996)
('yuv.max=', 242.68999999999997, 'yuv.min=', 11.353)
('yuv.max=', 234.214, 'yuv.min=', 39.956000000000003)
('yuv.max=', 252.036, 'yuv.min=', 78.120999999999995)
('yuv.max=', 187.53, 'yuv.min=', 48.939)
('yuv.max=', 224.88299999999998, 'yuv.min=', 48.497)
('yuv.max=', 246.55199999999999, 'yuv.min=', 5.6520000000000001)
('yuv.max=', 244.47300000000001, 'yuv.min=', 10.763999999999999)
('yuv.max=', 255.0, 'yuv.min=', 41.966999999999999)
('yuv.max=', 246.95999999999998, 'yuv.min=', 2.9349999999999996)
('yuv.max=', 255.0, 'yuv.min=', 38.488)
('yuv.max=', 242.91799999999998, 'yuv.min=', 0.0)
('yuv.max=', 231.86600000000001, 'yuv.min=', 32.945999999999998)
('yuv.max=', 237.21599999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 68.0)
('yuv.max=', 242.86900000000003, 'yuv.min=', 3.8969999999999998)
('yuv.max=', 246.744, 'yuv.min=', 3.7549999999999999)
('yuv.max=', 223.72900000000001, 'yuv.min=', 3.5759999999999996)
('yuv.max=', 226.68799999999999, 'yuv.min=', 10.282999999999999)
('yuv.max=', 251.44499999999996, 'yuv.min=', 42.224000000000004)
('yuv.max=', 161.93999999999997, 'yuv.min=', 0.0)
('yuv.max=', 254.35900000000001, 'yuv.min=', 49.341000000000001)
('yuv.max=', 252.68599999999998, 'yuv.min=', 3.1359999999999997)
('yuv.max=', 254.77200000000002, 'yuv.min=', 25.853999999999996)
('yuv.max=', 186.77199999999999, 'yuv.min=', 27.101999999999997)
('yuv.max=', 169.56800000000001, 'yuv.min=', 10.647)
('yuv.max=', 219.88099999999997, 'yuv.min=', 28.658999999999999)
('yuv.max=', 218.16, 'yuv.min=', 13.248999999999999)
('yuv.max=', 243.33099999999999, 'yuv.min=', 4.1139999999999999)
('yuv.max=', 182.37299999999999, 'yuv.min=', 8.8149999999999995)
('yuv.max=', 240.19499999999996, 'yuv.min=', 36.496000000000002)
('yuv.max=', 255.0, 'yuv.min=', 24.734000000000002)
('yuv.max=', 247.70699999999999, 'yuv.min=', 32.720999999999997)
('yuv.max=', 219.13999999999999, 'yuv.min=', 43.416999999999994)
('yuv.max=', 251.50500000000002, 'yuv.min=', 2.9290000000000003)
('yuv.max=', 187.43100000000001, 'yuv.min=', 27.196999999999999)
('yuv.max=', 251.48399999999998, 'yuv.min=', 31.766999999999996)
('yuv.max=', 233.46299999999997, 'yuv.min=', 19.597000000000001)
('yuv.max=', 226.22799999999998, 'yuv.min=', 15.961)
('yuv.max=', 242.75500000000002, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 236.22799999999998, 'yuv.min=', 55.780999999999999)
('yuv.max=', 230.02699999999999, 'yuv.min=', 64.079999999999998)
('yuv.max=', 234.99999999999997, 'yuv.min=', 26.999999999999996)
('yuv.max=', 241.12099999999998, 'yuv.min=', 0.0)
('yuv.max=', 252.202, 'yuv.min=', 31.422000000000001)
('yuv.max=', 250.18499999999997, 'yuv.min=', 10.885999999999999)
('yuv.max=', 235.73599999999999, 'yuv.min=', 58.697999999999993)
('yuv.max=', 255.0, 'yuv.min=', 37.974000000000004)
('yuv.max=', 223.87900000000002, 'yuv.min=', 13.146000000000001)
('yuv.max=', 254.17400000000001, 'yuv.min=', 5.6740000000000004)
('yuv.max=', 233.31799999999998, 'yuv.min=', 14.547000000000001)
('yuv.max=', 188.881, 'yuv.min=', 19.373999999999999)
('yuv.max=', 164.822, 'yuv.min=', 16.908999999999999)
('yuv.max=', 255.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 249.24399999999997, 'yuv.min=', 35.241999999999997)
('yuv.max=', 255.0, 'yuv.min=', 16.837999999999997)
('yuv.max=', 241.14600000000002, 'yuv.min=', 10.999999999999998)
('yuv.max=', 187.12265600000001, 'yuv.min=', 21.611999999999998)
('yuv.max=', 255.0, 'yuv.min=', 14.754999999999999)
('yuv.max=', 249.01999999999998, 'yuv.min=', 1.0429999999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', 9.6559999999999988)
('yuv.max=', 186.97799999999998, 'yuv.min=', 39.344000000000001)
('yuv.max=', 251.113, 'yuv.min=', 45.591000000000001)
('yuv.max=', 210.34799999999998, 'yuv.min=', 86.429999999999993)
('yuv.max=', 254.70099999999999, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 255.0, 'yuv.min=', 3.1739999999999999)
('yuv.max=', 203.17999999999998, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 246.08299999999997, 'yuv.min=', 22.154)
('yuv.max=', 218.84199999999998, 'yuv.min=', 29.467999999999996)
('yuv.max=', 247.078, 'yuv.min=', 33.578000000000003)
('yuv.max=', 252.03199999999998, 'yuv.min=', 10.949999999999999)
('yuv.max=', 238.99999999999997, 'yuv.min=', 36.0)
('yuv.max=', 210.542, 'yuv.min=', 10.700999999999999)
('yuv.max=', 239.94999999999999, 'yuv.min=', 32.111999999999995)
('yuv.max=', 239.14699999999999, 'yuv.min=', 30.283999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 239.29999999999998, 'yuv.min=', 18.834)
('yuv.max=', 212.09200000000001, 'yuv.min=', 31.940000000000001)
('yuv.max=', 189.87800000000001, 'yuv.min=', 22.538367999999998)
('yuv.max=', 234.95599999999996, 'yuv.min=', 46.317)
('yuv.max=', 203.03200000000001, 'yuv.min=', 22.530999999999999)
('yuv.max=', 234.755, 'yuv.min=', 11.185)
('yuv.max=', 194.117952, 'yuv.min=', 20.126999999999999)
('yuv.max=', 240.00799999999998, 'yuv.min=', 91.833999999999989)
('yuv.max=', 233.82899999999998, 'yuv.min=', 0.0)
('yuv.max=', 208.672, 'yuv.min=', 48.054000000000002)
('yuv.max=', 227.22900000000001, 'yuv.min=', 29.666)
('yuv.max=', 255.0, 'yuv.min=', 15.478)
('yuv.max=', 246.60299999999998, 'yuv.min=', 0.0)
('yuv.max=', 248.96099999999998, 'yuv.min=', 23.195999999999998)
('yuv.max=', 242.232, 'yuv.min=', 46.082999999999998)
('yuv.max=', 207.78699999999998, 'yuv.min=', 28.315999999999999)
('yuv.max=', 255.0, 'yuv.min=', 2.6090000000000004)
('yuv.max=', 252.92899999999997, 'yuv.min=', 9.3970000000000002)
('yuv.max=', 234.52999999999997, 'yuv.min=', 19.713999999999999)
('yuv.max=', 236.017, 'yuv.min=', 1.7829999999999999)
('yuv.max=', 240.76300000000001, 'yuv.min=', 34.548000000000002)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 178.70699999999999, 'yuv.min=', 0.0)
('yuv.max=', 200.83099999999999, 'yuv.min=', 41.326999999999998)
('yuv.max=', 224.07999999999998, 'yuv.min=', 24.125)
('yuv.max=', 248.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 236.52100000000002, 'yuv.min=', 78.441000000000003)
('yuv.max=', 212.45999999999998, 'yuv.min=', 28.070999999999998)
('yuv.max=', 255.0, 'yuv.min=', 7.5899999999999999)
('yuv.max=', 200.328, 'yuv.min=', 12.41)
('yuv.max=', 248.755, 'yuv.min=', 12.282)
('yuv.max=', 247.80399999999997, 'yuv.min=', 24.797000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 215.70999999999998, 'yuv.min=', 40.784999999999997)
('yuv.max=', 242.72200000000001, 'yuv.min=', 50.778999999999996)
('yuv.max=', 253.0, 'yuv.min=', 55.0)
('yuv.max=', 254.70099999999999, 'yuv.min=', 35.188999999999993)
('yuv.max=', 241.68099999999998, 'yuv.min=', 34.703999999999994)
('yuv.max=', 254.11399999999998, 'yuv.min=', 16.478999999999999)
('yuv.max=', 241.733, 'yuv.min=', 0.0)
('yuv.max=', 252.31999999999999, 'yuv.min=', 24.509999999999998)
('yuv.max=', 244.70100000000002, 'yuv.min=', 34.268999999999998)
('yuv.max=', 202.63199999999998, 'yuv.min=', 6.4239999999999995)
('yuv.max=', 225.29000000000002, 'yuv.min=', 23.262)
('yuv.max=', 255.0, 'yuv.min=', 4.1849999999999996)
('yuv.max=', 249.142, 'yuv.min=', 11.629999999999999)
('yuv.max=', 226.91999999999999, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 255.0, 'yuv.min=', 21.332000000000001)
('yuv.max=', 242.37199999999999, 'yuv.min=', 1.9289999999999998)
('yuv.max=', 196.16800000000001, 'yuv.min=', 21.475000000000001)
('yuv.max=', 255.0, 'yuv.min=', 24.808999999999997)
('yuv.max=', 243.929, 'yuv.min=', 20.369999999999997)
('yuv.max=', 254.40199999999999, 'yuv.min=', 26.445)
('yuv.max=', 245.03199999999998, 'yuv.min=', 16.777000000000001)
('yuv.max=', 255.0, 'yuv.min=', 33.680999999999997)
('yuv.max=', 252.28800000000001, 'yuv.min=', 25.646999999999998)
('yuv.max=', 255.0, 'yuv.min=', 38.287999999999997)
('yuv.max=', 245.488, 'yuv.min=', 14.587)
('yuv.max=', 238.815, 'yuv.min=', 33.498999999999995)
('yuv.max=', 253.87500000000003, 'yuv.min=', 6.2350000000000003)
('yuv.max=', 196.136, 'yuv.min=', 2.7609999999999997)
('yuv.max=', 253.52699999999999, 'yuv.min=', 6.0090000000000003)
('yuv.max=', 251.92899999999995, 'yuv.min=', 30.977999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 13.739999999999998)
('yuv.max=', 242.54400000000001, 'yuv.min=', 3.5870000000000002)
('yuv.max=', 211.28299999999999, 'yuv.min=', 39.469999999999999)
('yuv.max=', 230.89399999999998, 'yuv.min=', 31.571999999999999)
('yuv.max=', 195.85499999999999, 'yuv.min=', 39.685000000000002)
('yuv.max=', 248.97900000000001, 'yuv.min=', 4.9340000000000002)
('yuv.max=', 235.958, 'yuv.min=', 13.668999999999999)
('yuv.max=', 241.245, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 29.667999999999999)
('yuv.max=', 235.04399999999998, 'yuv.min=', 5.7439999999999998)
('yuv.max=', 255.0, 'yuv.min=', 26.228999999999999)
('yuv.max=', 232.721, 'yuv.min=', 9.9660000000000011)
('yuv.max=', 254.40199999999999, 'yuv.min=', 35.512)
('yuv.max=', 204.905, 'yuv.min=', 33.834999999999994)
('yuv.max=', 183.33999999999997, 'yuv.min=', 14.442)
('yuv.max=', 255.0, 'yuv.min=', 13.481)
('yuv.max=', 255.0, 'yuv.min=', 9.032)
('yuv.max=', 229.59299999999999, 'yuv.min=', 34.000999999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 216.959, 'yuv.min=', 22.771999999999998)
('yuv.max=', 255.0, 'yuv.min=', 23.420000000000002)
('yuv.max=', 235.53899999999999, 'yuv.min=', 10.924999999999999)
('yuv.max=', 204.65099999999998, 'yuv.min=', 23.838000000000001)
('yuv.max=', 225.08199999999999, 'yuv.min=', 51.077999999999996)
('yuv.max=', 237.57799999999997, 'yuv.min=', 45.597999999999999)
('yuv.max=', 255.0, 'yuv.min=', 18.601999999999997)
('yuv.max=', 231.13099999999997, 'yuv.min=', 35.200000000000003)
('yuv.max=', 252.309, 'yuv.min=', 18.242999999999999)
('yuv.max=', 252.15200000000002, 'yuv.min=', 41.805999999999997)
('yuv.max=', 245.41300000000001, 'yuv.min=', 21.785999999999998)
('yuv.max=', 243.971, 'yuv.min=', 0.114)
('yuv.max=', 237.49099999999999, 'yuv.min=', 19.386999999999997)
('yuv.max=', 203.044928, 'yuv.min=', 8.5210000000000008)
('yuv.max=', 224.703, 'yuv.min=', 28.856999999999999)
('yuv.max=', 186.13299999999998, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 240.0, 'yuv.min=', 21.0)
('yuv.max=', 242.54400000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 28.279999999999994)
('yuv.max=', 237.59799999999998, 'yuv.min=', 16.559999999999999)
('yuv.max=', 243.34099999999998, 'yuv.min=', 11.021999999999998)
('yuv.max=', 216.398, 'yuv.min=', 20.326000000000001)
('yuv.max=', 255.0, 'yuv.min=', 3.3739999999999997)
('yuv.max=', 190.43899999999999, 'yuv.min=', 4.2430000000000003)
('yuv.max=', 201.637, 'yuv.min=', 13.316000000000001)
('yuv.max=', 203.94299999999998, 'yuv.min=', 36.706999999999994)
('yuv.max=', 177.93899999999999, 'yuv.min=', 38.887999999999998)
('yuv.max=', 240.99999999999997, 'yuv.min=', 14.0)
('yuv.max=', 253.99999999999997, 'yuv.min=', 12.818)
('yuv.max=', 199.0, 'yuv.min=', 5.7009999999999996)
('yuv.max=', 245.20599999999999, 'yuv.min=', 28.268999999999998)
('yuv.max=', 209.441, 'yuv.min=', 20.515999999999998)
('yuv.max=', 238.15199999999999, 'yuv.min=', 26.608000000000001)
('yuv.max=', 254.77200000000002, 'yuv.min=', 10.562999999999999)
('yuv.max=', 251.43199999999996, 'yuv.min=', 25.511999999999997)
('yuv.max=', 234.05799999999999, 'yuv.min=', 37.364999999999995)
('yuv.max=', 226.12799999999999, 'yuv.min=', 11.712)
('yuv.max=', 207.92899999999997, 'yuv.min=', 22.641000000000002)
('yuv.max=', 218.58489600000001, 'yuv.min=', 29.329999999999998)
('yuv.max=', 247.02599999999998, 'yuv.min=', 47.782000000000004)
('yuv.max=', 237.07499999999999, 'yuv.min=', 8.1289999999999996)
('yuv.max=', 222.78899999999999, 'yuv.min=', 0.0)
('yuv.max=', 250.57599999999996, 'yuv.min=', 15.678999999999998)
('yuv.max=', 233.92100000000002, 'yuv.min=', 40.064999999999998)
('yuv.max=', 255.0, 'yuv.min=', 6.7839999999999989)
('yuv.max=', 216.01900000000001, 'yuv.min=', 18.266999999999999)
('yuv.max=', 235.62699999999998, 'yuv.min=', 25.555)
('yuv.max=', 237.017, 'yuv.min=', 0.0)
('yuv.max=', 253.80399999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 219.99099999999999, 'yuv.min=', 8.6449999999999996)
('yuv.max=', 232.04299999999998, 'yuv.min=', 19.836999999999996)
('yuv.max=', 234.339, 'yuv.min=', 13.58)
('yuv.max=', 240.97799999999998, 'yuv.min=', 9.6189999999999998)
('yuv.max=', 226.04000000000002, 'yuv.min=', 53.757999999999988)
('yuv.max=', 240.70599999999999, 'yuv.min=', 36.122999999999998)
('yuv.max=', 226.06099999999998, 'yuv.min=', 2.3529999999999998)
('yuv.max=', 211.41, 'yuv.min=', 38.259999999999998)
('yuv.max=', 255.0, 'yuv.min=', 16.587999999999997)
('yuv.max=', 201.21199999999999, 'yuv.min=', 17.236999999999998)
('yuv.max=', 226.12499999999997, 'yuv.min=', 18.085000000000001)
('yuv.max=', 243.60399999999998, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 169.40899999999999, 'yuv.min=', 14.209999999999999)
('yuv.max=', 188.97699999999998, 'yuv.min=', 71.683999999999997)
('yuv.max=', 247.90099999999998, 'yuv.min=', 8.6579999999999995)
('yuv.max=', 162.924384, 'yuv.min=', 42.085999999999999)
('yuv.max=', 253.13099999999997, 'yuv.min=', 16.786999999999999)
('yuv.max=', 255.0, 'yuv.min=', 16.907)
('yuv.max=', 251.15300000000002, 'yuv.min=', 5.2169999999999996)
('yuv.max=', 225.15999999999997, 'yuv.min=', 57.409000000000006)
('yuv.max=', 252.114, 'yuv.min=', 18.810999999999996)
('yuv.max=', 254.70099999999999, 'yuv.min=', 47.177999999999997)
('yuv.max=', 207.76299999999998, 'yuv.min=', 14.831)
('yuv.max=', 255.0, 'yuv.min=', 59.256768000000008)
('yuv.max=', 250.173, 'yuv.min=', 38.326000000000001)
('yuv.max=', 236.39699999999999, 'yuv.min=', 31.884)
('yuv.max=', 201.03499999999997, 'yuv.min=', 61.313000000000002)
('yuv.max=', 228.673, 'yuv.min=', 0.0)
('yuv.max=', 250.54399999999998, 'yuv.min=', 8.4239999999999995)
('yuv.max=', 255.0, 'yuv.min=', 7.9499999999999993)
('yuv.max=', 199.96600000000001, 'yuv.min=', 16.050000000000001)
('yuv.max=', 254.886, 'yuv.min=', 21.000999999999998)
('yuv.max=', 160.44900000000001, 'yuv.min=', 9.8149999999999995)
('yuv.max=', 253.52699999999999, 'yuv.min=', 27.988999999999997)
('yuv.max=', 225.28800000000001, 'yuv.min=', 36.493000000000002)
('yuv.max=', 228.64399999999998, 'yuv.min=', 4.956999999999999)
('yuv.max=', 250.25600000000003, 'yuv.min=', 4.2389999999999999)
('yuv.max=', 189.08799999999997, 'yuv.min=', 6.8300000000000001)
('yuv.max=', 237.42399999999998, 'yuv.min=', 45.850000000000001)
('yuv.max=', 255.0, 'yuv.min=', 55.152999999999999)
('yuv.max=', 249.94, 'yuv.min=', 8.032)
('yuv.max=', 215.03199999999998, 'yuv.min=', 75.640999999999991)
('yuv.max=', 245.23199999999997, 'yuv.min=', 29.582999999999998)
('yuv.max=', 154.74943999999999, 'yuv.min=', 47.323999999999998)
('yuv.max=', 217.731808, 'yuv.min=', 9.1690000000000005)
('yuv.max=', 217.40200000000002, 'yuv.min=', 0.70099999999999996)
('yuv.max=', 194.13399999999999, 'yuv.min=', 14.715999999999999)
('yuv.max=', 251.44099999999997, 'yuv.min=', 47.649999999999991)
('yuv.max=', 245.88800000000001, 'yuv.min=', 37.973999999999997)
('yuv.max=', 237.76999999999998, 'yuv.min=', 9.9299999999999997)
('yuv.max=', 216.08199999999999, 'yuv.min=', 12.815)
('yuv.max=', 202.63999999999999, 'yuv.min=', 0.0)
('yuv.max=', 248.87, 'yuv.min=', 15.736999999999998)
('yuv.max=', 224.05999999999997, 'yuv.min=', 32.016000000000005)
('yuv.max=', 250.184, 'yuv.min=', 34.966000000000001)
('yuv.max=', 181.328, 'yuv.min=', 18.741999999999997)
('yuv.max=', 202.03699999999998, 'yuv.min=', 35.216999999999999)
('yuv.max=', 249.65099999999995, 'yuv.min=', 33.281999999999996)
('yuv.max=', 249.673, 'yuv.min=', 19.216999999999999)
('yuv.max=', 223.15699999999998, 'yuv.min=', 43.225999999999992)
('yuv.max=', 230.99599999999995, 'yuv.min=', 32.080999999999996)
('yuv.max=', 242.33500000000001, 'yuv.min=', 3.1680000000000001)
('yuv.max=', 248.0, 'yuv.min=', 32.355000000000004)
('yuv.max=', 239.03199999999998, 'yuv.min=', 6.4779999999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', 1.157)
('yuv.max=', 139.012416, 'yuv.min=', 9.9290000000000003)
('yuv.max=', 242.96399999999997, 'yuv.min=', 6.2789999999999999)
('yuv.max=', 247.07999999999998, 'yuv.min=', 29.106999999999996)
('yuv.max=', 237.672, 'yuv.min=', 17.716999999999999)
('yuv.max=', 243.89899999999997, 'yuv.min=', 11.374000000000001)
('yuv.max=', 247.88600000000002, 'yuv.min=', 28.730999999999998)
('yuv.max=', 249.756, 'yuv.min=', 6.7010000000000005)
('yuv.max=', 221.25799999999998, 'yuv.min=', 10.847000000000001)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 209.22299999999998, 'yuv.min=', 10.81)
('yuv.max=', 212.96099999999998, 'yuv.min=', 21.794)
('yuv.max=', 254.886, 'yuv.min=', 60.565999999999995)
('yuv.max=', 252.0, 'yuv.min=', 30.227999999999998)
('yuv.max=', 215.77600000000001, 'yuv.min=', 56.795999999999999)
('yuv.max=', 195.583, 'yuv.min=', 18.427999999999997)
('yuv.max=', 235.77199999999999, 'yuv.min=', 25.459999999999997)
('yuv.max=', 248.20500000000001, 'yuv.min=', 36.046999999999997)
('yuv.max=', 253.333, 'yuv.min=', 25.613)
('yuv.max=', 250.99999999999997, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 245.96100000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 7.1870000000000003)
('yuv.max=', 224.35500000000002, 'yuv.min=', 28.068999999999996)
('yuv.max=', 204.59100000000001, 'yuv.min=', 35.859999999999999)
('yuv.max=', 212.46099999999998, 'yuv.min=', 11.474999999999998)
('yuv.max=', 255.0, 'yuv.min=', 7.5929999999999991)
('yuv.max=', 190.399, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 198.13299999999998, 'yuv.min=', 29.478999999999999)
('yuv.max=', 210.83399999999997, 'yuv.min=', 31.641999999999996)
('yuv.max=', 255.0, 'yuv.min=', 2.0859999999999999)
('yuv.max=', 245.0, 'yuv.min=', 25.0)
('yuv.max=', 192.345, 'yuv.min=', 2.0709999999999997)
('yuv.max=', 255.0, 'yuv.min=', 51.171999999999997)
('yuv.max=', 244.74399999999997, 'yuv.min=', 3.4129999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 32.890999999999998)
('yuv.max=', 219.41300000000001, 'yuv.min=', 59.923999999999999)
('yuv.max=', 244.19399999999999, 'yuv.min=', 23.260999999999999)
('yuv.max=', 255.0, 'yuv.min=', 13.791)
('yuv.max=', 196.65049599999998, 'yuv.min=', 35.689)
('yuv.max=', 210.134784, 'yuv.min=', 22.416999999999998)
('yuv.max=', 199.47599999999997, 'yuv.min=', 13.042)
('yuv.max=', 251.81499999999997, 'yuv.min=', 15.760999999999999)
('yuv.max=', 243.761, 'yuv.min=', 17.141000000000002)
('yuv.max=', 251.352, 'yuv.min=', 11.849999999999998)
('yuv.max=', 247.81499999999997, 'yuv.min=', 0.114)
('yuv.max=', 249.94599999999997, 'yuv.min=', 37.414000000000001)
('yuv.max=', 182.15199999999999, 'yuv.min=', 23.462)
('yuv.max=', 245.62799999999999, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 225.63799999999998, 'yuv.min=', 11.992999999999999)
('yuv.max=', 164.105536, 'yuv.min=', 37.295999999999999)
('yuv.max=', 205.03899999999999, 'yuv.min=', 20.920000000000002)
('yuv.max=', 226.91799999999998, 'yuv.min=', 12.598000000000001)
('yuv.max=', 255.0, 'yuv.min=', 15.282)
('yuv.max=', 253.56100000000001, 'yuv.min=', 65.313000000000002)
('yuv.max=', 236.70899999999997, 'yuv.min=', 3.4779999999999998)
('yuv.max=', 229.10200000000003, 'yuv.min=', 7.6899999999999995)
('yuv.max=', 191.18199999999999, 'yuv.min=', 22.739999999999998)
('yuv.max=', 237.98499999999999, 'yuv.min=', 19.376999999999999)
('yuv.max=', 253.989, 'yuv.min=', 23.027000000000001)
('yuv.max=', 241.10299999999998, 'yuv.min=', 2.7010000000000001)
('yuv.max=', 252.89699999999999, 'yuv.min=', 0.0)
('yuv.max=', 203.98299999999998, 'yuv.min=', 4.1029999999999998)
('yuv.max=', 254.131, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 224.13399999999999, 'yuv.min=', 12.408999999999999)
('yuv.max=', 254.54400000000001, 'yuv.min=', 1.2390000000000001)
('yuv.max=', 242.30999999999997, 'yuv.min=', 31.246000000000002)
('yuv.max=', 199.12299999999999, 'yuv.min=', 99.178336000000002)
('yuv.max=', 255.0, 'yuv.min=', 7.3000000000000007)
('yuv.max=', 208.35900000000001, 'yuv.min=', 27.858000000000001)
('yuv.max=', 252.42400000000001, 'yuv.min=', 18.710999999999999)
('yuv.max=', 177.45148800000001, 'yuv.min=', 6.8550000000000004)
('yuv.max=', 238.85399999999998, 'yuv.min=', 0.0)
('yuv.max=', 237.89600000000002, 'yuv.min=', 9.8259999999999987)
('yuv.max=', 248.83699999999999, 'yuv.min=', 0.0)
('yuv.max=', 237.70099999999999, 'yuv.min=', 36.244)
('yuv.max=', 233.38499999999999, 'yuv.min=', 48.533000000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 231.09899999999999, 'yuv.min=', 16.140999999999998)
('yuv.max=', 244.94999999999999, 'yuv.min=', 24.201000000000001)
('yuv.max=', 240.75899999999999, 'yuv.min=', 31.701000000000001)
('yuv.max=', 245.33799999999997, 'yuv.min=', 15.402999999999999)
('yuv.max=', 242.08500000000001, 'yuv.min=', 51.230000000000004)
('yuv.max=', 255.0, 'yuv.min=', 5.3360000000000003)
('yuv.max=', 179.72899999999998, 'yuv.min=', 29.785)
('yuv.max=', 242.94999999999999, 'yuv.min=', 51.155999999999999)
('yuv.max=', 248.452, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 231.809, 'yuv.min=', 50.467999999999996)
('yuv.max=', 241.94999999999999, 'yuv.min=', 31.890000000000001)
('yuv.max=', 202.447, 'yuv.min=', 16.692999999999998)
('yuv.max=', 228.47, 'yuv.min=', 17.966999999999999)
('yuv.max=', 255.0, 'yuv.min=', 12.239000000000001)
('yuv.max=', 201.34199999999998, 'yuv.min=', 5.5139999999999993)
('yuv.max=', 249.78299999999996, 'yuv.min=', 34.612000000000002)
('yuv.max=', 225.98400000000001, 'yuv.min=', 1.516)
('yuv.max=', 245.38099999999997, 'yuv.min=', 4.3190000000000008)
('yuv.max=', 211.38099999999997, 'yuv.min=', 39.330999999999989)
('yuv.max=', 253.86000000000001, 'yuv.min=', 46.990000000000002)
('yuv.max=', 221.04299999999998, 'yuv.min=', 5.6689999999999996)
('yuv.max=', 224.02800000000002, 'yuv.min=', 73.141999999999996)
('yuv.max=', 253.20599999999999, 'yuv.min=', 2.5699999999999998)
('yuv.max=', 218.292, 'yuv.min=', 33.594000000000001)
('yuv.max=', 253.46199999999999, 'yuv.min=', 28.419999999999995)
('yuv.max=', 248.875, 'yuv.min=', 6.9119999999999999)
('yuv.max=', 208.70099999999999, 'yuv.min=', 62.926999999999992)
('yuv.max=', 209.017, 'yuv.min=', 6.0170000000000003)
('yuv.max=', 241.35900000000001, 'yuv.min=', 20.603999999999999)
('yuv.max=', 240.29199999999997, 'yuv.min=', 41.671999999999997)
('yuv.max=', 195.52699999999999, 'yuv.min=', 5.2880000000000003)
('yuv.max=', 186.06199999999998, 'yuv.min=', 25.128)
('yuv.max=', 243.95599999999999, 'yuv.min=', 0.0)
('yuv.max=', 198.30899999999997, 'yuv.min=', 35.383999999999993)
('yuv.max=', 224.76999999999998, 'yuv.min=', 44.284999999999997)
('yuv.max=', 255.0, 'yuv.min=', 29.021999999999998)
('yuv.max=', 230.82999999999998, 'yuv.min=', 10.093)
('yuv.max=', 167.316, 'yuv.min=', 8.1890000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.114)
('yuv.max=', 191.00199999999998, 'yuv.min=', 89.310000000000002)
('yuv.max=', 248.0, 'yuv.min=', 58.842999999999996)
('yuv.max=', 223.05099999999999, 'yuv.min=', 31.48)
('yuv.max=', 252.60599999999999, 'yuv.min=', 23.352)
('yuv.max=', 255.0, 'yuv.min=', 35.652999999999999)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 216.01212800000002, 'yuv.min=', 27.010000000000002)
('yuv.max=', 255.0, 'yuv.min=', 70.421999999999997)
('yuv.max=', 202.13099999999997, 'yuv.min=', 33.928999999999995)
('yuv.max=', 249.94599999999997, 'yuv.min=', 12.555)
('yuv.max=', 254.29899999999995, 'yuv.min=', 0.0)
('yuv.max=', 253.68999999999997, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 239.01399999999998, 'yuv.min=', 22.575999999999997)
('yuv.max=', 249.73899999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.114)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 2.7719999999999998)
('yuv.max=', 230.172, 'yuv.min=', 2.8149999999999999)
('yuv.max=', 214.27399999999997, 'yuv.min=', 16.476999999999997)
('yuv.max=', 252.34999999999999, 'yuv.min=', 7.3759999999999994)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 254.06, 'yuv.min=', 15.843999999999999)
('yuv.max=', 176.80799999999999, 'yuv.min=', 9.6559999999999988)
('yuv.max=', 238.57999999999998, 'yuv.min=', 48.149999999999991)
('yuv.max=', 231.67199999999997, 'yuv.min=', 9.0039999999999996)
('yuv.max=', 158.30799999999999, 'yuv.min=', 37.884)
('yuv.max=', 223.01599999999999, 'yuv.min=', 42.966999999999999)
('yuv.max=', 232.26599999999999, 'yuv.min=', 0.0)
('yuv.max=', 233.84899999999999, 'yuv.min=', 2.7120000000000002)
('yuv.max=', 220.745, 'yuv.min=', 26.884)
('yuv.max=', 254.43000000000001, 'yuv.min=', 2.1959999999999997)
('yuv.max=', 204.245, 'yuv.min=', 36.578000000000003)
('yuv.max=', 239.11099999999999, 'yuv.min=', 19.479999999999997)
('yuv.max=', 240.465, 'yuv.min=', 60.920999999999999)
('yuv.max=', 234.84700000000001, 'yuv.min=', 25.152000000000001)
('yuv.max=', 227.13699999999997, 'yuv.min=', 54.138999999999996)
('yuv.max=', 247.24999999999997, 'yuv.min=', 10.69)
('yuv.max=', 212.989, 'yuv.min=', 17.776)
('yuv.max=', 185.86699999999999, 'yuv.min=', 22.010999999999999)
('yuv.max=', 191.43699999999998, 'yuv.min=', 14.744)
('yuv.max=', 250.65199999999999, 'yuv.min=', 11.238999999999999)
('yuv.max=', 254.35900000000001, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 48.050783999999993)
('yuv.max=', 204.62624, 'yuv.min=', 28.860999999999997)
('yuv.max=', 241.733, 'yuv.min=', 10.0)
('yuv.max=', 248.417, 'yuv.min=', 1.6299999999999999)
('yuv.max=', 249.11399999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 7.5759999999999996)
('yuv.max=', 250.91799999999998, 'yuv.min=', 38.476999999999997)
('yuv.max=', 202.40000000000001, 'yuv.min=', 76.126999999999995)
('yuv.max=', 177.47800000000001, 'yuv.min=', 24.277999999999999)
('yuv.max=', 250.04899999999998, 'yuv.min=', 28.717000000000002)
('yuv.max=', 255.0, 'yuv.min=', 31.937000000000001)
('yuv.max=', 229.846, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 221.60556800000001, 'yuv.min=', 21.212)
('yuv.max=', 236.06, 'yuv.min=', 1.2709999999999999)
('yuv.max=', 215.20199999999997, 'yuv.min=', 36.497999999999998)
('yuv.max=', 231.99100000000001, 'yuv.min=', 17.28032)
('yuv.max=', 221.74000000000001, 'yuv.min=', 52.632999999999996)
('yuv.max=', 255.0, 'yuv.min=', 8.391)
('yuv.max=', 233.28800000000001, 'yuv.min=', 28.114000000000001)
('yuv.max=', 209.85399999999998, 'yuv.min=', 17.885999999999999)
('yuv.max=', 219.0, 'yuv.min=', 2.6909999999999998)
('yuv.max=', 207.172, 'yuv.min=', 38.414000000000001)
('yuv.max=', 253.10299999999998, 'yuv.min=', 1.613)
('yuv.max=', 177.59312, 'yuv.min=', 61.707000000000001)
('yuv.max=', 218.63, 'yuv.min=', 25.945999999999998)
('yuv.max=', 250.88599999999997, 'yuv.min=', 0.0)
('yuv.max=', 254.65800000000002, 'yuv.min=', 8.0779999999999994)
('yuv.max=', 242.804, 'yuv.min=', 4.9530000000000003)
('yuv.max=', 208.95099999999999, 'yuv.min=', 48.457000000000001)
('yuv.max=', 226.56599999999997, 'yuv.min=', 11.786999999999999)
('yuv.max=', 220.68099999999998, 'yuv.min=', 1.2110000000000001)
('yuv.max=', 219.09400000000002, 'yuv.min=', 85.694688000000014)
('yuv.max=', 250.0, 'yuv.min=', 12.999999999999998)
('yuv.max=', 254.43000000000001, 'yuv.min=', 13.327)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 236.417, 'yuv.min=', 25.853999999999996)
('yuv.max=', 255.0, 'yuv.min=', 5.5979999999999999)
('yuv.max=', 255.0, 'yuv.min=', 6.5679999999999996)
('yuv.max=', 217.46600000000001, 'yuv.min=', 11.851000000000001)
('yuv.max=', 239.78299999999999, 'yuv.min=', 30.577999999999999)
('yuv.max=', 206.29099999999997, 'yuv.min=', 17.033000000000001)
('yuv.max=', 250.68999999999997, 'yuv.min=', 0.0)
('yuv.max=', 214.58399999999997, 'yuv.min=', 48.409999999999997)
('yuv.max=', 241.572, 'yuv.min=', 20.369999999999997)
('yuv.max=', 225.041, 'yuv.min=', 2.0600000000000001)
('yuv.max=', 251.167, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 254.41299999999995, 'yuv.min=', 40.187999999999995)
('yuv.max=', 254.65800000000002, 'yuv.min=', 37.454999999999998)
('yuv.max=', 205.40200000000002, 'yuv.min=', 8.6579999999999995)
('yuv.max=', 255.0, 'yuv.min=', 2.5870000000000002)
('yuv.max=', 251.38699999999997, 'yuv.min=', 20.731999999999999)
('yuv.max=', 214.51500000000001, 'yuv.min=', 10.800224)
('yuv.max=', 241.04299999999998, 'yuv.min=', 26.059999999999999)
('yuv.max=', 255.0, 'yuv.min=', 7.0709999999999997)
('yuv.max=', 249.02199999999999, 'yuv.min=', 40.890999999999998)
('yuv.max=', 253.65799999999999, 'yuv.min=', 38.173999999999999)
('yuv.max=', 255.0, 'yuv.min=', 26.999999999999996)
('yuv.max=', 239.249, 'yuv.min=', 10.776)
('yuv.max=', 236.86099999999999, 'yuv.min=', 41.917000000000002)
('yuv.max=', 254.08800000000002, 'yuv.min=', 13.032)
('yuv.max=', 249.755, 'yuv.min=', 24.693000000000001)
('yuv.max=', 235.72300000000001, 'yuv.min=', 44.970999999999997)
('yuv.max=', 248.40799999999999, 'yuv.min=', 107.304576)
('yuv.max=', 245.23899999999998, 'yuv.min=', 22.720999999999997)
('yuv.max=', 255.0, 'yuv.min=', 3.887)
('yuv.max=', 161.83737599999998, 'yuv.min=', 18.420000000000002)
('yuv.max=', 255.0, 'yuv.min=', 27.510000000000002)
('yuv.max=', 247.92899999999997, 'yuv.min=', 41.688000000000002)
('yuv.max=', 164.07449600000001, 'yuv.min=', 57.735999999999997)
('yuv.max=', 255.0, 'yuv.min=', 82.0)
('yuv.max=', 215.76100000000002, 'yuv.min=', 18.064999999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', 15.917999999999999)
('yuv.max=', 246.08699999999999, 'yuv.min=', 9.9350000000000005)
('yuv.max=', 205.26399999999998, 'yuv.min=', 0.0)
('yuv.max=', 189.69299999999998, 'yuv.min=', 36.884999999999998)
('yuv.max=', 255.0, 'yuv.min=', 35.851999999999997)
('yuv.max=', 255.0, 'yuv.min=', 13.569000000000001)
('yuv.max=', 255.0, 'yuv.min=', 3.2279999999999998)
('yuv.max=', 246.0, 'yuv.min=', 46.431999999999995)
('yuv.max=', 224.18899999999999, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 197.95899999999997, 'yuv.min=', 59.609999999999999)
('yuv.max=', 227.10299999999998, 'yuv.min=', 4.923)
('yuv.max=', 252.0, 'yuv.min=', 45.0)
('yuv.max=', 211.927232, 'yuv.min=', 5.9169999999999998)
('yuv.max=', 250.17899999999997, 'yuv.min=', 32.323)
('yuv.max=', 239.202, 'yuv.min=', 8.9609999999999985)
('yuv.max=', 250.99999999999997, 'yuv.min=', 18.016999999999996)
('yuv.max=', 244.02499999999998, 'yuv.min=', 58.954999999999998)
('yuv.max=', 200.858, 'yuv.min=', 9.2560000000000002)
('yuv.max=', 237.0, 'yuv.min=', 12.760999999999999)
('yuv.max=', 236.31, 'yuv.min=', 10.382999999999999)
('yuv.max=', 243.99999999999997, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 233.239, 'yuv.min=', 29.358999999999998)
('yuv.max=', 247.09199999999998, 'yuv.min=', 0.68400000000000005)
('yuv.max=', 252.13099999999997, 'yuv.min=', 29.229999999999997)
('yuv.max=', 254.886, 'yuv.min=', 60.461999999999996)
('yuv.max=', 213.77000000000001, 'yuv.min=', 35.686999999999998)
('yuv.max=', 255.0, 'yuv.min=', 12.905999999999999)
('yuv.max=', 203.054, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 242.971, 'yuv.min=', 17.117999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 198.20600000000002, 'yuv.min=', 28.320999999999998)
('yuv.max=', 243.74399999999997, 'yuv.min=', 7.8859999999999992)
('yuv.max=', 206.20999999999998, 'yuv.min=', 44.307000000000002)
('yuv.max=', 224.815, 'yuv.min=', 26.472999999999999)
('yuv.max=', 225.55499999999998, 'yuv.min=', 24.091999999999999)
('yuv.max=', 255.0, 'yuv.min=', 62.250999999999998)
('yuv.max=', 249.07499999999999, 'yuv.min=', 9.9290000000000003)
('yuv.max=', 214.92499999999998, 'yuv.min=', 4.5529999999999999)
('yuv.max=', 217.49000000000001, 'yuv.min=', 61.231999999999999)
('yuv.max=', 247.48799999999997, 'yuv.min=', 35.670000000000002)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 249.881, 'yuv.min=', 11.109)
('yuv.max=', 198.29900000000001, 'yuv.min=', 23.712)
('yuv.max=', 251.13099999999997, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 207.185, 'yuv.min=', 61.11099999999999)
('yuv.max=', 183.953, 'yuv.min=', 8.2669999999999995)
('yuv.max=', 248.88599999999997, 'yuv.min=', 7.7830000000000004)
('yuv.max=', 193.27100000000002, 'yuv.min=', 3.0489999999999995)
('yuv.max=', 255.0, 'yuv.min=', 15.261999999999999)
('yuv.max=', 215.74799999999999, 'yuv.min=', 13.484)
('yuv.max=', 251.42299999999997, 'yuv.min=', 22.402000000000001)
('yuv.max=', 208.24099999999999, 'yuv.min=', 46.164000000000001)
('yuv.max=', 203.80800000000002, 'yuv.min=', 14.245999999999999)
('yuv.max=', 221.82499999999996, 'yuv.min=', 15.701999999999998)
('yuv.max=', 214.09599999999998, 'yuv.min=', 6.5060000000000002)
('yuv.max=', 229.99999999999997, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 230.93499999999997, 'yuv.min=', 39.701000000000001)
('yuv.max=', 213.97200000000001, 'yuv.min=', 0.0)
('yuv.max=', 229.09699999999998, 'yuv.min=', 19.854999999999997)
('yuv.max=', 211.994, 'yuv.min=', 4.5809999999999995)
('yuv.max=', 248.69, 'yuv.min=', 30.041999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 0.0)
('yuv.max=', 188.14699999999999, 'yuv.min=', 25.515999999999998)
('yuv.max=', 237.40499999999997, 'yuv.min=', 15.959)
('yuv.max=', 188.94399999999999, 'yuv.min=', 14.861999999999998)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 219.19600000000003, 'yuv.min=', 6.3419999999999996)
('yuv.max=', 252.114, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 252.77199999999999, 'yuv.min=', 0.0)
('yuv.max=', 226.96099999999998, 'yuv.min=', 14.039)
('yuv.max=', 239.71699999999998, 'yuv.min=', 34.802)
('yuv.max=', 235.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 167.50299999999999, 'yuv.min=', 20.878999999999998)
('yuv.max=', 247.71199999999999, 'yuv.min=', 26.334)
('yuv.max=', 251.44499999999996, 'yuv.min=', 17.640999999999998)
('yuv.max=', 242.90299999999999, 'yuv.min=', 15.039000000000001)
('yuv.max=', 230.67999999999998, 'yuv.min=', 7.2000000000000002)
('yuv.max=', 141.181152, 'yuv.min=', 10.228)
('yuv.max=', 168.55099999999999, 'yuv.min=', 24.151)
('yuv.max=', 221.435, 'yuv.min=', 10.963999999999999)
('yuv.max=', 255.0, 'yuv.min=', 4.6559999999999997)
('yuv.max=', 255.0, 'yuv.min=', 34.192999999999998)
('yuv.max=', 220.02799999999996, 'yuv.min=', 8.875)
('yuv.max=', 228.31799999999998, 'yuv.min=', 32.446999999999996)
('yuv.max=', 203.78899999999999, 'yuv.min=', 29.728999999999999)
('yuv.max=', 214.84299999999999, 'yuv.min=', 28.309999999999999)
('yuv.max=', 214.761, 'yuv.min=', 48.786999999999999)
('yuv.max=', 229.78100000000001, 'yuv.min=', 19.57)
('yuv.max=', 253.59799999999998, 'yuv.min=', 43.059999999999995)
('yuv.max=', 255.0, 'yuv.min=', 12.048999999999999)
('yuv.max=', 255.0, 'yuv.min=', 66.778000000000006)
('yuv.max=', 221.55799999999999, 'yuv.min=', 17.704000000000001)
('yuv.max=', 252.64099999999996, 'yuv.min=', 36.375999999999998)
('yuv.max=', 233.62299999999999, 'yuv.min=', 7.4020000000000001)
('yuv.max=', 243.79300000000001, 'yuv.min=', 29.225999999999999)
('yuv.max=', 240.24299999999999, 'yuv.min=', 23.658000000000001)
('yuv.max=', 243.74499999999998, 'yuv.min=', 62.986000000000004)
('yuv.max=', 198.64299999999997, 'yuv.min=', 9.238999999999999)
('yuv.max=', 223.26399999999998, 'yuv.min=', 0.0)
('yuv.max=', 192.66761600000001, 'yuv.min=', 48.440999999999995)
('yuv.max=', 254.70099999999999, 'yuv.min=', 34.658000000000001)
('yuv.max=', 164.80531200000001, 'yuv.min=', 1.413)
('yuv.max=', 218.614, 'yuv.min=', 0.0)
('yuv.max=', 241.434, 'yuv.min=', 26.869)
('yuv.max=', 194.97099999999998, 'yuv.min=', 79.536383999999998)
('yuv.max=', 231.15799999999999, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 254.58699999999999, 'yuv.min=', 49.503)
('yuv.max=', 202.918688, 'yuv.min=', 26.216000000000001)
('yuv.max=', 235.25999999999999, 'yuv.min=', 3.1850000000000001)
('yuv.max=', 234.0, 'yuv.min=', 14.0)
('yuv.max=', 215.03280000000001, 'yuv.min=', 3.2989999999999999)
('yuv.max=', 255.0, 'yuv.min=', 51.689999999999998)
('yuv.max=', 246.00399999999999, 'yuv.min=', 30.579999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.28799999999995, 'yuv.min=', 0.0)
('yuv.max=', 236.79799999999997, 'yuv.min=', 22.583000000000002)
('yuv.max=', 228.40099999999998, 'yuv.min=', 2.0709999999999997)
('yuv.max=', 211.42600000000002, 'yuv.min=', 25.981000000000002)
('yuv.max=', 183.46699999999998, 'yuv.min=', 1.8240000000000001)
('yuv.max=', 253.70099999999996, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 252.24499999999998, 'yuv.min=', 3.4129999999999998)
('yuv.max=', 241.93999999999997, 'yuv.min=', 0.0)
('yuv.max=', 245.48400000000001, 'yuv.min=', 40.831000000000003)
('yuv.max=', 224.95699999999999, 'yuv.min=', 25.590999999999998)
('yuv.max=', 238.798, 'yuv.min=', 18.259999999999998)
('yuv.max=', 244.572, 'yuv.min=', 24.734999999999999)
('yuv.max=', 255.0, 'yuv.min=', 62.425000000000004)
('yuv.max=', 174.01899999999998, 'yuv.min=', 3.456)
('yuv.max=', 203.38099999999997, 'yuv.min=', 6.8860000000000001)
('yuv.max=', 252.57199999999997, 'yuv.min=', 50.635999999999996)
('yuv.max=', 175.90200000000002, 'yuv.min=', 28.793999999999997)
('yuv.max=', 254.77200000000002, 'yuv.min=', 38.169999999999995)
('yuv.max=', 254.886, 'yuv.min=', 8.0229999999999997)
('yuv.max=', 242.54900000000001, 'yuv.min=', 21.167999999999999)
('yuv.max=', 181.06, 'yuv.min=', 38.532000000000004)
('yuv.max=', 192.54199999999997, 'yuv.min=', 46.157000000000004)
('yuv.max=', 215.53899999999999, 'yuv.min=', 23.315999999999999)
('yuv.max=', 226.28600000000003, 'yuv.min=', 34.436)
('yuv.max=', 243.31799999999998, 'yuv.min=', 7.7719999999999994)
('yuv.max=', 210.52499999999998, 'yuv.min=', 43.695999999999998)
('yuv.max=', 226.36700000000002, 'yuv.min=', 26.024999999999999)
('yuv.max=', 236.89999999999998, 'yuv.min=', 18.074000000000002)
('yuv.max=', 222.99199999999996, 'yuv.min=', 10.725999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 1.0110000000000001)
('yuv.max=', 231.14399999999995, 'yuv.min=', 34.107999999999997)
('yuv.max=', 255.0, 'yuv.min=', 21.081999999999997)
('yuv.max=', 210.72199999999998, 'yuv.min=', 23.765000000000001)
('yuv.max=', 239.71799999999999, 'yuv.min=', 47.177999999999997)
('yuv.max=', 175.09199999999998, 'yuv.min=', 35.475000000000001)
('yuv.max=', 218.126, 'yuv.min=', 16.355)
('yuv.max=', 234.38499999999999, 'yuv.min=', 68.911999999999992)
('yuv.max=', 255.0, 'yuv.min=', 73.853999999999999)
('yuv.max=', 250.88599999999997, 'yuv.min=', 3.9569999999999999)
('yuv.max=', 186.22999999999999, 'yuv.min=', 51.155999999999999)
('yuv.max=', 227.13000000000002, 'yuv.min=', 32.102999999999994)
('yuv.max=', 255.0, 'yuv.min=', 12.907999999999999)
('yuv.max=', 194.72999999999999, 'yuv.min=', 12.657999999999999)
('yuv.max=', 216.62700000000001, 'yuv.min=', 41.279000000000003)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 235.58699999999996, 'yuv.min=', 21.043999999999997)
('yuv.max=', 248.84700000000001, 'yuv.min=', 2.1739999999999999)
('yuv.max=', 255.0, 'yuv.min=', 17.530999999999999)
('yuv.max=', 192.50300000000001, 'yuv.min=', 80.504999999999995)
('yuv.max=', 165.105536, 'yuv.min=', 16.628)
('yuv.max=', 161.29900000000001, 'yuv.min=', 16.436)
('yuv.max=', 255.0, 'yuv.min=', 8.6790000000000003)
('yuv.max=', 232.24600000000001, 'yuv.min=', 37.402000000000001)
('yuv.max=', 252.13299999999995, 'yuv.min=', 14.625)
('yuv.max=', 207.90099999999998, 'yuv.min=', 0.0)
('yuv.max=', 207.61099999999999, 'yuv.min=', 14.02)
('yuv.max=', 255.0, 'yuv.min=', 43.489000000000004)
('yuv.max=', 248.83599999999998, 'yuv.min=', 25.220000000000002)
('yuv.max=', 250.20699999999997, 'yuv.min=', 26.974999999999998)
('yuv.max=', 252.83199999999997, 'yuv.min=', 0.0)
('yuv.max=', 208.76499999999999, 'yuv.min=', 34.103000000000002)
('yuv.max=', 239.387, 'yuv.min=', 67.281999999999996)
('yuv.max=', 229.74099999999999, 'yuv.min=', 13.889999999999999)
('yuv.max=', 193.93081600000002, 'yuv.min=', 25.829000000000001)
('yuv.max=', 166.49200000000002, 'yuv.min=', 71.087999999999994)
('yuv.max=', 243.18800000000002, 'yuv.min=', 15.298999999999999)
('yuv.max=', 229.10599999999999, 'yuv.min=', 62.476999999999997)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 226.83699999999996, 'yuv.min=', 0.0)
('yuv.max=', 173.22799999999998, 'yuv.min=', 77.188999999999993)
('yuv.max=', 238.72899999999998, 'yuv.min=', 18.113)
('yuv.max=', 250.22800000000001, 'yuv.min=', 26.158999999999999)
('yuv.max=', 251.64099999999999, 'yuv.min=', 34.085999999999999)
('yuv.max=', 247.70099999999996, 'yuv.min=', 2.6579999999999999)
('yuv.max=', 220.31099999999998, 'yuv.min=', 16.928999999999998)
('yuv.max=', 205.762, 'yuv.min=', 3.8649999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 234.0, 'yuv.min=', 32.494)
('yuv.max=', 235.22399999999999, 'yuv.min=', 1.9830000000000001)
('yuv.max=', 255.0, 'yuv.min=', 1.4729999999999999)
('yuv.max=', 237.85299999999998, 'yuv.min=', 17.045000000000002)
('yuv.max=', 252.92899999999997, 'yuv.min=', 21.189)
('yuv.max=', 237.0, 'yuv.min=', 17.0)
('yuv.max=', 209.84599999999998, 'yuv.min=', 9.4019999999999992)
('yuv.max=', 208.76299999999998, 'yuv.min=', 51.715999999999994)
('yuv.max=', 242.786, 'yuv.min=', 3.331)
('yuv.max=', 251.83700000000002, 'yuv.min=', 38.063999999999993)
('yuv.max=', 222.547, 'yuv.min=', 0.0)
('yuv.max=', 235.09599999999998, 'yuv.min=', 12.225)
('yuv.max=', 238.42099999999999, 'yuv.min=', 49.090000000000003)
('yuv.max=', 230.27099999999999, 'yuv.min=', 8.1189999999999998)
('yuv.max=', 231.46699999999998, 'yuv.min=', 1.456)
('yuv.max=', 233.78299999999999, 'yuv.min=', 31.946000000000002)
('yuv.max=', 253.80399999999997, 'yuv.min=', 4.8319999999999999)
('yuv.max=', 240.99999999999997, 'yuv.min=', 71.647000000000006)
('yuv.max=', 205.61899999999997, 'yuv.min=', 13.895999999999999)
('yuv.max=', 247.77599999999998, 'yuv.min=', 1.516)
('yuv.max=', 177.30099999999999, 'yuv.min=', 20.597999999999999)
('yuv.max=', 250.114, 'yuv.min=', 22.359000000000002)
('yuv.max=', 208.999, 'yuv.min=', 18.956)
('yuv.max=', 255.0, 'yuv.min=', 47.890000000000001)
('yuv.max=', 255.0, 'yuv.min=', 15.475999999999999)
('yuv.max=', 246.80399999999997, 'yuv.min=', 42.084895999999993)
('yuv.max=', 255.0, 'yuv.min=', 26.999999999999996)
('yuv.max=', 222.23099999999999, 'yuv.min=', 19.632000000000001)
('yuv.max=', 216.10299999999998, 'yuv.min=', 39.060000000000002)
('yuv.max=', 242.61000000000001, 'yuv.min=', 1.325)
('yuv.max=', 210.90100000000001, 'yuv.min=', 17.593999999999998)
('yuv.max=', 201.86199999999997, 'yuv.min=', 39.562999999999995)
('yuv.max=', 247.11399999999998, 'yuv.min=', 51.010999999999996)
('yuv.max=', 248.28799999999995, 'yuv.min=', 23.257999999999999)
('yuv.max=', 255.0, 'yuv.min=', 24.332000000000001)
('yuv.max=', 234.95999999999998, 'yuv.min=', 31.491999999999997)
('yuv.max=', 220.93700000000001, 'yuv.min=', 67.262)
('yuv.max=', 210.768, 'yuv.min=', 49.881)
('yuv.max=', 234.10900000000001, 'yuv.min=', 1.587)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.10299999999998, 'yuv.min=', 13.055999999999999)
('yuv.max=', 255.0, 'yuv.min=', 48.423999999999992)
('yuv.max=', 228.08899999999997, 'yuv.min=', 38.323999999999998)
('yuv.max=', 255.0, 'yuv.min=', 11.317999999999998)
('yuv.max=', 249.00999999999999, 'yuv.min=', 74.11399999999999)
('yuv.max=', 231.226, 'yuv.min=', 17.893000000000001)
('yuv.max=', 237.90299999999999, 'yuv.min=', 26.983000000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 253.505, 'yuv.min=', 7.4779999999999998)
('yuv.max=', 255.0, 'yuv.min=', 60.591000000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', 34.478999999999999)
('yuv.max=', 215.09099999999998, 'yuv.min=', 0.0)
('yuv.max=', 237.14599999999996, 'yuv.min=', 78.833999999999989)
('yuv.max=', 255.0, 'yuv.min=', 59.338999999999999)
('yuv.max=', 246.0, 'yuv.min=', 8.0969999999999995)
('yuv.max=', 221.21800000000002, 'yuv.min=', 13.421999999999999)
('yuv.max=', 227.455072, 'yuv.min=', 1.516)
('yuv.max=', 198.43000000000001, 'yuv.min=', 42.515000000000001)
('yuv.max=', 255.0, 'yuv.min=', 41.585000000000001)
('yuv.max=', 255.0, 'yuv.min=', 34.707999999999998)
('yuv.max=', 250.79300000000001, 'yuv.min=', 2.3479999999999999)
('yuv.max=', 250.626, 'yuv.min=', 63.871000000000002)
('yuv.max=', 237.71599999999998, 'yuv.min=', 54.595999999999997)
('yuv.max=', 230.28100000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 18.971999999999998)
('yuv.max=', 192.69999999999999, 'yuv.min=', 6.4619999999999997)
('yuv.max=', 246.12300000000002, 'yuv.min=', 5.7720000000000002)
('yuv.max=', 240.47399999999999, 'yuv.min=', 23.815000000000001)
('yuv.max=', 187.80799999999999, 'yuv.min=', 71.09899999999999)
('yuv.max=', 251.495, 'yuv.min=', 54.521999999999998)
('yuv.max=', 232.45599999999999, 'yuv.min=', 13.983000000000001)
('yuv.max=', 159.16299999999998, 'yuv.min=', 19.809999999999999)
('yuv.max=', 227.822, 'yuv.min=', 14.169)
('yuv.max=', 240.31599999999997, 'yuv.min=', 37.018999999999998)
('yuv.max=', 231.267, 'yuv.min=', 4.9289999999999994)
('yuv.max=', 234.19999999999999, 'yuv.min=', 33.634999999999998)
('yuv.max=', 255.0, 'yuv.min=', 55.619)
('yuv.max=', 247.86499999999998, 'yuv.min=', 2.3940000000000001)
('yuv.max=', 218.69, 'yuv.min=', 9.6020000000000003)
('yuv.max=', 203.42099999999999, 'yuv.min=', 40.774999999999999)
('yuv.max=', 255.0, 'yuv.min=', 54.419000000000004)
('yuv.max=', 231.43099999999998, 'yuv.min=', 38.582999999999998)
('yuv.max=', 228.85399999999998, 'yuv.min=', 26.928999999999998)
('yuv.max=', 246.28299999999999, 'yuv.min=', 12.849)
('yuv.max=', 255.0, 'yuv.min=', 22.689999999999998)
('yuv.max=', 241.91399999999999, 'yuv.min=', 13.607999999999999)
('yuv.max=', 242.96099999999996, 'yuv.min=', 5.4729999999999999)
('yuv.max=', 240.078, 'yuv.min=', 15.033999999999999)
('yuv.max=', 179.37376, 'yuv.min=', 5.6579999999999995)
('yuv.max=', 197.74000000000001, 'yuv.min=', 5.0389999999999997)
('yuv.max=', 252.28800000000001, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 203.786688, 'yuv.min=', 21.090000000000003)
('yuv.max=', 253.0, 'yuv.min=', 38.999999999999993)
('yuv.max=', 204.18499999999997, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 255.0, 'yuv.min=', 9.9809999999999999)
('yuv.max=', 176.285, 'yuv.min=', 26.875)
('yuv.max=', 237.70899999999997, 'yuv.min=', 5.3849999999999998)
('yuv.max=', 255.0, 'yuv.min=', 31.241999999999997)
('yuv.max=', 255.0, 'yuv.min=', 18.662999999999997)
('yuv.max=', 237.13800000000001, 'yuv.min=', 10.327)
('yuv.max=', 240.54399999999998, 'yuv.min=', 43.402999999999999)
('yuv.max=', 234.834, 'yuv.min=', 23.748999999999999)
('yuv.max=', 174.95000000000002, 'yuv.min=', 7.6690000000000005)
('yuv.max=', 240.22799999999998, 'yuv.min=', 39.433999999999997)
('yuv.max=', 233.32500000000002, 'yuv.min=', 17.906880000000001)
('yuv.max=', 250.83599999999998, 'yuv.min=', 26.725999999999999)
('yuv.max=', 175.79599999999996, 'yuv.min=', 16.594999999999999)
('yuv.max=', 237.32499999999999, 'yuv.min=', 12.004000000000001)
('yuv.max=', 239.95699999999999, 'yuv.min=', 30.544)
('yuv.max=', 177.45099999999999, 'yuv.min=', 83.552000000000007)
('yuv.max=', 210.05199999999999, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 234.31, 'yuv.min=', 12.276999999999999)
('yuv.max=', 146.08699999999999, 'yuv.min=', 9.8529999999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', 14.248999999999999)
('yuv.max=', 245.65799999999999, 'yuv.min=', 4.718)
('yuv.max=', 244.08799999999999, 'yuv.min=', 30.059999999999999)
('yuv.max=', 205.91199999999998, 'yuv.min=', 10.620000000000001)
('yuv.max=', 229.58000000000001, 'yuv.min=', 37.151999999999994)
('yuv.max=', 230.90656000000001, 'yuv.min=', 37.692)
('yuv.max=', 255.0, 'yuv.min=', 12.472999999999999)
('yuv.max=', 229.97899999999996, 'yuv.min=', 17.004000000000001)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 237.45799999999997, 'yuv.min=', 43.210000000000001)
('yuv.max=', 244.18899999999999, 'yuv.min=', 27.021000000000001)
('yuv.max=', 240.43999999999997, 'yuv.min=', 8.1890000000000001)
('yuv.max=', 213.31700000000001, 'yuv.min=', 52.560999999999993)
('yuv.max=', 243.72199999999998, 'yuv.min=', 62.771000000000001)
('yuv.max=', 168.730816, 'yuv.min=', 25.131)
('yuv.max=', 229.92299999999997, 'yuv.min=', 29.130999999999997)
('yuv.max=', 184.68800000000002, 'yuv.min=', 20.372)
('yuv.max=', 252.0, 'yuv.min=', 19.0)
('yuv.max=', 248.24699999999999, 'yuv.min=', 26.597999999999999)
('yuv.max=', 227.755, 'yuv.min=', 27.381999999999998)
('yuv.max=', 216.37, 'yuv.min=', 10.465999999999999)
('yuv.max=', 236.334, 'yuv.min=', 31.267999999999997)
('yuv.max=', 255.0, 'yuv.min=', 15.637)
('yuv.max=', 227.09799999999998, 'yuv.min=', 29.337)
('yuv.max=', 212.44399999999999, 'yuv.min=', 25.622999999999998)
('yuv.max=', 239.131, 'yuv.min=', 59.908000000000001)
('yuv.max=', 186.58099999999999, 'yuv.min=', 13.516000000000002)
('yuv.max=', 217.32900000000001, 'yuv.min=', 6.9119999999999999)
('yuv.max=', 212.661, 'yuv.min=', 18.045999999999999)
('yuv.max=', 233.35499999999999, 'yuv.min=', 9.7379999999999995)
('yuv.max=', 237.86099999999999, 'yuv.min=', 16.173999999999999)
('yuv.max=', 216.84876800000001, 'yuv.min=', 16.613)
('yuv.max=', 184.024, 'yuv.min=', 59.503)
('yuv.max=', 247.548, 'yuv.min=', 29.733000000000001)
('yuv.max=', 252.81499999999997, 'yuv.min=', 30.928999999999998)
('yuv.max=', 193.25606400000001, 'yuv.min=', 2.9119999999999999)
('yuv.max=', 233.55599999999998, 'yuv.min=', 31.105999999999998)
('yuv.max=', 252.77199999999999, 'yuv.min=', 27.466999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 235.33199999999999, 'yuv.min=', 28.071999999999999)
('yuv.max=', 214.13499999999999, 'yuv.min=', 11.103)
('yuv.max=', 252.92899999999997, 'yuv.min=', 21.645)
('yuv.max=', 255.0, 'yuv.min=', 17.879999999999999)
('yuv.max=', 255.0, 'yuv.min=', 16.587)
('yuv.max=', 248.768, 'yuv.min=', 25.978999999999999)
('yuv.max=', 220.91799999999998, 'yuv.min=', 29.870999999999995)
('yuv.max=', 252.821, 'yuv.min=', 37.942)
('yuv.max=', 240.071, 'yuv.min=', 3.0121279999999935)
('yuv.max=', 255.0, 'yuv.min=', 16.196000000000002)
('yuv.max=', 236.05799999999999, 'yuv.min=', 14.715999999999999)
('yuv.max=', 243.89699999999999, 'yuv.min=', 14.407999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 221.86499999999998, 'yuv.min=', 35.805)
('yuv.max=', 255.0, 'yuv.min=', 5.2559999999999993)
('yuv.max=', 248.441, 'yuv.min=', 25.750999999999998)
('yuv.max=', 171.43680000000001, 'yuv.min=', 27.265999999999998)
('yuv.max=', 213.75099999999998, 'yuv.min=', 20.832999999999998)
('yuv.max=', 252.886, 'yuv.min=', 33.353000000000002)
('yuv.max=', 255.0, 'yuv.min=', 82.0)
('yuv.max=', 180.29289599999998, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 255.0, 'yuv.min=', 23.885999999999999)
('yuv.max=', 195.68199999999999, 'yuv.min=', 44.806999999999995)
('yuv.max=', 231.15100000000001, 'yuv.min=', 13.244)
('yuv.max=', 242.33500000000001, 'yuv.min=', 27.309999999999999)
('yuv.max=', 250.59800000000001, 'yuv.min=', 28.608999999999998)
('yuv.max=', 254.08800000000002, 'yuv.min=', 41.451999999999998)
('yuv.max=', 205.11499999999998, 'yuv.min=', 4.0410000000000004)
('yuv.max=', 248.61499999999998, 'yuv.min=', 4.2219999999999995)
('yuv.max=', 255.0, 'yuv.min=', 15.785999999999998)
('yuv.max=', 222.04299999999998, 'yuv.min=', 44.882999999999996)
('yuv.max=', 253.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 255.0, 'yuv.min=', 8.8520000000000003)
('yuv.max=', 210.31, 'yuv.min=', 42.723999999999997)
('yuv.max=', 214.54599999999999, 'yuv.min=', 10.717000000000001)
('yuv.max=', 255.0, 'yuv.min=', 16.43)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 188.90799999999999, 'yuv.min=', 14.960999999999999)
('yuv.max=', 193.0, 'yuv.min=', 38.0)
('yuv.max=', 229.89099999999996, 'yuv.min=', 0.114)
('yuv.max=', 245.869, 'yuv.min=', 0.0)
('yuv.max=', 243.76199999999997, 'yuv.min=', 24.556992000000001)
('yuv.max=', 236.232, 'yuv.min=', 28.991)
('yuv.max=', 233.96799999999999, 'yuv.min=', 49.809999999999995)
('yuv.max=', 248.35900000000001, 'yuv.min=', 26.004000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 33.57)
('yuv.max=', 229.07999999999998, 'yuv.min=', 49.54699999999999)
('yuv.max=', 233.95899999999997, 'yuv.min=', 18.957000000000001)
('yuv.max=', 200.11599999999999, 'yuv.min=', 29.856999999999996)
('yuv.max=', 254.28799999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 2.968)
('yuv.max=', 225.91800000000001, 'yuv.min=', 58.337000000000003)
('yuv.max=', 254.40199999999999, 'yuv.min=', 7.5590000000000002)
('yuv.max=', 251.989, 'yuv.min=', 13.911)
('yuv.max=', 181.37, 'yuv.min=', 19.331)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 238.64999999999998, 'yuv.min=', 11.291)
('yuv.max=', 197.06199999999998, 'yuv.min=', 2.1829999999999998)
('yuv.max=', 240.869, 'yuv.min=', 9.2539999999999996)
('yuv.max=', 242.71199999999999, 'yuv.min=', 50.283904000000007)
('yuv.max=', 254.017, 'yuv.min=', 16.456)
('yuv.max=', 246.98899999999998, 'yuv.min=', 67.259)
('yuv.max=', 248.131, 'yuv.min=', 3.2879999999999998)
('yuv.max=', 226.72899999999998, 'yuv.min=', 17.163)
('yuv.max=', 246.21699999999998, 'yuv.min=', 6.8319999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 50.999999999999993)
('yuv.max=', 184.21219200000002, 'yuv.min=', 3.2669999999999999)
('yuv.max=', 253.42999999999998, 'yuv.min=', 0.0)
('yuv.max=', 241.61200000000002, 'yuv.min=', 43.829999999999998)
('yuv.max=', 244.148, 'yuv.min=', 54.617000000000004)
('yuv.max=', 225.31799999999998, 'yuv.min=', 13.85)
('yuv.max=', 249.79299999999998, 'yuv.min=', 23.908000000000001)
('yuv.max=', 220.47300000000001, 'yuv.min=', 21.509999999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', 5.4169999999999998)
('yuv.max=', 255.0, 'yuv.min=', 65.225999999999999)
('yuv.max=', 224.30500000000001, 'yuv.min=', 12.071)
('yuv.max=', 208.739, 'yuv.min=', 0.0)
('yuv.max=', 250.98899999999998, 'yuv.min=', 1.7270000000000001)
('yuv.max=', 236.31699999999998, 'yuv.min=', 21.325999999999997)
('yuv.max=', 220.572, 'yuv.min=', 83.956999999999994)
('yuv.max=', 230.65699999999998, 'yuv.min=', 20.140999999999998)
('yuv.max=', 208.672, 'yuv.min=', 18.099999999999998)
('yuv.max=', 216.80099200000001, 'yuv.min=', 12.034000000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', 12.0)
('yuv.max=', 216.01900000000001, 'yuv.min=', 8.1349999999999998)
('yuv.max=', 247.95099999999996, 'yuv.min=', 30.619)
('yuv.max=', 185.62799999999999, 'yuv.min=', 24.115000000000002)
('yuv.max=', 248.76100000000002, 'yuv.min=', 21.468)
('yuv.max=', 210.71299999999999, 'yuv.min=', 43.561)
('yuv.max=', 233.0, 'yuv.min=', 15.0)
('yuv.max=', 239.98299999999998, 'yuv.min=', 25.532160000000005)
('yuv.max=', 250.79900000000004, 'yuv.min=', 52.955999999999996)
('yuv.max=', 166.47099999999998, 'yuv.min=', 24.773000000000003)
('yuv.max=', 255.0, 'yuv.min=', 19.826000000000001)
('yuv.max=', 234.114, 'yuv.min=', 38.887999999999998)
('yuv.max=', 235.33599999999998, 'yuv.min=', 20.790999999999997)
('yuv.max=', 237.0, 'yuv.min=', 50.0)
('yuv.max=', 237.148, 'yuv.min=', 5.1689999999999996)
('yuv.max=', 255.0, 'yuv.min=', 20.689999999999998)
('yuv.max=', 203.63299999999998, 'yuv.min=', 23.707999999999998)
('yuv.max=', 223.95899999999997, 'yuv.min=', 24.820999999999998)
('yuv.max=', 221.375, 'yuv.min=', 36.123999999999995)
('yuv.max=', 167.85599999999999, 'yuv.min=', 36.630000000000003)
('yuv.max=', 255.0, 'yuv.min=', 14.560999999999998)
('yuv.max=', 193.43199999999999, 'yuv.min=', 44.323)
('yuv.max=', 241.76299999999995, 'yuv.min=', 51.734999999999999)
('yuv.max=', 230.14399999999998, 'yuv.min=', 23.025999999999996)
('yuv.max=', 210.02499999999998, 'yuv.min=', 27.949999999999999)
('yuv.max=', 255.0, 'yuv.min=', 1.4990000000000001)
('yuv.max=', 251.804, 'yuv.min=', 23.618999999999996)
('yuv.max=', 243.99999999999997, 'yuv.min=', 6.0)
('yuv.max=', 254.65800000000002, 'yuv.min=', 18.652000000000001)
('yuv.max=', 240.92899999999997, 'yuv.min=', 11.645999999999999)
('yuv.max=', 245.05000000000001, 'yuv.min=', 90.087999999999994)
('yuv.max=', 251.17399999999998, 'yuv.min=', 3.1139999999999999)
('yuv.max=', 254.886, 'yuv.min=', 32.176000000000002)
('yuv.max=', 248.815, 'yuv.min=', 4.9889999999999999)
('yuv.max=', 253.11399999999998, 'yuv.min=', 5.8649999999999993)
('yuv.max=', 228.44099999999997, 'yuv.min=', 44.984999999999992)
('yuv.max=', 234.22099999999998, 'yuv.min=', 2.8520000000000003)
('yuv.max=', 245.0, 'yuv.min=', 96.0)
('yuv.max=', 255.0, 'yuv.min=', 25.885999999999999)
('yuv.max=', 248.38499999999996, 'yuv.min=', 8.302999999999999)
('yuv.max=', 251.49000000000001, 'yuv.min=', 36.923999999999999)
('yuv.max=', 252.92899999999997, 'yuv.min=', 46.521999999999998)
('yuv.max=', 237.77199999999999, 'yuv.min=', 36.700999999999993)
('yuv.max=', 210.82699999999997, 'yuv.min=', 16.234999999999999)
('yuv.max=', 248.74399999999997, 'yuv.min=', 7.7719999999999994)
('yuv.max=', 255.0, 'yuv.min=', 6.391)
('yuv.max=', 225.14600000000002, 'yuv.min=', 38.591999999999999)
('yuv.max=', 159.89443200000002, 'yuv.min=', 15.878999999999998)
('yuv.max=', 230.637, 'yuv.min=', 24.52)
('yuv.max=', 223.59999999999999, 'yuv.min=', 58.227999999999994)
('yuv.max=', 219.33800000000002, 'yuv.min=', 45.837000000000003)
('yuv.max=', 253.0, 'yuv.min=', 25.220999999999997)
('yuv.max=', 235.72300000000001, 'yuv.min=', 33.998999999999995)
('yuv.max=', 179.167, 'yuv.min=', 60.840000000000003)
('yuv.max=', 251.92899999999995, 'yuv.min=', 18.330999999999996)
('yuv.max=', 205.76599999999999, 'yuv.min=', 48.304000000000002)
('yuv.max=', 223.08399999999997, 'yuv.min=', 22.273)
('yuv.max=', 242.74799999999996, 'yuv.min=', 21.281999999999996)
('yuv.max=', 223.71199999999999, 'yuv.min=', 11.374000000000001)
('yuv.max=', 244.423, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 236.423, 'yuv.min=', 44.387)
('yuv.max=', 188.0, 'yuv.min=', 37.796999999999997)
('yuv.max=', 235.30999999999997, 'yuv.min=', 37.701999999999998)
('yuv.max=', 241.92299999999997, 'yuv.min=', 6.5919999999999987)
('yuv.max=', 202.834, 'yuv.min=', 30.767999999999997)
('yuv.max=', 236.36999999999995, 'yuv.min=', 33.257999999999996)
('yuv.max=', 249.48399999999998, 'yuv.min=', 34.195999999999998)
('yuv.max=', 247.38300000000001, 'yuv.min=', 9.9779999999999998)
('yuv.max=', 245.505, 'yuv.min=', 11.651999999999999)
('yuv.max=', 255.0, 'yuv.min=', 51.289999999999992)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.39699999999999, 'yuv.min=', 21.657999999999998)
('yuv.max=', 206.708, 'yuv.min=', 22.529)
('yuv.max=', 211.85199999999998, 'yuv.min=', 16.141999999999999)
('yuv.max=', 211.72300000000001, 'yuv.min=', 23.212999999999997)
('yuv.max=', 232.92099999999999, 'yuv.min=', 4.0749999999999993)
('yuv.max=', 214.21899999999999, 'yuv.min=', 40.649000000000001)
('yuv.max=', 244.38399999999999, 'yuv.min=', 16.629999999999999)
('yuv.max=', 229.44800000000001, 'yuv.min=', 31.686999999999998)
('yuv.max=', 253.03399999999999, 'yuv.min=', 29.754999999999999)
('yuv.max=', 214.00899999999996, 'yuv.min=', 51.302999999999997)
('yuv.max=', 248.91800000000001, 'yuv.min=', 9.9239999999999995)
('yuv.max=', 245.05000000000001, 'yuv.min=', 47.292999999999992)
('yuv.max=', 247.06, 'yuv.min=', 2.0259999999999998)
('yuv.max=', 253.27700000000002, 'yuv.min=', 61.141999999999996)
('yuv.max=', 237.30099999999999, 'yuv.min=', 30.753999999999998)
('yuv.max=', 194.69399999999999, 'yuv.min=', 54.713000000000001)
('yuv.max=', 220.58299999999997, 'yuv.min=', 14.260999999999999)
('yuv.max=', 240.893, 'yuv.min=', 17.370000000000001)
('yuv.max=', 216.84999999999999, 'yuv.min=', 14.43)
('yuv.max=', 253.48399999999998, 'yuv.min=', 19.928999999999998)
('yuv.max=', 241.80399999999997, 'yuv.min=', 17.766999999999999)
('yuv.max=', 241.309, 'yuv.min=', 37.027000000000001)
('yuv.max=', 186.78999999999999, 'yuv.min=', 63.929000000000002)
('yuv.max=', 229.68100000000001, 'yuv.min=', 20.148)
('yuv.max=', 230.41199999999998, 'yuv.min=', 20.967999999999996)
('yuv.max=', 253.61499999999995, 'yuv.min=', 30.101999999999997)
('yuv.max=', 255.0, 'yuv.min=', 31.091999999999999)
('yuv.max=', 200.39099999999999, 'yuv.min=', 21.706999999999997)
('yuv.max=', 136.51399999999998, 'yuv.min=', 13.064)
('yuv.max=', 251.33099999999996, 'yuv.min=', 42.725999999999999)
('yuv.max=', 255.0, 'yuv.min=', 2.2000000000000002)
('yuv.max=', 154.06100000000001, 'yuv.min=', 20.983999999999998)
('yuv.max=', 208.90655999999998, 'yuv.min=', 26.193999999999999)
('yuv.max=', 255.0, 'yuv.min=', 25.899999999999999)
('yuv.max=', 233.256, 'yuv.min=', 44.024999999999999)
('yuv.max=', 248.78300000000002, 'yuv.min=', 30.456)
('yuv.max=', 255.0, 'yuv.min=', 67.259999999999991)
('yuv.max=', 202.03099999999998, 'yuv.min=', 67.439999999999998)
('yuv.max=', 231.78599999999997, 'yuv.min=', 22.981999999999999)
('yuv.max=', 253.0, 'yuv.min=', 40.156999999999996)
('yuv.max=', 253.989, 'yuv.min=', 13.757)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 250.31999999999999, 'yuv.min=', 14.513999999999999)
('yuv.max=', 238.50099999999998, 'yuv.min=', 48.762)
('yuv.max=', 232.71699999999998, 'yuv.min=', 23.456)
('yuv.max=', 240.13099999999997, 'yuv.min=', 7.9290000000000003)
('yuv.max=', 234.86399999999998, 'yuv.min=', 19.410999999999998)
('yuv.max=', 246.03200000000001, 'yuv.min=', 18.450999999999997)
('yuv.max=', 255.0, 'yuv.min=', 9.9619999999999997)
('yuv.max=', 255.0, 'yuv.min=', 62.042999999999992)
('yuv.max=', 251.74399999999997, 'yuv.min=', 19.843)
('yuv.max=', 249.56999999999996, 'yuv.min=', 11.52)
('yuv.max=', 166.424384, 'yuv.min=', 84.908999999999992)
('yuv.max=', 141.09932800000001, 'yuv.min=', 54.244999999999997)
('yuv.max=', 196.03999999999996, 'yuv.min=', 29.122)
('yuv.max=', 185.09, 'yuv.min=', 31.189)
('yuv.max=', 253.80399999999997, 'yuv.min=', 37.046999999999997)
('yuv.max=', 233.768, 'yuv.min=', 37.372)
('yuv.max=', 255.0, 'yuv.min=', 42.544575999999992)
('yuv.max=', 216.036, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 231.74393599999999, 'yuv.min=', 23.437000000000001)
('yuv.max=', 197.22299999999998, 'yuv.min=', 51.201999999999998)
('yuv.max=', 248.869, 'yuv.min=', 5.1569999999999991)
('yuv.max=', 222.74100000000001, 'yuv.min=', 3.2779999999999996)
('yuv.max=', 249.32699999999997, 'yuv.min=', 0.0)
('yuv.max=', 207.559, 'yuv.min=', 38.330999999999996)
('yuv.max=', 251.886, 'yuv.min=', 15.992999999999999)
('yuv.max=', 254.202, 'yuv.min=', 2.8689999999999998)
('yuv.max=', 246.929, 'yuv.min=', 21.765999999999998)
('yuv.max=', 229.50899999999999, 'yuv.min=', 51.087000000000003)
('yuv.max=', 243.16499999999996, 'yuv.min=', 24.995000000000001)
('yuv.max=', 251.02799999999999, 'yuv.min=', 22.664999999999999)
('yuv.max=', 247.07599999999996, 'yuv.min=', 26.358999999999998)
('yuv.max=', 250.42299999999997, 'yuv.min=', 18.235999999999997)
('yuv.max=', 251.98499999999999, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 214.33379200000002, 'yuv.min=', 39.040999999999997)
('yuv.max=', 255.0, 'yuv.min=', 11.754999999999999)
('yuv.max=', 212.12900000000002, 'yuv.min=', 28.878999999999998)
('yuv.max=', 215.98899999999998, 'yuv.min=', 18.780000000000001)
('yuv.max=', 253.81499999999997, 'yuv.min=', 41.786999999999999)
('yuv.max=', 185.84299999999996, 'yuv.min=', 27.630000000000003)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 179.036, 'yuv.min=', 18.068000000000001)
('yuv.max=', 254.40199999999999, 'yuv.min=', 15.745999999999999)
('yuv.max=', 241.33099999999999, 'yuv.min=', 14.912999999999998)
('yuv.max=', 202.23299999999998, 'yuv.min=', 25.823)
('yuv.max=', 187.19, 'yuv.min=', 5.516)
('yuv.max=', 255.0, 'yuv.min=', 5.8259999999999996)
('yuv.max=', 223.07099999999997, 'yuv.min=', 51.159999999999997)
('yuv.max=', 252.50499999999997, 'yuv.min=', 8.484)
('yuv.max=', 246.96100000000001, 'yuv.min=', 7.8799999999999999)
('yuv.max=', 251.142, 'yuv.min=', 8.0500000000000007)
('yuv.max=', 247.39099999999996, 'yuv.min=', 52.405999999999999)
('yuv.max=', 240.67999999999998, 'yuv.min=', 15.869999999999999)
('yuv.max=', 255.0, 'yuv.min=', 2.71)
('yuv.max=', 254.41299999999995, 'yuv.min=', 56.316999999999993)
('yuv.max=', 255.0, 'yuv.min=', 18.444999999999997)
('yuv.max=', 219.57299999999998, 'yuv.min=', 61.004999999999995)
('yuv.max=', 205.74799999999999, 'yuv.min=', 76.987000000000009)
('yuv.max=', 205.42999999999998, 'yuv.min=', 8.9190000000000005)
('yuv.max=', 253.68999999999997, 'yuv.min=', 88.090999999999994)
('yuv.max=', 238.62999999999997, 'yuv.min=', 29.948)
('yuv.max=', 177.08070400000003, 'yuv.min=', 13.552999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 8.6370000000000005)
('yuv.max=', 247.21599999999998, 'yuv.min=', 47.780999999999992)
('yuv.max=', 211.03900000000002, 'yuv.min=', 12.228)
('yuv.max=', 231.316, 'yuv.min=', 27.108999999999998)
('yuv.max=', 236.86900000000003, 'yuv.min=', 40.397999999999996)
('yuv.max=', 221.93599999999998, 'yuv.min=', 10.683999999999999)
('yuv.max=', 251.41300000000001, 'yuv.min=', 27.560999999999996)
('yuv.max=', 206.13900000000001, 'yuv.min=', 11.216999999999999)
('yuv.max=', 230.21299999999999, 'yuv.min=', 23.359000000000002)
('yuv.max=', 255.0, 'yuv.min=', 33.595999999999997)
('yuv.max=', 217.85299999999995, 'yuv.min=', 18.001999999999999)
('yuv.max=', 234.33699999999999, 'yuv.min=', 55.488)
('yuv.max=', 230.27099999999999, 'yuv.min=', 6.2279999999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', 5.0539999999999994)
('yuv.max=', 224.37899999999999, 'yuv.min=', 23.171999999999997)
('yuv.max=', 248.35900000000001, 'yuv.min=', 102.712)
('yuv.max=', 254.70099999999999, 'yuv.min=', 5.0709999999999988)
('yuv.max=', 173.78899999999999, 'yuv.min=', 7.4930000000000003)
('yuv.max=', 244.97800000000001, 'yuv.min=', 2.7269999999999999)
('yuv.max=', 248.364, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 180.24600000000001, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 252.09899999999999, 'yuv.min=', 39.868999999999993)
('yuv.max=', 253.29900000000001, 'yuv.min=', 4.9359999999999999)
('yuv.max=', 226.13099999999997, 'yuv.min=', 10.999999999999998)
('yuv.max=', 250.929, 'yuv.min=', 52.061999999999998)
('yuv.max=', 205.42699999999999, 'yuv.min=', 74.309999999999988)
('yuv.max=', 228.21499999999997, 'yuv.min=', 56.798000000000002)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 253.518, 'yuv.min=', 59.167000000000002)
('yuv.max=', 233.11799999999999, 'yuv.min=', 3.129)
('yuv.max=', 238.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 249.756, 'yuv.min=', 73.954999999999984)
('yuv.max=', 234.505, 'yuv.min=', 2.3959999999999999)
('yuv.max=', 251.90699999999995, 'yuv.min=', 3.5270000000000001)
('yuv.max=', 210.41899999999998, 'yuv.min=', 34.073)
('yuv.max=', 226.98100000000002, 'yuv.min=', 38.315999999999995)
('yuv.max=', 228.447, 'yuv.min=', 13.655999999999999)
('yuv.max=', 241.39499999999998, 'yuv.min=', 30.287999999999997)
('yuv.max=', 225.797, 'yuv.min=', 82.902999999999992)
('yuv.max=', 201.86199999999997, 'yuv.min=', 7.8319999999999999)
('yuv.max=', 231.60499999999999, 'yuv.min=', 9.8109999999999999)
('yuv.max=', 228.07399999999998, 'yuv.min=', 28.434000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 245.59100000000001, 'yuv.min=', 24.276999999999997)
('yuv.max=', 230.499, 'yuv.min=', 24.582999999999998)
('yuv.max=', 216.00099999999998, 'yuv.min=', 13.42)
('yuv.max=', 242.50999999999996, 'yuv.min=', 46.210999999999999)
('yuv.max=', 235.41199999999998, 'yuv.min=', 37.125)
('yuv.max=', 211.875, 'yuv.min=', 57.113999999999997)
('yuv.max=', 240.733, 'yuv.min=', 37.298999999999992)
('yuv.max=', 224.63, 'yuv.min=', 48.997)
('yuv.max=', 245.41499999999999, 'yuv.min=', 0.0)
('yuv.max=', 244.05799999999996, 'yuv.min=', 45.347999999999999)
('yuv.max=', 229.00399999999999, 'yuv.min=', 19.434999999999999)
('yuv.max=', 253.0, 'yuv.min=', 4.8149999999999995)
('yuv.max=', 253.185, 'yuv.min=', 34.664999999999999)
('yuv.max=', 255.0, 'yuv.min=', 70.863423999999995)
('yuv.max=', 252.17400000000001, 'yuv.min=', 6.218)
('yuv.max=', 229.62899999999999, 'yuv.min=', 15.949999999999999)
('yuv.max=', 222.58799999999999, 'yuv.min=', 27.003999999999998)
('yuv.max=', 249.75700000000001, 'yuv.min=', 27.033999999999999)
('yuv.max=', 255.0, 'yuv.min=', 23.521000000000001)
('yuv.max=', 250.21699999999998, 'yuv.min=', 0.114)
('yuv.max=', 248.14599999999999, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 31.776)
('yuv.max=', 186.66399999999999, 'yuv.min=', 34.024999999999999)
('yuv.max=', 253.886, 'yuv.min=', 4.6799999999999997)
('yuv.max=', 204.399, 'yuv.min=', 10.173999999999999)
('yuv.max=', 240.81900000000002, 'yuv.min=', 23.100999999999999)
('yuv.max=', 254.47300000000001, 'yuv.min=', 36.080999999999996)
('yuv.max=', 204.59799999999998, 'yuv.min=', 55.592999999999996)
('yuv.max=', 225.21699999999998, 'yuv.min=', 32.771999999999998)
('yuv.max=', 248.071, 'yuv.min=', 12.375)
('yuv.max=', 255.0, 'yuv.min=', 66.189000000000007)
('yuv.max=', 251.09199999999998, 'yuv.min=', 6.6129999999999995)
('yuv.max=', 216.43680000000001, 'yuv.min=', 21.456000000000003)
('yuv.max=', 241.60999999999999, 'yuv.min=', 16.550999999999998)
('yuv.max=', 232.73399999999998, 'yuv.min=', 41.710999999999999)
('yuv.max=', 233.15299999999999, 'yuv.min=', 0.0)
('yuv.max=', 238.625, 'yuv.min=', 20.047999999999998)
('yuv.max=', 240.065, 'yuv.min=', 23.394999999999996)
('yuv.max=', 237.452, 'yuv.min=', 50.625999999999998)
('yuv.max=', 237.01999999999998, 'yuv.min=', 7.2599999999999998)
('yuv.max=', 211.45399999999998, 'yuv.min=', 30.548000000000002)
('yuv.max=', 238.714, 'yuv.min=', 5.2880000000000003)
('yuv.max=', 253.505, 'yuv.min=', 0.0)
('yuv.max=', 207.65199999999996, 'yuv.min=', 40.726999999999997)
('yuv.max=', 232.19599999999997, 'yuv.min=', 36.803999999999995)
('yuv.max=', 242.39999999999998, 'yuv.min=', 16.858999999999998)
('yuv.max=', 225.167, 'yuv.min=', 6.819)
('yuv.max=', 167.94300800000002, 'yuv.min=', 46.355999999999995)
('yuv.max=', 223.47499999999999, 'yuv.min=', 41.102999999999994)
('yuv.max=', 241.56999999999999, 'yuv.min=', 30.659999999999997)
('yuv.max=', 227.048, 'yuv.min=', 38.908999999999999)
('yuv.max=', 247.53799999999998, 'yuv.min=', 7.4519999999999991)
('yuv.max=', 225.06099999999998, 'yuv.min=', 25.217999999999996)
('yuv.max=', 210.233, 'yuv.min=', 2.069)
('yuv.max=', 198.23599999999999, 'yuv.min=', 67.117999999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 52.857999999999997)
('yuv.max=', 255.0, 'yuv.min=', 33.754999999999995)
('yuv.max=', 187.51499999999999, 'yuv.min=', 43.078000000000003)
('yuv.max=', 224.785, 'yuv.min=', 91.594000000000008)
('yuv.max=', 200.559, 'yuv.min=', 75.665000000000006)
('yuv.max=', 185.57449600000001, 'yuv.min=', 10.146000000000001)
('yuv.max=', 250.245, 'yuv.min=', 12.456)
('yuv.max=', 238.511, 'yuv.min=', 36.413088000000002)
('yuv.max=', 245.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 197.756, 'yuv.min=', 43.958999999999996)
('yuv.max=', 213.65299999999999, 'yuv.min=', 49.436999999999998)
('yuv.max=', 243.70099999999999, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 251.44499999999996, 'yuv.min=', 21.700999999999997)
('yuv.max=', 255.0, 'yuv.min=', 21.720000000000002)
('yuv.max=', 205.625, 'yuv.min=', 37.073999999999998)
('yuv.max=', 246.35900000000001, 'yuv.min=', 34.204999999999998)
('yuv.max=', 243.42699999999999, 'yuv.min=', 8.1029999999999998)
('yuv.max=', 223.92099999999999, 'yuv.min=', 59.064)
('yuv.max=', 231.14399999999998, 'yuv.min=', 0.0)
('yuv.max=', 236.374, 'yuv.min=', 23.040999999999997)
('yuv.max=', 237.47999999999996, 'yuv.min=', 56.126999999999995)
('yuv.max=', 226.45899999999997, 'yuv.min=', 62.427)
('yuv.max=', 181.07399999999998, 'yuv.min=', 11.558999999999999)
('yuv.max=', 242.99799999999999, 'yuv.min=', 32.267999999999994)
('yuv.max=', 192.05699999999999, 'yuv.min=', 13.185)
('yuv.max=', 224.327, 'yuv.min=', 33.917999999999999)
('yuv.max=', 190.482496, 'yuv.min=', 3.2389999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 12.0)
('yuv.max=', 249.27699999999999, 'yuv.min=', 29.650999999999996)
('yuv.max=', 193.19799999999998, 'yuv.min=', 18.131999999999998)
('yuv.max=', 247.43000000000001, 'yuv.min=', 39.115000000000002)
('yuv.max=', 239.29300000000001, 'yuv.min=', 8.9019999999999992)
('yuv.max=', 236.07299999999998, 'yuv.min=', 29.601999999999997)
('yuv.max=', 255.0, 'yuv.min=', 29.794)
('yuv.max=', 193.06799999999998, 'yuv.min=', 37.292999999999992)
('yuv.max=', 201.71899999999999, 'yuv.min=', 13.239000000000001)
('yuv.max=', 236.68899999999999, 'yuv.min=', 49.168735999999996)
('yuv.max=', 200.37017599999999, 'yuv.min=', 15.908999999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', 11.927)
('yuv.max=', 249.017, 'yuv.min=', 17.986999999999998)
('yuv.max=', 234.815, 'yuv.min=', 0.0)
('yuv.max=', 245.989, 'yuv.min=', 58.076999999999998)
('yuv.max=', 237.33100000000002, 'yuv.min=', 35.315999999999995)
('yuv.max=', 225.13100000000003, 'yuv.min=', 10.298999999999999)
('yuv.max=', 255.0, 'yuv.min=', 30.018000000000001)
('yuv.max=', 255.0, 'yuv.min=', 23.783999999999999)
('yuv.max=', 203.364, 'yuv.min=', 14.572999999999999)
('yuv.max=', 250.65199999999999, 'yuv.min=', 13.809000000000001)
('yuv.max=', 236.245, 'yuv.min=', 16.631999999999998)
('yuv.max=', 250.20199999999997, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 220.86199999999999, 'yuv.min=', 5.7069999999999999)
('yuv.max=', 167.428, 'yuv.min=', 13.530999999999999)
('yuv.max=', 221.80500000000001, 'yuv.min=', 3.2599999999999998)
('yuv.max=', 228.40899999999996, 'yuv.min=', 47.518999999999991)
('yuv.max=', 255.0, 'yuv.min=', 58.292000000000002)
('yuv.max=', 184.785, 'yuv.min=', 27.885999999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', 33.728999999999999)
('yuv.max=', 225.83199999999999, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 253.68999999999997, 'yuv.min=', 25.298000000000002)
('yuv.max=', 228.55900000000003, 'yuv.min=', 30.668999999999997)
('yuv.max=', 180.048, 'yuv.min=', 18.231999999999999)
('yuv.max=', 253.82599999999996, 'yuv.min=', 10.588999999999999)
('yuv.max=', 150.76999999999998, 'yuv.min=', 9.8420000000000005)
('yuv.max=', 210.33699999999999, 'yuv.min=', 5.7539999999999996)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 253.54399999999998, 'yuv.min=', 2.7549999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 83.135000000000005)
('yuv.max=', 252.65199999999999, 'yuv.min=', 6.9729999999999999)
('yuv.max=', 251.279, 'yuv.min=', 18.282)
('yuv.max=', 242.0, 'yuv.min=', 29.0)
('yuv.max=', 251.85300000000001, 'yuv.min=', 26.512)
('yuv.max=', 249.83599999999998, 'yuv.min=', 50.088999999999999)
('yuv.max=', 253.505, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 222.58599999999998, 'yuv.min=', 17.055999999999997)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0430000000000001)
('yuv.max=', 248.989, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.210000000000001)
('yuv.max=', 176.68003199999998, 'yuv.min=', 11.984999999999999)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 240.40655999999998, 'yuv.min=', 10.657999999999999)
('yuv.max=', 240.28299999999999, 'yuv.min=', 21.413)
('yuv.max=', 255.0, 'yuv.min=', 41.967999999999996)
('yuv.max=', 251.13499999999999, 'yuv.min=', 24.0)
('yuv.max=', 254.886, 'yuv.min=', 9.5689999999999991)
('yuv.max=', 248.124, 'yuv.min=', 2.4729999999999999)
('yuv.max=', 251.27700000000002, 'yuv.min=', 46.201999999999998)
('yuv.max=', 253.17399999999998, 'yuv.min=', 10.097999999999999)
('yuv.max=', 182.46399999999997, 'yuv.min=', 26.199999999999999)
('yuv.max=', 255.0, 'yuv.min=', 9.8040000000000003)
('yuv.max=', 252.13099999999997, 'yuv.min=', 12.244999999999999)
('yuv.max=', 220.11399999999998, 'yuv.min=', 28.576000000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', 49.0)
('yuv.max=', 213.94999999999999, 'yuv.min=', 7.3509999999999991)
('yuv.max=', 228.554, 'yuv.min=', 19.712)
('yuv.max=', 231.30100000000002, 'yuv.min=', 24.674999999999997)
('yuv.max=', 251.84299999999996, 'yuv.min=', 31.539999999999996)
('yuv.max=', 242.649, 'yuv.min=', 21.703999999999997)
('yuv.max=', 177.80699999999999, 'yuv.min=', 42.583999999999996)
('yuv.max=', 245.167, 'yuv.min=', 29.260999999999996)
('yuv.max=', 235.809, 'yuv.min=', 31.315999999999999)
('yuv.max=', 245.745, 'yuv.min=', 66.674000000000007)
('yuv.max=', 249.01999999999998, 'yuv.min=', 72.662527999999995)
('yuv.max=', 250.71099999999998, 'yuv.min=', 1.1139999999999999)
('yuv.max=', 255.0, 'yuv.min=', 16.023)
('yuv.max=', 229.38499999999999, 'yuv.min=', 22.923000000000002)
('yuv.max=', 244.928, 'yuv.min=', 45.482999999999997)
('yuv.max=', 255.0, 'yuv.min=', 22.628)
('yuv.max=', 239.23099999999997, 'yuv.min=', 5.9509999999999996)
('yuv.max=', 250.22800000000001, 'yuv.min=', 2.157)
('yuv.max=', 225.07900000000001, 'yuv.min=', 15.146000000000001)
('yuv.max=', 197.13699999999997, 'yuv.min=', 64.021000000000001)
('yuv.max=', 213.10499999999999, 'yuv.min=', 2.7120000000000002)
('yuv.max=', 239.131, 'yuv.min=', 0.0)
('yuv.max=', 215.041, 'yuv.min=', 11.772)
('yuv.max=', 255.0, 'yuv.min=', 43.548999999999992)
('yuv.max=', 223.62799999999999, 'yuv.min=', 18.620999999999999)
('yuv.max=', 214.11099999999999, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 254.70099999999999, 'yuv.min=', 29.494999999999997)
('yuv.max=', 255.0, 'yuv.min=', 61.287999999999997)
('yuv.max=', 248.684, 'yuv.min=', 35.646999999999998)
('yuv.max=', 227.63999999999999, 'yuv.min=', 54.725999999999999)
('yuv.max=', 200.55499999999998, 'yuv.min=', 20.751000000000001)
('yuv.max=', 225.167, 'yuv.min=', 3.641)
('yuv.max=', 255.0, 'yuv.min=', 9.2279999999999998)
('yuv.max=', 229.72900000000001, 'yuv.min=', 2.411)
('yuv.max=', 204.941, 'yuv.min=', 4.7119999999999997)
('yuv.max=', 227.80799999999999, 'yuv.min=', 64.600999999999999)
('yuv.max=', 234.23099999999999, 'yuv.min=', 27.305999999999997)
('yuv.max=', 251.78899999999999, 'yuv.min=', 17.155999999999999)
('yuv.max=', 243.02425599999998, 'yuv.min=', 5.3589999999999991)
('yuv.max=', 188.117952, 'yuv.min=', 33.282999999999994)
('yuv.max=', 144.83499999999998, 'yuv.min=', 6.4569999999999999)
('yuv.max=', 229.99399999999997, 'yuv.min=', 48.923999999999992)
('yuv.max=', 253.13099999999997, 'yuv.min=', 13.681000000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', 26.999999999999996)
('yuv.max=', 177.53699999999998, 'yuv.min=', 55.095999999999997)
('yuv.max=', 241.74200000000002, 'yuv.min=', 4.0110000000000001)
('yuv.max=', 240.148, 'yuv.min=', 11.902999999999999)
('yuv.max=', 255.0, 'yuv.min=', 85.697999999999993)
('yuv.max=', 166.97499999999999, 'yuv.min=', 33.244999999999997)
('yuv.max=', 219.25300000000001, 'yuv.min=', 2.093)
('yuv.max=', 233.69499999999999, 'yuv.min=', 20.167999999999999)
('yuv.max=', 246.49399999999997, 'yuv.min=', 0.0)
('yuv.max=', 253.81499999999997, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 227.27099999999999, 'yuv.min=', 34.077999999999996)
('yuv.max=', 228.29899999999998, 'yuv.min=', 26.064)
('yuv.max=', 238.04399999999998, 'yuv.min=', 23.352999999999998)
('yuv.max=', 241.06, 'yuv.min=', 10.619)
('yuv.max=', 253.16300000000001, 'yuv.min=', 3.7229999999999999)
('yuv.max=', 211.054, 'yuv.min=', 0.8859999999999999)
('yuv.max=', 251.34199999999996, 'yuv.min=', 0.0)
('yuv.max=', 180.96499999999997, 'yuv.min=', 41.448)
('yuv.max=', 249.98400000000001, 'yuv.min=', 4.5869999999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', 19.0)
('yuv.max=', 247.22799999999998, 'yuv.min=', 34.902999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 236.327, 'yuv.min=', 34.313999999999993)
('yuv.max=', 242.07100000000003, 'yuv.min=', 59.640999999999991)
('yuv.max=', 255.0, 'yuv.min=', 4.7719999999999994)
('yuv.max=', 219.696, 'yuv.min=', 22.591999999999999)
('yuv.max=', 228.94399999999999, 'yuv.min=', 0.0)
('yuv.max=', 196.56899999999999, 'yuv.min=', 12.815999999999999)
('yuv.max=', 198.94, 'yuv.min=', 37.094999999999999)
('yuv.max=', 196.95099999999999, 'yuv.min=', 28.984999999999999)
('yuv.max=', 201.03200000000001, 'yuv.min=', 53.803999999999995)
('yuv.max=', 177.30200000000002, 'yuv.min=', 27.658999999999999)
('yuv.max=', 201.87700000000001, 'yuv.min=', 47.961999999999996)
('yuv.max=', 240.13099999999997, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 209.37899999999999, 'yuv.min=', 17.736999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 239.86899999999997, 'yuv.min=', 52.517999999999994)
('yuv.max=', 249.27600000000001, 'yuv.min=', 25.559999999999999)
('yuv.max=', 248.113, 'yuv.min=', 25.789999999999999)
('yuv.max=', 216.262, 'yuv.min=', 36.98299999999999)
('yuv.max=', 209.309, 'yuv.min=', 52.058)
('yuv.max=', 180.131, 'yuv.min=', 13.657999999999999)
('yuv.max=', 237.40399999999997, 'yuv.min=', 34.393000000000001)
('yuv.max=', 231.33499999999998, 'yuv.min=', 50.958999999999996)
('yuv.max=', 254.29899999999995, 'yuv.min=', 30.596999999999998)
('yuv.max=', 227.434, 'yuv.min=', 4.6579999999999995)
('yuv.max=', 242.18899999999999, 'yuv.min=', 6.0919999999999996)
('yuv.max=', 227.339, 'yuv.min=', 9.761000000000001)
('yuv.max=', 240.70799999999997, 'yuv.min=', 4.9289999999999994)
('yuv.max=', 172.66799999999998, 'yuv.min=', 8.4619999999999997)
('yuv.max=', 247.768, 'yuv.min=', 2.5699999999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', 18.789999999999999)
('yuv.max=', 216.01499999999999, 'yuv.min=', 13.783999999999999)
('yuv.max=', 255.0, 'yuv.min=', 108.68848)
('yuv.max=', 255.0, 'yuv.min=', 30.140000000000001)
('yuv.max=', 245.49900000000002, 'yuv.min=', 11.303000000000001)
('yuv.max=', 252.35299999999998, 'yuv.min=', 75.998999999999995)
('yuv.max=', 237.762, 'yuv.min=', 12.167)
('yuv.max=', 204.18599999999998, 'yuv.min=', 62.885999999999996)
('yuv.max=', 215.18899999999996, 'yuv.min=', 0.0)
('yuv.max=', 210.11600000000001, 'yuv.min=', 28.094999999999999)
('yuv.max=', 239.40199999999999, 'yuv.min=', 11.704999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 194.761, 'yuv.min=', 66.424000000000007)
('yuv.max=', 222.70400000000001, 'yuv.min=', 40.854999999999997)
('yuv.max=', 235.18299999999999, 'yuv.min=', 50.291999999999994)
('yuv.max=', 188.43499999999997, 'yuv.min=', 29.481999999999999)
('yuv.max=', 255.0, 'yuv.min=', 59.663999999999994)
('yuv.max=', 200.84700000000001, 'yuv.min=', 7.6359999999999992)
('yuv.max=', 229.60399999999998, 'yuv.min=', 7.0939999999999994)
('yuv.max=', 254.77200000000002, 'yuv.min=', 21.130999999999997)
('yuv.max=', 240.869, 'yuv.min=', 58.202591999999996)
('yuv.max=', 206.16800000000001, 'yuv.min=', 24.419999999999998)
('yuv.max=', 212.71799999999999, 'yuv.min=', 25.856000000000002)
('yuv.max=', 232.96299999999999, 'yuv.min=', 6.4569999999999999)
('yuv.max=', 233.017, 'yuv.min=', 24.673000000000002)
('yuv.max=', 247.22799999999998, 'yuv.min=', 72.084000000000003)
('yuv.max=', 255.0, 'yuv.min=', 79.347000000000008)
('yuv.max=', 232.55099999999999, 'yuv.min=', 37.171999999999997)
('yuv.max=', 199.73699999999999, 'yuv.min=', 46.204000000000001)
('yuv.max=', 233.56899999999999, 'yuv.min=', 3.1629999999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', 62.247)
('yuv.max=', 195.15199999999999, 'yuv.min=', 15.342999999999998)
('yuv.max=', 244.249, 'yuv.min=', 22.768000000000001)
('yuv.max=', 239.55200000000002, 'yuv.min=', 23.363)
('yuv.max=', 239.66299999999998, 'yuv.min=', 42.796999999999997)
('yuv.max=', 254.017, 'yuv.min=', 12.102999999999998)
('yuv.max=', 168.62599999999998, 'yuv.min=', 25.597999999999999)
('yuv.max=', 210.05799999999999, 'yuv.min=', 50.507999999999996)
('yuv.max=', 251.58699999999996, 'yuv.min=', 17.616)
('yuv.max=', 249.31999999999999, 'yuv.min=', 18.669)
('yuv.max=', 222.58499999999998, 'yuv.min=', 2.0709999999999997)
('yuv.max=', 255.0, 'yuv.min=', 13.565999999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', 46.0)
('yuv.max=', 250.55500000000001, 'yuv.min=', 37.042999999999999)
('yuv.max=', 179.10299999999998, 'yuv.min=', 47.262)
('yuv.max=', 254.77200000000002, 'yuv.min=', 28.459)
('yuv.max=', 222.03299999999999, 'yuv.min=', 15.140000000000001)
('yuv.max=', 255.0, 'yuv.min=', 51.597999999999999)
('yuv.max=', 213.72499999999999, 'yuv.min=', 32.140999999999998)
('yuv.max=', 185.61499999999998, 'yuv.min=', 31.760999999999996)
('yuv.max=', 253.185, 'yuv.min=', 0.0)
('yuv.max=', 230.15300000000002, 'yuv.min=', 18.754999999999999)
('yuv.max=', 245.69599999999997, 'yuv.min=', 26.675000000000001)
('yuv.max=', 252.42999999999998, 'yuv.min=', 48.727999999999994)
('yuv.max=', 236.86899999999997, 'yuv.min=', 24.402999999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', 17.41)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 220.25999999999999, 'yuv.min=', 26.265999999999998)
('yuv.max=', 220.63, 'yuv.min=', 0.0)
('yuv.max=', 227.80900000000003, 'yuv.min=', 35.564)
('yuv.max=', 254.70099999999999, 'yuv.min=', 4.8089999999999993)
('yuv.max=', 232.53999999999999, 'yuv.min=', 3.0819999999999999)
('yuv.max=', 252.10499999999996, 'yuv.min=', 5.0719999999999992)
('yuv.max=', 223.316, 'yuv.min=', 53.950999999999993)
('yuv.max=', 253.071, 'yuv.min=', 33.345999999999997)
('yuv.max=', 186.327, 'yuv.min=', 53.748999999999995)
('yuv.max=', 250.83599999999998, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 216.43899999999999, 'yuv.min=', 21.0)
('yuv.max=', 250.34799999999996, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 79.016999999999996)
('yuv.max=', 255.0, 'yuv.min=', 1.026)
('yuv.max=', 238.43299999999999, 'yuv.min=', 21.826999999999998)
('yuv.max=', 244.05000000000001, 'yuv.min=', 26.281999999999996)
('yuv.max=', 234.56800000000001, 'yuv.min=', 9.2129999999999992)
('yuv.max=', 198.27099999999999, 'yuv.min=', 15.042999999999999)
('yuv.max=', 226.02999999999997, 'yuv.min=', 41.060000000000002)
('yuv.max=', 254.54400000000001, 'yuv.min=', 31.951000000000001)
('yuv.max=', 220.64699999999999, 'yuv.min=', 0.0)
('yuv.max=', 239.863, 'yuv.min=', 18.414999999999999)
('yuv.max=', 233.929, 'yuv.min=', 3.0)
('yuv.max=', 243.0, 'yuv.min=', 2.5269999999999997)
('yuv.max=', 253.17600000000002, 'yuv.min=', 67.817999999999998)
('yuv.max=', 170.63200000000001, 'yuv.min=', 8.7650000000000006)
('yuv.max=', 174.37799999999999, 'yuv.min=', 21.451000000000001)
('yuv.max=', 238.06499999999997, 'yuv.min=', 5.1009999999999991)
('yuv.max=', 247.07300000000001, 'yuv.min=', 55.5)
('yuv.max=', 209.70399999999995, 'yuv.min=', 8.7179999999999982)
('yuv.max=', 219.27699999999999, 'yuv.min=', 28.366999999999997)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.435776, 'yuv.min=', 10.143999999999998)
('yuv.max=', 200.22899999999998, 'yuv.min=', 57.381)
('yuv.max=', 224.077, 'yuv.min=', 15.08)
('yuv.max=', 220.22799999999998, 'yuv.min=', 28.114000000000001)
('yuv.max=', 228.46000000000001, 'yuv.min=', 44.448)
('yuv.max=', 241.11799999999999, 'yuv.min=', 42.441999999999993)
('yuv.max=', 234.86799999999997, 'yuv.min=', 24.147999999999996)
('yuv.max=', 222.52699999999999, 'yuv.min=', 3.6669999999999998)
('yuv.max=', 254.29899999999995, 'yuv.min=', 23.723999999999997)
('yuv.max=', 178.70899999999997, 'yuv.min=', 16.391999999999999)
('yuv.max=', 255.0, 'yuv.min=', 60.588000000000001)
('yuv.max=', 246.18900000000002, 'yuv.min=', 5.6760000000000002)
('yuv.max=', 255.0, 'yuv.min=', 18.619)
('yuv.max=', 242.70099999999999, 'yuv.min=', 0.0)
('yuv.max=', 242.22800000000001, 'yuv.min=', 34.586999999999996)
('yuv.max=', 181.76599999999999, 'yuv.min=', 26.814999999999998)
('yuv.max=', 243.13499999999999, 'yuv.min=', 28.442999999999998)
('yuv.max=', 248.327, 'yuv.min=', 7.1249999999999991)
('yuv.max=', 226.97299999999998, 'yuv.min=', 0.114)
('yuv.max=', 251.142, 'yuv.min=', 2.875)
('yuv.max=', 245.233, 'yuv.min=', 31.105)
('yuv.max=', 249.17399999999998, 'yuv.min=', 15.271000000000001)
('yuv.max=', 255.0, 'yuv.min=', 9.641)
('yuv.max=', 217.40299999999999, 'yuv.min=', 27.981375999999997)
('yuv.max=', 229.018, 'yuv.min=', 47.668735999999996)
('yuv.max=', 233.18900000000002, 'yuv.min=', 15.590999999999999)
('yuv.max=', 165.605536, 'yuv.min=', 40.409999999999997)
('yuv.max=', 232.75799999999998, 'yuv.min=', 67.423999999999992)
('yuv.max=', 236.303, 'yuv.min=', 25.837)
('yuv.max=', 213.245, 'yuv.min=', 41.924999999999997)
('yuv.max=', 233.03199999999998, 'yuv.min=', 47.974000000000004)
('yuv.max=', 170.14278400000001, 'yuv.min=', 19.289999999999999)
('yuv.max=', 253.41299999999998, 'yuv.min=', 3.7010000000000001)
('yuv.max=', 252.935, 'yuv.min=', 28.501999999999999)
('yuv.max=', 241.04699999999997, 'yuv.min=', 52.168735999999996)
('yuv.max=', 250.80399999999997, 'yuv.min=', 29.277000000000001)
('yuv.max=', 253.99999999999997, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 43.245000000000005)
('yuv.max=', 226.47299999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.41199999999998, 'yuv.min=', 55.520999999999994)
('yuv.max=', 237.37700000000001, 'yuv.min=', 0.114)
('yuv.max=', 242.58899999999997, 'yuv.min=', 37.120999999999995)
('yuv.max=', 242.48399999999998, 'yuv.min=', 21.928999999999998)
('yuv.max=', 241.869, 'yuv.min=', 46.767999999999994)
('yuv.max=', 194.297, 'yuv.min=', 2.7120000000000002)
('yuv.max=', 198.10499999999999, 'yuv.min=', 22.778000000000002)
('yuv.max=', 254.70099999999999, 'yuv.min=', 17.966999999999999)
('yuv.max=', 196.42899999999997, 'yuv.min=', 17.923999999999999)
('yuv.max=', 217.19300000000001, 'yuv.min=', 15.151999999999999)
('yuv.max=', 243.989, 'yuv.min=', 32.292000000000002)
('yuv.max=', 228.16999999999999, 'yuv.min=', 25.727)
('yuv.max=', 209.095, 'yuv.min=', 28.533999999999999)
('yuv.max=', 255.0, 'yuv.min=', 21.036999999999999)
('yuv.max=', 237.79199999999997, 'yuv.min=', 40.088999999999999)
('yuv.max=', 219.31, 'yuv.min=', 6.0219999999999994)
('yuv.max=', 224.08199999999997, 'yuv.min=', 9.3360000000000003)
('yuv.max=', 255.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 239.262, 'yuv.min=', 40.985999999999997)
('yuv.max=', 216.44499999999999, 'yuv.min=', 70.387999999999991)
('yuv.max=', 232.81799999999998, 'yuv.min=', 18.950336000000007)
('yuv.max=', 187.05587199999999, 'yuv.min=', 35.696999999999996)
('yuv.max=', 236.74599999999998, 'yuv.min=', 13.109999999999998)
('yuv.max=', 251.76599999999999, 'yuv.min=', 31.207000000000001)
('yuv.max=', 246.77799999999996, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 247.90099999999998, 'yuv.min=', 31.564999999999998)
('yuv.max=', 234.12800000000001, 'yuv.min=', 18.878)
('yuv.max=', 224.69000000000003, 'yuv.min=', 20.120000000000001)
('yuv.max=', 223.57599999999999, 'yuv.min=', 11.575999999999999)
('yuv.max=', 239.40000000000001, 'yuv.min=', 13.123000000000001)
('yuv.max=', 228.41499999999999, 'yuv.min=', 37.681999999999995)
('yuv.max=', 248.04900000000001, 'yuv.min=', 74.096999999999994)
('yuv.max=', 244.518, 'yuv.min=', 0.0)
('yuv.max=', 251.21299999999999, 'yuv.min=', 30.867999999999999)
('yuv.max=', 253.46199999999999, 'yuv.min=', 55.641999999999996)
('yuv.max=', 251.15699999999998, 'yuv.min=', 10.201000000000001)
('yuv.max=', 255.0, 'yuv.min=', 10.396999999999998)
('yuv.max=', 194.74999999999997, 'yuv.min=', 32.390000000000001)
('yuv.max=', 241.35399999999998, 'yuv.min=', 30.68)
('yuv.max=', 255.0, 'yuv.min=', 21.504999999999999)
('yuv.max=', 220.45599999999999, 'yuv.min=', 17.085999999999999)
('yuv.max=', 226.238, 'yuv.min=', 31.635999999999999)
('yuv.max=', 245.983, 'yuv.min=', 33.732999999999997)
('yuv.max=', 251.71100000000001, 'yuv.min=', 34.114000000000004)
('yuv.max=', 244.982, 'yuv.min=', 30.622999999999998)
('yuv.max=', 244.74399999999997, 'yuv.min=', 49.778999999999996)
('yuv.max=', 224.06100000000001, 'yuv.min=', 1.9380000000000002)
('yuv.max=', 250.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 21.026)
('yuv.max=', 208.96600000000001, 'yuv.min=', 4.6579999999999995)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.0)
('yuv.max=', 250.94599999999997, 'yuv.min=', 2.254)
('yuv.max=', 232.37200000000001, 'yuv.min=', 48.802999999999997)
('yuv.max=', 235.60900000000001, 'yuv.min=', 47.608999999999995)
('yuv.max=', 250.34200000000001, 'yuv.min=', 4.5549999999999997)
('yuv.max=', 236.31299999999999, 'yuv.min=', 34.877000000000002)
('yuv.max=', 214.28199999999998, 'yuv.min=', 6.1139999999999999)
('yuv.max=', 185.05099999999999, 'yuv.min=', 19.879999999999999)
('yuv.max=', 246.80399999999997, 'yuv.min=', 23.792999999999999)
('yuv.max=', 212.047, 'yuv.min=', 37.504999999999995)
('yuv.max=', 227.762, 'yuv.min=', 0.0)
('yuv.max=', 235.03699999999998, 'yuv.min=', 34.179000000000002)
('yuv.max=', 253.21699999999998, 'yuv.min=', 7.4239999999999995)
('yuv.max=', 240.92599999999999, 'yuv.min=', 22.150000000000002)
('yuv.max=', 255.0, 'yuv.min=', 108.036384)
('yuv.max=', 244.84099999999998, 'yuv.min=', 11.227999999999998)
('yuv.max=', 251.16800000000001, 'yuv.min=', 26.971999999999998)
('yuv.max=', 233.63499999999999, 'yuv.min=', 9.8689999999999998)
('yuv.max=', 253.376, 'yuv.min=', 0.0)
('yuv.max=', 223.78299999999999, 'yuv.min=', 30.091999999999999)
('yuv.max=', 205.369, 'yuv.min=', 5.5549999999999997)
('yuv.max=', 255.0, 'yuv.min=', 0.114)
('yuv.max=', 206.17499999999998, 'yuv.min=', 17.940000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.68400000000000005)
('yuv.max=', 240.00499999999997, 'yuv.min=', 3.0860000000000003)
('yuv.max=', 212.74899999999997, 'yuv.min=', 39.193999999999996)
('yuv.max=', 248.99999999999997, 'yuv.min=', 58.444000000000003)
('yuv.max=', 213.70499999999998, 'yuv.min=', 29.528999999999996)
('yuv.max=', 249.85399999999998, 'yuv.min=', 72.152999999999992)
('yuv.max=', 242.184, 'yuv.min=', 16.759)
('yuv.max=', 247.88600000000002, 'yuv.min=', 17.782)
('yuv.max=', 255.0, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 245.96099999999998, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 199.37299999999999, 'yuv.min=', 41.683)
('yuv.max=', 226.89399999999998, 'yuv.min=', 20.761999999999997)
('yuv.max=', 224.10299999999998, 'yuv.min=', 10.526999999999999)
('yuv.max=', 239.64099999999996, 'yuv.min=', 17.783000000000001)
('yuv.max=', 251.15699999999998, 'yuv.min=', 0.0)
('yuv.max=', 161.26185599999999, 'yuv.min=', 9.754999999999999)
('yuv.max=', 247.952, 'yuv.min=', 5.6029999999999998)
('yuv.max=', 255.0, 'yuv.min=', 42.244352000000006)
('yuv.max=', 245.08799999999999, 'yuv.min=', 29.456)
('yuv.max=', 237.30999999999997, 'yuv.min=', 1.8690000000000002)
('yuv.max=', 160.02067199999999, 'yuv.min=', 39.317999999999998)
('yuv.max=', 233.95299999999997, 'yuv.min=', 9.4190000000000005)
('yuv.max=', 160.68227200000001, 'yuv.min=', 35.972999999999999)
('yuv.max=', 241.94699999999997, 'yuv.min=', 3.2559999999999998)
('yuv.max=', 237.19199999999998, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 173.27899999999997, 'yuv.min=', 9.3209999999999997)
('yuv.max=', 255.0, 'yuv.min=', 35.241999999999997)
('yuv.max=', 251.77199999999999, 'yuv.min=', 12.593)
('yuv.max=', 240.0, 'yuv.min=', 7.4129999999999994)
('yuv.max=', 223.09899999999996, 'yuv.min=', 9.1319999999999997)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 225.26400000000001, 'yuv.min=', 60.25)
('yuv.max=', 205.11499999999998, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 213.379808, 'yuv.min=', 26.789000000000001)
('yuv.max=', 244.87599999999998, 'yuv.min=', 12.864999999999998)
('yuv.max=', 240.08599999999998, 'yuv.min=', 33.091999999999999)
('yuv.max=', 250.255, 'yuv.min=', 46.424999999999997)
('yuv.max=', 254.202, 'yuv.min=', 18.678999999999998)
('yuv.max=', 255.0, 'yuv.min=', 63.675999999999995)
('yuv.max=', 242.57900000000001, 'yuv.min=', 8.831999999999999)
('yuv.max=', 207.429, 'yuv.min=', 58.269999999999996)
('yuv.max=', 253.86000000000001, 'yuv.min=', 12.005000000000001)
('yuv.max=', 248.32599999999999, 'yuv.min=', 53.942999999999998)
('yuv.max=', 239.64799999999997, 'yuv.min=', 4.7719999999999994)
('yuv.max=', 230.21699999999998, 'yuv.min=', 15.147)
('yuv.max=', 236.32900000000001, 'yuv.min=', 17.508000000000003)
('yuv.max=', 253.52699999999999, 'yuv.min=', 14.097000000000001)
('yuv.max=', 251.59799999999998, 'yuv.min=', 24.271000000000001)
('yuv.max=', 218.0, 'yuv.min=', 8.7719999999999985)
('yuv.max=', 253.80399999999997, 'yuv.min=', 12.353000000000002)
('yuv.max=', 228.196, 'yuv.min=', 48.838000000000001)
('yuv.max=', 200.58599999999998, 'yuv.min=', 54.237999999999992)
('yuv.max=', 254.28799999999998, 'yuv.min=', 33.021999999999998)
('yuv.max=', 246.31, 'yuv.min=', 31.725999999999999)
('yuv.max=', 237.97399999999996, 'yuv.min=', 44.503999999999998)
('yuv.max=', 201.94099999999997, 'yuv.min=', 42.140000000000001)
('yuv.max=', 246.815, 'yuv.min=', 32.233999999999995)
('yuv.max=', 245.191, 'yuv.min=', 6.3479999999999999)
('yuv.max=', 161.94921599999998, 'yuv.min=', 9.222999999999999)
('yuv.max=', 253.40199999999996, 'yuv.min=', 0.0)
('yuv.max=', 240.411, 'yuv.min=', 34.222000000000001)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 205.81699999999998, 'yuv.min=', 4.2229999999999999)
('yuv.max=', 250.815, 'yuv.min=', 10.053999999999998)
('yuv.max=', 250.44499999999996, 'yuv.min=', 44.314999999999998)
('yuv.max=', 239.22799999999995, 'yuv.min=', 1.744)
('yuv.max=', 237.03, 'yuv.min=', 3.2989999999999999)
('yuv.max=', 240.88599999999997, 'yuv.min=', 24.895999999999997)
('yuv.max=', 232.0, 'yuv.min=', 53.0)
('yuv.max=', 238.75299999999999, 'yuv.min=', 23.809999999999999)
('yuv.max=', 181.55587200000002, 'yuv.min=', 52.219999999999999)
('yuv.max=', 184.17400000000001, 'yuv.min=', 83.221000000000004)
('yuv.max=', 255.0, 'yuv.min=', 46.402000000000001)
('yuv.max=', 211.68199999999999, 'yuv.min=', 32.846999999999994)
('yuv.max=', 246.32900000000001, 'yuv.min=', 0.0)
('yuv.max=', 254.70099999999999, 'yuv.min=', 8.7719999999999985)
('yuv.max=', 255.0, 'yuv.min=', 50.576000000000001)
('yuv.max=', 253.99999999999997, 'yuv.min=', 24.152999999999999)
('yuv.max=', 222.798, 'yuv.min=', 51.851999999999997)
('yuv.max=', 253.40199999999996, 'yuv.min=', 5.6349999999999998)
('yuv.max=', 240.78699999999998, 'yuv.min=', 53.367999999999995)
('yuv.max=', 189.33737600000001, 'yuv.min=', 38.454000000000001)
('yuv.max=', 237.18799999999999, 'yuv.min=', 17.553999999999998)
('yuv.max=', 250.94599999999997, 'yuv.min=', 15.786999999999999)
('yuv.max=', 211.0, 'yuv.min=', 12.0)
('yuv.max=', 232.92699999999999, 'yuv.min=', 21.5)
('yuv.max=', 255.0, 'yuv.min=', 30.982999999999997)
('yuv.max=', 206.56299999999999, 'yuv.min=', 49.850999999999999)
('yuv.max=', 245.18399999999997, 'yuv.min=', 1.4949999999999999)
('yuv.max=', 201.149, 'yuv.min=', 22.177)
('yuv.max=', 199.24299999999999, 'yuv.min=', 16.190000000000001)
('yuv.max=', 245.03199999999998, 'yuv.min=', 16.337)
('yuv.max=', 245.815, 'yuv.min=', 50.438000000000002)
('yuv.max=', 247.56899999999996, 'yuv.min=', 62.030999999999999)
('yuv.max=', 222.06199999999998, 'yuv.min=', 27.074999999999999)
('yuv.max=', 198.07399999999998, 'yuv.min=', 31.944999999999997)
('yuv.max=', 252.68599999999998, 'yuv.min=', 12.120000000000001)
('yuv.max=', 210.29299999999998, 'yuv.min=', 30.624000000000002)
('yuv.max=', 238.05700000000002, 'yuv.min=', 34.397999999999996)
('yuv.max=', 252.57199999999997, 'yuv.min=', 13.522)
('yuv.max=', 254.11399999999998, 'yuv.min=', 56.269999999999996)
('yuv.max=', 254.40199999999999, 'yuv.min=', 13.410999999999998)
('yuv.max=', 226.20799999999997, 'yuv.min=', 22.108999999999998)
('yuv.max=', 199.89399999999998, 'yuv.min=', 10.847000000000001)
('yuv.max=', 255.0, 'yuv.min=', 62.039999999999999)
('yuv.max=', 165.88092800000001, 'yuv.min=', 18.582999999999998)
('yuv.max=', 251.77199999999999, 'yuv.min=', 3.2169999999999996)
('yuv.max=', 240.66799999999995, 'yuv.min=', 24.515999999999998)
('yuv.max=', 248.02199999999999, 'yuv.min=', 2.972)
('yuv.max=', 215.619, 'yuv.min=', 11.857999999999999)
('yuv.max=', 246.10300000000001, 'yuv.min=', 15.228)
('yuv.max=', 196.52799999999999, 'yuv.min=', 49.204000000000001)
('yuv.max=', 193.82999999999998, 'yuv.min=', 15.347999999999999)
('yuv.max=', 255.0, 'yuv.min=', 51.469999999999999)
('yuv.max=', 224.13999999999999, 'yuv.min=', 24.939999999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', 44.830999999999996)
('yuv.max=', 218.59699999999998, 'yuv.min=', 22.433999999999997)
('yuv.max=', 248.42400000000001, 'yuv.min=', 52.221999999999994)
('yuv.max=', 214.928, 'yuv.min=', 46.0)
('yuv.max=', 184.41817600000002, 'yuv.min=', 45.591999999999999)
('yuv.max=', 191.62416000000002, 'yuv.min=', 21.087)
('yuv.max=', 224.33099999999996, 'yuv.min=', 31.885999999999996)
('yuv.max=', 229.065, 'yuv.min=', 10.366999999999999)
('yuv.max=', 135.75606399999998, 'yuv.min=', 2.1849999999999996)
('yuv.max=', 249.93899999999999, 'yuv.min=', 1.254)
('yuv.max=', 231.29300000000001, 'yuv.min=', 1.1139999999999999)
('yuv.max=', 227.93899999999999, 'yuv.min=', 59.512)
('yuv.max=', 215.93199999999999, 'yuv.min=', 12.515999999999998)
('yuv.max=', 208.404, 'yuv.min=', 26.797999999999995)
('yuv.max=', 255.0, 'yuv.min=', 35.296999999999997)
('yuv.max=', 255.0, 'yuv.min=', 9.282)
('yuv.max=', 233.62099999999998, 'yuv.min=', 66.497)
('yuv.max=', 255.0, 'yuv.min=', 45.100999999999999)
('yuv.max=', 255.0, 'yuv.min=', 56.999999999999993)
('yuv.max=', 234.20199999999997, 'yuv.min=', 65.195999999999998)
('yuv.max=', 208.17699999999999, 'yuv.min=', 44.653999999999996)
('yuv.max=', 181.422, 'yuv.min=', 1.1139999999999999)
('yuv.max=', 232.73999999999998, 'yuv.min=', 9.1890000000000001)
('yuv.max=', 247.90800000000002, 'yuv.min=', 18.928999999999995)
('yuv.max=', 238.12899999999999, 'yuv.min=', 5.819)
('yuv.max=', 255.0, 'yuv.min=', 18.82)
('yuv.max=', 252.61899999999997, 'yuv.min=', 15.705)
('yuv.max=', 209.76700000000002, 'yuv.min=', 57.646999999999998)
('yuv.max=', 255.0, 'yuv.min=', 57.738144000000005)
('yuv.max=', 227.77000000000001, 'yuv.min=', 21.838999999999999)
('yuv.max=', 243.01399999999998, 'yuv.min=', 4.3029999999999999)
('yuv.max=', 233.95299999999997, 'yuv.min=', 21.071999999999999)
('yuv.max=', 182.166, 'yuv.min=', 29.152000000000001)
('yuv.max=', 213.67971200000002, 'yuv.min=', 26.733999999999998)
('yuv.max=', 209.62199999999999, 'yuv.min=', 19.396999999999998)
('yuv.max=', 235.79699999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 15.358999999999998)
('yuv.max=', 221.99399999999997, 'yuv.min=', 15.917999999999999)
('yuv.max=', 205.12099999999998, 'yuv.min=', 60.058999999999997)
('yuv.max=', 216.08099999999999, 'yuv.min=', 22.225000000000001)
('yuv.max=', 245.95699999999999, 'yuv.min=', 30.646000000000001)
('yuv.max=', 253.70099999999996, 'yuv.min=', 16.693000000000001)
('yuv.max=', 252.64099999999996, 'yuv.min=', 55.131)
('yuv.max=', 254.886, 'yuv.min=', 34.970079999999996)
('yuv.max=', 255.0, 'yuv.min=', 5.9799999999999995)
('yuv.max=', 248.91800000000001, 'yuv.min=', 18.963000000000001)
('yuv.max=', 230.86199999999999, 'yuv.min=', 44.765000000000001)
('yuv.max=', 213.161, 'yuv.min=', 31.897999999999996)
('yuv.max=', 250.565, 'yuv.min=', 4.5869999999999997)
('yuv.max=', 227.87300000000002, 'yuv.min=', 55.186999999999998)
('yuv.max=', 246.64099999999999, 'yuv.min=', 0.0)
('yuv.max=', 186.46699999999998, 'yuv.min=', 4.9459999999999997)
('yuv.max=', 181.963616, 'yuv.min=', 21.736999999999998)
('yuv.max=', 238.18499999999997, 'yuv.min=', 5.9459999999999997)
('yuv.max=', 252.06, 'yuv.min=', 8.0519999999999996)
('yuv.max=', 242.744, 'yuv.min=', 13.849)
('yuv.max=', 233.33500000000001, 'yuv.min=', 4.6239999999999997)
('yuv.max=', 222.65599999999998, 'yuv.min=', 9.2769999999999992)
('yuv.max=', 237.28799999999998, 'yuv.min=', 18.184000000000001)
('yuv.max=', 255.0, 'yuv.min=', 1.5960000000000001)
('yuv.max=', 244.797, 'yuv.min=', 26.287999999999997)
('yuv.max=', 239.89999999999998, 'yuv.min=', 25.009)
('yuv.max=', 217.06, 'yuv.min=', 14.836999999999998)
('yuv.max=', 226.20000000000002, 'yuv.min=', 33.997999999999998)
('yuv.max=', 228.62, 'yuv.min=', 46.120999999999995)
('yuv.max=', 194.00299999999999, 'yuv.min=', 14.357999999999997)
('yuv.max=', 252.935, 'yuv.min=', 12.131)
('yuv.max=', 254.40199999999999, 'yuv.min=', 7.4630000000000001)
('yuv.max=', 244.86899999999997, 'yuv.min=', 10.401999999999999)
('yuv.max=', 191.32399999999998, 'yuv.min=', 28.975999999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', 30.564)
('yuv.max=', 254.43000000000001, 'yuv.min=', 21.870999999999999)
('yuv.max=', 242.45000000000002, 'yuv.min=', 9.8900000000000006)
('yuv.max=', 240.374, 'yuv.min=', 13.270999999999999)
('yuv.max=', 253.81499999999997, 'yuv.min=', 9.1289999999999996)
('yuv.max=', 248.929, 'yuv.min=', 20.266999999999999)
('yuv.max=', 197.79300000000001, 'yuv.min=', 13.423)
('yuv.max=', 250.00199999999998, 'yuv.min=', 54.171999999999997)
('yuv.max=', 245.45499999999998, 'yuv.min=', 31.358999999999998)
('yuv.max=', 249.66199999999998, 'yuv.min=', 42.488999999999997)
('yuv.max=', 174.92499999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 190.31399999999999, 'yuv.min=', 34.561)
('yuv.max=', 248.69, 'yuv.min=', 36.436999999999991)
('yuv.max=', 205.02499999999998, 'yuv.min=', 55.170999999999992)
('yuv.max=', 250.66899999999998, 'yuv.min=', 67.628999999999991)
('yuv.max=', 232.114, 'yuv.min=', 24.288)
('yuv.max=', 221.33799999999999, 'yuv.min=', 35.842999999999996)
('yuv.max=', 254.40199999999999, 'yuv.min=', 9.4249999999999989)
('yuv.max=', 254.77200000000002, 'yuv.min=', 26.016999999999996)
('yuv.max=', 227.38499999999999, 'yuv.min=', 62.463999999999999)
('yuv.max=', 226.10400000000001, 'yuv.min=', 39.541999999999994)
('yuv.max=', 211.65600000000001, 'yuv.min=', 5.2229999999999999)
('yuv.max=', 210.0, 'yuv.min=', 21.130999999999997)
('yuv.max=', 254.245, 'yuv.min=', 8.1690000000000005)
('yuv.max=', 245.50899999999999, 'yuv.min=', 14.131)
('yuv.max=', 251.70699999999999, 'yuv.min=', 27.241)
('yuv.max=', 222.03799999999998, 'yuv.min=', 31.680999999999997)
('yuv.max=', 249.91800000000001, 'yuv.min=', 34.287999999999997)
('yuv.max=', 224.71600000000001, 'yuv.min=', 48.341999999999999)
('yuv.max=', 199.61699999999999, 'yuv.min=', 68.111000000000004)
('yuv.max=', 141.15699999999998, 'yuv.min=', 12.456)
('yuv.max=', 244.62, 'yuv.min=', 10.204000000000001)
('yuv.max=', 217.87999999999997, 'yuv.min=', 34.422999999999995)
('yuv.max=', 235.90499999999997, 'yuv.min=', 52.703000000000003)
('yuv.max=', 245.46499999999997, 'yuv.min=', 52.592999999999996)
('yuv.max=', 232.76799999999997, 'yuv.min=', 29.132999999999999)
('yuv.max=', 245.25899999999999, 'yuv.min=', 48.0)
('yuv.max=', 247.0, 'yuv.min=', 34.0)
('yuv.max=', 248.69, 'yuv.min=', 7.3159999999999989)
('yuv.max=', 237.17199999999997, 'yuv.min=', 12.212999999999999)
('yuv.max=', 249.529, 'yuv.min=', 3.1829999999999998)
('yuv.max=', 184.19, 'yuv.min=', 20.587)
('yuv.max=', 245.15700000000001, 'yuv.min=', 28.956999999999997)
('yuv.max=', 249.96699999999998, 'yuv.min=', 17.442)
('yuv.max=', 237.78099999999998, 'yuv.min=', 4.7009999999999996)
('yuv.max=', 239.35900000000001, 'yuv.min=', 16.198)
('yuv.max=', 250.0, 'yuv.min=', 53.999999999999993)
('yuv.max=', 185.434, 'yuv.min=', 33.268999999999998)
('yuv.max=', 199.95399999999998, 'yuv.min=', 32.914000000000001)
('yuv.max=', 237.97199999999998, 'yuv.min=', 5.9190000000000005)
('yuv.max=', 229.23999999999998, 'yuv.min=', 10.379999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.114)
('yuv.max=', 253.99999999999997, 'yuv.min=', 48.945)
('yuv.max=', 251.60900000000001, 'yuv.min=', 56.831999999999994)
('yuv.max=', 248.99999999999997, 'yuv.min=', 11.324999999999999)
('yuv.max=', 251.45599999999996, 'yuv.min=', 52.486999999999995)
('yuv.max=', 236.22799999999998, 'yuv.min=', 4.6289999999999996)
('yuv.max=', 251.75199999999998, 'yuv.min=', 0.0)
('yuv.max=', 222.178, 'yuv.min=', 6.4619999999999997)
('yuv.max=', 254.70099999999999, 'yuv.min=', 4.9289999999999994)
('yuv.max=', 243.36999999999998, 'yuv.min=', 6.1740000000000004)
('yuv.max=', 255.0, 'yuv.min=', 22.900999999999996)
('yuv.max=', 236.80599999999998, 'yuv.min=', 22.315999999999999)
('yuv.max=', 243.22800000000001, 'yuv.min=', 23.759)
('yuv.max=', 247.33699999999999, 'yuv.min=', 46.653999999999996)
('yuv.max=', 250.08199999999997, 'yuv.min=', 3.8649999999999998)
('yuv.max=', 229.12900000000002, 'yuv.min=', 31.786999999999999)
('yuv.max=', 232.91, 'yuv.min=', 10.468959999999996)
('yuv.max=', 255.0, 'yuv.min=', 67.512)
('yuv.max=', 215.47299999999998, 'yuv.min=', 22.957000000000001)
('yuv.max=', 255.0, 'yuv.min=', 6.2279999999999998)
('yuv.max=', 201.99999999999997, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 0.8859999999999999)
('yuv.max=', 237.74599999999998, 'yuv.min=', 47.578999999999994)
('yuv.max=', 239.65599999999998, 'yuv.min=', 14.930999999999999)
('yuv.max=', 237.114, 'yuv.min=', 43.173999999999992)
('yuv.max=', 255.0, 'yuv.min=', 48.590999999999994)
('yuv.max=', 247.58199999999997, 'yuv.min=', 8.6849999999999987)
('yuv.max=', 175.17599999999999, 'yuv.min=', 54.655000000000001)
('yuv.max=', 254.316, 'yuv.min=', 25.298999999999999)
('yuv.max=', 178.815, 'yuv.min=', 23.587)
('yuv.max=', 254.47300000000001, 'yuv.min=', 33.591999999999999)
('yuv.max=', 254.11399999999998, 'yuv.min=', 40.373999999999995)
('yuv.max=', 236.90099999999998, 'yuv.min=', 3.129)
('yuv.max=', 218.298, 'yuv.min=', 13.042999999999999)
('yuv.max=', 247.58699999999999, 'yuv.min=', 16.835999999999999)
('yuv.max=', 243.96099999999998, 'yuv.min=', 9.7289999999999992)
('yuv.max=', 255.0, 'yuv.min=', 15.16)
('yuv.max=', 255.0, 'yuv.min=', 1.4949999999999999)
('yuv.max=', 254.40199999999999, 'yuv.min=', 6.8769999999999998)
('yuv.max=', 255.0, 'yuv.min=', 7.3209999999999997)
('yuv.max=', 251.14599999999996, 'yuv.min=', 46.264000000000003)
('yuv.max=', 245.09200000000001, 'yuv.min=', 79.538999999999987)
('yuv.max=', 248.57599999999999, 'yuv.min=', 5.9459999999999997)
('yuv.max=', 217.18000000000001, 'yuv.min=', 13.853999999999999)
('yuv.max=', 249.673, 'yuv.min=', 3.2559999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 236.04099999999997, 'yuv.min=', 15.832999999999998)
('yuv.max=', 250.0, 'yuv.min=', 32.465999999999994)
('yuv.max=', 250.86899999999997, 'yuv.min=', 10.462)
('yuv.max=', 210.47900000000001, 'yuv.min=', 55.076000000000001)
('yuv.max=', 251.02099999999999, 'yuv.min=', 10.924999999999999)
('yuv.max=', 255.0, 'yuv.min=', 8.4510000000000005)
('yuv.max=', 196.22200000000001, 'yuv.min=', 14.843999999999999)
('yuv.max=', 170.74323200000001, 'yuv.min=', 16.700999999999997)
('yuv.max=', 248.71699999999998, 'yuv.min=', 1.744)
('yuv.max=', 162.15399999999997, 'yuv.min=', 18.140999999999998)
('yuv.max=', 227.10400000000001, 'yuv.min=', 12.026)
('yuv.max=', 255.0, 'yuv.min=', 49.885999999999996)
('yuv.max=', 186.90464, 'yuv.min=', 8.0640000000000001)
('yuv.max=', 241.59099999999998, 'yuv.min=', 3.0)
('yuv.max=', 228.09100000000001, 'yuv.min=', 0.0)
('yuv.max=', 251.04900000000001, 'yuv.min=', 19.093)
('yuv.max=', 252.196, 'yuv.min=', 39.685000000000002)
('yuv.max=', 239.80399999999997, 'yuv.min=', 6.4730000000000008)
('yuv.max=', 245.886, 'yuv.min=', 28.120999999999995)
('yuv.max=', 220.96899999999999, 'yuv.min=', 29.877999999999997)
('yuv.max=', 226.39400000000001, 'yuv.min=', 4.2970000000000006)
('yuv.max=', 225.78599999999997, 'yuv.min=', 23.815000000000001)
('yuv.max=', 255.0, 'yuv.min=', 44.740000000000002)
('yuv.max=', 255.0, 'yuv.min=', 60.156999999999996)
('yuv.max=', 251.85300000000001, 'yuv.min=', 7.5310000000000006)
('yuv.max=', 218.59399999999997, 'yuv.min=', 50.824999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 202.286, 'yuv.min=', 72.075999999999993)
('yuv.max=', 255.0, 'yuv.min=', 58.999999999999993)
('yuv.max=', 205.0, 'yuv.min=', 18.728999999999999)
('yuv.max=', 220.56999999999999, 'yuv.min=', 14.744)
('yuv.max=', 255.0, 'yuv.min=', 2.4239999999999999)
('yuv.max=', 255.0, 'yuv.min=', 14.466999999999999)
('yuv.max=', 252.38000000000002, 'yuv.min=', 17.433999999999997)
('yuv.max=', 209.48899999999998, 'yuv.min=', 45.951999999999998)
('yuv.max=', 232.78199999999998, 'yuv.min=', 20.68)
('yuv.max=', 254.70099999999999, 'yuv.min=', 12.526999999999999)
('yuv.max=', 212.13999999999999, 'yuv.min=', 38.715999999999994)
('yuv.max=', 237.142, 'yuv.min=', 40.694999999999993)
('yuv.max=', 231.99641599999998, 'yuv.min=', 0.0)
('yuv.max=', 216.02100000000002, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 167.58599999999998, 'yuv.min=', 18.672999999999998)
('yuv.max=', 239.40999999999997, 'yuv.min=', 12.186)
('yuv.max=', 252.27699999999999, 'yuv.min=', 55.548512000000002)
('yuv.max=', 229.929, 'yuv.min=', 88.466999999999999)
('yuv.max=', 251.71100000000001, 'yuv.min=', 49.367999999999995)
('yuv.max=', 255.0, 'yuv.min=', 15.036999999999999)
('yuv.max=', 248.322, 'yuv.min=', 5.1139999999999999)
('yuv.max=', 245.13799999999998, 'yuv.min=', 3.5870000000000002)
('yuv.max=', 247.06, 'yuv.min=', 16.151999999999997)
('yuv.max=', 241.73999999999998, 'yuv.min=', 48.799999999999997)
('yuv.max=', 204.989, 'yuv.min=', 63.896999999999991)
('yuv.max=', 253.84299999999996, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 248.381, 'yuv.min=', 6.3040000000000003)
('yuv.max=', 238.42999999999995, 'yuv.min=', 47.799999999999997)
('yuv.max=', 253.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 200.60199999999998, 'yuv.min=', 1.5980000000000001)
('yuv.max=', 210.24300000000002, 'yuv.min=', 30.75)
('yuv.max=', 194.327, 'yuv.min=', 30.923999999999999)
('yuv.max=', 233.428, 'yuv.min=', 12.869)
('yuv.max=', 224.85199999999998, 'yuv.min=', 4.8319999999999999)
('yuv.max=', 195.50299999999999, 'yuv.min=', 63.137999999999991)
('yuv.max=', 181.386, 'yuv.min=', 36.908000000000001)
('yuv.max=', 250.72, 'yuv.min=', 28.544)
('yuv.max=', 233.05599999999998, 'yuv.min=', 59.634)
('yuv.max=', 219.387, 'yuv.min=', 6.6509999999999998)
('yuv.max=', 243.82399999999998, 'yuv.min=', 18.125)
('yuv.max=', 248.47300000000001, 'yuv.min=', 0.93999999999999995)
('yuv.max=', 193.44200000000001, 'yuv.min=', 34.808)
('yuv.max=', 202.91399999999999, 'yuv.min=', 27.792999999999999)
('yuv.max=', 177.19800000000001, 'yuv.min=', 4.4189999999999996)
('yuv.max=', 241.095, 'yuv.min=', 31.702000000000002)
('yuv.max=', 255.0, 'yuv.min=', 37.602999999999994)
('yuv.max=', 222.80099999999999, 'yuv.min=', 44.712999999999994)
('yuv.max=', 235.32099999999997, 'yuv.min=', 10.911999999999999)
('yuv.max=', 202.65199999999999, 'yuv.min=', 27.597999999999995)
('yuv.max=', 181.61799999999999, 'yuv.min=', 26.736000000000001)
('yuv.max=', 171.53200000000001, 'yuv.min=', 57.894000000000005)
('yuv.max=', 176.83000000000001, 'yuv.min=', 16.728999999999999)
('yuv.max=', 234.19999999999999, 'yuv.min=', 16.555)
('yuv.max=', 255.0, 'yuv.min=', 18.309999999999999)
('yuv.max=', 255.0, 'yuv.min=', 5.3250000000000002)
('yuv.max=', 255.0, 'yuv.min=', 12.935)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 240.71199999999999, 'yuv.min=', 0.0)
('yuv.max=', 252.10300000000001, 'yuv.min=', 18.027999999999999)
('yuv.max=', 184.16499999999999, 'yuv.min=', 37.613)
('yuv.max=', 211.345, 'yuv.min=', 12.681151999999997)
('yuv.max=', 230.464, 'yuv.min=', 2.6559999999999997)
('yuv.max=', 219.70099999999999, 'yuv.min=', 4.5439999999999996)
('yuv.max=', 255.0, 'yuv.min=', 8.4610000000000003)
('yuv.max=', 251.71800000000002, 'yuv.min=', 9.1739999999999995)
('yuv.max=', 233.69, 'yuv.min=', 0.0)
('yuv.max=', 200.0, 'yuv.min=', 45.0)
('yuv.max=', 193.88200000000001, 'yuv.min=', 15.896999999999998)
('yuv.max=', 230.39500000000001, 'yuv.min=', 1.9830000000000001)
('yuv.max=', 243.989, 'yuv.min=', 17.370000000000001)
('yuv.max=', 183.73499999999999, 'yuv.min=', 1.1400000000000001)
('yuv.max=', 236.32799999999997, 'yuv.min=', 0.0)
('yuv.max=', 239.69, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 198.31399999999999, 'yuv.min=', 17.872999999999998)
('yuv.max=', 235.68000000000001, 'yuv.min=', 43.725728000000004)
('yuv.max=', 255.0, 'yuv.min=', 9.5019999999999989)
('yuv.max=', 255.0, 'yuv.min=', 54.038999999999994)
('yuv.max=', 237.72899999999998, 'yuv.min=', 0.0)
('yuv.max=', 253.97400000000002, 'yuv.min=', 2.4129999999999998)
('yuv.max=', 227.0, 'yuv.min=', 43.0)
('yuv.max=', 185.296032, 'yuv.min=', 36.223999999999997)
('yuv.max=', 196.84300000000002, 'yuv.min=', 39.109000000000002)
('yuv.max=', 253.505, 'yuv.min=', 23.434999999999999)
('yuv.max=', 208.76899999999998, 'yuv.min=', 10.93)
('yuv.max=', 239.797, 'yuv.min=', 45.781999999999996)
('yuv.max=', 194.0, 'yuv.min=', 38.999999999999993)
('yuv.max=', 237.52199999999999, 'yuv.min=', 17.013999999999999)
('yuv.max=', 255.0, 'yuv.min=', 12.43)
('yuv.max=', 250.131, 'yuv.min=', 6.7699999999999996)
('yuv.max=', 207.642, 'yuv.min=', 37.298000000000002)
('yuv.max=', 255.0, 'yuv.min=', 47.186999999999998)
('yuv.max=', 237.77199999999999, 'yuv.min=', 25.152999999999999)
('yuv.max=', 213.745, 'yuv.min=', 9.5760000000000005)
('yuv.max=', 227.48400000000001, 'yuv.min=', 10.593)
('yuv.max=', 225.482, 'yuv.min=', 16.096999999999998)
('yuv.max=', 235.608, 'yuv.min=', 13.544)
('yuv.max=', 224.90699999999998, 'yuv.min=', 21.215)
('yuv.max=', 188.44499999999999, 'yuv.min=', 32.622999999999998)
('yuv.max=', 217.79799999999997, 'yuv.min=', 53.357999999999997)
('yuv.max=', 255.0, 'yuv.min=', 3.9719999999999995)
('yuv.max=', 251.41300000000001, 'yuv.min=', 47.125999999999998)
('yuv.max=', 249.85399999999998, 'yuv.min=', 14.365)
('yuv.max=', 255.0, 'yuv.min=', 13.446999999999999)
('yuv.max=', 255.0, 'yuv.min=', 4.1629999999999994)
('yuv.max=', 255.0, 'yuv.min=', 17.701000000000001)
('yuv.max=', 245.78100000000001, 'yuv.min=', 7.0809999999999995)
('yuv.max=', 254.886, 'yuv.min=', 47.795999999999999)
('yuv.max=', 233.13200000000001, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 247.46599999999998, 'yuv.min=', 1.8580000000000001)
('yuv.max=', 225.97800000000001, 'yuv.min=', 36.266999999999996)
('yuv.max=', 255.0, 'yuv.min=', 6.1579999999999995)
('yuv.max=', 206.65899999999999, 'yuv.min=', 52.712999999999994)
('yuv.max=', 239.88399999999999, 'yuv.min=', 16.0)
('yuv.max=', 242.874, 'yuv.min=', 3.2599999999999998)
('yuv.max=', 224.89699999999999, 'yuv.min=', 22.337)
('yuv.max=', 194.94199999999998, 'yuv.min=', 0.0)
('yuv.max=', 233.03099999999998, 'yuv.min=', 0.0)
('yuv.max=', 252.114, 'yuv.min=', 13.772)
('yuv.max=', 252.935, 'yuv.min=', 3.0709999999999997)
('yuv.max=', 244.72899999999998, 'yuv.min=', 28.119999999999997)
('yuv.max=', 250.99999999999997, 'yuv.min=', 9.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 220.78700000000001, 'yuv.min=', 47.787999999999997)
('yuv.max=', 243.35899999999998, 'yuv.min=', 36.048999999999992)
('yuv.max=', 254.18499999999997, 'yuv.min=', 3.8259999999999996)
('yuv.max=', 251.52700000000002, 'yuv.min=', 55.47699999999999)
('yuv.max=', 234.67999999999998, 'yuv.min=', 13.853999999999999)
('yuv.max=', 242.75, 'yuv.min=', 3.9569999999999999)
('yuv.max=', 255.0, 'yuv.min=', 32.515999999999998)
('yuv.max=', 247.33799999999999, 'yuv.min=', 31.534999999999997)
('yuv.max=', 245.0, 'yuv.min=', 40.0)
('yuv.max=', 224.06399999999999, 'yuv.min=', 0.0)
('yuv.max=', 207.0, 'yuv.min=', 14.0)
('yuv.max=', 205.99899999999997, 'yuv.min=', 19.583999999999996)
('yuv.max=', 228.34199999999998, 'yuv.min=', 21.689999999999998)
('yuv.max=', 249.64699999999999, 'yuv.min=', 0.0)
('yuv.max=', 201.13599999999997, 'yuv.min=', 24.835999999999999)
('yuv.max=', 218.36699999999999, 'yuv.min=', 14.847999999999999)
('yuv.max=', 237.13499999999996, 'yuv.min=', 13.039)
('yuv.max=', 248.40899999999999, 'yuv.min=', 46.298999999999999)
('yuv.max=', 235.46299999999999, 'yuv.min=', 6.4559999999999995)
('yuv.max=', 243.0, 'yuv.min=', 30.0)
('yuv.max=', 224.68299999999999, 'yuv.min=', 22.102999999999998)
('yuv.max=', 245.43999999999997, 'yuv.min=', 5.1040000000000001)
('yuv.max=', 253.58699999999999, 'yuv.min=', 5.4299999999999997)
('yuv.max=', 235.262, 'yuv.min=', 8.5329999999999995)
('yuv.max=', 227.54299999999995, 'yuv.min=', 0.0)
('yuv.max=', 243.75400000000002, 'yuv.min=', 46.000999999999998)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 148.955072, 'yuv.min=', 3.8890000000000002)
('yuv.max=', 211.89999999999998, 'yuv.min=', 78.448999999999998)
('yuv.max=', 217.059, 'yuv.min=', 37.199999999999996)
('yuv.max=', 252.309, 'yuv.min=', 13.183999999999997)
('yuv.max=', 228.27699999999996, 'yuv.min=', 16.456)
('yuv.max=', 253.36999999999998, 'yuv.min=', 21.940000000000001)
('yuv.max=', 242.0, 'yuv.min=', 55.0)
('yuv.max=', 238.072768, 'yuv.min=', 39.191000000000003)
('yuv.max=', 225.744, 'yuv.min=', 40.728999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 187.17999999999998, 'yuv.min=', 12.541999999999998)
('yuv.max=', 255.0, 'yuv.min=', 1.3100000000000001)
('yuv.max=', 241.17599999999999, 'yuv.min=', 27.033999999999999)
('yuv.max=', 248.51599999999996, 'yuv.min=', 12.789)
('yuv.max=', 227.03199999999998, 'yuv.min=', 5.4349999999999996)
('yuv.max=', 233.821, 'yuv.min=', 15.547999999999998)
('yuv.max=', 227.0, 'yuv.min=', 28.0)
('yuv.max=', 206.41300000000001, 'yuv.min=', 3.6989999999999998)
('yuv.max=', 255.0, 'yuv.min=', 6.7509999999999994)
('yuv.max=', 250.39099999999999, 'yuv.min=', 12.321)
('yuv.max=', 236.41, 'yuv.min=', 28.231999999999999)
('yuv.max=', 251.70099999999996, 'yuv.min=', 5.5439999999999996)
('yuv.max=', 206.97, 'yuv.min=', 41.749999999999993)
('yuv.max=', 237.142, 'yuv.min=', 29.561)
('yuv.max=', 225.72999999999999, 'yuv.min=', 57.720999999999989)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 236.84699999999998, 'yuv.min=', 34.141999999999996)
('yuv.max=', 182.068288, 'yuv.min=', 42.751999999999995)
('yuv.max=', 255.0, 'yuv.min=', 39.116999999999997)
('yuv.max=', 223.95699999999999, 'yuv.min=', 0.0)
('yuv.max=', 252.11599999999999, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 97.024256000000008)
('yuv.max=', 231.23599999999996, 'yuv.min=', 5.7329999999999997)
('yuv.max=', 232.99600000000001, 'yuv.min=', 12.085999999999999)
('yuv.max=', 220.97, 'yuv.min=', 31.228000000000002)
('yuv.max=', 246.51000000000002, 'yuv.min=', 43.929000000000002)
('yuv.max=', 236.36600000000001, 'yuv.min=', 8.270999999999999)
('yuv.max=', 239.61899999999997, 'yuv.min=', 46.268999999999998)
('yuv.max=', 221.81099999999998, 'yuv.min=', 27.325999999999997)
('yuv.max=', 212.40899999999999, 'yuv.min=', 63.367000000000004)
('yuv.max=', 253.19100000000003, 'yuv.min=', 6.968)
('yuv.max=', 215.625, 'yuv.min=', 25.619)
('yuv.max=', 229.285, 'yuv.min=', 13.674999999999999)
('yuv.max=', 184.952, 'yuv.min=', 38.806000000000004)
('yuv.max=', 173.88092799999998, 'yuv.min=', 16.928999999999998)
('yuv.max=', 251.755, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 234.46099999999998, 'yuv.min=', 44.891999999999996)
('yuv.max=', 248.46599999999998, 'yuv.min=', 44.488)
('yuv.max=', 156.418688, 'yuv.min=', 49.660000000000004)
('yuv.max=', 255.0, 'yuv.min=', 2.3100000000000001)
('yuv.max=', 248.95699999999999, 'yuv.min=', 40.338999999999999)
('yuv.max=', 211.14999999999998, 'yuv.min=', 25.919999999999998)
('yuv.max=', 252.22999999999996, 'yuv.min=', 32.277999999999999)
('yuv.max=', 227.755, 'yuv.min=', 21.228000000000002)
('yuv.max=', 216.35199999999998, 'yuv.min=', 32.844999999999999)
('yuv.max=', 253.404, 'yuv.min=', 1.1400000000000001)
('yuv.max=', 162.90099999999998, 'yuv.min=', 4.472999999999999)
('yuv.max=', 213.0, 'yuv.min=', 46.0)
('yuv.max=', 254.06, 'yuv.min=', 0.0)
('yuv.max=', 198.19499999999999, 'yuv.min=', 24.159999999999997)
('yuv.max=', 250.73299999999998, 'yuv.min=', 6.8620000000000001)
('yuv.max=', 252.91799999999998, 'yuv.min=', 26.449000000000002)
('yuv.max=', 254.47300000000001, 'yuv.min=', 17.184999999999999)
('yuv.max=', 253.29900000000001, 'yuv.min=', 8.3490000000000002)
('yuv.max=', 238.11599999999999, 'yuv.min=', 30.510000000000002)
('yuv.max=', 225.98599999999999, 'yuv.min=', 16.215)
('yuv.max=', 203.11599999999999, 'yuv.min=', 2.8039999999999998)
('yuv.max=', 210.21399999999997, 'yuv.min=', 12.966999999999999)
('yuv.max=', 221.685, 'yuv.min=', 32.109999999999999)
('yuv.max=', 192.637, 'yuv.min=', 29.372999999999998)
('yuv.max=', 248.10900000000001, 'yuv.min=', 9.1289999999999996)
('yuv.max=', 232.024, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 241.28799999999998, 'yuv.min=', 23.928999999999998)
('yuv.max=', 167.09932800000001, 'yuv.min=', 12.619)
('yuv.max=', 195.05199999999999, 'yuv.min=', 32.984999999999999)
('yuv.max=', 255.0, 'yuv.min=', 65.759647999999999)
('yuv.max=', 248.61600000000001, 'yuv.min=', 15.597999999999999)
('yuv.max=', 244.86799999999999, 'yuv.min=', 66.870000000000005)
('yuv.max=', 208.28200000000001, 'yuv.min=', 65.051000000000002)
('yuv.max=', 190.18799999999999, 'yuv.min=', 27.559000000000001)
('yuv.max=', 232.20400000000001, 'yuv.min=', 50.690999999999995)
('yuv.max=', 220.452, 'yuv.min=', 19.712)
('yuv.max=', 253.505, 'yuv.min=', 62.647999999999996)
('yuv.max=', 253.82599999999996, 'yuv.min=', 9.4299999999999997)
('yuv.max=', 232.25699999999998, 'yuv.min=', 36.68)
('yuv.max=', 203.01212799999999, 'yuv.min=', 43.244)
('yuv.max=', 250.63, 'yuv.min=', 14.669999999999998)
('yuv.max=', 243.52699999999999, 'yuv.min=', 6.0710000000000006)
('yuv.max=', 215.86199999999999, 'yuv.min=', 1.8149999999999999)
('yuv.max=', 244.398, 'yuv.min=', 47.035000000000004)
('yuv.max=', 210.16499999999999, 'yuv.min=', 6.4689999999999994)
('yuv.max=', 220.80399999999997, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 236.69399999999999, 'yuv.min=', 3.2879999999999998)
('yuv.max=', 241.04200000000003, 'yuv.min=', 24.579999999999998)
('yuv.max=', 188.328, 'yuv.min=', 58.121000000000002)
('yuv.max=', 248.0, 'yuv.min=', 65.417000000000002)
('yuv.max=', 226.85500000000002, 'yuv.min=', 8.7219999999999995)
('yuv.max=', 255.0, 'yuv.min=', 49.040999999999997)
('yuv.max=', 239.58700000000002, 'yuv.min=', 22.113999999999997)
('yuv.max=', 250.42299999999997, 'yuv.min=', 6.0969999999999995)
('yuv.max=', 248.71799999999999, 'yuv.min=', 1.228)
('yuv.max=', 211.12624, 'yuv.min=', 1.4729999999999999)
('yuv.max=', 248.75900000000001, 'yuv.min=', 8.9399999999999995)
('yuv.max=', 251.65799999999999, 'yuv.min=', 14.893999999999998)
('yuv.max=', 255.0, 'yuv.min=', 8.4130000000000003)
('yuv.max=', 243.62599999999998, 'yuv.min=', 43.357999999999997)
('yuv.max=', 165.97899999999998, 'yuv.min=', 35.634999999999998)
('yuv.max=', 251.22799999999998, 'yuv.min=', 34.771999999999998)
('yuv.max=', 252.80399999999997, 'yuv.min=', 11.462)
('yuv.max=', 248.99999999999997, 'yuv.min=', 23.0)
('yuv.max=', 243.21999999999997, 'yuv.min=', 48.670999999999999)
('yuv.max=', 255.0, 'yuv.min=', 23.878999999999998)
('yuv.max=', 214.077, 'yuv.min=', 33.170999999999999)
('yuv.max=', 243.28799999999998, 'yuv.min=', 29.020999999999997)
('yuv.max=', 252.02099999999996, 'yuv.min=', 36.051000000000002)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 240.71199999999999, 'yuv.min=', 52.344999999999999)
('yuv.max=', 216.19, 'yuv.min=', 16.942)
('yuv.max=', 206.78399999999999, 'yuv.min=', 58.088999999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', 20.120000000000001)
('yuv.max=', 254.316, 'yuv.min=', 0.0)
('yuv.max=', 180.88799999999998, 'yuv.min=', 9.9399999999999995)
('yuv.max=', 181.22799999999998, 'yuv.min=', 43.920000000000002)
('yuv.max=', 189.64899999999997, 'yuv.min=', 16.113999999999997)
('yuv.max=', 250.86199999999997, 'yuv.min=', 62.069999999999993)
('yuv.max=', 247.03199999999998, 'yuv.min=', 22.885999999999999)
('yuv.max=', 221.70499999999998, 'yuv.min=', 36.128)
('yuv.max=', 255.0, 'yuv.min=', 7.2279999999999998)
('yuv.max=', 229.99999999999997, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 8.6689999999999987)
('yuv.max=', 236.27800000000002, 'yuv.min=', 36.318000000000005)
('yuv.max=', 239.69399999999999, 'yuv.min=', 11.308999999999999)
('yuv.max=', 218.988, 'yuv.min=', 16.061999999999998)
('yuv.max=', 196.31199999999998, 'yuv.min=', 0.0)
('yuv.max=', 249.47800000000001, 'yuv.min=', 13.759999999999998)
('yuv.max=', 249.89099999999999, 'yuv.min=', 20.209)
('yuv.max=', 194.59399999999999, 'yuv.min=', 31.111999999999995)
('yuv.max=', 253.0, 'yuv.min=', 13.174000000000001)
('yuv.max=', 244.316, 'yuv.min=', 0.9830000000000001)
('yuv.max=', 243.523, 'yuv.min=', 4.516)
('yuv.max=', 255.0, 'yuv.min=', 5.7720000000000002)
('yuv.max=', 201.13899999999998, 'yuv.min=', 57.825999999999993)
('yuv.max=', 207.61000000000001, 'yuv.min=', 32.884999999999998)
('yuv.max=', 143.95148800000001, 'yuv.min=', 9.282)
('yuv.max=', 254.202, 'yuv.min=', 9.9399999999999995)
('yuv.max=', 255.0, 'yuv.min=', 9.5199999999999996)
('yuv.max=', 224.53699999999998, 'yuv.min=', 61.328831999999991)
('yuv.max=', 227.61499999999998, 'yuv.min=', 3.4459999999999997)
('yuv.max=', 176.799104, 'yuv.min=', 73.781999999999996)
('yuv.max=', 253.29900000000001, 'yuv.min=', 12.885999999999999)
('yuv.max=', 239.83799999999999, 'yuv.min=', 10.712)
('yuv.max=', 244.81700000000001, 'yuv.min=', 2.6390000000000002)
('yuv.max=', 199.13299999999998, 'yuv.min=', 17.413)
('yuv.max=', 165.61599999999999, 'yuv.min=', 9.8399999999999999)
('yuv.max=', 232.21699999999998, 'yuv.min=', 59.899999999999999)
('yuv.max=', 252.22999999999996, 'yuv.min=', 76.835999999999999)
('yuv.max=', 177.55799999999999, 'yuv.min=', 30.305)
('yuv.max=', 248.32999999999998, 'yuv.min=', 37.591000000000001)
('yuv.max=', 255.0, 'yuv.min=', 32.515999999999998)
('yuv.max=', 198.09299999999999, 'yuv.min=', 29.598000000000003)
('yuv.max=', 245.744, 'yuv.min=', 7.2000000000000002)
('yuv.max=', 222.80500000000001, 'yuv.min=', 16.085999999999999)
('yuv.max=', 231.21700000000001, 'yuv.min=', 24.271000000000001)
('yuv.max=', 209.38, 'yuv.min=', 11.827)
('yuv.max=', 237.69799999999995, 'yuv.min=', 44.605999999999995)
('yuv.max=', 238.09999999999999, 'yuv.min=', 16.940999999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', 1.5529999999999999)
('yuv.max=', 240.89399999999998, 'yuv.min=', 0.0)
('yuv.max=', 225.96100000000001, 'yuv.min=', 27.167999999999999)
('yuv.max=', 255.0, 'yuv.min=', 45.703000000000003)
('yuv.max=', 241.82599999999996, 'yuv.min=', 18.515999999999998)
('yuv.max=', 250.03899999999999, 'yuv.min=', 37.024999999999999)
('yuv.max=', 239.87199999999996, 'yuv.min=', 9.4669999999999987)
('yuv.max=', 248.0, 'yuv.min=', 9.4989999999999988)
('yuv.max=', 230.22799999999998, 'yuv.min=', 42.954999999999998)
('yuv.max=', 240.755, 'yuv.min=', 69.900999999999996)
('yuv.max=', 225.63700000000003, 'yuv.min=', 22.634)
('yuv.max=', 243.81100000000001, 'yuv.min=', 5.0110000000000001)
('yuv.max=', 240.11299999999997, 'yuv.min=', 54.809999999999995)
('yuv.max=', 250.26199999999997, 'yuv.min=', 34.048000000000002)
('yuv.max=', 230.64699999999996, 'yuv.min=', 16.143903999999992)
('yuv.max=', 249.07099999999997, 'yuv.min=', 3.577)
('yuv.max=', 231.0, 'yuv.min=', 35.607999999999997)
('yuv.max=', 216.04799999999997, 'yuv.min=', 25.393999999999998)
('yuv.max=', 236.66799999999998, 'yuv.min=', 15.613)
('yuv.max=', 250.815, 'yuv.min=', 11.977)
('yuv.max=', 249.14999999999998, 'yuv.min=', 62.946999999999996)
('yuv.max=', 216.44899999999998, 'yuv.min=', 19.673000000000002)
('yuv.max=', 202.381, 'yuv.min=', 6.032)
('yuv.max=', 233.07500000000002, 'yuv.min=', 21.813999999999997)
('yuv.max=', 241.97900000000001, 'yuv.min=', 44.309999999999995)
('yuv.max=', 193.90200000000002, 'yuv.min=', 45.012)
('yuv.max=', 245.376, 'yuv.min=', 38.382047999999998)
('yuv.max=', 252.58699999999999, 'yuv.min=', 8.8579999999999988)
('yuv.max=', 239.55299999999997, 'yuv.min=', 23.701000000000001)
('yuv.max=', 252.10300000000001, 'yuv.min=', 3.3230000000000004)
('yuv.max=', 159.44499999999996, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 255.0, 'yuv.min=', 73.303999999999988)
('yuv.max=', 246.35900000000001, 'yuv.min=', 6.0600000000000005)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 199.49299999999999, 'yuv.min=', 29.091000000000001)
('yuv.max=', 247.852, 'yuv.min=', 2.738)
('yuv.max=', 251.50500000000002, 'yuv.min=', 27.626999999999999)
('yuv.max=', 243.583, 'yuv.min=', 7.7009999999999996)
('yuv.max=', 247.893, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 231.43000000000001, 'yuv.min=', 9.9100000000000001)
('yuv.max=', 251.03799999999998, 'yuv.min=', 9.4939999999999998)
('yuv.max=', 255.0, 'yuv.min=', 30.893999999999998)
('yuv.max=', 156.55799999999999, 'yuv.min=', 19.853999999999999)
('yuv.max=', 246.26999999999998, 'yuv.min=', 39.856999999999999)
('yuv.max=', 250.501, 'yuv.min=', 38.646000000000001)
('yuv.max=', 238.99999999999997, 'yuv.min=', 26.999999999999996)
('yuv.max=', 225.24099999999999, 'yuv.min=', 34.440999999999995)
('yuv.max=', 176.364, 'yuv.min=', 73.817999999999998)
('yuv.max=', 212.96099999999998, 'yuv.min=', 9.1999999999999993)
('yuv.max=', 252.93999999999997, 'yuv.min=', 14.304)
('yuv.max=', 255.0, 'yuv.min=', 77.967199999999991)
('yuv.max=', 207.554, 'yuv.min=', 10.913)
('yuv.max=', 250.03200000000001, 'yuv.min=', 33.933)
('yuv.max=', 155.72460799999999, 'yuv.min=', 58.906999999999996)
('yuv.max=', 228.80199999999999, 'yuv.min=', 16.396999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 246.042, 'yuv.min=', 39.310000000000002)
('yuv.max=', 173.44099999999997, 'yuv.min=', 13.445)
('yuv.max=', 209.82699999999997, 'yuv.min=', 17.689999999999998)
('yuv.max=', 241.19900800000002, 'yuv.min=', 22.295999999999999)
('yuv.max=', 248.00999999999999, 'yuv.min=', 10.042)
('yuv.max=', 248.869, 'yuv.min=', 25.167999999999999)
('yuv.max=', 234.20599999999996, 'yuv.min=', 50.897999999999996)
('yuv.max=', 238.39599999999999, 'yuv.min=', 12.683999999999999)
('yuv.max=', 251.72199999999998, 'yuv.min=', 2.359)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 243.63200000000001, 'yuv.min=', 10.346)
('yuv.max=', 220.91, 'yuv.min=', 20.501000000000001)
('yuv.max=', 240.0, 'yuv.min=', 29.277999999999999)
('yuv.max=', 221.28800000000001, 'yuv.min=', 19.640999999999998)
('yuv.max=', 230.57199999999997, 'yuv.min=', 5.0709999999999988)
('yuv.max=', 237.17500000000001, 'yuv.min=', 19.847000000000001)
('yuv.max=', 230.13099999999997, 'yuv.min=', 9.8859999999999992)
('yuv.max=', 243.40100000000001, 'yuv.min=', 26.154)
('yuv.max=', 229.99999999999997, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 248.84299999999999, 'yuv.min=', 42.748999999999995)
('yuv.max=', 178.0, 'yuv.min=', 57.329000000000001)
('yuv.max=', 243.34599999999998, 'yuv.min=', 5.3589999999999991)
('yuv.max=', 254.70099999999999, 'yuv.min=', 0.0)
('yuv.max=', 173.54966400000001, 'yuv.min=', 52.560999999999993)
('yuv.max=', 242.92499999999998, 'yuv.min=', 8.020999999999999)
('yuv.max=', 238.53800000000001, 'yuv.min=', 14.027000000000001)
('yuv.max=', 255.0, 'yuv.min=', 10.725999999999999)
('yuv.max=', 239.78799999999998, 'yuv.min=', 26.561)
('yuv.max=', 248.99999999999997, 'yuv.min=', 11.222)
('yuv.max=', 204.03399999999999, 'yuv.min=', 21.076999999999998)
('yuv.max=', 253.11399999999998, 'yuv.min=', 44.491999999999997)
('yuv.max=', 175.81152, 'yuv.min=', 26.341999999999999)
('yuv.max=', 150.84099999999998, 'yuv.min=', 2.8860000000000001)
('yuv.max=', 247.08800000000002, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 234.75899999999999, 'yuv.min=', 32.308)
('yuv.max=', 243.31599999999997, 'yuv.min=', 2.0369999999999999)
('yuv.max=', 233.24199999999999, 'yuv.min=', 27.711999999999996)
('yuv.max=', 187.0, 'yuv.min=', 3.0)
('yuv.max=', 248.41800000000001, 'yuv.min=', 7.4409999999999998)
('yuv.max=', 197.602, 'yuv.min=', 25.305999999999997)
('yuv.max=', 227.71099999999998, 'yuv.min=', 53.591000000000001)
('yuv.max=', 255.0, 'yuv.min=', 41.656999999999996)
('yuv.max=', 220.0, 'yuv.min=', 50.0)
('yuv.max=', 247.0, 'yuv.min=', 19.712)
('yuv.max=', 238.36199999999999, 'yuv.min=', 8.5589999999999993)
('yuv.max=', 210.62499999999997, 'yuv.min=', 19.210999999999999)
('yuv.max=', 255.0, 'yuv.min=', 60.100448)
('yuv.max=', 228.31670399999999, 'yuv.min=', 45.358000000000004)
('yuv.max=', 197.48787200000001, 'yuv.min=', 17.786000000000001)
('yuv.max=', 233.11399999999998, 'yuv.min=', 37.739999999999995)
('yuv.max=', 254.886, 'yuv.min=', 2.4279999999999999)
('yuv.max=', 235.22299999999998, 'yuv.min=', 9.6900000000000013)
('yuv.max=', 251.30500000000001, 'yuv.min=', 5.2539999999999996)
('yuv.max=', 241.71799999999996, 'yuv.min=', 28.367999999999995)
('yuv.max=', 230.79799999999997, 'yuv.min=', 45.775999999999996)
('yuv.max=', 255.0, 'yuv.min=', 36.021999999999998)
('yuv.max=', 241.68399999999997, 'yuv.min=', 69.591999999999999)
('yuv.max=', 184.30099999999999, 'yuv.min=', 51.586999999999996)
('yuv.max=', 246.0, 'yuv.min=', 90.999999999999986)
('yuv.max=', 237.72199999999998, 'yuv.min=', 30.074999999999999)
('yuv.max=', 238.43099999999998, 'yuv.min=', 55.539968000000002)
('yuv.max=', 247.36399999999998, 'yuv.min=', 30.373999999999999)
('yuv.max=', 202.935, 'yuv.min=', 5.944)
('yuv.max=', 207.0, 'yuv.min=', 37.0)
('yuv.max=', 223.10556799999998, 'yuv.min=', 48.829000000000001)
('yuv.max=', 236.67599999999999, 'yuv.min=', 8.391)
('yuv.max=', 255.0, 'yuv.min=', 1.7829999999999999)
('yuv.max=', 251.393, 'yuv.min=', 16.753)
('yuv.max=', 253.52699999999999, 'yuv.min=', 1.7829999999999999)
('yuv.max=', 250.47299999999998, 'yuv.min=', 12.206)
('yuv.max=', 246.512, 'yuv.min=', 13.853000000000002)
('yuv.max=', 217.684, 'yuv.min=', 23.587)
('yuv.max=', 228.34800000000001, 'yuv.min=', 87.455999999999989)
('yuv.max=', 236.85600000000002, 'yuv.min=', 0.114)
('yuv.max=', 243.52699999999999, 'yuv.min=', 23.475000000000001)
('yuv.max=', 249.20799999999997, 'yuv.min=', 21.558999999999997)
('yuv.max=', 251.54399999999998, 'yuv.min=', 2.5699999999999998)
('yuv.max=', 253.0, 'yuv.min=', 3.5870000000000002)
('yuv.max=', 242.88799999999998, 'yuv.min=', 33.728999999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', 21.689999999999998)
('yuv.max=', 152.38092800000001, 'yuv.min=', 41.481000000000002)
('yuv.max=', 245.727, 'yuv.min=', 50.683999999999997)
('yuv.max=', 237.88799999999998, 'yuv.min=', 2.3700000000000001)
('yuv.max=', 245.76499999999999, 'yuv.min=', 0.0)
('yuv.max=', 231.435, 'yuv.min=', 2.6299999999999999)
('yuv.max=', 243.82999999999998, 'yuv.min=', 8.0969999999999995)
('yuv.max=', 250.02099999999999, 'yuv.min=', 64.328999999999994)
('yuv.max=', 230.732, 'yuv.min=', 60.889999999999993)
('yuv.max=', 199.535, 'yuv.min=', 85.158000000000001)
('yuv.max=', 241.447, 'yuv.min=', 17.489999999999998)
('yuv.max=', 255.0, 'yuv.min=', 14.734999999999999)
('yuv.max=', 202.20699999999997, 'yuv.min=', 20.943999999999999)
('yuv.max=', 243.536, 'yuv.min=', 39.840999999999994)
('yuv.max=', 189.37200000000001, 'yuv.min=', 18.749999999999996)
('yuv.max=', 187.14899999999997, 'yuv.min=', 7.4749999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 60.411000000000001)
('yuv.max=', 252.64099999999996, 'yuv.min=', 21.943999999999999)
('yuv.max=', 255.0, 'yuv.min=', 27.941999999999997)
('yuv.max=', 233.82599999999999, 'yuv.min=', 25.452999999999999)
('yuv.max=', 250.40599999999998, 'yuv.min=', 19.922999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 247.57099999999997, 'yuv.min=', 16.368999999999996)
('yuv.max=', 254.886, 'yuv.min=', 22.565999999999999)
('yuv.max=', 210.71100000000001, 'yuv.min=', 17.788)
('yuv.max=', 253.07700000000003, 'yuv.min=', 14.946)
('yuv.max=', 182.36600000000001, 'yuv.min=', 16.366)
('yuv.max=', 243.56999999999999, 'yuv.min=', 23.704000000000001)
('yuv.max=', 243.29800000000003, 'yuv.min=', 32.351999999999997)
('yuv.max=', 243.16099999999997, 'yuv.min=', 23.617999999999999)
('yuv.max=', 255.0, 'yuv.min=', 70.772000000000006)
('yuv.max=', 250.0, 'yuv.min=', 17.0)
('yuv.max=', 222.84699999999998, 'yuv.min=', 28.978999999999999)
('yuv.max=', 234.17599999999999, 'yuv.min=', 8.6820000000000004)
('yuv.max=', 250.53699999999998, 'yuv.min=', 9.8780000000000001)
('yuv.max=', 243.33499999999998, 'yuv.min=', 27.982999999999997)
('yuv.max=', 254.06, 'yuv.min=', 39.725000000000001)
('yuv.max=', 220.25499999999997, 'yuv.min=', 38.863)
('yuv.max=', 169.35999999999999, 'yuv.min=', 3.5589999999999997)
('yuv.max=', 238.23899999999998, 'yuv.min=', 4.5699999999999994)
('yuv.max=', 246.06, 'yuv.min=', 0.0)
('yuv.max=', 250.27099999999999, 'yuv.min=', 12.883999999999999)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 222.43935999999999, 'yuv.min=', 27.766000000000002)
('yuv.max=', 255.0, 'yuv.min=', 33.704999999999998)
('yuv.max=', 238.24199999999999, 'yuv.min=', 62.456543999999994)
('yuv.max=', 241.369, 'yuv.min=', 7.6909999999999998)
('yuv.max=', 253.97400000000002, 'yuv.min=', 55.75)
('yuv.max=', 231.56299999999999, 'yuv.min=', 22.161999999999999)
('yuv.max=', 235.256, 'yuv.min=', 5.9899999999999993)
('yuv.max=', 239.86899999999997, 'yuv.min=', 14.0)
('yuv.max=', 246.84599999999998, 'yuv.min=', 21.683)
('yuv.max=', 248.0, 'yuv.min=', 68.0)
('yuv.max=', 244.15699999999998, 'yuv.min=', 56.384999999999998)
('yuv.max=', 253.84299999999996, 'yuv.min=', 48.234999999999999)
('yuv.max=', 219.47799999999998, 'yuv.min=', 23.493999999999996)
('yuv.max=', 249.56499999999997, 'yuv.min=', 4.0860000000000003)
('yuv.max=', 247.06199999999998, 'yuv.min=', 30.194999999999997)
('yuv.max=', 237.05999999999997, 'yuv.min=', 13.961)
('yuv.max=', 255.0, 'yuv.min=', 36.322000000000003)
('yuv.max=', 254.70099999999999, 'yuv.min=', 12.082000000000001)
('yuv.max=', 215.25999999999999, 'yuv.min=', 42.128999999999998)
('yuv.max=', 250.77199999999996, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 80.455999999999989)
('yuv.max=', 246.00799999999995, 'yuv.min=', 43.173999999999999)
('yuv.max=', 236.87799999999999, 'yuv.min=', 33.229999999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', 44.048999999999992)
('yuv.max=', 226.08800000000002, 'yuv.min=', 17.492999999999999)
('yuv.max=', 234.185, 'yuv.min=', 32.480999999999995)
('yuv.max=', 217.97200000000001, 'yuv.min=', 35.722999999999999)
('yuv.max=', 234.08899999999997, 'yuv.min=', 34.097999999999999)
('yuv.max=', 250.99999999999997, 'yuv.min=', 6.5679999999999996)
('yuv.max=', 255.0, 'yuv.min=', 37.266999999999996)
('yuv.max=', 255.0, 'yuv.min=', 50.999999999999993)
('yuv.max=', 203.15699999999998, 'yuv.min=', 30.227999999999998)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 246.15299999999999, 'yuv.min=', 28.587)
('yuv.max=', 255.0, 'yuv.min=', 10.681151999999997)
('yuv.max=', 236.364, 'yuv.min=', 7.2710000000000008)
('yuv.max=', 204.07299999999998, 'yuv.min=', 6.1949999999999994)
('yuv.max=', 217.76899999999998, 'yuv.min=', 40.848999999999997)
('yuv.max=', 255.0, 'yuv.min=', 56.472999999999999)
('yuv.max=', 246.03399999999999, 'yuv.min=', 22.703999999999997)
('yuv.max=', 231.78, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 211.39500000000001, 'yuv.min=', 1.0110000000000001)
('yuv.max=', 247.83599999999998, 'yuv.min=', 38.604999999999997)
('yuv.max=', 243.99999999999997, 'yuv.min=', 15.0)
('yuv.max=', 236.41399999999999, 'yuv.min=', 7.9029999999999987)
('yuv.max=', 246.49299999999999, 'yuv.min=', 16.712)
('yuv.max=', 251.60599999999999, 'yuv.min=', 26.046999999999997)
('yuv.max=', 240.38300000000001, 'yuv.min=', 43.555)
('yuv.max=', 191.11599999999999, 'yuv.min=', 15.815)
('yuv.max=', 250.76099999999997, 'yuv.min=', 17.544999999999998)
('yuv.max=', 243.91399999999999, 'yuv.min=', 21.331)
('yuv.max=', 244.38299999999998, 'yuv.min=', 27.517999999999997)
('yuv.max=', 149.024832, 'yuv.min=', 18.698999999999998)
('yuv.max=', 216.84299999999999, 'yuv.min=', 15.889999999999999)
('yuv.max=', 254.29899999999995, 'yuv.min=', 9.1569999999999983)
('yuv.max=', 242.97800000000001, 'yuv.min=', 43.030000000000001)
('yuv.max=', 152.81699999999998, 'yuv.min=', 2.157)
('yuv.max=', 196.37, 'yuv.min=', 1.2390000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 245.64099999999999, 'yuv.min=', 13.858000000000001)
('yuv.max=', 236.75699999999998, 'yuv.min=', 5.8188480000000027)
('yuv.max=', 255.0, 'yuv.min=', 29.604999999999997)
('yuv.max=', 209.00300000000001, 'yuv.min=', 43.830999999999996)
('yuv.max=', 228.05799999999999, 'yuv.min=', 9.9819999999999993)
('yuv.max=', 255.0, 'yuv.min=', 15.151999999999999)
('yuv.max=', 248.58100000000002, 'yuv.min=', 21.940999999999995)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 237.32299999999998, 'yuv.min=', 20.614999999999998)
('yuv.max=', 254.202, 'yuv.min=', 1.5270000000000001)
('yuv.max=', 213.733, 'yuv.min=', 47.134999999999998)
('yuv.max=', 219.84700000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 52.325000000000003)
('yuv.max=', 255.0, 'yuv.min=', 26.999999999999996)
('yuv.max=', 236.44300000000001, 'yuv.min=', 18.477999999999998)
('yuv.max=', 197.15100000000001, 'yuv.min=', 10.027000000000001)
('yuv.max=', 237.10499999999999, 'yuv.min=', 76.942999999999998)
('yuv.max=', 221.62, 'yuv.min=', 19.350999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 232.62099999999998, 'yuv.min=', 70.234999999999999)
('yuv.max=', 255.0, 'yuv.min=', 37.401999999999994)
('yuv.max=', 234.08799999999997, 'yuv.min=', 42.248999999999995)
('yuv.max=', 172.17116799999999, 'yuv.min=', 7.8540000000000001)
('yuv.max=', 242.89699999999999, 'yuv.min=', 34.146000000000001)
('yuv.max=', 220.447, 'yuv.min=', 29.504999999999999)
('yuv.max=', 215.012, 'yuv.min=', 4.2449999999999992)
('yuv.max=', 177.887136, 'yuv.min=', 9.032)
('yuv.max=', 180.46600000000001, 'yuv.min=', 54.946999999999996)
('yuv.max=', 248.56, 'yuv.min=', 12.144)
('yuv.max=', 251.733, 'yuv.min=', 23.353999999999999)
('yuv.max=', 210.38499999999999, 'yuv.min=', 24.823)
('yuv.max=', 244.137, 'yuv.min=', 12.891999999999999)
('yuv.max=', 255.0, 'yuv.min=', 15.662999999999998)
('yuv.max=', 250.68999999999997, 'yuv.min=', 17.810999999999996)
('yuv.max=', 207.23500000000001, 'yuv.min=', 68.36999999999999)
('yuv.max=', 240.44999999999999, 'yuv.min=', 39.356999999999999)
('yuv.max=', 165.43199999999999, 'yuv.min=', 51.163999999999994)
('yuv.max=', 239.00599999999997, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 254.54400000000001, 'yuv.min=', 40.091999999999999)
('yuv.max=', 247.79999999999998, 'yuv.min=', 22.879999999999999)
('yuv.max=', 241.11899999999997, 'yuv.min=', 17.0)
('yuv.max=', 252.66899999999998, 'yuv.min=', 4.7400000000000002)
('yuv.max=', 252.27699999999999, 'yuv.min=', 0.0)
('yuv.max=', 239.499, 'yuv.min=', 36.789000000000001)
('yuv.max=', 232.53100000000001, 'yuv.min=', 33.994999999999997)
('yuv.max=', 226.17600000000002, 'yuv.min=', 54.755000000000003)
('yuv.max=', 242.61400000000003, 'yuv.min=', 0.0)
('yuv.max=', 253.47299999999998, 'yuv.min=', 23.701999999999998)
('yuv.max=', 138.02425600000001, 'yuv.min=', 6.0110000000000001)
('yuv.max=', 251.03199999999995, 'yuv.min=', 17.068999999999999)
('yuv.max=', 253.97400000000002, 'yuv.min=', 22.411999999999999)
('yuv.max=', 254.886, 'yuv.min=', 31.619)
('yuv.max=', 234.74199999999999, 'yuv.min=', 25.539000000000001)
('yuv.max=', 255.0, 'yuv.min=', 28.212999999999997)
('yuv.max=', 242.55700000000002, 'yuv.min=', 4.2990000000000004)
('yuv.max=', 248.245, 'yuv.min=', 20.403999999999996)
('yuv.max=', 220.29700000000003, 'yuv.min=', 55.235999999999997)
('yuv.max=', 247.83099999999996, 'yuv.min=', 4.3639999999999999)
('yuv.max=', 238.03199999999998, 'yuv.min=', 41.025999999999996)
('yuv.max=', 247.84299999999999, 'yuv.min=', 0.0)
('yuv.max=', 246.11399999999998, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 241.07899999999998, 'yuv.min=', 2.1080000000000001)
('yuv.max=', 215.0, 'yuv.min=', 15.999999999999998)
('yuv.max=', 155.67100000000002, 'yuv.min=', 25.582000000000001)
('yuv.max=', 212.38200000000001, 'yuv.min=', 28.259999999999998)
('yuv.max=', 210.131, 'yuv.min=', 45.474999999999994)
('yuv.max=', 213.83199999999999, 'yuv.min=', 16.513999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 4.4629999999999992)
('yuv.max=', 227.59899999999996, 'yuv.min=', 14.209)
('yuv.max=', 139.20755199999999, 'yuv.min=', 4.4740000000000002)
('yuv.max=', 231.20299999999997, 'yuv.min=', 9.6519999999999992)
('yuv.max=', 155.17999999999998, 'yuv.min=', 34.231999999999999)
('yuv.max=', 241.22799999999998, 'yuv.min=', 5.2279999999999998)
('yuv.max=', 250.84300000000002, 'yuv.min=', 16.780999999999999)
('yuv.max=', 248.26599999999996, 'yuv.min=', 1.7609999999999999)
('yuv.max=', 215.99999999999997, 'yuv.min=', 15.0)
('yuv.max=', 214.71599999999998, 'yuv.min=', 0.0)
('yuv.max=', 242.58100000000002, 'yuv.min=', 32.613)
('yuv.max=', 232.95899999999997, 'yuv.min=', 6.8559999999999999)
('yuv.max=', 244.142, 'yuv.min=', 60.736999999999995)
('yuv.max=', 206.71499999999997, 'yuv.min=', 48.207999999999998)
('yuv.max=', 246.0, 'yuv.min=', 71.0)
('yuv.max=', 255.0, 'yuv.min=', 25.999999999999996)
('yuv.max=', 251.184, 'yuv.min=', 27.906999999999996)
('yuv.max=', 255.0, 'yuv.min=', 16.576000000000001)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 232.12899999999999, 'yuv.min=', 5.1459999999999999)
('yuv.max=', 206.68699999999998, 'yuv.min=', 14.4)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 189.33700000000002, 'yuv.min=', 12.875)
('yuv.max=', 245.387, 'yuv.min=', 14.238999999999999)
('yuv.max=', 218.185, 'yuv.min=', 46.523999999999994)
('yuv.max=', 181.0, 'yuv.min=', 7.0)
('yuv.max=', 248.261, 'yuv.min=', 1.2709999999999999)
('yuv.max=', 234.85699999999997, 'yuv.min=', 6.1829999999999998)
('yuv.max=', 248.54800000000003, 'yuv.min=', 27.923999999999999)
('yuv.max=', 224.03, 'yuv.min=', 51.744999999999997)
('yuv.max=', 245.75299999999999, 'yuv.min=', 36.887999999999998)
('yuv.max=', 198.49200000000002, 'yuv.min=', 9.0190000000000001)
('yuv.max=', 231.70299999999997, 'yuv.min=', 14.904999999999999)
('yuv.max=', 232.50700000000001, 'yuv.min=', 21.248999999999999)
('yuv.max=', 216.79799999999997, 'yuv.min=', 118.512128)
('yuv.max=', 251.91799999999998, 'yuv.min=', 30.911999999999999)
('yuv.max=', 237.82299999999998, 'yuv.min=', 17.483999999999998)
('yuv.max=', 242.87299999999999, 'yuv.min=', 20.483999999999998)
('yuv.max=', 216.542, 'yuv.min=', 11.284000000000001)
('yuv.max=', 237.25, 'yuv.min=', 33.271000000000001)
('yuv.max=', 225.16799999999998, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 252.309, 'yuv.min=', 7.6280000000000001)
('yuv.max=', 217.58999999999997, 'yuv.min=', 3.0)
('yuv.max=', 201.99099999999999, 'yuv.min=', 12.287999999999998)
('yuv.max=', 236.77599999999998, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 217.23799999999997, 'yuv.min=', 22.251000000000001)
('yuv.max=', 255.0, 'yuv.min=', 19.309000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 29.43)
('yuv.max=', 248.84299999999999, 'yuv.min=', 11.792999999999999)
('yuv.max=', 254.886, 'yuv.min=', 0.0)
('yuv.max=', 235.66, 'yuv.min=', 10.760999999999999)
('yuv.max=', 255.0, 'yuv.min=', 12.629000000000001)
('yuv.max=', 254.65800000000002, 'yuv.min=', 14.483999999999998)
('yuv.max=', 217.499, 'yuv.min=', 33.140000000000001)
('yuv.max=', 255.0, 'yuv.min=', 38.466999999999999)
('yuv.max=', 195.57899999999998, 'yuv.min=', 9.75)
('yuv.max=', 250.99999999999997, 'yuv.min=', 33.686)
('yuv.max=', 249.815, 'yuv.min=', 26.700999999999997)
('yuv.max=', 244.38600000000002, 'yuv.min=', 16.472999999999999)
('yuv.max=', 235.79499999999996, 'yuv.min=', 48.376999999999995)
('yuv.max=', 216.70000000000002, 'yuv.min=', 33.220999999999997)
('yuv.max=', 243.309, 'yuv.min=', 2.2170000000000001)
('yuv.max=', 230.41199999999998, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 11.728999999999999)
('yuv.max=', 252.03399999999996, 'yuv.min=', 33.265999999999998)
('yuv.max=', 255.0, 'yuv.min=', 2.9079999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 0.0)
('yuv.max=', 240.184, 'yuv.min=', 16.030000000000001)
('yuv.max=', 252.309, 'yuv.min=', 14.0)
('yuv.max=', 236.92599999999999, 'yuv.min=', 4.1829999999999998)
('yuv.max=', 205.40099999999998, 'yuv.min=', 11.234)
('yuv.max=', 255.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 234.39999999999998, 'yuv.min=', 31.908000000000001)
('yuv.max=', 253.64700000000002, 'yuv.min=', 11.882)
('yuv.max=', 158.56208000000001, 'yuv.min=', 43.172000000000004)
('yuv.max=', 247.65800000000002, 'yuv.min=', 56.119999999999997)
('yuv.max=', 237.79699999999997, 'yuv.min=', 2.3919999999999999)
('yuv.max=', 245.58799999999999, 'yuv.min=', 10.591999999999999)
('yuv.max=', 234.38300000000001, 'yuv.min=', 47.785999999999994)
('yuv.max=', 208.82400000000001, 'yuv.min=', 18.483000000000001)
('yuv.max=', 251.24499999999995, 'yuv.min=', 10.716000000000001)
('yuv.max=', 213.39099999999996, 'yuv.min=', 8.4619999999999997)
('yuv.max=', 215.33399999999997, 'yuv.min=', 37.286000000000001)
('yuv.max=', 209.16, 'yuv.min=', 9.6039999999999992)
('yuv.max=', 250.16999999999999, 'yuv.min=', 20.983000000000001)
('yuv.max=', 245.077, 'yuv.min=', 29.381999999999998)
('yuv.max=', 187.453, 'yuv.min=', 12.388)
('yuv.max=', 200.29599999999996, 'yuv.min=', 29.885999999999999)
('yuv.max=', 241.61099999999999, 'yuv.min=', 15.372999999999999)
('yuv.max=', 234.99999999999997, 'yuv.min=', 37.390000000000001)
('yuv.max=', 237.21599999999998, 'yuv.min=', 55.976999999999997)
('yuv.max=', 179.911968, 'yuv.min=', 18.561)
('yuv.max=', 246.77199999999999, 'yuv.min=', 21.287999999999997)
('yuv.max=', 255.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 242.61899999999997, 'yuv.min=', 23.997)
('yuv.max=', 238.84699999999998, 'yuv.min=', 30.728999999999999)
('yuv.max=', 240.91800000000001, 'yuv.min=', 25.909999999999997)
('yuv.max=', 209.17100000000002, 'yuv.min=', 11.922000000000001)
('yuv.max=', 195.55099999999999, 'yuv.min=', 13.582999999999998)
('yuv.max=', 208.542, 'yuv.min=', 0.0)
('yuv.max=', 152.30799999999999, 'yuv.min=', 20.544999999999998)
('yuv.max=', 255.0, 'yuv.min=', 1.3100000000000001)
('yuv.max=', 184.36999999999998, 'yuv.min=', 7.3959999999999999)
('yuv.max=', 236.92699999999996, 'yuv.min=', 5.4240000000000004)
('yuv.max=', 189.40100000000001, 'yuv.min=', 1.71)
('yuv.max=', 232.09900000000002, 'yuv.min=', 9.918000000000001)
('yuv.max=', 228.91399999999999, 'yuv.min=', 37.893000000000001)
('yuv.max=', 217.298, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 246.56899999999999, 'yuv.min=', 22.942999999999998)
('yuv.max=', 253.14199999999997, 'yuv.min=', 1.196)
('yuv.max=', 255.0, 'yuv.min=', 56.309999999999995)
('yuv.max=', 245.43199999999999, 'yuv.min=', 63.266999999999996)
('yuv.max=', 217.71499999999997, 'yuv.min=', 20.866999999999997)
('yuv.max=', 255.0, 'yuv.min=', 48.507000000000005)
('yuv.max=', 207.63800000000001, 'yuv.min=', 56.946999999999996)
('yuv.max=', 255.0, 'yuv.min=', 16.213000000000001)
('yuv.max=', 203.05499999999998, 'yuv.min=', 18.768000000000001)
('yuv.max=', 144.887136, 'yuv.min=', 20.412999999999997)
('yuv.max=', 242.37399999999997, 'yuv.min=', 17.799999999999997)
('yuv.max=', 255.0, 'yuv.min=', 7.0709999999999997)
('yuv.max=', 226.90399999999997, 'yuv.min=', 0.0)
('yuv.max=', 227.036, 'yuv.min=', 13.227999999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', 29.0)
('yuv.max=', 243.88199999999998, 'yuv.min=', 2.282)
('yuv.max=', 212.232, 'yuv.min=', 80.611999999999995)
('yuv.max=', 251.27700000000002, 'yuv.min=', 80.694000000000003)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 231.20599999999999, 'yuv.min=', 0.114)
('yuv.max=', 238.392, 'yuv.min=', 57.538999999999994)
('yuv.max=', 230.51999999999998, 'yuv.min=', 7.145999999999999)
('yuv.max=', 250.91799999999998, 'yuv.min=', 19.271999999999998)
('yuv.max=', 182.245, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 230.423, 'yuv.min=', 32.106999999999999)
('yuv.max=', 236.14600000000002, 'yuv.min=', 0.0)
('yuv.max=', 226.0, 'yuv.min=', 63.0)
('yuv.max=', 146.36851200000001, 'yuv.min=', 13.760999999999999)
('yuv.max=', 255.0, 'yuv.min=', 58.947000000000003)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 220.21699999999998, 'yuv.min=', 16.867999999999999)
('yuv.max=', 229.88599999999997, 'yuv.min=', 4.1660000000000004)
('yuv.max=', 243.67099999999996, 'yuv.min=', 74.518000000000001)
('yuv.max=', 247.52499999999998, 'yuv.min=', 14.858000000000001)
('yuv.max=', 235.74000000000001, 'yuv.min=', 16.897000000000002)
('yuv.max=', 243.30500000000001, 'yuv.min=', 13.648000000000001)
('yuv.max=', 253.0, 'yuv.min=', 24.738)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.670999999999999)
('yuv.max=', 244.92700000000002, 'yuv.min=', 8.0759999999999987)
('yuv.max=', 173.81200000000001, 'yuv.min=', 44.831999999999994)
('yuv.max=', 245.91800000000001, 'yuv.min=', 22.988999999999997)
('yuv.max=', 255.0, 'yuv.min=', 66.228999999999999)
('yuv.max=', 189.07699999999997, 'yuv.min=', 44.257999999999996)
('yuv.max=', 164.59199999999998, 'yuv.min=', 0.0)
('yuv.max=', 227.46699999999998, 'yuv.min=', 40.158999999999999)
('yuv.max=', 255.0, 'yuv.min=', 8.7189999999999994)
('yuv.max=', 247.14599999999999, 'yuv.min=', 39.806999999999995)
('yuv.max=', 248.57599999999999, 'yuv.min=', 5.1200000000000001)
('yuv.max=', 249.70099999999999, 'yuv.min=', 26.989000000000001)
('yuv.max=', 252.53299999999999, 'yuv.min=', 13.602)
('yuv.max=', 255.0, 'yuv.min=', 18.167999999999999)
('yuv.max=', 253.202, 'yuv.min=', 0.0)
('yuv.max=', 233.387, 'yuv.min=', 21.657999999999998)
('yuv.max=', 245.387, 'yuv.min=', 33.733999999999995)
('yuv.max=', 173.10699999999997, 'yuv.min=', 0.92900000000000005)
('yuv.max=', 255.0, 'yuv.min=', 79.0)
('yuv.max=', 250.98899999999998, 'yuv.min=', 8.7719999999999985)
('yuv.max=', 194.322, 'yuv.min=', 7.0990000000000002)
('yuv.max=', 234.50099999999998, 'yuv.min=', 8.5220000000000002)
('yuv.max=', 253.0, 'yuv.min=', 6.5099999999999998)
('yuv.max=', 219.17400000000001, 'yuv.min=', 24.332999999999998)
('yuv.max=', 254.35900000000001, 'yuv.min=', 3.3909999999999996)
('yuv.max=', 216.96199999999999, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 225.733, 'yuv.min=', 10.254)
('yuv.max=', 229.86099999999999, 'yuv.min=', 15.387)
('yuv.max=', 245.98999999999998, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 246.17400000000001, 'yuv.min=', 19.126999999999999)
('yuv.max=', 248.28799999999995, 'yuv.min=', 12.100999999999999)
('yuv.max=', 247.10299999999998, 'yuv.min=', 13.49)
('yuv.max=', 249.804, 'yuv.min=', 2.4729999999999999)
('yuv.max=', 236.79099999999997, 'yuv.min=', 28.413)
('yuv.max=', 253.99999999999997, 'yuv.min=', 49.0)
('yuv.max=', 156.964, 'yuv.min=', 21.704000000000001)
('yuv.max=', 177.47599999999997, 'yuv.min=', 36.094999999999999)
('yuv.max=', 158.92399999999998, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 255.0, 'yuv.min=', 39.371000000000002)
('yuv.max=', 255.0, 'yuv.min=', 21.791999999999998)
('yuv.max=', 226.279, 'yuv.min=', 43.217000000000006)
('yuv.max=', 156.22460799999999, 'yuv.min=', 38.156999999999996)
('yuv.max=', 199.71700000000001, 'yuv.min=', 29.780999999999999)
('yuv.max=', 252.93999999999997, 'yuv.min=', 74.558999999999997)
('yuv.max=', 255.0, 'yuv.min=', 73.998000000000005)
('yuv.max=', 226.89399999999998, 'yuv.min=', 12.206)
('yuv.max=', 157.90600000000001, 'yuv.min=', 6.8090000000000002)
('yuv.max=', 246.31, 'yuv.min=', 29.968)
('yuv.max=', 255.0, 'yuv.min=', 48.618999999999993)
('yuv.max=', 253.39099999999999, 'yuv.min=', 3.4730000000000003)
('yuv.max=', 250.22800000000001, 'yuv.min=', 5.0)
('yuv.max=', 231.49899999999997, 'yuv.min=', 0.0)
('yuv.max=', 225.96199999999996, 'yuv.min=', 12.562999999999999)
('yuv.max=', 247.0, 'yuv.min=', 71.709999999999994)
('yuv.max=', 225.32399999999998, 'yuv.min=', 56.135999999999996)
('yuv.max=', 243.92000000000002, 'yuv.min=', 19.091000000000001)
('yuv.max=', 171.679, 'yuv.min=', 7.673)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 249.744, 'yuv.min=', 36.730999999999995)
('yuv.max=', 255.0, 'yuv.min=', 8.6469999999999985)
('yuv.max=', 172.30531200000001, 'yuv.min=', 34.422999999999995)
('yuv.max=', 227.41400000000002, 'yuv.min=', 32.061)
('yuv.max=', 226.39099999999996, 'yuv.min=', 35.925999999999995)
('yuv.max=', 233.98700000000002, 'yuv.min=', 35.573999999999998)
('yuv.max=', 244.97300000000001, 'yuv.min=', 12.016)
('yuv.max=', 240.92699999999999, 'yuv.min=', 91.764999999999986)
('yuv.max=', 196.38299999999998, 'yuv.min=', 46.158000000000001)
('yuv.max=', 229.18499999999997, 'yuv.min=', 30.086000000000002)
('yuv.max=', 243.15299999999999, 'yuv.min=', 26.693999999999999)
('yuv.max=', 250.131, 'yuv.min=', 19.173999999999999)
('yuv.max=', 238.61199999999999, 'yuv.min=', 6.1139999999999999)
('yuv.max=', 253.81499999999997, 'yuv.min=', 12.095000000000001)
('yuv.max=', 255.0, 'yuv.min=', 14.419999999999998)
('yuv.max=', 187.511, 'yuv.min=', 40.909999999999997)
('yuv.max=', 237.61799999999999, 'yuv.min=', 51.658000000000001)
('yuv.max=', 252.60399999999998, 'yuv.min=', 31.746999999999996)
('yuv.max=', 219.72499999999997, 'yuv.min=', 31.794999999999998)
('yuv.max=', 238.43799999999999, 'yuv.min=', 13.850999999999999)
('yuv.max=', 209.904, 'yuv.min=', 7.1749999999999989)
('yuv.max=', 247.78899999999999, 'yuv.min=', 22.115999999999996)
('yuv.max=', 243.04300000000001, 'yuv.min=', 35.014000000000003)
('yuv.max=', 212.93599999999998, 'yuv.min=', 9.8339999999999996)
('yuv.max=', 215.227, 'yuv.min=', 0.0)
('yuv.max=', 242.22800000000001, 'yuv.min=', 35.017999999999994)
('yuv.max=', 255.0, 'yuv.min=', 20.68)
('yuv.max=', 254.316, 'yuv.min=', 5.327)
('yuv.max=', 254.29899999999995, 'yuv.min=', 0.0)
('yuv.max=', 253.80399999999997, 'yuv.min=', 18.960999999999999)
('yuv.max=', 231.44699999999997, 'yuv.min=', 9.3159999999999989)
('yuv.max=', 202.91, 'yuv.min=', 7.673)
('yuv.max=', 252.50499999999997, 'yuv.min=', 43.162999999999997)
('yuv.max=', 225.31, 'yuv.min=', 39.536999999999999)
('yuv.max=', 228.36799999999999, 'yuv.min=', 32.662999999999997)
('yuv.max=', 248.86500000000001, 'yuv.min=', 27.640999999999998)
('yuv.max=', 253.505, 'yuv.min=', 36.920999999999999)
('yuv.max=', 223.435, 'yuv.min=', 43.287999999999997)
('yuv.max=', 205.60499999999999, 'yuv.min=', 17.983000000000001)
('yuv.max=', 245.04900000000001, 'yuv.min=', 4.391)
('yuv.max=', 255.0, 'yuv.min=', 25.196000000000002)
('yuv.max=', 254.77200000000002, 'yuv.min=', 52.221999999999994)
('yuv.max=', 211.0, 'yuv.min=', 21.0)
('yuv.max=', 239.56500000000003, 'yuv.min=', 46.893000000000001)
('yuv.max=', 251.71100000000001, 'yuv.min=', 8.4919999999999991)
('yuv.max=', 255.0, 'yuv.min=', 31.308999999999997)
('yuv.max=', 247.09899999999999, 'yuv.min=', 13.733000000000001)
('yuv.max=', 228.929, 'yuv.min=', 24.928999999999998)
('yuv.max=', 234.70799999999997, 'yuv.min=', 16.902999999999999)
('yuv.max=', 255.0, 'yuv.min=', 60.027000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 232.94800000000001, 'yuv.min=', 14.902999999999999)
('yuv.max=', 249.77199999999999, 'yuv.min=', 6.157)
('yuv.max=', 255.0, 'yuv.min=', 18.619)
('yuv.max=', 182.137, 'yuv.min=', 62.307999999999993)
('yuv.max=', 232.44999999999999, 'yuv.min=', 12.999999999999998)
('yuv.max=', 209.79599999999996, 'yuv.min=', 4.5699999999999994)
('yuv.max=', 185.83199999999999, 'yuv.min=', 9.2879999999999985)
('yuv.max=', 185.624, 'yuv.min=', 21.657999999999998)
('yuv.max=', 250.76099999999997, 'yuv.min=', 50.906999999999996)
('yuv.max=', 241.89199999999997, 'yuv.min=', 51.724999999999994)
('yuv.max=', 215.39099999999999, 'yuv.min=', 45.683999999999997)
('yuv.max=', 245.93899999999999, 'yuv.min=', 32.201999999999998)
('yuv.max=', 253.65799999999999, 'yuv.min=', 0.0)
('yuv.max=', 246.95599999999999, 'yuv.min=', 0.0)
('yuv.max=', 217.16999999999996, 'yuv.min=', 22.669)
('yuv.max=', 252.65199999999999, 'yuv.min=', 44.712999999999994)
('yuv.max=', 255.0, 'yuv.min=', 9.270999999999999)
('yuv.max=', 231.92000000000002, 'yuv.min=', 6.9460000000000006)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 223.74499999999998, 'yuv.min=', 21.399999999999999)
('yuv.max=', 183.51299999999998, 'yuv.min=', 40.588999999999999)
('yuv.max=', 245.78399999999999, 'yuv.min=', 14.555999999999999)
('yuv.max=', 255.0, 'yuv.min=', 3.3809999999999998)
('yuv.max=', 145.399552, 'yuv.min=', 41.323999999999998)
('yuv.max=', 248.89599999999999, 'yuv.min=', 33.351999999999997)
('yuv.max=', 228.87100000000001, 'yuv.min=', 12.016999999999999)
('yuv.max=', 255.0, 'yuv.min=', 27.808999999999997)
('yuv.max=', 249.916, 'yuv.min=', 40.686999999999998)
('yuv.max=', 237.82899999999998, 'yuv.min=', 40.658999999999999)
('yuv.max=', 250.77199999999996, 'yuv.min=', 14.657999999999999)
('yuv.max=', 199.62265600000001, 'yuv.min=', 24.539999999999999)
('yuv.max=', 234.77599999999995, 'yuv.min=', 15.629999999999999)
('yuv.max=', 187.52699999999999, 'yuv.min=', 11.488)
('yuv.max=', 224.613, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 248.53800000000001, 'yuv.min=', 33.130999999999993)
('yuv.max=', 248.59799999999998, 'yuv.min=', 35.409999999999997)
('yuv.max=', 252.85999999999999, 'yuv.min=', 17.983000000000001)
('yuv.max=', 253.72899999999996, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 25.999999999999996)
('yuv.max=', 212.93081599999999, 'yuv.min=', 3.032)
('yuv.max=', 169.605536, 'yuv.min=', 35.694999999999993)
('yuv.max=', 238.77600000000001, 'yuv.min=', 3.9889999999999994)
('yuv.max=', 200.06200000000001, 'yuv.min=', 33.576000000000001)
('yuv.max=', 255.0, 'yuv.min=', 12.505999999999998)
('yuv.max=', 234.78599999999997, 'yuv.min=', 12.195)
('yuv.max=', 236.59099999999998, 'yuv.min=', 8.2170000000000005)
('yuv.max=', 238.58699999999999, 'yuv.min=', 25.445)
('yuv.max=', 250.541, 'yuv.min=', 21.907)
('yuv.max=', 160.761, 'yuv.min=', 28.814999999999998)
('yuv.max=', 210.96099999999998, 'yuv.min=', 0.0)
('yuv.max=', 244.35900000000001, 'yuv.min=', 23.889999999999997)
('yuv.max=', 224.25400000000002, 'yuv.min=', 15.414999999999999)
('yuv.max=', 235.041, 'yuv.min=', 12.743999999999998)
('yuv.max=', 235.50099999999998, 'yuv.min=', 9.359)
('yuv.max=', 249.39599999999999, 'yuv.min=', 28.912999999999997)
('yuv.max=', 203.57999999999998, 'yuv.min=', 44.332999999999998)
('yuv.max=', 255.0, 'yuv.min=', 2.5489999999999999)
('yuv.max=', 245.0, 'yuv.min=', 37.0)
('yuv.max=', 216.07899999999998, 'yuv.min=', 0.755)
('yuv.max=', 248.81, 'yuv.min=', 28.725000000000001)
('yuv.max=', 180.37472, 'yuv.min=', 6.8580000000000005)
('yuv.max=', 228.75799999999998, 'yuv.min=', 14.526999999999999)
('yuv.max=', 165.02067199999999, 'yuv.min=', 24.821999999999999)
('yuv.max=', 243.24299999999999, 'yuv.min=', 89.519999999999996)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 182.21999999999997, 'yuv.min=', 30.968999999999998)
('yuv.max=', 244.64099999999996, 'yuv.min=', 2.2880000000000003)
('yuv.max=', 241.869, 'yuv.min=', 10.513999999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', 0.0)
('yuv.max=', 233.96799999999999, 'yuv.min=', 9.7070000000000007)
('yuv.max=', 240.98599999999996, 'yuv.min=', 4.7119999999999997)
('yuv.max=', 218.114, 'yuv.min=', 8.125)
('yuv.max=', 239.03799999999998, 'yuv.min=', 19.186999999999998)
('yuv.max=', 251.55499999999998, 'yuv.min=', 10.885999999999999)
('yuv.max=', 254.70099999999999, 'yuv.min=', 2.093)
('yuv.max=', 254.65800000000002, 'yuv.min=', 5.8860000000000001)
('yuv.max=', 243.71899999999999, 'yuv.min=', 4.8220000000000001)
('yuv.max=', 230.14599999999996, 'yuv.min=', 5.5060000000000002)
('yuv.max=', 173.96100000000001, 'yuv.min=', 41.176000000000002)
('yuv.max=', 195.17475200000001, 'yuv.min=', 5.0609999999999999)
('yuv.max=', 255.0, 'yuv.min=', 55.283000000000001)
('yuv.max=', 249.16200000000001, 'yuv.min=', 10.363)
('yuv.max=', 244.97300000000001, 'yuv.min=', 58.334999999999994)
('yuv.max=', 207.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 2.9939999999999998)
('yuv.max=', 255.0, 'yuv.min=', 7.6300000000000008)
('yuv.max=', 255.0, 'yuv.min=', 2.9119999999999999)
('yuv.max=', 254.886, 'yuv.min=', 30.288999999999998)
('yuv.max=', 239.78700000000001, 'yuv.min=', 24.335000000000001)
('yuv.max=', 173.96800000000002, 'yuv.min=', 13.605999999999998)
('yuv.max=', 250.21600000000001, 'yuv.min=', 28.585999999999999)
('yuv.max=', 229.58699999999999, 'yuv.min=', 20.495000000000001)
('yuv.max=', 205.006, 'yuv.min=', 42.920999999999992)
('yuv.max=', 247.28800000000001, 'yuv.min=', 32.436999999999998)
('yuv.max=', 238.05000000000001, 'yuv.min=', 46.128999999999998)
('yuv.max=', 215.96899999999999, 'yuv.min=', 30.353000000000002)
('yuv.max=', 242.75500000000002, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 254.11399999999998, 'yuv.min=', 8.641)
('yuv.max=', 255.0, 'yuv.min=', 17.324999999999999)
('yuv.max=', 244.01900000000001, 'yuv.min=', 49.156999999999996)
('yuv.max=', 255.0, 'yuv.min=', 34.331000000000003)
('yuv.max=', 255.0, 'yuv.min=', 71.459999999999994)
('yuv.max=', 242.411, 'yuv.min=', 30.631999999999998)
('yuv.max=', 252.61899999999997, 'yuv.min=', 6.548)
('yuv.max=', 242.43099999999995, 'yuv.min=', 0.0)
('yuv.max=', 177.75899999999999, 'yuv.min=', 16.597999999999999)
('yuv.max=', 245.24299999999999, 'yuv.min=', 1.325)
('yuv.max=', 234.03200000000001, 'yuv.min=', 23.576000000000001)
('yuv.max=', 190.38099999999997, 'yuv.min=', 35.803999999999995)
('yuv.max=', 176.23299999999998, 'yuv.min=', 11.968)
('yuv.max=', 248.131, 'yuv.min=', 24.0)
('yuv.max=', 234.82900000000001, 'yuv.min=', 19.227)
('yuv.max=', 225.28800000000001, 'yuv.min=', 14.842999999999998)
('yuv.max=', 254.245, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 254.77200000000002, 'yuv.min=', 10.058)
('yuv.max=', 254.41299999999995, 'yuv.min=', 52.032000000000004)
('yuv.max=', 255.0, 'yuv.min=', 27.492999999999995)
('yuv.max=', 242.86199999999997, 'yuv.min=', 10.609)
('yuv.max=', 238.46299999999997, 'yuv.min=', 18.287999999999997)
('yuv.max=', 219.70699999999999, 'yuv.min=', 9.1150000000000002)
('yuv.max=', 240.01099999999997, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 53.999999999999993)
('yuv.max=', 195.011, 'yuv.min=', 27.862999999999996)
('yuv.max=', 255.0, 'yuv.min=', 16.776)
('yuv.max=', 245.18099999999998, 'yuv.min=', 2.093)
('yuv.max=', 245.27599999999998, 'yuv.min=', 9.6559999999999988)
('yuv.max=', 215.63200000000001, 'yuv.min=', 15.283999999999999)
('yuv.max=', 238.58699999999999, 'yuv.min=', 42.721999999999994)
('yuv.max=', 236.43299999999999, 'yuv.min=', 22.162999999999997)
('yuv.max=', 255.0, 'yuv.min=', 19.715999999999998)
('yuv.max=', 253.21699999999998, 'yuv.min=', 30.085999999999999)
('yuv.max=', 247.47199999999995, 'yuv.min=', 45.615000000000002)
('yuv.max=', 255.0, 'yuv.min=', 77.999999999999986)
('yuv.max=', 250.99999999999997, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 247.48299999999995, 'yuv.min=', 6.1909999999999998)
('yuv.max=', 255.0, 'yuv.min=', 20.430000000000003)
('yuv.max=', 253.99999999999997, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 172.30500000000001, 'yuv.min=', 54.756)
('yuv.max=', 247.07500000000002, 'yuv.min=', 4.7329999999999997)
('yuv.max=', 238.761, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 248.929, 'yuv.min=', 4.956999999999999)
('yuv.max=', 201.05799999999999, 'yuv.min=', 21.417000000000002)
('yuv.max=', 251.66800000000001, 'yuv.min=', 14.929)
('yuv.max=', 243.66300000000001, 'yuv.min=', 1.254)
('yuv.max=', 253.10299999999998, 'yuv.min=', 10.434999999999999)
('yuv.max=', 202.18688, 'yuv.min=', 15.472999999999999)
('yuv.max=', 249.49499999999998, 'yuv.min=', 59.388000000000005)
('yuv.max=', 223.81799999999998, 'yuv.min=', 8.0990000000000002)
('yuv.max=', 255.0, 'yuv.min=', 61.646000000000001)
('yuv.max=', 206.64799999999997, 'yuv.min=', 0.114)
('yuv.max=', 234.57999999999998, 'yuv.min=', 11.420999999999999)
('yuv.max=', 253.54399999999998, 'yuv.min=', 21.641000000000002)
('yuv.max=', 214.84099999999998, 'yuv.min=', 65.079000000000008)
('yuv.max=', 192.976, 'yuv.min=', 12.223999999999998)
('yuv.max=', 254.54400000000001, 'yuv.min=', 16.544)
('yuv.max=', 233.05799999999999, 'yuv.min=', 2.0600000000000001)
('yuv.max=', 243.99999999999997, 'yuv.min=', 4.3589999999999991)
('yuv.max=', 254.10300000000001, 'yuv.min=', 2.9349999999999996)
('yuv.max=', 255.0, 'yuv.min=', 29.754999999999999)
('yuv.max=', 213.11700000000002, 'yuv.min=', 7.9499999999999993)
('yuv.max=', 204.40199999999999, 'yuv.min=', 9.113999999999999)
('yuv.max=', 255.0, 'yuv.min=', 28.081999999999997)
('yuv.max=', 241.21699999999998, 'yuv.min=', 29.154079999999997)
('yuv.max=', 204.50299999999999, 'yuv.min=', 41.118000000000002)
('yuv.max=', 229.607, 'yuv.min=', 37.758000000000003)
('yuv.max=', 253.0, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 254.41299999999995, 'yuv.min=', 13.936)
('yuv.max=', 241.92199999999997, 'yuv.min=', 20.539999999999999)
('yuv.max=', 226.0, 'yuv.min=', 56.999999999999993)
('yuv.max=', 254.40199999999999, 'yuv.min=', 12.654)
('yuv.max=', 254.886, 'yuv.min=', 13.402000000000001)
('yuv.max=', 222.15800000000002, 'yuv.min=', 20.387)
('yuv.max=', 229.65799999999996, 'yuv.min=', 39.722999999999999)
('yuv.max=', 215.0, 'yuv.min=', 47.331000000000003)
('yuv.max=', 184.804, 'yuv.min=', 12.869999999999999)
('yuv.max=', 248.02399999999997, 'yuv.min=', 18.590999999999998)
('yuv.max=', 203.785, 'yuv.min=', 19.003999999999998)
('yuv.max=', 252.97800000000001, 'yuv.min=', 4.4629999999999992)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 200.30099999999999, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 221.12699999999998, 'yuv.min=', 9.7720000000000002)
('yuv.max=', 220.071, 'yuv.min=', 21.405999999999999)
('yuv.max=', 253.80399999999997, 'yuv.min=', 0.0)
('yuv.max=', 247.95699999999999, 'yuv.min=', 5.7619999999999996)
('yuv.max=', 195.41, 'yuv.min=', 24.530999999999999)
('yuv.max=', 248.99999999999997, 'yuv.min=', 36.0)
('yuv.max=', 219.75, 'yuv.min=', 25.847000000000001)
('yuv.max=', 252.0, 'yuv.min=', 45.472999999999999)
('yuv.max=', 246.59799999999998, 'yuv.min=', 14.910999999999998)
('yuv.max=', 224.29499999999999, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 255.0, 'yuv.min=', 24.895999999999997)
('yuv.max=', 246.34799999999998, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 245.61500000000001, 'yuv.min=', 29.683)
('yuv.max=', 255.0, 'yuv.min=', 3.7229999999999999)
('yuv.max=', 221.82499999999999, 'yuv.min=', 40.847000000000001)
('yuv.max=', 224.35299999999995, 'yuv.min=', 18.585999999999999)
('yuv.max=', 231.011, 'yuv.min=', 55.888999999999996)
('yuv.max=', 182.46299999999999, 'yuv.min=', 27.939)
('yuv.max=', 235.667, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 199.77499999999998, 'yuv.min=', 19.645)
('yuv.max=', 201.61600000000001, 'yuv.min=', 34.717999999999996)
('yuv.max=', 216.477, 'yuv.min=', 3.3679999999999999)
('yuv.max=', 220.93799999999996, 'yuv.min=', 28.718999999999998)
('yuv.max=', 253.20599999999999, 'yuv.min=', 5.0800000000000001)
('yuv.max=', 250.10299999999998, 'yuv.min=', 14.112999999999998)
('yuv.max=', 252.90699999999998, 'yuv.min=', 7.5979999999999999)
('yuv.max=', 250.24899999999997, 'yuv.min=', 28.809999999999999)
('yuv.max=', 221.63399999999999, 'yuv.min=', 33.545999999999999)
('yuv.max=', 255.0, 'yuv.min=', 15.538)
('yuv.max=', 248.35900000000001, 'yuv.min=', 30.521000000000001)
('yuv.max=', 251.755, 'yuv.min=', 25.742999999999999)
('yuv.max=', 235.15700000000001, 'yuv.min=', 55.057999999999993)
('yuv.max=', 249.41299999999998, 'yuv.min=', 17.820999999999998)
('yuv.max=', 255.0, 'yuv.min=', 23.849999999999998)
('yuv.max=', 254.77200000000002, 'yuv.min=', 31.326999999999998)
('yuv.max=', 240.03499999999997, 'yuv.min=', 14.625999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 223.69499999999999, 'yuv.min=', 27.470999999999997)
('yuv.max=', 250.94599999999997, 'yuv.min=', 2.052)
('yuv.max=', 228.71599999999998, 'yuv.min=', 12.042999999999999)
('yuv.max=', 217.32599999999999, 'yuv.min=', 44.287000000000006)
('yuv.max=', 186.64699999999999, 'yuv.min=', 19.239999999999998)
('yuv.max=', 227.18799999999999, 'yuv.min=', 7.2059999999999995)
('yuv.max=', 213.374, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 245.69000000000003, 'yuv.min=', 19.483999999999998)
('yuv.max=', 219.85999999999999, 'yuv.min=', 12.821999999999999)
('yuv.max=', 213.58199999999999, 'yuv.min=', 14.534000000000001)
('yuv.max=', 218.25599999999997, 'yuv.min=', 16.126999999999999)
('yuv.max=', 245.376, 'yuv.min=', 53.453999999999994)
('yuv.max=', 251.381, 'yuv.min=', 24.902000000000001)
('yuv.max=', 254.43000000000001, 'yuv.min=', 14.923999999999999)
('yuv.max=', 254.40199999999999, 'yuv.min=', 6.9069999999999991)
('yuv.max=', 255.0, 'yuv.min=', 32.494999999999997)
('yuv.max=', 255.0, 'yuv.min=', 80.0)
('yuv.max=', 233.089, 'yuv.min=', 75.86999999999999)
('yuv.max=', 212.25799999999998, 'yuv.min=', 18.054000000000002)
('yuv.max=', 255.0, 'yuv.min=', 14.500999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 217.12200000000001, 'yuv.min=', 40.711999999999996)
('yuv.max=', 238.34, 'yuv.min=', 46.926999999999992)
('yuv.max=', 206.70299999999997, 'yuv.min=', 5.8149999999999995)
('yuv.max=', 253.35899999999998, 'yuv.min=', 15.831999999999999)
('yuv.max=', 219.96100000000001, 'yuv.min=', 3.456)
('yuv.max=', 221.15700000000001, 'yuv.min=', 9.4730000000000008)
('yuv.max=', 240.88999999999999, 'yuv.min=', 14.798)
('yuv.max=', 211.27099999999999, 'yuv.min=', 10.885999999999999)
('yuv.max=', 253.505, 'yuv.min=', 15.804)
('yuv.max=', 249.131, 'yuv.min=', 22.060000000000002)
('yuv.max=', 254.131, 'yuv.min=', 2.1659999999999999)
('yuv.max=', 198.650496, 'yuv.min=', 24.099)
('yuv.max=', 186.90100000000001, 'yuv.min=', 0.0)
('yuv.max=', 191.96599999999998, 'yuv.min=', 41.299000000000007)
('yuv.max=', 255.0, 'yuv.min=', 55.271000000000001)
('yuv.max=', 237.41300000000001, 'yuv.min=', 13.014999999999999)
('yuv.max=', 204.28799999999998, 'yuv.min=', 37.287999999999997)
('yuv.max=', 245.04300000000001, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 152.77199999999999, 'yuv.min=', 22.858000000000001)
('yuv.max=', 240.62099999999998, 'yuv.min=', 22.003999999999998)
('yuv.max=', 183.292, 'yuv.min=', 59.343999999999994)
('yuv.max=', 214.85400000000001, 'yuv.min=', 32.664000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 244.41499999999999, 'yuv.min=', 4.5270000000000001)
('yuv.max=', 252.42999999999998, 'yuv.min=', 15.631)
('yuv.max=', 179.23599999999999, 'yuv.min=', 8.1679999999999993)
('yuv.max=', 196.22499999999997, 'yuv.min=', 40.725999999999999)
('yuv.max=', 238.61399999999998, 'yuv.min=', 9.6579999999999995)
('yuv.max=', 252.47900000000001, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 237.03399999999999, 'yuv.min=', 11.945999999999998)
('yuv.max=', 221.64599999999999, 'yuv.min=', 43.876999999999995)
('yuv.max=', 231.15799999999999, 'yuv.min=', 7.5819999999999999)
('yuv.max=', 159.36000000000001, 'yuv.min=', 13.295)
('yuv.max=', 246.77600000000001, 'yuv.min=', 17.742000000000001)
('yuv.max=', 199.88499999999996, 'yuv.min=', 53.951999999999998)
('yuv.max=', 221.955072, 'yuv.min=', 14.577)
('yuv.max=', 200.357, 'yuv.min=', 10.113999999999999)
('yuv.max=', 255.0, 'yuv.min=', 81.167999999999992)
('yuv.max=', 249.04300000000001, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 183.499, 'yuv.min=', 28.429000000000002)
('yuv.max=', 197.43699999999998, 'yuv.min=', 10.65)
('yuv.max=', 244.732, 'yuv.min=', 1.482)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 248.34399999999999, 'yuv.min=', 1.51)
('yuv.max=', 211.56918400000001, 'yuv.min=', 4.4340000000000002)
('yuv.max=', 241.27799999999996, 'yuv.min=', 34.003)
('yuv.max=', 255.0, 'yuv.min=', 1.254)
('yuv.max=', 233.21099999999998, 'yuv.min=', 47.377999999999993)
('yuv.max=', 254.70099999999999, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 255.0, 'yuv.min=', 6.4730000000000008)
('yuv.max=', 209.24700000000001, 'yuv.min=', 56.807999999999993)
('yuv.max=', 171.16299999999998, 'yuv.min=', 24.108999999999998)
('yuv.max=', 250.34200000000001, 'yuv.min=', 31.300999999999998)
('yuv.max=', 241.702, 'yuv.min=', 78.421999999999997)
('yuv.max=', 218.10699999999997, 'yuv.min=', 39.427999999999997)
('yuv.max=', 204.61399999999998, 'yuv.min=', 69.320999999999998)
('yuv.max=', 228.67600000000002, 'yuv.min=', 24.968)
('yuv.max=', 210.40200000000002, 'yuv.min=', 1.9550000000000001)
('yuv.max=', 245.42299999999997, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 247.20700000000002, 'yuv.min=', 33.210999999999999)
('yuv.max=', 196.52999999999997, 'yuv.min=', 22.494999999999997)
('yuv.max=', 255.0, 'yuv.min=', 48.57)
('yuv.max=', 176.64899199999999, 'yuv.min=', 71.908999999999992)
('yuv.max=', 178.39599999999999, 'yuv.min=', 15.381)
('yuv.max=', 207.35899999999998, 'yuv.min=', 12.456)
('yuv.max=', 205.92899999999997, 'yuv.min=', 18.326999999999998)
('yuv.max=', 202.56399999999999, 'yuv.min=', 24.526999999999997)
('yuv.max=', 204.67099999999999, 'yuv.min=', 50.166999999999994)
('yuv.max=', 221.66399999999999, 'yuv.min=', 38.670999999999992)
('yuv.max=', 224.85999999999996, 'yuv.min=', 10.981375999999997)
('yuv.max=', 247.07300000000001, 'yuv.min=', 1.4949999999999999)
('yuv.max=', 214.75, 'yuv.min=', 3.5759999999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', 53.854999999999997)
('yuv.max=', 238.88899999999998, 'yuv.min=', 13.379999999999999)
('yuv.max=', 203.89699999999999, 'yuv.min=', 8.677999999999999)
('yuv.max=', 197.78799999999998, 'yuv.min=', 18.215)
('yuv.max=', 243.47299999999998, 'yuv.min=', 38.140000000000001)
('yuv.max=', 244.40099999999995, 'yuv.min=', 47.378)
('yuv.max=', 255.0, 'yuv.min=', 18.869)
('yuv.max=', 237.57499999999999, 'yuv.min=', 17.960999999999999)
('yuv.max=', 252.07099999999997, 'yuv.min=', 32.097000000000001)
('yuv.max=', 253.50099999999998, 'yuv.min=', 9.4190000000000005)
('yuv.max=', 206.14699999999999, 'yuv.min=', 24.734000000000002)
('yuv.max=', 241.59799999999996, 'yuv.min=', 17.982999999999997)
('yuv.max=', 255.0, 'yuv.min=', 17.776)
('yuv.max=', 251.27700000000002, 'yuv.min=', 39.87299999999999)
('yuv.max=', 235.20399999999998, 'yuv.min=', 30.998000000000001)
('yuv.max=', 234.37, 'yuv.min=', 33.256)
('yuv.max=', 220.20099999999999, 'yuv.min=', 21.120999999999999)
('yuv.max=', 177.14899199999999, 'yuv.min=', 1.897)
('yuv.max=', 206.86800000000002, 'yuv.min=', 33.936999999999998)
('yuv.max=', 219.68699999999998, 'yuv.min=', 22.614999999999998)
('yuv.max=', 249.125, 'yuv.min=', 63.314)
('yuv.max=', 255.0, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 254.316, 'yuv.min=', 9.4329999999999998)
('yuv.max=', 221.292, 'yuv.min=', 39.719000000000001)
('yuv.max=', 235.15300000000002, 'yuv.min=', 15.295999999999998)
('yuv.max=', 204.15799999999999, 'yuv.min=', 43.881999999999991)
('yuv.max=', 251.08799999999999, 'yuv.min=', 16.847000000000001)
('yuv.max=', 230.70599999999999, 'yuv.min=', 43.027999999999999)
('yuv.max=', 248.71199999999999, 'yuv.min=', 30.776)
('yuv.max=', 184.94799999999998, 'yuv.min=', 34.418999999999997)
('yuv.max=', 255.0, 'yuv.min=', 17.004999999999999)
('yuv.max=', 251.52700000000002, 'yuv.min=', 17.797999999999998)
('yuv.max=', 220.65199999999999, 'yuv.min=', 44.714000000000006)
('yuv.max=', 233.34999999999999, 'yuv.min=', 24.640000000000001)
('yuv.max=', 255.0, 'yuv.min=', 50.597999999999999)
('yuv.max=', 242.87099999999998, 'yuv.min=', 16.523)
('yuv.max=', 210.14099999999999, 'yuv.min=', 0.0)
('yuv.max=', 245.51999999999998, 'yuv.min=', 14.460999999999999)
('yuv.max=', 218.399, 'yuv.min=', 27.771999999999998)
('yuv.max=', 233.13399999999999, 'yuv.min=', 2.456)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 235.69799999999998, 'yuv.min=', 26.625)
('yuv.max=', 255.0, 'yuv.min=', 25.719000000000001)
('yuv.max=', 208.846, 'yuv.min=', 15.657999999999998)
('yuv.max=', 255.0, 'yuv.min=', 31.325999999999997)
('yuv.max=', 254.886, 'yuv.min=', 38.311999999999998)
('yuv.max=', 255.0, 'yuv.min=', 67.016999999999996)
('yuv.max=', 246.95700000000002, 'yuv.min=', 19.663999999999998)
('yuv.max=', 255.0, 'yuv.min=', 14.037999999999998)
('yuv.max=', 252.0, 'yuv.min=', 42.0)
('yuv.max=', 241.95099999999999, 'yuv.min=', 10.494999999999999)
('yuv.max=', 234.47199999999998, 'yuv.min=', 30.056999999999999)
('yuv.max=', 217.785, 'yuv.min=', 38.789000000000001)
('yuv.max=', 228.16699999999997, 'yuv.min=', 0.0)
('yuv.max=', 251.50099999999998, 'yuv.min=', 3.9119999999999999)
('yuv.max=', 253.11399999999998, 'yuv.min=', 13.359999999999999)
('yuv.max=', 247.846, 'yuv.min=', 42.969999999999999)
('yuv.max=', 255.0, 'yuv.min=', 10.039)
('yuv.max=', 233.005, 'yuv.min=', 29.309999999999999)
('yuv.max=', 228.27500000000001, 'yuv.min=', 28.353999999999999)
('yuv.max=', 172.96099999999998, 'yuv.min=', 27.331000000000003)
('yuv.max=', 233.59699999999998, 'yuv.min=', 44.497999999999998)
('yuv.max=', 246.28800000000001, 'yuv.min=', 18.698)
('yuv.max=', 246.19999999999999, 'yuv.min=', 41.994)
('yuv.max=', 189.232, 'yuv.min=', 25.255999999999997)
('yuv.max=', 255.0, 'yuv.min=', 22.849)
('yuv.max=', 223.417, 'yuv.min=', 31.675000000000001)
('yuv.max=', 240.36799999999999, 'yuv.min=', 5.9960000000000004)
('yuv.max=', 169.86599999999999, 'yuv.min=', 37.401999999999994)
('yuv.max=', 255.0, 'yuv.min=', 6.9830000000000005)
('yuv.max=', 238.095, 'yuv.min=', 4.9459999999999997)
('yuv.max=', 209.667, 'yuv.min=', 2.4129999999999998)
('yuv.max=', 254.65800000000002, 'yuv.min=', 28.281999999999996)
('yuv.max=', 215.13200000000001, 'yuv.min=', 4.0330000000000004)
('yuv.max=', 253.22799999999998, 'yuv.min=', 14.433)
('yuv.max=', 244.505, 'yuv.min=', 6.1959999999999997)
('yuv.max=', 252.608, 'yuv.min=', 7.8469999999999995)
('yuv.max=', 250.99999999999997, 'yuv.min=', 14.0)
('yuv.max=', 224.38999999999999, 'yuv.min=', 14.821)
('yuv.max=', 203.72399999999999, 'yuv.min=', 9.8149999999999995)
('yuv.max=', 209.71600000000001, 'yuv.min=', 47.984999999999999)
('yuv.max=', 220.642, 'yuv.min=', 24.201000000000001)
('yuv.max=', 250.02199999999999, 'yuv.min=', 32.329999999999998)
('yuv.max=', 255.0, 'yuv.min=', 2.052)
('yuv.max=', 239.38, 'yuv.min=', 55.581999999999994)
('yuv.max=', 240.071, 'yuv.min=', 26.462000000000003)
('yuv.max=', 249.857, 'yuv.min=', 19.771999999999998)
('yuv.max=', 233.25700000000001, 'yuv.min=', 33.756)
('yuv.max=', 245.04399999999998, 'yuv.min=', 35.537999999999997)
('yuv.max=', 255.0, 'yuv.min=', 90.853999999999999)
('yuv.max=', 245.90399999999997, 'yuv.min=', 22.107999999999997)
('yuv.max=', 249.696, 'yuv.min=', 0.0)
('yuv.max=', 164.114, 'yuv.min=', 58.421999999999997)
('yuv.max=', 249.87, 'yuv.min=', 60.316999999999993)
('yuv.max=', 253.52699999999999, 'yuv.min=', 51.869)
('yuv.max=', 213.005, 'yuv.min=', 20.928999999999998)
('yuv.max=', 255.0, 'yuv.min=', 61.325999999999993)
('yuv.max=', 162.52921599999999, 'yuv.min=', 36.134)
('yuv.max=', 255.0, 'yuv.min=', 12.960000000000001)
('yuv.max=', 240.58999999999997, 'yuv.min=', 14.722999999999999)
('yuv.max=', 232.22800000000001, 'yuv.min=', 35.455999999999996)
('yuv.max=', 247.12499999999997, 'yuv.min=', 16.387)
('yuv.max=', 255.0, 'yuv.min=', 1.228)
('yuv.max=', 242.797, 'yuv.min=', 5.3740000000000006)
('yuv.max=', 245.10299999999998, 'yuv.min=', 28.053999999999995)
('yuv.max=', 249.56099999999998, 'yuv.min=', 4.1139999999999999)
('yuv.max=', 248.66900000000001, 'yuv.min=', 1.7719999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 216.74000000000001, 'yuv.min=', 17.046999999999997)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 238.0, 'yuv.min=', 44.064)
('yuv.max=', 248.22800000000001, 'yuv.min=', 41.977999999999994)
('yuv.max=', 226.22799999999998, 'yuv.min=', 23.178999999999998)
('yuv.max=', 240.95699999999999, 'yuv.min=', 33.561)
('yuv.max=', 255.0, 'yuv.min=', 31.747999999999998)
('yuv.max=', 224.04300000000001, 'yuv.min=', 34.319999999999993)
('yuv.max=', 254.28799999999998, 'yuv.min=', 23.668999999999997)
('yuv.max=', 250.99999999999997, 'yuv.min=', 61.308999999999997)
('yuv.max=', 243.322, 'yuv.min=', 7.6039999999999992)
('yuv.max=', 249.70099999999999, 'yuv.min=', 6.1139999999999999)
('yuv.max=', 186.43099999999998, 'yuv.min=', 22.874999999999996)
('yuv.max=', 239.57599999999999, 'yuv.min=', 52.712000000000003)
('yuv.max=', 222.51599999999996, 'yuv.min=', 22.815000000000001)
('yuv.max=', 254.40199999999999, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 248.98299999999998, 'yuv.min=', 33.248000000000005)
('yuv.max=', 239.79399999999998, 'yuv.min=', 17.042999999999999)
('yuv.max=', 250.0, 'yuv.min=', 46.847000000000001)
('yuv.max=', 248.93899999999996, 'yuv.min=', 24.812000000000001)
('yuv.max=', 238.125, 'yuv.min=', 43.007327999999994)
('yuv.max=', 181.68000000000001, 'yuv.min=', 28.349999999999998)
('yuv.max=', 176.47200000000001, 'yuv.min=', 31.917999999999999)
('yuv.max=', 239.00999999999999, 'yuv.min=', 9.8259999999999987)
('yuv.max=', 255.0, 'yuv.min=', 25.621999999999996)
('yuv.max=', 187.48646400000001, 'yuv.min=', 30.103999999999996)
('yuv.max=', 209.04899999999998, 'yuv.min=', 7.9290000000000003)
('yuv.max=', 253.29900000000001, 'yuv.min=', 0.114)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 251.58699999999996, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 253.77199999999999, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 250.08099999999996, 'yuv.min=', 57.556999999999995)
('yuv.max=', 253.21699999999998, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 252.34199999999998, 'yuv.min=', 23.354999999999997)
('yuv.max=', 254.18499999999997, 'yuv.min=', 2.7609999999999997)
('yuv.max=', 210.081312, 'yuv.min=', 35.490000000000002)
('yuv.max=', 228.54600000000002, 'yuv.min=', 1.766)
('yuv.max=', 235.77999999999997, 'yuv.min=', 5.8209999999999997)
('yuv.max=', 253.46199999999999, 'yuv.min=', 14.864999999999998)
('yuv.max=', 255.0, 'yuv.min=', 6.8899999999999997)
('yuv.max=', 216.971, 'yuv.min=', 24.363)
('yuv.max=', 252.70699999999999, 'yuv.min=', 18.314999999999998)
('yuv.max=', 175.55399999999997, 'yuv.min=', 1.5980000000000001)
('yuv.max=', 201.089, 'yuv.min=', 46.540999999999997)
('yuv.max=', 227.899, 'yuv.min=', 9.6729999999999983)
('yuv.max=', 243.988, 'yuv.min=', 59.334000000000003)
('yuv.max=', 239.15899999999999, 'yuv.min=', 31.056000000000001)
('yuv.max=', 255.0, 'yuv.min=', 8.6950000000000003)
('yuv.max=', 226.899, 'yuv.min=', 32.786999999999999)
('yuv.max=', 172.11600000000001, 'yuv.min=', 22.852999999999998)
('yuv.max=', 255.0, 'yuv.min=', 19.489999999999998)
('yuv.max=', 251.626, 'yuv.min=', 8.620000000000001)
('yuv.max=', 253.80399999999997, 'yuv.min=', 5.1319999999999997)
('yuv.max=', 245.00699999999998, 'yuv.min=', 27.477999999999998)
('yuv.max=', 255.0, 'yuv.min=', 2.641)
('yuv.max=', 245.77199999999999, 'yuv.min=', 34.363)
('yuv.max=', 203.12200000000001, 'yuv.min=', 29.865999999999996)
('yuv.max=', 255.0, 'yuv.min=', 23.538999999999998)
('yuv.max=', 249.43000000000001, 'yuv.min=', 26.270999999999997)
('yuv.max=', 224.0, 'yuv.min=', 20.609999999999996)
('yuv.max=', 228.52199999999996, 'yuv.min=', 30.405000000000001)
('yuv.max=', 243.42999999999998, 'yuv.min=', 67.076999999999998)
('yuv.max=', 252.0, 'yuv.min=', 3.8929999999999998)
('yuv.max=', 253.14199999999997, 'yuv.min=', 13.185)
('yuv.max=', 176.74799999999999, 'yuv.min=', 14.037999999999998)
('yuv.max=', 255.0, 'yuv.min=', 33.298999999999999)
('yuv.max=', 255.0, 'yuv.min=', 59.822000000000003)
('yuv.max=', 255.0, 'yuv.min=', 19.583000000000002)
('yuv.max=', 255.0, 'yuv.min=', 47.189)
('yuv.max=', 245.59699999999998, 'yuv.min=', 36.105999999999995)
('yuv.max=', 183.54233600000001, 'yuv.min=', 16.428000000000001)
('yuv.max=', 223.07499999999999, 'yuv.min=', 31.048000000000002)
('yuv.max=', 254.65800000000002, 'yuv.min=', 22.018999999999998)
('yuv.max=', 231.54999999999998, 'yuv.min=', 3.9399999999999999)
('yuv.max=', 229.87299999999996, 'yuv.min=', 8.254999999999999)
('yuv.max=', 247.172, 'yuv.min=', 32.711999999999996)
('yuv.max=', 254.35900000000001, 'yuv.min=', 31.369)
('yuv.max=', 246.98500000000001, 'yuv.min=', 22.427999999999997)
('yuv.max=', 250.51499999999999, 'yuv.min=', 18.350999999999999)
('yuv.max=', 244.065, 'yuv.min=', 56.045999999999992)
('yuv.max=', 168.83699999999999, 'yuv.min=', 14.334999999999999)
('yuv.max=', 248.422, 'yuv.min=', 26.015000000000001)
('yuv.max=', 255.0, 'yuv.min=', 39.689999999999998)
('yuv.max=', 221.21899999999999, 'yuv.min=', 55.833999999999996)
('yuv.max=', 232.0, 'yuv.min=', 23.869)
('yuv.max=', 253.52699999999999, 'yuv.min=', 48.930000000000007)
('yuv.max=', 245.93799999999999, 'yuv.min=', 39.017999999999994)
('yuv.max=', 239.44499999999999, 'yuv.min=', 2.5699999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.52700000000000002)
('yuv.max=', 240.79499999999996, 'yuv.min=', 13.575999999999999)
('yuv.max=', 251.10299999999998, 'yuv.min=', 0.114)
('yuv.max=', 246.11299999999997, 'yuv.min=', 9.0760000000000005)
('yuv.max=', 255.0, 'yuv.min=', 52.402000000000001)
('yuv.max=', 209.886, 'yuv.min=', 4.3919999999999995)
('yuv.max=', 217.34399999999999, 'yuv.min=', 10.361000000000001)
('yuv.max=', 255.0, 'yuv.min=', 4.7759999999999998)
('yuv.max=', 238.53100000000001, 'yuv.min=', 60.892999999999994)
('yuv.max=', 244.58700000000002, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 252.761, 'yuv.min=', 13.256)
('yuv.max=', 234.80199999999999, 'yuv.min=', 11.634)
('yuv.max=', 239.096, 'yuv.min=', 42.140000000000001)
('yuv.max=', 220.82883200000001, 'yuv.min=', 13.869)
('yuv.max=', 235.87099999999995, 'yuv.min=', 73.702999999999989)
('yuv.max=', 246.869, 'yuv.min=', 54.481999999999999)
('yuv.max=', 237.899, 'yuv.min=', 8.1679999999999993)
('yuv.max=', 254.41299999999995, 'yuv.min=', 10.157)
('yuv.max=', 236.291, 'yuv.min=', 15.635999999999999)
('yuv.max=', 253.81499999999997, 'yuv.min=', 21.033000000000001)
('yuv.max=', 255.0, 'yuv.min=', 7.032)
('yuv.max=', 194.16399999999999, 'yuv.min=', 13.731999999999999)
('yuv.max=', 241.39299999999997, 'yuv.min=', 55.820999999999998)
('yuv.max=', 251.71100000000001, 'yuv.min=', 19.573999999999998)
('yuv.max=', 194.90575999999999, 'yuv.min=', 13.584999999999999)
('yuv.max=', 226.583, 'yuv.min=', 50.911999999999999)
('yuv.max=', 229.245, 'yuv.min=', 9.0)
('yuv.max=', 175.99999999999997, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 45.862000000000002)
('yuv.max=', 253.63200000000001, 'yuv.min=', 8.0709999999999997)
('yuv.max=', 220.40899999999999, 'yuv.min=', 10.456999999999999)
('yuv.max=', 238.34199999999998, 'yuv.min=', 82.052999999999997)
('yuv.max=', 227.75899999999999, 'yuv.min=', 51.670999999999999)
('yuv.max=', 232.40000000000001, 'yuv.min=', 34.863999999999997)
('yuv.max=', 228.30999999999997, 'yuv.min=', 16.488)
('yuv.max=', 227.99299999999999, 'yuv.min=', 27.510999999999999)
('yuv.max=', 252.114, 'yuv.min=', 0.0)
('yuv.max=', 235.142, 'yuv.min=', 8.3810000000000002)
('yuv.max=', 214.09500000000003, 'yuv.min=', 34.933999999999997)
('yuv.max=', 214.97800000000001, 'yuv.min=', 12.554)
('yuv.max=', 232.0, 'yuv.min=', 62.0)
('yuv.max=', 216.65199999999999, 'yuv.min=', 38.272999999999996)
('yuv.max=', 236.27800000000002, 'yuv.min=', 44.683999999999997)
('yuv.max=', 193.80999999999997, 'yuv.min=', 5.3419999999999996)
('yuv.max=', 223.83799999999999, 'yuv.min=', 82.958999999999989)
('yuv.max=', 229.00399999999999, 'yuv.min=', 0.0)
('yuv.max=', 238.97899999999998, 'yuv.min=', 23.581)
('yuv.max=', 225.285, 'yuv.min=', 0.0)
('yuv.max=', 247.19999999999999, 'yuv.min=', 4.2279999999999998)
('yuv.max=', 255.0, 'yuv.min=', 42.812999999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 244.70100000000002, 'yuv.min=', 25.519999999999996)
('yuv.max=', 251.755, 'yuv.min=', 0.45600000000000002)
('yuv.max=', 171.66, 'yuv.min=', 23.594999999999999)
('yuv.max=', 255.0, 'yuv.min=', 3.968)
('yuv.max=', 249.03899999999999, 'yuv.min=', 44.603999999999999)
('yuv.max=', 237.56899999999999, 'yuv.min=', 74.112999999999985)
('yuv.max=', 253.02799999999996, 'yuv.min=', 14.208)
('yuv.max=', 238.36599999999999, 'yuv.min=', 41.372)
('yuv.max=', 251.62099999999998, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 254.43000000000001, 'yuv.min=', 3.8319999999999999)
('yuv.max=', 238.99999999999997, 'yuv.min=', 19.0)
('yuv.max=', 251.381, 'yuv.min=', 25.747999999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', 7.524)
('yuv.max=', 228.96699999999998, 'yuv.min=', 16.134)
('yuv.max=', 255.0, 'yuv.min=', 15.668999999999999)
('yuv.max=', 211.25200000000001, 'yuv.min=', 24.623999999999999)
('yuv.max=', 234.815, 'yuv.min=', 39.954999999999998)
('yuv.max=', 254.10300000000001, 'yuv.min=', 45.753999999999991)
('yuv.max=', 246.49399999999997, 'yuv.min=', 2.359)
('yuv.max=', 244.03199999999998, 'yuv.min=', 11.358999999999998)
('yuv.max=', 208.22699999999998, 'yuv.min=', 17.042999999999999)
('yuv.max=', 233.52499999999998, 'yuv.min=', 13.498999999999999)
('yuv.max=', 254.11399999999998, 'yuv.min=', 16.609000000000002)
('yuv.max=', 233.72899999999998, 'yuv.min=', 24.070999999999998)
('yuv.max=', 255.0, 'yuv.min=', 19.509999999999998)
('yuv.max=', 248.86000000000001, 'yuv.min=', 36.244999999999997)
('yuv.max=', 255.0, 'yuv.min=', 50.925000000000004)
('yuv.max=', 207.29999999999998, 'yuv.min=', 4.6630000000000003)
('yuv.max=', 249.11799999999999, 'yuv.min=', 60.18099999999999)
('yuv.max=', 244.29499999999999, 'yuv.min=', 0.70099999999999996)
('yuv.max=', 250.99999999999997, 'yuv.min=', 14.26)
('yuv.max=', 255.0, 'yuv.min=', 12.364000000000001)
('yuv.max=', 255.0, 'yuv.min=', 46.085999999999999)
('yuv.max=', 197.761, 'yuv.min=', 12.798)
('yuv.max=', 194.94899999999998, 'yuv.min=', 33.689999999999998)
('yuv.max=', 255.0, 'yuv.min=', 65.611000000000004)
('yuv.max=', 181.90699999999998, 'yuv.min=', 57.749999999999993)
('yuv.max=', 250.51499999999999, 'yuv.min=', 69.793999999999997)
('yuv.max=', 247.35799999999998, 'yuv.min=', 17.102)
('yuv.max=', 227.0, 'yuv.min=', 35.0)
('yuv.max=', 244.52599999999998, 'yuv.min=', 1.5960000000000001)
('yuv.max=', 255.0, 'yuv.min=', 44.985999999999997)
('yuv.max=', 255.0, 'yuv.min=', 28.427)
('yuv.max=', 223.596, 'yuv.min=', 59.647999999999989)
('yuv.max=', 228.755, 'yuv.min=', 21.535999999999998)
('yuv.max=', 168.20599999999999, 'yuv.min=', 15.146000000000001)
('yuv.max=', 218.27500000000001, 'yuv.min=', 34.879999999999995)
('yuv.max=', 212.48399999999998, 'yuv.min=', 29.075000000000003)
('yuv.max=', 253.11999999999998, 'yuv.min=', 0.0)
('yuv.max=', 248.08000000000001, 'yuv.min=', 38.262999999999998)
('yuv.max=', 222.678336, 'yuv.min=', 1.4990000000000001)
('yuv.max=', 208.69299999999998, 'yuv.min=', 22.245000000000001)
('yuv.max=', 241.45599999999999, 'yuv.min=', 7.7509999999999994)
('yuv.max=', 252.70099999999999, 'yuv.min=', 21.555)
('yuv.max=', 144.83000000000001, 'yuv.min=', 18.886999999999997)
('yuv.max=', 255.0, 'yuv.min=', 25.023)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 242.52200000000002, 'yuv.min=', 18.113999999999997)
('yuv.max=', 235.25599999999997, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 240.99999999999997, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 252.114, 'yuv.min=', 9.743999999999998)
('yuv.max=', 246.42999999999998, 'yuv.min=', 36.717999999999996)
('yuv.max=', 230.72999999999999, 'yuv.min=', 11.305999999999999)
('yuv.max=', 226.0, 'yuv.min=', 27.683999999999997)
('yuv.max=', 239.10699999999997, 'yuv.min=', 52.296031999999997)
('yuv.max=', 229.887, 'yuv.min=', 8.6579999999999995)
('yuv.max=', 217.35199999999998, 'yuv.min=', 28.483999999999998)
('yuv.max=', 255.0, 'yuv.min=', 78.227999999999994)
('yuv.max=', 241.47300000000001, 'yuv.min=', 10.849)
('yuv.max=', 251.48300000000003, 'yuv.min=', 3.2669999999999999)
('yuv.max=', 205.89999999999998, 'yuv.min=', 17.937999999999999)
('yuv.max=', 249.20699999999999, 'yuv.min=', 36.526999999999994)
('yuv.max=', 255.0, 'yuv.min=', 2.1659999999999999)
('yuv.max=', 255.0, 'yuv.min=', 22.472999999999999)
('yuv.max=', 216.04999999999998, 'yuv.min=', 0.0)
('yuv.max=', 248.36599999999999, 'yuv.min=', 114.619072)
('yuv.max=', 212.91499999999999, 'yuv.min=', 0.0)
('yuv.max=', 227.95865599999999, 'yuv.min=', 9.9849999999999994)
('yuv.max=', 255.0, 'yuv.min=', 2.5870000000000002)
('yuv.max=', 208.905, 'yuv.min=', 89.156999999999996)
('yuv.max=', 227.21499999999997, 'yuv.min=', 13.684999999999999)
('yuv.max=', 250.08099999999999, 'yuv.min=', 10.587999999999999)
('yuv.max=', 247.61899999999997, 'yuv.min=', 52.593999999999994)
('yuv.max=', 225.11199999999999, 'yuv.min=', 7.9720000000000004)
('yuv.max=', 231.31899999999999, 'yuv.min=', 48.564)
('yuv.max=', 255.0, 'yuv.min=', 29.540999999999997)
('yuv.max=', 224.72199999999998, 'yuv.min=', 11.036999999999999)
('yuv.max=', 252.22799999999998, 'yuv.min=', 20.298999999999999)
('yuv.max=', 217.78899999999999, 'yuv.min=', 48.488999999999997)
('yuv.max=', 251.59799999999998, 'yuv.min=', 25.560999999999996)
('yuv.max=', 234.09899999999999, 'yuv.min=', 11.590999999999999)
('yuv.max=', 250.28799999999998, 'yuv.min=', 0.59799999999999998)
('yuv.max=', 230.39400000000001, 'yuv.min=', 28.165999999999997)
('yuv.max=', 243.0, 'yuv.min=', 25.999999999999996)
('yuv.max=', 254.65800000000002, 'yuv.min=', 1.6950000000000001)
('yuv.max=', 249.505, 'yuv.min=', 10.223999999999998)
('yuv.max=', 207.62799999999999, 'yuv.min=', 10.911)
('yuv.max=', 196.58699999999999, 'yuv.min=', 27.238999999999997)
('yuv.max=', 251.41199999999998, 'yuv.min=', 20.353999999999999)
('yuv.max=', 211.28799999999998, 'yuv.min=', 32.781999999999996)
('yuv.max=', 219.756, 'yuv.min=', 0.0)
('yuv.max=', 246.77699999999999, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 236.83199999999999, 'yuv.min=', 58.713999999999999)
('yuv.max=', 226.97800000000001, 'yuv.min=', 27.956)
('yuv.max=', 249.17399999999998, 'yuv.min=', 32.792999999999999)
('yuv.max=', 190.90999999999997, 'yuv.min=', 78.933999999999997)
('yuv.max=', 237.61600000000001, 'yuv.min=', 15.015999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', 0.0)
('yuv.max=', 254.40199999999999, 'yuv.min=', 29.238)
('yuv.max=', 248.262, 'yuv.min=', 31.731999999999999)
('yuv.max=', 223.83699999999999, 'yuv.min=', 9.9599999999999991)
('yuv.max=', 248.809, 'yuv.min=', 16.727)
('yuv.max=', 255.0, 'yuv.min=', 56.545999999999999)
('yuv.max=', 254.65800000000002, 'yuv.min=', 4.1289999999999996)
('yuv.max=', 218.71199999999999, 'yuv.min=', 47.125999999999998)
('yuv.max=', 237.96299999999997, 'yuv.min=', 3.6560000000000001)
('yuv.max=', 255.0, 'yuv.min=', 15.185999999999998)
('yuv.max=', 221.49799999999999, 'yuv.min=', 37.762)
('yuv.max=', 237.267, 'yuv.min=', 44.951000000000008)
('yuv.max=', 212.70699999999999, 'yuv.min=', 0.0)
('yuv.max=', 254.70099999999999, 'yuv.min=', 27.390999999999998)
('yuv.max=', 198.989, 'yuv.min=', 35.704999999999998)
('yuv.max=', 198.81312, 'yuv.min=', 29.731999999999999)
('yuv.max=', 252.42999999999998, 'yuv.min=', 4.4409999999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', 27.923000000000002)
('yuv.max=', 255.0, 'yuv.min=', 3.8369999999999997)
('yuv.max=', 214.0, 'yuv.min=', 6.0)
('yuv.max=', 164.61174399999999, 'yuv.min=', 25.416999999999998)
('yuv.max=', 217.87200000000001, 'yuv.min=', 11.038)
('yuv.max=', 237.715, 'yuv.min=', 29.015000000000001)
('yuv.max=', 149.59099999999998, 'yuv.min=', 26.244999999999997)
('yuv.max=', 232.071, 'yuv.min=', 50.107999999999997)
('yuv.max=', 254.07099999999997, 'yuv.min=', 25.629999999999999)
('yuv.max=', 255.0, 'yuv.min=', 26.193999999999999)
('yuv.max=', 227.27099999999999, 'yuv.min=', 3.6240000000000001)
('yuv.max=', 243.66800000000001, 'yuv.min=', 6.625)
('yuv.max=', 234.25, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 43.179000000000002)
('yuv.max=', 194.23676800000001, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 202.21299999999999, 'yuv.min=', 33.244)
('yuv.max=', 206.11799999999999, 'yuv.min=', 10.798)
('yuv.max=', 221.31999999999999, 'yuv.min=', 42.458999999999996)
('yuv.max=', 234.88799999999998, 'yuv.min=', 44.911000000000001)
('yuv.max=', 229.44899999999996, 'yuv.min=', 10.324999999999999)
('yuv.max=', 209.161, 'yuv.min=', 28.721999999999998)
('yuv.max=', 252.45799999999997, 'yuv.min=', 47.561999999999998)
('yuv.max=', 251.02199999999996, 'yuv.min=', 29.509999999999998)
('yuv.max=', 227.91399999999999, 'yuv.min=', 10.257999999999999)
('yuv.max=', 246.58399999999997, 'yuv.min=', 15.097999999999997)
('yuv.max=', 232.09799999999998, 'yuv.min=', 33.510999999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', 66.661000000000001)
('yuv.max=', 238.0, 'yuv.min=', 70.0)
('yuv.max=', 247.63, 'yuv.min=', 7.8879999999999999)
('yuv.max=', 249.18499999999997, 'yuv.min=', 0.114)
('yuv.max=', 225.285, 'yuv.min=', 47.966999999999999)
('yuv.max=', 247.499, 'yuv.min=', 15.332999999999998)
('yuv.max=', 238.0, 'yuv.min=', 6.7309999999999999)
('yuv.max=', 183.286, 'yuv.min=', 2.3919999999999999)
('yuv.max=', 228.80599999999998, 'yuv.min=', 12.999999999999998)
('yuv.max=', 255.0, 'yuv.min=', 51.412999999999997)
('yuv.max=', 249.52699999999999, 'yuv.min=', 18.335999999999999)
('yuv.max=', 255.0, 'yuv.min=', 47.844999999999999)
('yuv.max=', 203.94999999999999, 'yuv.min=', 42.399000000000001)
('yuv.max=', 240.62599999999998, 'yuv.min=', 32.783000000000001)
('yuv.max=', 251.71199999999999, 'yuv.min=', 13.035)
('yuv.max=', 233.73399999999998, 'yuv.min=', 11.989000000000001)
('yuv.max=', 223.71199999999999, 'yuv.min=', 27.122999999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', 23.370999999999999)
('yuv.max=', 231.0, 'yuv.min=', 15.999999999999998)
('yuv.max=', 200.30799999999999, 'yuv.min=', 29.524999999999999)
('yuv.max=', 254.06, 'yuv.min=', 37.068999999999996)
('yuv.max=', 196.81799999999998, 'yuv.min=', 8.3439999999999994)
('yuv.max=', 255.0, 'yuv.min=', 5.0389999999999997)
('yuv.max=', 255.0, 'yuv.min=', 28.058)
('yuv.max=', 192.976, 'yuv.min=', 48.346999999999994)
('yuv.max=', 244.05999999999997, 'yuv.min=', 14.521999999999998)
('yuv.max=', 166.86500000000001, 'yuv.min=', 58.891999999999996)
('yuv.max=', 254.77200000000002, 'yuv.min=', 25.625999999999998)
('yuv.max=', 233.54300000000001, 'yuv.min=', 7.7619999999999996)
('yuv.max=', 235.52099999999999, 'yuv.min=', 60.025999999999996)
('yuv.max=', 255.0, 'yuv.min=', 21.102999999999998)
('yuv.max=', 253.81499999999997, 'yuv.min=', 32.945999999999998)
('yuv.max=', 248.37399999999997, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 251.64299999999997, 'yuv.min=', 20.640999999999998)
('yuv.max=', 236.29899999999998, 'yuv.min=', 7.2110000000000003)
('yuv.max=', 179.59699999999998, 'yuv.min=', 49.697999999999993)
('yuv.max=', 204.91999999999999, 'yuv.min=', 24.209999999999997)
('yuv.max=', 241.85600000000002, 'yuv.min=', 70.807000000000002)
('yuv.max=', 236.30199999999999, 'yuv.min=', 88.774999999999991)
('yuv.max=', 226.81499999999997, 'yuv.min=', 59.722999999999999)
('yuv.max=', 210.55500000000001, 'yuv.min=', 21.010999999999996)
('yuv.max=', 243.09, 'yuv.min=', 24.489999999999998)
('yuv.max=', 251.21299999999999, 'yuv.min=', 28.879999999999999)
('yuv.max=', 250.08099999999999, 'yuv.min=', 9.048)
('yuv.max=', 197.86199999999997, 'yuv.min=', 5.5380000000000003)
('yuv.max=', 222.97199999999995, 'yuv.min=', 32.512999999999998)
('yuv.max=', 243.733, 'yuv.min=', 15.640999999999998)
('yuv.max=', 225.39199999999997, 'yuv.min=', 7.2670000000000003)
('yuv.max=', 254.65800000000002, 'yuv.min=', 19.636999999999997)
('yuv.max=', 218.233, 'yuv.min=', 63.011999999999993)
('yuv.max=', 236.64099999999999, 'yuv.min=', 10.69)
('yuv.max=', 253.989, 'yuv.min=', 71.23539199999999)
('yuv.max=', 252.63, 'yuv.min=', 7.8689999999999998)
('yuv.max=', 178.774272, 'yuv.min=', 75.528999999999996)
('yuv.max=', 250.66299999999998, 'yuv.min=', 31.085999999999999)
('yuv.max=', 254.245, 'yuv.min=', 17.957000000000001)
('yuv.max=', 212.249, 'yuv.min=', 4.3419999999999996)
('yuv.max=', 246.15699999999998, 'yuv.min=', 25.491999999999997)
('yuv.max=', 252.679, 'yuv.min=', 15.506)
('yuv.max=', 203.73099999999999, 'yuv.min=', 29.451000000000001)
('yuv.max=', 209.88800000000001, 'yuv.min=', 22.335999999999999)
('yuv.max=', 225.16999999999999, 'yuv.min=', 14.526999999999999)
('yuv.max=', 219.61699999999999, 'yuv.min=', 34.734999999999999)
('yuv.max=', 243.05999999999997, 'yuv.min=', 34.346000000000004)
('yuv.max=', 209.97199999999998, 'yuv.min=', 74.171999999999997)
('yuv.max=', 212.28599999999997, 'yuv.min=', 24.719999999999999)
('yuv.max=', 191.36299999999997, 'yuv.min=', 50.976287999999997)
('yuv.max=', 255.0, 'yuv.min=', 22.087999999999997)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 224.72399999999999, 'yuv.min=', 15.279)
('yuv.max=', 224.69999999999999, 'yuv.min=', 10.662999999999998)
('yuv.max=', 254.40199999999999, 'yuv.min=', 19.986000000000001)
('yuv.max=', 176.43299999999999, 'yuv.min=', 50.384999999999998)
('yuv.max=', 252.0, 'yuv.min=', 16.32)
('yuv.max=', 239.51599999999996, 'yuv.min=', 62.983999999999995)
('yuv.max=', 253.99999999999997, 'yuv.min=', 1.609)
('yuv.max=', 255.0, 'yuv.min=', 5.1859999999999991)
('yuv.max=', 245.56999999999999, 'yuv.min=', 15.180999999999999)
('yuv.max=', 237.24899999999997, 'yuv.min=', 6.3809999999999993)
('yuv.max=', 178.43680000000001, 'yuv.min=', 30.57)
('yuv.max=', 238.83099999999999, 'yuv.min=', 9.391)
('yuv.max=', 208.93081599999999, 'yuv.min=', 23.028000000000002)
('yuv.max=', 199.0, 'yuv.min=', 5.0)
('yuv.max=', 247.41200000000001, 'yuv.min=', 8.3829999999999991)
('yuv.max=', 238.81899999999999, 'yuv.min=', 3.331)
('yuv.max=', 255.0, 'yuv.min=', 14.456)
('yuv.max=', 190.86099999999999, 'yuv.min=', 5.9569999999999999)
('yuv.max=', 239.76999999999998, 'yuv.min=', 36.091000000000001)
('yuv.max=', 196.25, 'yuv.min=', 0.0)
('yuv.max=', 238.25200000000001, 'yuv.min=', 9.407)
('yuv.max=', 210.27799999999996, 'yuv.min=', 42.164999999999999)
('yuv.max=', 240.684, 'yuv.min=', 6.0969999999999995)
('yuv.max=', 231.67599999999999, 'yuv.min=', 51.690999999999995)
('yuv.max=', 234.078, 'yuv.min=', 28.353999999999999)
('yuv.max=', 227.01699999999997, 'yuv.min=', 7.641)
('yuv.max=', 197.34399999999999, 'yuv.min=', 47.030000000000001)
('yuv.max=', 220.51400000000001, 'yuv.min=', 12.327)
('yuv.max=', 253.42999999999998, 'yuv.min=', 32.417000000000002)
('yuv.max=', 213.328, 'yuv.min=', 5.8800000000000008)
('yuv.max=', 242.70099999999999, 'yuv.min=', 21.224)
('yuv.max=', 253.23899999999998, 'yuv.min=', 2.5640000000000001)
('yuv.max=', 208.214, 'yuv.min=', 41.826000000000001)
('yuv.max=', 229.68999999999997, 'yuv.min=', 50.646999999999998)
('yuv.max=', 247.52700000000002, 'yuv.min=', 31.409999999999997)
('yuv.max=', 237.857, 'yuv.min=', 36.059999999999995)
('yuv.max=', 254.77200000000002, 'yuv.min=', 0.114)
('yuv.max=', 241.18899999999999, 'yuv.min=', 52.384999999999998)
('yuv.max=', 248.10299999999998, 'yuv.min=', 34.551000000000002)
('yuv.max=', 253.0, 'yuv.min=', 21.0)
('yuv.max=', 236.34099999999998, 'yuv.min=', 49.721999999999994)
('yuv.max=', 245.24200000000002, 'yuv.min=', 14.833)
('yuv.max=', 205.89599999999999, 'yuv.min=', 6.4569999999999999)
('yuv.max=', 218.68199999999999, 'yuv.min=', 59.594999999999999)
('yuv.max=', 187.46784000000002, 'yuv.min=', 29.550783999999993)
('yuv.max=', 189.634784, 'yuv.min=', 29.504999999999999)
('yuv.max=', 251.24499999999995, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 192.488, 'yuv.min=', 9.4890000000000008)
('yuv.max=', 210.71499999999997, 'yuv.min=', 28.548000000000002)
('yuv.max=', 240.10499999999999, 'yuv.min=', 51.680999999999997)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 245.548, 'yuv.min=', 5.5809999999999995)
('yuv.max=', 251.45599999999996, 'yuv.min=', 8.0599999999999987)
('yuv.max=', 242.79299999999998, 'yuv.min=', 70.558999999999997)
('yuv.max=', 252.08799999999999, 'yuv.min=', 10.872999999999999)
('yuv.max=', 241.792, 'yuv.min=', 8.0640000000000001)
('yuv.max=', 193.34300000000002, 'yuv.min=', 49.799999999999997)
('yuv.max=', 234.89599999999999, 'yuv.min=', 39.655000000000001)
('yuv.max=', 199.918688, 'yuv.min=', 31.874000000000002)
('yuv.max=', 247.0, 'yuv.min=', 60.999999999999993)
('yuv.max=', 244.559, 'yuv.min=', 7.0)
('yuv.max=', 246.011, 'yuv.min=', 36.491999999999997)
('yuv.max=', 253.81499999999997, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 232.76599999999996, 'yuv.min=', 69.131)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 254.886, 'yuv.min=', 26.096999999999998)
('yuv.max=', 255.0, 'yuv.min=', 42.771999999999998)
('yuv.max=', 239.54599999999999, 'yuv.min=', 25.543999999999997)
('yuv.max=', 245.60799999999998, 'yuv.min=', 33.635999999999996)
('yuv.max=', 243.74399999999997, 'yuv.min=', 8.6080000000000005)
('yuv.max=', 231.71899999999999, 'yuv.min=', 8.2989999999999995)
('yuv.max=', 182.97800000000001, 'yuv.min=', 57.560000000000002)
('yuv.max=', 255.0, 'yuv.min=', 26.995999999999999)
('yuv.max=', 253.20599999999999, 'yuv.min=', 60.415000000000006)
('yuv.max=', 238.47899999999998, 'yuv.min=', 15.206)
('yuv.max=', 227.16300000000001, 'yuv.min=', 1.9380000000000002)
('yuv.max=', 217.25199999999998, 'yuv.min=', 55.554999999999993)
('yuv.max=', 228.31399999999996, 'yuv.min=', 11.606999999999999)
('yuv.max=', 248.60399999999998, 'yuv.min=', 13.186)
('yuv.max=', 203.20599999999999, 'yuv.min=', 15.004)
('yuv.max=', 203.012, 'yuv.min=', 45.422000000000004)
('yuv.max=', 248.21499999999997, 'yuv.min=', 10.51)
('yuv.max=', 245.65099999999998, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 174.34800000000001, 'yuv.min=', 70.763000000000005)
('yuv.max=', 254.77200000000002, 'yuv.min=', 30.613)
('yuv.max=', 211.47299999999998, 'yuv.min=', 15.244999999999999)
('yuv.max=', 249.06399999999996, 'yuv.min=', 46.286999999999992)
('yuv.max=', 180.41399999999999, 'yuv.min=', 17.530999999999999)
('yuv.max=', 247.803, 'yuv.min=', 21.853999999999999)
('yuv.max=', 180.59100000000001, 'yuv.min=', 40.335000000000001)
('yuv.max=', 255.0, 'yuv.min=', 24.928999999999998)
('yuv.max=', 208.91300000000001, 'yuv.min=', 0.0)
('yuv.max=', 248.81099999999998, 'yuv.min=', 18.005999999999997)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 230.81900000000002, 'yuv.min=', 31.5)
('yuv.max=', 221.64100000000002, 'yuv.min=', 16.113999999999997)
('yuv.max=', 253.59799999999998, 'yuv.min=', 4.5880000000000001)
('yuv.max=', 197.054, 'yuv.min=', 19.728999999999999)
('yuv.max=', 245.29900000000001, 'yuv.min=', 34.930999999999997)
('yuv.max=', 192.90300000000002, 'yuv.min=', 39.484999999999999)
('yuv.max=', 189.93299999999999, 'yuv.min=', 12.042999999999999)
('yuv.max=', 225.96799999999999, 'yuv.min=', 1.744)
('yuv.max=', 202.09399999999999, 'yuv.min=', 18.437000000000001)
('yuv.max=', 249.929, 'yuv.min=', 29.873000000000001)
('yuv.max=', 255.0, 'yuv.min=', 29.667000000000002)
('yuv.max=', 255.0, 'yuv.min=', 60.714432000000002)
('yuv.max=', 195.892, 'yuv.min=', 47.941000000000003)
('yuv.max=', 224.21299999999999, 'yuv.min=', 2.7269999999999999)
('yuv.max=', 176.88999999999999, 'yuv.min=', 17.916)
('yuv.max=', 248.161, 'yuv.min=', 11.053999999999998)
('yuv.max=', 191.81900000000002, 'yuv.min=', 2.4950000000000001)
('yuv.max=', 255.0, 'yuv.min=', 17.901)
('yuv.max=', 248.65799999999999, 'yuv.min=', 17.231000000000002)
('yuv.max=', 248.99999999999997, 'yuv.min=', 66.046000000000006)
('yuv.max=', 231.53100000000001, 'yuv.min=', 26.390999999999998)
('yuv.max=', 241.416, 'yuv.min=', 12.167)
('yuv.max=', 168.86399999999998, 'yuv.min=', 13.832000000000001)
('yuv.max=', 209.41499999999999, 'yuv.min=', 13.711)
('yuv.max=', 248.46099999999998, 'yuv.min=', 42.849503999999996)
('yuv.max=', 228.61099999999999, 'yuv.min=', 15.130999999999998)
('yuv.max=', 193.64899200000002, 'yuv.min=', 37.869)
('yuv.max=', 242.98499999999999, 'yuv.min=', 46.859000000000002)
('yuv.max=', 250.43399999999997, 'yuv.min=', 68.757000000000005)
('yuv.max=', 233.286, 'yuv.min=', 36.919999999999995)
('yuv.max=', 232.58699999999999, 'yuv.min=', 27.817999999999998)
('yuv.max=', 242.78699999999998, 'yuv.min=', 9.8809999999999985)
('yuv.max=', 180.06400000000002, 'yuv.min=', 39.649000000000001)
('yuv.max=', 221.553, 'yuv.min=', 22.337999999999997)
('yuv.max=', 240.70699999999999, 'yuv.min=', 51.202999999999996)
('yuv.max=', 177.75385600000001, 'yuv.min=', 1.325)
('yuv.max=', 225.376, 'yuv.min=', 30.626999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 244.28799999999998, 'yuv.min=', 11.24)
('yuv.max=', 151.642, 'yuv.min=', 20.545999999999999)
('yuv.max=', 246.47800000000001, 'yuv.min=', 25.805999999999997)
('yuv.max=', 251.74000000000001, 'yuv.min=', 36.925999999999995)
('yuv.max=', 234.47199999999995, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 6.7550000000000008)
('yuv.max=', 217.22800000000001, 'yuv.min=', 60.094999999999999)
('yuv.max=', 249.71699999999998, 'yuv.min=', 7.7289999999999992)
('yuv.max=', 249.47299999999998, 'yuv.min=', 39.594999999999999)
('yuv.max=', 229.33699999999999, 'yuv.min=', 0.0)
('yuv.max=', 220.489, 'yuv.min=', 27.725999999999999)
('yuv.max=', 250.35899999999998, 'yuv.min=', 93.049999999999997)
('yuv.max=', 218.13199999999998, 'yuv.min=', 33.670999999999999)
('yuv.max=', 248.82699999999997, 'yuv.min=', 28.184999999999999)
('yuv.max=', 235.51500000000001, 'yuv.min=', 0.86899999999999999)
('yuv.max=', 254.10300000000001, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 160.21600000000001, 'yuv.min=', 30.405999999999999)
('yuv.max=', 251.64299999999997, 'yuv.min=', 43.283999999999999)
('yuv.max=', 251.97800000000001, 'yuv.min=', 10.942)
('yuv.max=', 176.90464, 'yuv.min=', 60.695999999999998)
('yuv.max=', 251.97800000000001, 'yuv.min=', 12.543999999999999)
('yuv.max=', 209.46899999999999, 'yuv.min=', 8.2880000000000003)
('yuv.max=', 255.0, 'yuv.min=', 22.672999999999998)
('yuv.max=', 187.33699999999999, 'yuv.min=', 25.024999999999999)
('yuv.max=', 252.31, 'yuv.min=', 1.1739999999999999)
('yuv.max=', 243.815, 'yuv.min=', 16.814999999999998)
('yuv.max=', 238.19199999999998, 'yuv.min=', 3.2279999999999998)
('yuv.max=', 234.39099999999999, 'yuv.min=', 22.071000000000002)
('yuv.max=', 253.13099999999997, 'yuv.min=', 0.41299999999999998)
('yuv.max=', 246.13599999999997, 'yuv.min=', 61.058999999999997)
('yuv.max=', 228.02599999999998, 'yuv.min=', 0.57000000000000006)
('yuv.max=', 214.78031999999999, 'yuv.min=', 27.969999999999999)
('yuv.max=', 240.63, 'yuv.min=', 13.624999999999998)
('yuv.max=', 247.202, 'yuv.min=', 65.991)
('yuv.max=', 185.464, 'yuv.min=', 65.021000000000001)
('yuv.max=', 253.20599999999999, 'yuv.min=', 35.102999999999994)
('yuv.max=', 255.0, 'yuv.min=', 43.750999999999998)
('yuv.max=', 253.41299999999998, 'yuv.min=', 12.196)
('yuv.max=', 255.0, 'yuv.min=', 8.2599999999999998)
('yuv.max=', 167.0, 'yuv.min=', 3.9999999999999996)
('yuv.max=', 226.95500000000001, 'yuv.min=', 37.790999999999997)
('yuv.max=', 240.71099999999998, 'yuv.min=', 34.398000000000003)
('yuv.max=', 199.80099999999999, 'yuv.min=', 74.618000000000009)
('yuv.max=', 255.0, 'yuv.min=', 20.243000000000002)
('yuv.max=', 222.71799999999999, 'yuv.min=', 18.843)
('yuv.max=', 242.48399999999998, 'yuv.min=', 33.484000000000002)
('yuv.max=', 226.767, 'yuv.min=', 28.638000000000002)
('yuv.max=', 253.0, 'yuv.min=', 12.999999999999998)
('yuv.max=', 231.505, 'yuv.min=', 22.156999999999996)
('yuv.max=', 194.90000000000001, 'yuv.min=', 35.102999999999994)
('yuv.max=', 255.0, 'yuv.min=', 11.465)
('yuv.max=', 245.57699999999997, 'yuv.min=', 1.9889999999999999)
('yuv.max=', 247.90099999999998, 'yuv.min=', 28.025999999999996)
('yuv.max=', 255.0, 'yuv.min=', 1.4949999999999999)
('yuv.max=', 184.214, 'yuv.min=', 4.6839999999999993)
('yuv.max=', 244.886, 'yuv.min=', 52.529999999999994)
('yuv.max=', 253.31599999999997, 'yuv.min=', 8.5869999999999997)
('yuv.max=', 214.55587199999999, 'yuv.min=', 34.894999999999996)
('yuv.max=', 227.57599999999996, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 243.44499999999999, 'yuv.min=', 26.411000000000001)
('yuv.max=', 253.185, 'yuv.min=', 35.283903999999993)
('yuv.max=', 233.67099999999999, 'yuv.min=', 56.355999999999995)
('yuv.max=', 212.67475199999998, 'yuv.min=', 30.843)
('yuv.max=', 251.04299999999998, 'yuv.min=', 4.5359999999999996)
('yuv.max=', 198.93699999999998, 'yuv.min=', 24.564)
('yuv.max=', 239.161, 'yuv.min=', 28.200999999999997)
('yuv.max=', 255.0, 'yuv.min=', 42.408000000000001)
('yuv.max=', 255.0, 'yuv.min=', 18.939999999999998)
('yuv.max=', 249.61799999999999, 'yuv.min=', 0.0)
('yuv.max=', 233.02099999999999, 'yuv.min=', 53.117999999999995)
('yuv.max=', 255.0, 'yuv.min=', 44.729999999999997)
('yuv.max=', 216.02699999999999, 'yuv.min=', 15.985000000000001)
('yuv.max=', 192.96799999999999, 'yuv.min=', 8.484)
('yuv.max=', 239.16799999999998, 'yuv.min=', 17.0)
('yuv.max=', 174.03800000000001, 'yuv.min=', 28.282999999999998)
('yuv.max=', 240.41899999999998, 'yuv.min=', 24.065999999999999)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 254.70099999999999, 'yuv.min=', 64.89800000000001)
('yuv.max=', 242.21699999999998, 'yuv.min=', 49.998999999999995)
('yuv.max=', 245.91800000000001, 'yuv.min=', 14.021999999999998)
('yuv.max=', 228.89599999999996, 'yuv.min=', 67.168735999999996)
('yuv.max=', 206.94, 'yuv.min=', 6.4450000000000003)
('yuv.max=', 255.0, 'yuv.min=', 44.759999999999998)
('yuv.max=', 246.18399999999997, 'yuv.min=', 24.288)
('yuv.max=', 250.83599999999998, 'yuv.min=', 35.132999999999996)
('yuv.max=', 254.10300000000001, 'yuv.min=', 0.81499999999999995)
('yuv.max=', 255.0, 'yuv.min=', 5.6900000000000004)
('yuv.max=', 209.06399999999999, 'yuv.min=', 0.0)
('yuv.max=', 243.815, 'yuv.min=', 13.779999999999999)
('yuv.max=', 245.26099999999997, 'yuv.min=', 5.8649999999999993)
('yuv.max=', 224.04999999999998, 'yuv.min=', 5.7269999999999994)
('yuv.max=', 199.05705599999999, 'yuv.min=', 24.867999999999999)
('yuv.max=', 241.78399999999999, 'yuv.min=', 55.463000000000001)
('yuv.max=', 223.74399999999997, 'yuv.min=', 21.831999999999997)
('yuv.max=', 244.14599999999999, 'yuv.min=', 12.206)
('yuv.max=', 255.0, 'yuv.min=', 18.721)
('yuv.max=', 255.0, 'yuv.min=', 33.491999999999997)
('yuv.max=', 252.03199999999998, 'yuv.min=', 12.552)
('yuv.max=', 251.77799999999999, 'yuv.min=', 22.585999999999999)
('yuv.max=', 208.369, 'yuv.min=', 12.370000000000001)
('yuv.max=', 177.71499999999997, 'yuv.min=', 34.076999999999998)
('yuv.max=', 180.35900000000001, 'yuv.min=', 75.123999999999995)
('yuv.max=', 255.0, 'yuv.min=', 24.5)
('yuv.max=', 173.85500000000002, 'yuv.min=', 50.894999999999996)
('yuv.max=', 234.84299999999999, 'yuv.min=', 24.000999999999998)
('yuv.max=', 246.76599999999999, 'yuv.min=', 11.035999999999998)
('yuv.max=', 249.09899999999996, 'yuv.min=', 108.506)
('yuv.max=', 178.875136, 'yuv.min=', 37.864999999999995)
('yuv.max=', 225.28399999999999, 'yuv.min=', 60.999999999999993)
('yuv.max=', 230.267, 'yuv.min=', 22.128)
('yuv.max=', 239.39099999999996, 'yuv.min=', 96.714999999999989)
('yuv.max=', 246.26999999999998, 'yuv.min=', 6.5709999999999988)
('yuv.max=', 162.73399999999998, 'yuv.min=', 13.186)
('yuv.max=', 248.73999999999998, 'yuv.min=', 29.836999999999996)
('yuv.max=', 243.03, 'yuv.min=', 12.693999999999999)
('yuv.max=', 161.70400000000001, 'yuv.min=', 19.159999999999997)
('yuv.max=', 251.16800000000001, 'yuv.min=', 15.683)
('yuv.max=', 237.94200000000001, 'yuv.min=', 14.196999999999999)
('yuv.max=', 253.99999999999997, 'yuv.min=', 58.999999999999993)
('yuv.max=', 207.06299999999999, 'yuv.min=', 34.055999999999997)
('yuv.max=', 243.21699999999998, 'yuv.min=', 48.042999999999999)
('yuv.max=', 244.74399999999997, 'yuv.min=', 22.815000000000001)
('yuv.max=', 186.20099999999999, 'yuv.min=', 48.741)
('yuv.max=', 200.66873600000002, 'yuv.min=', 0.0)
('yuv.max=', 247.65199999999999, 'yuv.min=', 43.412999999999997)
('yuv.max=', 247.64100000000002, 'yuv.min=', 27.677)
('yuv.max=', 244.25899999999999, 'yuv.min=', 76.556999999999988)
('yuv.max=', 217.15600000000001, 'yuv.min=', 6.1139999999999999)
('yuv.max=', 255.0, 'yuv.min=', 57.678999999999995)
('yuv.max=', 194.57599999999996, 'yuv.min=', 3.5589999999999997)
('yuv.max=', 255.0, 'yuv.min=', 8.4450000000000003)
('yuv.max=', 255.0, 'yuv.min=', 31.387999999999998)
('yuv.max=', 243.71199999999999, 'yuv.min=', 80.325999999999993)
('yuv.max=', 219.56918400000001, 'yuv.min=', 14.516999999999999)
('yuv.max=', 255.0, 'yuv.min=', 62.326999999999991)
('yuv.max=', 244.70100000000002, 'yuv.min=', 39.722999999999999)
('yuv.max=', 200.329024, 'yuv.min=', 5.012127999999997)
('yuv.max=', 233.22099999999998, 'yuv.min=', 13.391)
('yuv.max=', 172.46719999999999, 'yuv.min=', 29.879999999999999)
('yuv.max=', 234.14699999999999, 'yuv.min=', 1.353)
('yuv.max=', 237.44, 'yuv.min=', 15.951000000000001)
('yuv.max=', 216.54099999999997, 'yuv.min=', 38.786000000000001)
('yuv.max=', 230.23499999999999, 'yuv.min=', 14.682999999999998)
('yuv.max=', 206.07300000000001, 'yuv.min=', 10.032)
('yuv.max=', 242.29300000000001, 'yuv.min=', 26.195999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 252.44099999999997, 'yuv.min=', 13.866)
('yuv.max=', 233.25199999999998, 'yuv.min=', 24.959)
('yuv.max=', 154.07449600000001, 'yuv.min=', 42.177999999999997)
('yuv.max=', 251.49000000000001, 'yuv.min=', 8.3419999999999987)
('yuv.max=', 242.35599999999999, 'yuv.min=', 3.1249999999999996)
('yuv.max=', 179.804, 'yuv.min=', 5.0599999999999996)
('yuv.max=', 176.45099999999996, 'yuv.min=', 2.8580000000000001)
('yuv.max=', 214.349504, 'yuv.min=', 4.1859999999999999)
('yuv.max=', 203.45499999999998, 'yuv.min=', 31.949999999999999)
('yuv.max=', 230.80799999999999, 'yuv.min=', 2.5760000000000001)
('yuv.max=', 248.17399999999998, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 241.548, 'yuv.min=', 31.929999999999996)
('yuv.max=', 253.80399999999997, 'yuv.min=', 7.5869999999999997)
('yuv.max=', 200.50899999999999, 'yuv.min=', 35.022999999999996)
('yuv.max=', 255.0, 'yuv.min=', 45.092999999999996)
('yuv.max=', 253.74600000000001, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 214.71700000000001, 'yuv.min=', 49.493000000000002)
('yuv.max=', 253.25599999999997, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 252.17400000000001, 'yuv.min=', 8.2170000000000005)
('yuv.max=', 237.92899999999997, 'yuv.min=', 49.198999999999998)
('yuv.max=', 238.20600000000002, 'yuv.min=', 41.356999999999999)
('yuv.max=', 249.886, 'yuv.min=', 46.466999999999999)
('yuv.max=', 228.12699999999998, 'yuv.min=', 50.156999999999996)
('yuv.max=', 255.0, 'yuv.min=', 6.3590000000000009)
('yuv.max=', 240.47899999999998, 'yuv.min=', 38.479000000000006)
('yuv.max=', 217.98099999999999, 'yuv.min=', 26.305)
('yuv.max=', 240.071, 'yuv.min=', 39.640999999999991)
('yuv.max=', 248.74299999999999, 'yuv.min=', 25.304999999999996)
('yuv.max=', 248.37999999999997, 'yuv.min=', 1.587)
('yuv.max=', 190.399, 'yuv.min=', 52.191000000000003)
('yuv.max=', 253.77199999999999, 'yuv.min=', 0.0)
('yuv.max=', 243.755, 'yuv.min=', 21.372)
('yuv.max=', 215.05799999999999, 'yuv.min=', 30.926999999999996)
('yuv.max=', 228.33100000000002, 'yuv.min=', 37.006999999999998)
('yuv.max=', 255.0, 'yuv.min=', 38.494)
('yuv.max=', 184.863, 'yuv.min=', 24.254999999999999)
('yuv.max=', 231.24699999999996, 'yuv.min=', 13.017000000000001)
('yuv.max=', 240.02399999999994, 'yuv.min=', 0.68400000000000005)
('yuv.max=', 253.48399999999998, 'yuv.min=', 21.324999999999999)
('yuv.max=', 243.40600000000001, 'yuv.min=', 55.651999999999994)
('yuv.max=', 253.29900000000001, 'yuv.min=', 29.596999999999998)
('yuv.max=', 255.0, 'yuv.min=', 36.315999999999995)
('yuv.max=', 222.63999999999999, 'yuv.min=', 0.0)
('yuv.max=', 227.374, 'yuv.min=', 36.367999999999995)
('yuv.max=', 255.0, 'yuv.min=', 31.421999999999997)
('yuv.max=', 159.54345599999999, 'yuv.min=', 28.687999999999999)
('yuv.max=', 255.0, 'yuv.min=', 35.763999999999996)
('yuv.max=', 238.565, 'yuv.min=', 16.202999999999999)
('yuv.max=', 234.96100000000001, 'yuv.min=', 0.114)
('yuv.max=', 253.989, 'yuv.min=', 4.0709999999999997)
('yuv.max=', 254.06, 'yuv.min=', 27.447999999999997)
('yuv.max=', 165.89084799999998, 'yuv.min=', 43.472000000000001)
('yuv.max=', 255.0, 'yuv.min=', 20.125)
('yuv.max=', 245.28100000000001, 'yuv.min=', 66.608000000000004)
('yuv.max=', 215.19299999999998, 'yuv.min=', 31.802999999999997)
('yuv.max=', 186.82999999999998, 'yuv.min=', 51.488)
('yuv.max=', 250.0, 'yuv.min=', 41.0)
('yuv.max=', 242.13999999999999, 'yuv.min=', 60.896000000000001)
('yuv.max=', 254.08800000000002, 'yuv.min=', 10.369999999999999)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 245.798, 'yuv.min=', 15.760999999999999)
('yuv.max=', 255.0, 'yuv.min=', 24.771999999999998)
('yuv.max=', 235.80999999999997, 'yuv.min=', 11.763)
('yuv.max=', 254.08800000000002, 'yuv.min=', 54.032999999999994)
('yuv.max=', 197.89099999999996, 'yuv.min=', 9.8300000000000001)
('yuv.max=', 207.42999999999998, 'yuv.min=', 2.9009999999999998)
('yuv.max=', 204.188256, 'yuv.min=', 11.244999999999999)
('yuv.max=', 231.51300000000001, 'yuv.min=', 42.287999999999997)
('yuv.max=', 253.185, 'yuv.min=', 44.539999999999999)
('yuv.max=', 248.05999999999997, 'yuv.min=', 23.712)
('yuv.max=', 254.65800000000002, 'yuv.min=', 0.99999999999999989)
('yuv.max=', 252.22799999999998, 'yuv.min=', 0.0)
('yuv.max=', 230.02499999999998, 'yuv.min=', 1.4019999999999999)
('yuv.max=', 227.09700000000001, 'yuv.min=', 2.3419999999999996)
('yuv.max=', 218.62, 'yuv.min=', 28.567)
('yuv.max=', 241.60199999999998, 'yuv.min=', 65.971000000000004)
('yuv.max=', 215.017, 'yuv.min=', 45.001000000000005)
('yuv.max=', 247.917, 'yuv.min=', 8.9789999999999992)
('yuv.max=', 198.20099999999999, 'yuv.min=', 34.808999999999997)
('yuv.max=', 217.273, 'yuv.min=', 13.206999999999999)
('yuv.max=', 225.09, 'yuv.min=', 21.648)
('yuv.max=', 246.92499999999995, 'yuv.min=', 48.878999999999998)
('yuv.max=', 255.0, 'yuv.min=', 7.6899999999999995)
('yuv.max=', 229.38200000000001, 'yuv.min=', 4.7439999999999998)
('yuv.max=', 217.45600000000002, 'yuv.min=', 37.542000000000002)
('yuv.max=', 129.0, 'yuv.min=', 5.1139999999999999)
('yuv.max=', 252.99099999999999, 'yuv.min=', 33.530000000000001)
('yuv.max=', 253.53300000000002, 'yuv.min=', 47.104999999999997)
('yuv.max=', 248.99999999999997, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 16.506)
('yuv.max=', 210.92399999999998, 'yuv.min=', 13.273)
('yuv.max=', 255.0, 'yuv.min=', 26.738143999999991)
('yuv.max=', 252.08199999999999, 'yuv.min=', 8.3810000000000002)
('yuv.max=', 229.62700000000001, 'yuv.min=', 58.678999999999995)
('yuv.max=', 249.04199999999997, 'yuv.min=', 3.7010000000000001)
('yuv.max=', 235.37699999999998, 'yuv.min=', 30.591000000000001)
('yuv.max=', 241.82500000000002, 'yuv.min=', 6.8469999999999995)
('yuv.max=', 253.376, 'yuv.min=', 13.942)
('yuv.max=', 255.0, 'yuv.min=', 27.762999999999998)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 37.116999999999997)
('yuv.max=', 250.77100000000002, 'yuv.min=', 19.895999999999997)
('yuv.max=', 246.0, 'yuv.min=', 26.300999999999998)
('yuv.max=', 252.28800000000001, 'yuv.min=', 0.79800000000000004)
('yuv.max=', 164.886, 'yuv.min=', 59.526999999999994)
('yuv.max=', 255.0, 'yuv.min=', 50.814999999999998)
('yuv.max=', 249.15299999999999, 'yuv.min=', 30.451999999999998)
('yuv.max=', 234.72299999999998, 'yuv.min=', 1.798)
('yuv.max=', 255.0, 'yuv.min=', 9.7659999999999982)
('yuv.max=', 223.81799999999998, 'yuv.min=', 3.5100000000000002)
('yuv.max=', 241.25299999999996, 'yuv.min=', 20.936)
('yuv.max=', 181.67099999999999, 'yuv.min=', 23.189)
('yuv.max=', 243.12899999999999, 'yuv.min=', 72.043999999999997)
('yuv.max=', 212.23899999999998, 'yuv.min=', 55.842999999999996)
('yuv.max=', 224.39099999999999, 'yuv.min=', 40.021000000000001)
('yuv.max=', 214.053, 'yuv.min=', 63.077999999999996)
('yuv.max=', 249.16899999999995, 'yuv.min=', 26.399000000000001)
('yuv.max=', 229.25799999999998, 'yuv.min=', 11.152999999999999)
('yuv.max=', 251.09199999999998, 'yuv.min=', 26.003)
('yuv.max=', 228.12599999999998, 'yuv.min=', 11.18)
('yuv.max=', 204.56599999999997, 'yuv.min=', 3.673)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 165.292, 'yuv.min=', 13.980999999999998)
('yuv.max=', 232.67399999999998, 'yuv.min=', 24.810000000000002)
('yuv.max=', 229.34799999999996, 'yuv.min=', 22.242999999999999)
('yuv.max=', 252.09200000000001, 'yuv.min=', 42.750999999999991)
('yuv.max=', 255.0, 'yuv.min=', 5.407)
('yuv.max=', 246.77699999999999, 'yuv.min=', 4.9710000000000001)
('yuv.max=', 224.148, 'yuv.min=', 74.75200000000001)
('yuv.max=', 237.57399999999998, 'yuv.min=', 5.8800000000000008)
('yuv.max=', 192.06399999999999, 'yuv.min=', 71.825999999999993)
('yuv.max=', 254.07099999999997, 'yuv.min=', 7.359)
('yuv.max=', 216.387, 'yuv.min=', 50.902000000000001)
('yuv.max=', 252.04499999999999, 'yuv.min=', 13.347999999999999)
('yuv.max=', 198.91499999999996, 'yuv.min=', 33.146000000000001)
('yuv.max=', 254.77200000000002, 'yuv.min=', 17.852999999999998)
('yuv.max=', 255.0, 'yuv.min=', 58.016999999999996)
('yuv.max=', 241.34199999999998, 'yuv.min=', 12.015000000000001)
('yuv.max=', 199.077, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 80.573999999999998)
('yuv.max=', 170.994, 'yuv.min=', 24.835999999999999)
('yuv.max=', 240.0, 'yuv.min=', 15.999999999999998)
('yuv.max=', 234.036, 'yuv.min=', 84.254999999999995)
('yuv.max=', 255.0, 'yuv.min=', 26.637)
('yuv.max=', 254.70099999999999, 'yuv.min=', 42.800999999999995)
('yuv.max=', 236.14799999999997, 'yuv.min=', 10.843)
('yuv.max=', 203.52199999999999, 'yuv.min=', 3.9459999999999997)
('yuv.max=', 188.959, 'yuv.min=', 39.103999999999999)
('yuv.max=', 216.82599999999999, 'yuv.min=', 12.903)
('yuv.max=', 252.0, 'yuv.min=', 25.0)
('yuv.max=', 238.21699999999998, 'yuv.min=', 18.874000000000002)
('yuv.max=', 170.69800000000001, 'yuv.min=', 21.891999999999999)
('yuv.max=', 183.34199999999998, 'yuv.min=', 25.872)
('yuv.max=', 207.16300000000001, 'yuv.min=', 39.810000000000002)
('yuv.max=', 236.316, 'yuv.min=', 11.792999999999999)
('yuv.max=', 207.61899999999997, 'yuv.min=', 3.5589999999999997)
('yuv.max=', 239.19399999999999, 'yuv.min=', 57.303999999999995)
('yuv.max=', 254.65800000000002, 'yuv.min=', 71.918000000000006)
('yuv.max=', 245.81299999999999, 'yuv.min=', 26.081)
('yuv.max=', 255.0, 'yuv.min=', 16.619)
('yuv.max=', 231.923, 'yuv.min=', 38.096999999999994)
('yuv.max=', 251.184, 'yuv.min=', 51.352999999999994)
('yuv.max=', 252.73500000000001, 'yuv.min=', 54.043552000000005)
('yuv.max=', 220.91799999999998, 'yuv.min=', 25.43)
('yuv.max=', 242.821, 'yuv.min=', 6.4689999999999994)
('yuv.max=', 246.10699999999997, 'yuv.min=', 37.262999999999998)
('yuv.max=', 231.46299999999997, 'yuv.min=', 4.7609999999999992)
('yuv.max=', 206.09299999999999, 'yuv.min=', 10.655999999999999)
('yuv.max=', 222.99999999999997, 'yuv.min=', 67.266000000000005)
('yuv.max=', 255.0, 'yuv.min=', 16.658000000000001)
('yuv.max=', 228.91800000000001, 'yuv.min=', 19.420999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 205.32900000000001, 'yuv.min=', 39.163999999999994)
('yuv.max=', 232.69300000000001, 'yuv.min=', 15.343999999999999)
('yuv.max=', 163.09932800000001, 'yuv.min=', 30.167000000000002)
('yuv.max=', 255.0, 'yuv.min=', 22.504999999999999)
('yuv.max=', 217.53300000000002, 'yuv.min=', 23.134999999999998)
('yuv.max=', 222.624, 'yuv.min=', 49.768000000000001)
('yuv.max=', 255.0, 'yuv.min=', 18.363)
('yuv.max=', 242.75500000000002, 'yuv.min=', 112.15407999999999)
('yuv.max=', 253.52699999999999, 'yuv.min=', 0.86899999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 93.24799999999999)
('yuv.max=', 238.12900000000002, 'yuv.min=', 40.488)
('yuv.max=', 255.0, 'yuv.min=', 19.995000000000001)
('yuv.max=', 248.99999999999997, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 8.093)
('yuv.max=', 222.19200000000001, 'yuv.min=', 20.042999999999999)
('yuv.max=', 242.0, 'yuv.min=', 22.259999999999998)
('yuv.max=', 245.05199999999996, 'yuv.min=', 18.661999999999999)
('yuv.max=', 253.15899999999996, 'yuv.min=', 94.575000000000003)
('yuv.max=', 255.0, 'yuv.min=', 68.091999999999999)
('yuv.max=', 222.99999999999997, 'yuv.min=', 19.0)
('yuv.max=', 250.99999999999997, 'yuv.min=', 12.999999999999998)
('yuv.max=', 242.0, 'yuv.min=', 1.9999999999999998)
('yuv.max=', 242.185, 'yuv.min=', 2.8039999999999998)
('yuv.max=', 229.80199999999999, 'yuv.min=', 6.766)
('yuv.max=', 224.06799999999998, 'yuv.min=', 35.169000000000004)
('yuv.max=', 204.40099999999998, 'yuv.min=', 30.692999999999998)
('yuv.max=', 224.16199999999998, 'yuv.min=', 26.769999999999996)
('yuv.max=', 240.64099999999999, 'yuv.min=', 44.113999999999997)
('yuv.max=', 230.77199999999999, 'yuv.min=', 19.384999999999998)
('yuv.max=', 168.45033599999999, 'yuv.min=', 8.0429999999999993)
('yuv.max=', 236.566, 'yuv.min=', 16.440999999999999)
('yuv.max=', 213.80399999999997, 'yuv.min=', 34.534999999999997)
('yuv.max=', 181.75564800000001, 'yuv.min=', 3.4129999999999998)
('yuv.max=', 243.33099999999999, 'yuv.min=', 83.825999999999993)
('yuv.max=', 224.10999999999999, 'yuv.min=', 11.94)
('yuv.max=', 250.56599999999997, 'yuv.min=', 24.570999999999998)
('yuv.max=', 250.99999999999997, 'yuv.min=', 53.999999999999993)
('yuv.max=', 190.18688, 'yuv.min=', 28.735999999999997)
('yuv.max=', 209.21900000000002, 'yuv.min=', 25.625280000000004)
('yuv.max=', 239.93999999999997, 'yuv.min=', 51.527000000000001)
('yuv.max=', 153.11499999999998, 'yuv.min=', 41.926000000000002)
('yuv.max=', 224.102, 'yuv.min=', 49.441000000000003)
('yuv.max=', 241.17699999999996, 'yuv.min=', 16.919)
('yuv.max=', 226.12599999999998, 'yuv.min=', 27.006)
('yuv.max=', 247.86400000000003, 'yuv.min=', 2.1739999999999999)
('yuv.max=', 232.47999999999996, 'yuv.min=', 19.486999999999998)
('yuv.max=', 208.285, 'yuv.min=', 30.018000000000001)
('yuv.max=', 251.37799999999999, 'yuv.min=', 10.266999999999999)
('yuv.max=', 223.54400000000001, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 1.744)
('yuv.max=', 249.65099999999995, 'yuv.min=', 10.591999999999999)
('yuv.max=', 196.08699999999999, 'yuv.min=', 79.571999999999989)
('yuv.max=', 196.12299999999999, 'yuv.min=', 9.6999999999999993)
('yuv.max=', 210.00199999999998, 'yuv.min=', 6.2279999999999998)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 197.90800000000002, 'yuv.min=', 17.809000000000001)
('yuv.max=', 255.0, 'yuv.min=', 4.798)
('yuv.max=', 243.58699999999999, 'yuv.min=', 52.076999999999998)
('yuv.max=', 248.77199999999999, 'yuv.min=', 32.534999999999997)
('yuv.max=', 201.578, 'yuv.min=', 49.466999999999999)
('yuv.max=', 205.43599999999998, 'yuv.min=', 32.086999999999996)
('yuv.max=', 238.93099999999998, 'yuv.min=', 0.0)
('yuv.max=', 202.21099999999998, 'yuv.min=', 60.150999999999996)
('yuv.max=', 255.0, 'yuv.min=', 47.878999999999998)
('yuv.max=', 234.32299999999998, 'yuv.min=', 17.817)
('yuv.max=', 238.89000000000001, 'yuv.min=', 8.1870000000000012)
('yuv.max=', 254.06, 'yuv.min=', 27.563000000000002)
('yuv.max=', 250.47299999999998, 'yuv.min=', 59.354999999999997)
('yuv.max=', 244.28799999999998, 'yuv.min=', 28.827999999999996)
('yuv.max=', 250.619, 'yuv.min=', 26.846999999999998)
('yuv.max=', 201.96100000000001, 'yuv.min=', 0.0)
('yuv.max=', 233.45599999999999, 'yuv.min=', 1.9830000000000001)
('yuv.max=', 255.0, 'yuv.min=', 11.016999999999998)
('yuv.max=', 193.87599999999998, 'yuv.min=', 36.842999999999996)
('yuv.max=', 200.98399999999998, 'yuv.min=', 2.8689999999999998)
('yuv.max=', 226.08699999999999, 'yuv.min=', 38.883000000000003)
('yuv.max=', 248.10299999999998, 'yuv.min=', 62.000999999999998)
('yuv.max=', 252.65199999999999, 'yuv.min=', 6.7550000000000008)
('yuv.max=', 246.77199999999999, 'yuv.min=', 11.950000000000001)
('yuv.max=', 235.26599999999999, 'yuv.min=', 13.624999999999998)
('yuv.max=', 255.0, 'yuv.min=', 57.762)
('yuv.max=', 237.65100000000001, 'yuv.min=', 46.953999999999994)
('yuv.max=', 208.72800000000001, 'yuv.min=', 17.462)
('yuv.max=', 249.245, 'yuv.min=', 14.161999999999999)
('yuv.max=', 222.14599999999999, 'yuv.min=', 0.0)
('yuv.max=', 227.363, 'yuv.min=', 15.365)
('yuv.max=', 180.17099999999999, 'yuv.min=', 32.789999999999999)
('yuv.max=', 248.798, 'yuv.min=', 2.4649999999999999)
('yuv.max=', 199.47399999999999, 'yuv.min=', 16.305)
('yuv.max=', 199.87900000000002, 'yuv.min=', 38.958999999999996)
('yuv.max=', 254.47300000000001, 'yuv.min=', 0.0)
('yuv.max=', 250.017, 'yuv.min=', 32.708999999999996)
('yuv.max=', 215.33099999999999, 'yuv.min=', 10.978)
('yuv.max=', 255.0, 'yuv.min=', 11.613)
('yuv.max=', 255.0, 'yuv.min=', 20.881999999999998)
('yuv.max=', 210.374, 'yuv.min=', 24.728999999999999)
('yuv.max=', 204.80399999999997, 'yuv.min=', 12.954000000000001)
('yuv.max=', 237.0, 'yuv.min=', 43.999999999999993)
('yuv.max=', 254.316, 'yuv.min=', 49.207999999999998)
('yuv.max=', 228.56699999999998, 'yuv.min=', 41.402000000000001)
('yuv.max=', 245.24800000000002, 'yuv.min=', 42.689)
('yuv.max=', 248.809, 'yuv.min=', 11.384)
('yuv.max=', 255.0, 'yuv.min=', 44.23299999999999)
('yuv.max=', 210.56799999999998, 'yuv.min=', 24.625)
('yuv.max=', 199.73499999999999, 'yuv.min=', 31.405999999999999)
('yuv.max=', 211.81900000000002, 'yuv.min=', 41.911999999999999)
('yuv.max=', 197.24943999999999, 'yuv.min=', 19.590999999999998)
('yuv.max=', 224.73499999999999, 'yuv.min=', 5.6879999999999997)
('yuv.max=', 250.66399999999999, 'yuv.min=', 21.904999999999998)
('yuv.max=', 254.47300000000001, 'yuv.min=', 75.810999999999993)
('yuv.max=', 247.51599999999999, 'yuv.min=', 11.716000000000001)
('yuv.max=', 174.78899999999999, 'yuv.min=', 32.058)
('yuv.max=', 255.0, 'yuv.min=', 9.7319999999999993)
('yuv.max=', 183.82599999999999, 'yuv.min=', 0.34200000000000003)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 238.99999999999997, 'yuv.min=', 21.266999999999996)
('yuv.max=', 241.91899999999998, 'yuv.min=', 26.279)
('yuv.max=', 255.0, 'yuv.min=', 29.280999999999999)
('yuv.max=', 198.84999999999999, 'yuv.min=', 27.802)
('yuv.max=', 255.0, 'yuv.min=', 12.837)
('yuv.max=', 255.0, 'yuv.min=', 37.128999999999998)
('yuv.max=', 247.68000000000001, 'yuv.min=', 0.0)
('yuv.max=', 241.405, 'yuv.min=', 80.263232000000002)
('yuv.max=', 254.886, 'yuv.min=', 0.0)
('yuv.max=', 248.047, 'yuv.min=', 8.8000000000000007)
('yuv.max=', 197.41399999999999, 'yuv.min=', 42.869999999999997)
('yuv.max=', 228.41299999999998, 'yuv.min=', 12.587)
('yuv.max=', 255.0, 'yuv.min=', 15.699000000000002)
('yuv.max=', 255.0, 'yuv.min=', 19.445)
('yuv.max=', 249.61799999999999, 'yuv.min=', 9.9220000000000006)
('yuv.max=', 160.911968, 'yuv.min=', 35.296999999999997)
('yuv.max=', 221.49899999999997, 'yuv.min=', 28.342999999999996)
('yuv.max=', 178.75606400000001, 'yuv.min=', 9.1850000000000005)
('yuv.max=', 252.51599999999999, 'yuv.min=', 19.954999999999998)
('yuv.max=', 240.73399999999998, 'yuv.min=', 15.289)
('yuv.max=', 206.517, 'yuv.min=', 0.91200000000000003)
('yuv.max=', 244.75199999999998, 'yuv.min=', 1.196)
('yuv.max=', 234.0, 'yuv.min=', 19.0)
('yuv.max=', 253.82599999999996, 'yuv.min=', 31.059999999999999)
('yuv.max=', 253.20599999999999, 'yuv.min=', 33.438999999999993)
('yuv.max=', 255.0, 'yuv.min=', 41.035999999999994)
('yuv.max=', 204.21899999999999, 'yuv.min=', 38.900999999999996)
('yuv.max=', 252.886, 'yuv.min=', 0.0)
('yuv.max=', 253.82599999999996, 'yuv.min=', 20.701999999999998)
('yuv.max=', 217.97899999999998, 'yuv.min=', 11.617000000000001)
('yuv.max=', 237.64400000000001, 'yuv.min=', 6.0539999999999994)
('yuv.max=', 238.73299999999998, 'yuv.min=', 5.6280000000000001)
('yuv.max=', 236.68999999999997, 'yuv.min=', 38.842999999999996)
('yuv.max=', 254.18499999999997, 'yuv.min=', 15.788999999999998)
('yuv.max=', 246.78700000000001, 'yuv.min=', 43.625000000000007)
('yuv.max=', 254.06, 'yuv.min=', 14.600999999999999)
('yuv.max=', 246.36999999999998, 'yuv.min=', 18.744999999999997)
('yuv.max=', 245.76499999999999, 'yuv.min=', 24.291999999999998)
('yuv.max=', 232.64499999999998, 'yuv.min=', 35.201000000000001)
('yuv.max=', 249.15700000000001, 'yuv.min=', 12.180999999999999)
('yuv.max=', 246.02799999999996, 'yuv.min=', 5.4610000000000003)
('yuv.max=', 251.70099999999996, 'yuv.min=', 74.837000000000003)
('yuv.max=', 255.0, 'yuv.min=', 27.405999999999999)
('yuv.max=', 247.68999999999997, 'yuv.min=', 19.0)
('yuv.max=', 233.84368000000001, 'yuv.min=', 14.553000000000001)
('yuv.max=', 224.61000000000001, 'yuv.min=', 6.5709999999999997)
('yuv.max=', 240.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 252.61899999999997, 'yuv.min=', 3.516)
('yuv.max=', 234.91, 'yuv.min=', 16.977999999999998)
('yuv.max=', 255.0, 'yuv.min=', 1.0429999999999999)
('yuv.max=', 242.85299999999998, 'yuv.min=', 24.43)
('yuv.max=', 239.929, 'yuv.min=', 0.64100000000000001)
('yuv.max=', 217.01499999999999, 'yuv.min=', 19.247999999999998)
('yuv.max=', 205.12100000000001, 'yuv.min=', 67.87299999999999)
('yuv.max=', 222.61499999999998, 'yuv.min=', 54.836999999999996)
('yuv.max=', 241.55199999999996, 'yuv.min=', 7.1419999999999995)
('yuv.max=', 202.63399999999999, 'yuv.min=', 32.347999999999999)
('yuv.max=', 249.21599999999998, 'yuv.min=', 0.0)
('yuv.max=', 227.11799999999999, 'yuv.min=', 0.0)
('yuv.max=', 252.22799999999998, 'yuv.min=', 58.682000000000002)
('yuv.max=', 236.01599999999999, 'yuv.min=', 9.6900000000000013)
('yuv.max=', 158.18000000000001, 'yuv.min=', 17.558999999999997)
('yuv.max=', 255.0, 'yuv.min=', 71.0)
('yuv.max=', 184.494, 'yuv.min=', 12.091999999999999)
('yuv.max=', 224.90799999999999, 'yuv.min=', 20.864000000000001)
('yuv.max=', 194.99999999999997, 'yuv.min=', 59.063999999999993)
('yuv.max=', 227.52699999999999, 'yuv.min=', 2.097)
('yuv.max=', 252.01899999999995, 'yuv.min=', 74.597999999999985)
('yuv.max=', 173.71219200000002, 'yuv.min=', 5.383)
('yuv.max=', 255.0, 'yuv.min=', 54.389471999999998)
('yuv.max=', 254.70099999999999, 'yuv.min=', 2.9009999999999998)
('yuv.max=', 245.298, 'yuv.min=', 2.4020000000000001)
('yuv.max=', 232.35899999999998, 'yuv.min=', 17.558999999999997)
('yuv.max=', 195.59899999999999, 'yuv.min=', 33.629999999999995)
('yuv.max=', 180.13599999999997, 'yuv.min=', 45.510999999999996)
('yuv.max=', 252.03199999999998, 'yuv.min=', 66.703999999999994)
('yuv.max=', 249.62099999999998, 'yuv.min=', 9.1069999999999993)
('yuv.max=', 234.59800000000001, 'yuv.min=', 39.895999999999994)
('yuv.max=', 255.0, 'yuv.min=', 32.497)
('yuv.max=', 236.22199999999998, 'yuv.min=', 14.628)
('yuv.max=', 230.024, 'yuv.min=', 7.7719999999999994)
('yuv.max=', 255.0, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 221.22799999999998, 'yuv.min=', 21.861999999999998)
('yuv.max=', 222.19099999999997, 'yuv.min=', 18.997)
('yuv.max=', 221.58799999999999, 'yuv.min=', 47.470999999999997)
('yuv.max=', 238.815, 'yuv.min=', 10.445)
('yuv.max=', 244.40199999999999, 'yuv.min=', 90.727999999999994)
('yuv.max=', 235.90399999999997, 'yuv.min=', 36.480000000000004)
('yuv.max=', 238.21100000000001, 'yuv.min=', 17.971999999999998)
('yuv.max=', 255.0, 'yuv.min=', 3.6189999999999998)
('yuv.max=', 237.20299999999997, 'yuv.min=', 42.223999999999997)
('yuv.max=', 227.79900000000001, 'yuv.min=', 1.712)
('yuv.max=', 160.554, 'yuv.min=', 28.070999999999998)
('yuv.max=', 195.98399999999998, 'yuv.min=', 15.624999999999998)
('yuv.max=', 247.02799999999999, 'yuv.min=', 43.933)
('yuv.max=', 236.327, 'yuv.min=', 35.064000000000007)
('yuv.max=', 233.97200000000001, 'yuv.min=', 17.857999999999997)
('yuv.max=', 243.62599999999998, 'yuv.min=', 68.662999999999997)
('yuv.max=', 202.66799999999998, 'yuv.min=', 24.460000000000001)
('yuv.max=', 220.28800000000001, 'yuv.min=', 14.994999999999999)
('yuv.max=', 246.40199999999999, 'yuv.min=', 10.369999999999999)
('yuv.max=', 228.58699999999999, 'yuv.min=', 1.1850000000000001)
('yuv.max=', 255.0, 'yuv.min=', 0.29899999999999999)
('yuv.max=', 242.67299999999997, 'yuv.min=', 46.802)
('yuv.max=', 239.71399999999997, 'yuv.min=', 19.07)
('yuv.max=', 204.26399999999998, 'yuv.min=', 0.0)
('yuv.max=', 239.24099999999996, 'yuv.min=', 43.911999999999999)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 16.788)
('yuv.max=', 229.76400000000001, 'yuv.min=', 53.585000000000001)
('yuv.max=', 255.0, 'yuv.min=', 9.8149999999999995)
('yuv.max=', 217.33699999999999, 'yuv.min=', 58.457999999999998)
('yuv.max=', 214.49199999999996, 'yuv.min=', 49.86999999999999)
('yuv.max=', 234.62300000000002, 'yuv.min=', 22.119)
('yuv.max=', 254.43000000000001, 'yuv.min=', 14.853999999999999)
('yuv.max=', 228.185, 'yuv.min=', 31.866999999999997)
('yuv.max=', 225.26000000000002, 'yuv.min=', 44.960999999999999)
('yuv.max=', 255.0, 'yuv.min=', 26.407)
('yuv.max=', 191.38900000000001, 'yuv.min=', 67.563000000000002)
('yuv.max=', 254.316, 'yuv.min=', 6.8259999999999996)
('yuv.max=', 247.75500000000002, 'yuv.min=', 0.0)
('yuv.max=', 171.44899999999998, 'yuv.min=', 18.737000000000002)
('yuv.max=', 189.35499999999999, 'yuv.min=', 19.536999999999999)
('yuv.max=', 215.892, 'yuv.min=', 29.663)
('yuv.max=', 233.0, 'yuv.min=', 7.9999999999999991)
('yuv.max=', 224.74199999999999, 'yuv.min=', 43.616999999999997)
('yuv.max=', 217.64600000000002, 'yuv.min=', 11.888)
('yuv.max=', 248.99999999999997, 'yuv.min=', 28.600000000000001)
('yuv.max=', 205.12900000000002, 'yuv.min=', 5.9180000000000001)
('yuv.max=', 240.07499999999999, 'yuv.min=', 19.048999999999999)
('yuv.max=', 213.44799999999998, 'yuv.min=', 5.5439999999999996)
('yuv.max=', 238.45799999999997, 'yuv.min=', 65.944000000000003)
('yuv.max=', 255.0, 'yuv.min=', 42.627999999999993)
('yuv.max=', 186.886, 'yuv.min=', 48.185000000000002)
('yuv.max=', 210.339, 'yuv.min=', 4.3739999999999997)
('yuv.max=', 176.799104, 'yuv.min=', 20.901)
('yuv.max=', 251.804, 'yuv.min=', 23.039999999999999)
('yuv.max=', 209.84499999999997, 'yuv.min=', 18.416999999999998)
('yuv.max=', 241.75399999999999, 'yuv.min=', 44.897999999999996)
('yuv.max=', 254.131, 'yuv.min=', 16.204000000000001)
('yuv.max=', 255.0, 'yuv.min=', 46.114000000000004)
('yuv.max=', 250.55500000000001, 'yuv.min=', 7.8710000000000004)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 248.00999999999999, 'yuv.min=', 2.6559999999999997)
('yuv.max=', 250.64699999999996, 'yuv.min=', 66.725999999999999)
('yuv.max=', 248.733, 'yuv.min=', 32.817999999999998)
('yuv.max=', 237.0, 'yuv.min=', 70.968999999999994)
('yuv.max=', 168.07299999999998, 'yuv.min=', 16.130999999999997)
('yuv.max=', 255.0, 'yuv.min=', 23.232999999999997)
('yuv.max=', 255.0, 'yuv.min=', 16.341999999999999)
('yuv.max=', 239.495, 'yuv.min=', 7.8220000000000001)
('yuv.max=', 206.15999999999997, 'yuv.min=', 44.103000000000002)
('yuv.max=', 228.32399999999998, 'yuv.min=', 24.898999999999997)
('yuv.max=', 208.72299999999998, 'yuv.min=', 10.097)
('yuv.max=', 205.31900000000002, 'yuv.min=', 30.306999999999999)
('yuv.max=', 255.0, 'yuv.min=', 22.299999999999997)
('yuv.max=', 255.0, 'yuv.min=', 18.658000000000001)
('yuv.max=', 235.98899999999998, 'yuv.min=', 56.838000000000001)
('yuv.max=', 255.0, 'yuv.min=', 5.2880000000000003)
('yuv.max=', 250.43399999999997, 'yuv.min=', 5.4129999999999994)
('yuv.max=', 227.81899999999999, 'yuv.min=', 8.1739999999999995)
('yuv.max=', 255.0, 'yuv.min=', 7.2769999999999992)
('yuv.max=', 183.06999999999999, 'yuv.min=', 44.598999999999997)
('yuv.max=', 198.893, 'yuv.min=', 24.442)
('yuv.max=', 227.02799999999999, 'yuv.min=', 24.722999999999999)
('yuv.max=', 215.38800000000001, 'yuv.min=', 45.948)
('yuv.max=', 250.02800000000002, 'yuv.min=', 23.658000000000001)
('yuv.max=', 159.87900000000002, 'yuv.min=', 12.928999999999998)
('yuv.max=', 244.499, 'yuv.min=', 23.390000000000001)
('yuv.max=', 248.34200000000001, 'yuv.min=', 16.797999999999998)
('yuv.max=', 237.131, 'yuv.min=', 0.0)
('yuv.max=', 239.03199999999998, 'yuv.min=', 0.114)
('yuv.max=', 219.893, 'yuv.min=', 24.579999999999998)
('yuv.max=', 251.60400000000001, 'yuv.min=', 43.140999999999991)
('yuv.max=', 177.427232, 'yuv.min=', 69.588999999999999)
('yuv.max=', 254.77200000000002, 'yuv.min=', 52.879999999999995)
('yuv.max=', 252.54399999999998, 'yuv.min=', 59.135999999999996)
('yuv.max=', 206.0, 'yuv.min=', 66.0)
('yuv.max=', 254.40199999999999, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 214.166, 'yuv.min=', 35.835999999999999)
('yuv.max=', 254.886, 'yuv.min=', 80.689999999999998)
('yuv.max=', 236.40200000000002, 'yuv.min=', 63.378)
('yuv.max=', 236.36699999999996, 'yuv.min=', 83.462000000000003)
('yuv.max=', 245.54399999999998, 'yuv.min=', 29.962999999999997)
('yuv.max=', 193.34899999999999, 'yuv.min=', 25.689999999999998)
('yuv.max=', 236.191, 'yuv.min=', 10.439)
('yuv.max=', 233.98500000000001, 'yuv.min=', 27.338999999999999)
('yuv.max=', 204.11499999999998, 'yuv.min=', 66.926000000000002)
('yuv.max=', 252.65199999999999, 'yuv.min=', 5.6839999999999993)
('yuv.max=', 245.29300000000001, 'yuv.min=', 13.569999999999999)
('yuv.max=', 221.52425600000001, 'yuv.min=', 25.652000000000001)
('yuv.max=', 207.94299999999998, 'yuv.min=', 27.715999999999998)
('yuv.max=', 255.0, 'yuv.min=', 11.439)
('yuv.max=', 230.17499999999998, 'yuv.min=', 9.4390000000000001)
('yuv.max=', 173.19977599999999, 'yuv.min=', 19.670999999999999)
('yuv.max=', 255.0, 'yuv.min=', 8.3719999999999999)
('yuv.max=', 228.14599999999999, 'yuv.min=', 18.911999999999999)
('yuv.max=', 239.30499999999995, 'yuv.min=', 0.755)
('yuv.max=', 248.93599999999998, 'yuv.min=', 17.396999999999998)
('yuv.max=', 255.0, 'yuv.min=', 44.530999999999999)
('yuv.max=', 196.74099999999999, 'yuv.min=', 15.921999999999999)
('yuv.max=', 239.79300000000001, 'yuv.min=', 8.3490000000000002)
('yuv.max=', 170.26199999999997, 'yuv.min=', 34.371999999999993)
('yuv.max=', 248.48399999999998, 'yuv.min=', 23.486000000000001)
('yuv.max=', 251.12399999999997, 'yuv.min=', 34.476999999999997)
('yuv.max=', 242.62300000000002, 'yuv.min=', 0.22800000000000001)
('yuv.max=', 255.0, 'yuv.min=', 2.7719999999999998)
('yuv.max=', 229.08700000000002, 'yuv.min=', 55.359999999999999)
('yuv.max=', 215.161, 'yuv.min=', 13.577)
('yuv.max=', 252.91399999999999, 'yuv.min=', 36.07)
('yuv.max=', 207.803, 'yuv.min=', 13.870000000000001)
('yuv.max=', 253.16300000000001, 'yuv.min=', 19.481999999999999)
('yuv.max=', 195.62416000000002, 'yuv.min=', 6.8399999999999999)
('yuv.max=', 242.56400000000002, 'yuv.min=', 32.286000000000001)
('yuv.max=', 195.38899999999998, 'yuv.min=', 37.420999999999999)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 190.25200000000001, 'yuv.min=', 21.704999999999998)
('yuv.max=', 255.0, 'yuv.min=', 10.935)
('yuv.max=', 250.99999999999997, 'yuv.min=', 19.0)
('yuv.max=', 238.98299999999998, 'yuv.min=', 54.467999999999996)
('yuv.max=', 166.12100000000001, 'yuv.min=', 19.771999999999998)
('yuv.max=', 209.81299999999999, 'yuv.min=', 42.875)
('yuv.max=', 249.03200000000001, 'yuv.min=', 0.0)
('yuv.max=', 254.10300000000001, 'yuv.min=', 0.89700000000000002)
('yuv.max=', 218.0, 'yuv.min=', 31.0)
('yuv.max=', 196.91199999999998, 'yuv.min=', 40.715999999999994)
('yuv.max=', 250.28999999999999, 'yuv.min=', 58.153999999999996)
('yuv.max=', 245.59999999999999, 'yuv.min=', 42.097999999999999)
('yuv.max=', 241.33700000000002, 'yuv.min=', 12.097)
('yuv.max=', 204.45542399999999, 'yuv.min=', 10.603999999999999)
('yuv.max=', 246.0, 'yuv.min=', 12.0)
('yuv.max=', 244.58700000000002, 'yuv.min=', 31.765000000000001)
('yuv.max=', 247.89599999999999, 'yuv.min=', 6.5979999999999999)
('yuv.max=', 216.64691200000001, 'yuv.min=', 19.219000000000001)
('yuv.max=', 238.50800000000001, 'yuv.min=', 13.198)
('yuv.max=', 237.79300000000001, 'yuv.min=', 27.745999999999999)
('yuv.max=', 190.26300000000001, 'yuv.min=', 33.781999999999996)
('yuv.max=', 225.101, 'yuv.min=', 56.539000000000001)
('yuv.max=', 223.25599999999997, 'yuv.min=', 9.2840000000000007)
('yuv.max=', 234.08499999999998, 'yuv.min=', 0.0)
('yuv.max=', 230.928, 'yuv.min=', 0.0)
('yuv.max=', 236.39299999999997, 'yuv.min=', 62.156999999999996)
('yuv.max=', 239.45599999999996, 'yuv.min=', 1.8690000000000002)
('yuv.max=', 246.858, 'yuv.min=', 1.1400000000000001)
('yuv.max=', 246.02799999999996, 'yuv.min=', 32.631488000000004)
('yuv.max=', 251.42299999999997, 'yuv.min=', 0.0)
('yuv.max=', 254.08800000000002, 'yuv.min=', 47.528999999999996)
('yuv.max=', 240.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 55.506208000000001)
('yuv.max=', 252.40799999999999, 'yuv.min=', 35.341999999999999)
('yuv.max=', 248.59399999999999, 'yuv.min=', 18.523)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 250.23399999999998, 'yuv.min=', 0.58699999999999997)
('yuv.max=', 218.554, 'yuv.min=', 0.755)
('yuv.max=', 249.815, 'yuv.min=', 11.700999999999999)
('yuv.max=', 246.91199999999998, 'yuv.min=', 28.271000000000001)
('yuv.max=', 244.84899999999999, 'yuv.min=', 0.0)
('yuv.max=', 241.35299999999998, 'yuv.min=', 12.907999999999999)
('yuv.max=', 234.35099999999997, 'yuv.min=', 2.3810000000000002)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7490 ', 'GAN acc 0.5039', 'Discriminator loss 0.7460', 'Discriminator accuracy 0.4980', 'Total loss: 1.4950', 'for batch', 0)
('GAN loss 0.6940 ', 'GAN acc 0.5391', 'Discriminator loss 0.7709', 'Discriminator accuracy 0.5039', 'Total loss: 1.4649', 'for batch', 1)
('GAN loss 0.7791 ', 'GAN acc 0.5078', 'Discriminator loss 0.8003', 'Discriminator accuracy 0.4844', 'Total loss: 1.5794', 'for batch', 2)
('GAN loss 0.8832 ', 'GAN acc 0.3672', 'Discriminator loss 0.7549', 'Discriminator accuracy 0.5332', 'Total loss: 1.6380', 'for batch', 3)
('GAN loss 0.7885 ', 'GAN acc 0.4375', 'Discriminator loss 0.7689', 'Discriminator accuracy 0.4785', 'Total loss: 1.5574', 'for batch', 4)
('GAN loss 0.7394 ', 'GAN acc 0.4922', 'Discriminator loss 0.7768', 'Discriminator accuracy 0.4766', 'Total loss: 1.5162', 'for batch', 5)
('GAN loss 0.7460 ', 'GAN acc 0.4727', 'Discriminator loss 0.7120', 'Discriminator accuracy 0.5371', 'Total loss: 1.4579', 'for batch', 6)
('GAN loss 0.8483 ', 'GAN acc 0.3594', 'Discriminator loss 0.7138', 'Discriminator accuracy 0.5312', 'Total loss: 1.5621', 'for batch', 7)
('GAN loss 0.7890 ', 'GAN acc 0.3984', 'Discriminator loss 0.7303', 'Discriminator accuracy 0.5488', 'Total loss: 1.5193', 'for batch', 8)
('GAN loss 0.9399 ', 'GAN acc 0.2734', 'Discriminator loss 0.7086', 'Discriminator accuracy 0.5352', 'Total loss: 1.6486', 'for batch', 9)
('GAN loss 1.0000 ', 'GAN acc 0.2344', 'Discriminator loss 0.6567', 'Discriminator accuracy 0.6016', 'Total loss: 1.6566', 'for batch', 10)
('GAN loss 1.0320 ', 'GAN acc 0.2578', 'Discriminator loss 0.6680', 'Discriminator accuracy 0.6074', 'Total loss: 1.7000', 'for batch', 11)
('GAN loss 1.0048 ', 'GAN acc 0.2422', 'Discriminator loss 0.6010', 'Discriminator accuracy 0.6992', 'Total loss: 1.6057', 'for batch', 12)
('GAN loss 1.0551 ', 'GAN acc 0.2070', 'Discriminator loss 0.6076', 'Discriminator accuracy 0.7031', 'Total loss: 1.6626', 'for batch', 13)
('GAN loss 1.1186 ', 'GAN acc 0.1602', 'Discriminator loss 0.5856', 'Discriminator accuracy 0.7012', 'Total loss: 1.7042', 'for batch', 14)
('GAN loss 1.1628 ', 'GAN acc 0.1602', 'Discriminator loss 0.5923', 'Discriminator accuracy 0.6973', 'Total loss: 1.7551', 'for batch', 15)
('GAN loss 1.1203 ', 'GAN acc 0.2070', 'Discriminator loss 0.5899', 'Discriminator accuracy 0.7188', 'Total loss: 1.7102', 'for batch', 16)
('GAN loss 1.1420 ', 'GAN acc 0.1680', 'Discriminator loss 0.5657', 'Discriminator accuracy 0.7324', 'Total loss: 1.7077', 'for batch', 17)
('GAN loss 1.1878 ', 'GAN acc 0.1367', 'Discriminator loss 0.5548', 'Discriminator accuracy 0.7402', 'Total loss: 1.7426', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.81055164)
('DISCRIMINATOR_Imagem FAKE=', 0.6419701)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.37635803222656, 'rgb.min=', -226.60008239746094)
('rgb.max=', 136.17384338378906, 'rgb.min=', -226.74610900878906)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.72245788574219)
('rgb.max=', 136.45703125, 'rgb.min=', -226.69314575195312)
('rgb.max=', 136.34544372558594, 'rgb.min=', -226.75262451171875)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.30075073242188, 'rgb.min=', -226.70826721191406)
('rgb.max=', 136.36402893066406, 'rgb.min=', -226.80795288085938)
('rgb.max=', 136.349853515625, 'rgb.min=', -226.76876831054688)
('rgb.max=', 136.14549255371094, 'rgb.min=', -226.64231872558594)
('rgb.max=', 136.1649169921875, 'rgb.min=', -226.74053955078125)
('rgb.max=', 136.326904296875, 'rgb.min=', -226.78773498535156)
('rgb.max=', 136.28106689453125, 'rgb.min=', -226.81242370605469)
('rgb.max=', 136.198974609375, 'rgb.min=', -226.72944641113281)
('rgb.max=', 136.21896362304688, 'rgb.min=', -226.76571655273438)
('rgb.max=', 136.23114013671875, 'rgb.min=', -226.75900268554688)
('rgb.max=', 136.3084716796875, 'rgb.min=', -226.75274658203125)
('rgb.max=', 136.171875, 'rgb.min=', -226.60636901855469)
('rgb.max=', 136.40895080566406, 'rgb.min=', -226.71580505371094)
('rgb.max=', 136.39930725097656, 'rgb.min=', -226.75746154785156)
('rgb.max=', 136.4329833984375, 'rgb.min=', -226.78666687011719)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.68856811523438)
('rgb.max=', 136.45097351074219, 'rgb.min=', -226.49050903320312)
('rgb.max=', 136.36459350585938, 'rgb.min=', -226.175537109375)
('rgb.max=', 136.2681884765625, 'rgb.min=', -226.73687744140625)
('rgb.max=', 136.45445251464844, 'rgb.min=', -226.75912475585938)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81138610839844)
('rgb.max=', 136.29490661621094, 'rgb.min=', -226.5638427734375)
('rgb.max=', 136.22793579101562, 'rgb.min=', -226.5789794921875)
('rgb.max=', 136.26594543457031, 'rgb.min=', -226.79319763183594)
('rgb.max=', 136.33229064941406, 'rgb.min=', -226.75390625)
('rgb.max=', 136.21768188476562, 'rgb.min=', -226.77337646484375)
('rgb.max=', 136.27908325195312, 'rgb.min=', -226.77883911132812)
('rgb.max=', 136.29327392578125, 'rgb.min=', -226.75796508789062)
('rgb.max=', 136.26925659179688, 'rgb.min=', -226.77330017089844)
('rgb.max=', 136.39260864257812, 'rgb.min=', -226.75401306152344)
('rgb.max=', 136.43136596679688, 'rgb.min=', -226.69422912597656)
('rgb.max=', 136.42796325683594, 'rgb.min=', -226.8074951171875)
('rgb.max=', 136.16860961914062, 'rgb.min=', -226.72148132324219)
('rgb.max=', 136.16326904296875, 'rgb.min=', -226.79794311523438)
('rgb.max=', 136.183837890625, 'rgb.min=', -226.65403747558594)
('rgb.max=', 136.44482421875, 'rgb.min=', -226.5992431640625)
('rgb.max=', 136.23431396484375, 'rgb.min=', -226.76495361328125)
('rgb.max=', 136.23277282714844, 'rgb.min=', -226.66976928710938)
('rgb.max=', 136.267333984375, 'rgb.min=', -226.81280517578125)
('rgb.max=', 136.01640319824219, 'rgb.min=', -226.72634887695312)
('rgb.max=', 136.38302612304688, 'rgb.min=', -226.72970581054688)
('rgb.max=', 136.16136169433594, 'rgb.min=', -226.38825988769531)
('rgb.max=', 136.26235961914062, 'rgb.min=', -226.68789672851562)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.41729736328125, 'rgb.min=', -226.79824829101562)
('rgb.max=', 136.43841552734375, 'rgb.min=', -226.75469970703125)
('rgb.max=', 136.16169738769531, 'rgb.min=', -226.78396606445312)
('rgb.max=', 136.1622314453125, 'rgb.min=', -226.65628051757812)
('rgb.max=', 136.38211059570312, 'rgb.min=', -226.77812194824219)
('rgb.max=', 136.40811157226562, 'rgb.min=', -226.81369018554688)
('rgb.max=', 136.38836669921875, 'rgb.min=', -226.76914978027344)
('rgb.max=', 136.24482727050781, 'rgb.min=', -226.6439208984375)
('rgb.max=', 136.13528442382812, 'rgb.min=', -226.77156066894531)
('rgb.max=', 136.05447387695312, 'rgb.min=', -226.76385498046875)
('rgb.max=', 136.40092468261719, 'rgb.min=', -226.74641418457031)
('rgb.max=', 136.08573913574219, 'rgb.min=', -226.57640075683594)
('rgb.max=', 136.19454956054688, 'rgb.min=', -226.75883483886719)
('rgb.max=', 136.24453735351562, 'rgb.min=', -226.77633666992188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.48591613769531)
('rgb.max=', 136.29019165039062, 'rgb.min=', -226.81376647949219)
('rgb.max=', 136.0618896484375, 'rgb.min=', -226.70451354980469)
('rgb.max=', 136.23307800292969, 'rgb.min=', -226.77423095703125)
('rgb.max=', 136.39582824707031, 'rgb.min=', -226.8101806640625)
('rgb.max=', 136.38038635253906, 'rgb.min=', -226.79638671875)
('rgb.max=', 136.43270874023438, 'rgb.min=', -226.78717041015625)
('rgb.max=', 136.1553955078125, 'rgb.min=', -226.79859924316406)
('rgb.max=', 136.34811401367188, 'rgb.min=', -226.68264770507812)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.81108093261719)
('rgb.max=', 136.37336730957031, 'rgb.min=', -226.56967163085938)
('rgb.max=', 136.452880859375, 'rgb.min=', -226.81246948242188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.79060363769531)
('rgb.max=', 136.25497436523438, 'rgb.min=', -226.49836730957031)
('rgb.max=', 136.121337890625, 'rgb.min=', -226.72145080566406)
('rgb.max=', 136.4405517578125, 'rgb.min=', -226.65547180175781)
('rgb.max=', 136.34226989746094, 'rgb.min=', -226.42742919921875)
('rgb.max=', 136.31413269042969, 'rgb.min=', -226.661376953125)
('rgb.max=', 136.21578979492188, 'rgb.min=', -226.54414367675781)
('rgb.max=', 136.273681640625, 'rgb.min=', -226.62747192382812)
('rgb.max=', 136.28068542480469, 'rgb.min=', -226.80833435058594)
('rgb.max=', 136.18746948242188, 'rgb.min=', -226.81246948242188)
('rgb.max=', 136.37907409667969, 'rgb.min=', -226.68576049804688)
('rgb.max=', 136.2216796875, 'rgb.min=', -226.727783203125)
('rgb.max=', 136.40972900390625, 'rgb.min=', -226.62551879882812)
('rgb.max=', 136.0115966796875, 'rgb.min=', -226.349853515625)
('rgb.max=', 136.15841674804688, 'rgb.min=', -226.75567626953125)
('rgb.max=', 136.19679260253906, 'rgb.min=', -226.76715087890625)
('rgb.max=', 136.25836181640625, 'rgb.min=', -226.74412536621094)
('rgb.max=', 136.25318908691406, 'rgb.min=', -226.71980285644531)
('rgb.max=', 136.25477600097656, 'rgb.min=', -226.61668395996094)
('rgb.max=', 136.30908203125, 'rgb.min=', -226.66433715820312)
('rgb.max=', 136.34062194824219, 'rgb.min=', -226.69427490234375)
('rgb.max=', 136.40498352050781, 'rgb.min=', -226.81013488769531)
('rgb.max=', 136.20843505859375, 'rgb.min=', -226.7879638671875)
('rgb.max=', 136.42453002929688, 'rgb.min=', -226.60479736328125)
('rgb.max=', 136.29551696777344, 'rgb.min=', -226.76351928710938)
('rgb.max=', 136.25840759277344, 'rgb.min=', -226.78196716308594)
('rgb.max=', 136.21954345703125, 'rgb.min=', -226.74456787109375)
('rgb.max=', 136.31234741210938, 'rgb.min=', -226.63069152832031)
('rgb.max=', 136.30632019042969, 'rgb.min=', -226.63020324707031)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74200439453125)
('rgb.max=', 136.357421875, 'rgb.min=', -226.74555969238281)
('rgb.max=', 136.41619873046875, 'rgb.min=', -226.69012451171875)
('rgb.max=', 136.43757629394531, 'rgb.min=', -226.77838134765625)
('rgb.max=', 136.24382019042969, 'rgb.min=', -226.718994140625)
('rgb.max=', 136.40145874023438, 'rgb.min=', -226.74546813964844)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74627685546875)
('rgb.max=', 136.21661376953125, 'rgb.min=', -226.54183959960938)
('rgb.max=', 136.32601928710938, 'rgb.min=', -226.639404296875)
('rgb.max=', 136.30526733398438, 'rgb.min=', -226.68557739257812)
('rgb.max=', 136.32235717773438, 'rgb.min=', -226.73316955566406)
('rgb.max=', 136.13363647460938, 'rgb.min=', -226.80854797363281)
('rgb.max=', 136.20906066894531, 'rgb.min=', -226.68290710449219)
('rgb.max=', 136.31640625, 'rgb.min=', -226.72731018066406)
('rgb.max=', 136.39236450195312, 'rgb.min=', -226.52487182617188)
('rgb.max=', 136.44491577148438, 'rgb.min=', -226.814208984375)
('rgb.max=', 136.44967651367188, 'rgb.min=', -226.77900695800781)
('rgb.max=', 136.31095886230469, 'rgb.min=', -226.64344787597656)
('rgb.max=', 136.3809814453125, 'rgb.min=', -226.75601196289062)
('rgb.max=', 136.2269287109375, 'rgb.min=', -226.64390563964844)
('rgb.max=', 136.44044494628906, 'rgb.min=', -226.74992370605469)
('rgb.max=', 136.32005310058594, 'rgb.min=', -226.64726257324219)
('rgb.max=', 136.43096923828125, 'rgb.min=', -226.6446533203125)
('rgb.max=', 136.18409729003906, 'rgb.min=', -226.68101501464844)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74931335449219)
('rgb.max=', 136.40476989746094, 'rgb.min=', -226.74620056152344)
('rgb.max=', 136.15948486328125, 'rgb.min=', -226.63279724121094)
('rgb.max=', 136.33744812011719, 'rgb.min=', -226.7193603515625)
('rgb.max=', 136.43763732910156, 'rgb.min=', -226.59677124023438)
('rgb.max=', 136.38397216796875, 'rgb.min=', -226.75120544433594)
('rgb.max=', 136.28289794921875, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.41378784179688, 'rgb.min=', -226.75927734375)
('rgb.max=', 136.26826477050781, 'rgb.min=', -226.6900634765625)
('rgb.max=', 136.34927368164062, 'rgb.min=', -226.80636596679688)
('rgb.max=', 136.28129577636719, 'rgb.min=', -226.57177734375)
('rgb.max=', 136.36642456054688, 'rgb.min=', -226.71157836914062)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71513366699219)
('rgb.max=', 136.16947937011719, 'rgb.min=', -226.75459289550781)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.69314575195312)
('rgb.max=', 136.41709899902344, 'rgb.min=', -226.66575622558594)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.53898620605469)
('rgb.max=', 136.41757202148438, 'rgb.min=', -226.71598815917969)
('rgb.max=', 136.44781494140625, 'rgb.min=', -226.76094055175781)
('rgb.max=', 136.43528747558594, 'rgb.min=', -226.6395263671875)
('rgb.max=', 136.34957885742188, 'rgb.min=', -226.66462707519531)
('rgb.max=', 136.20838928222656, 'rgb.min=', -226.6981201171875)
('rgb.max=', 136.29646301269531, 'rgb.min=', -226.66387939453125)
('rgb.max=', 136.34672546386719, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.37033081054688, 'rgb.min=', -226.8006591796875)
('rgb.max=', 136.30714416503906, 'rgb.min=', -226.65638732910156)
('rgb.max=', 136.43075561523438, 'rgb.min=', -226.50436401367188)
('rgb.max=', 136.44990539550781, 'rgb.min=', -226.77662658691406)
('rgb.max=', 136.30010986328125, 'rgb.min=', -226.67556762695312)
('rgb.max=', 136.25830078125, 'rgb.min=', -226.70480346679688)
('rgb.max=', 136.11306762695312, 'rgb.min=', -226.70881652832031)
('rgb.max=', 136.20021057128906, 'rgb.min=', -226.59381103515625)
('rgb.max=', 136.38774108886719, 'rgb.min=', -226.74267578125)
('rgb.max=', 136.27442932128906, 'rgb.min=', -226.65130615234375)
('rgb.max=', 136.17570495605469, 'rgb.min=', -226.695556640625)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71760559082031)
('rgb.max=', 136.30101013183594, 'rgb.min=', -226.68516540527344)
('rgb.max=', 136.40142822265625, 'rgb.min=', -226.79248046875)
('rgb.max=', 136.1094970703125, 'rgb.min=', -226.50286865234375)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78860473632812)
('rgb.max=', 136.38351440429688, 'rgb.min=', -226.79190063476562)
('rgb.max=', 136.2801513671875, 'rgb.min=', -226.80653381347656)
('rgb.max=', 136.45108032226562, 'rgb.min=', -226.705078125)
('rgb.max=', 136.25990295410156, 'rgb.min=', -226.80018615722656)
('rgb.max=', 136.45187377929688, 'rgb.min=', -226.7593994140625)
('rgb.max=', 136.41766357421875, 'rgb.min=', -226.79170227050781)
('rgb.max=', 136.43572998046875, 'rgb.min=', -226.78521728515625)
('rgb.max=', 136.43580627441406, 'rgb.min=', -226.76109313964844)
('rgb.max=', 136.29263305664062, 'rgb.min=', -226.75787353515625)
('rgb.max=', 136.1546630859375, 'rgb.min=', -226.77751159667969)
('rgb.max=', 136.26554870605469, 'rgb.min=', -226.62782287597656)
('rgb.max=', 136.32408142089844, 'rgb.min=', -226.72108459472656)
('rgb.max=', 136.43930053710938, 'rgb.min=', -226.67752075195312)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.80795288085938)
('rgb.max=', 136.33563232421875, 'rgb.min=', -226.5980224609375)
('rgb.max=', 136.364013671875, 'rgb.min=', -226.679443359375)
('rgb.max=', 136.25544738769531, 'rgb.min=', -226.73846435546875)
('rgb.max=', 136.22087097167969, 'rgb.min=', -226.68362426757812)
('rgb.max=', 136.24305725097656, 'rgb.min=', -226.56831359863281)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.35325622558594)
('rgb.max=', 136.38014221191406, 'rgb.min=', -226.72792053222656)
('rgb.max=', 136.39132690429688, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.10240173339844, 'rgb.min=', -226.58688354492188)
('rgb.max=', 136.43551635742188, 'rgb.min=', -226.53610229492188)
('rgb.max=', 136.43388366699219, 'rgb.min=', -226.61257934570312)
('rgb.max=', 136.23617553710938, 'rgb.min=', -226.73391723632812)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.40815734863281)
('rgb.max=', 136.00518798828125, 'rgb.min=', -226.67428588867188)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.76516723632812)
('rgb.max=', 136.20819091796875, 'rgb.min=', -226.75715637207031)
('rgb.max=', 136.36239624023438, 'rgb.min=', -226.64079284667969)
('rgb.max=', 136.42793273925781, 'rgb.min=', -226.75172424316406)
('rgb.max=', 136.38784790039062, 'rgb.min=', -226.81117248535156)
('rgb.max=', 136.40182495117188, 'rgb.min=', -226.794921875)
('rgb.max=', 136.3475341796875, 'rgb.min=', -226.70463562011719)
('rgb.max=', 136.39482116699219, 'rgb.min=', -226.79986572265625)
('rgb.max=', 136.40895080566406, 'rgb.min=', -226.80905151367188)
('rgb.max=', 136.43618774414062, 'rgb.min=', -226.81465148925781)
('rgb.max=', 136.26458740234375, 'rgb.min=', -226.74490356445312)
('rgb.max=', 136.45489501953125, 'rgb.min=', -226.66697692871094)
('rgb.max=', 136.37141418457031, 'rgb.min=', -226.64274597167969)
('rgb.max=', 136.42440795898438, 'rgb.min=', -226.64537048339844)
('rgb.max=', 136.34597778320312, 'rgb.min=', -226.72509765625)
('rgb.max=', 136.36250305175781, 'rgb.min=', -226.67536926269531)
('rgb.max=', 136.44705200195312, 'rgb.min=', -226.69149780273438)
('rgb.max=', 136.3265380859375, 'rgb.min=', -226.68141174316406)
('rgb.max=', 136.37318420410156, 'rgb.min=', -226.70452880859375)
('rgb.max=', 136.39886474609375, 'rgb.min=', -226.55876159667969)
('rgb.max=', 136.31509399414062, 'rgb.min=', -226.7498779296875)
('rgb.max=', 136.43803405761719, 'rgb.min=', -226.79202270507812)
('rgb.max=', 136.14186096191406, 'rgb.min=', -226.72628784179688)
('rgb.max=', 136.30377197265625, 'rgb.min=', -226.51374816894531)
('rgb.max=', 136.12252807617188, 'rgb.min=', -226.72651672363281)
('rgb.max=', 136.42364501953125, 'rgb.min=', -226.81134033203125)
('rgb.max=', 136.3570556640625, 'rgb.min=', -226.68560791015625)
('rgb.max=', 136.24911499023438, 'rgb.min=', -226.74916076660156)
('rgb.max=', 136.439208984375, 'rgb.min=', -226.63227844238281)
('rgb.max=', 136.43504333496094, 'rgb.min=', -226.71868896484375)
('rgb.max=', 136.31988525390625, 'rgb.min=', -226.63372802734375)
('rgb.max=', 136.1650390625, 'rgb.min=', -226.69187927246094)
('rgb.max=', 136.12904357910156, 'rgb.min=', -226.69082641601562)
('rgb.max=', 136.36386108398438, 'rgb.min=', -226.7774658203125)
('rgb.max=', 136.25689697265625, 'rgb.min=', -226.71159362792969)
('rgb.max=', 136.0823974609375, 'rgb.min=', -226.69793701171875)
('rgb.max=', 136.25904846191406, 'rgb.min=', -226.78489685058594)
('rgb.max=', 136.4521484375, 'rgb.min=', -226.8155517578125)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.71795654296875)
('rgb.max=', 136.35293579101562, 'rgb.min=', -226.81509399414062)
('rgb.max=', 136.4500732421875, 'rgb.min=', -226.81138610839844)
('rgb.max=', 136.43952941894531, 'rgb.min=', -226.35990905761719)
('rgb.max=', 136.42863464355469, 'rgb.min=', -226.81509399414062)
('rgb.max=', 136.44839477539062, 'rgb.min=', -226.72441101074219)
('rgb.max=', 136.44357299804688, 'rgb.min=', -226.80516052246094)
('rgb.max=', 136.10958862304688, 'rgb.min=', -226.51100158691406)
('rgb.max=', 136.32835388183594, 'rgb.min=', -226.80906677246094)
('rgb.max=', 136.37654113769531, 'rgb.min=', -226.79316711425781)
('rgb.max=', 136.44635009765625, 'rgb.min=', -226.75770568847656)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78897094726562)
('rgb.max=', 136.28656005859375, 'rgb.min=', -226.69625854492188)
('rgb.max=', 136.43464660644531, 'rgb.min=', -226.74417114257812)
('rgb.max=', 136.12744140625, 'rgb.min=', -226.80972290039062)
('rgb.max=', 136.24740600585938, 'rgb.min=', -226.63348388671875)
('rgb.max=', 136.33090209960938, 'rgb.min=', -226.77806091308594)
('rgb.max=', 136.21055603027344, 'rgb.min=', -226.4990234375)
('rgb.max=', 136.36270141601562, 'rgb.min=', -226.69419860839844)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78189086914062)
('rgb.max=', 136.30929565429688, 'rgb.min=', -226.65731811523438)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:45.252558')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1603 ', 'GAN acc 0.1914', 'Discriminator loss 0.5580', 'Discriminator accuracy 0.7598', 'Total loss: 1.7184', 'for batch', 0)
('GAN loss 1.3781 ', 'GAN acc 0.0898', 'Discriminator loss 0.5976', 'Discriminator accuracy 0.7051', 'Total loss: 1.9758', 'for batch', 1)
('GAN loss 1.4323 ', 'GAN acc 0.0781', 'Discriminator loss 0.5283', 'Discriminator accuracy 0.7402', 'Total loss: 1.9606', 'for batch', 2)
('GAN loss 1.1665 ', 'GAN acc 0.2031', 'Discriminator loss 0.5327', 'Discriminator accuracy 0.7422', 'Total loss: 1.6992', 'for batch', 3)
('GAN loss 1.2276 ', 'GAN acc 0.1719', 'Discriminator loss 0.5212', 'Discriminator accuracy 0.7871', 'Total loss: 1.7488', 'for batch', 4)
('GAN loss 1.2526 ', 'GAN acc 0.1289', 'Discriminator loss 0.5307', 'Discriminator accuracy 0.7871', 'Total loss: 1.7833', 'for batch', 5)
('GAN loss 1.3484 ', 'GAN acc 0.1367', 'Discriminator loss 0.5524', 'Discriminator accuracy 0.7344', 'Total loss: 1.9007', 'for batch', 6)
('GAN loss 1.4153 ', 'GAN acc 0.1016', 'Discriminator loss 0.5431', 'Discriminator accuracy 0.7324', 'Total loss: 1.9584', 'for batch', 7)
('GAN loss 1.1813 ', 'GAN acc 0.2070', 'Discriminator loss 0.5189', 'Discriminator accuracy 0.7832', 'Total loss: 1.7002', 'for batch', 8)
('GAN loss 1.2761 ', 'GAN acc 0.1523', 'Discriminator loss 0.5946', 'Discriminator accuracy 0.6992', 'Total loss: 1.8707', 'for batch', 9)
('GAN loss 1.3987 ', 'GAN acc 0.1445', 'Discriminator loss 0.5522', 'Discriminator accuracy 0.7188', 'Total loss: 1.9509', 'for batch', 10)
('GAN loss 1.4491 ', 'GAN acc 0.1484', 'Discriminator loss 0.6541', 'Discriminator accuracy 0.6387', 'Total loss: 2.1032', 'for batch', 11)
('GAN loss 1.3526 ', 'GAN acc 0.1758', 'Discriminator loss 0.6733', 'Discriminator accuracy 0.5410', 'Total loss: 2.0259', 'for batch', 12)
('GAN loss 1.1747 ', 'GAN acc 0.2422', 'Discriminator loss 0.6140', 'Discriminator accuracy 0.6113', 'Total loss: 1.7887', 'for batch', 13)
('GAN loss 1.1462 ', 'GAN acc 0.2344', 'Discriminator loss 0.6194', 'Discriminator accuracy 0.6562', 'Total loss: 1.7656', 'for batch', 14)
('GAN loss 1.2588 ', 'GAN acc 0.1719', 'Discriminator loss 0.6550', 'Discriminator accuracy 0.6348', 'Total loss: 1.9137', 'for batch', 15)
('GAN loss 1.2227 ', 'GAN acc 0.1836', 'Discriminator loss 0.6481', 'Discriminator accuracy 0.6211', 'Total loss: 1.8708', 'for batch', 16)
('GAN loss 1.0139 ', 'GAN acc 0.2930', 'Discriminator loss 0.6427', 'Discriminator accuracy 0.5996', 'Total loss: 1.6567', 'for batch', 17)
('GAN loss 1.0432 ', 'GAN acc 0.2344', 'Discriminator loss 0.6137', 'Discriminator accuracy 0.6738', 'Total loss: 1.6568', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.86123317)
('DISCRIMINATOR_Imagem FAKE=', 0.80356359)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.22798156738281, 'rgb.min=', -226.37844848632812)
('rgb.max=', 135.99676513671875, 'rgb.min=', -226.74610900878906)
('rgb.max=', 136.35171508789062, 'rgb.min=', -226.48883056640625)
('rgb.max=', 136.26713562011719, 'rgb.min=', -226.62228393554688)
('rgb.max=', 136.16148376464844, 'rgb.min=', -226.6422119140625)
('rgb.max=', 136.45651245117188, 'rgb.min=', -226.81599426269531)
('rgb.max=', 135.96641540527344, 'rgb.min=', -226.70826721191406)
('rgb.max=', 136.306640625, 'rgb.min=', -226.53233337402344)
('rgb.max=', 136.181396484375, 'rgb.min=', -226.64959716796875)
('rgb.max=', 136.02474975585938, 'rgb.min=', -226.60191345214844)
('rgb.max=', 136.04020690917969, 'rgb.min=', -226.74053955078125)
('rgb.max=', 135.93632507324219, 'rgb.min=', -226.75672912597656)
('rgb.max=', 136.12615966796875, 'rgb.min=', -226.53373718261719)
('rgb.max=', 135.99882507324219, 'rgb.min=', -226.55499267578125)
('rgb.max=', 136.01405334472656, 'rgb.min=', -226.76571655273438)
('rgb.max=', 135.90542602539062, 'rgb.min=', -226.75900268554688)
('rgb.max=', 136.3084716796875, 'rgb.min=', -226.71530151367188)
('rgb.max=', 136.01882934570312, 'rgb.min=', -226.55204772949219)
('rgb.max=', 136.15821838378906, 'rgb.min=', -226.71833801269531)
('rgb.max=', 136.272705078125, 'rgb.min=', -226.75746154785156)
('rgb.max=', 136.26255798339844, 'rgb.min=', -226.00314331054688)
('rgb.max=', 136.30488586425781, 'rgb.min=', -226.51133728027344)
('rgb.max=', 136.33828735351562, 'rgb.min=', -226.34541320800781)
('rgb.max=', 136.19389343261719, 'rgb.min=', -226.08699035644531)
('rgb.max=', 135.93635559082031, 'rgb.min=', -226.73147583007812)
('rgb.max=', 136.30313110351562, 'rgb.min=', -226.75912475585938)
('rgb.max=', 136.31098937988281, 'rgb.min=', -226.79254150390625)
('rgb.max=', 136.12258911132812, 'rgb.min=', -226.51898193359375)
('rgb.max=', 135.8819580078125, 'rgb.min=', -226.56990051269531)
('rgb.max=', 136.16024780273438, 'rgb.min=', -226.59490966796875)
('rgb.max=', 136.03128051757812, 'rgb.min=', -226.16923522949219)
('rgb.max=', 136.03228759765625, 'rgb.min=', -226.46728515625)
('rgb.max=', 136.23869323730469, 'rgb.min=', -226.03611755371094)
('rgb.max=', 136.24972534179688, 'rgb.min=', -226.75796508789062)
('rgb.max=', 136.05157470703125, 'rgb.min=', -226.77330017089844)
('rgb.max=', 136.07254028320312, 'rgb.min=', -226.55624389648438)
('rgb.max=', 136.20750427246094, 'rgb.min=', -226.58491516113281)
('rgb.max=', 136.33406066894531, 'rgb.min=', -226.79460144042969)
('rgb.max=', 136.03985595703125, 'rgb.min=', -226.11288452148438)
('rgb.max=', 136.00704956054688, 'rgb.min=', -226.1195068359375)
('rgb.max=', 135.9376220703125, 'rgb.min=', -226.55282592773438)
('rgb.max=', 136.15029907226562, 'rgb.min=', -226.5992431640625)
('rgb.max=', 136.07389831542969, 'rgb.min=', -226.65863037109375)
('rgb.max=', 136.0684814453125, 'rgb.min=', -226.66976928710938)
('rgb.max=', 136.16647338867188, 'rgb.min=', -226.81280517578125)
('rgb.max=', 135.93954467773438, 'rgb.min=', -226.38121032714844)
('rgb.max=', 136.28202819824219, 'rgb.min=', -226.72970581054688)
('rgb.max=', 136.05633544921875, 'rgb.min=', -226.36680603027344)
('rgb.max=', 136.25067138671875, 'rgb.min=', -226.67341613769531)
('rgb.max=', 136.35903930664062, 'rgb.min=', -226.80691528320312)
('rgb.max=', 136.37840270996094, 'rgb.min=', -226.78944396972656)
('rgb.max=', 136.397705078125, 'rgb.min=', -226.74411010742188)
('rgb.max=', 135.98115539550781, 'rgb.min=', -226.54672241210938)
('rgb.max=', 135.99470520019531, 'rgb.min=', -226.56842041015625)
('rgb.max=', 136.29226684570312, 'rgb.min=', -226.66413879394531)
('rgb.max=', 136.16696166992188, 'rgb.min=', -226.44096374511719)
('rgb.max=', 136.33529663085938, 'rgb.min=', -226.72920227050781)
('rgb.max=', 136.19137573242188, 'rgb.min=', -226.59861755371094)
('rgb.max=', 136.00450134277344, 'rgb.min=', -226.24447631835938)
('rgb.max=', 135.99208068847656, 'rgb.min=', -226.76385498046875)
('rgb.max=', 136.11888122558594, 'rgb.min=', -226.63650512695312)
('rgb.max=', 135.99008178710938, 'rgb.min=', -226.54167175292969)
('rgb.max=', 136.19454956054688, 'rgb.min=', -226.75883483886719)
('rgb.max=', 136.05519104003906, 'rgb.min=', -226.77633666992188)
('rgb.max=', 136.26353454589844, 'rgb.min=', -226.27784729003906)
('rgb.max=', 136.12631225585938, 'rgb.min=', -226.70457458496094)
('rgb.max=', 135.98855590820312, 'rgb.min=', -226.33319091796875)
('rgb.max=', 136.10302734375, 'rgb.min=', -226.77423095703125)
('rgb.max=', 136.1158447265625, 'rgb.min=', -226.80513000488281)
('rgb.max=', 136.22590637207031, 'rgb.min=', -226.79638671875)
('rgb.max=', 136.250732421875, 'rgb.min=', -226.78410339355469)
('rgb.max=', 136.1060791015625, 'rgb.min=', -226.79859924316406)
('rgb.max=', 136.15510559082031, 'rgb.min=', -226.62699890136719)
('rgb.max=', 136.18162536621094, 'rgb.min=', -226.78144836425781)
('rgb.max=', 136.08155822753906, 'rgb.min=', -226.20053100585938)
('rgb.max=', 136.10873413085938, 'rgb.min=', -226.50164794921875)
('rgb.max=', 136.291015625, 'rgb.min=', -226.73329162597656)
('rgb.max=', 136.24179077148438, 'rgb.min=', -226.05192565917969)
('rgb.max=', 136.09059143066406, 'rgb.min=', -226.72145080566406)
('rgb.max=', 136.20330810546875, 'rgb.min=', -226.58686828613281)
('rgb.max=', 136.30189514160156, 'rgb.min=', -225.94564819335938)
('rgb.max=', 136.21214294433594, 'rgb.min=', -226.661376953125)
('rgb.max=', 136.04377746582031, 'rgb.min=', -226.54414367675781)
('rgb.max=', 136.20637512207031, 'rgb.min=', -226.62747192382812)
('rgb.max=', 136.2340087890625, 'rgb.min=', -226.80833435058594)
('rgb.max=', 136.01181030273438, 'rgb.min=', -226.60514831542969)
('rgb.max=', 136.11880493164062, 'rgb.min=', -226.08522033691406)
('rgb.max=', 136.05085754394531, 'rgb.min=', -226.47137451171875)
('rgb.max=', 136.23661804199219, 'rgb.min=', -226.62551879882812)
('rgb.max=', 135.94956970214844, 'rgb.min=', -226.337646484375)
('rgb.max=', 136.14999389648438, 'rgb.min=', -226.75567626953125)
('rgb.max=', 136.19679260253906, 'rgb.min=', -226.76715087890625)
('rgb.max=', 136.08575439453125, 'rgb.min=', -226.74412536621094)
('rgb.max=', 136.05072021484375, 'rgb.min=', -226.71980285644531)
('rgb.max=', 136.07156372070312, 'rgb.min=', -226.33145141601562)
('rgb.max=', 136.2255859375, 'rgb.min=', -226.00314331054688)
('rgb.max=', 135.99649047851562, 'rgb.min=', -226.40153503417969)
('rgb.max=', 136.11776733398438, 'rgb.min=', -226.81013488769531)
('rgb.max=', 136.04534912109375, 'rgb.min=', -226.66976928710938)
('rgb.max=', 136.26472473144531, 'rgb.min=', -226.59471130371094)
('rgb.max=', 136.19009399414062, 'rgb.min=', -226.76351928710938)
('rgb.max=', 135.97357177734375, 'rgb.min=', -226.60118103027344)
('rgb.max=', 136.07310485839844, 'rgb.min=', -226.06748962402344)
('rgb.max=', 136.19758605957031, 'rgb.min=', -226.47100830078125)
('rgb.max=', 136.180419921875, 'rgb.min=', -226.44638061523438)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.74200439453125)
('rgb.max=', 136.12945556640625, 'rgb.min=', -226.57293701171875)
('rgb.max=', 136.32391357421875, 'rgb.min=', -226.69012451171875)
('rgb.max=', 136.276123046875, 'rgb.min=', -225.88368225097656)
('rgb.max=', 136.12777709960938, 'rgb.min=', -226.03633117675781)
('rgb.max=', 136.29345703125, 'rgb.min=', -226.47868347167969)
('rgb.max=', 136.25552368164062, 'rgb.min=', -226.47250366210938)
('rgb.max=', 136.0670166015625, 'rgb.min=', -226.45419311523438)
('rgb.max=', 136.1871337890625, 'rgb.min=', -226.45895385742188)
('rgb.max=', 136.07977294921875, 'rgb.min=', -226.68557739257812)
('rgb.max=', 136.32235717773438, 'rgb.min=', -226.73316955566406)
('rgb.max=', 136.04473876953125, 'rgb.min=', -226.80854797363281)
('rgb.max=', 136.07200622558594, 'rgb.min=', -226.09114074707031)
('rgb.max=', 136.09840393066406, 'rgb.min=', -226.54808044433594)
('rgb.max=', 136.31114196777344, 'rgb.min=', -226.46864318847656)
('rgb.max=', 136.3153076171875, 'rgb.min=', -226.814208984375)
('rgb.max=', 136.41481018066406, 'rgb.min=', -226.77900695800781)
('rgb.max=', 136.03955078125, 'rgb.min=', -226.25068664550781)
('rgb.max=', 136.20445251464844, 'rgb.min=', -226.75601196289062)
('rgb.max=', 136.02264404296875, 'rgb.min=', -226.47904968261719)
('rgb.max=', 136.13969421386719, 'rgb.min=', -226.7449951171875)
('rgb.max=', 136.07774353027344, 'rgb.min=', -226.31124877929688)
('rgb.max=', 136.25337219238281, 'rgb.min=', -226.41136169433594)
('rgb.max=', 135.8526611328125, 'rgb.min=', -226.62939453125)
('rgb.max=', 136.39656066894531, 'rgb.min=', -226.74931335449219)
('rgb.max=', 136.34480285644531, 'rgb.min=', -226.072509765625)
('rgb.max=', 136.02641296386719, 'rgb.min=', -226.61830139160156)
('rgb.max=', 136.2156982421875, 'rgb.min=', -226.66940307617188)
('rgb.max=', 136.29148864746094, 'rgb.min=', -226.2181396484375)
('rgb.max=', 136.373046875, 'rgb.min=', -226.39218139648438)
('rgb.max=', 136.22865295410156, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.11958312988281, 'rgb.min=', -226.74794006347656)
('rgb.max=', 136.06922912597656, 'rgb.min=', -226.6900634765625)
('rgb.max=', 135.99639892578125, 'rgb.min=', -226.80244445800781)
('rgb.max=', 136.20590209960938, 'rgb.min=', -226.05900573730469)
('rgb.max=', 136.06369018554688, 'rgb.min=', -226.63935852050781)
('rgb.max=', 136.31454467773438, 'rgb.min=', -226.59136962890625)
('rgb.max=', 135.94865417480469, 'rgb.min=', -226.73361206054688)
('rgb.max=', 136.36007690429688, 'rgb.min=', -226.5521240234375)
('rgb.max=', 135.92863464355469, 'rgb.min=', -226.59819030761719)
('rgb.max=', 136.33381652832031, 'rgb.min=', -226.42721557617188)
('rgb.max=', 135.85078430175781, 'rgb.min=', -226.61328125)
('rgb.max=', 136.35385131835938, 'rgb.min=', -226.76094055175781)
('rgb.max=', 136.32589721679688, 'rgb.min=', -226.6395263671875)
('rgb.max=', 136.29768371582031, 'rgb.min=', -226.14312744140625)
('rgb.max=', 135.93243408203125, 'rgb.min=', -226.48551940917969)
('rgb.max=', 136.09982299804688, 'rgb.min=', -226.0704345703125)
('rgb.max=', 136.30961608886719, 'rgb.min=', -226.81599426269531)
('rgb.max=', 136.10733032226562, 'rgb.min=', -226.8006591796875)
('rgb.max=', 135.91087341308594, 'rgb.min=', -226.54096984863281)
('rgb.max=', 136.10116577148438, 'rgb.min=', -226.4879150390625)
('rgb.max=', 136.28433227539062, 'rgb.min=', -226.77662658691406)
('rgb.max=', 136.06973266601562, 'rgb.min=', -226.49467468261719)
('rgb.max=', 136.08821105957031, 'rgb.min=', -226.70480346679688)
('rgb.max=', 136.08131408691406, 'rgb.min=', -226.49867248535156)
('rgb.max=', 135.95951843261719, 'rgb.min=', -226.38740539550781)
('rgb.max=', 136.10067749023438, 'rgb.min=', -226.74267578125)
('rgb.max=', 136.1055908203125, 'rgb.min=', -226.65130615234375)
('rgb.max=', 136.05947875976562, 'rgb.min=', -226.69184875488281)
('rgb.max=', 136.33798217773438, 'rgb.min=', -226.18513488769531)
('rgb.max=', 136.10847473144531, 'rgb.min=', -226.05366516113281)
('rgb.max=', 136.39691162109375, 'rgb.min=', -226.79248046875)
('rgb.max=', 135.86839294433594, 'rgb.min=', -226.40641784667969)
('rgb.max=', 136.31428527832031, 'rgb.min=', -226.78860473632812)
('rgb.max=', 136.23081970214844, 'rgb.min=', -226.76741027832031)
('rgb.max=', 136.23727416992188, 'rgb.min=', -226.77505493164062)
('rgb.max=', 136.4404296875, 'rgb.min=', -226.705078125)
('rgb.max=', 136.21981811523438, 'rgb.min=', -226.15113830566406)
('rgb.max=', 136.40966796875, 'rgb.min=', -226.7593994140625)
('rgb.max=', 136.18710327148438, 'rgb.min=', -226.72042846679688)
('rgb.max=', 136.331298828125, 'rgb.min=', -226.78521728515625)
('rgb.max=', 136.43580627441406, 'rgb.min=', -226.76109313964844)
('rgb.max=', 136.18620300292969, 'rgb.min=', -226.75787353515625)
('rgb.max=', 135.93710327148438, 'rgb.min=', -226.58622741699219)
('rgb.max=', 136.05892944335938, 'rgb.min=', -226.36294555664062)
('rgb.max=', 136.17807006835938, 'rgb.min=', -226.72108459472656)
('rgb.max=', 136.28146362304688, 'rgb.min=', -226.65399169921875)
('rgb.max=', 136.1177978515625, 'rgb.min=', -226.53854370117188)
('rgb.max=', 136.13026428222656, 'rgb.min=', -226.29277038574219)
('rgb.max=', 136.12052917480469, 'rgb.min=', -226.39813232421875)
('rgb.max=', 136.19198608398438, 'rgb.min=', -226.73846435546875)
('rgb.max=', 136.03080749511719, 'rgb.min=', -226.55220031738281)
('rgb.max=', 136.1451416015625, 'rgb.min=', -226.49053955078125)
('rgb.max=', 136.31503295898438, 'rgb.min=', -225.81599426269531)
('rgb.max=', 136.32565307617188, 'rgb.min=', -226.72792053222656)
('rgb.max=', 136.21675109863281, 'rgb.min=', -226.81599426269531)
('rgb.max=', 135.90194702148438, 'rgb.min=', -226.43426513671875)
('rgb.max=', 136.142578125, 'rgb.min=', -226.21678161621094)
('rgb.max=', 136.25823974609375, 'rgb.min=', -226.60081481933594)
('rgb.max=', 136.16558837890625, 'rgb.min=', -226.73391723632812)
('rgb.max=', 136.31942749023438, 'rgb.min=', -225.81599426269531)
('rgb.max=', 135.9736328125, 'rgb.min=', -226.3402099609375)
('rgb.max=', 136.20806884765625, 'rgb.min=', -226.76516723632812)
('rgb.max=', 136.01303100585938, 'rgb.min=', -226.75715637207031)
('rgb.max=', 136.14651489257812, 'rgb.min=', -226.55845642089844)
('rgb.max=', 136.03363037109375, 'rgb.min=', -226.69020080566406)
('rgb.max=', 136.08895874023438, 'rgb.min=', -225.67160034179688)
('rgb.max=', 136.28718566894531, 'rgb.min=', -226.79452514648438)
('rgb.max=', 136.32205200195312, 'rgb.min=', -226.46992492675781)
('rgb.max=', 136.23757934570312, 'rgb.min=', -226.79986572265625)
('rgb.max=', 136.13740539550781, 'rgb.min=', -226.80905151367188)
('rgb.max=', 136.07955932617188, 'rgb.min=', -226.76173400878906)
('rgb.max=', 136.033447265625, 'rgb.min=', -226.44758605957031)
('rgb.max=', 136.3365478515625, 'rgb.min=', -226.63560485839844)
('rgb.max=', 136.18707275390625, 'rgb.min=', -226.26333618164062)
('rgb.max=', 136.37286376953125, 'rgb.min=', -226.49447631835938)
('rgb.max=', 136.14329528808594, 'rgb.min=', -226.669921875)
('rgb.max=', 136.09053039550781, 'rgb.min=', -226.20103454589844)
('rgb.max=', 136.36871337890625, 'rgb.min=', -226.67324829101562)
('rgb.max=', 136.1378173828125, 'rgb.min=', -226.30552673339844)
('rgb.max=', 136.18443298339844, 'rgb.min=', -226.43783569335938)
('rgb.max=', 136.13662719726562, 'rgb.min=', -226.5284423828125)
('rgb.max=', 136.08145141601562, 'rgb.min=', -226.67124938964844)
('rgb.max=', 136.12255859375, 'rgb.min=', -226.79202270507812)
('rgb.max=', 136.028564453125, 'rgb.min=', -226.48269653320312)
('rgb.max=', 136.01295471191406, 'rgb.min=', -226.50338745117188)
('rgb.max=', 135.98362731933594, 'rgb.min=', -226.63490295410156)
('rgb.max=', 136.20526123046875, 'rgb.min=', -226.81134033203125)
('rgb.max=', 136.12664794921875, 'rgb.min=', -226.6373291015625)
('rgb.max=', 135.99435424804688, 'rgb.min=', -226.53128051757812)
('rgb.max=', 136.3358154296875, 'rgb.min=', -226.18853759765625)
('rgb.max=', 136.19438171386719, 'rgb.min=', -226.71868896484375)
('rgb.max=', 136.18896484375, 'rgb.min=', -226.42974853515625)
('rgb.max=', 136.05154418945312, 'rgb.min=', -226.67901611328125)
('rgb.max=', 136.03741455078125, 'rgb.min=', -226.54563903808594)
('rgb.max=', 136.17037963867188, 'rgb.min=', -226.7774658203125)
('rgb.max=', 135.87234497070312, 'rgb.min=', -226.71159362792969)
('rgb.max=', 136.05014038085938, 'rgb.min=', -226.69793701171875)
('rgb.max=', 136.03579711914062, 'rgb.min=', -226.78489685058594)
('rgb.max=', 136.36488342285156, 'rgb.min=', -226.8155517578125)
('rgb.max=', 136.32756042480469, 'rgb.min=', -226.71795654296875)
('rgb.max=', 135.91641235351562, 'rgb.min=', -226.76933288574219)
('rgb.max=', 136.35675048828125, 'rgb.min=', -226.49293518066406)
('rgb.max=', 136.26048278808594, 'rgb.min=', -225.96673583984375)
('rgb.max=', 136.35325622558594, 'rgb.min=', -226.66499328613281)
('rgb.max=', 136.1326904296875, 'rgb.min=', -226.60087585449219)
('rgb.max=', 136.19728088378906, 'rgb.min=', -226.77125549316406)
('rgb.max=', 135.96978759765625, 'rgb.min=', -226.51100158691406)
('rgb.max=', 136.27397155761719, 'rgb.min=', -226.78907775878906)
('rgb.max=', 136.26629638671875, 'rgb.min=', -226.5823974609375)
('rgb.max=', 136.27104187011719, 'rgb.min=', -225.82846069335938)
('rgb.max=', 136.45881652832031, 'rgb.min=', -226.78897094726562)
('rgb.max=', 136.03128051757812, 'rgb.min=', -226.4295654296875)
('rgb.max=', 136.08279418945312, 'rgb.min=', -226.16835021972656)
('rgb.max=', 136.05436706542969, 'rgb.min=', -226.80972290039062)
('rgb.max=', 136.04757690429688, 'rgb.min=', -226.59822082519531)
('rgb.max=', 136.11480712890625, 'rgb.min=', -226.77806091308594)
('rgb.max=', 135.99371337890625, 'rgb.min=', -226.45478820800781)
('rgb.max=', 136.10757446289062, 'rgb.min=', -226.54849243164062)
('rgb.max=', 136.17268371582031, 'rgb.min=', -226.71522521972656)
('rgb.max=', 136.02789306640625, 'rgb.min=', -226.51982116699219)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.447655')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1307 ', 'GAN acc 0.2109', 'Discriminator loss 0.6608', 'Discriminator accuracy 0.6074', 'Total loss: 1.7916', 'for batch', 0)
('GAN loss 1.0852 ', 'GAN acc 0.2266', 'Discriminator loss 0.6428', 'Discriminator accuracy 0.6152', 'Total loss: 1.7280', 'for batch', 1)
('GAN loss 0.9549 ', 'GAN acc 0.3320', 'Discriminator loss 0.6346', 'Discriminator accuracy 0.6055', 'Total loss: 1.5894', 'for batch', 2)
('GAN loss 0.8734 ', 'GAN acc 0.3555', 'Discriminator loss 0.6475', 'Discriminator accuracy 0.6016', 'Total loss: 1.5209', 'for batch', 3)
('GAN loss 0.8948 ', 'GAN acc 0.4141', 'Discriminator loss 0.6436', 'Discriminator accuracy 0.6348', 'Total loss: 1.5384', 'for batch', 4)
('GAN loss 0.8939 ', 'GAN acc 0.4023', 'Discriminator loss 0.6593', 'Discriminator accuracy 0.6113', 'Total loss: 1.5532', 'for batch', 5)
('GAN loss 0.8540 ', 'GAN acc 0.4062', 'Discriminator loss 0.6479', 'Discriminator accuracy 0.5996', 'Total loss: 1.5019', 'for batch', 6)
('GAN loss 0.8714 ', 'GAN acc 0.3672', 'Discriminator loss 0.6569', 'Discriminator accuracy 0.6191', 'Total loss: 1.5283', 'for batch', 7)
('GAN loss 0.8721 ', 'GAN acc 0.3242', 'Discriminator loss 0.6392', 'Discriminator accuracy 0.6270', 'Total loss: 1.5113', 'for batch', 8)
('GAN loss 0.8327 ', 'GAN acc 0.3867', 'Discriminator loss 0.6777', 'Discriminator accuracy 0.5605', 'Total loss: 1.5105', 'for batch', 9)
('GAN loss 0.8278 ', 'GAN acc 0.3711', 'Discriminator loss 0.6649', 'Discriminator accuracy 0.5762', 'Total loss: 1.4928', 'for batch', 10)
('GAN loss 0.7465 ', 'GAN acc 0.4922', 'Discriminator loss 0.6881', 'Discriminator accuracy 0.5605', 'Total loss: 1.4346', 'for batch', 11)
('GAN loss 0.7829 ', 'GAN acc 0.4531', 'Discriminator loss 0.6786', 'Discriminator accuracy 0.5762', 'Total loss: 1.4615', 'for batch', 12)
('GAN loss 0.7985 ', 'GAN acc 0.4297', 'Discriminator loss 0.6396', 'Discriminator accuracy 0.6270', 'Total loss: 1.4380', 'for batch', 13)
('GAN loss 0.7787 ', 'GAN acc 0.4727', 'Discriminator loss 0.6428', 'Discriminator accuracy 0.6133', 'Total loss: 1.4215', 'for batch', 14)
('GAN loss 0.7875 ', 'GAN acc 0.4766', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.6113', 'Total loss: 1.4398', 'for batch', 15)
('GAN loss 0.7867 ', 'GAN acc 0.4219', 'Discriminator loss 0.6789', 'Discriminator accuracy 0.5781', 'Total loss: 1.4656', 'for batch', 16)
('GAN loss 0.8655 ', 'GAN acc 0.3398', 'Discriminator loss 0.6773', 'Discriminator accuracy 0.5684', 'Total loss: 1.5427', 'for batch', 17)
('GAN loss 0.7929 ', 'GAN acc 0.4375', 'Discriminator loss 0.6784', 'Discriminator accuracy 0.5488', 'Total loss: 1.4713', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.83590406)
('DISCRIMINATOR_Imagem FAKE=', 0.80429602)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.20559692382812, 'rgb.min=', -226.37440490722656)
('rgb.max=', 136.00393676757812, 'rgb.min=', -226.74130249023438)
('rgb.max=', 136.05223083496094, 'rgb.min=', -226.48422241210938)
('rgb.max=', 136.20402526855469, 'rgb.min=', -226.4915771484375)
('rgb.max=', 136.30317687988281, 'rgb.min=', -226.42997741699219)
('rgb.max=', 136.24977111816406, 'rgb.min=', -226.79112243652344)
('rgb.max=', 135.91372680664062, 'rgb.min=', -226.70826721191406)
('rgb.max=', 136.00350952148438, 'rgb.min=', -226.22850036621094)
('rgb.max=', 136.12249755859375, 'rgb.min=', -226.29734802246094)
('rgb.max=', 135.84364318847656, 'rgb.min=', -226.52778625488281)
('rgb.max=', 135.95985412597656, 'rgb.min=', -226.73490905761719)
('rgb.max=', 135.97943115234375, 'rgb.min=', -226.47427368164062)
('rgb.max=', 135.91200256347656, 'rgb.min=', -226.51020812988281)
('rgb.max=', 136.02847290039062, 'rgb.min=', -226.59500122070312)
('rgb.max=', 135.96464538574219, 'rgb.min=', -226.68133544921875)
('rgb.max=', 135.88410949707031, 'rgb.min=', -226.33000183105469)
('rgb.max=', 136.09579467773438, 'rgb.min=', -226.36300659179688)
('rgb.max=', 135.9674072265625, 'rgb.min=', -226.23959350585938)
('rgb.max=', 136.13458251953125, 'rgb.min=', -226.70689392089844)
('rgb.max=', 136.18147277832031, 'rgb.min=', -226.75502014160156)
('rgb.max=', 136.21438598632812, 'rgb.min=', -226.23599243164062)
('rgb.max=', 136.11468505859375, 'rgb.min=', -226.23654174804688)
('rgb.max=', 136.11358642578125, 'rgb.min=', -226.21719360351562)
('rgb.max=', 136.17713928222656, 'rgb.min=', -226.08625793457031)
('rgb.max=', 135.91293334960938, 'rgb.min=', -226.20640563964844)
('rgb.max=', 136.10336303710938, 'rgb.min=', -226.60618591308594)
('rgb.max=', 136.1009521484375, 'rgb.min=', -226.30836486816406)
('rgb.max=', 135.94602966308594, 'rgb.min=', -226.04960632324219)
('rgb.max=', 135.98794555664062, 'rgb.min=', -226.48262023925781)
('rgb.max=', 135.9560546875, 'rgb.min=', -226.26271057128906)
('rgb.max=', 136.09381103515625, 'rgb.min=', -226.18099975585938)
('rgb.max=', 136.09815979003906, 'rgb.min=', -226.364013671875)
('rgb.max=', 136.1817626953125, 'rgb.min=', -226.20439147949219)
('rgb.max=', 136.04595947265625, 'rgb.min=', -226.31304931640625)
('rgb.max=', 136.11946105957031, 'rgb.min=', -226.12646484375)
('rgb.max=', 136.06057739257812, 'rgb.min=', -226.42291259765625)
('rgb.max=', 136.07872009277344, 'rgb.min=', -225.77593994140625)
('rgb.max=', 136.17259216308594, 'rgb.min=', -226.33110046386719)
('rgb.max=', 136.14663696289062, 'rgb.min=', -226.11288452148438)
('rgb.max=', 136.15121459960938, 'rgb.min=', -226.11004638671875)
('rgb.max=', 135.83493041992188, 'rgb.min=', -226.31546020507812)
('rgb.max=', 136.23040771484375, 'rgb.min=', -226.560546875)
('rgb.max=', 135.95626831054688, 'rgb.min=', -226.27297973632812)
('rgb.max=', 136.12045288085938, 'rgb.min=', -226.12579345703125)
('rgb.max=', 135.92178344726562, 'rgb.min=', -226.78346252441406)
('rgb.max=', 135.83029174804688, 'rgb.min=', -226.28607177734375)
('rgb.max=', 136.08584594726562, 'rgb.min=', -226.39151000976562)
('rgb.max=', 135.8729248046875, 'rgb.min=', -226.26759338378906)
('rgb.max=', 136.04388427734375, 'rgb.min=', -226.33116149902344)
('rgb.max=', 136.29087829589844, 'rgb.min=', -225.99383544921875)
('rgb.max=', 136.09028625488281, 'rgb.min=', -226.16654968261719)
('rgb.max=', 136.3192138671875, 'rgb.min=', -226.68113708496094)
('rgb.max=', 135.87269592285156, 'rgb.min=', -226.52995300292969)
('rgb.max=', 136.01869201660156, 'rgb.min=', -226.18104553222656)
('rgb.max=', 136.02143859863281, 'rgb.min=', -226.58815002441406)
('rgb.max=', 136.1531982421875, 'rgb.min=', -226.27186584472656)
('rgb.max=', 136.154541015625, 'rgb.min=', -226.72920227050781)
('rgb.max=', 135.9237060546875, 'rgb.min=', -226.49690246582031)
('rgb.max=', 136.04750061035156, 'rgb.min=', -226.18890380859375)
('rgb.max=', 135.94924926757812, 'rgb.min=', -226.76240539550781)
('rgb.max=', 136.06256103515625, 'rgb.min=', -226.62767028808594)
('rgb.max=', 136.02340698242188, 'rgb.min=', -226.20272827148438)
('rgb.max=', 136.0068359375, 'rgb.min=', -226.69987487792969)
('rgb.max=', 135.81437683105469, 'rgb.min=', -226.72860717773438)
('rgb.max=', 136.43710327148438, 'rgb.min=', -226.11390686035156)
('rgb.max=', 136.03646850585938, 'rgb.min=', -226.58358764648438)
('rgb.max=', 135.9267578125, 'rgb.min=', -226.25349426269531)
('rgb.max=', 135.852294921875, 'rgb.min=', -226.45738220214844)
('rgb.max=', 136.26419067382812, 'rgb.min=', -226.22080993652344)
('rgb.max=', 136.23779296875, 'rgb.min=', -226.74540710449219)
('rgb.max=', 136.21354675292969, 'rgb.min=', -226.76634216308594)
('rgb.max=', 135.99888610839844, 'rgb.min=', -226.66670227050781)
('rgb.max=', 136.02775573730469, 'rgb.min=', -226.59716796875)
('rgb.max=', 136.24969482421875, 'rgb.min=', -226.56405639648438)
('rgb.max=', 136.12312316894531, 'rgb.min=', -226.14483642578125)
('rgb.max=', 136.27682495117188, 'rgb.min=', -226.49739074707031)
('rgb.max=', 136.31260681152344, 'rgb.min=', -226.13153076171875)
('rgb.max=', 136.1884765625, 'rgb.min=', -226.07037353515625)
('rgb.max=', 135.99859619140625, 'rgb.min=', -226.71951293945312)
('rgb.max=', 136.05451965332031, 'rgb.min=', -226.37620544433594)
('rgb.max=', 136.06791687011719, 'rgb.min=', -225.59678649902344)
('rgb.max=', 136.05943298339844, 'rgb.min=', -226.19520568847656)
('rgb.max=', 135.91372680664062, 'rgb.min=', -226.49433898925781)
('rgb.max=', 136.2291259765625, 'rgb.min=', -226.38316345214844)
('rgb.max=', 136.17535400390625, 'rgb.min=', -226.14920043945312)
('rgb.max=', 136.06240844726562, 'rgb.min=', -226.53814697265625)
('rgb.max=', 136.00064086914062, 'rgb.min=', -225.89610290527344)
('rgb.max=', 135.93675231933594, 'rgb.min=', -226.43035888671875)
('rgb.max=', 136.14895629882812, 'rgb.min=', -226.6026611328125)
('rgb.max=', 135.92887878417969, 'rgb.min=', -226.31694030761719)
('rgb.max=', 136.10386657714844, 'rgb.min=', -226.25601196289062)
('rgb.max=', 136.13784790039062, 'rgb.min=', -226.70329284667969)
('rgb.max=', 135.98628234863281, 'rgb.min=', -226.74412536621094)
('rgb.max=', 135.90531921386719, 'rgb.min=', -226.58177185058594)
('rgb.max=', 135.90541076660156, 'rgb.min=', -226.31924438476562)
('rgb.max=', 136.20771789550781, 'rgb.min=', -226.0186767578125)
('rgb.max=', 136.13475036621094, 'rgb.min=', -226.26731872558594)
('rgb.max=', 136.17355346679688, 'rgb.min=', -226.80548095703125)
('rgb.max=', 135.91258239746094, 'rgb.min=', -226.58230590820312)
('rgb.max=', 136.09393310546875, 'rgb.min=', -226.53457641601562)
('rgb.max=', 136.02519226074219, 'rgb.min=', -226.59442138671875)
('rgb.max=', 135.87655639648438, 'rgb.min=', -226.36363220214844)
('rgb.max=', 136.1873779296875, 'rgb.min=', -226.0714111328125)
('rgb.max=', 135.98220825195312, 'rgb.min=', -226.41714477539062)
('rgb.max=', 135.93446350097656, 'rgb.min=', -226.37445068359375)
('rgb.max=', 136.19619750976562, 'rgb.min=', -226.71321105957031)
('rgb.max=', 136.05384826660156, 'rgb.min=', -226.5655517578125)
('rgb.max=', 136.11810302734375, 'rgb.min=', -226.67451477050781)
('rgb.max=', 136.07731628417969, 'rgb.min=', -225.813720703125)
('rgb.max=', 136.183837890625, 'rgb.min=', -226.034912109375)
('rgb.max=', 136.04896545410156, 'rgb.min=', -226.43287658691406)
('rgb.max=', 136.12857055664062, 'rgb.min=', -226.22401428222656)
('rgb.max=', 136.1507568359375, 'rgb.min=', -226.10566711425781)
('rgb.max=', 136.16024780273438, 'rgb.min=', -225.93524169921875)
('rgb.max=', 135.9384765625, 'rgb.min=', -226.57135009765625)
('rgb.max=', 136.208251953125, 'rgb.min=', -226.69308471679688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -226.6712646484375)
('rgb.max=', 136.17654418945312, 'rgb.min=', -226.08859252929688)
('rgb.max=', 135.94363403320312, 'rgb.min=', -226.12269592285156)
('rgb.max=', 136.04472351074219, 'rgb.min=', -226.42062377929688)
('rgb.max=', 136.16806030273438, 'rgb.min=', -226.15126037597656)
('rgb.max=', 136.43353271484375, 'rgb.min=', -226.58760070800781)
('rgb.max=', 135.88131713867188, 'rgb.min=', -226.20181274414062)
('rgb.max=', 135.89520263671875, 'rgb.min=', -226.54425048828125)
('rgb.max=', 135.93315124511719, 'rgb.min=', -226.08622741699219)
('rgb.max=', 135.95005798339844, 'rgb.min=', -226.70915222167969)
('rgb.max=', 135.92416381835938, 'rgb.min=', -226.24339294433594)
('rgb.max=', 136.35946655273438, 'rgb.min=', -226.22306823730469)
('rgb.max=', 135.78973388671875, 'rgb.min=', -226.55560302734375)
('rgb.max=', 136.40042114257812, 'rgb.min=', -226.66044616699219)
('rgb.max=', 136.15190124511719, 'rgb.min=', -225.82168579101562)
('rgb.max=', 135.8917236328125, 'rgb.min=', -226.55410766601562)
('rgb.max=', 136.18344116210938, 'rgb.min=', -226.42604064941406)
('rgb.max=', 136.24075317382812, 'rgb.min=', -226.09373474121094)
('rgb.max=', 136.22099304199219, 'rgb.min=', -226.14111328125)
('rgb.max=', 136.20199584960938, 'rgb.min=', -226.61595153808594)
('rgb.max=', 135.95451354980469, 'rgb.min=', -226.73579406738281)
('rgb.max=', 136.17509460449219, 'rgb.min=', -226.02743530273438)
('rgb.max=', 135.93011474609375, 'rgb.min=', -226.50440979003906)
('rgb.max=', 136.19219970703125, 'rgb.min=', -226.07940673828125)
('rgb.max=', 136.10861206054688, 'rgb.min=', -226.22697448730469)
('rgb.max=', 136.22349548339844, 'rgb.min=', -226.34884643554688)
('rgb.max=', 135.78570556640625, 'rgb.min=', -226.61679077148438)
('rgb.max=', 136.11076354980469, 'rgb.min=', -226.50994873046875)
('rgb.max=', 136.188720703125, 'rgb.min=', -226.53292846679688)
('rgb.max=', 136.11468505859375, 'rgb.min=', -226.18855285644531)
('rgb.max=', 135.8671875, 'rgb.min=', -226.41618347167969)
('rgb.max=', 136.16336059570312, 'rgb.min=', -226.45623779296875)
('rgb.max=', 136.28228759765625, 'rgb.min=', -226.6395263671875)
('rgb.max=', 136.29286193847656, 'rgb.min=', -225.96986389160156)
('rgb.max=', 135.84071350097656, 'rgb.min=', -226.2315673828125)
('rgb.max=', 136.19085693359375, 'rgb.min=', -226.06607055664062)
('rgb.max=', 136.18849182128906, 'rgb.min=', -226.56790161132812)
('rgb.max=', 136.1148681640625, 'rgb.min=', -226.17546081542969)
('rgb.max=', 135.89462280273438, 'rgb.min=', -226.4814453125)
('rgb.max=', 136.01449584960938, 'rgb.min=', -226.22303771972656)
('rgb.max=', 136.3502197265625, 'rgb.min=', -226.77662658691406)
('rgb.max=', 136.15785217285156, 'rgb.min=', -226.05992126464844)
('rgb.max=', 135.86982727050781, 'rgb.min=', -226.70480346679688)
('rgb.max=', 135.98384094238281, 'rgb.min=', -226.16658020019531)
('rgb.max=', 135.89329528808594, 'rgb.min=', -226.19369506835938)
('rgb.max=', 136.00843811035156, 'rgb.min=', -226.52653503417969)
('rgb.max=', 136.0013427734375, 'rgb.min=', -226.44525146484375)
('rgb.max=', 135.8927001953125, 'rgb.min=', -226.30082702636719)
('rgb.max=', 136.29818725585938, 'rgb.min=', -226.08843994140625)
('rgb.max=', 136.219970703125, 'rgb.min=', -226.00445556640625)
('rgb.max=', 136.39691162109375, 'rgb.min=', -226.75114440917969)
('rgb.max=', 135.82449340820312, 'rgb.min=', -226.50286865234375)
('rgb.max=', 136.14494323730469, 'rgb.min=', -226.7861328125)
('rgb.max=', 136.20309448242188, 'rgb.min=', -226.21749877929688)
('rgb.max=', 136.0638427734375, 'rgb.min=', -226.2059326171875)
('rgb.max=', 136.38566589355469, 'rgb.min=', -226.64553833007812)
('rgb.max=', 136.208251953125, 'rgb.min=', -226.5941162109375)
('rgb.max=', 136.03190612792969, 'rgb.min=', -226.14707946777344)
('rgb.max=', 136.16395568847656, 'rgb.min=', -226.44233703613281)
('rgb.max=', 136.02223205566406, 'rgb.min=', -226.55122375488281)
('rgb.max=', 136.43580627441406, 'rgb.min=', -226.72935485839844)
('rgb.max=', 136.14068603515625, 'rgb.min=', -226.75787353515625)
('rgb.max=', 135.92208862304688, 'rgb.min=', -226.55653381347656)
('rgb.max=', 135.89106750488281, 'rgb.min=', -226.35694885253906)
('rgb.max=', 136.15818786621094, 'rgb.min=', -226.71794128417969)
('rgb.max=', 136.20748901367188, 'rgb.min=', -226.51441955566406)
('rgb.max=', 136.07194519042969, 'rgb.min=', -226.43577575683594)
('rgb.max=', 136.23062133789062, 'rgb.min=', -226.09053039550781)
('rgb.max=', 136.31356811523438, 'rgb.min=', -226.09382629394531)
('rgb.max=', 136.09233093261719, 'rgb.min=', -226.66752624511719)
('rgb.max=', 135.91729736328125, 'rgb.min=', -226.60067749023438)
('rgb.max=', 135.94747924804688, 'rgb.min=', -226.48886108398438)
('rgb.max=', 136.10420227050781, 'rgb.min=', -225.70088195800781)
('rgb.max=', 136.20701599121094, 'rgb.min=', -226.03306579589844)
('rgb.max=', 136.04156494140625, 'rgb.min=', -226.68878173828125)
('rgb.max=', 135.900146484375, 'rgb.min=', -226.36894226074219)
('rgb.max=', 136.2203369140625, 'rgb.min=', -226.058837890625)
('rgb.max=', 136.01905822753906, 'rgb.min=', -226.58120727539062)
('rgb.max=', 136.0111083984375, 'rgb.min=', -226.71430969238281)
('rgb.max=', 136.15048217773438, 'rgb.min=', -225.60014343261719)
('rgb.max=', 135.76112365722656, 'rgb.min=', -226.01536560058594)
('rgb.max=', 136.35195922851562, 'rgb.min=', -226.76516723632812)
('rgb.max=', 135.98814392089844, 'rgb.min=', -226.72398376464844)
('rgb.max=', 136.22726440429688, 'rgb.min=', -225.97492980957031)
('rgb.max=', 136.03469848632812, 'rgb.min=', -226.54977416992188)
('rgb.max=', 135.98536682128906, 'rgb.min=', -225.98872375488281)
('rgb.max=', 136.18934631347656, 'rgb.min=', -226.76887512207031)
('rgb.max=', 136.1021728515625, 'rgb.min=', -226.45913696289062)
('rgb.max=', 136.04234313964844, 'rgb.min=', -226.49635314941406)
('rgb.max=', 136.18589782714844, 'rgb.min=', -226.76283264160156)
('rgb.max=', 135.87908935546875, 'rgb.min=', -226.58291625976562)
('rgb.max=', 136.098876953125, 'rgb.min=', -226.18075561523438)
('rgb.max=', 136.20950317382812, 'rgb.min=', -226.32194519042969)
('rgb.max=', 136.0450439453125, 'rgb.min=', -225.79203796386719)
('rgb.max=', 136.11172485351562, 'rgb.min=', -226.48388671875)
('rgb.max=', 135.90228271484375, 'rgb.min=', -226.60028076171875)
('rgb.max=', 136.21998596191406, 'rgb.min=', -226.16361999511719)
('rgb.max=', 136.0599365234375, 'rgb.min=', -226.50816345214844)
('rgb.max=', 136.15248107910156, 'rgb.min=', -226.09164428710938)
('rgb.max=', 136.13688659667969, 'rgb.min=', -226.13792419433594)
('rgb.max=', 136.21435546875, 'rgb.min=', -226.10629272460938)
('rgb.max=', 136.16371154785156, 'rgb.min=', -226.47531127929688)
('rgb.max=', 135.99740600585938, 'rgb.min=', -226.76348876953125)
('rgb.max=', 135.81512451171875, 'rgb.min=', -226.19792175292969)
('rgb.max=', 135.94818115234375, 'rgb.min=', -226.48475646972656)
('rgb.max=', 135.85337829589844, 'rgb.min=', -226.07572937011719)
('rgb.max=', 136.30293273925781, 'rgb.min=', -226.80908203125)
('rgb.max=', 136.18499755859375, 'rgb.min=', -226.29092407226562)
('rgb.max=', 135.91384887695312, 'rgb.min=', -226.38076782226562)
('rgb.max=', 136.16851806640625, 'rgb.min=', -225.67243957519531)
('rgb.max=', 136.10989379882812, 'rgb.min=', -226.66238403320312)
('rgb.max=', 136.0416259765625, 'rgb.min=', -226.10165405273438)
('rgb.max=', 135.9305419921875, 'rgb.min=', -226.33433532714844)
('rgb.max=', 135.82392883300781, 'rgb.min=', -225.92724609375)
('rgb.max=', 136.067626953125, 'rgb.min=', -226.736572265625)
('rgb.max=', 135.94711303710938, 'rgb.min=', -226.61376953125)
('rgb.max=', 135.89016723632812, 'rgb.min=', -226.06440734863281)
('rgb.max=', 135.939453125, 'rgb.min=', -226.44143676757812)
('rgb.max=', 136.24388122558594, 'rgb.min=', -226.79457092285156)
('rgb.max=', 136.10292053222656, 'rgb.min=', -226.43692016601562)
('rgb.max=', 135.97116088867188, 'rgb.min=', -226.68524169921875)
('rgb.max=', 136.11663818359375, 'rgb.min=', -226.47088623046875)
('rgb.max=', 135.94082641601562, 'rgb.min=', -225.82386779785156)
('rgb.max=', 136.10986328125, 'rgb.min=', -226.45503234863281)
('rgb.max=', 136.08554077148438, 'rgb.min=', -226.56552124023438)
('rgb.max=', 136.19099426269531, 'rgb.min=', -226.57977294921875)
('rgb.max=', 135.7156982421875, 'rgb.min=', -226.34512329101562)
('rgb.max=', 136.18995666503906, 'rgb.min=', -226.76124572753906)
('rgb.max=', 135.95979309082031, 'rgb.min=', -226.26950073242188)
('rgb.max=', 135.97463989257812, 'rgb.min=', -225.68052673339844)
('rgb.max=', 136.39002990722656, 'rgb.min=', -226.78897094726562)
('rgb.max=', 136.13462829589844, 'rgb.min=', -226.125244140625)
('rgb.max=', 136.17092895507812, 'rgb.min=', -226.1038818359375)
('rgb.max=', 135.82388305664062, 'rgb.min=', -226.7449951171875)
('rgb.max=', 135.79154968261719, 'rgb.min=', -226.37898254394531)
('rgb.max=', 135.93753051757812, 'rgb.min=', -226.67207336425781)
('rgb.max=', 135.99755859375, 'rgb.min=', -226.37722778320312)
('rgb.max=', 136.1011962890625, 'rgb.min=', -226.51319885253906)
('rgb.max=', 136.26939392089844, 'rgb.min=', -226.58851623535156)
('rgb.max=', 136.0743408203125, 'rgb.min=', -226.16653442382812)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.131222')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7499 ', 'GAN acc 0.5352', 'Discriminator loss 0.6879', 'Discriminator accuracy 0.5703', 'Total loss: 1.4379', 'for batch', 0)
('GAN loss 0.7539 ', 'GAN acc 0.4570', 'Discriminator loss 0.6828', 'Discriminator accuracy 0.5859', 'Total loss: 1.4367', 'for batch', 1)
('GAN loss 0.7841 ', 'GAN acc 0.4844', 'Discriminator loss 0.6772', 'Discriminator accuracy 0.5586', 'Total loss: 1.4613', 'for batch', 2)
('GAN loss 0.7274 ', 'GAN acc 0.5117', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.5410', 'Total loss: 1.4252', 'for batch', 3)
('GAN loss 0.7101 ', 'GAN acc 0.5000', 'Discriminator loss 0.6881', 'Discriminator accuracy 0.5625', 'Total loss: 1.3982', 'for batch', 4)
('GAN loss 0.6906 ', 'GAN acc 0.5547', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5625', 'Total loss: 1.3819', 'for batch', 5)
('GAN loss 0.7196 ', 'GAN acc 0.5117', 'Discriminator loss 0.6860', 'Discriminator accuracy 0.5664', 'Total loss: 1.4057', 'for batch', 6)
('GAN loss 0.7081 ', 'GAN acc 0.5078', 'Discriminator loss 0.6870', 'Discriminator accuracy 0.5605', 'Total loss: 1.3951', 'for batch', 7)
('GAN loss 0.7098 ', 'GAN acc 0.5195', 'Discriminator loss 0.6747', 'Discriminator accuracy 0.5684', 'Total loss: 1.3845', 'for batch', 8)
('GAN loss 0.6950 ', 'GAN acc 0.5547', 'Discriminator loss 0.6891', 'Discriminator accuracy 0.5449', 'Total loss: 1.3841', 'for batch', 9)
('GAN loss 0.7471 ', 'GAN acc 0.4766', 'Discriminator loss 0.6565', 'Discriminator accuracy 0.6094', 'Total loss: 1.4036', 'for batch', 10)
('GAN loss 0.7303 ', 'GAN acc 0.5625', 'Discriminator loss 0.6590', 'Discriminator accuracy 0.5781', 'Total loss: 1.3893', 'for batch', 11)
('GAN loss 0.7416 ', 'GAN acc 0.5000', 'Discriminator loss 0.6785', 'Discriminator accuracy 0.5801', 'Total loss: 1.4201', 'for batch', 12)
('GAN loss 0.7964 ', 'GAN acc 0.3750', 'Discriminator loss 0.6854', 'Discriminator accuracy 0.5625', 'Total loss: 1.4818', 'for batch', 13)
('GAN loss 0.7251 ', 'GAN acc 0.4844', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5273', 'Total loss: 1.4215', 'for batch', 14)
('GAN loss 0.6976 ', 'GAN acc 0.5625', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.5098', 'Total loss: 1.3973', 'for batch', 15)
('GAN loss 0.7100 ', 'GAN acc 0.5039', 'Discriminator loss 0.6800', 'Discriminator accuracy 0.5645', 'Total loss: 1.3900', 'for batch', 16)
('GAN loss 0.7122 ', 'GAN acc 0.5234', 'Discriminator loss 0.7080', 'Discriminator accuracy 0.5137', 'Total loss: 1.4202', 'for batch', 17)
('GAN loss 0.7239 ', 'GAN acc 0.4844', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.5215', 'Total loss: 1.4297', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.78480178)
('DISCRIMINATOR_Imagem FAKE=', 0.77318752)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.06571960449219, 'rgb.min=', -226.2353515625)
('rgb.max=', 135.93775939941406, 'rgb.min=', -226.32913208007812)
('rgb.max=', 136.2591552734375, 'rgb.min=', -226.12142944335938)
('rgb.max=', 136.029541015625, 'rgb.min=', -226.31669616699219)
('rgb.max=', 136.21217346191406, 'rgb.min=', -226.038330078125)
('rgb.max=', 136.40631103515625, 'rgb.min=', -226.24189758300781)
('rgb.max=', 135.85812377929688, 'rgb.min=', -226.43629455566406)
('rgb.max=', 136.0062255859375, 'rgb.min=', -226.07667541503906)
('rgb.max=', 135.98362731933594, 'rgb.min=', -226.41719055175781)
('rgb.max=', 135.83354187011719, 'rgb.min=', -226.25221252441406)
('rgb.max=', 135.767822265625, 'rgb.min=', -226.44859313964844)
('rgb.max=', 135.90826416015625, 'rgb.min=', -226.12306213378906)
('rgb.max=', 135.87953186035156, 'rgb.min=', -226.2572021484375)
('rgb.max=', 135.96580505371094, 'rgb.min=', -226.20440673828125)
('rgb.max=', 135.8311767578125, 'rgb.min=', -226.1932373046875)
('rgb.max=', 135.81988525390625, 'rgb.min=', -226.17755126953125)
('rgb.max=', 135.92478942871094, 'rgb.min=', -225.974365234375)
('rgb.max=', 135.91262817382812, 'rgb.min=', -225.95344543457031)
('rgb.max=', 135.95417785644531, 'rgb.min=', -226.41889953613281)
('rgb.max=', 136.03639221191406, 'rgb.min=', -226.47552490234375)
('rgb.max=', 136.25294494628906, 'rgb.min=', -226.21072387695312)
('rgb.max=', 136.202880859375, 'rgb.min=', -225.99650573730469)
('rgb.max=', 136.17282104492188, 'rgb.min=', -225.94334411621094)
('rgb.max=', 136.14503479003906, 'rgb.min=', -226.08816528320312)
('rgb.max=', 135.87013244628906, 'rgb.min=', -226.01884460449219)
('rgb.max=', 136.21601867675781, 'rgb.min=', -226.29331970214844)
('rgb.max=', 136.31343078613281, 'rgb.min=', -226.05583190917969)
('rgb.max=', 135.84622192382812, 'rgb.min=', -226.06222534179688)
('rgb.max=', 135.89955139160156, 'rgb.min=', -226.04100036621094)
('rgb.max=', 135.85493469238281, 'rgb.min=', -226.06680297851562)
('rgb.max=', 135.97428894042969, 'rgb.min=', -226.16258239746094)
('rgb.max=', 135.94940185546875, 'rgb.min=', -226.03094482421875)
('rgb.max=', 136.18356323242188, 'rgb.min=', -226.09663391113281)
('rgb.max=', 135.9356689453125, 'rgb.min=', -226.21817016601562)
('rgb.max=', 136.06439208984375, 'rgb.min=', -226.14259338378906)
('rgb.max=', 136.14657592773438, 'rgb.min=', -226.0118408203125)
('rgb.max=', 136.349365234375, 'rgb.min=', -225.95578002929688)
('rgb.max=', 136.14266967773438, 'rgb.min=', -226.00894165039062)
('rgb.max=', 136.1175537109375, 'rgb.min=', -226.11288452148438)
('rgb.max=', 136.12881469726562, 'rgb.min=', -226.11849975585938)
('rgb.max=', 135.75570678710938, 'rgb.min=', -226.00115966796875)
('rgb.max=', 136.03652954101562, 'rgb.min=', -226.31141662597656)
('rgb.max=', 135.93356323242188, 'rgb.min=', -226.22183227539062)
('rgb.max=', 136.05780029296875, 'rgb.min=', -225.99568176269531)
('rgb.max=', 135.94248962402344, 'rgb.min=', -226.51576232910156)
('rgb.max=', 135.6932373046875, 'rgb.min=', -225.95419311523438)
('rgb.max=', 135.96418762207031, 'rgb.min=', -226.04974365234375)
('rgb.max=', 135.8087158203125, 'rgb.min=', -225.94111633300781)
('rgb.max=', 135.96369934082031, 'rgb.min=', -226.02815246582031)
('rgb.max=', 136.40899658203125, 'rgb.min=', -225.97882080078125)
('rgb.max=', 135.93197631835938, 'rgb.min=', -226.0108642578125)
('rgb.max=', 136.23548889160156, 'rgb.min=', -226.06944274902344)
('rgb.max=', 135.69647216796875, 'rgb.min=', -226.29855346679688)
('rgb.max=', 135.77899169921875, 'rgb.min=', -226.10270690917969)
('rgb.max=', 136.05947875976562, 'rgb.min=', -226.31083679199219)
('rgb.max=', 136.24424743652344, 'rgb.min=', -226.14712524414062)
('rgb.max=', 135.92959594726562, 'rgb.min=', -226.22470092773438)
('rgb.max=', 135.92318725585938, 'rgb.min=', -225.94895935058594)
('rgb.max=', 135.90348815917969, 'rgb.min=', -225.95301818847656)
('rgb.max=', 135.78584289550781, 'rgb.min=', -226.32110595703125)
('rgb.max=', 135.98298645019531, 'rgb.min=', -226.10870361328125)
('rgb.max=', 135.85052490234375, 'rgb.min=', -225.92323303222656)
('rgb.max=', 135.85260009765625, 'rgb.min=', -226.15863037109375)
('rgb.max=', 135.74581909179688, 'rgb.min=', -226.4520263671875)
('rgb.max=', 136.45489501953125, 'rgb.min=', -226.01602172851562)
('rgb.max=', 135.93959045410156, 'rgb.min=', -226.34724426269531)
('rgb.max=', 135.77667236328125, 'rgb.min=', -225.93002319335938)
('rgb.max=', 135.76416015625, 'rgb.min=', -226.17454528808594)
('rgb.max=', 136.21530151367188, 'rgb.min=', -226.20034790039062)
('rgb.max=', 136.14729309082031, 'rgb.min=', -226.03414916992188)
('rgb.max=', 136.12413024902344, 'rgb.min=', -226.08909606933594)
('rgb.max=', 135.88987731933594, 'rgb.min=', -226.09495544433594)
('rgb.max=', 135.93145751953125, 'rgb.min=', -226.3795166015625)
('rgb.max=', 136.04367065429688, 'rgb.min=', -226.08599853515625)
('rgb.max=', 136.01718139648438, 'rgb.min=', -225.93997192382812)
('rgb.max=', 136.0369873046875, 'rgb.min=', -226.05633544921875)
('rgb.max=', 136.3890380859375, 'rgb.min=', -226.01565551757812)
('rgb.max=', 136.20530700683594, 'rgb.min=', -226.07037353515625)
('rgb.max=', 135.8837890625, 'rgb.min=', -226.08973693847656)
('rgb.max=', 136.04083251953125, 'rgb.min=', -226.00862121582031)
('rgb.max=', 136.15817260742188, 'rgb.min=', -225.94564819335938)
('rgb.max=', 135.98551940917969, 'rgb.min=', -225.94413757324219)
('rgb.max=', 135.83917236328125, 'rgb.min=', -226.2376708984375)
('rgb.max=', 136.11862182617188, 'rgb.min=', -226.31938171386719)
('rgb.max=', 136.14007568359375, 'rgb.min=', -226.10128784179688)
('rgb.max=', 135.94683837890625, 'rgb.min=', -226.25836181640625)
('rgb.max=', 136.07781982421875, 'rgb.min=', -225.92950439453125)
('rgb.max=', 135.80392456054688, 'rgb.min=', -226.01644897460938)
('rgb.max=', 136.08323669433594, 'rgb.min=', -226.33613586425781)
('rgb.max=', 135.76177978515625, 'rgb.min=', -225.90647888183594)
('rgb.max=', 135.99929809570312, 'rgb.min=', -225.97750854492188)
('rgb.max=', 135.82740783691406, 'rgb.min=', -226.51881408691406)
('rgb.max=', 135.86502075195312, 'rgb.min=', -226.38204956054688)
('rgb.max=', 135.78445434570312, 'rgb.min=', -226.04508972167969)
('rgb.max=', 135.84088134765625, 'rgb.min=', -225.90391540527344)
('rgb.max=', 136.23410034179688, 'rgb.min=', -226.01953125)
('rgb.max=', 136.0987548828125, 'rgb.min=', -226.10093688964844)
('rgb.max=', 135.99737548828125, 'rgb.min=', -226.53330993652344)
('rgb.max=', 135.82852172851562, 'rgb.min=', -226.40240478515625)
('rgb.max=', 135.99557495117188, 'rgb.min=', -226.20907592773438)
('rgb.max=', 135.9224853515625, 'rgb.min=', -226.25361633300781)
('rgb.max=', 135.78758239746094, 'rgb.min=', -226.0091552734375)
('rgb.max=', 136.16600036621094, 'rgb.min=', -226.06748962402344)
('rgb.max=', 135.9559326171875, 'rgb.min=', -226.10101318359375)
('rgb.max=', 135.9288330078125, 'rgb.min=', -225.96150207519531)
('rgb.max=', 136.27435302734375, 'rgb.min=', -226.18186950683594)
('rgb.max=', 136.04376220703125, 'rgb.min=', -226.36210632324219)
('rgb.max=', 136.02665710449219, 'rgb.min=', -226.18002319335938)
('rgb.max=', 136.27505493164062, 'rgb.min=', -226.07334899902344)
('rgb.max=', 136.15971374511719, 'rgb.min=', -226.03633117675781)
('rgb.max=', 135.99934387207031, 'rgb.min=', -226.124267578125)
('rgb.max=', 136.14178466796875, 'rgb.min=', -226.07208251953125)
('rgb.max=', 135.97076416015625, 'rgb.min=', -225.94721984863281)
('rgb.max=', 136.10969543457031, 'rgb.min=', -226.01271057128906)
('rgb.max=', 135.90647888183594, 'rgb.min=', -226.00346374511719)
('rgb.max=', 135.96815490722656, 'rgb.min=', -226.52894592285156)
('rgb.max=', 135.64822387695312, 'rgb.min=', -226.09123229980469)
('rgb.max=', 136.1300048828125, 'rgb.min=', -226.08885192871094)
('rgb.max=', 135.84359741210938, 'rgb.min=', -225.90936279296875)
('rgb.max=', 136.11717224121094, 'rgb.min=', -226.05528259277344)
('rgb.max=', 136.18153381347656, 'rgb.min=', -226.0411376953125)
('rgb.max=', 136.35458374023438, 'rgb.min=', -226.122314453125)
('rgb.max=', 135.85003662109375, 'rgb.min=', -225.97900390625)
('rgb.max=', 135.9342041015625, 'rgb.min=', -226.00672912597656)
('rgb.max=', 135.85305786132812, 'rgb.min=', -226.03327941894531)
('rgb.max=', 135.97238159179688, 'rgb.min=', -226.38349914550781)
('rgb.max=', 135.89450073242188, 'rgb.min=', -225.959716796875)
('rgb.max=', 136.27496337890625, 'rgb.min=', -226.04292297363281)
('rgb.max=', 135.66758728027344, 'rgb.min=', -226.30152893066406)
('rgb.max=', 136.13499450683594, 'rgb.min=', -226.36105346679688)
('rgb.max=', 136.22964477539062, 'rgb.min=', -226.08309936523438)
('rgb.max=', 135.82106018066406, 'rgb.min=', -226.35893249511719)
('rgb.max=', 136.0263671875, 'rgb.min=', -226.08576965332031)
('rgb.max=', 136.15338134765625, 'rgb.min=', -226.10212707519531)
('rgb.max=', 136.13447570800781, 'rgb.min=', -226.06004333496094)
('rgb.max=', 135.76470947265625, 'rgb.min=', -226.35134887695312)
('rgb.max=', 135.91374206542969, 'rgb.min=', -226.28598022460938)
('rgb.max=', 136.13864135742188, 'rgb.min=', -226.03448486328125)
('rgb.max=', 135.8848876953125, 'rgb.min=', -226.28367614746094)
('rgb.max=', 136.12992858886719, 'rgb.min=', -226.08209228515625)
('rgb.max=', 135.97402954101562, 'rgb.min=', -226.00054931640625)
('rgb.max=', 136.13836669921875, 'rgb.min=', -226.29527282714844)
('rgb.max=', 135.75633239746094, 'rgb.min=', -226.43431091308594)
('rgb.max=', 136.32766723632812, 'rgb.min=', -226.04388427734375)
('rgb.max=', 136.00973510742188, 'rgb.min=', -226.29975891113281)
('rgb.max=', 136.28802490234375, 'rgb.min=', -226.02725219726562)
('rgb.max=', 135.89418029785156, 'rgb.min=', -226.0220947265625)
('rgb.max=', 136.17608642578125, 'rgb.min=', -226.40751647949219)
('rgb.max=', 136.1951904296875, 'rgb.min=', -226.47482299804688)
('rgb.max=', 136.3072509765625, 'rgb.min=', -225.96986389160156)
('rgb.max=', 135.8238525390625, 'rgb.min=', -226.08796691894531)
('rgb.max=', 136.16110229492188, 'rgb.min=', -226.06651306152344)
('rgb.max=', 136.22413635253906, 'rgb.min=', -226.06623840332031)
('rgb.max=', 136.0396728515625, 'rgb.min=', -226.11537170410156)
('rgb.max=', 135.854736328125, 'rgb.min=', -226.19169616699219)
('rgb.max=', 135.873291015625, 'rgb.min=', -226.02970886230469)
('rgb.max=', 136.28425598144531, 'rgb.min=', -226.08309936523438)
('rgb.max=', 136.12022399902344, 'rgb.min=', -226.09944152832031)
('rgb.max=', 135.8131103515625, 'rgb.min=', -226.48101806640625)
('rgb.max=', 135.81973266601562, 'rgb.min=', -225.89265441894531)
('rgb.max=', 135.87405395507812, 'rgb.min=', -225.92997741699219)
('rgb.max=', 135.97567749023438, 'rgb.min=', -226.350830078125)
('rgb.max=', 135.92799377441406, 'rgb.min=', -226.15318298339844)
('rgb.max=', 135.76425170898438, 'rgb.min=', -226.01327514648438)
('rgb.max=', 136.23286437988281, 'rgb.min=', -226.17648315429688)
('rgb.max=', 136.22906494140625, 'rgb.min=', -226.00445556640625)
('rgb.max=', 136.12698364257812, 'rgb.min=', -226.36175537109375)
('rgb.max=', 135.69618225097656, 'rgb.min=', -226.06350708007812)
('rgb.max=', 136.14680480957031, 'rgb.min=', -226.13540649414062)
('rgb.max=', 136.21983337402344, 'rgb.min=', -226.07785034179688)
('rgb.max=', 135.89990234375, 'rgb.min=', -226.02462768554688)
('rgb.max=', 136.14761352539062, 'rgb.min=', -226.25753784179688)
('rgb.max=', 136.20303344726562, 'rgb.min=', -226.16511535644531)
('rgb.max=', 136.07731628417969, 'rgb.min=', -225.89389038085938)
('rgb.max=', 136.04158020019531, 'rgb.min=', -226.15910339355469)
('rgb.max=', 136.1500244140625, 'rgb.min=', -226.24516296386719)
('rgb.max=', 136.10780334472656, 'rgb.min=', -225.98457336425781)
('rgb.max=', 135.83786010742188, 'rgb.min=', -226.04167175292969)
('rgb.max=', 135.77738952636719, 'rgb.min=', -226.13880920410156)
('rgb.max=', 135.81918334960938, 'rgb.min=', -225.93153381347656)
('rgb.max=', 135.99166870117188, 'rgb.min=', -226.45281982421875)
('rgb.max=', 136.051025390625, 'rgb.min=', -226.33006286621094)
('rgb.max=', 135.99949645996094, 'rgb.min=', -226.03450012207031)
('rgb.max=', 136.25344848632812, 'rgb.min=', -226.0213623046875)
('rgb.max=', 136.35992431640625, 'rgb.min=', -226.09382629394531)
('rgb.max=', 135.97576904296875, 'rgb.min=', -226.04646301269531)
('rgb.max=', 135.90126037597656, 'rgb.min=', -226.23654174804688)
('rgb.max=', 135.92381286621094, 'rgb.min=', -226.14407348632812)
('rgb.max=', 136.3524169921875, 'rgb.min=', -225.81599426269531)
('rgb.max=', 136.20088195800781, 'rgb.min=', -226.04600524902344)
('rgb.max=', 136.13931274414062, 'rgb.min=', -226.45787048339844)
('rgb.max=', 135.74800109863281, 'rgb.min=', -225.95114135742188)
('rgb.max=', 136.09602355957031, 'rgb.min=', -226.05447387695312)
('rgb.max=', 135.93748474121094, 'rgb.min=', -226.25071716308594)
('rgb.max=', 135.82028198242188, 'rgb.min=', -226.33345031738281)
('rgb.max=', 136.27241516113281, 'rgb.min=', -225.77345275878906)
('rgb.max=', 135.76017761230469, 'rgb.min=', -226.05307006835938)
('rgb.max=', 136.25457763671875, 'rgb.min=', -226.51614379882812)
('rgb.max=', 135.913330078125, 'rgb.min=', -226.27813720703125)
('rgb.max=', 136.1529541015625, 'rgb.min=', -226.03338623046875)
('rgb.max=', 135.94181823730469, 'rgb.min=', -226.21255493164062)
('rgb.max=', 136.00270080566406, 'rgb.min=', -225.90547180175781)
('rgb.max=', 135.93032836914062, 'rgb.min=', -226.49305725097656)
('rgb.max=', 136.06877136230469, 'rgb.min=', -226.15777587890625)
('rgb.max=', 136.06510925292969, 'rgb.min=', -225.95144653320312)
('rgb.max=', 136.0137939453125, 'rgb.min=', -226.38819885253906)
('rgb.max=', 135.9849853515625, 'rgb.min=', -226.23164367675781)
('rgb.max=', 135.9254150390625, 'rgb.min=', -225.95046997070312)
('rgb.max=', 136.16998291015625, 'rgb.min=', -226.02838134765625)
('rgb.max=', 136.06222534179688, 'rgb.min=', -225.91062927246094)
('rgb.max=', 136.15606689453125, 'rgb.min=', -226.16165161132812)
('rgb.max=', 135.83949279785156, 'rgb.min=', -226.39459228515625)
('rgb.max=', 136.06686401367188, 'rgb.min=', -226.05482482910156)
('rgb.max=', 136.14347839355469, 'rgb.min=', -226.2757568359375)
('rgb.max=', 136.076171875, 'rgb.min=', -226.09556579589844)
('rgb.max=', 136.03720092773438, 'rgb.min=', -226.0262451171875)
('rgb.max=', 136.05101013183594, 'rgb.min=', -226.13154602050781)
('rgb.max=', 136.00389099121094, 'rgb.min=', -226.27230834960938)
('rgb.max=', 136.03561401367188, 'rgb.min=', -226.3836669921875)
('rgb.max=', 135.7991943359375, 'rgb.min=', -226.1099853515625)
('rgb.max=', 135.9044189453125, 'rgb.min=', -226.18162536621094)
('rgb.max=', 135.84934997558594, 'rgb.min=', -226.01284790039062)
('rgb.max=', 136.13211059570312, 'rgb.min=', -226.0269775390625)
('rgb.max=', 136.08187866210938, 'rgb.min=', -225.98292541503906)
('rgb.max=', 135.87187194824219, 'rgb.min=', -226.31880187988281)
('rgb.max=', 136.09231567382812, 'rgb.min=', -225.86697387695312)
('rgb.max=', 135.97166442871094, 'rgb.min=', -226.451416015625)
('rgb.max=', 135.99967956542969, 'rgb.min=', -226.08145141601562)
('rgb.max=', 135.864013671875, 'rgb.min=', -225.98513793945312)
('rgb.max=', 135.78973388671875, 'rgb.min=', -226.04637145996094)
('rgb.max=', 135.95455932617188, 'rgb.min=', -226.42356872558594)
('rgb.max=', 135.92739868164062, 'rgb.min=', -226.47163391113281)
('rgb.max=', 135.80923461914062, 'rgb.min=', -225.91453552246094)
('rgb.max=', 135.80848693847656, 'rgb.min=', -225.93797302246094)
('rgb.max=', 136.01072692871094, 'rgb.min=', -226.484619140625)
('rgb.max=', 136.15097045898438, 'rgb.min=', -226.40521240234375)
('rgb.max=', 135.95695495605469, 'rgb.min=', -226.54310607910156)
('rgb.max=', 136.20924377441406, 'rgb.min=', -226.15550231933594)
('rgb.max=', 136.08004760742188, 'rgb.min=', -226.16264343261719)
('rgb.max=', 136.1883544921875, 'rgb.min=', -226.33218383789062)
('rgb.max=', 136.00326538085938, 'rgb.min=', -226.29930114746094)
('rgb.max=', 136.0992431640625, 'rgb.min=', -226.11044311523438)
('rgb.max=', 135.70756530761719, 'rgb.min=', -226.20115661621094)
('rgb.max=', 136.06979370117188, 'rgb.min=', -226.09391784667969)
('rgb.max=', 136.07647705078125, 'rgb.min=', -226.1680908203125)
('rgb.max=', 136.12644958496094, 'rgb.min=', -225.90170288085938)
('rgb.max=', 136.13677978515625, 'rgb.min=', -226.41098022460938)
('rgb.max=', 135.9261474609375, 'rgb.min=', -225.99227905273438)
('rgb.max=', 136.05462646484375, 'rgb.min=', -226.1038818359375)
('rgb.max=', 135.74148559570312, 'rgb.min=', -226.60305786132812)
('rgb.max=', 135.77615356445312, 'rgb.min=', -226.24830627441406)
('rgb.max=', 135.8829345703125, 'rgb.min=', -226.22451782226562)
('rgb.max=', 135.94183349609375, 'rgb.min=', -226.16603088378906)
('rgb.max=', 135.93185424804688, 'rgb.min=', -226.16567993164062)
('rgb.max=', 136.01058959960938, 'rgb.min=', -226.39610290527344)
('rgb.max=', 136.0185546875, 'rgb.min=', -226.08457946777344)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.643872')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7113 ', 'GAN acc 0.5312', 'Discriminator loss 0.7045', 'Discriminator accuracy 0.5234', 'Total loss: 1.4158', 'for batch', 0)
('GAN loss 0.7056 ', 'GAN acc 0.5234', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.5137', 'Total loss: 1.4056', 'for batch', 1)
('GAN loss 0.6852 ', 'GAN acc 0.5430', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.5117', 'Total loss: 1.3880', 'for batch', 2)
('GAN loss 0.6676 ', 'GAN acc 0.6094', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5078', 'Total loss: 1.3691', 'for batch', 3)
('GAN loss 0.6619 ', 'GAN acc 0.6016', 'Discriminator loss 0.7141', 'Discriminator accuracy 0.5078', 'Total loss: 1.3759', 'for batch', 4)
('GAN loss 0.6534 ', 'GAN acc 0.5781', 'Discriminator loss 0.7098', 'Discriminator accuracy 0.4902', 'Total loss: 1.3632', 'for batch', 5)
('GAN loss 0.6816 ', 'GAN acc 0.6250', 'Discriminator loss 0.7087', 'Discriminator accuracy 0.4824', 'Total loss: 1.3903', 'for batch', 6)
('GAN loss 0.6961 ', 'GAN acc 0.5469', 'Discriminator loss 0.7124', 'Discriminator accuracy 0.4746', 'Total loss: 1.4085', 'for batch', 7)
('GAN loss 0.6808 ', 'GAN acc 0.5586', 'Discriminator loss 0.7125', 'Discriminator accuracy 0.4941', 'Total loss: 1.3933', 'for batch', 8)
('GAN loss 0.6733 ', 'GAN acc 0.5898', 'Discriminator loss 0.7137', 'Discriminator accuracy 0.4766', 'Total loss: 1.3871', 'for batch', 9)
('GAN loss 0.6859 ', 'GAN acc 0.5195', 'Discriminator loss 0.7089', 'Discriminator accuracy 0.5098', 'Total loss: 1.3947', 'for batch', 10)
('GAN loss 0.6880 ', 'GAN acc 0.5547', 'Discriminator loss 0.7060', 'Discriminator accuracy 0.5098', 'Total loss: 1.3940', 'for batch', 11)
('GAN loss 0.6825 ', 'GAN acc 0.5625', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5078', 'Total loss: 1.3777', 'for batch', 12)
('GAN loss 0.6987 ', 'GAN acc 0.5312', 'Discriminator loss 0.7149', 'Discriminator accuracy 0.4727', 'Total loss: 1.4136', 'for batch', 13)
('GAN loss 0.6714 ', 'GAN acc 0.6445', 'Discriminator loss 0.7129', 'Discriminator accuracy 0.4727', 'Total loss: 1.3843', 'for batch', 14)
('GAN loss 0.6622 ', 'GAN acc 0.6133', 'Discriminator loss 0.7128', 'Discriminator accuracy 0.4688', 'Total loss: 1.3750', 'for batch', 15)
('GAN loss 0.6760 ', 'GAN acc 0.6016', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4941', 'Total loss: 1.3796', 'for batch', 16)
('GAN loss 0.6771 ', 'GAN acc 0.6016', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.4980', 'Total loss: 1.3807', 'for batch', 17)
('GAN loss 0.6668 ', 'GAN acc 0.5781', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.5098', 'Total loss: 1.3663', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.71030259)
('DISCRIMINATOR_Imagem FAKE=', 0.70163417)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.07376098632812, 'rgb.min=', -226.093017578125)
('rgb.max=', 135.97052001953125, 'rgb.min=', -226.21296691894531)
('rgb.max=', 136.23445129394531, 'rgb.min=', -226.052001953125)
('rgb.max=', 136.07298278808594, 'rgb.min=', -226.23770141601562)
('rgb.max=', 136.15032958984375, 'rgb.min=', -226.00296020507812)
('rgb.max=', 136.32078552246094, 'rgb.min=', -226.37838745117188)
('rgb.max=', 135.88455200195312, 'rgb.min=', -226.44227600097656)
('rgb.max=', 136.02743530273438, 'rgb.min=', -226.03152465820312)
('rgb.max=', 135.9129638671875, 'rgb.min=', -226.43415832519531)
('rgb.max=', 135.85214233398438, 'rgb.min=', -226.18295288085938)
('rgb.max=', 135.77735900878906, 'rgb.min=', -226.39817810058594)
('rgb.max=', 135.90228271484375, 'rgb.min=', -226.09992980957031)
('rgb.max=', 135.86329650878906, 'rgb.min=', -226.20492553710938)
('rgb.max=', 135.97322082519531, 'rgb.min=', -226.18887329101562)
('rgb.max=', 135.84642028808594, 'rgb.min=', -226.14447021484375)
('rgb.max=', 135.82778930664062, 'rgb.min=', -226.16424560546875)
('rgb.max=', 135.87945556640625, 'rgb.min=', -225.99751281738281)
('rgb.max=', 135.93397521972656, 'rgb.min=', -225.93252563476562)
('rgb.max=', 135.94511413574219, 'rgb.min=', -226.39443969726562)
('rgb.max=', 135.99964904785156, 'rgb.min=', -226.61959838867188)
('rgb.max=', 136.14007568359375, 'rgb.min=', -226.08406066894531)
('rgb.max=', 136.20375061035156, 'rgb.min=', -226.01516723632812)
('rgb.max=', 136.14759826660156, 'rgb.min=', -225.9395751953125)
('rgb.max=', 136.08056640625, 'rgb.min=', -226.06651306152344)
('rgb.max=', 135.8524169921875, 'rgb.min=', -226.05781555175781)
('rgb.max=', 136.19595336914062, 'rgb.min=', -226.22151184082031)
('rgb.max=', 136.21682739257812, 'rgb.min=', -226.16624450683594)
('rgb.max=', 135.90409851074219, 'rgb.min=', -226.10562133789062)
('rgb.max=', 135.93730163574219, 'rgb.min=', -225.98968505859375)
('rgb.max=', 135.87591552734375, 'rgb.min=', -226.05319213867188)
('rgb.max=', 135.96018981933594, 'rgb.min=', -226.25537109375)
('rgb.max=', 135.9241943359375, 'rgb.min=', -225.99452209472656)
('rgb.max=', 136.10391235351562, 'rgb.min=', -226.15583801269531)
('rgb.max=', 135.92463684082031, 'rgb.min=', -226.0594482421875)
('rgb.max=', 135.97122192382812, 'rgb.min=', -226.09266662597656)
('rgb.max=', 136.14634704589844, 'rgb.min=', -225.98921203613281)
('rgb.max=', 136.2744140625, 'rgb.min=', -226.0447998046875)
('rgb.max=', 136.1292724609375, 'rgb.min=', -226.07595825195312)
('rgb.max=', 136.04315185546875, 'rgb.min=', -226.037353515625)
('rgb.max=', 136.05088806152344, 'rgb.min=', -226.06207275390625)
('rgb.max=', 135.76034545898438, 'rgb.min=', -226.00677490234375)
('rgb.max=', 136.041015625, 'rgb.min=', -226.37521362304688)
('rgb.max=', 135.93971252441406, 'rgb.min=', -226.19786071777344)
('rgb.max=', 135.97282409667969, 'rgb.min=', -225.974609375)
('rgb.max=', 135.98284912109375, 'rgb.min=', -226.68342590332031)
('rgb.max=', 135.68972778320312, 'rgb.min=', -225.93775939941406)
('rgb.max=', 135.95883178710938, 'rgb.min=', -226.09207153320312)
('rgb.max=', 135.80459594726562, 'rgb.min=', -225.93109130859375)
('rgb.max=', 135.95004272460938, 'rgb.min=', -226.00914001464844)
('rgb.max=', 136.35293579101562, 'rgb.min=', -225.95773315429688)
('rgb.max=', 135.99580383300781, 'rgb.min=', -226.12451171875)
('rgb.max=', 136.26669311523438, 'rgb.min=', -226.0501708984375)
('rgb.max=', 135.71455383300781, 'rgb.min=', -226.20773315429688)
('rgb.max=', 135.76956176757812, 'rgb.min=', -226.18380737304688)
('rgb.max=', 136.0540771484375, 'rgb.min=', -226.26141357421875)
('rgb.max=', 136.16790771484375, 'rgb.min=', -226.14633178710938)
('rgb.max=', 135.90487670898438, 'rgb.min=', -226.22584533691406)
('rgb.max=', 135.89768981933594, 'rgb.min=', -225.93455505371094)
('rgb.max=', 135.91539001464844, 'rgb.min=', -225.98974609375)
('rgb.max=', 135.69204711914062, 'rgb.min=', -226.29096984863281)
('rgb.max=', 136.01345825195312, 'rgb.min=', -226.1395263671875)
('rgb.max=', 135.78948974609375, 'rgb.min=', -225.891357421875)
('rgb.max=', 135.77778625488281, 'rgb.min=', -226.077880859375)
('rgb.max=', 135.76838684082031, 'rgb.min=', -226.60385131835938)
('rgb.max=', 136.40492248535156, 'rgb.min=', -225.97770690917969)
('rgb.max=', 135.96994018554688, 'rgb.min=', -226.29318237304688)
('rgb.max=', 135.73481750488281, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.763671875, 'rgb.min=', -226.13180541992188)
('rgb.max=', 136.11582946777344, 'rgb.min=', -226.29873657226562)
('rgb.max=', 136.135498046875, 'rgb.min=', -226.16429138183594)
('rgb.max=', 136.10174560546875, 'rgb.min=', -226.17008972167969)
('rgb.max=', 135.82371520996094, 'rgb.min=', -226.09445190429688)
('rgb.max=', 135.94436645507812, 'rgb.min=', -226.51365661621094)
('rgb.max=', 136.06903076171875, 'rgb.min=', -226.29965209960938)
('rgb.max=', 135.93768310546875, 'rgb.min=', -225.82786560058594)
('rgb.max=', 136.09242248535156, 'rgb.min=', -226.10452270507812)
('rgb.max=', 136.30178833007812, 'rgb.min=', -226.05683898925781)
('rgb.max=', 136.14920043945312, 'rgb.min=', -226.06297302246094)
('rgb.max=', 135.79385375976562, 'rgb.min=', -226.1021728515625)
('rgb.max=', 136.02685546875, 'rgb.min=', -226.03256225585938)
('rgb.max=', 136.06497192382812, 'rgb.min=', -225.8294677734375)
('rgb.max=', 135.95138549804688, 'rgb.min=', -226.01362609863281)
('rgb.max=', 135.83610534667969, 'rgb.min=', -226.16668701171875)
('rgb.max=', 136.05062866210938, 'rgb.min=', -226.32411193847656)
('rgb.max=', 136.04159545898438, 'rgb.min=', -226.32061767578125)
('rgb.max=', 135.942138671875, 'rgb.min=', -226.23652648925781)
('rgb.max=', 136.00303649902344, 'rgb.min=', -225.86056518554688)
('rgb.max=', 135.78800964355469, 'rgb.min=', -226.01466369628906)
('rgb.max=', 136.03607177734375, 'rgb.min=', -226.49200439453125)
('rgb.max=', 135.72898864746094, 'rgb.min=', -225.87689208984375)
('rgb.max=', 135.9183349609375, 'rgb.min=', -226.0089111328125)
('rgb.max=', 135.83120727539062, 'rgb.min=', -226.48219299316406)
('rgb.max=', 135.82716369628906, 'rgb.min=', -226.60830688476562)
('rgb.max=', 135.80215454101562, 'rgb.min=', -225.99639892578125)
('rgb.max=', 135.83921813964844, 'rgb.min=', -225.87187194824219)
('rgb.max=', 136.14395141601562, 'rgb.min=', -226.01953125)
('rgb.max=', 136.07102966308594, 'rgb.min=', -226.0894775390625)
('rgb.max=', 136.06918334960938, 'rgb.min=', -226.70704650878906)
('rgb.max=', 135.82278442382812, 'rgb.min=', -226.31581115722656)
('rgb.max=', 136.00457763671875, 'rgb.min=', -226.13313293457031)
('rgb.max=', 135.92094421386719, 'rgb.min=', -226.17996215820312)
('rgb.max=', 135.79159545898438, 'rgb.min=', -225.98063659667969)
('rgb.max=', 136.10011291503906, 'rgb.min=', -226.056396484375)
('rgb.max=', 135.93888854980469, 'rgb.min=', -226.0460205078125)
('rgb.max=', 135.95072937011719, 'rgb.min=', -225.92018127441406)
('rgb.max=', 136.20196533203125, 'rgb.min=', -226.15415954589844)
('rgb.max=', 136.001708984375, 'rgb.min=', -226.26739501953125)
('rgb.max=', 136.00978088378906, 'rgb.min=', -226.140869140625)
('rgb.max=', 136.17108154296875, 'rgb.min=', -226.11885070800781)
('rgb.max=', 136.12539672851562, 'rgb.min=', -226.03633117675781)
('rgb.max=', 136.02545166015625, 'rgb.min=', -226.13623046875)
('rgb.max=', 136.15791320800781, 'rgb.min=', -225.99569702148438)
('rgb.max=', 135.95492553710938, 'rgb.min=', -225.87930297851562)
('rgb.max=', 136.08543395996094, 'rgb.min=', -226.00007629394531)
('rgb.max=', 135.90470886230469, 'rgb.min=', -226.06724548339844)
('rgb.max=', 135.93428039550781, 'rgb.min=', -226.60957336425781)
('rgb.max=', 135.6280517578125, 'rgb.min=', -226.08271789550781)
('rgb.max=', 136.04129028320312, 'rgb.min=', -225.98648071289062)
('rgb.max=', 135.83967590332031, 'rgb.min=', -225.91824340820312)
('rgb.max=', 136.10990905761719, 'rgb.min=', -226.00680541992188)
('rgb.max=', 136.10206604003906, 'rgb.min=', -226.10365295410156)
('rgb.max=', 136.32000732421875, 'rgb.min=', -226.06491088867188)
('rgb.max=', 135.85772705078125, 'rgb.min=', -226.01213073730469)
('rgb.max=', 135.94834899902344, 'rgb.min=', -225.98202514648438)
('rgb.max=', 135.87020874023438, 'rgb.min=', -226.03768920898438)
('rgb.max=', 136.01033020019531, 'rgb.min=', -226.30258178710938)
('rgb.max=', 135.89578247070312, 'rgb.min=', -225.88931274414062)
('rgb.max=', 136.24066162109375, 'rgb.min=', -226.00993347167969)
('rgb.max=', 135.68170166015625, 'rgb.min=', -226.30136108398438)
('rgb.max=', 136.09016418457031, 'rgb.min=', -226.28628540039062)
('rgb.max=', 136.174072265625, 'rgb.min=', -226.08309936523438)
('rgb.max=', 135.78138732910156, 'rgb.min=', -226.31765747070312)
('rgb.max=', 135.99412536621094, 'rgb.min=', -226.07537841796875)
('rgb.max=', 136.19590759277344, 'rgb.min=', -225.92947387695312)
('rgb.max=', 136.08682250976562, 'rgb.min=', -226.04049682617188)
('rgb.max=', 135.77352905273438, 'rgb.min=', -226.33927917480469)
('rgb.max=', 135.92971801757812, 'rgb.min=', -226.43235778808594)
('rgb.max=', 136.096923828125, 'rgb.min=', -226.03297424316406)
('rgb.max=', 135.87742614746094, 'rgb.min=', -226.20677185058594)
('rgb.max=', 136.07014465332031, 'rgb.min=', -226.08209228515625)
('rgb.max=', 135.93798828125, 'rgb.min=', -225.92451477050781)
('rgb.max=', 136.18988037109375, 'rgb.min=', -226.29414367675781)
('rgb.max=', 135.7744140625, 'rgb.min=', -226.34983825683594)
('rgb.max=', 136.26132202148438, 'rgb.min=', -225.98188781738281)
('rgb.max=', 135.99282836914062, 'rgb.min=', -226.24116516113281)
('rgb.max=', 136.25259399414062, 'rgb.min=', -225.99830627441406)
('rgb.max=', 135.90701293945312, 'rgb.min=', -225.96633911132812)
('rgb.max=', 136.13919067382812, 'rgb.min=', -226.38621520996094)
('rgb.max=', 136.16468811035156, 'rgb.min=', -226.30818176269531)
('rgb.max=', 136.20401000976562, 'rgb.min=', -225.96986389160156)
('rgb.max=', 135.85934448242188, 'rgb.min=', -226.04119873046875)
('rgb.max=', 136.0960693359375, 'rgb.min=', -226.06651306152344)
('rgb.max=', 136.07955932617188, 'rgb.min=', -226.19168090820312)
('rgb.max=', 136.09114074707031, 'rgb.min=', -226.16580200195312)
('rgb.max=', 135.90814208984375, 'rgb.min=', -226.14579772949219)
('rgb.max=', 135.90487670898438, 'rgb.min=', -225.975341796875)
('rgb.max=', 136.23762512207031, 'rgb.min=', -226.13104248046875)
('rgb.max=', 136.04888916015625, 'rgb.min=', -226.08213806152344)
('rgb.max=', 135.82272338867188, 'rgb.min=', -226.4970703125)
('rgb.max=', 135.84686279296875, 'rgb.min=', -225.95809936523438)
('rgb.max=', 135.89410400390625, 'rgb.min=', -225.91389465332031)
('rgb.max=', 135.98979187011719, 'rgb.min=', -226.263427734375)
('rgb.max=', 135.97396850585938, 'rgb.min=', -226.1187744140625)
('rgb.max=', 135.75169372558594, 'rgb.min=', -226.07501220703125)
('rgb.max=', 136.25462341308594, 'rgb.min=', -226.13661193847656)
('rgb.max=', 136.15509033203125, 'rgb.min=', -226.00053405761719)
('rgb.max=', 136.07669067382812, 'rgb.min=', -226.26643371582031)
('rgb.max=', 135.68588256835938, 'rgb.min=', -226.03443908691406)
('rgb.max=', 136.1353759765625, 'rgb.min=', -226.1290283203125)
('rgb.max=', 136.12887573242188, 'rgb.min=', -226.03324890136719)
('rgb.max=', 135.85543823242188, 'rgb.min=', -226.02104187011719)
('rgb.max=', 136.16131591796875, 'rgb.min=', -226.07217407226562)
('rgb.max=', 136.14820861816406, 'rgb.min=', -226.18072509765625)
('rgb.max=', 136.04000854492188, 'rgb.min=', -225.95722961425781)
('rgb.max=', 135.97084045410156, 'rgb.min=', -226.22944641113281)
('rgb.max=', 136.13375854492188, 'rgb.min=', -226.17268371582031)
('rgb.max=', 136.08360290527344, 'rgb.min=', -226.26789855957031)
('rgb.max=', 135.84068298339844, 'rgb.min=', -226.14395141601562)
('rgb.max=', 135.79292297363281, 'rgb.min=', -226.10569763183594)
('rgb.max=', 135.8133544921875, 'rgb.min=', -225.89633178710938)
('rgb.max=', 135.958251953125, 'rgb.min=', -226.44242858886719)
('rgb.max=', 136.09199523925781, 'rgb.min=', -226.23234558105469)
('rgb.max=', 135.99620056152344, 'rgb.min=', -226.01875305175781)
('rgb.max=', 136.16221618652344, 'rgb.min=', -225.85508728027344)
('rgb.max=', 136.32652282714844, 'rgb.min=', -226.041015625)
('rgb.max=', 135.9713134765625, 'rgb.min=', -226.06588745117188)
('rgb.max=', 135.90032958984375, 'rgb.min=', -226.20841979980469)
('rgb.max=', 135.93040466308594, 'rgb.min=', -226.14456176757812)
('rgb.max=', 136.2626953125, 'rgb.min=', -225.7442626953125)
('rgb.max=', 136.14935302734375, 'rgb.min=', -226.067626953125)
('rgb.max=', 136.09884643554688, 'rgb.min=', -226.60816955566406)
('rgb.max=', 135.70130920410156, 'rgb.min=', -225.92689514160156)
('rgb.max=', 136.00271606445312, 'rgb.min=', -225.89573669433594)
('rgb.max=', 135.94338989257812, 'rgb.min=', -226.18655395507812)
('rgb.max=', 135.83688354492188, 'rgb.min=', -226.25515747070312)
('rgb.max=', 136.19778442382812, 'rgb.min=', -225.65377807617188)
('rgb.max=', 135.76666259765625, 'rgb.min=', -226.08316040039062)
('rgb.max=', 136.1932373046875, 'rgb.min=', -226.46261596679688)
('rgb.max=', 135.92323303222656, 'rgb.min=', -226.15792846679688)
('rgb.max=', 136.13932800292969, 'rgb.min=', -226.02255249023438)
('rgb.max=', 135.96072387695312, 'rgb.min=', -226.18222045898438)
('rgb.max=', 136.03904724121094, 'rgb.min=', -225.94172668457031)
('rgb.max=', 135.9342041015625, 'rgb.min=', -226.40055847167969)
('rgb.max=', 136.0299072265625, 'rgb.min=', -226.10444641113281)
('rgb.max=', 136.06382751464844, 'rgb.min=', -226.064208984375)
('rgb.max=', 135.98747253417969, 'rgb.min=', -226.29115295410156)
('rgb.max=', 136.0675048828125, 'rgb.min=', -226.26048278808594)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.95191955566406)
('rgb.max=', 136.18551635742188, 'rgb.min=', -226.02137756347656)
('rgb.max=', 136.0721435546875, 'rgb.min=', -225.91952514648438)
('rgb.max=', 136.10968017578125, 'rgb.min=', -226.09092712402344)
('rgb.max=', 135.87905883789062, 'rgb.min=', -226.30101013183594)
('rgb.max=', 135.97084045410156, 'rgb.min=', -225.91867065429688)
('rgb.max=', 136.12008666992188, 'rgb.min=', -226.18133544921875)
('rgb.max=', 135.98635864257812, 'rgb.min=', -225.91387939453125)
('rgb.max=', 136.04222106933594, 'rgb.min=', -225.94227600097656)
('rgb.max=', 136.11614990234375, 'rgb.min=', -226.11968994140625)
('rgb.max=', 135.95326232910156, 'rgb.min=', -226.17747497558594)
('rgb.max=', 135.97805786132812, 'rgb.min=', -226.3670654296875)
('rgb.max=', 135.81535339355469, 'rgb.min=', -226.08152770996094)
('rgb.max=', 135.92057800292969, 'rgb.min=', -226.110595703125)
('rgb.max=', 135.85585021972656, 'rgb.min=', -225.99693298339844)
('rgb.max=', 136.14794921875, 'rgb.min=', -226.12895202636719)
('rgb.max=', 136.09034729003906, 'rgb.min=', -225.99263000488281)
('rgb.max=', 135.89971923828125, 'rgb.min=', -226.31486511230469)
('rgb.max=', 136.13365173339844, 'rgb.min=', -225.73892211914062)
('rgb.max=', 135.9881591796875, 'rgb.min=', -226.3394775390625)
('rgb.max=', 135.98947143554688, 'rgb.min=', -226.072265625)
('rgb.max=', 135.80953979492188, 'rgb.min=', -226.03738403320312)
('rgb.max=', 135.82174682617188, 'rgb.min=', -226.07708740234375)
('rgb.max=', 135.947265625, 'rgb.min=', -226.319091796875)
('rgb.max=', 135.95042419433594, 'rgb.min=', -226.39390563964844)
('rgb.max=', 135.85397338867188, 'rgb.min=', -225.99948120117188)
('rgb.max=', 135.83436584472656, 'rgb.min=', -226.00433349609375)
('rgb.max=', 136.02423095703125, 'rgb.min=', -226.34550476074219)
('rgb.max=', 136.18742370605469, 'rgb.min=', -226.38357543945312)
('rgb.max=', 135.99563598632812, 'rgb.min=', -226.50982666015625)
('rgb.max=', 136.18376159667969, 'rgb.min=', -226.0872802734375)
('rgb.max=', 136.04470825195312, 'rgb.min=', -225.86212158203125)
('rgb.max=', 136.13197326660156, 'rgb.min=', -226.29327392578125)
('rgb.max=', 135.98576354980469, 'rgb.min=', -226.22682189941406)
('rgb.max=', 136.18626403808594, 'rgb.min=', -226.05961608886719)
('rgb.max=', 135.72276306152344, 'rgb.min=', -226.16549682617188)
('rgb.max=', 136.03256225585938, 'rgb.min=', -226.10383605957031)
('rgb.max=', 136.05972290039062, 'rgb.min=', -226.13323974609375)
('rgb.max=', 136.16903686523438, 'rgb.min=', -225.86294555664062)
('rgb.max=', 136.13922119140625, 'rgb.min=', -226.38902282714844)
('rgb.max=', 135.84629821777344, 'rgb.min=', -225.96292114257812)
('rgb.max=', 135.96270751953125, 'rgb.min=', -225.88229370117188)
('rgb.max=', 135.74874877929688, 'rgb.min=', -226.52764892578125)
('rgb.max=', 135.77426147460938, 'rgb.min=', -226.20184326171875)
('rgb.max=', 135.8819580078125, 'rgb.min=', -226.25379943847656)
('rgb.max=', 135.93646240234375, 'rgb.min=', -226.102783203125)
('rgb.max=', 135.94737243652344, 'rgb.min=', -226.10539245605469)
('rgb.max=', 136.03105163574219, 'rgb.min=', -226.30642700195312)
('rgb.max=', 135.98771667480469, 'rgb.min=', -226.07383728027344)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.186396')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6734 ', 'GAN acc 0.5938', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.5234', 'Total loss: 1.3743', 'for batch', 0)
('GAN loss 0.6824 ', 'GAN acc 0.5508', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4844', 'Total loss: 1.3838', 'for batch', 1)
('GAN loss 0.6666 ', 'GAN acc 0.6172', 'Discriminator loss 0.7083', 'Discriminator accuracy 0.4824', 'Total loss: 1.3749', 'for batch', 2)
('GAN loss 0.6653 ', 'GAN acc 0.5938', 'Discriminator loss 0.7107', 'Discriminator accuracy 0.4727', 'Total loss: 1.3761', 'for batch', 3)
('GAN loss 0.6569 ', 'GAN acc 0.6562', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5176', 'Total loss: 1.3580', 'for batch', 4)
('GAN loss 0.6755 ', 'GAN acc 0.6172', 'Discriminator loss 0.7057', 'Discriminator accuracy 0.4902', 'Total loss: 1.3811', 'for batch', 5)
('GAN loss 0.6749 ', 'GAN acc 0.5977', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.5020', 'Total loss: 1.3746', 'for batch', 6)
('GAN loss 0.6773 ', 'GAN acc 0.5781', 'Discriminator loss 0.7064', 'Discriminator accuracy 0.4805', 'Total loss: 1.3836', 'for batch', 7)
('GAN loss 0.6668 ', 'GAN acc 0.6328', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5176', 'Total loss: 1.3587', 'for batch', 8)
('GAN loss 0.6669 ', 'GAN acc 0.6328', 'Discriminator loss 0.7136', 'Discriminator accuracy 0.4668', 'Total loss: 1.3805', 'for batch', 9)
('GAN loss 0.6803 ', 'GAN acc 0.5820', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.4766', 'Total loss: 1.3847', 'for batch', 10)
('GAN loss 0.6781 ', 'GAN acc 0.5820', 'Discriminator loss 0.7128', 'Discriminator accuracy 0.4434', 'Total loss: 1.3909', 'for batch', 11)
('GAN loss 0.6795 ', 'GAN acc 0.5938', 'Discriminator loss 0.7091', 'Discriminator accuracy 0.4531', 'Total loss: 1.3887', 'for batch', 12)
('GAN loss 0.6620 ', 'GAN acc 0.6172', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.5117', 'Total loss: 1.3601', 'for batch', 13)
('GAN loss 0.6663 ', 'GAN acc 0.6250', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5020', 'Total loss: 1.3632', 'for batch', 14)
('GAN loss 0.6766 ', 'GAN acc 0.5469', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.4941', 'Total loss: 1.3810', 'for batch', 15)
('GAN loss 0.6939 ', 'GAN acc 0.5117', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5215', 'Total loss: 1.3902', 'for batch', 16)
('GAN loss 0.6869 ', 'GAN acc 0.5547', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4883', 'Total loss: 1.3936', 'for batch', 17)
('GAN loss 0.6845 ', 'GAN acc 0.5625', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4941', 'Total loss: 1.3830', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.65062046)
('DISCRIMINATOR_Imagem FAKE=', 0.64922178)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.08280944824219, 'rgb.min=', -226.04170227050781)
('rgb.max=', 135.955322265625, 'rgb.min=', -226.15800476074219)
('rgb.max=', 136.13339233398438, 'rgb.min=', -225.98626708984375)
('rgb.max=', 136.04464721679688, 'rgb.min=', -226.17332458496094)
('rgb.max=', 136.0885009765625, 'rgb.min=', -225.971435546875)
('rgb.max=', 136.30821228027344, 'rgb.min=', -226.41073608398438)
('rgb.max=', 135.86686706542969, 'rgb.min=', -226.36631774902344)
('rgb.max=', 135.97344970703125, 'rgb.min=', -226.03208923339844)
('rgb.max=', 135.876953125, 'rgb.min=', -226.35884094238281)
('rgb.max=', 135.83534240722656, 'rgb.min=', -226.10447692871094)
('rgb.max=', 135.7265625, 'rgb.min=', -226.34800720214844)
('rgb.max=', 135.86834716796875, 'rgb.min=', -226.05572509765625)
('rgb.max=', 135.8570556640625, 'rgb.min=', -226.12322998046875)
('rgb.max=', 135.97299194335938, 'rgb.min=', -226.11753845214844)
('rgb.max=', 135.82452392578125, 'rgb.min=', -226.07945251464844)
('rgb.max=', 135.80250549316406, 'rgb.min=', -226.09159851074219)
('rgb.max=', 135.84187316894531, 'rgb.min=', -225.95635986328125)
('rgb.max=', 135.9139404296875, 'rgb.min=', -225.85797119140625)
('rgb.max=', 135.92001342773438, 'rgb.min=', -226.31887817382812)
('rgb.max=', 135.98812866210938, 'rgb.min=', -226.55130004882812)
('rgb.max=', 136.07958984375, 'rgb.min=', -225.97865295410156)
('rgb.max=', 136.15438842773438, 'rgb.min=', -225.97169494628906)
('rgb.max=', 136.12643432617188, 'rgb.min=', -225.87327575683594)
('rgb.max=', 136.05508422851562, 'rgb.min=', -225.96153259277344)
('rgb.max=', 135.83114624023438, 'rgb.min=', -225.99543762207031)
('rgb.max=', 136.05769348144531, 'rgb.min=', -226.13436889648438)
('rgb.max=', 136.1484375, 'rgb.min=', -226.16152954101562)
('rgb.max=', 135.90580749511719, 'rgb.min=', -226.04653930664062)
('rgb.max=', 135.9111328125, 'rgb.min=', -225.89166259765625)
('rgb.max=', 135.87045288085938, 'rgb.min=', -226.02005004882812)
('rgb.max=', 135.96110534667969, 'rgb.min=', -226.17250061035156)
('rgb.max=', 135.90133666992188, 'rgb.min=', -225.94236755371094)
('rgb.max=', 136.09646606445312, 'rgb.min=', -226.08076477050781)
('rgb.max=', 135.89442443847656, 'rgb.min=', -225.98583984375)
('rgb.max=', 135.94741821289062, 'rgb.min=', -226.06228637695312)
('rgb.max=', 136.01129150390625, 'rgb.min=', -225.98600769042969)
('rgb.max=', 136.18475341796875, 'rgb.min=', -226.00326538085938)
('rgb.max=', 136.03408813476562, 'rgb.min=', -226.05793762207031)
('rgb.max=', 136.02426147460938, 'rgb.min=', -225.95783996582031)
('rgb.max=', 136.03047180175781, 'rgb.min=', -226.0159912109375)
('rgb.max=', 135.73471069335938, 'rgb.min=', -225.88157653808594)
('rgb.max=', 135.99452209472656, 'rgb.min=', -226.30984497070312)
('rgb.max=', 135.91145324707031, 'rgb.min=', -226.09463500976562)
('rgb.max=', 135.93519592285156, 'rgb.min=', -225.91096496582031)
('rgb.max=', 135.94976806640625, 'rgb.min=', -226.59864807128906)
('rgb.max=', 135.66777038574219, 'rgb.min=', -225.89108276367188)
('rgb.max=', 135.9178466796875, 'rgb.min=', -226.05654907226562)
('rgb.max=', 135.76869201660156, 'rgb.min=', -225.87576293945312)
('rgb.max=', 135.90948486328125, 'rgb.min=', -225.96064758300781)
('rgb.max=', 136.22688293457031, 'rgb.min=', -226.05291748046875)
('rgb.max=', 135.99478149414062, 'rgb.min=', -226.05299377441406)
('rgb.max=', 136.26309204101562, 'rgb.min=', -226.02104187011719)
('rgb.max=', 135.68865966796875, 'rgb.min=', -226.1396484375)
('rgb.max=', 135.77923583984375, 'rgb.min=', -226.15473937988281)
('rgb.max=', 136.08123779296875, 'rgb.min=', -226.18235778808594)
('rgb.max=', 136.13864135742188, 'rgb.min=', -226.08393859863281)
('rgb.max=', 135.89262390136719, 'rgb.min=', -226.13566589355469)
('rgb.max=', 135.84542846679688, 'rgb.min=', -225.87796020507812)
('rgb.max=', 135.89529418945312, 'rgb.min=', -225.95550537109375)
('rgb.max=', 135.61799621582031, 'rgb.min=', -226.18910217285156)
('rgb.max=', 136.00851440429688, 'rgb.min=', -226.03866577148438)
('rgb.max=', 135.75975036621094, 'rgb.min=', -225.82789611816406)
('rgb.max=', 135.74490356445312, 'rgb.min=', -226.00929260253906)
('rgb.max=', 135.75973510742188, 'rgb.min=', -226.5321044921875)
('rgb.max=', 136.36819458007812, 'rgb.min=', -225.90763854980469)
('rgb.max=', 135.99652099609375, 'rgb.min=', -226.22990417480469)
('rgb.max=', 135.7034912109375, 'rgb.min=', -225.89511108398438)
('rgb.max=', 135.73954772949219, 'rgb.min=', -226.10586547851562)
('rgb.max=', 136.09140014648438, 'rgb.min=', -226.28863525390625)
('rgb.max=', 136.1148681640625, 'rgb.min=', -226.11997985839844)
('rgb.max=', 136.04743957519531, 'rgb.min=', -226.07279968261719)
('rgb.max=', 135.78872680664062, 'rgb.min=', -226.13157653808594)
('rgb.max=', 135.90950012207031, 'rgb.min=', -226.44216918945312)
('rgb.max=', 136.01138305664062, 'rgb.min=', -226.20713806152344)
('rgb.max=', 135.91217041015625, 'rgb.min=', -225.7952880859375)
('rgb.max=', 136.05650329589844, 'rgb.min=', -226.11668395996094)
('rgb.max=', 136.23202514648438, 'rgb.min=', -226.048828125)
('rgb.max=', 136.12030029296875, 'rgb.min=', -225.99745178222656)
('rgb.max=', 135.76681518554688, 'rgb.min=', -226.11079406738281)
('rgb.max=', 135.99281311035156, 'rgb.min=', -225.92288208007812)
('rgb.max=', 136.05796813964844, 'rgb.min=', -225.70327758789062)
('rgb.max=', 135.89920043945312, 'rgb.min=', -225.93544006347656)
('rgb.max=', 135.820068359375, 'rgb.min=', -226.12449645996094)
('rgb.max=', 136.02304077148438, 'rgb.min=', -226.21446228027344)
('rgb.max=', 136.02751159667969, 'rgb.min=', -226.30513000488281)
('rgb.max=', 135.91567993164062, 'rgb.min=', -226.18907165527344)
('rgb.max=', 136.03054809570312, 'rgb.min=', -225.82473754882812)
('rgb.max=', 135.77011108398438, 'rgb.min=', -225.95851135253906)
('rgb.max=', 135.9627685546875, 'rgb.min=', -226.42643737792969)
('rgb.max=', 135.68807983398438, 'rgb.min=', -225.80479431152344)
('rgb.max=', 135.87747192382812, 'rgb.min=', -225.97787475585938)
('rgb.max=', 135.80311584472656, 'rgb.min=', -226.41452026367188)
('rgb.max=', 135.83229064941406, 'rgb.min=', -226.53215026855469)
('rgb.max=', 135.7662353515625, 'rgb.min=', -225.94146728515625)
('rgb.max=', 135.80424499511719, 'rgb.min=', -225.81259155273438)
('rgb.max=', 136.1121826171875, 'rgb.min=', -226.01953125)
('rgb.max=', 136.02801513671875, 'rgb.min=', -226.02766418457031)
('rgb.max=', 135.9652099609375, 'rgb.min=', -226.60646057128906)
('rgb.max=', 135.79168701171875, 'rgb.min=', -226.24836730957031)
('rgb.max=', 135.97161865234375, 'rgb.min=', -226.06990051269531)
('rgb.max=', 135.89091491699219, 'rgb.min=', -226.10774230957031)
('rgb.max=', 135.74899291992188, 'rgb.min=', -225.9197998046875)
('rgb.max=', 136.07164001464844, 'rgb.min=', -225.95164489746094)
('rgb.max=', 135.90444946289062, 'rgb.min=', -225.9788818359375)
('rgb.max=', 135.92265319824219, 'rgb.min=', -225.84634399414062)
('rgb.max=', 136.1705322265625, 'rgb.min=', -226.10508728027344)
('rgb.max=', 135.95004272460938, 'rgb.min=', -226.17889404296875)
('rgb.max=', 135.98591613769531, 'rgb.min=', -226.07571411132812)
('rgb.max=', 136.12117004394531, 'rgb.min=', -226.08988952636719)
('rgb.max=', 136.09042358398438, 'rgb.min=', -225.947998046875)
('rgb.max=', 136.05039978027344, 'rgb.min=', -226.0899658203125)
('rgb.max=', 136.17684936523438, 'rgb.min=', -225.91600036621094)
('rgb.max=', 135.95027160644531, 'rgb.min=', -225.84689331054688)
('rgb.max=', 136.0616455078125, 'rgb.min=', -225.87765502929688)
('rgb.max=', 135.86907958984375, 'rgb.min=', -226.06332397460938)
('rgb.max=', 135.88980102539062, 'rgb.min=', -226.54322814941406)
('rgb.max=', 135.61433410644531, 'rgb.min=', -226.0443115234375)
('rgb.max=', 136.01217651367188, 'rgb.min=', -225.89509582519531)
('rgb.max=', 135.81893920898438, 'rgb.min=', -225.88978576660156)
('rgb.max=', 136.03799438476562, 'rgb.min=', -225.93539428710938)
('rgb.max=', 136.07377624511719, 'rgb.min=', -226.02873229980469)
('rgb.max=', 136.30058288574219, 'rgb.min=', -226.03201293945312)
('rgb.max=', 135.829345703125, 'rgb.min=', -225.94381713867188)
('rgb.max=', 135.92620849609375, 'rgb.min=', -225.94654846191406)
('rgb.max=', 135.84175109863281, 'rgb.min=', -225.97116088867188)
('rgb.max=', 135.99491882324219, 'rgb.min=', -226.26177978515625)
('rgb.max=', 135.86825561523438, 'rgb.min=', -225.80224609375)
('rgb.max=', 136.2513427734375, 'rgb.min=', -225.99220275878906)
('rgb.max=', 135.64749145507812, 'rgb.min=', -226.2332763671875)
('rgb.max=', 136.02932739257812, 'rgb.min=', -226.22247314453125)
('rgb.max=', 136.03726196289062, 'rgb.min=', -225.98176574707031)
('rgb.max=', 135.75544738769531, 'rgb.min=', -226.2381591796875)
('rgb.max=', 135.97525024414062, 'rgb.min=', -225.98374938964844)
('rgb.max=', 136.15921020507812, 'rgb.min=', -225.90948486328125)
('rgb.max=', 136.0916748046875, 'rgb.min=', -225.97285461425781)
('rgb.max=', 135.75410461425781, 'rgb.min=', -226.29058837890625)
('rgb.max=', 135.90184020996094, 'rgb.min=', -226.34169006347656)
('rgb.max=', 136.07791137695312, 'rgb.min=', -225.96543884277344)
('rgb.max=', 135.84909057617188, 'rgb.min=', -226.14143371582031)
('rgb.max=', 136.04226684570312, 'rgb.min=', -225.99444580078125)
('rgb.max=', 135.91075134277344, 'rgb.min=', -225.86941528320312)
('rgb.max=', 136.20274353027344, 'rgb.min=', -226.15310668945312)
('rgb.max=', 135.75303649902344, 'rgb.min=', -226.28657531738281)
('rgb.max=', 136.1376953125, 'rgb.min=', -226.01129150390625)
('rgb.max=', 135.94805908203125, 'rgb.min=', -226.16633605957031)
('rgb.max=', 136.13551330566406, 'rgb.min=', -225.9354248046875)
('rgb.max=', 135.88589477539062, 'rgb.min=', -225.89112854003906)
('rgb.max=', 136.10684204101562, 'rgb.min=', -226.28175354003906)
('rgb.max=', 136.08134460449219, 'rgb.min=', -226.22492980957031)
('rgb.max=', 136.19912719726562, 'rgb.min=', -225.96755981445312)
('rgb.max=', 135.84623718261719, 'rgb.min=', -225.97102355957031)
('rgb.max=', 136.05419921875, 'rgb.min=', -225.98725891113281)
('rgb.max=', 136.06239318847656, 'rgb.min=', -226.16632080078125)
('rgb.max=', 136.04508972167969, 'rgb.min=', -226.15763854980469)
('rgb.max=', 135.86949157714844, 'rgb.min=', -226.08009338378906)
('rgb.max=', 135.87582397460938, 'rgb.min=', -225.85377502441406)
('rgb.max=', 136.08921813964844, 'rgb.min=', -226.13531494140625)
('rgb.max=', 136.00212097167969, 'rgb.min=', -225.95614624023438)
('rgb.max=', 135.79153442382812, 'rgb.min=', -226.41015625)
('rgb.max=', 135.83428955078125, 'rgb.min=', -225.8231201171875)
('rgb.max=', 135.863525390625, 'rgb.min=', -225.85629272460938)
('rgb.max=', 135.96833801269531, 'rgb.min=', -226.21717834472656)
('rgb.max=', 135.95384216308594, 'rgb.min=', -226.07792663574219)
('rgb.max=', 135.73463439941406, 'rgb.min=', -225.95870971679688)
('rgb.max=', 136.17825317382812, 'rgb.min=', -226.04702758789062)
('rgb.max=', 136.14389038085938, 'rgb.min=', -225.98356628417969)
('rgb.max=', 136.04747009277344, 'rgb.min=', -226.29847717285156)
('rgb.max=', 135.6590576171875, 'rgb.min=', -226.015380859375)
('rgb.max=', 136.15672302246094, 'rgb.min=', -226.03277587890625)
('rgb.max=', 136.11135864257812, 'rgb.min=', -226.00337219238281)
('rgb.max=', 135.82652282714844, 'rgb.min=', -225.96614074707031)
('rgb.max=', 136.14016723632812, 'rgb.min=', -226.01518249511719)
('rgb.max=', 136.11235046386719, 'rgb.min=', -226.11152648925781)
('rgb.max=', 136.0133056640625, 'rgb.min=', -225.96859741210938)
('rgb.max=', 135.94989013671875, 'rgb.min=', -226.09318542480469)
('rgb.max=', 136.11529541015625, 'rgb.min=', -226.11685180664062)
('rgb.max=', 136.09127807617188, 'rgb.min=', -226.14595031738281)
('rgb.max=', 135.79817199707031, 'rgb.min=', -226.0606689453125)
('rgb.max=', 135.7603759765625, 'rgb.min=', -226.02969360351562)
('rgb.max=', 135.79402160644531, 'rgb.min=', -225.83421325683594)
('rgb.max=', 135.96308898925781, 'rgb.min=', -226.37159729003906)
('rgb.max=', 136.06915283203125, 'rgb.min=', -226.13908386230469)
('rgb.max=', 135.97282409667969, 'rgb.min=', -225.96586608886719)
('rgb.max=', 136.11961364746094, 'rgb.min=', -225.78031921386719)
('rgb.max=', 136.27586364746094, 'rgb.min=', -225.97611999511719)
('rgb.max=', 135.95722961425781, 'rgb.min=', -225.98782348632812)
('rgb.max=', 135.87124633789062, 'rgb.min=', -226.14788818359375)
('rgb.max=', 135.90887451171875, 'rgb.min=', -226.06324768066406)
('rgb.max=', 136.21354675292969, 'rgb.min=', -225.59246826171875)
('rgb.max=', 136.11302185058594, 'rgb.min=', -226.04327392578125)
('rgb.max=', 136.03121948242188, 'rgb.min=', -226.53659057617188)
('rgb.max=', 135.65763854980469, 'rgb.min=', -225.84762573242188)
('rgb.max=', 135.97660827636719, 'rgb.min=', -225.78538513183594)
('rgb.max=', 135.92884826660156, 'rgb.min=', -226.12864685058594)
('rgb.max=', 135.81887817382812, 'rgb.min=', -226.19615173339844)
('rgb.max=', 136.174072265625, 'rgb.min=', -225.6104736328125)
('rgb.max=', 135.74028015136719, 'rgb.min=', -226.01873779296875)
('rgb.max=', 136.17225646972656, 'rgb.min=', -226.42140197753906)
('rgb.max=', 135.90495300292969, 'rgb.min=', -226.13359069824219)
('rgb.max=', 136.1107177734375, 'rgb.min=', -225.89642333984375)
('rgb.max=', 135.93563842773438, 'rgb.min=', -226.11647033691406)
('rgb.max=', 136.03822326660156, 'rgb.min=', -225.91030883789062)
('rgb.max=', 135.90545654296875, 'rgb.min=', -226.33082580566406)
('rgb.max=', 136.00723266601562, 'rgb.min=', -226.02926635742188)
('rgb.max=', 136.06159973144531, 'rgb.min=', -226.02000427246094)
('rgb.max=', 135.9522705078125, 'rgb.min=', -226.22578430175781)
('rgb.max=', 136.01594543457031, 'rgb.min=', -226.23484802246094)
('rgb.max=', 135.83207702636719, 'rgb.min=', -225.85226440429688)
('rgb.max=', 136.15914916992188, 'rgb.min=', -225.94828796386719)
('rgb.max=', 136.07757568359375, 'rgb.min=', -225.82456970214844)
('rgb.max=', 136.06280517578125, 'rgb.min=', -226.01972961425781)
('rgb.max=', 135.85012817382812, 'rgb.min=', -226.22076416015625)
('rgb.max=', 135.9306640625, 'rgb.min=', -225.88906860351562)
('rgb.max=', 136.13624572753906, 'rgb.min=', -226.11126708984375)
('rgb.max=', 135.94122314453125, 'rgb.min=', -225.79949951171875)
('rgb.max=', 136.02117919921875, 'rgb.min=', -225.85331726074219)
('rgb.max=', 136.08676147460938, 'rgb.min=', -226.00033569335938)
('rgb.max=', 135.94158935546875, 'rgb.min=', -226.09785461425781)
('rgb.max=', 135.94168090820312, 'rgb.min=', -226.29591369628906)
('rgb.max=', 135.79052734375, 'rgb.min=', -225.97637939453125)
('rgb.max=', 135.904052734375, 'rgb.min=', -226.03709411621094)
('rgb.max=', 135.82893371582031, 'rgb.min=', -225.93238830566406)
('rgb.max=', 136.14999389648438, 'rgb.min=', -226.10104370117188)
('rgb.max=', 136.07933044433594, 'rgb.min=', -225.9041748046875)
('rgb.max=', 135.87615966796875, 'rgb.min=', -226.23371887207031)
('rgb.max=', 136.09719848632812, 'rgb.min=', -225.71697998046875)
('rgb.max=', 135.957275390625, 'rgb.min=', -226.27073669433594)
('rgb.max=', 135.99165344238281, 'rgb.min=', -226.00291442871094)
('rgb.max=', 135.77203369140625, 'rgb.min=', -225.9847412109375)
('rgb.max=', 135.8013916015625, 'rgb.min=', -225.95333862304688)
('rgb.max=', 135.90769958496094, 'rgb.min=', -226.23284912109375)
('rgb.max=', 135.92568969726562, 'rgb.min=', -226.33114624023438)
('rgb.max=', 135.8394775390625, 'rgb.min=', -225.93765258789062)
('rgb.max=', 135.81732177734375, 'rgb.min=', -225.92182922363281)
('rgb.max=', 135.98629760742188, 'rgb.min=', -226.26771545410156)
('rgb.max=', 136.14628601074219, 'rgb.min=', -226.31208801269531)
('rgb.max=', 135.93284606933594, 'rgb.min=', -226.43165588378906)
('rgb.max=', 136.13832092285156, 'rgb.min=', -226.02755737304688)
('rgb.max=', 136.01728820800781, 'rgb.min=', -225.79551696777344)
('rgb.max=', 136.09262084960938, 'rgb.min=', -226.22525024414062)
('rgb.max=', 135.968994140625, 'rgb.min=', -226.16183471679688)
('rgb.max=', 136.15281677246094, 'rgb.min=', -225.98127746582031)
('rgb.max=', 135.69784545898438, 'rgb.min=', -226.09614562988281)
('rgb.max=', 135.99197387695312, 'rgb.min=', -226.07801818847656)
('rgb.max=', 136.03254699707031, 'rgb.min=', -226.06686401367188)
('rgb.max=', 136.1146240234375, 'rgb.min=', -225.84783935546875)
('rgb.max=', 136.11940002441406, 'rgb.min=', -226.29550170898438)
('rgb.max=', 135.83355712890625, 'rgb.min=', -225.87921142578125)
('rgb.max=', 135.93280029296875, 'rgb.min=', -225.83811950683594)
('rgb.max=', 135.70921325683594, 'rgb.min=', -226.44767761230469)
('rgb.max=', 135.75428771972656, 'rgb.min=', -226.12834167480469)
('rgb.max=', 135.86758422851562, 'rgb.min=', -226.17689514160156)
('rgb.max=', 135.91984558105469, 'rgb.min=', -226.02944946289062)
('rgb.max=', 135.91845703125, 'rgb.min=', -226.04710388183594)
('rgb.max=', 135.98681640625, 'rgb.min=', -226.22906494140625)
('rgb.max=', 135.95538330078125, 'rgb.min=', -225.98896789550781)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.691089')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6865 ', 'GAN acc 0.5352', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4824', 'Total loss: 1.3843', 'for batch', 0)
('GAN loss 0.6772 ', 'GAN acc 0.5898', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5410', 'Total loss: 1.3723', 'for batch', 1)
('GAN loss 0.6875 ', 'GAN acc 0.5117', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.5000', 'Total loss: 1.3849', 'for batch', 2)
('GAN loss 0.6763 ', 'GAN acc 0.6055', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4570', 'Total loss: 1.3800', 'for batch', 3)
('GAN loss 0.6800 ', 'GAN acc 0.5742', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4980', 'Total loss: 1.3814', 'for batch', 4)
('GAN loss 0.6878 ', 'GAN acc 0.5430', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.5371', 'Total loss: 1.3877', 'for batch', 5)
('GAN loss 0.6751 ', 'GAN acc 0.5938', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4883', 'Total loss: 1.3739', 'for batch', 6)
('GAN loss 0.6837 ', 'GAN acc 0.5664', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4727', 'Total loss: 1.3839', 'for batch', 7)
('GAN loss 0.6901 ', 'GAN acc 0.5352', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4961', 'Total loss: 1.3864', 'for batch', 8)
('GAN loss 0.6997 ', 'GAN acc 0.5078', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4785', 'Total loss: 1.4007', 'for batch', 9)
('GAN loss 0.6866 ', 'GAN acc 0.5625', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4824', 'Total loss: 1.3881', 'for batch', 10)
('GAN loss 0.6829 ', 'GAN acc 0.5312', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4980', 'Total loss: 1.3794', 'for batch', 11)
('GAN loss 0.6760 ', 'GAN acc 0.6094', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.5039', 'Total loss: 1.3807', 'for batch', 12)
('GAN loss 0.6822 ', 'GAN acc 0.5469', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4883', 'Total loss: 1.3837', 'for batch', 13)
('GAN loss 0.6872 ', 'GAN acc 0.5586', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5098', 'Total loss: 1.3837', 'for batch', 14)
('GAN loss 0.7038 ', 'GAN acc 0.4922', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4648', 'Total loss: 1.4022', 'for batch', 15)
('GAN loss 0.7076 ', 'GAN acc 0.5000', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4707', 'Total loss: 1.4075', 'for batch', 16)
('GAN loss 0.7132 ', 'GAN acc 0.4453', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4902', 'Total loss: 1.4168', 'for batch', 17)
('GAN loss 0.7039 ', 'GAN acc 0.4219', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4863', 'Total loss: 1.4077', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.61307842)
('DISCRIMINATOR_Imagem FAKE=', 0.61351556)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.05198669433594, 'rgb.min=', -225.87559509277344)
('rgb.max=', 135.9429931640625, 'rgb.min=', -226.02275085449219)
('rgb.max=', 136.12071228027344, 'rgb.min=', -225.94793701171875)
('rgb.max=', 136.0242919921875, 'rgb.min=', -226.16316223144531)
('rgb.max=', 136.09855651855469, 'rgb.min=', -225.93600463867188)
('rgb.max=', 136.28677368164062, 'rgb.min=', -226.34793090820312)
('rgb.max=', 135.86558532714844, 'rgb.min=', -226.17338562011719)
('rgb.max=', 135.95843505859375, 'rgb.min=', -226.01466369628906)
('rgb.max=', 135.87673950195312, 'rgb.min=', -226.30696105957031)
('rgb.max=', 135.82498168945312, 'rgb.min=', -226.05796813964844)
('rgb.max=', 135.70875549316406, 'rgb.min=', -226.16354370117188)
('rgb.max=', 135.87095642089844, 'rgb.min=', -226.01927185058594)
('rgb.max=', 135.82191467285156, 'rgb.min=', -226.11320495605469)
('rgb.max=', 135.96096801757812, 'rgb.min=', -226.145751953125)
('rgb.max=', 135.82693481445312, 'rgb.min=', -225.99955749511719)
('rgb.max=', 135.80453491210938, 'rgb.min=', -226.05978393554688)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.96141052246094)
('rgb.max=', 135.91525268554688, 'rgb.min=', -225.79618835449219)
('rgb.max=', 135.92575073242188, 'rgb.min=', -226.11599731445312)
('rgb.max=', 135.982421875, 'rgb.min=', -226.3408203125)
('rgb.max=', 136.07945251464844, 'rgb.min=', -225.90272521972656)
('rgb.max=', 136.14306640625, 'rgb.min=', -225.94789123535156)
('rgb.max=', 136.11042785644531, 'rgb.min=', -225.84689331054688)
('rgb.max=', 136.0543212890625, 'rgb.min=', -225.83984375)
('rgb.max=', 135.810302734375, 'rgb.min=', -225.96940612792969)
('rgb.max=', 136.08120727539062, 'rgb.min=', -226.03732299804688)
('rgb.max=', 136.10777282714844, 'rgb.min=', -226.09486389160156)
('rgb.max=', 135.853515625, 'rgb.min=', -226.02076721191406)
('rgb.max=', 135.92262268066406, 'rgb.min=', -225.85639953613281)
('rgb.max=', 135.82344055175781, 'rgb.min=', -226.04313659667969)
('rgb.max=', 135.93362426757812, 'rgb.min=', -226.14218139648438)
('rgb.max=', 135.88845825195312, 'rgb.min=', -225.98574829101562)
('rgb.max=', 136.09439086914062, 'rgb.min=', -226.08695983886719)
('rgb.max=', 135.89031982421875, 'rgb.min=', -225.98210144042969)
('rgb.max=', 135.95797729492188, 'rgb.min=', -226.04774475097656)
('rgb.max=', 136.01316833496094, 'rgb.min=', -225.9547119140625)
('rgb.max=', 136.18243408203125, 'rgb.min=', -225.99395751953125)
('rgb.max=', 136.03031921386719, 'rgb.min=', -226.03790283203125)
('rgb.max=', 136.01704406738281, 'rgb.min=', -225.94203186035156)
('rgb.max=', 136.0267333984375, 'rgb.min=', -225.99871826171875)
('rgb.max=', 135.73539733886719, 'rgb.min=', -225.88546752929688)
('rgb.max=', 136.00640869140625, 'rgb.min=', -226.17323303222656)
('rgb.max=', 135.91366577148438, 'rgb.min=', -226.06314086914062)
('rgb.max=', 135.91624450683594, 'rgb.min=', -225.89674377441406)
('rgb.max=', 135.9224853515625, 'rgb.min=', -226.42533874511719)
('rgb.max=', 135.63774108886719, 'rgb.min=', -225.89627075195312)
('rgb.max=', 135.93702697753906, 'rgb.min=', -226.024658203125)
('rgb.max=', 135.74160766601562, 'rgb.min=', -225.82733154296875)
('rgb.max=', 135.897216796875, 'rgb.min=', -225.96907043457031)
('rgb.max=', 136.2449951171875, 'rgb.min=', -226.07545471191406)
('rgb.max=', 135.9659423828125, 'rgb.min=', -226.11082458496094)
('rgb.max=', 136.2489013671875, 'rgb.min=', -226.01470947265625)
('rgb.max=', 135.71675109863281, 'rgb.min=', -226.01216125488281)
('rgb.max=', 135.77955627441406, 'rgb.min=', -226.14328002929688)
('rgb.max=', 136.07388305664062, 'rgb.min=', -226.08619689941406)
('rgb.max=', 136.10122680664062, 'rgb.min=', -226.08113098144531)
('rgb.max=', 135.89044189453125, 'rgb.min=', -226.06686401367188)
('rgb.max=', 135.84443664550781, 'rgb.min=', -225.85943603515625)
('rgb.max=', 135.89785766601562, 'rgb.min=', -225.96820068359375)
('rgb.max=', 135.60971069335938, 'rgb.min=', -226.15150451660156)
('rgb.max=', 135.96174621582031, 'rgb.min=', -226.02943420410156)
('rgb.max=', 135.76559448242188, 'rgb.min=', -225.83247375488281)
('rgb.max=', 135.70329284667969, 'rgb.min=', -225.92642211914062)
('rgb.max=', 135.78170776367188, 'rgb.min=', -226.32438659667969)
('rgb.max=', 136.40184020996094, 'rgb.min=', -225.83477783203125)
('rgb.max=', 135.98410034179688, 'rgb.min=', -226.17782592773438)
('rgb.max=', 135.70881652832031, 'rgb.min=', -225.89306640625)
('rgb.max=', 135.7412109375, 'rgb.min=', -226.07002258300781)
('rgb.max=', 136.08279418945312, 'rgb.min=', -226.2880859375)
('rgb.max=', 136.07096862792969, 'rgb.min=', -226.16525268554688)
('rgb.max=', 136.03239440917969, 'rgb.min=', -226.04925537109375)
('rgb.max=', 135.79295349121094, 'rgb.min=', -226.07048034667969)
('rgb.max=', 135.91900634765625, 'rgb.min=', -226.24935913085938)
('rgb.max=', 136.01528930664062, 'rgb.min=', -226.23359680175781)
('rgb.max=', 135.90550231933594, 'rgb.min=', -225.79597473144531)
('rgb.max=', 136.06178283691406, 'rgb.min=', -226.02993774414062)
('rgb.max=', 136.27798461914062, 'rgb.min=', -226.07470703125)
('rgb.max=', 136.11192321777344, 'rgb.min=', -225.86607360839844)
('rgb.max=', 135.77000427246094, 'rgb.min=', -225.99964904785156)
('rgb.max=', 135.9678955078125, 'rgb.min=', -225.90457153320312)
('rgb.max=', 136.04104614257812, 'rgb.min=', -225.64726257324219)
('rgb.max=', 135.88357543945312, 'rgb.min=', -225.92970275878906)
('rgb.max=', 135.80328369140625, 'rgb.min=', -226.03150939941406)
('rgb.max=', 136.03083801269531, 'rgb.min=', -226.18658447265625)
('rgb.max=', 136.03276062011719, 'rgb.min=', -226.26409912109375)
('rgb.max=', 135.90325927734375, 'rgb.min=', -226.03839111328125)
('rgb.max=', 136.05047607421875, 'rgb.min=', -225.82699584960938)
('rgb.max=', 135.76860046386719, 'rgb.min=', -225.95823669433594)
('rgb.max=', 135.97111511230469, 'rgb.min=', -226.23880004882812)
('rgb.max=', 135.67803955078125, 'rgb.min=', -225.75459289550781)
('rgb.max=', 135.88337707519531, 'rgb.min=', -225.9638671875)
('rgb.max=', 135.80867004394531, 'rgb.min=', -226.26571655273438)
('rgb.max=', 135.80386352539062, 'rgb.min=', -226.36447143554688)
('rgb.max=', 135.76100158691406, 'rgb.min=', -225.89682006835938)
('rgb.max=', 135.78108215332031, 'rgb.min=', -225.75471496582031)
('rgb.max=', 136.12393188476562, 'rgb.min=', -225.95353698730469)
('rgb.max=', 136.00823974609375, 'rgb.min=', -225.99740600585938)
('rgb.max=', 135.97909545898438, 'rgb.min=', -226.46234130859375)
('rgb.max=', 135.79171752929688, 'rgb.min=', -226.20945739746094)
('rgb.max=', 135.9674072265625, 'rgb.min=', -226.02403259277344)
('rgb.max=', 135.88735961914062, 'rgb.min=', -226.06312561035156)
('rgb.max=', 135.75639343261719, 'rgb.min=', -225.92692565917969)
('rgb.max=', 136.06491088867188, 'rgb.min=', -225.8502197265625)
('rgb.max=', 135.90890502929688, 'rgb.min=', -225.92990112304688)
('rgb.max=', 135.92471313476562, 'rgb.min=', -225.84028625488281)
('rgb.max=', 136.15852355957031, 'rgb.min=', -226.053466796875)
('rgb.max=', 135.93014526367188, 'rgb.min=', -226.07505798339844)
('rgb.max=', 135.98147583007812, 'rgb.min=', -226.09303283691406)
('rgb.max=', 136.09663391113281, 'rgb.min=', -226.07333374023438)
('rgb.max=', 136.08323669433594, 'rgb.min=', -225.88851928710938)
('rgb.max=', 136.02519226074219, 'rgb.min=', -226.03407287597656)
('rgb.max=', 136.16525268554688, 'rgb.min=', -225.87901306152344)
('rgb.max=', 135.95236206054688, 'rgb.min=', -225.83279418945312)
('rgb.max=', 136.06788635253906, 'rgb.min=', -225.82476806640625)
('rgb.max=', 135.871337890625, 'rgb.min=', -226.05630493164062)
('rgb.max=', 135.85659790039062, 'rgb.min=', -226.34135437011719)
('rgb.max=', 135.62081909179688, 'rgb.min=', -226.00135803222656)
('rgb.max=', 136.01231384277344, 'rgb.min=', -225.81690979003906)
('rgb.max=', 135.79682922363281, 'rgb.min=', -225.88319396972656)
('rgb.max=', 136.02250671386719, 'rgb.min=', -225.88688659667969)
('rgb.max=', 136.02053833007812, 'rgb.min=', -226.01951599121094)
('rgb.max=', 136.35614013671875, 'rgb.min=', -226.02445983886719)
('rgb.max=', 135.82829284667969, 'rgb.min=', -225.94586181640625)
('rgb.max=', 135.91546630859375, 'rgb.min=', -225.9403076171875)
('rgb.max=', 135.81916809082031, 'rgb.min=', -225.93058776855469)
('rgb.max=', 135.9609375, 'rgb.min=', -226.1044921875)
('rgb.max=', 135.86007690429688, 'rgb.min=', -225.77853393554688)
('rgb.max=', 136.26898193359375, 'rgb.min=', -225.95855712890625)
('rgb.max=', 135.65254211425781, 'rgb.min=', -226.1671142578125)
('rgb.max=', 136.00740051269531, 'rgb.min=', -226.14340209960938)
('rgb.max=', 136.03877258300781, 'rgb.min=', -225.81869506835938)
('rgb.max=', 135.75143432617188, 'rgb.min=', -226.22596740722656)
('rgb.max=', 135.94998168945312, 'rgb.min=', -225.98063659667969)
('rgb.max=', 136.12098693847656, 'rgb.min=', -225.90370178222656)
('rgb.max=', 136.07682800292969, 'rgb.min=', -225.92715454101562)
('rgb.max=', 135.72720336914062, 'rgb.min=', -226.18350219726562)
('rgb.max=', 135.89923095703125, 'rgb.min=', -226.17181396484375)
('rgb.max=', 136.07504272460938, 'rgb.min=', -225.85700988769531)
('rgb.max=', 135.84130859375, 'rgb.min=', -226.10285949707031)
('rgb.max=', 136.03086853027344, 'rgb.min=', -225.9788818359375)
('rgb.max=', 135.90080261230469, 'rgb.min=', -225.86758422851562)
('rgb.max=', 136.15129089355469, 'rgb.min=', -226.01513671875)
('rgb.max=', 135.75845336914062, 'rgb.min=', -226.11714172363281)
('rgb.max=', 136.11573791503906, 'rgb.min=', -225.9056396484375)
('rgb.max=', 135.95660400390625, 'rgb.min=', -226.09814453125)
('rgb.max=', 136.11181640625, 'rgb.min=', -225.88836669921875)
('rgb.max=', 135.89138793945312, 'rgb.min=', -225.85261535644531)
('rgb.max=', 136.10293579101562, 'rgb.min=', -226.137939453125)
('rgb.max=', 136.07179260253906, 'rgb.min=', -226.17127990722656)
('rgb.max=', 136.1895751953125, 'rgb.min=', -225.87173461914062)
('rgb.max=', 135.84529113769531, 'rgb.min=', -225.94001770019531)
('rgb.max=', 136.04530334472656, 'rgb.min=', -225.83448791503906)
('rgb.max=', 136.06552124023438, 'rgb.min=', -226.05680847167969)
('rgb.max=', 136.01284790039062, 'rgb.min=', -226.11268615722656)
('rgb.max=', 135.88328552246094, 'rgb.min=', -226.01593017578125)
('rgb.max=', 135.87721252441406, 'rgb.min=', -225.80976867675781)
('rgb.max=', 136.07365417480469, 'rgb.min=', -226.08146667480469)
('rgb.max=', 135.99432373046875, 'rgb.min=', -225.89395141601562)
('rgb.max=', 135.793701171875, 'rgb.min=', -226.24021911621094)
('rgb.max=', 135.81436157226562, 'rgb.min=', -225.78717041015625)
('rgb.max=', 135.86767578125, 'rgb.min=', -225.80717468261719)
('rgb.max=', 135.96905517578125, 'rgb.min=', -226.06303405761719)
('rgb.max=', 135.95401000976562, 'rgb.min=', -226.01779174804688)
('rgb.max=', 135.73837280273438, 'rgb.min=', -225.93304443359375)
('rgb.max=', 136.17027282714844, 'rgb.min=', -226.01141357421875)
('rgb.max=', 136.14047241210938, 'rgb.min=', -225.8597412109375)
('rgb.max=', 136.02728271484375, 'rgb.min=', -226.17488098144531)
('rgb.max=', 135.65164184570312, 'rgb.min=', -225.90269470214844)
('rgb.max=', 136.15103149414062, 'rgb.min=', -225.98670959472656)
('rgb.max=', 136.08612060546875, 'rgb.min=', -225.96377563476562)
('rgb.max=', 135.81686401367188, 'rgb.min=', -225.97901916503906)
('rgb.max=', 136.09184265136719, 'rgb.min=', -225.9364013671875)
('rgb.max=', 136.10610961914062, 'rgb.min=', -226.008544921875)
('rgb.max=', 135.98724365234375, 'rgb.min=', -225.94761657714844)
('rgb.max=', 135.94186401367188, 'rgb.min=', -226.05101013183594)
('rgb.max=', 136.11128234863281, 'rgb.min=', -226.04299926757812)
('rgb.max=', 136.07843017578125, 'rgb.min=', -226.07760620117188)
('rgb.max=', 135.79672241210938, 'rgb.min=', -226.05140686035156)
('rgb.max=', 135.7657470703125, 'rgb.min=', -225.9549560546875)
('rgb.max=', 135.78460693359375, 'rgb.min=', -225.78990173339844)
('rgb.max=', 135.98330688476562, 'rgb.min=', -226.29086303710938)
('rgb.max=', 136.06460571289062, 'rgb.min=', -226.01710510253906)
('rgb.max=', 135.97564697265625, 'rgb.min=', -225.96107482910156)
('rgb.max=', 136.11225891113281, 'rgb.min=', -225.77375793457031)
('rgb.max=', 136.28526306152344, 'rgb.min=', -225.87168884277344)
('rgb.max=', 135.94532775878906, 'rgb.min=', -225.9874267578125)
('rgb.max=', 135.87643432617188, 'rgb.min=', -226.11080932617188)
('rgb.max=', 135.90628051757812, 'rgb.min=', -225.98176574707031)
('rgb.max=', 136.17214965820312, 'rgb.min=', -225.60670471191406)
('rgb.max=', 136.10719299316406, 'rgb.min=', -226.01080322265625)
('rgb.max=', 135.99107360839844, 'rgb.min=', -226.32975769042969)
('rgb.max=', 135.63705444335938, 'rgb.min=', -225.799560546875)
('rgb.max=', 135.96992492675781, 'rgb.min=', -225.70533752441406)
('rgb.max=', 135.9254150390625, 'rgb.min=', -226.06358337402344)
('rgb.max=', 135.80461120605469, 'rgb.min=', -226.15229797363281)
('rgb.max=', 136.14082336425781, 'rgb.min=', -225.64968872070312)
('rgb.max=', 135.71798706054688, 'rgb.min=', -225.98585510253906)
('rgb.max=', 136.09097290039062, 'rgb.min=', -226.25833129882812)
('rgb.max=', 135.90618896484375, 'rgb.min=', -226.05142211914062)
('rgb.max=', 136.10519409179688, 'rgb.min=', -225.84727478027344)
('rgb.max=', 135.93826293945312, 'rgb.min=', -226.06507873535156)
('rgb.max=', 136.04721069335938, 'rgb.min=', -225.92488098144531)
('rgb.max=', 135.8997802734375, 'rgb.min=', -226.26058959960938)
('rgb.max=', 135.98739624023438, 'rgb.min=', -226.00086975097656)
('rgb.max=', 136.04348754882812, 'rgb.min=', -225.99691772460938)
('rgb.max=', 135.95071411132812, 'rgb.min=', -226.18455505371094)
('rgb.max=', 136.00538635253906, 'rgb.min=', -226.20721435546875)
('rgb.max=', 135.8056640625, 'rgb.min=', -225.85258483886719)
('rgb.max=', 136.12725830078125, 'rgb.min=', -225.91802978515625)
('rgb.max=', 136.08126831054688, 'rgb.min=', -225.78251647949219)
('rgb.max=', 136.042236328125, 'rgb.min=', -225.98008728027344)
('rgb.max=', 135.84745788574219, 'rgb.min=', -226.1756591796875)
('rgb.max=', 135.94573974609375, 'rgb.min=', -225.912841796875)
('rgb.max=', 136.12551879882812, 'rgb.min=', -226.06239318847656)
('rgb.max=', 135.91769409179688, 'rgb.min=', -225.809814453125)
('rgb.max=', 136.00895690917969, 'rgb.min=', -225.86956787109375)
('rgb.max=', 136.08059692382812, 'rgb.min=', -225.9576416015625)
('rgb.max=', 135.91555786132812, 'rgb.min=', -226.07081604003906)
('rgb.max=', 135.95066833496094, 'rgb.min=', -226.22560119628906)
('rgb.max=', 135.7674560546875, 'rgb.min=', -225.94741821289062)
('rgb.max=', 135.9010009765625, 'rgb.min=', -225.99734497070312)
('rgb.max=', 135.82899475097656, 'rgb.min=', -225.88632202148438)
('rgb.max=', 136.14833068847656, 'rgb.min=', -226.01968383789062)
('rgb.max=', 136.07469177246094, 'rgb.min=', -225.88919067382812)
('rgb.max=', 135.87240600585938, 'rgb.min=', -226.19598388671875)
('rgb.max=', 136.06932067871094, 'rgb.min=', -225.74403381347656)
('rgb.max=', 135.94474792480469, 'rgb.min=', -226.17971801757812)
('rgb.max=', 135.95994567871094, 'rgb.min=', -225.96290588378906)
('rgb.max=', 135.75390625, 'rgb.min=', -225.95887756347656)
('rgb.max=', 135.78276062011719, 'rgb.min=', -225.90826416015625)
('rgb.max=', 135.90414428710938, 'rgb.min=', -226.14059448242188)
('rgb.max=', 135.92745971679688, 'rgb.min=', -226.29803466796875)
('rgb.max=', 135.81887817382812, 'rgb.min=', -225.94294738769531)
('rgb.max=', 135.79852294921875, 'rgb.min=', -225.96292114257812)
('rgb.max=', 135.96888732910156, 'rgb.min=', -226.20777893066406)
('rgb.max=', 136.13815307617188, 'rgb.min=', -226.28596496582031)
('rgb.max=', 135.95805358886719, 'rgb.min=', -226.38160705566406)
('rgb.max=', 136.1356201171875, 'rgb.min=', -226.02191162109375)
('rgb.max=', 136.009765625, 'rgb.min=', -225.71430969238281)
('rgb.max=', 136.08476257324219, 'rgb.min=', -226.19259643554688)
('rgb.max=', 135.962890625, 'rgb.min=', -226.11978149414062)
('rgb.max=', 136.13473510742188, 'rgb.min=', -226.02157592773438)
('rgb.max=', 135.67684936523438, 'rgb.min=', -226.05953979492188)
('rgb.max=', 135.97232055664062, 'rgb.min=', -226.03976440429688)
('rgb.max=', 136.01887512207031, 'rgb.min=', -226.033447265625)
('rgb.max=', 136.10696411132812, 'rgb.min=', -225.85592651367188)
('rgb.max=', 136.080810546875, 'rgb.min=', -226.20733642578125)
('rgb.max=', 135.82632446289062, 'rgb.min=', -225.87486267089844)
('rgb.max=', 135.9232177734375, 'rgb.min=', -225.83815002441406)
('rgb.max=', 135.70181274414062, 'rgb.min=', -226.35548400878906)
('rgb.max=', 135.74430847167969, 'rgb.min=', -226.09321594238281)
('rgb.max=', 135.8670654296875, 'rgb.min=', -226.11471557617188)
('rgb.max=', 135.90988159179688, 'rgb.min=', -225.99455261230469)
('rgb.max=', 135.91644287109375, 'rgb.min=', -226.01300048828125)
('rgb.max=', 136.00709533691406, 'rgb.min=', -226.16651916503906)
('rgb.max=', 135.9462890625, 'rgb.min=', -225.96885681152344)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.210991')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6975 ', 'GAN acc 0.5039', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4980', 'Total loss: 1.4011', 'for batch', 0)
('GAN loss 0.6960 ', 'GAN acc 0.5430', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4688', 'Total loss: 1.3991', 'for batch', 1)
('GAN loss 0.6905 ', 'GAN acc 0.5234', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4844', 'Total loss: 1.3912', 'for batch', 2)
('GAN loss 0.6777 ', 'GAN acc 0.5625', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5195', 'Total loss: 1.3723', 'for batch', 3)
('GAN loss 0.6761 ', 'GAN acc 0.5859', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4941', 'Total loss: 1.3703', 'for batch', 4)
('GAN loss 0.6778 ', 'GAN acc 0.5859', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.4668', 'Total loss: 1.3791', 'for batch', 5)
('GAN loss 0.6777 ', 'GAN acc 0.5508', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4844', 'Total loss: 1.3754', 'for batch', 6)
('GAN loss 0.6849 ', 'GAN acc 0.5664', 'Discriminator loss 0.6872', 'Discriminator accuracy 0.5469', 'Total loss: 1.3721', 'for batch', 7)
('GAN loss 0.6803 ', 'GAN acc 0.5820', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4766', 'Total loss: 1.3804', 'for batch', 8)
('GAN loss 0.6897 ', 'GAN acc 0.5352', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5000', 'Total loss: 1.3880', 'for batch', 9)
('GAN loss 0.6912 ', 'GAN acc 0.5391', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.5059', 'Total loss: 1.3898', 'for batch', 10)
('GAN loss 0.6927 ', 'GAN acc 0.5195', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4863', 'Total loss: 1.3923', 'for batch', 11)
('GAN loss 0.6981 ', 'GAN acc 0.5039', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4863', 'Total loss: 1.3989', 'for batch', 12)
('GAN loss 0.6863 ', 'GAN acc 0.5469', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4941', 'Total loss: 1.3842', 'for batch', 13)
('GAN loss 0.6892 ', 'GAN acc 0.5273', 'Discriminator loss 0.7073', 'Discriminator accuracy 0.4727', 'Total loss: 1.3966', 'for batch', 14)
('GAN loss 0.6848 ', 'GAN acc 0.5820', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4883', 'Total loss: 1.3808', 'for batch', 15)
('GAN loss 0.6964 ', 'GAN acc 0.5508', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5059', 'Total loss: 1.3931', 'for batch', 16)
('GAN loss 0.6850 ', 'GAN acc 0.5781', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.4844', 'Total loss: 1.3885', 'for batch', 17)
('GAN loss 0.6914 ', 'GAN acc 0.5391', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5293', 'Total loss: 1.3849', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5918895)
('DISCRIMINATOR_Imagem FAKE=', 0.59378529)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.06083679199219, 'rgb.min=', -225.93238830566406)
('rgb.max=', 135.92414855957031, 'rgb.min=', -226.02967834472656)
('rgb.max=', 136.12322998046875, 'rgb.min=', -225.97808837890625)
('rgb.max=', 136.01626586914062, 'rgb.min=', -226.16523742675781)
('rgb.max=', 136.06529235839844, 'rgb.min=', -225.90534973144531)
('rgb.max=', 136.27191162109375, 'rgb.min=', -226.36174011230469)
('rgb.max=', 135.84931945800781, 'rgb.min=', -226.08546447753906)
('rgb.max=', 135.95672607421875, 'rgb.min=', -226.0189208984375)
('rgb.max=', 135.86154174804688, 'rgb.min=', -226.26316833496094)
('rgb.max=', 135.80702209472656, 'rgb.min=', -226.07756042480469)
('rgb.max=', 135.69772338867188, 'rgb.min=', -226.10171508789062)
('rgb.max=', 135.85319519042969, 'rgb.min=', -225.98153686523438)
('rgb.max=', 135.78997802734375, 'rgb.min=', -226.08430480957031)
('rgb.max=', 135.92190551757812, 'rgb.min=', -226.11697387695312)
('rgb.max=', 135.80877685546875, 'rgb.min=', -226.02323913574219)
('rgb.max=', 135.79142761230469, 'rgb.min=', -226.06602478027344)
('rgb.max=', 135.83529663085938, 'rgb.min=', -225.95085144042969)
('rgb.max=', 135.90274047851562, 'rgb.min=', -225.78636169433594)
('rgb.max=', 135.91636657714844, 'rgb.min=', -226.06753540039062)
('rgb.max=', 135.96311950683594, 'rgb.min=', -226.25132751464844)
('rgb.max=', 136.07937622070312, 'rgb.min=', -225.88682556152344)
('rgb.max=', 136.15028381347656, 'rgb.min=', -225.93350219726562)
('rgb.max=', 136.11793518066406, 'rgb.min=', -225.82575988769531)
('rgb.max=', 136.01676940917969, 'rgb.min=', -225.85549926757812)
('rgb.max=', 135.79096984863281, 'rgb.min=', -225.96195983886719)
('rgb.max=', 136.14805603027344, 'rgb.min=', -226.03694152832031)
('rgb.max=', 136.09605407714844, 'rgb.min=', -226.07351684570312)
('rgb.max=', 135.85896301269531, 'rgb.min=', -226.01251220703125)
('rgb.max=', 135.90948486328125, 'rgb.min=', -225.89530944824219)
('rgb.max=', 135.83236694335938, 'rgb.min=', -226.01504516601562)
('rgb.max=', 135.90571594238281, 'rgb.min=', -226.1378173828125)
('rgb.max=', 135.86624145507812, 'rgb.min=', -225.95170593261719)
('rgb.max=', 136.07362365722656, 'rgb.min=', -226.08930969238281)
('rgb.max=', 135.87055969238281, 'rgb.min=', -225.97036743164062)
('rgb.max=', 135.93870544433594, 'rgb.min=', -226.01177978515625)
('rgb.max=', 136.07658386230469, 'rgb.min=', -225.94570922851562)
('rgb.max=', 136.17509460449219, 'rgb.min=', -225.98097229003906)
('rgb.max=', 136.0731201171875, 'rgb.min=', -226.02433776855469)
('rgb.max=', 135.98698425292969, 'rgb.min=', -225.923828125)
('rgb.max=', 135.99519348144531, 'rgb.min=', -225.9964599609375)
('rgb.max=', 135.7247314453125, 'rgb.min=', -225.85989379882812)
('rgb.max=', 135.97854614257812, 'rgb.min=', -226.08592224121094)
('rgb.max=', 135.90802001953125, 'rgb.min=', -226.054443359375)
('rgb.max=', 135.87492370605469, 'rgb.min=', -225.88075256347656)
('rgb.max=', 135.92573547363281, 'rgb.min=', -226.34077453613281)
('rgb.max=', 135.65177917480469, 'rgb.min=', -225.88285827636719)
('rgb.max=', 135.92961120605469, 'rgb.min=', -226.03785705566406)
('rgb.max=', 135.72525024414062, 'rgb.min=', -225.83384704589844)
('rgb.max=', 135.8861083984375, 'rgb.min=', -225.94561767578125)
('rgb.max=', 136.25218200683594, 'rgb.min=', -226.08769226074219)
('rgb.max=', 136.0135498046875, 'rgb.min=', -226.10108947753906)
('rgb.max=', 136.2379150390625, 'rgb.min=', -225.98649597167969)
('rgb.max=', 135.68551635742188, 'rgb.min=', -226.02334594726562)
('rgb.max=', 135.79153442382812, 'rgb.min=', -226.15139770507812)
('rgb.max=', 136.06661987304688, 'rgb.min=', -226.0894775390625)
('rgb.max=', 136.10711669921875, 'rgb.min=', -226.07011413574219)
('rgb.max=', 135.88748168945312, 'rgb.min=', -226.076416015625)
('rgb.max=', 135.83285522460938, 'rgb.min=', -225.87818908691406)
('rgb.max=', 135.88432312011719, 'rgb.min=', -225.9473876953125)
('rgb.max=', 135.59877014160156, 'rgb.min=', -226.15498352050781)
('rgb.max=', 135.95588684082031, 'rgb.min=', -226.08187866210938)
('rgb.max=', 135.75323486328125, 'rgb.min=', -225.79470825195312)
('rgb.max=', 135.72734069824219, 'rgb.min=', -226.06721496582031)
('rgb.max=', 135.77621459960938, 'rgb.min=', -226.23905944824219)
('rgb.max=', 136.31085205078125, 'rgb.min=', -225.85758972167969)
('rgb.max=', 135.97882080078125, 'rgb.min=', -226.16773986816406)
('rgb.max=', 135.68450927734375, 'rgb.min=', -225.864013671875)
('rgb.max=', 135.73353576660156, 'rgb.min=', -226.08192443847656)
('rgb.max=', 136.07864379882812, 'rgb.min=', -226.23812866210938)
('rgb.max=', 136.07473754882812, 'rgb.min=', -226.0784912109375)
('rgb.max=', 136.02496337890625, 'rgb.min=', -226.05499267578125)
('rgb.max=', 135.7562255859375, 'rgb.min=', -226.10153198242188)
('rgb.max=', 135.90007019042969, 'rgb.min=', -226.16259765625)
('rgb.max=', 135.99235534667969, 'rgb.min=', -226.24198913574219)
('rgb.max=', 135.89369201660156, 'rgb.min=', -225.75505065917969)
('rgb.max=', 136.02655029296875, 'rgb.min=', -226.04217529296875)
('rgb.max=', 136.21449279785156, 'rgb.min=', -226.08506774902344)
('rgb.max=', 136.085205078125, 'rgb.min=', -225.90321350097656)
('rgb.max=', 135.7423095703125, 'rgb.min=', -226.10453796386719)
('rgb.max=', 135.95014953613281, 'rgb.min=', -225.8671875)
('rgb.max=', 136.03472900390625, 'rgb.min=', -225.64610290527344)
('rgb.max=', 135.85568237304688, 'rgb.min=', -225.88633728027344)
('rgb.max=', 135.80184936523438, 'rgb.min=', -226.03248596191406)
('rgb.max=', 135.9888916015625, 'rgb.min=', -226.16912841796875)
('rgb.max=', 136.00849914550781, 'rgb.min=', -226.19590759277344)
('rgb.max=', 135.89324951171875, 'rgb.min=', -225.99790954589844)
('rgb.max=', 136.05473327636719, 'rgb.min=', -225.81755065917969)
('rgb.max=', 135.74246215820312, 'rgb.min=', -225.93009948730469)
('rgb.max=', 135.96337890625, 'rgb.min=', -226.15017700195312)
('rgb.max=', 135.63934326171875, 'rgb.min=', -225.76907348632812)
('rgb.max=', 135.83882141113281, 'rgb.min=', -225.96597290039062)
('rgb.max=', 135.78865051269531, 'rgb.min=', -226.25146484375)
('rgb.max=', 135.7869873046875, 'rgb.min=', -226.27532958984375)
('rgb.max=', 135.75236511230469, 'rgb.min=', -225.92111206054688)
('rgb.max=', 135.77201843261719, 'rgb.min=', -225.80500793457031)
('rgb.max=', 136.10806274414062, 'rgb.min=', -226.01158142089844)
('rgb.max=', 135.97821044921875, 'rgb.min=', -225.99078369140625)
('rgb.max=', 135.97552490234375, 'rgb.min=', -226.38435363769531)
('rgb.max=', 135.77922058105469, 'rgb.min=', -226.21168518066406)
('rgb.max=', 135.95053100585938, 'rgb.min=', -226.04852294921875)
('rgb.max=', 135.87612915039062, 'rgb.min=', -226.08984375)
('rgb.max=', 135.74647521972656, 'rgb.min=', -225.90937805175781)
('rgb.max=', 136.03085327148438, 'rgb.min=', -225.83662414550781)
('rgb.max=', 135.89756774902344, 'rgb.min=', -225.95555114746094)
('rgb.max=', 135.91062927246094, 'rgb.min=', -225.85234069824219)
('rgb.max=', 136.15817260742188, 'rgb.min=', -226.10577392578125)
('rgb.max=', 135.92005920410156, 'rgb.min=', -226.07588195800781)
('rgb.max=', 135.99205017089844, 'rgb.min=', -226.14161682128906)
('rgb.max=', 136.08473205566406, 'rgb.min=', -226.05412292480469)
('rgb.max=', 136.04963684082031, 'rgb.min=', -225.88456726074219)
('rgb.max=', 136.0037841796875, 'rgb.min=', -226.02522277832031)
('rgb.max=', 136.16481018066406, 'rgb.min=', -225.88261413574219)
('rgb.max=', 135.93557739257812, 'rgb.min=', -225.80181884765625)
('rgb.max=', 136.05360412597656, 'rgb.min=', -225.77503967285156)
('rgb.max=', 135.86199951171875, 'rgb.min=', -226.0794677734375)
('rgb.max=', 135.87005615234375, 'rgb.min=', -226.26228332519531)
('rgb.max=', 135.62518310546875, 'rgb.min=', -226.01921081542969)
('rgb.max=', 135.984619140625, 'rgb.min=', -225.79524230957031)
('rgb.max=', 135.80097961425781, 'rgb.min=', -225.8695068359375)
('rgb.max=', 136.06492614746094, 'rgb.min=', -225.908203125)
('rgb.max=', 136.02189636230469, 'rgb.min=', -226.06413269042969)
('rgb.max=', 136.29843139648438, 'rgb.min=', -226.02737426757812)
('rgb.max=', 135.81251525878906, 'rgb.min=', -225.87704467773438)
('rgb.max=', 135.89541625976562, 'rgb.min=', -226.03315734863281)
('rgb.max=', 135.81884765625, 'rgb.min=', -225.92523193359375)
('rgb.max=', 135.96713256835938, 'rgb.min=', -226.04754638671875)
('rgb.max=', 135.84037780761719, 'rgb.min=', -225.78263854980469)
('rgb.max=', 136.24740600585938, 'rgb.min=', -225.955810546875)
('rgb.max=', 135.6417236328125, 'rgb.min=', -226.16534423828125)
('rgb.max=', 135.98782348632812, 'rgb.min=', -226.14094543457031)
('rgb.max=', 136.11155700683594, 'rgb.min=', -225.85050964355469)
('rgb.max=', 135.73849487304688, 'rgb.min=', -226.22013854980469)
('rgb.max=', 135.94325256347656, 'rgb.min=', -225.95106506347656)
('rgb.max=', 136.13165283203125, 'rgb.min=', -225.90841674804688)
('rgb.max=', 136.05262756347656, 'rgb.min=', -225.92973327636719)
('rgb.max=', 135.74061584472656, 'rgb.min=', -226.1448974609375)
('rgb.max=', 135.87776184082031, 'rgb.min=', -226.14675903320312)
('rgb.max=', 136.03582763671875, 'rgb.min=', -225.84138488769531)
('rgb.max=', 135.8182373046875, 'rgb.min=', -226.11274719238281)
('rgb.max=', 135.99322509765625, 'rgb.min=', -225.98020935058594)
('rgb.max=', 135.8892822265625, 'rgb.min=', -225.84475708007812)
('rgb.max=', 136.13749694824219, 'rgb.min=', -226.08096313476562)
('rgb.max=', 135.74177551269531, 'rgb.min=', -226.08515930175781)
('rgb.max=', 136.14584350585938, 'rgb.min=', -226.00770568847656)
('rgb.max=', 135.93544006347656, 'rgb.min=', -226.12699890136719)
('rgb.max=', 136.15386962890625, 'rgb.min=', -225.89256286621094)
('rgb.max=', 135.88491821289062, 'rgb.min=', -225.91334533691406)
('rgb.max=', 136.09367370605469, 'rgb.min=', -226.11433410644531)
('rgb.max=', 136.08120727539062, 'rgb.min=', -226.13514709472656)
('rgb.max=', 136.15545654296875, 'rgb.min=', -225.8927001953125)
('rgb.max=', 135.81552124023438, 'rgb.min=', -225.93424987792969)
('rgb.max=', 136.00453186035156, 'rgb.min=', -225.85429382324219)
('rgb.max=', 136.03970336914062, 'rgb.min=', -226.12094116210938)
('rgb.max=', 136.00106811523438, 'rgb.min=', -226.07475280761719)
('rgb.max=', 135.87397766113281, 'rgb.min=', -226.0513916015625)
('rgb.max=', 135.85748291015625, 'rgb.min=', -225.75886535644531)
('rgb.max=', 136.16230773925781, 'rgb.min=', -226.17219543457031)
('rgb.max=', 135.95632934570312, 'rgb.min=', -225.84799194335938)
('rgb.max=', 135.78141784667969, 'rgb.min=', -226.16813659667969)
('rgb.max=', 135.82418823242188, 'rgb.min=', -225.76731872558594)
('rgb.max=', 135.8604736328125, 'rgb.min=', -225.8111572265625)
('rgb.max=', 135.94233703613281, 'rgb.min=', -226.00131225585938)
('rgb.max=', 135.93684387207031, 'rgb.min=', -226.01115417480469)
('rgb.max=', 135.72727966308594, 'rgb.min=', -225.90310668945312)
('rgb.max=', 136.19215393066406, 'rgb.min=', -225.97914123535156)
('rgb.max=', 136.11004638671875, 'rgb.min=', -225.88983154296875)
('rgb.max=', 136.02229309082031, 'rgb.min=', -226.1964111328125)
('rgb.max=', 135.64926147460938, 'rgb.min=', -226.01966857910156)
('rgb.max=', 136.14151000976562, 'rgb.min=', -226.09120178222656)
('rgb.max=', 136.07679748535156, 'rgb.min=', -225.965576171875)
('rgb.max=', 135.81141662597656, 'rgb.min=', -225.96726989746094)
('rgb.max=', 136.11431884765625, 'rgb.min=', -225.98690795898438)
('rgb.max=', 136.0780029296875, 'rgb.min=', -226.02784729003906)
('rgb.max=', 135.98355102539062, 'rgb.min=', -225.92446899414062)
('rgb.max=', 135.9322509765625, 'rgb.min=', -226.02609252929688)
('rgb.max=', 136.09793090820312, 'rgb.min=', -226.10453796386719)
('rgb.max=', 136.0511474609375, 'rgb.min=', -226.16705322265625)
('rgb.max=', 135.79525756835938, 'rgb.min=', -226.00408935546875)
('rgb.max=', 135.75460815429688, 'rgb.min=', -225.93777465820312)
('rgb.max=', 135.7686767578125, 'rgb.min=', -225.86079406738281)
('rgb.max=', 135.94894409179688, 'rgb.min=', -226.31010437011719)
('rgb.max=', 136.03146362304688, 'rgb.min=', -226.0301513671875)
('rgb.max=', 135.96308898925781, 'rgb.min=', -225.95054626464844)
('rgb.max=', 136.06576538085938, 'rgb.min=', -225.74125671386719)
('rgb.max=', 136.21968078613281, 'rgb.min=', -225.8765869140625)
('rgb.max=', 135.92314147949219, 'rgb.min=', -225.98756408691406)
('rgb.max=', 135.8572998046875, 'rgb.min=', -226.10910034179688)
('rgb.max=', 135.89553833007812, 'rgb.min=', -225.97685241699219)
('rgb.max=', 136.16836547851562, 'rgb.min=', -225.59109497070312)
('rgb.max=', 136.08001708984375, 'rgb.min=', -226.02435302734375)
('rgb.max=', 136.06282043457031, 'rgb.min=', -226.24111938476562)
('rgb.max=', 135.60899353027344, 'rgb.min=', -225.87442016601562)
('rgb.max=', 135.94621276855469, 'rgb.min=', -225.69557189941406)
('rgb.max=', 135.91548156738281, 'rgb.min=', -226.07734680175781)
('rgb.max=', 135.78913879394531, 'rgb.min=', -226.17665100097656)
('rgb.max=', 136.13265991210938, 'rgb.min=', -225.66383361816406)
('rgb.max=', 135.71549987792969, 'rgb.min=', -225.96934509277344)
('rgb.max=', 136.0892333984375, 'rgb.min=', -226.18609619140625)
('rgb.max=', 135.879638671875, 'rgb.min=', -226.14852905273438)
('rgb.max=', 136.09658813476562, 'rgb.min=', -225.80203247070312)
('rgb.max=', 135.92578125, 'rgb.min=', -226.09808349609375)
('rgb.max=', 136.04420471191406, 'rgb.min=', -225.91911315917969)
('rgb.max=', 135.88764953613281, 'rgb.min=', -226.239013671875)
('rgb.max=', 135.97134399414062, 'rgb.min=', -225.99310302734375)
('rgb.max=', 136.030517578125, 'rgb.min=', -226.0164794921875)
('rgb.max=', 135.93359375, 'rgb.min=', -226.19633483886719)
('rgb.max=', 135.99607849121094, 'rgb.min=', -226.16844177246094)
('rgb.max=', 135.81361389160156, 'rgb.min=', -225.83000183105469)
('rgb.max=', 136.1253662109375, 'rgb.min=', -225.90876770019531)
('rgb.max=', 136.078125, 'rgb.min=', -225.753173828125)
('rgb.max=', 136.06613159179688, 'rgb.min=', -225.990234375)
('rgb.max=', 135.848388671875, 'rgb.min=', -226.17738342285156)
('rgb.max=', 135.92698669433594, 'rgb.min=', -225.85760498046875)
('rgb.max=', 136.11448669433594, 'rgb.min=', -226.07615661621094)
('rgb.max=', 135.91838073730469, 'rgb.min=', -225.783203125)
('rgb.max=', 136.01548767089844, 'rgb.min=', -225.83985900878906)
('rgb.max=', 136.09100341796875, 'rgb.min=', -225.91255187988281)
('rgb.max=', 135.88296508789062, 'rgb.min=', -226.063232421875)
('rgb.max=', 135.91636657714844, 'rgb.min=', -226.23480224609375)
('rgb.max=', 135.76528930664062, 'rgb.min=', -225.94677734375)
('rgb.max=', 135.87889099121094, 'rgb.min=', -226.00120544433594)
('rgb.max=', 135.8145751953125, 'rgb.min=', -225.88224792480469)
('rgb.max=', 136.13920593261719, 'rgb.min=', -226.05908203125)
('rgb.max=', 136.07525634765625, 'rgb.min=', -225.86123657226562)
('rgb.max=', 135.86328125, 'rgb.min=', -226.18495178222656)
('rgb.max=', 136.07582092285156, 'rgb.min=', -225.71853637695312)
('rgb.max=', 135.92881774902344, 'rgb.min=', -226.16358947753906)
('rgb.max=', 135.9510498046875, 'rgb.min=', -225.95570373535156)
('rgb.max=', 135.75132751464844, 'rgb.min=', -225.94548034667969)
('rgb.max=', 135.781982421875, 'rgb.min=', -225.89453125)
('rgb.max=', 135.882568359375, 'rgb.min=', -226.13766479492188)
('rgb.max=', 135.91929626464844, 'rgb.min=', -226.31317138671875)
('rgb.max=', 135.81985473632812, 'rgb.min=', -225.89683532714844)
('rgb.max=', 135.79736328125, 'rgb.min=', -225.97805786132812)
('rgb.max=', 135.95782470703125, 'rgb.min=', -226.21652221679688)
('rgb.max=', 136.13145446777344, 'rgb.min=', -226.26974487304688)
('rgb.max=', 135.9320068359375, 'rgb.min=', -226.39411926269531)
('rgb.max=', 136.12913513183594, 'rgb.min=', -225.99763488769531)
('rgb.max=', 135.99783325195312, 'rgb.min=', -225.76026916503906)
('rgb.max=', 136.07597351074219, 'rgb.min=', -226.18867492675781)
('rgb.max=', 135.92840576171875, 'rgb.min=', -226.13661193847656)
('rgb.max=', 136.12014770507812, 'rgb.min=', -225.97247314453125)
('rgb.max=', 135.661865234375, 'rgb.min=', -226.05378723144531)
('rgb.max=', 135.95222473144531, 'rgb.min=', -226.05574035644531)
('rgb.max=', 136.03271484375, 'rgb.min=', -226.02732849121094)
('rgb.max=', 136.10102844238281, 'rgb.min=', -225.83988952636719)
('rgb.max=', 136.10357666015625, 'rgb.min=', -226.22419738769531)
('rgb.max=', 135.82601928710938, 'rgb.min=', -225.84896850585938)
('rgb.max=', 135.90174865722656, 'rgb.min=', -225.82362365722656)
('rgb.max=', 135.69728088378906, 'rgb.min=', -226.34378051757812)
('rgb.max=', 135.72940063476562, 'rgb.min=', -226.08238220214844)
('rgb.max=', 135.84706115722656, 'rgb.min=', -226.13510131835938)
('rgb.max=', 135.88621520996094, 'rgb.min=', -225.99772644042969)
('rgb.max=', 135.90306091308594, 'rgb.min=', -226.02725219726562)
('rgb.max=', 135.9923095703125, 'rgb.min=', -226.16937255859375)
('rgb.max=', 135.92536926269531, 'rgb.min=', -225.95947265625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.737246')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6865 ', 'GAN acc 0.5469', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4941', 'Total loss: 1.3877', 'for batch', 0)
('GAN loss 0.6911 ', 'GAN acc 0.5234', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4570', 'Total loss: 1.3906', 'for batch', 1)
('GAN loss 0.7034 ', 'GAN acc 0.4570', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5312', 'Total loss: 1.3971', 'for batch', 2)
('GAN loss 0.6815 ', 'GAN acc 0.5703', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4707', 'Total loss: 1.3808', 'for batch', 3)
('GAN loss 0.6854 ', 'GAN acc 0.5508', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4863', 'Total loss: 1.3794', 'for batch', 4)
('GAN loss 0.6976 ', 'GAN acc 0.4922', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4668', 'Total loss: 1.3995', 'for batch', 5)
('GAN loss 0.6890 ', 'GAN acc 0.5312', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5098', 'Total loss: 1.3844', 'for batch', 6)
('GAN loss 0.6973 ', 'GAN acc 0.5039', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5273', 'Total loss: 1.3915', 'for batch', 7)
('GAN loss 0.6932 ', 'GAN acc 0.5195', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5078', 'Total loss: 1.3914', 'for batch', 8)
('GAN loss 0.7025 ', 'GAN acc 0.4492', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5156', 'Total loss: 1.3956', 'for batch', 9)
('GAN loss 0.6973 ', 'GAN acc 0.5000', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4961', 'Total loss: 1.3939', 'for batch', 10)
('GAN loss 0.6981 ', 'GAN acc 0.5039', 'Discriminator loss 0.7053', 'Discriminator accuracy 0.4785', 'Total loss: 1.4033', 'for batch', 11)
('GAN loss 0.6831 ', 'GAN acc 0.5586', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4590', 'Total loss: 1.3861', 'for batch', 12)
('GAN loss 0.6795 ', 'GAN acc 0.5781', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4863', 'Total loss: 1.3815', 'for batch', 13)
('GAN loss 0.6850 ', 'GAN acc 0.5703', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4844', 'Total loss: 1.3848', 'for batch', 14)
('GAN loss 0.6949 ', 'GAN acc 0.5078', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5020', 'Total loss: 1.3906', 'for batch', 15)
('GAN loss 0.6988 ', 'GAN acc 0.5156', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5020', 'Total loss: 1.3941', 'for batch', 16)
('GAN loss 0.6939 ', 'GAN acc 0.5117', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4668', 'Total loss: 1.3961', 'for batch', 17)
('GAN loss 0.6961 ', 'GAN acc 0.5000', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5020', 'Total loss: 1.3916', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.57211143)
('DISCRIMINATOR_Imagem FAKE=', 0.57256228)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.08128356933594, 'rgb.min=', -225.88949584960938)
('rgb.max=', 135.93527221679688, 'rgb.min=', -226.01515197753906)
('rgb.max=', 136.09689331054688, 'rgb.min=', -225.98103332519531)
('rgb.max=', 136.01947021484375, 'rgb.min=', -226.17201232910156)
('rgb.max=', 136.08831787109375, 'rgb.min=', -225.92216491699219)
('rgb.max=', 136.243896484375, 'rgb.min=', -226.35772705078125)
('rgb.max=', 135.84747314453125, 'rgb.min=', -226.04902648925781)
('rgb.max=', 135.96066284179688, 'rgb.min=', -226.01426696777344)
('rgb.max=', 135.86262512207031, 'rgb.min=', -226.23489379882812)
('rgb.max=', 135.80708312988281, 'rgb.min=', -226.08268737792969)
('rgb.max=', 135.69587707519531, 'rgb.min=', -226.08578491210938)
('rgb.max=', 135.8515625, 'rgb.min=', -225.94354248046875)
('rgb.max=', 135.81234741210938, 'rgb.min=', -226.09384155273438)
('rgb.max=', 135.95367431640625, 'rgb.min=', -226.16482543945312)
('rgb.max=', 135.8118896484375, 'rgb.min=', -226.04177856445312)
('rgb.max=', 135.79733276367188, 'rgb.min=', -226.05470275878906)
('rgb.max=', 135.82194519042969, 'rgb.min=', -225.93983459472656)
('rgb.max=', 135.90487670898438, 'rgb.min=', -225.78079223632812)
('rgb.max=', 135.91775512695312, 'rgb.min=', -226.04524230957031)
('rgb.max=', 135.968017578125, 'rgb.min=', -226.21331787109375)
('rgb.max=', 136.06973266601562, 'rgb.min=', -225.89036560058594)
('rgb.max=', 136.12397766113281, 'rgb.min=', -225.92739868164062)
('rgb.max=', 136.09532165527344, 'rgb.min=', -225.82566833496094)
('rgb.max=', 135.9471435546875, 'rgb.min=', -225.85543823242188)
('rgb.max=', 135.8040771484375, 'rgb.min=', -225.96255493164062)
('rgb.max=', 136.07481384277344, 'rgb.min=', -226.03132629394531)
('rgb.max=', 136.12718200683594, 'rgb.min=', -226.12423706054688)
('rgb.max=', 135.85432434082031, 'rgb.min=', -226.00263977050781)
('rgb.max=', 135.91171264648438, 'rgb.min=', -225.8779296875)
('rgb.max=', 135.8470458984375, 'rgb.min=', -226.00656127929688)
('rgb.max=', 135.94070434570312, 'rgb.min=', -226.09249877929688)
('rgb.max=', 135.86393737792969, 'rgb.min=', -225.98207092285156)
('rgb.max=', 136.02032470703125, 'rgb.min=', -226.10124206542969)
('rgb.max=', 135.88595581054688, 'rgb.min=', -226.01487731933594)
('rgb.max=', 135.890380859375, 'rgb.min=', -225.99311828613281)
('rgb.max=', 136.04934692382812, 'rgb.min=', -225.95191955566406)
('rgb.max=', 136.18363952636719, 'rgb.min=', -225.96853637695312)
('rgb.max=', 136.0260009765625, 'rgb.min=', -226.064208984375)
('rgb.max=', 135.94084167480469, 'rgb.min=', -225.9315185546875)
('rgb.max=', 135.94793701171875, 'rgb.min=', -225.99325561523438)
('rgb.max=', 135.72625732421875, 'rgb.min=', -225.84886169433594)
('rgb.max=', 135.99655151367188, 'rgb.min=', -226.05776977539062)
('rgb.max=', 135.9075927734375, 'rgb.min=', -226.02305603027344)
('rgb.max=', 135.86578369140625, 'rgb.min=', -225.86752319335938)
('rgb.max=', 135.97657775878906, 'rgb.min=', -226.29788208007812)
('rgb.max=', 135.65444946289062, 'rgb.min=', -225.87991333007812)
('rgb.max=', 135.961669921875, 'rgb.min=', -225.99974060058594)
('rgb.max=', 135.70480346679688, 'rgb.min=', -225.83958435058594)
('rgb.max=', 135.86250305175781, 'rgb.min=', -225.94108581542969)
('rgb.max=', 136.20228576660156, 'rgb.min=', -226.08662414550781)
('rgb.max=', 136.0303955078125, 'rgb.min=', -226.00999450683594)
('rgb.max=', 136.22079467773438, 'rgb.min=', -225.99496459960938)
('rgb.max=', 135.66864013671875, 'rgb.min=', -226.02578735351562)
('rgb.max=', 135.79124450683594, 'rgb.min=', -226.12501525878906)
('rgb.max=', 136.0419921875, 'rgb.min=', -226.08340454101562)
('rgb.max=', 136.12757873535156, 'rgb.min=', -226.05595397949219)
('rgb.max=', 135.88961791992188, 'rgb.min=', -226.04412841796875)
('rgb.max=', 135.83135986328125, 'rgb.min=', -225.96495056152344)
('rgb.max=', 135.87687683105469, 'rgb.min=', -225.94573974609375)
('rgb.max=', 135.5916748046875, 'rgb.min=', -226.177978515625)
('rgb.max=', 135.9385986328125, 'rgb.min=', -226.07984924316406)
('rgb.max=', 135.75285339355469, 'rgb.min=', -225.76695251464844)
('rgb.max=', 135.72738647460938, 'rgb.min=', -225.989990234375)
('rgb.max=', 135.77899169921875, 'rgb.min=', -226.19110107421875)
('rgb.max=', 136.27449035644531, 'rgb.min=', -225.89762878417969)
('rgb.max=', 135.9881591796875, 'rgb.min=', -226.19392395019531)
('rgb.max=', 135.68313598632812, 'rgb.min=', -225.893310546875)
('rgb.max=', 135.73074340820312, 'rgb.min=', -226.03359985351562)
('rgb.max=', 136.01992797851562, 'rgb.min=', -226.24324035644531)
('rgb.max=', 136.09429931640625, 'rgb.min=', -226.04048156738281)
('rgb.max=', 136.02618408203125, 'rgb.min=', -225.988525390625)
('rgb.max=', 135.73994445800781, 'rgb.min=', -226.13522338867188)
('rgb.max=', 135.8984375, 'rgb.min=', -226.13179016113281)
('rgb.max=', 136.00411987304688, 'rgb.min=', -226.17881774902344)
('rgb.max=', 135.89480590820312, 'rgb.min=', -225.7628173828125)
('rgb.max=', 136.0322265625, 'rgb.min=', -226.0228271484375)
('rgb.max=', 136.20550537109375, 'rgb.min=', -225.99995422363281)
('rgb.max=', 136.02388000488281, 'rgb.min=', -225.87579345703125)
('rgb.max=', 135.73284912109375, 'rgb.min=', -226.112060546875)
('rgb.max=', 135.94526672363281, 'rgb.min=', -225.88381958007812)
('rgb.max=', 136.06184387207031, 'rgb.min=', -225.72038269042969)
('rgb.max=', 135.85598754882812, 'rgb.min=', -225.87107849121094)
('rgb.max=', 135.78401184082031, 'rgb.min=', -226.05264282226562)
('rgb.max=', 135.96002197265625, 'rgb.min=', -226.12100219726562)
('rgb.max=', 135.96293640136719, 'rgb.min=', -226.19184875488281)
('rgb.max=', 135.8861083984375, 'rgb.min=', -226.01104736328125)
('rgb.max=', 136.00335693359375, 'rgb.min=', -225.81596374511719)
('rgb.max=', 135.74136352539062, 'rgb.min=', -225.92581176757812)
('rgb.max=', 135.9749755859375, 'rgb.min=', -226.12451171875)
('rgb.max=', 135.64004516601562, 'rgb.min=', -225.78034973144531)
('rgb.max=', 135.80596923828125, 'rgb.min=', -225.95782470703125)
('rgb.max=', 135.79220581054688, 'rgb.min=', -226.23422241210938)
('rgb.max=', 135.79844665527344, 'rgb.min=', -226.2459716796875)
('rgb.max=', 135.75114440917969, 'rgb.min=', -225.94500732421875)
('rgb.max=', 135.77975463867188, 'rgb.min=', -225.77850341796875)
('rgb.max=', 136.04498291015625, 'rgb.min=', -225.983642578125)
('rgb.max=', 135.91079711914062, 'rgb.min=', -226.00254821777344)
('rgb.max=', 135.97410583496094, 'rgb.min=', -226.38618469238281)
('rgb.max=', 135.78128051757812, 'rgb.min=', -226.22190856933594)
('rgb.max=', 135.96054077148438, 'rgb.min=', -226.06211853027344)
('rgb.max=', 135.87020874023438, 'rgb.min=', -226.16940307617188)
('rgb.max=', 135.73846435546875, 'rgb.min=', -225.89697265625)
('rgb.max=', 135.96405029296875, 'rgb.min=', -225.82376098632812)
('rgb.max=', 135.90272521972656, 'rgb.min=', -225.97703552246094)
('rgb.max=', 135.90660095214844, 'rgb.min=', -225.829345703125)
('rgb.max=', 136.17044067382812, 'rgb.min=', -226.12815856933594)
('rgb.max=', 135.93069458007812, 'rgb.min=', -226.09123229980469)
('rgb.max=', 136.00019836425781, 'rgb.min=', -226.239501953125)
('rgb.max=', 136.09646606445312, 'rgb.min=', -226.00279235839844)
('rgb.max=', 135.97331237792969, 'rgb.min=', -225.87950134277344)
('rgb.max=', 136.0228271484375, 'rgb.min=', -226.03956604003906)
('rgb.max=', 136.14143371582031, 'rgb.min=', -225.88491821289062)
('rgb.max=', 135.95050048828125, 'rgb.min=', -225.81071472167969)
('rgb.max=', 136.01606750488281, 'rgb.min=', -225.74822998046875)
('rgb.max=', 135.85848999023438, 'rgb.min=', -226.04226684570312)
('rgb.max=', 135.87179565429688, 'rgb.min=', -226.22161865234375)
('rgb.max=', 135.62919616699219, 'rgb.min=', -225.99407958984375)
('rgb.max=', 135.93359375, 'rgb.min=', -225.80281066894531)
('rgb.max=', 135.79745483398438, 'rgb.min=', -225.8623046875)
('rgb.max=', 135.99897766113281, 'rgb.min=', -225.9219970703125)
('rgb.max=', 136.044677734375, 'rgb.min=', -226.03848266601562)
('rgb.max=', 136.24995422363281, 'rgb.min=', -226.01324462890625)
('rgb.max=', 135.81080627441406, 'rgb.min=', -225.89834594726562)
('rgb.max=', 135.88478088378906, 'rgb.min=', -226.019287109375)
('rgb.max=', 135.80496215820312, 'rgb.min=', -225.92420959472656)
('rgb.max=', 136.02224731445312, 'rgb.min=', -226.05186462402344)
('rgb.max=', 135.84066772460938, 'rgb.min=', -225.79386901855469)
('rgb.max=', 136.19107055664062, 'rgb.min=', -226.0211181640625)
('rgb.max=', 135.63787841796875, 'rgb.min=', -226.15884399414062)
('rgb.max=', 135.99566650390625, 'rgb.min=', -226.15200805664062)
('rgb.max=', 136.05009460449219, 'rgb.min=', -225.86337280273438)
('rgb.max=', 135.7388916015625, 'rgb.min=', -226.22262573242188)
('rgb.max=', 135.96626281738281, 'rgb.min=', -225.92257690429688)
('rgb.max=', 136.18057250976562, 'rgb.min=', -225.79263305664062)
('rgb.max=', 136.02378845214844, 'rgb.min=', -225.92765808105469)
('rgb.max=', 135.73548889160156, 'rgb.min=', -226.16436767578125)
('rgb.max=', 135.87898254394531, 'rgb.min=', -226.17454528808594)
('rgb.max=', 135.96493530273438, 'rgb.min=', -225.8468017578125)
('rgb.max=', 135.81619262695312, 'rgb.min=', -226.1204833984375)
('rgb.max=', 135.93716430664062, 'rgb.min=', -226.00105285644531)
('rgb.max=', 135.89717102050781, 'rgb.min=', -225.83489990234375)
('rgb.max=', 136.12702941894531, 'rgb.min=', -226.03971862792969)
('rgb.max=', 135.73861694335938, 'rgb.min=', -226.05569458007812)
('rgb.max=', 136.13812255859375, 'rgb.min=', -225.98773193359375)
('rgb.max=', 135.96011352539062, 'rgb.min=', -226.13613891601562)
('rgb.max=', 136.13371276855469, 'rgb.min=', -225.89753723144531)
('rgb.max=', 135.8828125, 'rgb.min=', -225.88348388671875)
('rgb.max=', 136.12229919433594, 'rgb.min=', -226.17657470703125)
('rgb.max=', 136.09127807617188, 'rgb.min=', -226.08050537109375)
('rgb.max=', 136.09268188476562, 'rgb.min=', -225.90644836425781)
('rgb.max=', 135.81977844238281, 'rgb.min=', -225.94515991210938)
('rgb.max=', 135.95452880859375, 'rgb.min=', -225.8189697265625)
('rgb.max=', 135.96928405761719, 'rgb.min=', -226.22421264648438)
('rgb.max=', 136.04135131835938, 'rgb.min=', -226.02969360351562)
('rgb.max=', 135.85722351074219, 'rgb.min=', -226.05427551269531)
('rgb.max=', 135.86077880859375, 'rgb.min=', -225.72877502441406)
('rgb.max=', 136.12156677246094, 'rgb.min=', -226.10931396484375)
('rgb.max=', 135.885009765625, 'rgb.min=', -225.81689453125)
('rgb.max=', 135.77684020996094, 'rgb.min=', -226.14976501464844)
('rgb.max=', 135.80613708496094, 'rgb.min=', -225.77037048339844)
('rgb.max=', 135.85797119140625, 'rgb.min=', -225.81724548339844)
('rgb.max=', 135.93257141113281, 'rgb.min=', -226.02786254882812)
('rgb.max=', 135.9500732421875, 'rgb.min=', -226.02236938476562)
('rgb.max=', 135.70010375976562, 'rgb.min=', -225.8944091796875)
('rgb.max=', 136.17864990234375, 'rgb.min=', -225.98002624511719)
('rgb.max=', 136.04315185546875, 'rgb.min=', -225.88496398925781)
('rgb.max=', 136.02125549316406, 'rgb.min=', -226.23619079589844)
('rgb.max=', 135.64990234375, 'rgb.min=', -225.95912170410156)
('rgb.max=', 136.11508178710938, 'rgb.min=', -226.05876159667969)
('rgb.max=', 136.09001159667969, 'rgb.min=', -225.97959899902344)
('rgb.max=', 135.81024169921875, 'rgb.min=', -225.9732666015625)
('rgb.max=', 136.10641479492188, 'rgb.min=', -226.00555419921875)
('rgb.max=', 136.00894165039062, 'rgb.min=', -226.01229858398438)
('rgb.max=', 136.04539489746094, 'rgb.min=', -225.94828796386719)
('rgb.max=', 135.92562866210938, 'rgb.min=', -226.03033447265625)
('rgb.max=', 136.07315063476562, 'rgb.min=', -226.09027099609375)
('rgb.max=', 136.02760314941406, 'rgb.min=', -226.12973022460938)
('rgb.max=', 135.78561401367188, 'rgb.min=', -225.9708251953125)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.94038391113281)
('rgb.max=', 135.768310546875, 'rgb.min=', -225.815185546875)
('rgb.max=', 135.92416381835938, 'rgb.min=', -226.28167724609375)
('rgb.max=', 136.02658081054688, 'rgb.min=', -226.02119445800781)
('rgb.max=', 135.96141052246094, 'rgb.min=', -225.94944763183594)
('rgb.max=', 136.05386352539062, 'rgb.min=', -225.76065063476562)
('rgb.max=', 136.17546081542969, 'rgb.min=', -225.91488647460938)
('rgb.max=', 135.9393310546875, 'rgb.min=', -226.02360534667969)
('rgb.max=', 135.8590087890625, 'rgb.min=', -226.11497497558594)
('rgb.max=', 135.89527893066406, 'rgb.min=', -225.98542785644531)
('rgb.max=', 136.18450927734375, 'rgb.min=', -225.74531555175781)
('rgb.max=', 136.07626342773438, 'rgb.min=', -226.02217102050781)
('rgb.max=', 136.01626586914062, 'rgb.min=', -226.19656372070312)
('rgb.max=', 135.61309814453125, 'rgb.min=', -225.84194946289062)
('rgb.max=', 135.93600463867188, 'rgb.min=', -225.68099975585938)
('rgb.max=', 135.916015625, 'rgb.min=', -226.08840942382812)
('rgb.max=', 135.78973388671875, 'rgb.min=', -226.18223571777344)
('rgb.max=', 136.11599731445312, 'rgb.min=', -225.60362243652344)
('rgb.max=', 135.7060546875, 'rgb.min=', -225.96253967285156)
('rgb.max=', 136.11181640625, 'rgb.min=', -226.16642761230469)
('rgb.max=', 135.88102722167969, 'rgb.min=', -226.10287475585938)
('rgb.max=', 136.03782653808594, 'rgb.min=', -225.78578186035156)
('rgb.max=', 135.91885375976562, 'rgb.min=', -226.07247924804688)
('rgb.max=', 136.0240478515625, 'rgb.min=', -225.92326354980469)
('rgb.max=', 135.88702392578125, 'rgb.min=', -226.27099609375)
('rgb.max=', 135.9686279296875, 'rgb.min=', -226.00498962402344)
('rgb.max=', 136.00788879394531, 'rgb.min=', -226.03770446777344)
('rgb.max=', 135.93081665039062, 'rgb.min=', -226.19992065429688)
('rgb.max=', 136.04466247558594, 'rgb.min=', -226.20228576660156)
('rgb.max=', 135.78829956054688, 'rgb.min=', -225.83491516113281)
('rgb.max=', 136.14195251464844, 'rgb.min=', -225.91282653808594)
('rgb.max=', 136.01492309570312, 'rgb.min=', -225.76206970214844)
('rgb.max=', 136.01995849609375, 'rgb.min=', -225.99729919433594)
('rgb.max=', 135.85043334960938, 'rgb.min=', -226.19010925292969)
('rgb.max=', 135.88809204101562, 'rgb.min=', -225.8677978515625)
('rgb.max=', 136.09547424316406, 'rgb.min=', -226.0875244140625)
('rgb.max=', 135.93661499023438, 'rgb.min=', -225.7728271484375)
('rgb.max=', 136.00296020507812, 'rgb.min=', -225.84263610839844)
('rgb.max=', 136.05438232421875, 'rgb.min=', -225.88822937011719)
('rgb.max=', 135.89678955078125, 'rgb.min=', -226.07113647460938)
('rgb.max=', 135.91642761230469, 'rgb.min=', -226.22799682617188)
('rgb.max=', 135.75535583496094, 'rgb.min=', -225.94789123535156)
('rgb.max=', 135.88836669921875, 'rgb.min=', -226.00657653808594)
('rgb.max=', 135.81472778320312, 'rgb.min=', -225.90853881835938)
('rgb.max=', 136.08251953125, 'rgb.min=', -226.153076171875)
('rgb.max=', 136.02766418457031, 'rgb.min=', -225.8565673828125)
('rgb.max=', 135.86433410644531, 'rgb.min=', -226.19216918945312)
('rgb.max=', 136.09304809570312, 'rgb.min=', -225.70942687988281)
('rgb.max=', 135.93267822265625, 'rgb.min=', -226.20692443847656)
('rgb.max=', 135.92108154296875, 'rgb.min=', -225.95268249511719)
('rgb.max=', 135.73831176757812, 'rgb.min=', -225.93257141113281)
('rgb.max=', 135.76724243164062, 'rgb.min=', -225.87730407714844)
('rgb.max=', 135.89137268066406, 'rgb.min=', -226.15327453613281)
('rgb.max=', 135.91716003417969, 'rgb.min=', -226.32688903808594)
('rgb.max=', 135.80184936523438, 'rgb.min=', -225.91607666015625)
('rgb.max=', 135.78105163574219, 'rgb.min=', -225.91743469238281)
('rgb.max=', 135.95782470703125, 'rgb.min=', -226.31315612792969)
('rgb.max=', 136.10575866699219, 'rgb.min=', -226.27560424804688)
('rgb.max=', 135.94740295410156, 'rgb.min=', -226.40678405761719)
('rgb.max=', 136.11116027832031, 'rgb.min=', -225.99664306640625)
('rgb.max=', 136.03314208984375, 'rgb.min=', -225.74488830566406)
('rgb.max=', 136.04409790039062, 'rgb.min=', -226.19483947753906)
('rgb.max=', 135.95167541503906, 'rgb.min=', -226.14340209960938)
('rgb.max=', 136.111328125, 'rgb.min=', -225.95901489257812)
('rgb.max=', 135.64317321777344, 'rgb.min=', -226.06163024902344)
('rgb.max=', 135.92924499511719, 'rgb.min=', -226.12939453125)
('rgb.max=', 135.98355102539062, 'rgb.min=', -226.04019165039062)
('rgb.max=', 136.07315063476562, 'rgb.min=', -225.84858703613281)
('rgb.max=', 136.10992431640625, 'rgb.min=', -226.24200439453125)
('rgb.max=', 135.7996826171875, 'rgb.min=', -225.85548400878906)
('rgb.max=', 135.92507934570312, 'rgb.min=', -225.83570861816406)
('rgb.max=', 135.69052124023438, 'rgb.min=', -226.34774780273438)
('rgb.max=', 135.72346496582031, 'rgb.min=', -226.09248352050781)
('rgb.max=', 135.84861755371094, 'rgb.min=', -226.21415710449219)
('rgb.max=', 135.88984680175781, 'rgb.min=', -226.00993347167969)
('rgb.max=', 135.88948059082031, 'rgb.min=', -226.04277038574219)
('rgb.max=', 135.99517822265625, 'rgb.min=', -226.18316650390625)
('rgb.max=', 135.90322875976562, 'rgb.min=', -225.98751831054688)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.271739')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6907 ', 'GAN acc 0.5312', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4863', 'Total loss: 1.3908', 'for batch', 0)
('GAN loss 0.6857 ', 'GAN acc 0.5781', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4824', 'Total loss: 1.3872', 'for batch', 1)
('GAN loss 0.6825 ', 'GAN acc 0.5742', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4551', 'Total loss: 1.3831', 'for batch', 2)
('GAN loss 0.6817 ', 'GAN acc 0.5820', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4922', 'Total loss: 1.3824', 'for batch', 3)
('GAN loss 0.6874 ', 'GAN acc 0.5547', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4707', 'Total loss: 1.3856', 'for batch', 4)
('GAN loss 0.6848 ', 'GAN acc 0.5469', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5078', 'Total loss: 1.3779', 'for batch', 5)
('GAN loss 0.6805 ', 'GAN acc 0.5859', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5039', 'Total loss: 1.3738', 'for batch', 6)
('GAN loss 0.6867 ', 'GAN acc 0.4961', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4805', 'Total loss: 1.3847', 'for batch', 7)
('GAN loss 0.6885 ', 'GAN acc 0.5117', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5117', 'Total loss: 1.3815', 'for batch', 8)
('GAN loss 0.6934 ', 'GAN acc 0.5117', 'Discriminator loss 0.7048', 'Discriminator accuracy 0.4375', 'Total loss: 1.3982', 'for batch', 9)
('GAN loss 0.6915 ', 'GAN acc 0.4922', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5176', 'Total loss: 1.3855', 'for batch', 10)
('GAN loss 0.6985 ', 'GAN acc 0.4961', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5039', 'Total loss: 1.3956', 'for batch', 11)
('GAN loss 0.6837 ', 'GAN acc 0.5703', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5020', 'Total loss: 1.3772', 'for batch', 12)
('GAN loss 0.6980 ', 'GAN acc 0.4844', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5117', 'Total loss: 1.3942', 'for batch', 13)
('GAN loss 0.6917 ', 'GAN acc 0.5547', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5000', 'Total loss: 1.3832', 'for batch', 14)
('GAN loss 0.7053 ', 'GAN acc 0.4336', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4707', 'Total loss: 1.4026', 'for batch', 15)
('GAN loss 0.7018 ', 'GAN acc 0.4297', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5137', 'Total loss: 1.3943', 'for batch', 16)
('GAN loss 0.7111 ', 'GAN acc 0.4258', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4941', 'Total loss: 1.4117', 'for batch', 17)
('GAN loss 0.7101 ', 'GAN acc 0.4336', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4590', 'Total loss: 1.4141', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55968434)
('DISCRIMINATOR_Imagem FAKE=', 0.5600177)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.09710693359375, 'rgb.min=', -225.85786437988281)
('rgb.max=', 135.92352294921875, 'rgb.min=', -225.99046325683594)
('rgb.max=', 136.17633056640625, 'rgb.min=', -225.96408081054688)
('rgb.max=', 136.02482604980469, 'rgb.min=', -226.14849853515625)
('rgb.max=', 136.1429443359375, 'rgb.min=', -225.90715026855469)
('rgb.max=', 136.21170043945312, 'rgb.min=', -226.34347534179688)
('rgb.max=', 135.8408203125, 'rgb.min=', -226.01823425292969)
('rgb.max=', 135.95947265625, 'rgb.min=', -225.95878601074219)
('rgb.max=', 135.85794067382812, 'rgb.min=', -226.1846923828125)
('rgb.max=', 135.8109130859375, 'rgb.min=', -226.07917785644531)
('rgb.max=', 135.69783020019531, 'rgb.min=', -226.07014465332031)
('rgb.max=', 135.84420776367188, 'rgb.min=', -225.95161437988281)
('rgb.max=', 135.79022216796875, 'rgb.min=', -226.09181213378906)
('rgb.max=', 135.94612121582031, 'rgb.min=', -226.14663696289062)
('rgb.max=', 135.8048095703125, 'rgb.min=', -226.03195190429688)
('rgb.max=', 135.79153442382812, 'rgb.min=', -226.06059265136719)
('rgb.max=', 135.81842041015625, 'rgb.min=', -225.94964599609375)
('rgb.max=', 135.89906311035156, 'rgb.min=', -225.78199768066406)
('rgb.max=', 135.91749572753906, 'rgb.min=', -226.02735900878906)
('rgb.max=', 135.96536254882812, 'rgb.min=', -226.18002319335938)
('rgb.max=', 136.07568359375, 'rgb.min=', -225.94558715820312)
('rgb.max=', 136.20956420898438, 'rgb.min=', -225.93450927734375)
('rgb.max=', 136.1787109375, 'rgb.min=', -225.82487487792969)
('rgb.max=', 135.97569274902344, 'rgb.min=', -225.86442565917969)
('rgb.max=', 135.7978515625, 'rgb.min=', -225.94618225097656)
('rgb.max=', 136.05181884765625, 'rgb.min=', -226.02630615234375)
('rgb.max=', 136.08836364746094, 'rgb.min=', -226.06901550292969)
('rgb.max=', 135.83938598632812, 'rgb.min=', -225.92866516113281)
('rgb.max=', 135.91201782226562, 'rgb.min=', -225.86203002929688)
('rgb.max=', 135.8883056640625, 'rgb.min=', -226.00369262695312)
('rgb.max=', 135.92420959472656, 'rgb.min=', -226.05082702636719)
('rgb.max=', 135.84468078613281, 'rgb.min=', -225.98258972167969)
('rgb.max=', 136.03170776367188, 'rgb.min=', -226.11764526367188)
('rgb.max=', 135.87944030761719, 'rgb.min=', -226.0108642578125)
('rgb.max=', 135.9193115234375, 'rgb.min=', -225.976318359375)
('rgb.max=', 136.03518676757812, 'rgb.min=', -225.95884704589844)
('rgb.max=', 136.12348937988281, 'rgb.min=', -225.948974609375)
('rgb.max=', 136.00373840332031, 'rgb.min=', -226.03196716308594)
('rgb.max=', 135.96870422363281, 'rgb.min=', -225.93147277832031)
('rgb.max=', 135.97596740722656, 'rgb.min=', -226.00550842285156)
('rgb.max=', 135.73081970214844, 'rgb.min=', -225.85955810546875)
('rgb.max=', 135.9892578125, 'rgb.min=', -226.0205078125)
('rgb.max=', 135.90748596191406, 'rgb.min=', -226.03788757324219)
('rgb.max=', 135.91014099121094, 'rgb.min=', -225.87409973144531)
('rgb.max=', 135.9696044921875, 'rgb.min=', -226.24346923828125)
('rgb.max=', 135.6259765625, 'rgb.min=', -225.88385009765625)
('rgb.max=', 135.96261596679688, 'rgb.min=', -225.98774719238281)
('rgb.max=', 135.724609375, 'rgb.min=', -225.77029418945312)
('rgb.max=', 135.90101623535156, 'rgb.min=', -225.94866943359375)
('rgb.max=', 136.19270324707031, 'rgb.min=', -226.06849670410156)
('rgb.max=', 136.02114868164062, 'rgb.min=', -226.0142822265625)
('rgb.max=', 136.24148559570312, 'rgb.min=', -225.9649658203125)
('rgb.max=', 135.6707763671875, 'rgb.min=', -226.02830505371094)
('rgb.max=', 135.85917663574219, 'rgb.min=', -226.05476379394531)
('rgb.max=', 136.11843872070312, 'rgb.min=', -226.02374267578125)
('rgb.max=', 136.14152526855469, 'rgb.min=', -226.06388854980469)
('rgb.max=', 135.89260864257812, 'rgb.min=', -225.99526977539062)
('rgb.max=', 135.82693481445312, 'rgb.min=', -225.91905212402344)
('rgb.max=', 135.867431640625, 'rgb.min=', -225.94749450683594)
('rgb.max=', 135.59228515625, 'rgb.min=', -226.17304992675781)
('rgb.max=', 135.93644714355469, 'rgb.min=', -226.11082458496094)
('rgb.max=', 135.75144958496094, 'rgb.min=', -225.75975036621094)
('rgb.max=', 135.68238830566406, 'rgb.min=', -225.96554565429688)
('rgb.max=', 135.76248168945312, 'rgb.min=', -226.15658569335938)
('rgb.max=', 136.35238647460938, 'rgb.min=', -225.944091796875)
('rgb.max=', 136.00126647949219, 'rgb.min=', -226.18380737304688)
('rgb.max=', 135.68890380859375, 'rgb.min=', -225.88676452636719)
('rgb.max=', 135.73831176757812, 'rgb.min=', -226.03115844726562)
('rgb.max=', 136.03678894042969, 'rgb.min=', -226.24412536621094)
('rgb.max=', 136.11865234375, 'rgb.min=', -226.05410766601562)
('rgb.max=', 136.03982543945312, 'rgb.min=', -225.97663879394531)
('rgb.max=', 135.78114318847656, 'rgb.min=', -226.04264831542969)
('rgb.max=', 135.89933776855469, 'rgb.min=', -226.07542419433594)
('rgb.max=', 135.99313354492188, 'rgb.min=', -226.09039306640625)
('rgb.max=', 135.890869140625, 'rgb.min=', -225.75032043457031)
('rgb.max=', 136.07009887695312, 'rgb.min=', -226.01918029785156)
('rgb.max=', 136.28684997558594, 'rgb.min=', -226.05743408203125)
('rgb.max=', 136.05868530273438, 'rgb.min=', -225.88963317871094)
('rgb.max=', 135.78060913085938, 'rgb.min=', -226.11882019042969)
('rgb.max=', 135.94526672363281, 'rgb.min=', -225.85720825195312)
('rgb.max=', 136.07658386230469, 'rgb.min=', -225.70967102050781)
('rgb.max=', 135.85400390625, 'rgb.min=', -225.85945129394531)
('rgb.max=', 135.77410888671875, 'rgb.min=', -226.04916381835938)
('rgb.max=', 136.02365112304688, 'rgb.min=', -226.09194946289062)
('rgb.max=', 135.99406433105469, 'rgb.min=', -226.21102905273438)
('rgb.max=', 135.88336181640625, 'rgb.min=', -226.01104736328125)
('rgb.max=', 136.01873779296875, 'rgb.min=', -225.81939697265625)
('rgb.max=', 135.73043823242188, 'rgb.min=', -225.94685363769531)
('rgb.max=', 135.9661865234375, 'rgb.min=', -226.06617736816406)
('rgb.max=', 135.6434326171875, 'rgb.min=', -225.78385925292969)
('rgb.max=', 135.86798095703125, 'rgb.min=', -225.91523742675781)
('rgb.max=', 135.78993225097656, 'rgb.min=', -226.19113159179688)
('rgb.max=', 135.79109191894531, 'rgb.min=', -226.19618225097656)
('rgb.max=', 135.747802734375, 'rgb.min=', -225.91639709472656)
('rgb.max=', 135.77493286132812, 'rgb.min=', -225.79400634765625)
('rgb.max=', 136.09600830078125, 'rgb.min=', -225.96043395996094)
('rgb.max=', 135.93626403808594, 'rgb.min=', -225.986083984375)
('rgb.max=', 135.98246765136719, 'rgb.min=', -226.28697204589844)
('rgb.max=', 135.78268432617188, 'rgb.min=', -226.215087890625)
('rgb.max=', 135.95571899414062, 'rgb.min=', -226.06117248535156)
('rgb.max=', 135.86729431152344, 'rgb.min=', -226.11099243164062)
('rgb.max=', 135.74176025390625, 'rgb.min=', -225.87542724609375)
('rgb.max=', 135.99783325195312, 'rgb.min=', -225.82408142089844)
('rgb.max=', 135.89851379394531, 'rgb.min=', -225.94961547851562)
('rgb.max=', 135.90655517578125, 'rgb.min=', -225.79286193847656)
('rgb.max=', 136.22044372558594, 'rgb.min=', -226.0206298828125)
('rgb.max=', 135.97535705566406, 'rgb.min=', -226.093505859375)
('rgb.max=', 135.98124694824219, 'rgb.min=', -226.09072875976562)
('rgb.max=', 136.1378173828125, 'rgb.min=', -225.98866271972656)
('rgb.max=', 136.00599670410156, 'rgb.min=', -225.89601135253906)
('rgb.max=', 136.0301513671875, 'rgb.min=', -225.99110412597656)
('rgb.max=', 136.22718811035156, 'rgb.min=', -225.8758544921875)
('rgb.max=', 135.95590209960938, 'rgb.min=', -225.804931640625)
('rgb.max=', 136.02505493164062, 'rgb.min=', -225.7442626953125)
('rgb.max=', 135.86076354980469, 'rgb.min=', -226.05740356445312)
('rgb.max=', 135.82574462890625, 'rgb.min=', -226.18527221679688)
('rgb.max=', 135.64273071289062, 'rgb.min=', -225.96963500976562)
('rgb.max=', 135.97012329101562, 'rgb.min=', -225.80024719238281)
('rgb.max=', 135.79058837890625, 'rgb.min=', -225.86820983886719)
('rgb.max=', 136.04702758789062, 'rgb.min=', -225.89012145996094)
('rgb.max=', 136.05404663085938, 'rgb.min=', -225.98881530761719)
('rgb.max=', 136.31863403320312, 'rgb.min=', -226.01849365234375)
('rgb.max=', 135.8104248046875, 'rgb.min=', -225.91683959960938)
('rgb.max=', 135.87591552734375, 'rgb.min=', -225.97201538085938)
('rgb.max=', 135.79335021972656, 'rgb.min=', -225.85404968261719)
('rgb.max=', 135.98199462890625, 'rgb.min=', -226.06669616699219)
('rgb.max=', 135.83648681640625, 'rgb.min=', -225.79179382324219)
('rgb.max=', 136.20265197753906, 'rgb.min=', -225.97528076171875)
('rgb.max=', 135.64170837402344, 'rgb.min=', -226.13325500488281)
('rgb.max=', 135.98094177246094, 'rgb.min=', -226.15180969238281)
('rgb.max=', 136.00970458984375, 'rgb.min=', -225.86051940917969)
('rgb.max=', 135.74400329589844, 'rgb.min=', -226.16226196289062)
('rgb.max=', 135.94317626953125, 'rgb.min=', -225.93711853027344)
('rgb.max=', 136.15483093261719, 'rgb.min=', -225.78538513183594)
('rgb.max=', 136.08480834960938, 'rgb.min=', -225.86067199707031)
('rgb.max=', 135.70068359375, 'rgb.min=', -226.09564208984375)
('rgb.max=', 135.86935424804688, 'rgb.min=', -226.08212280273438)
('rgb.max=', 135.99703979492188, 'rgb.min=', -225.85603332519531)
('rgb.max=', 135.80996704101562, 'rgb.min=', -226.11872863769531)
('rgb.max=', 135.96873474121094, 'rgb.min=', -225.95895385742188)
('rgb.max=', 135.89833068847656, 'rgb.min=', -225.84239196777344)
('rgb.max=', 136.16403198242188, 'rgb.min=', -226.00335693359375)
('rgb.max=', 135.73269653320312, 'rgb.min=', -226.05520629882812)
('rgb.max=', 136.18086242675781, 'rgb.min=', -225.97322082519531)
('rgb.max=', 135.95388793945312, 'rgb.min=', -226.13206481933594)
('rgb.max=', 136.18756103515625, 'rgb.min=', -225.83125305175781)
('rgb.max=', 135.87321472167969, 'rgb.min=', -225.85015869140625)
('rgb.max=', 136.13310241699219, 'rgb.min=', -226.17588806152344)
('rgb.max=', 136.11395263671875, 'rgb.min=', -226.08213806152344)
('rgb.max=', 136.119873046875, 'rgb.min=', -225.93075561523438)
('rgb.max=', 135.80819702148438, 'rgb.min=', -225.87603759765625)
('rgb.max=', 135.96707153320312, 'rgb.min=', -225.85885620117188)
('rgb.max=', 135.99295043945312, 'rgb.min=', -226.16238403320312)
('rgb.max=', 136.05966186523438, 'rgb.min=', -226.02586364746094)
('rgb.max=', 135.85743713378906, 'rgb.min=', -226.04316711425781)
('rgb.max=', 135.85362243652344, 'rgb.min=', -225.71815490722656)
('rgb.max=', 136.06610107421875, 'rgb.min=', -226.04725646972656)
('rgb.max=', 135.9560546875, 'rgb.min=', -225.86761474609375)
('rgb.max=', 135.77255249023438, 'rgb.min=', -226.12417602539062)
('rgb.max=', 135.73612976074219, 'rgb.min=', -225.77349853515625)
('rgb.max=', 135.85874938964844, 'rgb.min=', -225.75141906738281)
('rgb.max=', 135.92947387695312, 'rgb.min=', -225.99043273925781)
('rgb.max=', 135.93692016601562, 'rgb.min=', -225.97265625)
('rgb.max=', 135.70271301269531, 'rgb.min=', -225.89408874511719)
('rgb.max=', 136.23054504394531, 'rgb.min=', -225.99574279785156)
('rgb.max=', 136.06549072265625, 'rgb.min=', -225.88603210449219)
('rgb.max=', 136.0084228515625, 'rgb.min=', -226.15847778320312)
('rgb.max=', 135.65750122070312, 'rgb.min=', -225.92756652832031)
('rgb.max=', 136.1954345703125, 'rgb.min=', -226.02987670898438)
('rgb.max=', 136.10488891601562, 'rgb.min=', -225.97259521484375)
('rgb.max=', 135.80255126953125, 'rgb.min=', -225.97775268554688)
('rgb.max=', 136.11720275878906, 'rgb.min=', -225.97817993164062)
('rgb.max=', 136.04290771484375, 'rgb.min=', -225.98509216308594)
('rgb.max=', 136.00166320800781, 'rgb.min=', -225.95236206054688)
('rgb.max=', 135.92373657226562, 'rgb.min=', -226.04373168945312)
('rgb.max=', 136.14620971679688, 'rgb.min=', -226.07241821289062)
('rgb.max=', 136.08224487304688, 'rgb.min=', -225.98953247070312)
('rgb.max=', 135.79270935058594, 'rgb.min=', -225.95451354980469)
('rgb.max=', 135.75270080566406, 'rgb.min=', -225.93656921386719)
('rgb.max=', 135.7557373046875, 'rgb.min=', -225.77778625488281)
('rgb.max=', 135.92404174804688, 'rgb.min=', -226.23493957519531)
('rgb.max=', 136.0450439453125, 'rgb.min=', -226.01472473144531)
('rgb.max=', 135.96318054199219, 'rgb.min=', -225.94767761230469)
('rgb.max=', 136.1341552734375, 'rgb.min=', -225.83793640136719)
('rgb.max=', 136.25477600097656, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.93905639648438, 'rgb.min=', -226.0050048828125)
('rgb.max=', 135.85563659667969, 'rgb.min=', -226.03776550292969)
('rgb.max=', 135.89517211914062, 'rgb.min=', -225.98162841796875)
('rgb.max=', 136.21817016601562, 'rgb.min=', -225.7490234375)
('rgb.max=', 136.09213256835938, 'rgb.min=', -225.99777221679688)
('rgb.max=', 136.00120544433594, 'rgb.min=', -226.15669250488281)
('rgb.max=', 135.59767150878906, 'rgb.min=', -225.81352233886719)
('rgb.max=', 135.94918823242188, 'rgb.min=', -225.69868469238281)
('rgb.max=', 135.91377258300781, 'rgb.min=', -226.08763122558594)
('rgb.max=', 135.78170776367188, 'rgb.min=', -226.18556213378906)
('rgb.max=', 136.18568420410156, 'rgb.min=', -225.60673522949219)
('rgb.max=', 135.65892028808594, 'rgb.min=', -225.88700866699219)
('rgb.max=', 136.12419128417969, 'rgb.min=', -226.17144775390625)
('rgb.max=', 135.87423706054688, 'rgb.min=', -226.08624267578125)
('rgb.max=', 136.05413818359375, 'rgb.min=', -225.779296875)
('rgb.max=', 135.91513061523438, 'rgb.min=', -226.07061767578125)
('rgb.max=', 136.00991821289062, 'rgb.min=', -225.91119384765625)
('rgb.max=', 135.87846374511719, 'rgb.min=', -226.26425170898438)
('rgb.max=', 136.01498413085938, 'rgb.min=', -225.97618103027344)
('rgb.max=', 136.06802368164062, 'rgb.min=', -226.023193359375)
('rgb.max=', 135.91964721679688, 'rgb.min=', -226.198974609375)
('rgb.max=', 136.02052307128906, 'rgb.min=', -226.15158081054688)
('rgb.max=', 135.78997802734375, 'rgb.min=', -225.83248901367188)
('rgb.max=', 136.16377258300781, 'rgb.min=', -225.85244750976562)
('rgb.max=', 136.016357421875, 'rgb.min=', -225.76194763183594)
('rgb.max=', 136.04763793945312, 'rgb.min=', -225.98223876953125)
('rgb.max=', 135.83432006835938, 'rgb.min=', -226.19865417480469)
('rgb.max=', 135.92446899414062, 'rgb.min=', -225.87124633789062)
('rgb.max=', 136.16683959960938, 'rgb.min=', -226.08029174804688)
('rgb.max=', 135.95291137695312, 'rgb.min=', -225.75888061523438)
('rgb.max=', 135.98109436035156, 'rgb.min=', -225.83782958984375)
('rgb.max=', 136.06367492675781, 'rgb.min=', -225.84870910644531)
('rgb.max=', 135.8792724609375, 'rgb.min=', -226.04449462890625)
('rgb.max=', 135.902099609375, 'rgb.min=', -226.17149353027344)
('rgb.max=', 135.7098388671875, 'rgb.min=', -225.90017700195312)
('rgb.max=', 135.88034057617188, 'rgb.min=', -225.98782348632812)
('rgb.max=', 135.81379699707031, 'rgb.min=', -225.85392761230469)
('rgb.max=', 136.06895446777344, 'rgb.min=', -226.06951904296875)
('rgb.max=', 136.03701782226562, 'rgb.min=', -225.84788513183594)
('rgb.max=', 135.863037109375, 'rgb.min=', -226.11953735351562)
('rgb.max=', 136.10453796386719, 'rgb.min=', -225.71511840820312)
('rgb.max=', 135.92875671386719, 'rgb.min=', -226.18605041503906)
('rgb.max=', 135.94354248046875, 'rgb.min=', -225.88394165039062)
('rgb.max=', 135.72158813476562, 'rgb.min=', -225.91557312011719)
('rgb.max=', 135.71859741210938, 'rgb.min=', -225.79727172851562)
('rgb.max=', 135.88040161132812, 'rgb.min=', -226.15812683105469)
('rgb.max=', 135.91865539550781, 'rgb.min=', -226.32276916503906)
('rgb.max=', 135.75210571289062, 'rgb.min=', -225.88240051269531)
('rgb.max=', 135.7601318359375, 'rgb.min=', -225.89076232910156)
('rgb.max=', 135.9503173828125, 'rgb.min=', -226.178955078125)
('rgb.max=', 136.17735290527344, 'rgb.min=', -226.20573425292969)
('rgb.max=', 135.93991088867188, 'rgb.min=', -226.40238952636719)
('rgb.max=', 136.178955078125, 'rgb.min=', -225.98794555664062)
('rgb.max=', 136.0426025390625, 'rgb.min=', -225.69059753417969)
('rgb.max=', 136.11849975585938, 'rgb.min=', -226.13943481445312)
('rgb.max=', 135.94677734375, 'rgb.min=', -226.14523315429688)
('rgb.max=', 136.14776611328125, 'rgb.min=', -225.96412658691406)
('rgb.max=', 135.639892578125, 'rgb.min=', -226.00709533691406)
('rgb.max=', 135.96128845214844, 'rgb.min=', -226.06376647949219)
('rgb.max=', 136.0477294921875, 'rgb.min=', -225.97676086425781)
('rgb.max=', 136.15153503417969, 'rgb.min=', -225.84355163574219)
('rgb.max=', 136.05319213867188, 'rgb.min=', -226.21542358398438)
('rgb.max=', 135.821044921875, 'rgb.min=', -225.85002136230469)
('rgb.max=', 135.89956665039062, 'rgb.min=', -225.83383178710938)
('rgb.max=', 135.6826171875, 'rgb.min=', -226.35908508300781)
('rgb.max=', 135.72462463378906, 'rgb.min=', -226.0335693359375)
('rgb.max=', 135.84556579589844, 'rgb.min=', -226.13946533203125)
('rgb.max=', 135.89453125, 'rgb.min=', -225.96492004394531)
('rgb.max=', 135.90399169921875, 'rgb.min=', -226.03363037109375)
('rgb.max=', 135.9884033203125, 'rgb.min=', -226.18879699707031)
('rgb.max=', 135.94430541992188, 'rgb.min=', -225.90423583984375)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.762730')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6984 ', 'GAN acc 0.4570', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4922', 'Total loss: 1.3948', 'for batch', 0)
('GAN loss 0.6972 ', 'GAN acc 0.4922', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4766', 'Total loss: 1.3975', 'for batch', 1)
('GAN loss 0.7025 ', 'GAN acc 0.4258', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4824', 'Total loss: 1.4021', 'for batch', 2)
('GAN loss 0.6961 ', 'GAN acc 0.5469', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4844', 'Total loss: 1.3955', 'for batch', 3)
('GAN loss 0.6855 ', 'GAN acc 0.5703', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5234', 'Total loss: 1.3820', 'for batch', 4)
('GAN loss 0.6829 ', 'GAN acc 0.5820', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5215', 'Total loss: 1.3772', 'for batch', 5)
('GAN loss 0.6857 ', 'GAN acc 0.5664', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4746', 'Total loss: 1.3832', 'for batch', 6)
('GAN loss 0.6807 ', 'GAN acc 0.5703', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5039', 'Total loss: 1.3771', 'for batch', 7)
('GAN loss 0.6845 ', 'GAN acc 0.5859', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5137', 'Total loss: 1.3803', 'for batch', 8)
('GAN loss 0.6799 ', 'GAN acc 0.6172', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4863', 'Total loss: 1.3752', 'for batch', 9)
('GAN loss 0.6785 ', 'GAN acc 0.6289', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4941', 'Total loss: 1.3786', 'for batch', 10)
('GAN loss 0.6878 ', 'GAN acc 0.5430', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4648', 'Total loss: 1.3900', 'for batch', 11)
('GAN loss 0.6946 ', 'GAN acc 0.4883', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5059', 'Total loss: 1.3879', 'for batch', 12)
('GAN loss 0.7013 ', 'GAN acc 0.4766', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5117', 'Total loss: 1.3975', 'for batch', 13)
('GAN loss 0.6992 ', 'GAN acc 0.4844', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4707', 'Total loss: 1.3999', 'for batch', 14)
('GAN loss 0.7028 ', 'GAN acc 0.4883', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4668', 'Total loss: 1.4011', 'for batch', 15)
('GAN loss 0.7045 ', 'GAN acc 0.4258', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4590', 'Total loss: 1.4049', 'for batch', 16)
('GAN loss 0.7020 ', 'GAN acc 0.4883', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4805', 'Total loss: 1.4007', 'for batch', 17)
('GAN loss 0.6911 ', 'GAN acc 0.5312', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5195', 'Total loss: 1.3837', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55059385)
('DISCRIMINATOR_Imagem FAKE=', 0.55189806)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.13113403320312, 'rgb.min=', -226.0244140625)
('rgb.max=', 135.94758605957031, 'rgb.min=', -226.00492858886719)
('rgb.max=', 136.23617553710938, 'rgb.min=', -226.01614379882812)
('rgb.max=', 136.02374267578125, 'rgb.min=', -226.15872192382812)
('rgb.max=', 136.18075561523438, 'rgb.min=', -225.93232727050781)
('rgb.max=', 136.2177734375, 'rgb.min=', -226.33256530761719)
('rgb.max=', 135.85498046875, 'rgb.min=', -226.11845397949219)
('rgb.max=', 135.96794128417969, 'rgb.min=', -225.96900939941406)
('rgb.max=', 135.90301513671875, 'rgb.min=', -226.20999145507812)
('rgb.max=', 135.82545471191406, 'rgb.min=', -226.079345703125)
('rgb.max=', 135.71043395996094, 'rgb.min=', -226.10047912597656)
('rgb.max=', 135.8612060546875, 'rgb.min=', -225.99331665039062)
('rgb.max=', 135.78488159179688, 'rgb.min=', -226.09428405761719)
('rgb.max=', 135.93588256835938, 'rgb.min=', -226.15458679199219)
('rgb.max=', 135.81634521484375, 'rgb.min=', -226.03141784667969)
('rgb.max=', 135.81327819824219, 'rgb.min=', -226.05781555175781)
('rgb.max=', 135.826171875, 'rgb.min=', -225.95281982421875)
('rgb.max=', 135.92117309570312, 'rgb.min=', -225.81532287597656)
('rgb.max=', 135.93247985839844, 'rgb.min=', -226.05360412597656)
('rgb.max=', 135.97184753417969, 'rgb.min=', -226.26992797851562)
('rgb.max=', 136.10983276367188, 'rgb.min=', -225.98774719238281)
('rgb.max=', 136.27165222167969, 'rgb.min=', -225.95086669921875)
('rgb.max=', 136.24089050292969, 'rgb.min=', -225.85430908203125)
('rgb.max=', 135.98013305664062, 'rgb.min=', -226.02792358398438)
('rgb.max=', 135.80836486816406, 'rgb.min=', -226.00779724121094)
('rgb.max=', 136.04840087890625, 'rgb.min=', -226.03219604492188)
('rgb.max=', 136.08242797851562, 'rgb.min=', -226.12106323242188)
('rgb.max=', 135.8321533203125, 'rgb.min=', -225.91633605957031)
('rgb.max=', 135.9342041015625, 'rgb.min=', -225.95761108398438)
('rgb.max=', 135.91177368164062, 'rgb.min=', -226.02528381347656)
('rgb.max=', 135.92330932617188, 'rgb.min=', -226.11135864257812)
('rgb.max=', 135.872802734375, 'rgb.min=', -226.03648376464844)
('rgb.max=', 136.02963256835938, 'rgb.min=', -226.15779113769531)
('rgb.max=', 135.89981079101562, 'rgb.min=', -226.03050231933594)
('rgb.max=', 135.92015075683594, 'rgb.min=', -226.02958679199219)
('rgb.max=', 135.98751831054688, 'rgb.min=', -225.98545837402344)
('rgb.max=', 136.1324462890625, 'rgb.min=', -226.00907897949219)
('rgb.max=', 136.00584411621094, 'rgb.min=', -226.0462646484375)
('rgb.max=', 135.99639892578125, 'rgb.min=', -226.11405944824219)
('rgb.max=', 135.98544311523438, 'rgb.min=', -226.11520385742188)
('rgb.max=', 135.74070739746094, 'rgb.min=', -225.94277954101562)
('rgb.max=', 136.00642395019531, 'rgb.min=', -226.09904479980469)
('rgb.max=', 135.91984558105469, 'rgb.min=', -226.06192016601562)
('rgb.max=', 135.95913696289062, 'rgb.min=', -225.95986938476562)
('rgb.max=', 136.00521850585938, 'rgb.min=', -226.33424377441406)
('rgb.max=', 135.65093994140625, 'rgb.min=', -225.942626953125)
('rgb.max=', 135.95600891113281, 'rgb.min=', -225.99078369140625)
('rgb.max=', 135.74882507324219, 'rgb.min=', -225.89927673339844)
('rgb.max=', 135.9305419921875, 'rgb.min=', -225.98507690429688)
('rgb.max=', 136.25360107421875, 'rgb.min=', -226.05612182617188)
('rgb.max=', 136.0391845703125, 'rgb.min=', -226.02738952636719)
('rgb.max=', 136.27993774414062, 'rgb.min=', -226.02088928222656)
('rgb.max=', 135.69044494628906, 'rgb.min=', -226.03572082519531)
('rgb.max=', 135.88742065429688, 'rgb.min=', -226.04304504394531)
('rgb.max=', 136.17198181152344, 'rgb.min=', -226.04684448242188)
('rgb.max=', 136.16201782226562, 'rgb.min=', -226.09304809570312)
('rgb.max=', 135.90223693847656, 'rgb.min=', -226.01261901855469)
('rgb.max=', 135.83306884765625, 'rgb.min=', -226.07394409179688)
('rgb.max=', 135.87225341796875, 'rgb.min=', -225.9796142578125)
('rgb.max=', 135.60050964355469, 'rgb.min=', -226.16685485839844)
('rgb.max=', 135.97381591796875, 'rgb.min=', -226.13410949707031)
('rgb.max=', 135.77090454101562, 'rgb.min=', -225.8897705078125)
('rgb.max=', 135.75048828125, 'rgb.min=', -225.916015625)
('rgb.max=', 135.78172302246094, 'rgb.min=', -226.25079345703125)
('rgb.max=', 136.37135314941406, 'rgb.min=', -225.97032165527344)
('rgb.max=', 136.00637817382812, 'rgb.min=', -226.173583984375)
('rgb.max=', 135.712646484375, 'rgb.min=', -225.95610046386719)
('rgb.max=', 135.74746704101562, 'rgb.min=', -226.12030029296875)
('rgb.max=', 136.05047607421875, 'rgb.min=', -226.20265197753906)
('rgb.max=', 136.13031005859375, 'rgb.min=', -226.1009521484375)
('rgb.max=', 136.05172729492188, 'rgb.min=', -226.01681518554688)
('rgb.max=', 135.81698608398438, 'rgb.min=', -226.04855346679688)
('rgb.max=', 135.91650390625, 'rgb.min=', -226.176513671875)
('rgb.max=', 136.00851440429688, 'rgb.min=', -226.21882629394531)
('rgb.max=', 135.94810485839844, 'rgb.min=', -225.92558288574219)
('rgb.max=', 136.10415649414062, 'rgb.min=', -226.03318786621094)
('rgb.max=', 136.3057861328125, 'rgb.min=', -226.09976196289062)
('rgb.max=', 136.09121704101562, 'rgb.min=', -226.05821228027344)
('rgb.max=', 135.81202697753906, 'rgb.min=', -226.11711120605469)
('rgb.max=', 135.95773315429688, 'rgb.min=', -225.87271118164062)
('rgb.max=', 136.09222412109375, 'rgb.min=', -225.94786071777344)
('rgb.max=', 135.85676574707031, 'rgb.min=', -225.92274475097656)
('rgb.max=', 135.80535888671875, 'rgb.min=', -226.04338073730469)
('rgb.max=', 136.07176208496094, 'rgb.min=', -226.132080078125)
('rgb.max=', 136.04074096679688, 'rgb.min=', -226.16659545898438)
('rgb.max=', 135.89212036132812, 'rgb.min=', -226.01310729980469)
('rgb.max=', 135.98947143554688, 'rgb.min=', -225.92454528808594)
('rgb.max=', 135.74533081054688, 'rgb.min=', -225.98008728027344)
('rgb.max=', 135.98126220703125, 'rgb.min=', -226.175048828125)
('rgb.max=', 135.67431640625, 'rgb.min=', -226.01179504394531)
('rgb.max=', 135.921142578125, 'rgb.min=', -225.94058227539062)
('rgb.max=', 135.79812622070312, 'rgb.min=', -226.18782043457031)
('rgb.max=', 135.82131958007812, 'rgb.min=', -226.29110717773438)
('rgb.max=', 135.75836181640625, 'rgb.min=', -225.90374755859375)
('rgb.max=', 135.77249145507812, 'rgb.min=', -225.99220275878906)
('rgb.max=', 136.1336669921875, 'rgb.min=', -226.00428771972656)
('rgb.max=', 135.90243530273438, 'rgb.min=', -226.01470947265625)
('rgb.max=', 135.96525573730469, 'rgb.min=', -226.3717041015625)
('rgb.max=', 135.79591369628906, 'rgb.min=', -226.207763671875)
('rgb.max=', 135.94964599609375, 'rgb.min=', -226.05473327636719)
('rgb.max=', 135.8756103515625, 'rgb.min=', -226.09564208984375)
('rgb.max=', 135.75094604492188, 'rgb.min=', -225.90084838867188)
('rgb.max=', 135.96994018554688, 'rgb.min=', -225.93862915039062)
('rgb.max=', 135.91567993164062, 'rgb.min=', -225.95115661621094)
('rgb.max=', 135.91867065429688, 'rgb.min=', -225.90951538085938)
('rgb.max=', 136.2833251953125, 'rgb.min=', -226.05831909179688)
('rgb.max=', 136.00408935546875, 'rgb.min=', -226.09529113769531)
('rgb.max=', 135.98504638671875, 'rgb.min=', -226.09916687011719)
('rgb.max=', 136.18467712402344, 'rgb.min=', -225.95315551757812)
('rgb.max=', 135.96749877929688, 'rgb.min=', -225.92355346679688)
('rgb.max=', 136.04403686523438, 'rgb.min=', -226.01950073242188)
('rgb.max=', 136.28997802734375, 'rgb.min=', -225.90289306640625)
('rgb.max=', 135.94900512695312, 'rgb.min=', -225.8323974609375)
('rgb.max=', 136.03195190429688, 'rgb.min=', -225.87156677246094)
('rgb.max=', 135.87387084960938, 'rgb.min=', -226.04707336425781)
('rgb.max=', 135.85446166992188, 'rgb.min=', -226.28742980957031)
('rgb.max=', 135.6439208984375, 'rgb.min=', -225.97610473632812)
('rgb.max=', 135.9576416015625, 'rgb.min=', -225.92439270019531)
('rgb.max=', 135.80593872070312, 'rgb.min=', -225.89413452148438)
('rgb.max=', 136.08201599121094, 'rgb.min=', -225.90530395507812)
('rgb.max=', 136.05986022949219, 'rgb.min=', -226.08901977539062)
('rgb.max=', 136.35786437988281, 'rgb.min=', -226.08914184570312)
('rgb.max=', 135.82102966308594, 'rgb.min=', -225.92933654785156)
('rgb.max=', 135.88739013671875, 'rgb.min=', -225.96658325195312)
('rgb.max=', 135.83428955078125, 'rgb.min=', -225.83549499511719)
('rgb.max=', 135.94744873046875, 'rgb.min=', -226.0655517578125)
('rgb.max=', 135.84562683105469, 'rgb.min=', -225.78683471679688)
('rgb.max=', 136.17616271972656, 'rgb.min=', -226.00221252441406)
('rgb.max=', 135.64877319335938, 'rgb.min=', -226.12287902832031)
('rgb.max=', 135.990966796875, 'rgb.min=', -226.15608215332031)
('rgb.max=', 135.96170043945312, 'rgb.min=', -226.04719543457031)
('rgb.max=', 135.75527954101562, 'rgb.min=', -226.1417236328125)
('rgb.max=', 135.97189331054688, 'rgb.min=', -225.968017578125)
('rgb.max=', 136.19680786132812, 'rgb.min=', -225.94258117675781)
('rgb.max=', 136.12899780273438, 'rgb.min=', -225.84684753417969)
('rgb.max=', 135.70851135253906, 'rgb.min=', -226.12471008300781)
('rgb.max=', 135.88372802734375, 'rgb.min=', -226.08547973632812)
('rgb.max=', 135.96710205078125, 'rgb.min=', -226.03448486328125)
('rgb.max=', 135.82394409179688, 'rgb.min=', -226.11715698242188)
('rgb.max=', 135.97291564941406, 'rgb.min=', -226.06817626953125)
('rgb.max=', 135.89129638671875, 'rgb.min=', -225.896240234375)
('rgb.max=', 136.19386291503906, 'rgb.min=', -225.99342346191406)
('rgb.max=', 135.74436950683594, 'rgb.min=', -226.05838012695312)
('rgb.max=', 136.24772644042969, 'rgb.min=', -225.92024230957031)
('rgb.max=', 135.95083618164062, 'rgb.min=', -226.12744140625)
('rgb.max=', 136.25840759277344, 'rgb.min=', -225.81329345703125)
('rgb.max=', 135.88388061523438, 'rgb.min=', -225.87617492675781)
('rgb.max=', 136.19219970703125, 'rgb.min=', -226.20695495605469)
('rgb.max=', 136.17448425292969, 'rgb.min=', -226.14071655273438)
('rgb.max=', 136.16339111328125, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.82014465332031, 'rgb.min=', -225.85736083984375)
('rgb.max=', 135.99363708496094, 'rgb.min=', -226.059814453125)
('rgb.max=', 136.0235595703125, 'rgb.min=', -226.11337280273438)
('rgb.max=', 136.04917907714844, 'rgb.min=', -226.00927734375)
('rgb.max=', 135.87699890136719, 'rgb.min=', -226.03526306152344)
('rgb.max=', 135.87356567382812, 'rgb.min=', -225.77862548828125)
('rgb.max=', 136.1124267578125, 'rgb.min=', -226.02711486816406)
('rgb.max=', 135.95869445800781, 'rgb.min=', -226.03253173828125)
('rgb.max=', 135.78575134277344, 'rgb.min=', -226.15107727050781)
('rgb.max=', 135.74018859863281, 'rgb.min=', -225.79734802246094)
('rgb.max=', 135.86688232421875, 'rgb.min=', -225.89053344726562)
('rgb.max=', 135.95005798339844, 'rgb.min=', -226.01895141601562)
('rgb.max=', 135.96633911132812, 'rgb.min=', -226.04696655273438)
('rgb.max=', 135.70864868164062, 'rgb.min=', -225.9300537109375)
('rgb.max=', 136.27163696289062, 'rgb.min=', -226.00736999511719)
('rgb.max=', 136.07562255859375, 'rgb.min=', -226.00053405761719)
('rgb.max=', 136.01223754882812, 'rgb.min=', -226.04832458496094)
('rgb.max=', 135.70790100097656, 'rgb.min=', -226.04837036132812)
('rgb.max=', 136.24859619140625, 'rgb.min=', -226.13639831542969)
('rgb.max=', 136.11724853515625, 'rgb.min=', -225.97802734375)
('rgb.max=', 135.8271484375, 'rgb.min=', -226.00747680664062)
('rgb.max=', 136.12841796875, 'rgb.min=', -226.1055908203125)
('rgb.max=', 136.03555297851562, 'rgb.min=', -226.05186462402344)
('rgb.max=', 135.98420715332031, 'rgb.min=', -225.93096923828125)
('rgb.max=', 135.98536682128906, 'rgb.min=', -226.06857299804688)
('rgb.max=', 136.19821166992188, 'rgb.min=', -226.12855529785156)
('rgb.max=', 136.121337890625, 'rgb.min=', -225.9591064453125)
('rgb.max=', 135.79978942871094, 'rgb.min=', -225.95474243164062)
('rgb.max=', 135.76101684570312, 'rgb.min=', -226.00099182128906)
('rgb.max=', 135.76565551757812, 'rgb.min=', -225.92767333984375)
('rgb.max=', 135.91618347167969, 'rgb.min=', -226.23150634765625)
('rgb.max=', 136.05670166015625, 'rgb.min=', -226.01353454589844)
('rgb.max=', 135.97563171386719, 'rgb.min=', -225.96514892578125)
('rgb.max=', 136.18377685546875, 'rgb.min=', -226.01933288574219)
('rgb.max=', 136.28334045410156, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.95234680175781, 'rgb.min=', -226.12095642089844)
('rgb.max=', 135.87696838378906, 'rgb.min=', -226.02555847167969)
('rgb.max=', 135.906005859375, 'rgb.min=', -225.96965026855469)
('rgb.max=', 136.27523803710938, 'rgb.min=', -225.74575805664062)
('rgb.max=', 136.11175537109375, 'rgb.min=', -226.05178833007812)
('rgb.max=', 136.04440307617188, 'rgb.min=', -226.25810241699219)
('rgb.max=', 135.61209106445312, 'rgb.min=', -225.90840148925781)
('rgb.max=', 135.94900512695312, 'rgb.min=', -225.82640075683594)
('rgb.max=', 135.92391967773438, 'rgb.min=', -226.09251403808594)
('rgb.max=', 135.80323791503906, 'rgb.min=', -226.19090270996094)
('rgb.max=', 136.24319458007812, 'rgb.min=', -225.64372253417969)
('rgb.max=', 135.63069152832031, 'rgb.min=', -225.8758544921875)
('rgb.max=', 136.126953125, 'rgb.min=', -226.20303344726562)
('rgb.max=', 135.884765625, 'rgb.min=', -226.05232238769531)
('rgb.max=', 136.06869506835938, 'rgb.min=', -225.81600952148438)
('rgb.max=', 135.92704772949219, 'rgb.min=', -226.0721435546875)
('rgb.max=', 135.99618530273438, 'rgb.min=', -225.95835876464844)
('rgb.max=', 135.89375305175781, 'rgb.min=', -226.265625)
('rgb.max=', 136.03689575195312, 'rgb.min=', -225.97589111328125)
('rgb.max=', 136.10519409179688, 'rgb.min=', -226.08526611328125)
('rgb.max=', 135.93016052246094, 'rgb.min=', -226.205322265625)
('rgb.max=', 136.03199768066406, 'rgb.min=', -226.19532775878906)
('rgb.max=', 135.804443359375, 'rgb.min=', -225.85791015625)
('rgb.max=', 136.21907043457031, 'rgb.min=', -225.86434936523438)
('rgb.max=', 135.97772216796875, 'rgb.min=', -225.78834533691406)
('rgb.max=', 136.07562255859375, 'rgb.min=', -225.983642578125)
('rgb.max=', 135.84498596191406, 'rgb.min=', -226.19874572753906)
('rgb.max=', 135.92642211914062, 'rgb.min=', -225.90171813964844)
('rgb.max=', 136.22352600097656, 'rgb.min=', -226.08134460449219)
('rgb.max=', 135.95872497558594, 'rgb.min=', -225.79524230957031)
('rgb.max=', 136.01495361328125, 'rgb.min=', -225.88069152832031)
('rgb.max=', 136.07208251953125, 'rgb.min=', -225.91563415527344)
('rgb.max=', 135.89895629882812, 'rgb.min=', -226.04296875)
('rgb.max=', 135.90774536132812, 'rgb.min=', -226.18881225585938)
('rgb.max=', 135.695556640625, 'rgb.min=', -225.92959594726562)
('rgb.max=', 135.88690185546875, 'rgb.min=', -225.99073791503906)
('rgb.max=', 135.82673645019531, 'rgb.min=', -225.88005065917969)
('rgb.max=', 136.08517456054688, 'rgb.min=', -226.04756164550781)
('rgb.max=', 136.0501708984375, 'rgb.min=', -225.87895202636719)
('rgb.max=', 135.87725830078125, 'rgb.min=', -226.11610412597656)
('rgb.max=', 136.11962890625, 'rgb.min=', -225.74388122558594)
('rgb.max=', 135.94802856445312, 'rgb.min=', -226.18528747558594)
('rgb.max=', 135.96821594238281, 'rgb.min=', -225.86898803710938)
('rgb.max=', 135.72599792480469, 'rgb.min=', -225.97038269042969)
('rgb.max=', 135.68400573730469, 'rgb.min=', -225.8311767578125)
('rgb.max=', 135.89633178710938, 'rgb.min=', -226.17343139648438)
('rgb.max=', 135.93026733398438, 'rgb.min=', -226.31675720214844)
('rgb.max=', 135.71272277832031, 'rgb.min=', -225.92619323730469)
('rgb.max=', 135.77902221679688, 'rgb.min=', -225.96006774902344)
('rgb.max=', 135.95767211914062, 'rgb.min=', -226.21305847167969)
('rgb.max=', 136.23794555664062, 'rgb.min=', -226.18769836425781)
('rgb.max=', 135.92933654785156, 'rgb.min=', -226.39596557617188)
('rgb.max=', 136.24070739746094, 'rgb.min=', -226.00502014160156)
('rgb.max=', 136.08920288085938, 'rgb.min=', -225.70069885253906)
('rgb.max=', 136.17262268066406, 'rgb.min=', -226.12873840332031)
('rgb.max=', 135.9461669921875, 'rgb.min=', -226.14602661132812)
('rgb.max=', 136.18466186523438, 'rgb.min=', -226.03556823730469)
('rgb.max=', 135.65625, 'rgb.min=', -225.9964599609375)
('rgb.max=', 135.99348449707031, 'rgb.min=', -226.09686279296875)
('rgb.max=', 136.08921813964844, 'rgb.min=', -225.968505859375)
('rgb.max=', 136.21055603027344, 'rgb.min=', -225.86846923828125)
('rgb.max=', 136.040771484375, 'rgb.min=', -226.26988220214844)
('rgb.max=', 135.82052612304688, 'rgb.min=', -225.88238525390625)
('rgb.max=', 135.90509033203125, 'rgb.min=', -225.859130859375)
('rgb.max=', 135.69082641601562, 'rgb.min=', -226.35888671875)
('rgb.max=', 135.73052978515625, 'rgb.min=', -226.02072143554688)
('rgb.max=', 135.86065673828125, 'rgb.min=', -226.1820068359375)
('rgb.max=', 135.90037536621094, 'rgb.min=', -225.96054077148438)
('rgb.max=', 135.91534423828125, 'rgb.min=', -226.03652954101562)
('rgb.max=', 135.99490356445312, 'rgb.min=', -226.19267272949219)
('rgb.max=', 135.98419189453125, 'rgb.min=', -225.93846130371094)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.289182')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6933 ', 'GAN acc 0.5234', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5078', 'Total loss: 1.3898', 'for batch', 0)
('GAN loss 0.6895 ', 'GAN acc 0.5430', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5156', 'Total loss: 1.3826', 'for batch', 1)
('GAN loss 0.6932 ', 'GAN acc 0.5312', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.4727', 'Total loss: 1.3944', 'for batch', 2)
('GAN loss 0.6881 ', 'GAN acc 0.5508', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4902', 'Total loss: 1.3850', 'for batch', 3)
('GAN loss 0.6858 ', 'GAN acc 0.5469', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4688', 'Total loss: 1.3851', 'for batch', 4)
('GAN loss 0.6877 ', 'GAN acc 0.5820', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4980', 'Total loss: 1.3819', 'for batch', 5)
('GAN loss 0.6826 ', 'GAN acc 0.5820', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5000', 'Total loss: 1.3764', 'for batch', 6)
('GAN loss 0.6844 ', 'GAN acc 0.6055', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4902', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6836 ', 'GAN acc 0.5820', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4844', 'Total loss: 1.3809', 'for batch', 8)
('GAN loss 0.6829 ', 'GAN acc 0.6133', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4453', 'Total loss: 1.3828', 'for batch', 9)
('GAN loss 0.6934 ', 'GAN acc 0.5117', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5078', 'Total loss: 1.3890', 'for batch', 10)
('GAN loss 0.6874 ', 'GAN acc 0.5703', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4961', 'Total loss: 1.3826', 'for batch', 11)
('GAN loss 0.6821 ', 'GAN acc 0.5703', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4922', 'Total loss: 1.3795', 'for batch', 12)
('GAN loss 0.6850 ', 'GAN acc 0.5391', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4668', 'Total loss: 1.3854', 'for batch', 13)
('GAN loss 0.6903 ', 'GAN acc 0.5391', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4785', 'Total loss: 1.3891', 'for batch', 14)
('GAN loss 0.6859 ', 'GAN acc 0.5547', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5215', 'Total loss: 1.3794', 'for batch', 15)
('GAN loss 0.6879 ', 'GAN acc 0.5430', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5137', 'Total loss: 1.3830', 'for batch', 16)
('GAN loss 0.6983 ', 'GAN acc 0.4570', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4648', 'Total loss: 1.3985', 'for batch', 17)
('GAN loss 0.6962 ', 'GAN acc 0.4922', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4844', 'Total loss: 1.3936', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54342902)
('DISCRIMINATOR_Imagem FAKE=', 0.54390091)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.12155151367188, 'rgb.min=', -226.08786010742188)
('rgb.max=', 135.92190551757812, 'rgb.min=', -226.03390502929688)
('rgb.max=', 136.25283813476562, 'rgb.min=', -225.95219421386719)
('rgb.max=', 136.05953979492188, 'rgb.min=', -226.12432861328125)
('rgb.max=', 136.18716430664062, 'rgb.min=', -225.92936706542969)
('rgb.max=', 136.25558471679688, 'rgb.min=', -226.44020080566406)
('rgb.max=', 135.83840942382812, 'rgb.min=', -226.11361694335938)
('rgb.max=', 135.95869445800781, 'rgb.min=', -225.95985412597656)
('rgb.max=', 135.8828125, 'rgb.min=', -226.14862060546875)
('rgb.max=', 135.80093383789062, 'rgb.min=', -226.04783630371094)
('rgb.max=', 135.70565795898438, 'rgb.min=', -226.11471557617188)
('rgb.max=', 135.84426879882812, 'rgb.min=', -225.95751953125)
('rgb.max=', 135.78318786621094, 'rgb.min=', -226.04164123535156)
('rgb.max=', 135.94732666015625, 'rgb.min=', -226.20277404785156)
('rgb.max=', 135.79977416992188, 'rgb.min=', -226.084228515625)
('rgb.max=', 135.8004150390625, 'rgb.min=', -226.03390502929688)
('rgb.max=', 135.82403564453125, 'rgb.min=', -225.90611267089844)
('rgb.max=', 135.89886474609375, 'rgb.min=', -225.81379699707031)
('rgb.max=', 135.92770385742188, 'rgb.min=', -226.06741333007812)
('rgb.max=', 135.99159240722656, 'rgb.min=', -226.27751159667969)
('rgb.max=', 136.13151550292969, 'rgb.min=', -225.98774719238281)
('rgb.max=', 136.29080200195312, 'rgb.min=', -225.91207885742188)
('rgb.max=', 136.25741577148438, 'rgb.min=', -225.89198303222656)
('rgb.max=', 136.0048828125, 'rgb.min=', -226.08926391601562)
('rgb.max=', 135.789306640625, 'rgb.min=', -225.92591857910156)
('rgb.max=', 136.07086181640625, 'rgb.min=', -225.96279907226562)
('rgb.max=', 136.138671875, 'rgb.min=', -226.03616333007812)
('rgb.max=', 135.84564208984375, 'rgb.min=', -225.81562805175781)
('rgb.max=', 135.92861938476562, 'rgb.min=', -225.918212890625)
('rgb.max=', 135.86569213867188, 'rgb.min=', -225.99266052246094)
('rgb.max=', 135.91477966308594, 'rgb.min=', -226.03857421875)
('rgb.max=', 135.84516906738281, 'rgb.min=', -226.00332641601562)
('rgb.max=', 136.070556640625, 'rgb.min=', -226.09025573730469)
('rgb.max=', 135.87812805175781, 'rgb.min=', -226.00666809082031)
('rgb.max=', 135.92536926269531, 'rgb.min=', -226.05099487304688)
('rgb.max=', 136.03173828125, 'rgb.min=', -225.97958374023438)
('rgb.max=', 136.18093872070312, 'rgb.min=', -225.93196105957031)
('rgb.max=', 136.03521728515625, 'rgb.min=', -226.06880187988281)
('rgb.max=', 136.01087951660156, 'rgb.min=', -226.11405944824219)
('rgb.max=', 135.9991455078125, 'rgb.min=', -226.11575317382812)
('rgb.max=', 135.72442626953125, 'rgb.min=', -226.01380920410156)
('rgb.max=', 136.00323486328125, 'rgb.min=', -226.10060119628906)
('rgb.max=', 135.9051513671875, 'rgb.min=', -226.04583740234375)
('rgb.max=', 135.95733642578125, 'rgb.min=', -226.04678344726562)
('rgb.max=', 136.026611328125, 'rgb.min=', -226.34419250488281)
('rgb.max=', 135.66864013671875, 'rgb.min=', -226.01835632324219)
('rgb.max=', 135.97773742675781, 'rgb.min=', -226.0323486328125)
('rgb.max=', 135.73089599609375, 'rgb.min=', -225.99754333496094)
('rgb.max=', 135.94357299804688, 'rgb.min=', -225.93232727050781)
('rgb.max=', 136.27468872070312, 'rgb.min=', -226.118896484375)
('rgb.max=', 136.04985046386719, 'rgb.min=', -226.05303955078125)
('rgb.max=', 136.26033020019531, 'rgb.min=', -226.05718994140625)
('rgb.max=', 135.6629638671875, 'rgb.min=', -225.97320556640625)
('rgb.max=', 135.91264343261719, 'rgb.min=', -225.91024780273438)
('rgb.max=', 136.18505859375, 'rgb.min=', -226.12577819824219)
('rgb.max=', 136.17091369628906, 'rgb.min=', -226.04243469238281)
('rgb.max=', 135.889404296875, 'rgb.min=', -225.98320007324219)
('rgb.max=', 135.81216430664062, 'rgb.min=', -226.05291748046875)
('rgb.max=', 135.85614013671875, 'rgb.min=', -226.03079223632812)
('rgb.max=', 135.57469177246094, 'rgb.min=', -226.10752868652344)
('rgb.max=', 135.97433471679688, 'rgb.min=', -226.02078247070312)
('rgb.max=', 135.78976440429688, 'rgb.min=', -225.94143676757812)
('rgb.max=', 135.73272705078125, 'rgb.min=', -225.93606567382812)
('rgb.max=', 135.75790405273438, 'rgb.min=', -226.25730895996094)
('rgb.max=', 136.39883422851562, 'rgb.min=', -225.87687683105469)
('rgb.max=', 135.97811889648438, 'rgb.min=', -226.1070556640625)
('rgb.max=', 135.72573852539062, 'rgb.min=', -226.00631713867188)
('rgb.max=', 135.73214721679688, 'rgb.min=', -226.03761291503906)
('rgb.max=', 136.08985900878906, 'rgb.min=', -226.18702697753906)
('rgb.max=', 136.13320922851562, 'rgb.min=', -226.07945251464844)
('rgb.max=', 136.05084228515625, 'rgb.min=', -225.9873046875)
('rgb.max=', 135.79598999023438, 'rgb.min=', -226.0379638671875)
('rgb.max=', 135.90695190429688, 'rgb.min=', -226.18551635742188)
('rgb.max=', 135.98712158203125, 'rgb.min=', -226.10043334960938)
('rgb.max=', 135.933349609375, 'rgb.min=', -225.99725341796875)
('rgb.max=', 136.11579895019531, 'rgb.min=', -226.01809692382812)
('rgb.max=', 136.33868408203125, 'rgb.min=', -226.11669921875)
('rgb.max=', 136.11795043945312, 'rgb.min=', -226.05821228027344)
('rgb.max=', 135.82412719726562, 'rgb.min=', -226.01116943359375)
('rgb.max=', 135.93721008300781, 'rgb.min=', -225.83744812011719)
('rgb.max=', 136.08316040039062, 'rgb.min=', -225.94956970214844)
('rgb.max=', 135.848388671875, 'rgb.min=', -225.93788146972656)
('rgb.max=', 135.7918701171875, 'rgb.min=', -225.97627258300781)
('rgb.max=', 136.04415893554688, 'rgb.min=', -226.08073425292969)
('rgb.max=', 136.05097961425781, 'rgb.min=', -226.15692138671875)
('rgb.max=', 135.8616943359375, 'rgb.min=', -226.01121520996094)
('rgb.max=', 136.05210876464844, 'rgb.min=', -225.92926025390625)
('rgb.max=', 135.78413391113281, 'rgb.min=', -225.92610168457031)
('rgb.max=', 135.96868896484375, 'rgb.min=', -226.18510437011719)
('rgb.max=', 135.67411804199219, 'rgb.min=', -226.00581359863281)
('rgb.max=', 135.90716552734375, 'rgb.min=', -225.98289489746094)
('rgb.max=', 135.77662658691406, 'rgb.min=', -226.18325805664062)
('rgb.max=', 135.81947326660156, 'rgb.min=', -226.28839111328125)
('rgb.max=', 135.74099731445312, 'rgb.min=', -225.85011291503906)
('rgb.max=', 135.75784301757812, 'rgb.min=', -225.97734069824219)
('rgb.max=', 136.14486694335938, 'rgb.min=', -226.00428771972656)
('rgb.max=', 135.9366455078125, 'rgb.min=', -226.05009460449219)
('rgb.max=', 136.01896667480469, 'rgb.min=', -226.38436889648438)
('rgb.max=', 135.77273559570312, 'rgb.min=', -226.16392517089844)
('rgb.max=', 135.94416809082031, 'rgb.min=', -226.00836181640625)
('rgb.max=', 135.87808227539062, 'rgb.min=', -226.20907592773438)
('rgb.max=', 135.73760986328125, 'rgb.min=', -225.85307312011719)
('rgb.max=', 135.99253845214844, 'rgb.min=', -225.9923095703125)
('rgb.max=', 135.90550231933594, 'rgb.min=', -225.88699340820312)
('rgb.max=', 135.89471435546875, 'rgb.min=', -225.90647888183594)
('rgb.max=', 136.29937744140625, 'rgb.min=', -226.06800842285156)
('rgb.max=', 135.9720458984375, 'rgb.min=', -226.02621459960938)
('rgb.max=', 135.98846435546875, 'rgb.min=', -226.19157409667969)
('rgb.max=', 136.19880676269531, 'rgb.min=', -226.01921081542969)
('rgb.max=', 135.99600219726562, 'rgb.min=', -225.97389221191406)
('rgb.max=', 136.02752685546875, 'rgb.min=', -225.97677612304688)
('rgb.max=', 136.30644226074219, 'rgb.min=', -225.89749145507812)
('rgb.max=', 135.95797729492188, 'rgb.min=', -225.82386779785156)
('rgb.max=', 136.02120971679688, 'rgb.min=', -225.95245361328125)
('rgb.max=', 135.85284423828125, 'rgb.min=', -225.97622680664062)
('rgb.max=', 135.8441162109375, 'rgb.min=', -226.28166198730469)
('rgb.max=', 135.62754821777344, 'rgb.min=', -226.03538513183594)
('rgb.max=', 135.97511291503906, 'rgb.min=', -225.99026489257812)
('rgb.max=', 135.78315734863281, 'rgb.min=', -225.84654235839844)
('rgb.max=', 136.09420776367188, 'rgb.min=', -225.87652587890625)
('rgb.max=', 136.06486511230469, 'rgb.min=', -226.00215148925781)
('rgb.max=', 136.36183166503906, 'rgb.min=', -226.05064392089844)
('rgb.max=', 135.80827331542969, 'rgb.min=', -225.87547302246094)
('rgb.max=', 135.86875915527344, 'rgb.min=', -225.95925903320312)
('rgb.max=', 135.81596374511719, 'rgb.min=', -225.78065490722656)
('rgb.max=', 135.98451232910156, 'rgb.min=', -226.07127380371094)
('rgb.max=', 135.82296752929688, 'rgb.min=', -225.85408020019531)
('rgb.max=', 136.21115112304688, 'rgb.min=', -226.02505493164062)
('rgb.max=', 135.62997436523438, 'rgb.min=', -226.06816101074219)
('rgb.max=', 136.00228881835938, 'rgb.min=', -226.14627075195312)
('rgb.max=', 136.01834106445312, 'rgb.min=', -226.06349182128906)
('rgb.max=', 135.73309326171875, 'rgb.min=', -226.05702209472656)
('rgb.max=', 136.00337219238281, 'rgb.min=', -225.90385437011719)
('rgb.max=', 136.21475219726562, 'rgb.min=', -225.94258117675781)
('rgb.max=', 136.14044189453125, 'rgb.min=', -225.8653564453125)
('rgb.max=', 135.68392944335938, 'rgb.min=', -226.13543701171875)
('rgb.max=', 135.8629150390625, 'rgb.min=', -226.10047912597656)
('rgb.max=', 136.00917053222656, 'rgb.min=', -226.03448486328125)
('rgb.max=', 135.82115173339844, 'rgb.min=', -226.05476379394531)
('rgb.max=', 136.01412963867188, 'rgb.min=', -226.095703125)
('rgb.max=', 135.8797607421875, 'rgb.min=', -226.00370788574219)
('rgb.max=', 136.16102600097656, 'rgb.min=', -225.9730224609375)
('rgb.max=', 135.7230224609375, 'rgb.min=', -226.06381225585938)
('rgb.max=', 136.26463317871094, 'rgb.min=', -225.91090393066406)
('rgb.max=', 135.95376586914062, 'rgb.min=', -226.08583068847656)
('rgb.max=', 136.27912902832031, 'rgb.min=', -225.90847778320312)
('rgb.max=', 135.875, 'rgb.min=', -225.85563659667969)
('rgb.max=', 136.20526123046875, 'rgb.min=', -226.16949462890625)
('rgb.max=', 136.18925476074219, 'rgb.min=', -226.08955383300781)
('rgb.max=', 136.20669555664062, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.80227661132812, 'rgb.min=', -225.9013671875)
('rgb.max=', 136.01693725585938, 'rgb.min=', -226.07928466796875)
('rgb.max=', 136.07595825195312, 'rgb.min=', -226.146728515625)
('rgb.max=', 136.07351684570312, 'rgb.min=', -226.04988098144531)
('rgb.max=', 135.87214660644531, 'rgb.min=', -226.01127624511719)
('rgb.max=', 135.84735107421875, 'rgb.min=', -225.83866882324219)
('rgb.max=', 136.1302490234375, 'rgb.min=', -226.03877258300781)
('rgb.max=', 135.96002197265625, 'rgb.min=', -226.06968688964844)
('rgb.max=', 135.76068115234375, 'rgb.min=', -226.16262817382812)
('rgb.max=', 135.74209594726562, 'rgb.min=', -225.83720397949219)
('rgb.max=', 135.84054565429688, 'rgb.min=', -225.96841430664062)
('rgb.max=', 135.92352294921875, 'rgb.min=', -226.02824401855469)
('rgb.max=', 135.94740295410156, 'rgb.min=', -226.01545715332031)
('rgb.max=', 135.71575927734375, 'rgb.min=', -225.91079711914062)
('rgb.max=', 136.28573608398438, 'rgb.min=', -225.97628784179688)
('rgb.max=', 136.11341857910156, 'rgb.min=', -226.00053405761719)
('rgb.max=', 135.98680114746094, 'rgb.min=', -226.10125732421875)
('rgb.max=', 135.712646484375, 'rgb.min=', -226.03411865234375)
('rgb.max=', 136.26089477539062, 'rgb.min=', -226.06320190429688)
('rgb.max=', 136.12004089355469, 'rgb.min=', -225.94680786132812)
('rgb.max=', 135.81538391113281, 'rgb.min=', -225.96867370605469)
('rgb.max=', 136.13946533203125, 'rgb.min=', -226.11566162109375)
('rgb.max=', 136.06587219238281, 'rgb.min=', -226.05186462402344)
('rgb.max=', 136.0108642578125, 'rgb.min=', -225.91094970703125)
('rgb.max=', 135.97195434570312, 'rgb.min=', -226.02604675292969)
('rgb.max=', 136.20985412597656, 'rgb.min=', -226.06591796875)
('rgb.max=', 136.13951110839844, 'rgb.min=', -226.00190734863281)
('rgb.max=', 135.78219604492188, 'rgb.min=', -226.00042724609375)
('rgb.max=', 135.73681640625, 'rgb.min=', -225.92393493652344)
('rgb.max=', 135.75772094726562, 'rgb.min=', -225.877197265625)
('rgb.max=', 135.8929443359375, 'rgb.min=', -226.20219421386719)
('rgb.max=', 136.07676696777344, 'rgb.min=', -225.97251892089844)
('rgb.max=', 135.95552062988281, 'rgb.min=', -225.928955078125)
('rgb.max=', 136.19271850585938, 'rgb.min=', -226.01933288574219)
('rgb.max=', 136.30853271484375, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.93223571777344, 'rgb.min=', -226.04475402832031)
('rgb.max=', 135.84974670410156, 'rgb.min=', -225.96131896972656)
('rgb.max=', 135.88156127929688, 'rgb.min=', -225.92381286621094)
('rgb.max=', 136.28988647460938, 'rgb.min=', -225.81599426269531)
('rgb.max=', 136.10816955566406, 'rgb.min=', -226.05178833007812)
('rgb.max=', 136.05613708496094, 'rgb.min=', -226.27204895019531)
('rgb.max=', 135.64155578613281, 'rgb.min=', -225.84930419921875)
('rgb.max=', 135.94775390625, 'rgb.min=', -225.87767028808594)
('rgb.max=', 135.90985107421875, 'rgb.min=', -226.04994201660156)
('rgb.max=', 135.78515625, 'rgb.min=', -226.14048767089844)
('rgb.max=', 136.2572021484375, 'rgb.min=', -225.64131164550781)
('rgb.max=', 135.58219909667969, 'rgb.min=', -225.77613830566406)
('rgb.max=', 136.14216613769531, 'rgb.min=', -226.201904296875)
('rgb.max=', 135.87286376953125, 'rgb.min=', -225.9862060546875)
('rgb.max=', 136.06838989257812, 'rgb.min=', -225.81961059570312)
('rgb.max=', 135.90892028808594, 'rgb.min=', -226.0396728515625)
('rgb.max=', 136.06547546386719, 'rgb.min=', -225.92027282714844)
('rgb.max=', 135.87188720703125, 'rgb.min=', -226.25825500488281)
('rgb.max=', 136.02200317382812, 'rgb.min=', -225.89730834960938)
('rgb.max=', 136.12002563476562, 'rgb.min=', -226.01216125488281)
('rgb.max=', 135.92338562011719, 'rgb.min=', -226.16091918945312)
('rgb.max=', 136.05752563476562, 'rgb.min=', -226.22393798828125)
('rgb.max=', 135.83822631835938, 'rgb.min=', -225.81387329101562)
('rgb.max=', 136.23239135742188, 'rgb.min=', -225.80488586425781)
('rgb.max=', 136.08332824707031, 'rgb.min=', -225.75051879882812)
('rgb.max=', 136.08819580078125, 'rgb.min=', -225.92921447753906)
('rgb.max=', 135.82327270507812, 'rgb.min=', -226.13276672363281)
('rgb.max=', 135.92263793945312, 'rgb.min=', -225.85272216796875)
('rgb.max=', 136.23565673828125, 'rgb.min=', -226.09666442871094)
('rgb.max=', 135.93058776855469, 'rgb.min=', -225.87144470214844)
('rgb.max=', 136.01258850097656, 'rgb.min=', -225.84080505371094)
('rgb.max=', 136.10653686523438, 'rgb.min=', -225.88818359375)
('rgb.max=', 135.89431762695312, 'rgb.min=', -225.97479248046875)
('rgb.max=', 135.92915344238281, 'rgb.min=', -226.19004821777344)
('rgb.max=', 135.67961120605469, 'rgb.min=', -225.94059753417969)
('rgb.max=', 135.87654113769531, 'rgb.min=', -225.9271240234375)
('rgb.max=', 135.80157470703125, 'rgb.min=', -225.84262084960938)
('rgb.max=', 136.11138916015625, 'rgb.min=', -226.04397583007812)
('rgb.max=', 136.03791809082031, 'rgb.min=', -225.85308837890625)
('rgb.max=', 135.85888671875, 'rgb.min=', -226.00369262695312)
('rgb.max=', 136.12503051757812, 'rgb.min=', -225.78013610839844)
('rgb.max=', 135.93080139160156, 'rgb.min=', -226.22218322753906)
('rgb.max=', 135.9681396484375, 'rgb.min=', -225.75701904296875)
('rgb.max=', 135.707763671875, 'rgb.min=', -225.936279296875)
('rgb.max=', 135.65098571777344, 'rgb.min=', -225.76930236816406)
('rgb.max=', 135.8768310546875, 'rgb.min=', -226.10606384277344)
('rgb.max=', 135.912353515625, 'rgb.min=', -226.27220153808594)
('rgb.max=', 135.70175170898438, 'rgb.min=', -225.8895263671875)
('rgb.max=', 135.76821899414062, 'rgb.min=', -225.89588928222656)
('rgb.max=', 135.96392822265625, 'rgb.min=', -226.29205322265625)
('rgb.max=', 136.25477600097656, 'rgb.min=', -226.09553527832031)
('rgb.max=', 135.96682739257812, 'rgb.min=', -226.35685729980469)
('rgb.max=', 136.253662109375, 'rgb.min=', -225.96359252929688)
('rgb.max=', 136.10208129882812, 'rgb.min=', -225.61074829101562)
('rgb.max=', 136.18234252929688, 'rgb.min=', -226.0792236328125)
('rgb.max=', 135.94638061523438, 'rgb.min=', -226.10092163085938)
('rgb.max=', 136.20773315429688, 'rgb.min=', -225.99151611328125)
('rgb.max=', 135.64344787597656, 'rgb.min=', -225.89263916015625)
('rgb.max=', 136.00187683105469, 'rgb.min=', -226.07749938964844)
('rgb.max=', 136.10472106933594, 'rgb.min=', -225.93798828125)
('rgb.max=', 136.22169494628906, 'rgb.min=', -225.83673095703125)
('rgb.max=', 136.01992797851562, 'rgb.min=', -226.29887390136719)
('rgb.max=', 135.8399658203125, 'rgb.min=', -225.83372497558594)
('rgb.max=', 135.89569091796875, 'rgb.min=', -225.84765625)
('rgb.max=', 135.6689453125, 'rgb.min=', -226.29670715332031)
('rgb.max=', 135.71612548828125, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.84512329101562, 'rgb.min=', -226.23957824707031)
('rgb.max=', 135.88702392578125, 'rgb.min=', -225.86833190917969)
('rgb.max=', 135.93104553222656, 'rgb.min=', -225.99580383300781)
('rgb.max=', 135.98489379882812, 'rgb.min=', -226.13165283203125)
('rgb.max=', 135.95162963867188, 'rgb.min=', -225.84832763671875)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.759012')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6942 ', 'GAN acc 0.5195', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5020', 'Total loss: 1.3905', 'for batch', 0)
('GAN loss 0.7032 ', 'GAN acc 0.4648', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5215', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.6983 ', 'GAN acc 0.4922', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4824', 'Total loss: 1.3938', 'for batch', 2)
('GAN loss 0.6945 ', 'GAN acc 0.5312', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4648', 'Total loss: 1.3930', 'for batch', 3)
('GAN loss 0.6896 ', 'GAN acc 0.5312', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4453', 'Total loss: 1.3906', 'for batch', 4)
('GAN loss 0.6862 ', 'GAN acc 0.5703', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4824', 'Total loss: 1.3821', 'for batch', 5)
('GAN loss 0.6825 ', 'GAN acc 0.5898', 'Discriminator loss 0.7049', 'Discriminator accuracy 0.4473', 'Total loss: 1.3874', 'for batch', 6)
('GAN loss 0.6842 ', 'GAN acc 0.5352', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5215', 'Total loss: 1.3772', 'for batch', 7)
('GAN loss 0.6865 ', 'GAN acc 0.5391', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5098', 'Total loss: 1.3805', 'for batch', 8)
('GAN loss 0.6877 ', 'GAN acc 0.5312', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5371', 'Total loss: 1.3813', 'for batch', 9)
('GAN loss 0.6848 ', 'GAN acc 0.5586', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5078', 'Total loss: 1.3772', 'for batch', 10)
('GAN loss 0.6930 ', 'GAN acc 0.5117', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4531', 'Total loss: 1.3926', 'for batch', 11)
('GAN loss 0.6863 ', 'GAN acc 0.5742', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4805', 'Total loss: 1.3796', 'for batch', 12)
('GAN loss 0.6872 ', 'GAN acc 0.5547', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4941', 'Total loss: 1.3808', 'for batch', 13)
('GAN loss 0.6877 ', 'GAN acc 0.5508', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4707', 'Total loss: 1.3861', 'for batch', 14)
('GAN loss 0.7007 ', 'GAN acc 0.4492', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4922', 'Total loss: 1.3963', 'for batch', 15)
('GAN loss 0.7092 ', 'GAN acc 0.4062', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4785', 'Total loss: 1.4063', 'for batch', 16)
('GAN loss 0.6996 ', 'GAN acc 0.4531', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3925', 'for batch', 17)
('GAN loss 0.7057 ', 'GAN acc 0.4258', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4844', 'Total loss: 1.4051', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53664172)
('DISCRIMINATOR_Imagem FAKE=', 0.53703314)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.21260070800781, 'rgb.min=', -226.05317687988281)
('rgb.max=', 135.92558288574219, 'rgb.min=', -226.08981323242188)
('rgb.max=', 136.1898193359375, 'rgb.min=', -225.97428894042969)
('rgb.max=', 136.0372314453125, 'rgb.min=', -226.12554931640625)
('rgb.max=', 136.22857666015625, 'rgb.min=', -225.92936706542969)
('rgb.max=', 136.28614807128906, 'rgb.min=', -226.4373779296875)
('rgb.max=', 135.84266662597656, 'rgb.min=', -226.18516540527344)
('rgb.max=', 135.94082641601562, 'rgb.min=', -225.96107482910156)
('rgb.max=', 135.93536376953125, 'rgb.min=', -226.1488037109375)
('rgb.max=', 135.80462646484375, 'rgb.min=', -226.03038024902344)
('rgb.max=', 135.69931030273438, 'rgb.min=', -226.18592834472656)
('rgb.max=', 135.84516906738281, 'rgb.min=', -226.02938842773438)
('rgb.max=', 135.80271911621094, 'rgb.min=', -226.05099487304688)
('rgb.max=', 135.94358825683594, 'rgb.min=', -226.18348693847656)
('rgb.max=', 135.80316162109375, 'rgb.min=', -226.04905700683594)
('rgb.max=', 135.79960632324219, 'rgb.min=', -226.03007507324219)
('rgb.max=', 135.84512329101562, 'rgb.min=', -225.92239379882812)
('rgb.max=', 135.90756225585938, 'rgb.min=', -225.78858947753906)
('rgb.max=', 135.91656494140625, 'rgb.min=', -226.13970947265625)
('rgb.max=', 135.98922729492188, 'rgb.min=', -226.35641479492188)
('rgb.max=', 136.17616271972656, 'rgb.min=', -225.98774719238281)
('rgb.max=', 136.22293090820312, 'rgb.min=', -225.89826965332031)
('rgb.max=', 136.189208984375, 'rgb.min=', -225.85202026367188)
('rgb.max=', 136.05795288085938, 'rgb.min=', -226.06576538085938)
('rgb.max=', 135.798583984375, 'rgb.min=', -226.01904296875)
('rgb.max=', 136.06263732910156, 'rgb.min=', -225.97344970703125)
('rgb.max=', 136.22718811035156, 'rgb.min=', -226.07005310058594)
('rgb.max=', 135.8193359375, 'rgb.min=', -225.84248352050781)
('rgb.max=', 135.93074035644531, 'rgb.min=', -225.94145202636719)
('rgb.max=', 135.863525390625, 'rgb.min=', -225.99026489257812)
('rgb.max=', 135.92495727539062, 'rgb.min=', -226.04591369628906)
('rgb.max=', 135.88723754882812, 'rgb.min=', -226.00668334960938)
('rgb.max=', 136.10675048828125, 'rgb.min=', -226.13482666015625)
('rgb.max=', 135.89569091796875, 'rgb.min=', -226.05142211914062)
('rgb.max=', 135.95744323730469, 'rgb.min=', -226.04524230957031)
('rgb.max=', 136.04609680175781, 'rgb.min=', -225.94557189941406)
('rgb.max=', 136.2449951171875, 'rgb.min=', -226.0076904296875)
('rgb.max=', 136.02928161621094, 'rgb.min=', -226.11393737792969)
('rgb.max=', 136.06695556640625, 'rgb.min=', -226.11405944824219)
('rgb.max=', 136.05685424804688, 'rgb.min=', -226.11575317382812)
('rgb.max=', 135.72775268554688, 'rgb.min=', -226.01852416992188)
('rgb.max=', 136.0068359375, 'rgb.min=', -226.167724609375)
('rgb.max=', 135.9114990234375, 'rgb.min=', -226.04878234863281)
('rgb.max=', 135.9984130859375, 'rgb.min=', -225.98992919921875)
('rgb.max=', 135.99996948242188, 'rgb.min=', -226.41603088378906)
('rgb.max=', 135.65348815917969, 'rgb.min=', -226.01905822753906)
('rgb.max=', 135.98507690429688, 'rgb.min=', -226.02952575683594)
('rgb.max=', 135.70951843261719, 'rgb.min=', -225.98616027832031)
('rgb.max=', 135.89860534667969, 'rgb.min=', -225.95390319824219)
('rgb.max=', 136.29513549804688, 'rgb.min=', -226.06353759765625)
('rgb.max=', 136.052490234375, 'rgb.min=', -226.04510498046875)
('rgb.max=', 136.30320739746094, 'rgb.min=', -225.97749328613281)
('rgb.max=', 135.697265625, 'rgb.min=', -226.03683471679688)
('rgb.max=', 135.885498046875, 'rgb.min=', -225.91487121582031)
('rgb.max=', 136.12550354003906, 'rgb.min=', -226.08599853515625)
('rgb.max=', 136.28053283691406, 'rgb.min=', -226.06303405761719)
('rgb.max=', 135.895751953125, 'rgb.min=', -226.02511596679688)
('rgb.max=', 135.81298828125, 'rgb.min=', -226.06159973144531)
('rgb.max=', 135.8587646484375, 'rgb.min=', -226.01826477050781)
('rgb.max=', 135.57933044433594, 'rgb.min=', -226.09588623046875)
('rgb.max=', 135.96168518066406, 'rgb.min=', -226.11883544921875)
('rgb.max=', 135.80366516113281, 'rgb.min=', -225.942626953125)
('rgb.max=', 135.72462463378906, 'rgb.min=', -225.95967102050781)
('rgb.max=', 135.75947570800781, 'rgb.min=', -226.33450317382812)
('rgb.max=', 136.44694519042969, 'rgb.min=', -225.86656188964844)
('rgb.max=', 135.98243713378906, 'rgb.min=', -226.157958984375)
('rgb.max=', 135.73246765136719, 'rgb.min=', -225.99676513671875)
('rgb.max=', 135.72618103027344, 'rgb.min=', -226.07400512695312)
('rgb.max=', 136.12528991699219, 'rgb.min=', -226.22795104980469)
('rgb.max=', 136.24256896972656, 'rgb.min=', -226.13583374023438)
('rgb.max=', 136.1448974609375, 'rgb.min=', -226.043701171875)
('rgb.max=', 135.84634399414062, 'rgb.min=', -226.01348876953125)
('rgb.max=', 135.91464233398438, 'rgb.min=', -226.26365661621094)
('rgb.max=', 135.97895812988281, 'rgb.min=', -226.05769348144531)
('rgb.max=', 135.98991394042969, 'rgb.min=', -225.97024536132812)
('rgb.max=', 136.07827758789062, 'rgb.min=', -226.06739807128906)
('rgb.max=', 136.34051513671875, 'rgb.min=', -226.0313720703125)
('rgb.max=', 136.15997314453125, 'rgb.min=', -226.05821228027344)
('rgb.max=', 135.84506225585938, 'rgb.min=', -226.125244140625)
('rgb.max=', 135.9354248046875, 'rgb.min=', -225.92353820800781)
('rgb.max=', 136.17684936523438, 'rgb.min=', -225.94956970214844)
('rgb.max=', 135.87725830078125, 'rgb.min=', -225.93283081054688)
('rgb.max=', 135.7803955078125, 'rgb.min=', -226.02680969238281)
('rgb.max=', 136.09658813476562, 'rgb.min=', -226.05308532714844)
('rgb.max=', 136.09449768066406, 'rgb.min=', -226.25555419921875)
('rgb.max=', 135.87149047851562, 'rgb.min=', -226.07479858398438)
('rgb.max=', 136.07099914550781, 'rgb.min=', -225.92926025390625)
('rgb.max=', 135.76300048828125, 'rgb.min=', -225.95494079589844)
('rgb.max=', 135.96519470214844, 'rgb.min=', -226.26507568359375)
('rgb.max=', 135.69462585449219, 'rgb.min=', -226.03337097167969)
('rgb.max=', 135.96443176269531, 'rgb.min=', -225.96101379394531)
('rgb.max=', 135.77754211425781, 'rgb.min=', -226.25592041015625)
('rgb.max=', 135.79957580566406, 'rgb.min=', -226.36320495605469)
('rgb.max=', 135.74331665039062, 'rgb.min=', -225.87356567382812)
('rgb.max=', 135.75515747070312, 'rgb.min=', -226.00248718261719)
('rgb.max=', 136.19656372070312, 'rgb.min=', -226.00428771972656)
('rgb.max=', 135.94451904296875, 'rgb.min=', -226.00663757324219)
('rgb.max=', 135.98052978515625, 'rgb.min=', -226.42485046386719)
('rgb.max=', 135.77630615234375, 'rgb.min=', -226.14002990722656)
('rgb.max=', 135.94218444824219, 'rgb.min=', -226.00135803222656)
('rgb.max=', 135.88652038574219, 'rgb.min=', -226.18942260742188)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.88961791992188)
('rgb.max=', 136.0443115234375, 'rgb.min=', -225.97125244140625)
('rgb.max=', 135.90777587890625, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.90017700195312, 'rgb.min=', -225.91313171386719)
('rgb.max=', 136.25393676757812, 'rgb.min=', -226.03433227539062)
('rgb.max=', 135.94595336914062, 'rgb.min=', -226.08073425292969)
('rgb.max=', 135.98095703125, 'rgb.min=', -226.15322875976562)
('rgb.max=', 136.229248046875, 'rgb.min=', -225.99385070800781)
('rgb.max=', 136.03848266601562, 'rgb.min=', -225.9542236328125)
('rgb.max=', 136.08425903320312, 'rgb.min=', -226.02168273925781)
('rgb.max=', 136.23936462402344, 'rgb.min=', -225.89338684082031)
('rgb.max=', 135.955810546875, 'rgb.min=', -225.79486083984375)
('rgb.max=', 136.10874938964844, 'rgb.min=', -225.926025390625)
('rgb.max=', 135.85568237304688, 'rgb.min=', -226.05679321289062)
('rgb.max=', 135.82872009277344, 'rgb.min=', -226.36796569824219)
('rgb.max=', 135.6334228515625, 'rgb.min=', -225.99569702148438)
('rgb.max=', 136.02821350097656, 'rgb.min=', -225.95426940917969)
('rgb.max=', 135.78889465332031, 'rgb.min=', -225.86077880859375)
('rgb.max=', 136.05050659179688, 'rgb.min=', -225.89399719238281)
('rgb.max=', 136.16403198242188, 'rgb.min=', -226.0152587890625)
('rgb.max=', 136.40530395507812, 'rgb.min=', -226.02423095703125)
('rgb.max=', 135.81062316894531, 'rgb.min=', -225.86888122558594)
('rgb.max=', 135.87847900390625, 'rgb.min=', -225.93336486816406)
('rgb.max=', 135.8099365234375, 'rgb.min=', -225.79537963867188)
('rgb.max=', 135.97590637207031, 'rgb.min=', -226.14083862304688)
('rgb.max=', 135.82551574707031, 'rgb.min=', -225.82331848144531)
('rgb.max=', 136.2550048828125, 'rgb.min=', -226.01248168945312)
('rgb.max=', 135.63462829589844, 'rgb.min=', -226.04966735839844)
('rgb.max=', 136.00639343261719, 'rgb.min=', -226.10746765136719)
('rgb.max=', 136.02589416503906, 'rgb.min=', -226.06349182128906)
('rgb.max=', 135.73776245117188, 'rgb.min=', -226.07579040527344)
('rgb.max=', 135.95697021484375, 'rgb.min=', -225.9730224609375)
('rgb.max=', 136.20684814453125, 'rgb.min=', -225.94258117675781)
('rgb.max=', 136.0887451171875, 'rgb.min=', -225.82514953613281)
('rgb.max=', 135.71585083007812, 'rgb.min=', -226.14736938476562)
('rgb.max=', 135.859375, 'rgb.min=', -226.16903686523438)
('rgb.max=', 136.04866027832031, 'rgb.min=', -226.03448486328125)
('rgb.max=', 135.82977294921875, 'rgb.min=', -226.0479736328125)
('rgb.max=', 136.06172180175781, 'rgb.min=', -226.095703125)
('rgb.max=', 135.8914794921875, 'rgb.min=', -225.9854736328125)
('rgb.max=', 136.23460388183594, 'rgb.min=', -225.9730224609375)
('rgb.max=', 135.72784423828125, 'rgb.min=', -226.13226318359375)
('rgb.max=', 136.1923828125, 'rgb.min=', -225.96896362304688)
('rgb.max=', 135.95849609375, 'rgb.min=', -226.08262634277344)
('rgb.max=', 136.20724487304688, 'rgb.min=', -225.8780517578125)
('rgb.max=', 135.87911987304688, 'rgb.min=', -225.86891174316406)
('rgb.max=', 136.1435546875, 'rgb.min=', -226.16804504394531)
('rgb.max=', 136.12631225585938, 'rgb.min=', -226.09092712402344)
('rgb.max=', 136.24974060058594, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.81455993652344, 'rgb.min=', -225.89256286621094)
('rgb.max=', 136.06686401367188, 'rgb.min=', -226.07928466796875)
('rgb.max=', 136.10662841796875, 'rgb.min=', -226.18055725097656)
('rgb.max=', 136.1339111328125, 'rgb.min=', -226.04988098144531)
('rgb.max=', 135.859619140625, 'rgb.min=', -225.97564697265625)
('rgb.max=', 135.85017395019531, 'rgb.min=', -225.82492065429688)
('rgb.max=', 136.10391235351562, 'rgb.min=', -225.95603942871094)
('rgb.max=', 136.01307678222656, 'rgb.min=', -226.06968688964844)
('rgb.max=', 135.76412963867188, 'rgb.min=', -226.22984313964844)
('rgb.max=', 135.77191162109375, 'rgb.min=', -225.80929565429688)
('rgb.max=', 135.84745788574219, 'rgb.min=', -225.97264099121094)
('rgb.max=', 135.91815185546875, 'rgb.min=', -226.08953857421875)
('rgb.max=', 135.93780517578125, 'rgb.min=', -226.03385925292969)
('rgb.max=', 135.69903564453125, 'rgb.min=', -225.9298095703125)
('rgb.max=', 136.22256469726562, 'rgb.min=', -226.00108337402344)
('rgb.max=', 136.15591430664062, 'rgb.min=', -226.00053405761719)
('rgb.max=', 135.98365783691406, 'rgb.min=', -226.10423278808594)
('rgb.max=', 135.72203063964844, 'rgb.min=', -226.05178833007812)
('rgb.max=', 136.20034790039062, 'rgb.min=', -225.99436950683594)
('rgb.max=', 136.21670532226562, 'rgb.min=', -225.96611022949219)
('rgb.max=', 135.86241149902344, 'rgb.min=', -225.96211242675781)
('rgb.max=', 136.23672485351562, 'rgb.min=', -226.11201477050781)
('rgb.max=', 136.12042236328125, 'rgb.min=', -226.05186462402344)
('rgb.max=', 136.0025634765625, 'rgb.min=', -225.98399353027344)
('rgb.max=', 136.03022766113281, 'rgb.min=', -226.02810668945312)
('rgb.max=', 136.15101623535156, 'rgb.min=', -226.06210327148438)
('rgb.max=', 136.08877563476562, 'rgb.min=', -226.07167053222656)
('rgb.max=', 135.7747802734375, 'rgb.min=', -226.03341674804688)
('rgb.max=', 135.74037170410156, 'rgb.min=', -225.97579956054688)
('rgb.max=', 135.76292419433594, 'rgb.min=', -225.90501403808594)
('rgb.max=', 135.85958862304688, 'rgb.min=', -226.25254821777344)
('rgb.max=', 136.02981567382812, 'rgb.min=', -226.03343200683594)
('rgb.max=', 135.96275329589844, 'rgb.min=', -225.93769836425781)
('rgb.max=', 136.18487548828125, 'rgb.min=', -226.01933288574219)
('rgb.max=', 136.34091186523438, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.94737243652344, 'rgb.min=', -226.06642150878906)
('rgb.max=', 135.8565673828125, 'rgb.min=', -225.97756958007812)
('rgb.max=', 135.88523864746094, 'rgb.min=', -225.97935485839844)
('rgb.max=', 136.30157470703125, 'rgb.min=', -225.79397583007812)
('rgb.max=', 136.19807434082031, 'rgb.min=', -226.05178833007812)
('rgb.max=', 136.03355407714844, 'rgb.min=', -226.34844970703125)
('rgb.max=', 135.62832641601562, 'rgb.min=', -225.86875915527344)
('rgb.max=', 135.99594116210938, 'rgb.min=', -225.832763671875)
('rgb.max=', 135.9156494140625, 'rgb.min=', -226.04336547851562)
('rgb.max=', 135.79605102539062, 'rgb.min=', -226.13729858398438)
('rgb.max=', 136.24099731445312, 'rgb.min=', -225.59112548828125)
('rgb.max=', 135.59796142578125, 'rgb.min=', -225.777587890625)
('rgb.max=', 136.241455078125, 'rgb.min=', -226.27220153808594)
('rgb.max=', 135.87265014648438, 'rgb.min=', -226.02821350097656)
('rgb.max=', 136.13189697265625, 'rgb.min=', -225.81509399414062)
('rgb.max=', 135.90679931640625, 'rgb.min=', -226.06291198730469)
('rgb.max=', 136.032958984375, 'rgb.min=', -225.925048828125)
('rgb.max=', 135.873779296875, 'rgb.min=', -226.21583557128906)
('rgb.max=', 135.98890686035156, 'rgb.min=', -225.89430236816406)
('rgb.max=', 136.0726318359375, 'rgb.min=', -226.02723693847656)
('rgb.max=', 135.92121887207031, 'rgb.min=', -226.15226745605469)
('rgb.max=', 136.06732177734375, 'rgb.min=', -226.17697143554688)
('rgb.max=', 135.80169677734375, 'rgb.min=', -225.81526184082031)
('rgb.max=', 136.26737976074219, 'rgb.min=', -225.81498718261719)
('rgb.max=', 136.01589965820312, 'rgb.min=', -225.748046875)
('rgb.max=', 136.03880310058594, 'rgb.min=', -225.92304992675781)
('rgb.max=', 135.82540893554688, 'rgb.min=', -226.12356567382812)
('rgb.max=', 135.97038269042969, 'rgb.min=', -225.84854125976562)
('rgb.max=', 136.1754150390625, 'rgb.min=', -226.05412292480469)
('rgb.max=', 135.98190307617188, 'rgb.min=', -225.82904052734375)
('rgb.max=', 136.01927185058594, 'rgb.min=', -225.83505249023438)
('rgb.max=', 136.15151977539062, 'rgb.min=', -225.91346740722656)
('rgb.max=', 135.89486694335938, 'rgb.min=', -225.96322631835938)
('rgb.max=', 135.93025207519531, 'rgb.min=', -226.15203857421875)
('rgb.max=', 135.68659973144531, 'rgb.min=', -225.91780090332031)
('rgb.max=', 135.87983703613281, 'rgb.min=', -225.932373046875)
('rgb.max=', 135.80552673339844, 'rgb.min=', -225.87208557128906)
('rgb.max=', 136.11235046386719, 'rgb.min=', -226.07208251953125)
('rgb.max=', 136.11653137207031, 'rgb.min=', -225.87199401855469)
('rgb.max=', 135.86325073242188, 'rgb.min=', -226.00480651855469)
('rgb.max=', 136.21969604492188, 'rgb.min=', -225.75462341308594)
('rgb.max=', 135.939453125, 'rgb.min=', -226.18954467773438)
('rgb.max=', 135.93385314941406, 'rgb.min=', -225.76470947265625)
('rgb.max=', 135.7176513671875, 'rgb.min=', -225.89509582519531)
('rgb.max=', 135.69200134277344, 'rgb.min=', -225.76670837402344)
('rgb.max=', 135.88034057617188, 'rgb.min=', -226.12745666503906)
('rgb.max=', 135.91497802734375, 'rgb.min=', -226.25624084472656)
('rgb.max=', 135.74362182617188, 'rgb.min=', -225.90255737304688)
('rgb.max=', 135.76542663574219, 'rgb.min=', -225.93486022949219)
('rgb.max=', 135.96209716796875, 'rgb.min=', -226.25091552734375)
('rgb.max=', 136.19631958007812, 'rgb.min=', -226.09516906738281)
('rgb.max=', 135.9674072265625, 'rgb.min=', -226.34709167480469)
('rgb.max=', 136.19413757324219, 'rgb.min=', -225.96903991699219)
('rgb.max=', 136.05178833007812, 'rgb.min=', -225.66766357421875)
('rgb.max=', 136.12586975097656, 'rgb.min=', -226.08599853515625)
('rgb.max=', 135.94076538085938, 'rgb.min=', -226.09683227539062)
('rgb.max=', 136.15753173828125, 'rgb.min=', -226.07858276367188)
('rgb.max=', 135.64903259277344, 'rgb.min=', -225.89326477050781)
('rgb.max=', 135.95843505859375, 'rgb.min=', -226.085693359375)
('rgb.max=', 136.05850219726562, 'rgb.min=', -225.94366455078125)
('rgb.max=', 136.15957641601562, 'rgb.min=', -225.84246826171875)
('rgb.max=', 136.01542663574219, 'rgb.min=', -226.32386779785156)
('rgb.max=', 135.83766174316406, 'rgb.min=', -225.82942199707031)
('rgb.max=', 135.92530822753906, 'rgb.min=', -225.81410217285156)
('rgb.max=', 135.66726684570312, 'rgb.min=', -226.28271484375)
('rgb.max=', 135.7125244140625, 'rgb.min=', -225.94148254394531)
('rgb.max=', 135.8544921875, 'rgb.min=', -226.20608520507812)
('rgb.max=', 135.88230895996094, 'rgb.min=', -225.89414978027344)
('rgb.max=', 135.91375732421875, 'rgb.min=', -225.99581909179688)
('rgb.max=', 135.99002075195312, 'rgb.min=', -226.12246704101562)
('rgb.max=', 136.00811767578125, 'rgb.min=', -225.88714599609375)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.305893')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6988 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5234', 'Total loss: 1.3949', 'for batch', 0)
('GAN loss 0.6971 ', 'GAN acc 0.5156', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5098', 'Total loss: 1.3917', 'for batch', 1)
('GAN loss 0.6966 ', 'GAN acc 0.4844', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5156', 'Total loss: 1.3911', 'for batch', 2)
('GAN loss 0.6870 ', 'GAN acc 0.5859', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3811', 'for batch', 3)
('GAN loss 0.6858 ', 'GAN acc 0.5781', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4473', 'Total loss: 1.3855', 'for batch', 4)
('GAN loss 0.6843 ', 'GAN acc 0.5664', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4766', 'Total loss: 1.3793', 'for batch', 5)
('GAN loss 0.6833 ', 'GAN acc 0.5898', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3782', 'for batch', 6)
('GAN loss 0.6863 ', 'GAN acc 0.5547', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5000', 'Total loss: 1.3793', 'for batch', 7)
('GAN loss 0.6811 ', 'GAN acc 0.5898', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5156', 'Total loss: 1.3748', 'for batch', 8)
('GAN loss 0.6778 ', 'GAN acc 0.6445', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5078', 'Total loss: 1.3750', 'for batch', 9)
('GAN loss 0.6887 ', 'GAN acc 0.5391', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4961', 'Total loss: 1.3844', 'for batch', 10)
('GAN loss 0.6921 ', 'GAN acc 0.5078', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4766', 'Total loss: 1.3909', 'for batch', 11)
('GAN loss 0.6885 ', 'GAN acc 0.5430', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4980', 'Total loss: 1.3824', 'for batch', 12)
('GAN loss 0.6934 ', 'GAN acc 0.5078', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4434', 'Total loss: 1.3954', 'for batch', 13)
('GAN loss 0.6903 ', 'GAN acc 0.5273', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4922', 'Total loss: 1.3875', 'for batch', 14)
('GAN loss 0.7077 ', 'GAN acc 0.4375', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4941', 'Total loss: 1.4048', 'for batch', 15)
('GAN loss 0.6976 ', 'GAN acc 0.4844', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5039', 'Total loss: 1.3922', 'for batch', 16)
('GAN loss 0.7029 ', 'GAN acc 0.4453', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.7049 ', 'GAN acc 0.4531', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5078', 'Total loss: 1.4000', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53191978)
('DISCRIMINATOR_Imagem FAKE=', 0.53214109)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.11370849609375, 'rgb.min=', -226.01744079589844)
('rgb.max=', 135.92951965332031, 'rgb.min=', -226.07844543457031)
('rgb.max=', 136.11125183105469, 'rgb.min=', -225.93974304199219)
('rgb.max=', 135.98426818847656, 'rgb.min=', -226.05816650390625)
('rgb.max=', 136.150390625, 'rgb.min=', -225.93778991699219)
('rgb.max=', 136.22618103027344, 'rgb.min=', -226.48631286621094)
('rgb.max=', 135.84745788574219, 'rgb.min=', -226.20314025878906)
('rgb.max=', 135.93406677246094, 'rgb.min=', -225.95909118652344)
('rgb.max=', 135.86309814453125, 'rgb.min=', -226.15969848632812)
('rgb.max=', 135.8095703125, 'rgb.min=', -225.99351501464844)
('rgb.max=', 135.69981384277344, 'rgb.min=', -226.20135498046875)
('rgb.max=', 135.85165405273438, 'rgb.min=', -225.99977111816406)
('rgb.max=', 135.762939453125, 'rgb.min=', -226.04966735839844)
('rgb.max=', 135.948486328125, 'rgb.min=', -226.14817810058594)
('rgb.max=', 135.80775451660156, 'rgb.min=', -226.0255126953125)
('rgb.max=', 135.786376953125, 'rgb.min=', -226.01908874511719)
('rgb.max=', 135.8282470703125, 'rgb.min=', -225.92889404296875)
('rgb.max=', 135.91938781738281, 'rgb.min=', -225.80880737304688)
('rgb.max=', 135.91932678222656, 'rgb.min=', -226.16836547851562)
('rgb.max=', 135.97259521484375, 'rgb.min=', -226.42868041992188)
('rgb.max=', 136.09881591796875, 'rgb.min=', -225.98774719238281)
('rgb.max=', 136.12112426757812, 'rgb.min=', -225.92720031738281)
('rgb.max=', 136.08932495117188, 'rgb.min=', -225.80921936035156)
('rgb.max=', 135.96482849121094, 'rgb.min=', -226.00503540039062)
('rgb.max=', 135.7991943359375, 'rgb.min=', -225.95220947265625)
('rgb.max=', 136.08041381835938, 'rgb.min=', -225.95819091796875)
('rgb.max=', 136.133056640625, 'rgb.min=', -226.04017639160156)
('rgb.max=', 135.80986022949219, 'rgb.min=', -225.83306884765625)
('rgb.max=', 135.91069030761719, 'rgb.min=', -225.88571166992188)
('rgb.max=', 135.81954956054688, 'rgb.min=', -226.01174926757812)
('rgb.max=', 135.92501831054688, 'rgb.min=', -226.03858947753906)
('rgb.max=', 135.85981750488281, 'rgb.min=', -225.99983215332031)
('rgb.max=', 136.03265380859375, 'rgb.min=', -226.12309265136719)
('rgb.max=', 135.88810729980469, 'rgb.min=', -226.0328369140625)
('rgb.max=', 135.88232421875, 'rgb.min=', -225.99444580078125)
('rgb.max=', 136.080078125, 'rgb.min=', -225.96104431152344)
('rgb.max=', 136.16340637207031, 'rgb.min=', -226.00086975097656)
('rgb.max=', 136.0552978515625, 'rgb.min=', -226.07087707519531)
('rgb.max=', 135.98216247558594, 'rgb.min=', -226.11405944824219)
('rgb.max=', 135.97186279296875, 'rgb.min=', -226.10597229003906)
('rgb.max=', 135.72860717773438, 'rgb.min=', -225.92489624023438)
('rgb.max=', 135.9871826171875, 'rgb.min=', -226.17098999023438)
('rgb.max=', 135.91499328613281, 'rgb.min=', -226.07135009765625)
('rgb.max=', 135.92424011230469, 'rgb.min=', -225.92964172363281)
('rgb.max=', 135.90658569335938, 'rgb.min=', -226.471435546875)
('rgb.max=', 135.58087158203125, 'rgb.min=', -225.9334716796875)
('rgb.max=', 135.93643188476562, 'rgb.min=', -225.9970703125)
('rgb.max=', 135.70576477050781, 'rgb.min=', -225.89981079101562)
('rgb.max=', 135.82177734375, 'rgb.min=', -225.9820556640625)
('rgb.max=', 136.19256591796875, 'rgb.min=', -225.99855041503906)
('rgb.max=', 136.04335021972656, 'rgb.min=', -226.01902770996094)
('rgb.max=', 136.2685546875, 'rgb.min=', -225.98979187011719)
('rgb.max=', 135.67825317382812, 'rgb.min=', -226.01728820800781)
('rgb.max=', 135.84085083007812, 'rgb.min=', -225.90585327148438)
('rgb.max=', 136.03976440429688, 'rgb.min=', -226.02957153320312)
('rgb.max=', 136.16940307617188, 'rgb.min=', -226.06973266601562)
('rgb.max=', 135.90397644042969, 'rgb.min=', -226.02194213867188)
('rgb.max=', 135.8221435546875, 'rgb.min=', -225.99729919433594)
('rgb.max=', 135.86004638671875, 'rgb.min=', -225.98089599609375)
('rgb.max=', 135.58419799804688, 'rgb.min=', -226.100830078125)
('rgb.max=', 135.94761657714844, 'rgb.min=', -226.09217834472656)
('rgb.max=', 135.75238037109375, 'rgb.min=', -225.9091796875)
('rgb.max=', 135.73074340820312, 'rgb.min=', -225.97738647460938)
('rgb.max=', 135.77621459960938, 'rgb.min=', -226.38174438476562)
('rgb.max=', 136.37403869628906, 'rgb.min=', -225.82463073730469)
('rgb.max=', 135.97433471679688, 'rgb.min=', -226.14405822753906)
('rgb.max=', 135.6680908203125, 'rgb.min=', -225.94163513183594)
('rgb.max=', 135.73590087890625, 'rgb.min=', -226.01153564453125)
('rgb.max=', 136.05674743652344, 'rgb.min=', -226.21633911132812)
('rgb.max=', 136.1458740234375, 'rgb.min=', -226.12928771972656)
('rgb.max=', 136.06661987304688, 'rgb.min=', -226.0008544921875)
('rgb.max=', 135.77001953125, 'rgb.min=', -226.04875183105469)
('rgb.max=', 135.90275573730469, 'rgb.min=', -226.28152465820312)
('rgb.max=', 135.96920776367188, 'rgb.min=', -226.13230895996094)
('rgb.max=', 135.90776062011719, 'rgb.min=', -225.95297241210938)
('rgb.max=', 136.07243347167969, 'rgb.min=', -226.07786560058594)
('rgb.max=', 136.25523376464844, 'rgb.min=', -226.03443908691406)
('rgb.max=', 136.0838623046875, 'rgb.min=', -226.05821228027344)
('rgb.max=', 135.77114868164062, 'rgb.min=', -226.09080505371094)
('rgb.max=', 135.94683837890625, 'rgb.min=', -225.89793395996094)
('rgb.max=', 136.09652709960938, 'rgb.min=', -225.94956970214844)
('rgb.max=', 135.82846069335938, 'rgb.min=', -225.89938354492188)
('rgb.max=', 135.76817321777344, 'rgb.min=', -226.00411987304688)
('rgb.max=', 136.00100708007812, 'rgb.min=', -226.06863403320312)
('rgb.max=', 136.02120971679688, 'rgb.min=', -226.19639587402344)
('rgb.max=', 135.87985229492188, 'rgb.min=', -226.06002807617188)
('rgb.max=', 136.01976013183594, 'rgb.min=', -225.92926025390625)
('rgb.max=', 135.7626953125, 'rgb.min=', -225.9591064453125)
('rgb.max=', 135.95858764648438, 'rgb.min=', -226.2784423828125)
('rgb.max=', 135.61241149902344, 'rgb.min=', -225.99050903320312)
('rgb.max=', 135.88345336914062, 'rgb.min=', -225.94833374023438)
('rgb.max=', 135.78775024414062, 'rgb.min=', -226.25151062011719)
('rgb.max=', 135.80990600585938, 'rgb.min=', -226.41693115234375)
('rgb.max=', 135.74659729003906, 'rgb.min=', -225.87437438964844)
('rgb.max=', 135.747314453125, 'rgb.min=', -225.95587158203125)
('rgb.max=', 136.11335754394531, 'rgb.min=', -226.00428771972656)
('rgb.max=', 135.87730407714844, 'rgb.min=', -225.96502685546875)
('rgb.max=', 135.9307861328125, 'rgb.min=', -226.46453857421875)
('rgb.max=', 135.78121948242188, 'rgb.min=', -226.11019897460938)
('rgb.max=', 135.94538879394531, 'rgb.min=', -225.96609497070312)
('rgb.max=', 135.87669372558594, 'rgb.min=', -226.13542175292969)
('rgb.max=', 135.73733520507812, 'rgb.min=', -225.88270568847656)
('rgb.max=', 135.9554443359375, 'rgb.min=', -225.93023681640625)
('rgb.max=', 135.89927673339844, 'rgb.min=', -225.89199829101562)
('rgb.max=', 135.90870666503906, 'rgb.min=', -225.85513305664062)
('rgb.max=', 136.15274047851562, 'rgb.min=', -226.01547241210938)
('rgb.max=', 135.93321228027344, 'rgb.min=', -226.07147216796875)
('rgb.max=', 135.9544677734375, 'rgb.min=', -226.12301635742188)
('rgb.max=', 136.1268310546875, 'rgb.min=', -226.01589965820312)
('rgb.max=', 135.95523071289062, 'rgb.min=', -225.9161376953125)
('rgb.max=', 136.00752258300781, 'rgb.min=', -226.03878784179688)
('rgb.max=', 136.12142944335938, 'rgb.min=', -225.90260314941406)
('rgb.max=', 135.93019104003906, 'rgb.min=', -225.80635070800781)
('rgb.max=', 136.01730346679688, 'rgb.min=', -225.88081359863281)
('rgb.max=', 135.86050415039062, 'rgb.min=', -226.00149536132812)
('rgb.max=', 135.85006713867188, 'rgb.min=', -226.4049072265625)
('rgb.max=', 135.63916015625, 'rgb.min=', -226.01904296875)
('rgb.max=', 135.93658447265625, 'rgb.min=', -225.91743469238281)
('rgb.max=', 135.79408264160156, 'rgb.min=', -225.88845825195312)
('rgb.max=', 135.98698425292969, 'rgb.min=', -225.83332824707031)
('rgb.max=', 136.07635498046875, 'rgb.min=', -226.02188110351562)
('rgb.max=', 136.31570434570312, 'rgb.min=', -226.04859924316406)
('rgb.max=', 135.811279296875, 'rgb.min=', -225.8695068359375)
('rgb.max=', 135.88621520996094, 'rgb.min=', -225.91851806640625)
('rgb.max=', 135.78530883789062, 'rgb.min=', -225.80134582519531)
('rgb.max=', 135.90415954589844, 'rgb.min=', -226.13504028320312)
('rgb.max=', 135.84275817871094, 'rgb.min=', -225.79107666015625)
('rgb.max=', 136.18380737304688, 'rgb.min=', -225.99287414550781)
('rgb.max=', 135.63604736328125, 'rgb.min=', -226.04794311523438)
('rgb.max=', 135.97361755371094, 'rgb.min=', -226.07426452636719)
('rgb.max=', 136.00128173828125, 'rgb.min=', -226.05641174316406)
('rgb.max=', 135.75074768066406, 'rgb.min=', -226.06082153320312)
('rgb.max=', 135.94187927246094, 'rgb.min=', -225.919189453125)
('rgb.max=', 136.10797119140625, 'rgb.min=', -225.94258117675781)
('rgb.max=', 135.98481750488281, 'rgb.min=', -225.78628540039062)
('rgb.max=', 135.68743896484375, 'rgb.min=', -226.10755920410156)
('rgb.max=', 135.87033081054688, 'rgb.min=', -226.1826171875)
('rgb.max=', 135.96910095214844, 'rgb.min=', -226.03448486328125)
('rgb.max=', 135.81997680664062, 'rgb.min=', -226.01382446289062)
('rgb.max=', 135.97174072265625, 'rgb.min=', -226.07615661621094)
('rgb.max=', 135.857421875, 'rgb.min=', -225.93772888183594)
('rgb.max=', 136.15151977539062, 'rgb.min=', -225.9730224609375)
('rgb.max=', 135.72927856445312, 'rgb.min=', -226.12516784667969)
('rgb.max=', 136.14370727539062, 'rgb.min=', -225.90444946289062)
('rgb.max=', 135.94815063476562, 'rgb.min=', -226.04679870605469)
('rgb.max=', 136.11015319824219, 'rgb.min=', -225.77767944335938)
('rgb.max=', 135.87814331054688, 'rgb.min=', -225.81617736816406)
('rgb.max=', 136.05859375, 'rgb.min=', -226.14022827148438)
('rgb.max=', 136.05422973632812, 'rgb.min=', -226.08595275878906)
('rgb.max=', 136.16719055175781, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.81692504882812, 'rgb.min=', -225.80670166015625)
('rgb.max=', 135.97451782226562, 'rgb.min=', -226.07928466796875)
('rgb.max=', 136.02288818359375, 'rgb.min=', -226.17279052734375)
('rgb.max=', 136.05686950683594, 'rgb.min=', -226.03445434570312)
('rgb.max=', 135.87799072265625, 'rgb.min=', -225.94363403320312)
('rgb.max=', 135.86038208007812, 'rgb.min=', -225.78350830078125)
('rgb.max=', 136.08866882324219, 'rgb.min=', -226.03236389160156)
('rgb.max=', 135.92474365234375, 'rgb.min=', -226.0289306640625)
('rgb.max=', 135.77415466308594, 'rgb.min=', -226.23468017578125)
('rgb.max=', 135.70571899414062, 'rgb.min=', -225.78045654296875)
('rgb.max=', 135.8541259765625, 'rgb.min=', -225.8909912109375)
('rgb.max=', 135.92422485351562, 'rgb.min=', -226.07931518554688)
('rgb.max=', 135.916748046875, 'rgb.min=', -225.99234008789062)
('rgb.max=', 135.70712280273438, 'rgb.min=', -225.88795471191406)
('rgb.max=', 136.16622924804688, 'rgb.min=', -226.00770568847656)
('rgb.max=', 136.07382202148438, 'rgb.min=', -226.00053405761719)
('rgb.max=', 136.002685546875, 'rgb.min=', -226.07672119140625)
('rgb.max=', 135.70040893554688, 'rgb.min=', -226.02131652832031)
('rgb.max=', 136.11947631835938, 'rgb.min=', -226.1038818359375)
('rgb.max=', 136.1336669921875, 'rgb.min=', -226.01596069335938)
('rgb.max=', 135.79244995117188, 'rgb.min=', -225.97001647949219)
('rgb.max=', 136.14556884765625, 'rgb.min=', -226.07560729980469)
('rgb.max=', 136.03652954101562, 'rgb.min=', -226.05186462402344)
('rgb.max=', 135.94296264648438, 'rgb.min=', -225.94096374511719)
('rgb.max=', 135.94598388671875, 'rgb.min=', -226.04208374023438)
('rgb.max=', 136.03961181640625, 'rgb.min=', -226.13218688964844)
('rgb.max=', 136.03414916992188, 'rgb.min=', -226.09458923339844)
('rgb.max=', 135.78118896484375, 'rgb.min=', -225.95137023925781)
('rgb.max=', 135.7437744140625, 'rgb.min=', -225.95233154296875)
('rgb.max=', 135.76217651367188, 'rgb.min=', -225.84965515136719)
('rgb.max=', 135.90452575683594, 'rgb.min=', -226.22529602050781)
('rgb.max=', 136.05003356933594, 'rgb.min=', -226.01385498046875)
('rgb.max=', 135.96351623535156, 'rgb.min=', -225.96551513671875)
('rgb.max=', 136.16970825195312, 'rgb.min=', -226.01933288574219)
('rgb.max=', 136.27586364746094, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.94755554199219, 'rgb.min=', -226.03367614746094)
('rgb.max=', 135.86663818359375, 'rgb.min=', -225.92794799804688)
('rgb.max=', 135.89141845703125, 'rgb.min=', -225.96377563476562)
('rgb.max=', 136.20892333984375, 'rgb.min=', -225.7247314453125)
('rgb.max=', 136.1224365234375, 'rgb.min=', -226.05178833007812)
('rgb.max=', 135.98118591308594, 'rgb.min=', -226.37928771972656)
('rgb.max=', 135.57391357421875, 'rgb.min=', -225.81394958496094)
('rgb.max=', 135.92483520507812, 'rgb.min=', -225.78231811523438)
('rgb.max=', 135.920654296875, 'rgb.min=', -226.01824951171875)
('rgb.max=', 135.79095458984375, 'rgb.min=', -226.10783386230469)
('rgb.max=', 136.13658142089844, 'rgb.min=', -225.67008972167969)
('rgb.max=', 135.58319091796875, 'rgb.min=', -225.80088806152344)
('rgb.max=', 136.14195251464844, 'rgb.min=', -226.28683471679688)
('rgb.max=', 135.86537170410156, 'rgb.min=', -225.98919677734375)
('rgb.max=', 136.04324340820312, 'rgb.min=', -225.78730773925781)
('rgb.max=', 135.91390991210938, 'rgb.min=', -226.06098937988281)
('rgb.max=', 136.0302734375, 'rgb.min=', -225.97038269042969)
('rgb.max=', 135.88351440429688, 'rgb.min=', -226.19575500488281)
('rgb.max=', 135.93080139160156, 'rgb.min=', -225.8736572265625)
('rgb.max=', 135.97869873046875, 'rgb.min=', -226.05091857910156)
('rgb.max=', 135.93174743652344, 'rgb.min=', -226.12197875976562)
('rgb.max=', 136.01438903808594, 'rgb.min=', -226.14199829101562)
('rgb.max=', 135.79011535644531, 'rgb.min=', -225.85002136230469)
('rgb.max=', 136.17831420898438, 'rgb.min=', -225.81634521484375)
('rgb.max=', 136.01750183105469, 'rgb.min=', -225.77609252929688)
('rgb.max=', 135.96737670898438, 'rgb.min=', -225.88859558105469)
('rgb.max=', 135.846923828125, 'rgb.min=', -226.09156799316406)
('rgb.max=', 135.88674926757812, 'rgb.min=', -225.86399841308594)
('rgb.max=', 136.0850830078125, 'rgb.min=', -226.0450439453125)
('rgb.max=', 135.91326904296875, 'rgb.min=', -225.7979736328125)
('rgb.max=', 135.99319458007812, 'rgb.min=', -225.87855529785156)
('rgb.max=', 136.06718444824219, 'rgb.min=', -225.89834594726562)
('rgb.max=', 135.87229919433594, 'rgb.min=', -225.93865966796875)
('rgb.max=', 135.90724182128906, 'rgb.min=', -226.15496826171875)
('rgb.max=', 135.6888427734375, 'rgb.min=', -225.91552734375)
('rgb.max=', 135.87336730957031, 'rgb.min=', -225.89350891113281)
('rgb.max=', 135.81349182128906, 'rgb.min=', -225.87776184082031)
('rgb.max=', 136.04266357421875, 'rgb.min=', -226.0621337890625)
('rgb.max=', 136.02743530273438, 'rgb.min=', -225.87078857421875)
('rgb.max=', 135.87049865722656, 'rgb.min=', -226.00584411621094)
('rgb.max=', 136.12870788574219, 'rgb.min=', -225.7239990234375)
('rgb.max=', 135.94621276855469, 'rgb.min=', -226.15882873535156)
('rgb.max=', 135.89407348632812, 'rgb.min=', -225.77397155761719)
('rgb.max=', 135.72428894042969, 'rgb.min=', -225.91517639160156)
('rgb.max=', 135.63584899902344, 'rgb.min=', -225.80555725097656)
('rgb.max=', 135.87835693359375, 'rgb.min=', -226.14297485351562)
('rgb.max=', 135.92683410644531, 'rgb.min=', -226.21769714355469)
('rgb.max=', 135.67315673828125, 'rgb.min=', -225.90814208984375)
('rgb.max=', 135.76058959960938, 'rgb.min=', -225.94172668457031)
('rgb.max=', 135.96331787109375, 'rgb.min=', -226.21084594726562)
('rgb.max=', 136.10720825195312, 'rgb.min=', -226.10011291503906)
('rgb.max=', 135.9205322265625, 'rgb.min=', -226.32322692871094)
('rgb.max=', 136.11073303222656, 'rgb.min=', -225.97076416015625)
('rgb.max=', 136.04351806640625, 'rgb.min=', -225.6519775390625)
('rgb.max=', 136.02951049804688, 'rgb.min=', -226.08808898925781)
('rgb.max=', 135.93385314941406, 'rgb.min=', -226.066650390625)
('rgb.max=', 136.06813049316406, 'rgb.min=', -226.05995178222656)
('rgb.max=', 135.64288330078125, 'rgb.min=', -225.90257263183594)
('rgb.max=', 135.892822265625, 'rgb.min=', -226.08172607421875)
('rgb.max=', 135.95033264160156, 'rgb.min=', -225.94354248046875)
('rgb.max=', 136.06878662109375, 'rgb.min=', -225.86344909667969)
('rgb.max=', 136.02812194824219, 'rgb.min=', -226.28640747070312)
('rgb.max=', 135.79264831542969, 'rgb.min=', -225.86685180664062)
('rgb.max=', 135.90736389160156, 'rgb.min=', -225.84625244140625)
('rgb.max=', 135.67857360839844, 'rgb.min=', -226.26275634765625)
('rgb.max=', 135.71353149414062, 'rgb.min=', -225.93508911132812)
('rgb.max=', 135.85786437988281, 'rgb.min=', -226.1673583984375)
('rgb.max=', 135.89030456542969, 'rgb.min=', -225.86094665527344)
('rgb.max=', 135.90289306640625, 'rgb.min=', -225.98454284667969)
('rgb.max=', 135.99482727050781, 'rgb.min=', -226.091796875)
('rgb.max=', 135.94734191894531, 'rgb.min=', -225.9334716796875)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.752904')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7002 ', 'GAN acc 0.4492', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4727', 'Total loss: 1.3977', 'for batch', 0)
('GAN loss 0.7008 ', 'GAN acc 0.4766', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4766', 'Total loss: 1.3983', 'for batch', 1)
('GAN loss 0.6963 ', 'GAN acc 0.4883', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4961', 'Total loss: 1.3922', 'for batch', 2)
('GAN loss 0.7000 ', 'GAN acc 0.4102', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5332', 'Total loss: 1.3916', 'for batch', 3)
('GAN loss 0.6927 ', 'GAN acc 0.5312', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4922', 'Total loss: 1.3887', 'for batch', 4)
('GAN loss 0.6861 ', 'GAN acc 0.5508', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4512', 'Total loss: 1.3824', 'for batch', 5)
('GAN loss 0.6814 ', 'GAN acc 0.5898', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4961', 'Total loss: 1.3758', 'for batch', 6)
('GAN loss 0.6826 ', 'GAN acc 0.6133', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3761', 'for batch', 7)
('GAN loss 0.6753 ', 'GAN acc 0.6250', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4961', 'Total loss: 1.3703', 'for batch', 8)
('GAN loss 0.6797 ', 'GAN acc 0.6172', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5020', 'Total loss: 1.3752', 'for batch', 9)
('GAN loss 0.6851 ', 'GAN acc 0.5664', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4531', 'Total loss: 1.3835', 'for batch', 10)
('GAN loss 0.6855 ', 'GAN acc 0.5664', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5039', 'Total loss: 1.3771', 'for batch', 11)
('GAN loss 0.6883 ', 'GAN acc 0.5273', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4746', 'Total loss: 1.3836', 'for batch', 12)
('GAN loss 0.6884 ', 'GAN acc 0.5664', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5352', 'Total loss: 1.3799', 'for batch', 13)
('GAN loss 0.6890 ', 'GAN acc 0.5547', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5234', 'Total loss: 1.3821', 'for batch', 14)
('GAN loss 0.6963 ', 'GAN acc 0.4922', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4824', 'Total loss: 1.3923', 'for batch', 15)
('GAN loss 0.6998 ', 'GAN acc 0.4688', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4805', 'Total loss: 1.3975', 'for batch', 16)
('GAN loss 0.7032 ', 'GAN acc 0.4453', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4941', 'Total loss: 1.4011', 'for batch', 17)
('GAN loss 0.7066 ', 'GAN acc 0.4062', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4727', 'Total loss: 1.4020', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52713794)
('DISCRIMINATOR_Imagem FAKE=', 0.52772814)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.08909606933594, 'rgb.min=', -225.94699096679688)
('rgb.max=', 135.92532348632812, 'rgb.min=', -226.04533386230469)
('rgb.max=', 136.18167114257812, 'rgb.min=', -225.96537780761719)
('rgb.max=', 135.9967041015625, 'rgb.min=', -226.07110595703125)
('rgb.max=', 136.15386962890625, 'rgb.min=', -225.90216064453125)
('rgb.max=', 136.2164306640625, 'rgb.min=', -226.36187744140625)
('rgb.max=', 135.84600830078125, 'rgb.min=', -226.16522216796875)
('rgb.max=', 135.96099853515625, 'rgb.min=', -225.93550109863281)
('rgb.max=', 135.86163330078125, 'rgb.min=', -226.15621948242188)
('rgb.max=', 135.80082702636719, 'rgb.min=', -226.0079345703125)
('rgb.max=', 135.70066833496094, 'rgb.min=', -226.183349609375)
('rgb.max=', 135.85345458984375, 'rgb.min=', -225.99449157714844)
('rgb.max=', 135.7850341796875, 'rgb.min=', -226.04595947265625)
('rgb.max=', 135.94972229003906, 'rgb.min=', -226.11189270019531)
('rgb.max=', 135.80706787109375, 'rgb.min=', -225.98735046386719)
('rgb.max=', 135.788330078125, 'rgb.min=', -226.02259826660156)
('rgb.max=', 135.82716369628906, 'rgb.min=', -225.92051696777344)
('rgb.max=', 135.91957092285156, 'rgb.min=', -225.86058044433594)
('rgb.max=', 135.92735290527344, 'rgb.min=', -226.11949157714844)
('rgb.max=', 135.978271484375, 'rgb.min=', -226.33334350585938)
('rgb.max=', 136.08807373046875, 'rgb.min=', -225.98774719238281)
('rgb.max=', 136.20460510253906, 'rgb.min=', -225.90966796875)
('rgb.max=', 136.1123046875, 'rgb.min=', -225.81048583984375)
('rgb.max=', 135.9639892578125, 'rgb.min=', -225.96299743652344)
('rgb.max=', 135.78494262695312, 'rgb.min=', -225.95046997070312)
('rgb.max=', 136.15348815917969, 'rgb.min=', -225.975341796875)
('rgb.max=', 136.14662170410156, 'rgb.min=', -226.05059814453125)
('rgb.max=', 135.82168579101562, 'rgb.min=', -225.87220764160156)
('rgb.max=', 135.91989135742188, 'rgb.min=', -225.90571594238281)
('rgb.max=', 135.83786010742188, 'rgb.min=', -225.998046875)
('rgb.max=', 135.90899658203125, 'rgb.min=', -226.08392333984375)
('rgb.max=', 135.86264038085938, 'rgb.min=', -225.96185302734375)
('rgb.max=', 136.03073120117188, 'rgb.min=', -226.11312866210938)
('rgb.max=', 135.88841247558594, 'rgb.min=', -226.05581665039062)
('rgb.max=', 135.88528442382812, 'rgb.min=', -225.95930480957031)
('rgb.max=', 136.16117858886719, 'rgb.min=', -225.9420166015625)
('rgb.max=', 136.14797973632812, 'rgb.min=', -225.90571594238281)
('rgb.max=', 136.13214111328125, 'rgb.min=', -226.07456970214844)
('rgb.max=', 135.98745727539062, 'rgb.min=', -226.0726318359375)
('rgb.max=', 135.97926330566406, 'rgb.min=', -226.060546875)
('rgb.max=', 135.72184753417969, 'rgb.min=', -225.95597839355469)
('rgb.max=', 135.98159790039062, 'rgb.min=', -226.18101501464844)
('rgb.max=', 135.91049194335938, 'rgb.min=', -226.03681945800781)
('rgb.max=', 135.9189453125, 'rgb.min=', -225.89639282226562)
('rgb.max=', 135.96199035644531, 'rgb.min=', -226.41365051269531)
('rgb.max=', 135.60324096679688, 'rgb.min=', -225.96324157714844)
('rgb.max=', 135.95132446289062, 'rgb.min=', -225.96041870117188)
('rgb.max=', 135.72312927246094, 'rgb.min=', -225.92832946777344)
('rgb.max=', 135.86505126953125, 'rgb.min=', -225.95999145507812)
('rgb.max=', 136.1732177734375, 'rgb.min=', -226.08071899414062)
('rgb.max=', 136.03401184082031, 'rgb.min=', -226.03179931640625)
('rgb.max=', 136.26168823242188, 'rgb.min=', -225.97190856933594)
('rgb.max=', 135.703857421875, 'rgb.min=', -226.04995727539062)
('rgb.max=', 135.82814025878906, 'rgb.min=', -225.91954040527344)
('rgb.max=', 136.04116821289062, 'rgb.min=', -226.00856018066406)
('rgb.max=', 136.15779113769531, 'rgb.min=', -226.06341552734375)
('rgb.max=', 135.897216796875, 'rgb.min=', -226.00106811523438)
('rgb.max=', 135.82968139648438, 'rgb.min=', -226.02572631835938)
('rgb.max=', 135.85420227050781, 'rgb.min=', -225.97279357910156)
('rgb.max=', 135.58132934570312, 'rgb.min=', -226.07708740234375)
('rgb.max=', 135.9228515625, 'rgb.min=', -226.13890075683594)
('rgb.max=', 135.74954223632812, 'rgb.min=', -225.90272521972656)
('rgb.max=', 135.72956848144531, 'rgb.min=', -226.03880310058594)
('rgb.max=', 135.77369689941406, 'rgb.min=', -226.32235717773438)
('rgb.max=', 136.39222717285156, 'rgb.min=', -225.81991577148438)
('rgb.max=', 135.9837646484375, 'rgb.min=', -226.16740417480469)
('rgb.max=', 135.671875, 'rgb.min=', -225.96269226074219)
('rgb.max=', 135.72544860839844, 'rgb.min=', -226.03207397460938)
('rgb.max=', 136.064453125, 'rgb.min=', -226.17048645019531)
('rgb.max=', 136.12677001953125, 'rgb.min=', -226.05070495605469)
('rgb.max=', 136.03662109375, 'rgb.min=', -226.06272888183594)
('rgb.max=', 135.77711486816406, 'rgb.min=', -226.05422973632812)
('rgb.max=', 135.90921020507812, 'rgb.min=', -226.25959777832031)
('rgb.max=', 135.97885131835938, 'rgb.min=', -226.12802124023438)
('rgb.max=', 135.90785217285156, 'rgb.min=', -225.95167541503906)
('rgb.max=', 136.10031127929688, 'rgb.min=', -226.01649475097656)
('rgb.max=', 136.28611755371094, 'rgb.min=', -226.11973571777344)
('rgb.max=', 136.08029174804688, 'rgb.min=', -226.05821228027344)
('rgb.max=', 135.77568054199219, 'rgb.min=', -226.13243103027344)
('rgb.max=', 135.93502807617188, 'rgb.min=', -225.96627807617188)
('rgb.max=', 136.07452392578125, 'rgb.min=', -225.88368225097656)
('rgb.max=', 135.85780334472656, 'rgb.min=', -225.8956298828125)
('rgb.max=', 135.77633666992188, 'rgb.min=', -226.04386901855469)
('rgb.max=', 136.01118469238281, 'rgb.min=', -226.08116149902344)
('rgb.max=', 136.02435302734375, 'rgb.min=', -226.16818237304688)
('rgb.max=', 135.86996459960938, 'rgb.min=', -226.08448791503906)
('rgb.max=', 136.01673889160156, 'rgb.min=', -225.90280151367188)
('rgb.max=', 135.74929809570312, 'rgb.min=', -226.0008544921875)
('rgb.max=', 135.97364807128906, 'rgb.min=', -226.26052856445312)
('rgb.max=', 135.63839721679688, 'rgb.min=', -226.00898742675781)
('rgb.max=', 135.88243103027344, 'rgb.min=', -225.94825744628906)
('rgb.max=', 135.79330444335938, 'rgb.min=', -226.25177001953125)
('rgb.max=', 135.82029724121094, 'rgb.min=', -226.36775207519531)
('rgb.max=', 135.7376708984375, 'rgb.min=', -225.868896484375)
('rgb.max=', 135.75637817382812, 'rgb.min=', -225.99058532714844)
('rgb.max=', 136.11495971679688, 'rgb.min=', -226.00428771972656)
('rgb.max=', 135.87831115722656, 'rgb.min=', -225.98121643066406)
('rgb.max=', 135.97666931152344, 'rgb.min=', -226.41714477539062)
('rgb.max=', 135.77885437011719, 'rgb.min=', -226.11404418945312)
('rgb.max=', 135.94351196289062, 'rgb.min=', -225.97950744628906)
('rgb.max=', 135.8751220703125, 'rgb.min=', -226.09884643554688)
('rgb.max=', 135.73580932617188, 'rgb.min=', -225.88600158691406)
('rgb.max=', 135.95782470703125, 'rgb.min=', -225.88319396972656)
('rgb.max=', 135.90780639648438, 'rgb.min=', -225.95768737792969)
('rgb.max=', 135.90274047851562, 'rgb.min=', -225.86125183105469)
('rgb.max=', 136.14749145507812, 'rgb.min=', -226.05421447753906)
('rgb.max=', 135.96226501464844, 'rgb.min=', -226.09295654296875)
('rgb.max=', 135.97233581542969, 'rgb.min=', -226.11482238769531)
('rgb.max=', 136.10931396484375, 'rgb.min=', -226.00570678710938)
('rgb.max=', 135.95187377929688, 'rgb.min=', -225.89788818359375)
('rgb.max=', 135.97203063964844, 'rgb.min=', -225.97657775878906)
('rgb.max=', 136.15948486328125, 'rgb.min=', -225.89678955078125)
('rgb.max=', 135.94680786132812, 'rgb.min=', -225.77017211914062)
('rgb.max=', 135.99462890625, 'rgb.min=', -225.82427978515625)
('rgb.max=', 135.85963439941406, 'rgb.min=', -226.03118896484375)
('rgb.max=', 135.84527587890625, 'rgb.min=', -226.34974670410156)
('rgb.max=', 135.6431884765625, 'rgb.min=', -225.97718811035156)
('rgb.max=', 135.939697265625, 'rgb.min=', -225.864990234375)
('rgb.max=', 135.79327392578125, 'rgb.min=', -225.8626708984375)
('rgb.max=', 136.05526733398438, 'rgb.min=', -225.86273193359375)
('rgb.max=', 136.06826782226562, 'rgb.min=', -225.98796081542969)
('rgb.max=', 136.31088256835938, 'rgb.min=', -226.0518798828125)
('rgb.max=', 135.80401611328125, 'rgb.min=', -225.8673095703125)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.94766235351562)
('rgb.max=', 135.80804443359375, 'rgb.min=', -225.77632141113281)
('rgb.max=', 135.9359130859375, 'rgb.min=', -226.1275634765625)
('rgb.max=', 135.84458923339844, 'rgb.min=', -225.80313110351562)
('rgb.max=', 136.18118286132812, 'rgb.min=', -225.94061279296875)
('rgb.max=', 135.63018798828125, 'rgb.min=', -226.06398010253906)
('rgb.max=', 135.96566772460938, 'rgb.min=', -226.091064453125)
('rgb.max=', 136.07888793945312, 'rgb.min=', -225.99008178710938)
('rgb.max=', 135.73980712890625, 'rgb.min=', -226.06565856933594)
('rgb.max=', 135.95301818847656, 'rgb.min=', -225.90310668945312)
('rgb.max=', 136.12518310546875, 'rgb.min=', -225.92945861816406)
('rgb.max=', 135.97561645507812, 'rgb.min=', -225.78390502929688)
('rgb.max=', 135.68063354492188, 'rgb.min=', -226.09317016601562)
('rgb.max=', 135.86912536621094, 'rgb.min=', -226.17054748535156)
('rgb.max=', 135.96365356445312, 'rgb.min=', -226.02716064453125)
('rgb.max=', 135.82366943359375, 'rgb.min=', -226.01968383789062)
('rgb.max=', 135.96531677246094, 'rgb.min=', -226.02317810058594)
('rgb.max=', 135.87260437011719, 'rgb.min=', -225.88114929199219)
('rgb.max=', 136.1336669921875, 'rgb.min=', -225.9730224609375)
('rgb.max=', 135.73016357421875, 'rgb.min=', -226.1207275390625)
('rgb.max=', 136.18864440917969, 'rgb.min=', -225.97908020019531)
('rgb.max=', 135.97026062011719, 'rgb.min=', -226.05398559570312)
('rgb.max=', 136.19145202636719, 'rgb.min=', -225.80900573730469)
('rgb.max=', 135.884765625, 'rgb.min=', -225.86105346679688)
('rgb.max=', 136.10343933105469, 'rgb.min=', -226.07357788085938)
('rgb.max=', 136.13111877441406, 'rgb.min=', -226.06166076660156)
('rgb.max=', 136.15396118164062, 'rgb.min=', -225.96797180175781)
('rgb.max=', 135.80880737304688, 'rgb.min=', -225.82524108886719)
('rgb.max=', 135.96443176269531, 'rgb.min=', -226.02311706542969)
('rgb.max=', 136.01637268066406, 'rgb.min=', -226.12606811523438)
('rgb.max=', 136.05865478515625, 'rgb.min=', -226.05316162109375)
('rgb.max=', 135.87388610839844, 'rgb.min=', -225.98088073730469)
('rgb.max=', 135.86076354980469, 'rgb.min=', -225.82084655761719)
('rgb.max=', 136.1668701171875, 'rgb.min=', -226.00735473632812)
('rgb.max=', 135.92681884765625, 'rgb.min=', -225.98991394042969)
('rgb.max=', 135.77529907226562, 'rgb.min=', -226.23713684082031)
('rgb.max=', 135.702392578125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.85134887695312, 'rgb.min=', -225.92257690429688)
('rgb.max=', 135.93034362792969, 'rgb.min=', -226.08909606933594)
('rgb.max=', 135.91748046875, 'rgb.min=', -226.00511169433594)
('rgb.max=', 135.7099609375, 'rgb.min=', -225.91143798828125)
('rgb.max=', 136.19169616699219, 'rgb.min=', -225.98289489746094)
('rgb.max=', 136.06364440917969, 'rgb.min=', -226.00053405761719)
('rgb.max=', 136.00897216796875, 'rgb.min=', -226.06834411621094)
('rgb.max=', 135.68405151367188, 'rgb.min=', -226.04217529296875)
('rgb.max=', 136.12068176269531, 'rgb.min=', -226.06681823730469)
('rgb.max=', 136.1114501953125, 'rgb.min=', -225.99002075195312)
('rgb.max=', 135.79707336425781, 'rgb.min=', -225.97981262207031)
('rgb.max=', 136.12210083007812, 'rgb.min=', -226.11061096191406)
('rgb.max=', 136.02949523925781, 'rgb.min=', -226.05099487304688)
('rgb.max=', 135.96821594238281, 'rgb.min=', -225.92967224121094)
('rgb.max=', 135.94784545898438, 'rgb.min=', -226.02886962890625)
('rgb.max=', 136.1146240234375, 'rgb.min=', -226.11396789550781)
('rgb.max=', 136.05178833007812, 'rgb.min=', -226.02598571777344)
('rgb.max=', 135.79924011230469, 'rgb.min=', -226.02311706542969)
('rgb.max=', 135.74119567871094, 'rgb.min=', -225.99656677246094)
('rgb.max=', 135.75628662109375, 'rgb.min=', -225.88577270507812)
('rgb.max=', 135.91290283203125, 'rgb.min=', -226.25820922851562)
('rgb.max=', 136.06126403808594, 'rgb.min=', -226.05062866210938)
('rgb.max=', 135.96249389648438, 'rgb.min=', -225.93482971191406)
('rgb.max=', 136.15200805664062, 'rgb.min=', -225.9761962890625)
('rgb.max=', 136.2615966796875, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.93586730957031, 'rgb.min=', -226.10966491699219)
('rgb.max=', 135.86370849609375, 'rgb.min=', -225.94491577148438)
('rgb.max=', 135.88845825195312, 'rgb.min=', -226.02009582519531)
('rgb.max=', 136.1954345703125, 'rgb.min=', -225.61918640136719)
('rgb.max=', 136.08746337890625, 'rgb.min=', -226.04707336425781)
('rgb.max=', 136.04812622070312, 'rgb.min=', -226.33735656738281)
('rgb.max=', 135.5885009765625, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.92796325683594, 'rgb.min=', -225.75938415527344)
('rgb.max=', 135.91679382324219, 'rgb.min=', -226.02590942382812)
('rgb.max=', 135.79055786132812, 'rgb.min=', -226.109375)
('rgb.max=', 136.12481689453125, 'rgb.min=', -225.66213989257812)
('rgb.max=', 135.57562255859375, 'rgb.min=', -225.78956604003906)
('rgb.max=', 136.12652587890625, 'rgb.min=', -226.26333618164062)
('rgb.max=', 135.86146545410156, 'rgb.min=', -226.03680419921875)
('rgb.max=', 136.01611328125, 'rgb.min=', -225.78564453125)
('rgb.max=', 135.91494750976562, 'rgb.min=', -226.10020446777344)
('rgb.max=', 136.02531433105469, 'rgb.min=', -225.95762634277344)
('rgb.max=', 135.87620544433594, 'rgb.min=', -226.18586730957031)
('rgb.max=', 135.95086669921875, 'rgb.min=', -225.90229797363281)
('rgb.max=', 135.96432495117188, 'rgb.min=', -226.02973937988281)
('rgb.max=', 135.92381286621094, 'rgb.min=', -226.12222290039062)
('rgb.max=', 136.05868530273438, 'rgb.min=', -226.13743591308594)
('rgb.max=', 135.79356384277344, 'rgb.min=', -225.82090759277344)
('rgb.max=', 136.1474609375, 'rgb.min=', -225.81697082519531)
('rgb.max=', 136.00271606445312, 'rgb.min=', -225.75523376464844)
('rgb.max=', 136.03721618652344, 'rgb.min=', -225.91094970703125)
('rgb.max=', 135.83149719238281, 'rgb.min=', -226.09140014648438)
('rgb.max=', 135.88746643066406, 'rgb.min=', -225.85261535644531)
('rgb.max=', 136.08352661132812, 'rgb.min=', -226.01828002929688)
('rgb.max=', 135.88204956054688, 'rgb.min=', -225.76193237304688)
('rgb.max=', 135.99183654785156, 'rgb.min=', -225.86083984375)
('rgb.max=', 136.03729248046875, 'rgb.min=', -225.93745422363281)
('rgb.max=', 135.87351989746094, 'rgb.min=', -225.959228515625)
('rgb.max=', 135.92352294921875, 'rgb.min=', -226.1531982421875)
('rgb.max=', 135.686279296875, 'rgb.min=', -225.94073486328125)
('rgb.max=', 135.86888122558594, 'rgb.min=', -225.91659545898438)
('rgb.max=', 135.8052978515625, 'rgb.min=', -225.86016845703125)
('rgb.max=', 136.06318664550781, 'rgb.min=', -226.00813293457031)
('rgb.max=', 136.00146484375, 'rgb.min=', -225.90957641601562)
('rgb.max=', 135.860595703125, 'rgb.min=', -226.01560974121094)
('rgb.max=', 136.10569763183594, 'rgb.min=', -225.7550048828125)
('rgb.max=', 135.94952392578125, 'rgb.min=', -226.14176940917969)
('rgb.max=', 135.88833618164062, 'rgb.min=', -225.79408264160156)
('rgb.max=', 135.72616577148438, 'rgb.min=', -225.91041564941406)
('rgb.max=', 135.63053894042969, 'rgb.min=', -225.77886962890625)
('rgb.max=', 135.87167358398438, 'rgb.min=', -226.12124633789062)
('rgb.max=', 135.92242431640625, 'rgb.min=', -226.23129272460938)
('rgb.max=', 135.67306518554688, 'rgb.min=', -225.90158081054688)
('rgb.max=', 135.759521484375, 'rgb.min=', -225.9398193359375)
('rgb.max=', 135.96267700195312, 'rgb.min=', -226.20588684082031)
('rgb.max=', 136.16018676757812, 'rgb.min=', -226.12129211425781)
('rgb.max=', 135.94683837890625, 'rgb.min=', -226.31520080566406)
('rgb.max=', 136.11810302734375, 'rgb.min=', -225.97811889648438)
('rgb.max=', 136.03570556640625, 'rgb.min=', -225.61781311035156)
('rgb.max=', 136.08053588867188, 'rgb.min=', -226.07597351074219)
('rgb.max=', 135.951171875, 'rgb.min=', -226.07524108886719)
('rgb.max=', 136.05740356445312, 'rgb.min=', -226.058837890625)
('rgb.max=', 135.635009765625, 'rgb.min=', -225.92253112792969)
('rgb.max=', 135.94757080078125, 'rgb.min=', -226.07525634765625)
('rgb.max=', 136.00364685058594, 'rgb.min=', -225.93452453613281)
('rgb.max=', 136.13262939453125, 'rgb.min=', -225.84542846679688)
('rgb.max=', 136.01652526855469, 'rgb.min=', -226.23471069335938)
('rgb.max=', 135.78411865234375, 'rgb.min=', -225.84034729003906)
('rgb.max=', 135.9033203125, 'rgb.min=', -225.82672119140625)
('rgb.max=', 135.66740417480469, 'rgb.min=', -226.25910949707031)
('rgb.max=', 135.72093200683594, 'rgb.min=', -225.97195434570312)
('rgb.max=', 135.85659790039062, 'rgb.min=', -226.14340209960938)
('rgb.max=', 135.89273071289062, 'rgb.min=', -225.88345336914062)
('rgb.max=', 135.89620971679688, 'rgb.min=', -226.00515747070312)
('rgb.max=', 135.99726867675781, 'rgb.min=', -226.09553527832031)
('rgb.max=', 135.9483642578125, 'rgb.min=', -225.87152099609375)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.316289')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7046 ', 'GAN acc 0.3828', 'Discriminator loss 0.6897', 'Discriminator accuracy 0.5293', 'Total loss: 1.3943', 'for batch', 0)
('GAN loss 0.7031 ', 'GAN acc 0.4414', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4688', 'Total loss: 1.3983', 'for batch', 1)
('GAN loss 0.6987 ', 'GAN acc 0.4570', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4883', 'Total loss: 1.3959', 'for batch', 2)
('GAN loss 0.6950 ', 'GAN acc 0.5078', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5078', 'Total loss: 1.3875', 'for batch', 3)
('GAN loss 0.6904 ', 'GAN acc 0.5391', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4922', 'Total loss: 1.3862', 'for batch', 4)
('GAN loss 0.6881 ', 'GAN acc 0.5391', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5195', 'Total loss: 1.3816', 'for batch', 5)
('GAN loss 0.6876 ', 'GAN acc 0.5508', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5332', 'Total loss: 1.3781', 'for batch', 6)
('GAN loss 0.6838 ', 'GAN acc 0.5820', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5020', 'Total loss: 1.3808', 'for batch', 7)
('GAN loss 0.6844 ', 'GAN acc 0.5898', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4707', 'Total loss: 1.3806', 'for batch', 8)
('GAN loss 0.6785 ', 'GAN acc 0.6289', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4824', 'Total loss: 1.3761', 'for batch', 9)
('GAN loss 0.6788 ', 'GAN acc 0.6445', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5352', 'Total loss: 1.3690', 'for batch', 10)
('GAN loss 0.6881 ', 'GAN acc 0.5977', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4844', 'Total loss: 1.3843', 'for batch', 11)
('GAN loss 0.6859 ', 'GAN acc 0.5938', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4688', 'Total loss: 1.3847', 'for batch', 12)
('GAN loss 0.6867 ', 'GAN acc 0.5820', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4824', 'Total loss: 1.3835', 'for batch', 13)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5117', 'Total loss: 1.3886', 'for batch', 14)
('GAN loss 0.6938 ', 'GAN acc 0.5273', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5156', 'Total loss: 1.3869', 'for batch', 15)
('GAN loss 0.7003 ', 'GAN acc 0.4727', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5273', 'Total loss: 1.3947', 'for batch', 16)
('GAN loss 0.6986 ', 'GAN acc 0.4688', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4824', 'Total loss: 1.3920', 'for batch', 17)
('GAN loss 0.7024 ', 'GAN acc 0.4805', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4922', 'Total loss: 1.3968', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52463925)
('DISCRIMINATOR_Imagem FAKE=', 0.52475768)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.04071044921875, 'rgb.min=', -225.81468200683594)
('rgb.max=', 135.91766357421875, 'rgb.min=', -226.05113220214844)
('rgb.max=', 136.16255187988281, 'rgb.min=', -225.94085693359375)
('rgb.max=', 136.01275634765625, 'rgb.min=', -226.08251953125)
('rgb.max=', 136.14285278320312, 'rgb.min=', -225.93113708496094)
('rgb.max=', 136.18844604492188, 'rgb.min=', -226.416748046875)
('rgb.max=', 135.84402465820312, 'rgb.min=', -226.1710205078125)
('rgb.max=', 135.96694946289062, 'rgb.min=', -225.97749328613281)
('rgb.max=', 135.868408203125, 'rgb.min=', -226.17770385742188)
('rgb.max=', 135.79798889160156, 'rgb.min=', -226.01998901367188)
('rgb.max=', 135.7169189453125, 'rgb.min=', -226.18954467773438)
('rgb.max=', 135.85383605957031, 'rgb.min=', -226.03160095214844)
('rgb.max=', 135.78851318359375, 'rgb.min=', -226.04681396484375)
('rgb.max=', 135.92742919921875, 'rgb.min=', -226.14723205566406)
('rgb.max=', 135.80763244628906, 'rgb.min=', -226.05244445800781)
('rgb.max=', 135.78013610839844, 'rgb.min=', -226.06034851074219)
('rgb.max=', 135.82374572753906, 'rgb.min=', -225.93849182128906)
('rgb.max=', 135.91242980957031, 'rgb.min=', -225.83076477050781)
('rgb.max=', 135.91763305664062, 'rgb.min=', -226.12384033203125)
('rgb.max=', 135.96786499023438, 'rgb.min=', -226.349365234375)
('rgb.max=', 136.08975219726562, 'rgb.min=', -225.90640258789062)
('rgb.max=', 136.17742919921875, 'rgb.min=', -225.92193603515625)
('rgb.max=', 136.11418151855469, 'rgb.min=', -225.77973937988281)
('rgb.max=', 135.96353149414062, 'rgb.min=', -225.81289672851562)
('rgb.max=', 135.78810119628906, 'rgb.min=', -225.94194030761719)
('rgb.max=', 136.1451416015625, 'rgb.min=', -225.97941589355469)
('rgb.max=', 136.13278198242188, 'rgb.min=', -226.06504821777344)
('rgb.max=', 135.82701110839844, 'rgb.min=', -225.8582763671875)
('rgb.max=', 135.8973388671875, 'rgb.min=', -225.84284973144531)
('rgb.max=', 135.86734008789062, 'rgb.min=', -226.00160217285156)
('rgb.max=', 135.90010070800781, 'rgb.min=', -226.09194946289062)
('rgb.max=', 135.86248779296875, 'rgb.min=', -225.93824768066406)
('rgb.max=', 136.03607177734375, 'rgb.min=', -226.1185302734375)
('rgb.max=', 135.8870849609375, 'rgb.min=', -226.03105163574219)
('rgb.max=', 135.89546203613281, 'rgb.min=', -225.9925537109375)
('rgb.max=', 136.16384887695312, 'rgb.min=', -225.9427490234375)
('rgb.max=', 136.13836669921875, 'rgb.min=', -225.93061828613281)
('rgb.max=', 136.12277221679688, 'rgb.min=', -226.07609558105469)
('rgb.max=', 135.98960876464844, 'rgb.min=', -225.93191528320312)
('rgb.max=', 135.98211669921875, 'rgb.min=', -226.00675964355469)
('rgb.max=', 135.72653198242188, 'rgb.min=', -225.86940002441406)
('rgb.max=', 135.95748901367188, 'rgb.min=', -226.15896606445312)
('rgb.max=', 135.90899658203125, 'rgb.min=', -226.06344604492188)
('rgb.max=', 135.92184448242188, 'rgb.min=', -225.92724609375)
('rgb.max=', 135.9169921875, 'rgb.min=', -226.42132568359375)
('rgb.max=', 135.61026000976562, 'rgb.min=', -225.87953186035156)
('rgb.max=', 135.94427490234375, 'rgb.min=', -225.94920349121094)
('rgb.max=', 135.76220703125, 'rgb.min=', -225.77639770507812)
('rgb.max=', 135.86996459960938, 'rgb.min=', -225.95706176757812)
('rgb.max=', 136.16627502441406, 'rgb.min=', -226.15766906738281)
('rgb.max=', 136.05364990234375, 'rgb.min=', -226.03805541992188)
('rgb.max=', 136.219482421875, 'rgb.min=', -225.96368408203125)
('rgb.max=', 135.68466186523438, 'rgb.min=', -226.0543212890625)
('rgb.max=', 135.84767150878906, 'rgb.min=', -225.96150207519531)
('rgb.max=', 136.08201599121094, 'rgb.min=', -226.056884765625)
('rgb.max=', 136.07093811035156, 'rgb.min=', -226.06271362304688)
('rgb.max=', 135.89642333984375, 'rgb.min=', -226.03598022460938)
('rgb.max=', 135.82919311523438, 'rgb.min=', -225.9288330078125)
('rgb.max=', 135.85743713378906, 'rgb.min=', -225.95423889160156)
('rgb.max=', 135.5863037109375, 'rgb.min=', -226.08712768554688)
('rgb.max=', 135.92088317871094, 'rgb.min=', -226.14616394042969)
('rgb.max=', 135.75094604492188, 'rgb.min=', -225.80014038085938)
('rgb.max=', 135.719482421875, 'rgb.min=', -226.06617736816406)
('rgb.max=', 135.77114868164062, 'rgb.min=', -226.32124328613281)
('rgb.max=', 136.39617919921875, 'rgb.min=', -225.81991577148438)
('rgb.max=', 135.99154663085938, 'rgb.min=', -226.16827392578125)
('rgb.max=', 135.68058776855469, 'rgb.min=', -225.900390625)
('rgb.max=', 135.72576904296875, 'rgb.min=', -226.01841735839844)
('rgb.max=', 136.0653076171875, 'rgb.min=', -226.1826171875)
('rgb.max=', 136.06192016601562, 'rgb.min=', -226.0369873046875)
('rgb.max=', 136.01524353027344, 'rgb.min=', -226.08512878417969)
('rgb.max=', 135.78532409667969, 'rgb.min=', -226.04034423828125)
('rgb.max=', 135.88166809082031, 'rgb.min=', -226.25636291503906)
('rgb.max=', 135.97740173339844, 'rgb.min=', -226.16453552246094)
('rgb.max=', 135.90158081054688, 'rgb.min=', -225.82241821289062)
('rgb.max=', 136.12432861328125, 'rgb.min=', -226.04527282714844)
('rgb.max=', 136.28871154785156, 'rgb.min=', -226.10926818847656)
('rgb.max=', 136.08209228515625, 'rgb.min=', -225.92507934570312)
('rgb.max=', 135.78741455078125, 'rgb.min=', -226.11767578125)
('rgb.max=', 135.9423828125, 'rgb.min=', -225.95013427734375)
('rgb.max=', 136.02877807617188, 'rgb.min=', -225.68167114257812)
('rgb.max=', 135.85755920410156, 'rgb.min=', -225.89488220214844)
('rgb.max=', 135.8046875, 'rgb.min=', -226.04051208496094)
('rgb.max=', 136.01820373535156, 'rgb.min=', -226.05641174316406)
('rgb.max=', 136.01812744140625, 'rgb.min=', -226.2099609375)
('rgb.max=', 135.88017272949219, 'rgb.min=', -226.09007263183594)
('rgb.max=', 136.03707885742188, 'rgb.min=', -225.82711791992188)
('rgb.max=', 135.7794189453125, 'rgb.min=', -225.98788452148438)
('rgb.max=', 135.96144104003906, 'rgb.min=', -226.25404357910156)
('rgb.max=', 135.63505554199219, 'rgb.min=', -225.88197326660156)
('rgb.max=', 135.87760925292969, 'rgb.min=', -225.91461181640625)
('rgb.max=', 135.78804016113281, 'rgb.min=', -226.24440002441406)
('rgb.max=', 135.83114624023438, 'rgb.min=', -226.35885620117188)
('rgb.max=', 135.744873046875, 'rgb.min=', -225.88066101074219)
('rgb.max=', 135.77581787109375, 'rgb.min=', -225.86141967773438)
('rgb.max=', 136.11866760253906, 'rgb.min=', -225.94813537597656)
('rgb.max=', 135.89276123046875, 'rgb.min=', -225.97666931152344)
('rgb.max=', 135.992919921875, 'rgb.min=', -226.40989685058594)
('rgb.max=', 135.7828369140625, 'rgb.min=', -226.13941955566406)
('rgb.max=', 135.93699645996094, 'rgb.min=', -225.99069213867188)
('rgb.max=', 135.86863708496094, 'rgb.min=', -226.17962646484375)
('rgb.max=', 135.73405456542969, 'rgb.min=', -225.90995788574219)
('rgb.max=', 135.95956420898438, 'rgb.min=', -225.82713317871094)
('rgb.max=', 135.89886474609375, 'rgb.min=', -225.92680358886719)
('rgb.max=', 135.90696716308594, 'rgb.min=', -225.85127258300781)
('rgb.max=', 136.14031982421875, 'rgb.min=', -226.05671691894531)
('rgb.max=', 135.94757080078125, 'rgb.min=', -226.09358215332031)
('rgb.max=', 135.95231628417969, 'rgb.min=', -226.23350524902344)
('rgb.max=', 136.09030151367188, 'rgb.min=', -225.97341918945312)
('rgb.max=', 135.95684814453125, 'rgb.min=', -225.9033203125)
('rgb.max=', 135.95953369140625, 'rgb.min=', -226.00398254394531)
('rgb.max=', 136.14750671386719, 'rgb.min=', -225.88580322265625)
('rgb.max=', 135.91162109375, 'rgb.min=', -225.78443908691406)
('rgb.max=', 135.95230102539062, 'rgb.min=', -225.79747009277344)
('rgb.max=', 135.86288452148438, 'rgb.min=', -226.05162048339844)
('rgb.max=', 135.84921264648438, 'rgb.min=', -226.34542846679688)
('rgb.max=', 135.63369750976562, 'rgb.min=', -226.00350952148438)
('rgb.max=', 135.94036865234375, 'rgb.min=', -225.79776000976562)
('rgb.max=', 135.79483032226562, 'rgb.min=', -225.86981201171875)
('rgb.max=', 136.05404663085938, 'rgb.min=', -225.84138488769531)
('rgb.max=', 136.00860595703125, 'rgb.min=', -225.97744750976562)
('rgb.max=', 136.31771850585938, 'rgb.min=', -226.03007507324219)
('rgb.max=', 135.80812072753906, 'rgb.min=', -225.8668212890625)
('rgb.max=', 135.88442993164062, 'rgb.min=', -225.95341491699219)
('rgb.max=', 135.80088806152344, 'rgb.min=', -225.79527282714844)
('rgb.max=', 135.90312194824219, 'rgb.min=', -226.12141418457031)
('rgb.max=', 135.85475158691406, 'rgb.min=', -225.79341125488281)
('rgb.max=', 136.17501831054688, 'rgb.min=', -225.97555541992188)
('rgb.max=', 135.63388061523438, 'rgb.min=', -226.05506896972656)
('rgb.max=', 135.9765625, 'rgb.min=', -226.09004211425781)
('rgb.max=', 136.07524108886719, 'rgb.min=', -225.83746337890625)
('rgb.max=', 135.74429321289062, 'rgb.min=', -226.08073425292969)
('rgb.max=', 135.95184326171875, 'rgb.min=', -225.92724609375)
('rgb.max=', 136.15399169921875, 'rgb.min=', -225.84625244140625)
('rgb.max=', 135.98341369628906, 'rgb.min=', -225.80154418945312)
('rgb.max=', 135.68623352050781, 'rgb.min=', -226.09236145019531)
('rgb.max=', 135.86590576171875, 'rgb.min=', -226.17295837402344)
('rgb.max=', 135.96173095703125, 'rgb.min=', -225.86518859863281)
('rgb.max=', 135.80928039550781, 'rgb.min=', -226.03153991699219)
('rgb.max=', 135.95668029785156, 'rgb.min=', -225.92044067382812)
('rgb.max=', 135.87489318847656, 'rgb.min=', -225.83187866210938)
('rgb.max=', 136.07135009765625, 'rgb.min=', -225.92033386230469)
('rgb.max=', 135.7314453125, 'rgb.min=', -226.12152099609375)
('rgb.max=', 136.16436767578125, 'rgb.min=', -226.01580810546875)
('rgb.max=', 135.95367431640625, 'rgb.min=', -226.06744384765625)
('rgb.max=', 136.16439819335938, 'rgb.min=', -225.77973937988281)
('rgb.max=', 135.87644958496094, 'rgb.min=', -225.81777954101562)
('rgb.max=', 136.0887451171875, 'rgb.min=', -226.03289794921875)
('rgb.max=', 136.11807250976562, 'rgb.min=', -226.06173706054688)
('rgb.max=', 136.13861083984375, 'rgb.min=', -225.87394714355469)
('rgb.max=', 135.80772399902344, 'rgb.min=', -225.821533203125)
('rgb.max=', 135.96139526367188, 'rgb.min=', -225.85443115234375)
('rgb.max=', 136.01254272460938, 'rgb.min=', -226.13026428222656)
('rgb.max=', 136.0101318359375, 'rgb.min=', -226.05502319335938)
('rgb.max=', 135.88314819335938, 'rgb.min=', -225.98585510253906)
('rgb.max=', 135.85983276367188, 'rgb.min=', -225.80953979492188)
('rgb.max=', 136.145751953125, 'rgb.min=', -226.0377197265625)
('rgb.max=', 135.90846252441406, 'rgb.min=', -225.84963989257812)
('rgb.max=', 135.779541015625, 'rgb.min=', -226.22955322265625)
('rgb.max=', 135.721923828125, 'rgb.min=', -225.76812744140625)
('rgb.max=', 135.85859680175781, 'rgb.min=', -225.76469421386719)
('rgb.max=', 135.92623901367188, 'rgb.min=', -226.08631896972656)
('rgb.max=', 135.90809631347656, 'rgb.min=', -225.92977905273438)
('rgb.max=', 135.74203491210938, 'rgb.min=', -225.88377380371094)
('rgb.max=', 136.18739318847656, 'rgb.min=', -226.01483154296875)
('rgb.max=', 136.06373596191406, 'rgb.min=', -225.8798828125)
('rgb.max=', 135.9993896484375, 'rgb.min=', -226.09237670898438)
('rgb.max=', 135.68521118164062, 'rgb.min=', -225.9263916015625)
('rgb.max=', 136.15544128417969, 'rgb.min=', -226.14509582519531)
('rgb.max=', 136.0660400390625, 'rgb.min=', -225.99737548828125)
('rgb.max=', 135.80532836914062, 'rgb.min=', -226.00984191894531)
('rgb.max=', 136.09564208984375, 'rgb.min=', -226.01762390136719)
('rgb.max=', 136.03511047363281, 'rgb.min=', -226.01431274414062)
('rgb.max=', 135.96975708007812, 'rgb.min=', -225.95851135253906)
('rgb.max=', 135.94477844238281, 'rgb.min=', -226.02290344238281)
('rgb.max=', 136.11308288574219, 'rgb.min=', -226.11871337890625)
('rgb.max=', 136.05900573730469, 'rgb.min=', -226.02145385742188)
('rgb.max=', 135.81529235839844, 'rgb.min=', -226.0626220703125)
('rgb.max=', 135.74746704101562, 'rgb.min=', -225.99104309082031)
('rgb.max=', 135.76828002929688, 'rgb.min=', -225.760498046875)
('rgb.max=', 135.88003540039062, 'rgb.min=', -226.25714111328125)
('rgb.max=', 136.10183715820312, 'rgb.min=', -226.0511474609375)
('rgb.max=', 135.96266174316406, 'rgb.min=', -225.95477294921875)
('rgb.max=', 136.1280517578125, 'rgb.min=', -225.78819274902344)
('rgb.max=', 136.2459716796875, 'rgb.min=', -225.93421936035156)
('rgb.max=', 135.928466796875, 'rgb.min=', -226.02520751953125)
('rgb.max=', 135.86776733398438, 'rgb.min=', -225.97134399414062)
('rgb.max=', 135.89663696289062, 'rgb.min=', -226.00697326660156)
('rgb.max=', 136.17398071289062, 'rgb.min=', -225.44523620605469)
('rgb.max=', 136.04048156738281, 'rgb.min=', -225.942626953125)
('rgb.max=', 136.04299926757812, 'rgb.min=', -226.33116149902344)
('rgb.max=', 135.58447265625, 'rgb.min=', -225.85502624511719)
('rgb.max=', 135.91252136230469, 'rgb.min=', -225.67498779296875)
('rgb.max=', 135.92167663574219, 'rgb.min=', -226.03912353515625)
('rgb.max=', 135.78446960449219, 'rgb.min=', -226.11880493164062)
('rgb.max=', 136.13400268554688, 'rgb.min=', -225.65675354003906)
('rgb.max=', 135.59890747070312, 'rgb.min=', -225.8299560546875)
('rgb.max=', 136.05433654785156, 'rgb.min=', -226.27523803710938)
('rgb.max=', 135.84169006347656, 'rgb.min=', -226.05320739746094)
('rgb.max=', 136.00572204589844, 'rgb.min=', -225.78445434570312)
('rgb.max=', 135.90472412109375, 'rgb.min=', -226.06648254394531)
('rgb.max=', 136.00843811035156, 'rgb.min=', -225.95550537109375)
('rgb.max=', 135.87579345703125, 'rgb.min=', -226.26756286621094)
('rgb.max=', 135.98097229003906, 'rgb.min=', -225.90687561035156)
('rgb.max=', 135.98391723632812, 'rgb.min=', -226.0081787109375)
('rgb.max=', 135.93472290039062, 'rgb.min=', -226.12986755371094)
('rgb.max=', 136.02822875976562, 'rgb.min=', -226.16580200195312)
('rgb.max=', 135.8033447265625, 'rgb.min=', -225.8302001953125)
('rgb.max=', 136.12860107421875, 'rgb.min=', -225.82220458984375)
('rgb.max=', 135.98471069335938, 'rgb.min=', -225.76553344726562)
('rgb.max=', 136.03396606445312, 'rgb.min=', -225.91415405273438)
('rgb.max=', 135.83370971679688, 'rgb.min=', -226.10087585449219)
('rgb.max=', 135.90278625488281, 'rgb.min=', -225.85121154785156)
('rgb.max=', 136.11302185058594, 'rgb.min=', -226.07765197753906)
('rgb.max=', 135.85502624511719, 'rgb.min=', -225.76319885253906)
('rgb.max=', 135.96923828125, 'rgb.min=', -225.86599731445312)
('rgb.max=', 136.02301025390625, 'rgb.min=', -225.92555236816406)
('rgb.max=', 135.85028076171875, 'rgb.min=', -225.96427917480469)
('rgb.max=', 135.9798583984375, 'rgb.min=', -226.15641784667969)
('rgb.max=', 135.68820190429688, 'rgb.min=', -225.92384338378906)
('rgb.max=', 135.86962890625, 'rgb.min=', -225.92277526855469)
('rgb.max=', 135.80734252929688, 'rgb.min=', -225.86738586425781)
('rgb.max=', 136.07371520996094, 'rgb.min=', -226.02137756347656)
('rgb.max=', 135.95379638671875, 'rgb.min=', -225.88027954101562)
('rgb.max=', 135.86587524414062, 'rgb.min=', -226.04879760742188)
('rgb.max=', 136.03797912597656, 'rgb.min=', -225.74104309082031)
('rgb.max=', 135.95246887207031, 'rgb.min=', -226.21224975585938)
('rgb.max=', 135.91560363769531, 'rgb.min=', -225.82281494140625)
('rgb.max=', 135.73391723632812, 'rgb.min=', -225.92625427246094)
('rgb.max=', 135.64932250976562, 'rgb.min=', -225.80694580078125)
('rgb.max=', 135.86903381347656, 'rgb.min=', -226.122314453125)
('rgb.max=', 135.92733764648438, 'rgb.min=', -226.24432373046875)
('rgb.max=', 135.680419921875, 'rgb.min=', -225.89129638671875)
('rgb.max=', 135.76522827148438, 'rgb.min=', -225.97634887695312)
('rgb.max=', 135.95449829101562, 'rgb.min=', -226.30429077148438)
('rgb.max=', 136.14790344238281, 'rgb.min=', -226.14646911621094)
('rgb.max=', 135.91828918457031, 'rgb.min=', -226.31951904296875)
('rgb.max=', 136.14738464355469, 'rgb.min=', -225.98918151855469)
('rgb.max=', 136.03520202636719, 'rgb.min=', -225.67945861816406)
('rgb.max=', 136.06770324707031, 'rgb.min=', -226.09751892089844)
('rgb.max=', 135.93635559082031, 'rgb.min=', -226.08564758300781)
('rgb.max=', 136.07411193847656, 'rgb.min=', -226.07472229003906)
('rgb.max=', 135.65483093261719, 'rgb.min=', -225.94699096679688)
('rgb.max=', 135.93670654296875, 'rgb.min=', -226.11952209472656)
('rgb.max=', 135.99824523925781, 'rgb.min=', -225.94639587402344)
('rgb.max=', 136.12298583984375, 'rgb.min=', -225.84892272949219)
('rgb.max=', 136.0384521484375, 'rgb.min=', -226.18450927734375)
('rgb.max=', 135.79350280761719, 'rgb.min=', -225.85305786132812)
('rgb.max=', 135.9049072265625, 'rgb.min=', -225.841552734375)
('rgb.max=', 135.67294311523438, 'rgb.min=', -226.25648498535156)
('rgb.max=', 135.73155212402344, 'rgb.min=', -225.97113037109375)
('rgb.max=', 135.83818054199219, 'rgb.min=', -226.18826293945312)
('rgb.max=', 135.88125610351562, 'rgb.min=', -225.90737915039062)
('rgb.max=', 135.903076171875, 'rgb.min=', -226.01582336425781)
('rgb.max=', 135.98890686035156, 'rgb.min=', -226.10345458984375)
('rgb.max=', 135.94538879394531, 'rgb.min=', -225.89308166503906)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.752762')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6970 ', 'GAN acc 0.4570', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4922', 'Total loss: 1.3911', 'for batch', 0)
('GAN loss 0.7040 ', 'GAN acc 0.4141', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5039', 'Total loss: 1.3987', 'for batch', 1)
('GAN loss 0.7042 ', 'GAN acc 0.4414', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.3984', 'for batch', 2)
('GAN loss 0.6933 ', 'GAN acc 0.5234', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4922', 'Total loss: 1.3885', 'for batch', 3)
('GAN loss 0.6924 ', 'GAN acc 0.5273', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4922', 'Total loss: 1.3880', 'for batch', 4)
('GAN loss 0.6924 ', 'GAN acc 0.5195', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4336', 'Total loss: 1.3924', 'for batch', 5)
('GAN loss 0.6886 ', 'GAN acc 0.5352', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5176', 'Total loss: 1.3815', 'for batch', 6)
('GAN loss 0.6813 ', 'GAN acc 0.6133', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5000', 'Total loss: 1.3781', 'for batch', 7)
('GAN loss 0.6870 ', 'GAN acc 0.6094', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5469', 'Total loss: 1.3787', 'for batch', 8)
('GAN loss 0.6849 ', 'GAN acc 0.6172', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4551', 'Total loss: 1.3813', 'for batch', 9)
('GAN loss 0.6770 ', 'GAN acc 0.6562', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5078', 'Total loss: 1.3716', 'for batch', 10)
('GAN loss 0.6932 ', 'GAN acc 0.5117', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4531', 'Total loss: 1.3913', 'for batch', 11)
('GAN loss 0.6860 ', 'GAN acc 0.5273', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5078', 'Total loss: 1.3798', 'for batch', 12)
('GAN loss 0.6878 ', 'GAN acc 0.5742', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5020', 'Total loss: 1.3822', 'for batch', 13)
('GAN loss 0.6912 ', 'GAN acc 0.5391', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5039', 'Total loss: 1.3852', 'for batch', 14)
('GAN loss 0.6991 ', 'GAN acc 0.4844', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4688', 'Total loss: 1.3954', 'for batch', 15)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4863', 'Total loss: 1.3922', 'for batch', 16)
('GAN loss 0.7028 ', 'GAN acc 0.4219', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5234', 'Total loss: 1.3953', 'for batch', 17)
('GAN loss 0.6971 ', 'GAN acc 0.4766', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5000', 'Total loss: 1.3914', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52192426)
('DISCRIMINATOR_Imagem FAKE=', 0.52233535)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.00993347167969, 'rgb.min=', -225.83100891113281)
('rgb.max=', 135.91708374023438, 'rgb.min=', -226.10850524902344)
('rgb.max=', 136.17330932617188, 'rgb.min=', -225.98086547851562)
('rgb.max=', 136.00038146972656, 'rgb.min=', -226.08462524414062)
('rgb.max=', 136.14877319335938, 'rgb.min=', -225.96194458007812)
('rgb.max=', 136.18934631347656, 'rgb.min=', -226.45936584472656)
('rgb.max=', 135.83445739746094, 'rgb.min=', -226.232177734375)
('rgb.max=', 135.97682189941406, 'rgb.min=', -225.96592712402344)
('rgb.max=', 135.85549926757812, 'rgb.min=', -226.17915344238281)
('rgb.max=', 135.80195617675781, 'rgb.min=', -226.00775146484375)
('rgb.max=', 135.71878051757812, 'rgb.min=', -226.25569152832031)
('rgb.max=', 135.84603881835938, 'rgb.min=', -226.09140014648438)
('rgb.max=', 135.80180358886719, 'rgb.min=', -226.06826782226562)
('rgb.max=', 135.92555236816406, 'rgb.min=', -226.10971069335938)
('rgb.max=', 135.80644226074219, 'rgb.min=', -226.01258850097656)
('rgb.max=', 135.77882385253906, 'rgb.min=', -226.06021118164062)
('rgb.max=', 135.8250732421875, 'rgb.min=', -225.9532470703125)
('rgb.max=', 135.91140747070312, 'rgb.min=', -225.82913208007812)
('rgb.max=', 135.90728759765625, 'rgb.min=', -226.1912841796875)
('rgb.max=', 135.95855712890625, 'rgb.min=', -226.4156494140625)
('rgb.max=', 136.10247802734375, 'rgb.min=', -225.91777038574219)
('rgb.max=', 136.17955017089844, 'rgb.min=', -225.91932678222656)
('rgb.max=', 136.12696838378906, 'rgb.min=', -225.78616333007812)
('rgb.max=', 135.93685913085938, 'rgb.min=', -225.79142761230469)
('rgb.max=', 135.7891845703125, 'rgb.min=', -226.04708862304688)
('rgb.max=', 136.1558837890625, 'rgb.min=', -226.03279113769531)
('rgb.max=', 136.18074035644531, 'rgb.min=', -226.06733703613281)
('rgb.max=', 135.83079528808594, 'rgb.min=', -225.88685607910156)
('rgb.max=', 135.90876770019531, 'rgb.min=', -225.83950805664062)
('rgb.max=', 135.90255737304688, 'rgb.min=', -226.00323486328125)
('rgb.max=', 135.90576171875, 'rgb.min=', -226.09835815429688)
('rgb.max=', 135.86395263671875, 'rgb.min=', -225.95988464355469)
('rgb.max=', 135.99758911132812, 'rgb.min=', -226.10035705566406)
('rgb.max=', 135.88687133789062, 'rgb.min=', -226.02877807617188)
('rgb.max=', 135.87049865722656, 'rgb.min=', -226.05641174316406)
('rgb.max=', 136.17422485351562, 'rgb.min=', -225.94680786132812)
('rgb.max=', 136.18341064453125, 'rgb.min=', -225.990966796875)
('rgb.max=', 136.1334228515625, 'rgb.min=', -226.15211486816406)
('rgb.max=', 135.96272277832031, 'rgb.min=', -225.94462585449219)
('rgb.max=', 135.95492553710938, 'rgb.min=', -226.01448059082031)
('rgb.max=', 135.72247314453125, 'rgb.min=', -225.87013244628906)
('rgb.max=', 135.96163940429688, 'rgb.min=', -226.21786499023438)
('rgb.max=', 135.90316772460938, 'rgb.min=', -226.04301452636719)
('rgb.max=', 135.89537048339844, 'rgb.min=', -226.0274658203125)
('rgb.max=', 135.99072265625, 'rgb.min=', -226.50616455078125)
('rgb.max=', 135.59196472167969, 'rgb.min=', -225.88052368164062)
('rgb.max=', 135.95608520507812, 'rgb.min=', -225.94023132324219)
('rgb.max=', 135.79452514648438, 'rgb.min=', -225.74087524414062)
('rgb.max=', 135.896484375, 'rgb.min=', -225.94937133789062)
('rgb.max=', 136.20791625976562, 'rgb.min=', -226.24641418457031)
('rgb.max=', 136.06561279296875, 'rgb.min=', -226.12165832519531)
('rgb.max=', 136.16653442382812, 'rgb.min=', -225.98509216308594)
('rgb.max=', 135.6815185546875, 'rgb.min=', -226.10499572753906)
('rgb.max=', 135.85609436035156, 'rgb.min=', -225.98493957519531)
('rgb.max=', 136.097412109375, 'rgb.min=', -226.05482482910156)
('rgb.max=', 136.02197265625, 'rgb.min=', -226.07711791992188)
('rgb.max=', 135.8984375, 'rgb.min=', -226.04623413085938)
('rgb.max=', 135.83847045898438, 'rgb.min=', -225.89346313476562)
('rgb.max=', 135.85177612304688, 'rgb.min=', -225.95097351074219)
('rgb.max=', 135.58456420898438, 'rgb.min=', -226.15046691894531)
('rgb.max=', 135.96952819824219, 'rgb.min=', -226.12687683105469)
('rgb.max=', 135.74372863769531, 'rgb.min=', -225.824951171875)
('rgb.max=', 135.68844604492188, 'rgb.min=', -226.07960510253906)
('rgb.max=', 135.75668334960938, 'rgb.min=', -226.39056396484375)
('rgb.max=', 136.33639526367188, 'rgb.min=', -225.81991577148438)
('rgb.max=', 135.99188232421875, 'rgb.min=', -226.23234558105469)
('rgb.max=', 135.6630859375, 'rgb.min=', -225.90150451660156)
('rgb.max=', 135.72488403320312, 'rgb.min=', -226.11468505859375)
('rgb.max=', 136.02130126953125, 'rgb.min=', -226.21278381347656)
('rgb.max=', 136.10659790039062, 'rgb.min=', -226.10240173339844)
('rgb.max=', 136.02864074707031, 'rgb.min=', -226.15766906738281)
('rgb.max=', 135.76611328125, 'rgb.min=', -226.05511474609375)
('rgb.max=', 135.89456176757812, 'rgb.min=', -226.32386779785156)
('rgb.max=', 135.951904296875, 'rgb.min=', -226.13752746582031)
('rgb.max=', 135.87484741210938, 'rgb.min=', -225.76901245117188)
('rgb.max=', 136.10714721679688, 'rgb.min=', -226.03750610351562)
('rgb.max=', 136.22770690917969, 'rgb.min=', -226.14324951171875)
('rgb.max=', 136.04911804199219, 'rgb.min=', -225.89141845703125)
('rgb.max=', 135.77001953125, 'rgb.min=', -226.09288024902344)
('rgb.max=', 135.94096374511719, 'rgb.min=', -225.98828125)
('rgb.max=', 136.03709411621094, 'rgb.min=', -225.69598388671875)
('rgb.max=', 135.86978149414062, 'rgb.min=', -225.95832824707031)
('rgb.max=', 135.84323120117188, 'rgb.min=', -226.09408569335938)
('rgb.max=', 135.97520446777344, 'rgb.min=', -226.0235595703125)
('rgb.max=', 135.98934936523438, 'rgb.min=', -226.24177551269531)
('rgb.max=', 135.87826538085938, 'rgb.min=', -226.15634155273438)
('rgb.max=', 136.01071166992188, 'rgb.min=', -225.81503295898438)
('rgb.max=', 135.80250549316406, 'rgb.min=', -226.02859497070312)
('rgb.max=', 135.96247863769531, 'rgb.min=', -226.32749938964844)
('rgb.max=', 135.61215209960938, 'rgb.min=', -225.8231201171875)
('rgb.max=', 135.85189819335938, 'rgb.min=', -225.98728942871094)
('rgb.max=', 135.7794189453125, 'rgb.min=', -226.30094909667969)
('rgb.max=', 135.84719848632812, 'rgb.min=', -226.44914245605469)
('rgb.max=', 135.743408203125, 'rgb.min=', -225.90228271484375)
('rgb.max=', 135.79043579101562, 'rgb.min=', -225.80387878417969)
('rgb.max=', 136.09046936035156, 'rgb.min=', -225.90892028808594)
('rgb.max=', 135.90289306640625, 'rgb.min=', -225.95890808105469)
('rgb.max=', 135.99577331542969, 'rgb.min=', -226.47621154785156)
('rgb.max=', 135.77714538574219, 'rgb.min=', -226.1146240234375)
('rgb.max=', 135.92965698242188, 'rgb.min=', -226.003662109375)
('rgb.max=', 135.87060546875, 'rgb.min=', -226.13885498046875)
('rgb.max=', 135.73019409179688, 'rgb.min=', -225.92945861816406)
('rgb.max=', 135.93641662597656, 'rgb.min=', -225.83026123046875)
('rgb.max=', 135.88671875, 'rgb.min=', -225.96522521972656)
('rgb.max=', 135.90257263183594, 'rgb.min=', -225.83653259277344)
('rgb.max=', 136.15963745117188, 'rgb.min=', -226.03160095214844)
('rgb.max=', 135.97296142578125, 'rgb.min=', -226.14787292480469)
('rgb.max=', 135.96940612792969, 'rgb.min=', -226.17137145996094)
('rgb.max=', 136.12164306640625, 'rgb.min=', -225.98710632324219)
('rgb.max=', 135.928955078125, 'rgb.min=', -225.92060852050781)
('rgb.max=', 135.95994567871094, 'rgb.min=', -225.97563171386719)
('rgb.max=', 136.16651916503906, 'rgb.min=', -225.92921447753906)
('rgb.max=', 135.9217529296875, 'rgb.min=', -225.77401733398438)
('rgb.max=', 135.93601989746094, 'rgb.min=', -225.82475280761719)
('rgb.max=', 135.8568115234375, 'rgb.min=', -226.04580688476562)
('rgb.max=', 135.82101440429688, 'rgb.min=', -226.41224670410156)
('rgb.max=', 135.63099670410156, 'rgb.min=', -226.05087280273438)
('rgb.max=', 135.91726684570312, 'rgb.min=', -225.79135131835938)
('rgb.max=', 135.80256652832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 136.0665283203125, 'rgb.min=', -225.88340759277344)
('rgb.max=', 136.01005554199219, 'rgb.min=', -226.06269836425781)
('rgb.max=', 136.27360534667969, 'rgb.min=', -226.03057861328125)
('rgb.max=', 135.80975341796875, 'rgb.min=', -225.87124633789062)
('rgb.max=', 135.88008117675781, 'rgb.min=', -225.95477294921875)
('rgb.max=', 135.83592224121094, 'rgb.min=', -225.80979919433594)
('rgb.max=', 135.90670776367188, 'rgb.min=', -226.17582702636719)
('rgb.max=', 135.84866333007812, 'rgb.min=', -225.79411315917969)
('rgb.max=', 136.13687133789062, 'rgb.min=', -225.95820617675781)
('rgb.max=', 135.633544921875, 'rgb.min=', -226.09388732910156)
('rgb.max=', 135.94821166992188, 'rgb.min=', -226.13162231445312)
('rgb.max=', 136.085205078125, 'rgb.min=', -225.84750366210938)
('rgb.max=', 135.74089050292969, 'rgb.min=', -226.08845520019531)
('rgb.max=', 135.95893859863281, 'rgb.min=', -225.93544006347656)
('rgb.max=', 136.12051391601562, 'rgb.min=', -225.85977172851562)
('rgb.max=', 136.02423095703125, 'rgb.min=', -225.8018798828125)
('rgb.max=', 135.68583679199219, 'rgb.min=', -226.13053894042969)
('rgb.max=', 135.863525390625, 'rgb.min=', -226.23741149902344)
('rgb.max=', 135.92906188964844, 'rgb.min=', -225.86076354980469)
('rgb.max=', 135.80705261230469, 'rgb.min=', -226.07508850097656)
('rgb.max=', 135.93408203125, 'rgb.min=', -225.93977355957031)
('rgb.max=', 135.88542175292969, 'rgb.min=', -225.83607482910156)
('rgb.max=', 136.09796142578125, 'rgb.min=', -225.95457458496094)
('rgb.max=', 135.72525024414062, 'rgb.min=', -226.18135070800781)
('rgb.max=', 136.17210388183594, 'rgb.min=', -225.97445678710938)
('rgb.max=', 135.92758178710938, 'rgb.min=', -226.05223083496094)
('rgb.max=', 136.17034912109375, 'rgb.min=', -225.78012084960938)
('rgb.max=', 135.867919921875, 'rgb.min=', -225.85531616210938)
('rgb.max=', 136.10832214355469, 'rgb.min=', -226.04806518554688)
('rgb.max=', 136.1336669921875, 'rgb.min=', -226.11039733886719)
('rgb.max=', 136.098876953125, 'rgb.min=', -225.88150024414062)
('rgb.max=', 135.79864501953125, 'rgb.min=', -225.82266235351562)
('rgb.max=', 135.94358825683594, 'rgb.min=', -225.83489990234375)
('rgb.max=', 135.98126220703125, 'rgb.min=', -226.17791748046875)
('rgb.max=', 135.98916625976562, 'rgb.min=', -226.05130004882812)
('rgb.max=', 135.89459228515625, 'rgb.min=', -226.00146484375)
('rgb.max=', 135.86006164550781, 'rgb.min=', -225.83253479003906)
('rgb.max=', 136.15574645996094, 'rgb.min=', -226.01277160644531)
('rgb.max=', 135.8843994140625, 'rgb.min=', -225.87950134277344)
('rgb.max=', 135.77049255371094, 'rgb.min=', -226.29679870605469)
('rgb.max=', 135.71173095703125, 'rgb.min=', -225.76275634765625)
('rgb.max=', 135.8516845703125, 'rgb.min=', -225.72406005859375)
('rgb.max=', 135.9298095703125, 'rgb.min=', -226.15583801269531)
('rgb.max=', 135.91471862792969, 'rgb.min=', -225.94973754882812)
('rgb.max=', 135.75361633300781, 'rgb.min=', -225.94131469726562)
('rgb.max=', 136.23455810546875, 'rgb.min=', -226.02569580078125)
('rgb.max=', 136.03007507324219, 'rgb.min=', -225.86381530761719)
('rgb.max=', 135.99786376953125, 'rgb.min=', -226.12385559082031)
('rgb.max=', 135.68951416015625, 'rgb.min=', -225.88594055175781)
('rgb.max=', 136.16659545898438, 'rgb.min=', -226.06253051757812)
('rgb.max=', 136.03759765625, 'rgb.min=', -226.00717163085938)
('rgb.max=', 135.79069519042969, 'rgb.min=', -226.03718566894531)
('rgb.max=', 136.06439208984375, 'rgb.min=', -225.92753601074219)
('rgb.max=', 136.0050048828125, 'rgb.min=', -226.01058959960938)
('rgb.max=', 136.00006103515625, 'rgb.min=', -226.02816772460938)
('rgb.max=', 135.9202880859375, 'rgb.min=', -226.00955200195312)
('rgb.max=', 136.12213134765625, 'rgb.min=', -226.10798645019531)
('rgb.max=', 136.01695251464844, 'rgb.min=', -226.13432312011719)
('rgb.max=', 135.8218994140625, 'rgb.min=', -226.1019287109375)
('rgb.max=', 135.74226379394531, 'rgb.min=', -226.03346252441406)
('rgb.max=', 135.78019714355469, 'rgb.min=', -225.79743957519531)
('rgb.max=', 135.88145446777344, 'rgb.min=', -226.29501342773438)
('rgb.max=', 136.10050964355469, 'rgb.min=', -226.1019287109375)
('rgb.max=', 135.95291137695312, 'rgb.min=', -225.96885681152344)
('rgb.max=', 136.0938720703125, 'rgb.min=', -225.73733520507812)
('rgb.max=', 136.20698547363281, 'rgb.min=', -225.93031311035156)
('rgb.max=', 135.93611145019531, 'rgb.min=', -226.03900146484375)
('rgb.max=', 135.8636474609375, 'rgb.min=', -225.97727966308594)
('rgb.max=', 135.889404296875, 'rgb.min=', -226.0560302734375)
('rgb.max=', 136.22019958496094, 'rgb.min=', -225.48335266113281)
('rgb.max=', 136.01129150390625, 'rgb.min=', -226.03703308105469)
('rgb.max=', 136.06271362304688, 'rgb.min=', -226.39300537109375)
('rgb.max=', 135.55763244628906, 'rgb.min=', -225.8980712890625)
('rgb.max=', 135.92562866210938, 'rgb.min=', -225.66615295410156)
('rgb.max=', 135.91770935058594, 'rgb.min=', -226.020751953125)
('rgb.max=', 135.78861999511719, 'rgb.min=', -226.1080322265625)
('rgb.max=', 136.16741943359375, 'rgb.min=', -225.66423034667969)
('rgb.max=', 135.60794067382812, 'rgb.min=', -225.83108520507812)
('rgb.max=', 136.02937316894531, 'rgb.min=', -226.33103942871094)
('rgb.max=', 135.85525512695312, 'rgb.min=', -226.07391357421875)
('rgb.max=', 136.00334167480469, 'rgb.min=', -225.79362487792969)
('rgb.max=', 135.90275573730469, 'rgb.min=', -226.06565856933594)
('rgb.max=', 136.00323486328125, 'rgb.min=', -225.95242309570312)
('rgb.max=', 135.87762451171875, 'rgb.min=', -226.21389770507812)
('rgb.max=', 136.01258850097656, 'rgb.min=', -225.9130859375)
('rgb.max=', 136.02182006835938, 'rgb.min=', -226.03321838378906)
('rgb.max=', 135.93534851074219, 'rgb.min=', -226.11384582519531)
('rgb.max=', 136.03689575195312, 'rgb.min=', -226.13172912597656)
('rgb.max=', 135.82235717773438, 'rgb.min=', -225.82685852050781)
('rgb.max=', 136.14508056640625, 'rgb.min=', -225.82363891601562)
('rgb.max=', 136.00901794433594, 'rgb.min=', -225.76449584960938)
('rgb.max=', 136.04983520507812, 'rgb.min=', -225.93649291992188)
('rgb.max=', 135.831298828125, 'rgb.min=', -226.10591125488281)
('rgb.max=', 135.92596435546875, 'rgb.min=', -225.85879516601562)
('rgb.max=', 136.15194702148438, 'rgb.min=', -226.03804016113281)
('rgb.max=', 135.88310241699219, 'rgb.min=', -225.75360107421875)
('rgb.max=', 135.98468017578125, 'rgb.min=', -225.86770629882812)
('rgb.max=', 136.05644226074219, 'rgb.min=', -225.94973754882812)
('rgb.max=', 135.85745239257812, 'rgb.min=', -225.97087097167969)
('rgb.max=', 135.99945068359375, 'rgb.min=', -226.17715454101562)
('rgb.max=', 135.68316650390625, 'rgb.min=', -225.91648864746094)
('rgb.max=', 135.86183166503906, 'rgb.min=', -225.93087768554688)
('rgb.max=', 135.79902648925781, 'rgb.min=', -225.86488342285156)
('rgb.max=', 136.06025695800781, 'rgb.min=', -226.05909729003906)
('rgb.max=', 135.9754638671875, 'rgb.min=', -225.90971374511719)
('rgb.max=', 135.86271667480469, 'rgb.min=', -226.05105590820312)
('rgb.max=', 136.03759765625, 'rgb.min=', -225.73431396484375)
('rgb.max=', 135.93492126464844, 'rgb.min=', -226.19833374023438)
('rgb.max=', 135.95811462402344, 'rgb.min=', -225.82102966308594)
('rgb.max=', 135.73526000976562, 'rgb.min=', -225.9520263671875)
('rgb.max=', 135.65826416015625, 'rgb.min=', -225.81179809570312)
('rgb.max=', 135.869140625, 'rgb.min=', -226.16654968261719)
('rgb.max=', 135.92474365234375, 'rgb.min=', -226.23704528808594)
('rgb.max=', 135.68989562988281, 'rgb.min=', -225.95011901855469)
('rgb.max=', 135.78239440917969, 'rgb.min=', -225.99720764160156)
('rgb.max=', 135.96148681640625, 'rgb.min=', -226.24247741699219)
('rgb.max=', 136.16165161132812, 'rgb.min=', -226.15231323242188)
('rgb.max=', 135.90032958984375, 'rgb.min=', -226.31097412109375)
('rgb.max=', 136.15962219238281, 'rgb.min=', -225.98507690429688)
('rgb.max=', 136.01939392089844, 'rgb.min=', -225.76957702636719)
('rgb.max=', 136.09234619140625, 'rgb.min=', -226.10992431640625)
('rgb.max=', 135.93914794921875, 'rgb.min=', -226.0721435546875)
('rgb.max=', 136.10945129394531, 'rgb.min=', -226.12551879882812)
('rgb.max=', 135.66522216796875, 'rgb.min=', -225.95144653320312)
('rgb.max=', 135.96157836914062, 'rgb.min=', -226.12626647949219)
('rgb.max=', 136.01284790039062, 'rgb.min=', -225.95918273925781)
('rgb.max=', 136.13873291015625, 'rgb.min=', -225.86099243164062)
('rgb.max=', 136.04150390625, 'rgb.min=', -226.22383117675781)
('rgb.max=', 135.79693603515625, 'rgb.min=', -225.84275817871094)
('rgb.max=', 135.90623474121094, 'rgb.min=', -225.83729553222656)
('rgb.max=', 135.66400146484375, 'rgb.min=', -226.31330871582031)
('rgb.max=', 135.73371887207031, 'rgb.min=', -225.97805786132812)
('rgb.max=', 135.84231567382812, 'rgb.min=', -226.17816162109375)
('rgb.max=', 135.88937377929688, 'rgb.min=', -225.91453552246094)
('rgb.max=', 135.90885925292969, 'rgb.min=', -226.03263854980469)
('rgb.max=', 135.98654174804688, 'rgb.min=', -226.12632751464844)
('rgb.max=', 135.92819213867188, 'rgb.min=', -225.90902709960938)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.815654')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7026 ', 'GAN acc 0.4453', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5117', 'Total loss: 1.3983', 'for batch', 0)
('GAN loss 0.7054 ', 'GAN acc 0.4102', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4961', 'Total loss: 1.3992', 'for batch', 1)
('GAN loss 0.7073 ', 'GAN acc 0.4062', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5273', 'Total loss: 1.3998', 'for batch', 2)
('GAN loss 0.6987 ', 'GAN acc 0.4492', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5117', 'Total loss: 1.3909', 'for batch', 3)
('GAN loss 0.6931 ', 'GAN acc 0.5039', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4785', 'Total loss: 1.3897', 'for batch', 4)
('GAN loss 0.6943 ', 'GAN acc 0.5078', 'Discriminator loss 0.6892', 'Discriminator accuracy 0.5547', 'Total loss: 1.3835', 'for batch', 5)
('GAN loss 0.6857 ', 'GAN acc 0.5625', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5215', 'Total loss: 1.3775', 'for batch', 6)
('GAN loss 0.6827 ', 'GAN acc 0.5742', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5273', 'Total loss: 1.3744', 'for batch', 7)
('GAN loss 0.6846 ', 'GAN acc 0.5820', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5254', 'Total loss: 1.3760', 'for batch', 8)
('GAN loss 0.6834 ', 'GAN acc 0.5859', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5332', 'Total loss: 1.3756', 'for batch', 9)
('GAN loss 0.6852 ', 'GAN acc 0.5586', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4883', 'Total loss: 1.3798', 'for batch', 10)
('GAN loss 0.6857 ', 'GAN acc 0.5938', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5215', 'Total loss: 1.3794', 'for batch', 11)
('GAN loss 0.6815 ', 'GAN acc 0.6094', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4844', 'Total loss: 1.3764', 'for batch', 12)
('GAN loss 0.6884 ', 'GAN acc 0.5234', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3830', 'for batch', 13)
('GAN loss 0.6882 ', 'GAN acc 0.5547', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5078', 'Total loss: 1.3824', 'for batch', 14)
('GAN loss 0.6968 ', 'GAN acc 0.4922', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5117', 'Total loss: 1.3906', 'for batch', 15)
('GAN loss 0.6977 ', 'GAN acc 0.4883', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4941', 'Total loss: 1.3911', 'for batch', 16)
('GAN loss 0.6950 ', 'GAN acc 0.5391', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5176', 'Total loss: 1.3869', 'for batch', 17)
('GAN loss 0.6954 ', 'GAN acc 0.4922', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4824', 'Total loss: 1.3891', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52259421)
('DISCRIMINATOR_Imagem FAKE=', 0.52346438)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 135.99542236328125, 'rgb.min=', -225.81173706054688)
('rgb.max=', 135.914794921875, 'rgb.min=', -226.0770263671875)
('rgb.max=', 136.16658020019531, 'rgb.min=', -225.9688720703125)
('rgb.max=', 136.01406860351562, 'rgb.min=', -226.07191467285156)
('rgb.max=', 136.118408203125, 'rgb.min=', -225.93147277832031)
('rgb.max=', 136.15203857421875, 'rgb.min=', -226.40290832519531)
('rgb.max=', 135.83761596679688, 'rgb.min=', -226.20272827148438)
('rgb.max=', 135.96917724609375, 'rgb.min=', -225.95590209960938)
('rgb.max=', 135.85418701171875, 'rgb.min=', -226.18867492675781)
('rgb.max=', 135.80790710449219, 'rgb.min=', -225.99751281738281)
('rgb.max=', 135.72189331054688, 'rgb.min=', -226.21308898925781)
('rgb.max=', 135.84808349609375, 'rgb.min=', -226.04576110839844)
('rgb.max=', 135.78895568847656, 'rgb.min=', -226.09466552734375)
('rgb.max=', 135.95451354980469, 'rgb.min=', -226.09152221679688)
('rgb.max=', 135.80516052246094, 'rgb.min=', -225.97671508789062)
('rgb.max=', 135.78012084960938, 'rgb.min=', -226.04208374023438)
('rgb.max=', 135.82466125488281, 'rgb.min=', -225.96929931640625)
('rgb.max=', 135.91571044921875, 'rgb.min=', -225.83619689941406)
('rgb.max=', 135.91940307617188, 'rgb.min=', -226.16436767578125)
('rgb.max=', 135.96749877929688, 'rgb.min=', -226.39309692382812)
('rgb.max=', 136.07643127441406, 'rgb.min=', -225.92779541015625)
('rgb.max=', 136.168701171875, 'rgb.min=', -225.94683837890625)
('rgb.max=', 136.10755920410156, 'rgb.min=', -225.86453247070312)
('rgb.max=', 135.92352294921875, 'rgb.min=', -225.67588806152344)
('rgb.max=', 135.78652954101562, 'rgb.min=', -225.99490356445312)
('rgb.max=', 136.1422119140625, 'rgb.min=', -225.99440002441406)
('rgb.max=', 136.09951782226562, 'rgb.min=', -226.09007263183594)
('rgb.max=', 135.82476806640625, 'rgb.min=', -225.88539123535156)
('rgb.max=', 135.91067504882812, 'rgb.min=', -225.83242797851562)
('rgb.max=', 135.9022216796875, 'rgb.min=', -226.01611328125)
('rgb.max=', 135.9251708984375, 'rgb.min=', -226.10791015625)
('rgb.max=', 135.86241149902344, 'rgb.min=', -225.98355102539062)
('rgb.max=', 135.99488830566406, 'rgb.min=', -226.11068725585938)
('rgb.max=', 135.89410400390625, 'rgb.min=', -226.05479431152344)
('rgb.max=', 135.85563659667969, 'rgb.min=', -226.02774047851562)
('rgb.max=', 136.14324951171875, 'rgb.min=', -225.96736145019531)
('rgb.max=', 136.10362243652344, 'rgb.min=', -226.00505065917969)
('rgb.max=', 136.11697387695312, 'rgb.min=', -226.08419799804688)
('rgb.max=', 135.95547485351562, 'rgb.min=', -225.95480346679688)
('rgb.max=', 135.94892883300781, 'rgb.min=', -226.03326416015625)
('rgb.max=', 135.72674560546875, 'rgb.min=', -225.90083312988281)
('rgb.max=', 135.96759033203125, 'rgb.min=', -226.1778564453125)
('rgb.max=', 135.90826416015625, 'rgb.min=', -226.04435729980469)
('rgb.max=', 135.8839111328125, 'rgb.min=', -225.97169494628906)
('rgb.max=', 135.94343566894531, 'rgb.min=', -226.45968627929688)
('rgb.max=', 135.594482421875, 'rgb.min=', -225.90536499023438)
('rgb.max=', 135.96554565429688, 'rgb.min=', -225.97264099121094)
('rgb.max=', 135.79449462890625, 'rgb.min=', -225.74116516113281)
('rgb.max=', 135.90510559082031, 'rgb.min=', -225.96589660644531)
('rgb.max=', 136.14805603027344, 'rgb.min=', -226.12615966796875)
('rgb.max=', 136.044189453125, 'rgb.min=', -226.11074829101562)
('rgb.max=', 136.14668273925781, 'rgb.min=', -225.99766540527344)
('rgb.max=', 135.6839599609375, 'rgb.min=', -226.06332397460938)
('rgb.max=', 135.845947265625, 'rgb.min=', -225.99043273925781)
('rgb.max=', 136.07745361328125, 'rgb.min=', -226.02264404296875)
('rgb.max=', 136.00531005859375, 'rgb.min=', -226.09934997558594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -226.0172119140625)
('rgb.max=', 135.81986999511719, 'rgb.min=', -225.89912414550781)
('rgb.max=', 135.85574340820312, 'rgb.min=', -225.95263671875)
('rgb.max=', 135.58544921875, 'rgb.min=', -226.10760498046875)
('rgb.max=', 135.93272399902344, 'rgb.min=', -226.12449645996094)
('rgb.max=', 135.74652099609375, 'rgb.min=', -225.83197021484375)
('rgb.max=', 135.69892883300781, 'rgb.min=', -226.013427734375)
('rgb.max=', 135.76838684082031, 'rgb.min=', -226.36140441894531)
('rgb.max=', 136.32817077636719, 'rgb.min=', -225.757080078125)
('rgb.max=', 135.98373413085938, 'rgb.min=', -226.18232727050781)
('rgb.max=', 135.67037963867188, 'rgb.min=', -225.89944458007812)
('rgb.max=', 135.72334289550781, 'rgb.min=', -226.08509826660156)
('rgb.max=', 136.02011108398438, 'rgb.min=', -226.21844482421875)
('rgb.max=', 136.027099609375, 'rgb.min=', -226.07560729980469)
('rgb.max=', 136.00848388671875, 'rgb.min=', -226.05368041992188)
('rgb.max=', 135.7598876953125, 'rgb.min=', -226.02740478515625)
('rgb.max=', 135.88836669921875, 'rgb.min=', -226.27995300292969)
('rgb.max=', 135.962890625, 'rgb.min=', -226.10844421386719)
('rgb.max=', 135.86561584472656, 'rgb.min=', -225.75755310058594)
('rgb.max=', 136.10421752929688, 'rgb.min=', -226.04995727539062)
('rgb.max=', 136.22048950195312, 'rgb.min=', -226.09086608886719)
('rgb.max=', 136.04556274414062, 'rgb.min=', -225.77027893066406)
('rgb.max=', 135.76312255859375, 'rgb.min=', -226.12484741210938)
('rgb.max=', 135.94378662109375, 'rgb.min=', -225.93304443359375)
('rgb.max=', 135.97700500488281, 'rgb.min=', -225.57159423828125)
('rgb.max=', 135.84588623046875, 'rgb.min=', -225.97499084472656)
('rgb.max=', 135.83950805664062, 'rgb.min=', -226.050048828125)
('rgb.max=', 135.98004150390625, 'rgb.min=', -225.98249816894531)
('rgb.max=', 135.98112487792969, 'rgb.min=', -226.22467041015625)
('rgb.max=', 135.88462829589844, 'rgb.min=', -226.10789489746094)
('rgb.max=', 136.00093078613281, 'rgb.min=', -225.83721923828125)
('rgb.max=', 135.81192016601562, 'rgb.min=', -225.97615051269531)
('rgb.max=', 135.96589660644531, 'rgb.min=', -226.27810668945312)
('rgb.max=', 135.61654663085938, 'rgb.min=', -225.716552734375)
('rgb.max=', 135.84346008300781, 'rgb.min=', -225.98574829101562)
('rgb.max=', 135.78971862792969, 'rgb.min=', -226.25936889648438)
('rgb.max=', 135.85296630859375, 'rgb.min=', -226.39813232421875)
('rgb.max=', 135.75555419921875, 'rgb.min=', -225.91294860839844)
('rgb.max=', 135.80625915527344, 'rgb.min=', -225.75506591796875)
('rgb.max=', 136.08938598632812, 'rgb.min=', -225.84516906738281)
('rgb.max=', 135.89314270019531, 'rgb.min=', -225.95536804199219)
('rgb.max=', 135.9874267578125, 'rgb.min=', -226.44577026367188)
('rgb.max=', 135.78230285644531, 'rgb.min=', -226.09700012207031)
('rgb.max=', 135.93452453613281, 'rgb.min=', -225.97109985351562)
('rgb.max=', 135.89523315429688, 'rgb.min=', -226.10894775390625)
('rgb.max=', 135.73666381835938, 'rgb.min=', -225.96327209472656)
('rgb.max=', 135.92300415039062, 'rgb.min=', -225.83851623535156)
('rgb.max=', 135.90205383300781, 'rgb.min=', -225.9232177734375)
('rgb.max=', 135.90449523925781, 'rgb.min=', -225.86299133300781)
('rgb.max=', 136.14036560058594, 'rgb.min=', -226.02566528320312)
('rgb.max=', 135.96820068359375, 'rgb.min=', -226.10791015625)
('rgb.max=', 135.96975708007812, 'rgb.min=', -226.01882934570312)
('rgb.max=', 136.10162353515625, 'rgb.min=', -225.97283935546875)
('rgb.max=', 135.91937255859375, 'rgb.min=', -225.93289184570312)
('rgb.max=', 135.97259521484375, 'rgb.min=', -225.9718017578125)
('rgb.max=', 136.1387939453125, 'rgb.min=', -225.9111328125)
('rgb.max=', 135.94012451171875, 'rgb.min=', -225.79962158203125)
('rgb.max=', 135.91455078125, 'rgb.min=', -225.77865600585938)
('rgb.max=', 135.86288452148438, 'rgb.min=', -226.02912902832031)
('rgb.max=', 135.84098815917969, 'rgb.min=', -226.38693237304688)
('rgb.max=', 135.64347839355469, 'rgb.min=', -225.97880554199219)
('rgb.max=', 135.90495300292969, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.79945373535156, 'rgb.min=', -225.90997314453125)
('rgb.max=', 136.03350830078125, 'rgb.min=', -225.84512329101562)
('rgb.max=', 136.00114440917969, 'rgb.min=', -226.07264709472656)
('rgb.max=', 136.27133178710938, 'rgb.min=', -226.07820129394531)
('rgb.max=', 135.81459045410156, 'rgb.min=', -225.91122436523438)
('rgb.max=', 135.88070678710938, 'rgb.min=', -225.95625305175781)
('rgb.max=', 135.84471130371094, 'rgb.min=', -225.83985900878906)
('rgb.max=', 135.93748474121094, 'rgb.min=', -226.13990783691406)
('rgb.max=', 135.85154724121094, 'rgb.min=', -225.81455993652344)
('rgb.max=', 136.12825012207031, 'rgb.min=', -225.9522705078125)
('rgb.max=', 135.63883972167969, 'rgb.min=', -226.05665588378906)
('rgb.max=', 135.95196533203125, 'rgb.min=', -226.09120178222656)
('rgb.max=', 136.06239318847656, 'rgb.min=', -225.72554016113281)
('rgb.max=', 135.74507141113281, 'rgb.min=', -226.08343505859375)
('rgb.max=', 135.95700073242188, 'rgb.min=', -225.93275451660156)
('rgb.max=', 136.12539672851562, 'rgb.min=', -225.86991882324219)
('rgb.max=', 136.02786254882812, 'rgb.min=', -225.82106018066406)
('rgb.max=', 135.68649291992188, 'rgb.min=', -226.07136535644531)
('rgb.max=', 135.86593627929688, 'rgb.min=', -226.19282531738281)
('rgb.max=', 135.91554260253906, 'rgb.min=', -225.89559936523438)
('rgb.max=', 135.80609130859375, 'rgb.min=', -226.03358459472656)
('rgb.max=', 135.92144775390625, 'rgb.min=', -225.94535827636719)
('rgb.max=', 135.89913940429688, 'rgb.min=', -225.86360168457031)
('rgb.max=', 136.09773254394531, 'rgb.min=', -225.91642761230469)
('rgb.max=', 135.72659301757812, 'rgb.min=', -226.14151000976562)
('rgb.max=', 136.1685791015625, 'rgb.min=', -225.89643859863281)
('rgb.max=', 135.94595336914062, 'rgb.min=', -226.03837585449219)
('rgb.max=', 136.16035461425781, 'rgb.min=', -225.84577941894531)
('rgb.max=', 135.86798095703125, 'rgb.min=', -225.83334350585938)
('rgb.max=', 136.09355163574219, 'rgb.min=', -225.99160766601562)
('rgb.max=', 136.11117553710938, 'rgb.min=', -226.07833862304688)
('rgb.max=', 136.09230041503906, 'rgb.min=', -225.83969116210938)
('rgb.max=', 135.80522155761719, 'rgb.min=', -225.82562255859375)
('rgb.max=', 135.95352172851562, 'rgb.min=', -225.8306884765625)
('rgb.max=', 135.96943664550781, 'rgb.min=', -226.12437438964844)
('rgb.max=', 136.00180053710938, 'rgb.min=', -226.04351806640625)
('rgb.max=', 135.89045715332031, 'rgb.min=', -225.95500183105469)
('rgb.max=', 135.861083984375, 'rgb.min=', -225.79154968261719)
('rgb.max=', 136.14459228515625, 'rgb.min=', -226.03153991699219)
('rgb.max=', 135.86344909667969, 'rgb.min=', -225.83122253417969)
('rgb.max=', 135.77401733398438, 'rgb.min=', -226.25276184082031)
('rgb.max=', 135.69610595703125, 'rgb.min=', -225.78407287597656)
('rgb.max=', 135.85862731933594, 'rgb.min=', -225.74465942382812)
('rgb.max=', 135.93035888671875, 'rgb.min=', -226.10894775390625)
('rgb.max=', 135.91888427734375, 'rgb.min=', -225.95150756835938)
('rgb.max=', 135.7650146484375, 'rgb.min=', -225.93511962890625)
('rgb.max=', 136.17816162109375, 'rgb.min=', -226.06356811523438)
('rgb.max=', 136.02447509765625, 'rgb.min=', -225.76043701171875)
('rgb.max=', 136.00950622558594, 'rgb.min=', -226.03030395507812)
('rgb.max=', 135.65017700195312, 'rgb.min=', -225.86834716796875)
('rgb.max=', 136.14675903320312, 'rgb.min=', -226.12315368652344)
('rgb.max=', 136.01773071289062, 'rgb.min=', -226.02839660644531)
('rgb.max=', 135.78305053710938, 'rgb.min=', -226.01699829101562)
('rgb.max=', 136.06520080566406, 'rgb.min=', -225.96670532226562)
('rgb.max=', 135.99443054199219, 'rgb.min=', -226.01170349121094)
('rgb.max=', 135.99749755859375, 'rgb.min=', -225.94511413574219)
('rgb.max=', 135.92086791992188, 'rgb.min=', -226.03919982910156)
('rgb.max=', 136.09368896484375, 'rgb.min=', -226.14334106445312)
('rgb.max=', 136.02877807617188, 'rgb.min=', -226.03114318847656)
('rgb.max=', 135.80986022949219, 'rgb.min=', -226.06179809570312)
('rgb.max=', 135.74929809570312, 'rgb.min=', -226.01248168945312)
('rgb.max=', 135.79722595214844, 'rgb.min=', -225.76921081542969)
('rgb.max=', 135.90335083007812, 'rgb.min=', -226.24356079101562)
('rgb.max=', 136.10484313964844, 'rgb.min=', -226.0615234375)
('rgb.max=', 135.95753479003906, 'rgb.min=', -225.97222900390625)
('rgb.max=', 136.09002685546875, 'rgb.min=', -225.75108337402344)
('rgb.max=', 136.20391845703125, 'rgb.min=', -225.89472961425781)
('rgb.max=', 135.94821166992188, 'rgb.min=', -226.0230712890625)
('rgb.max=', 135.86900329589844, 'rgb.min=', -225.97712707519531)
('rgb.max=', 135.89781188964844, 'rgb.min=', -226.00868225097656)
('rgb.max=', 136.15220642089844, 'rgb.min=', -225.49516296386719)
('rgb.max=', 136.00045776367188, 'rgb.min=', -225.98384094238281)
('rgb.max=', 136.03231811523438, 'rgb.min=', -226.35574340820312)
('rgb.max=', 135.56642150878906, 'rgb.min=', -225.85560607910156)
('rgb.max=', 135.9012451171875, 'rgb.min=', -225.68486022949219)
('rgb.max=', 135.92036437988281, 'rgb.min=', -226.01785278320312)
('rgb.max=', 135.79290771484375, 'rgb.min=', -226.09764099121094)
('rgb.max=', 136.14814758300781, 'rgb.min=', -225.66694641113281)
('rgb.max=', 135.61343383789062, 'rgb.min=', -225.85118103027344)
('rgb.max=', 136.04293823242188, 'rgb.min=', -226.29879760742188)
('rgb.max=', 135.85859680175781, 'rgb.min=', -226.02249145507812)
('rgb.max=', 135.978515625, 'rgb.min=', -225.80253601074219)
('rgb.max=', 135.90322875976562, 'rgb.min=', -226.06268310546875)
('rgb.max=', 136.00872802734375, 'rgb.min=', -225.97555541992188)
('rgb.max=', 135.87429809570312, 'rgb.min=', -226.17831420898438)
('rgb.max=', 135.99345397949219, 'rgb.min=', -225.90461730957031)
('rgb.max=', 136.03071594238281, 'rgb.min=', -226.05047607421875)
('rgb.max=', 135.9432373046875, 'rgb.min=', -226.10450744628906)
('rgb.max=', 136.073486328125, 'rgb.min=', -226.09588623046875)
('rgb.max=', 135.81916809082031, 'rgb.min=', -225.84542846679688)
('rgb.max=', 136.13923645019531, 'rgb.min=', -225.85610961914062)
('rgb.max=', 136.01457214355469, 'rgb.min=', -225.78370666503906)
('rgb.max=', 136.03581237792969, 'rgb.min=', -225.91357421875)
('rgb.max=', 135.83840942382812, 'rgb.min=', -226.07647705078125)
('rgb.max=', 135.93855285644531, 'rgb.min=', -225.87493896484375)
('rgb.max=', 136.13905334472656, 'rgb.min=', -226.01101684570312)
('rgb.max=', 135.86752319335938, 'rgb.min=', -225.770751953125)
('rgb.max=', 135.98171997070312, 'rgb.min=', -225.87178039550781)
('rgb.max=', 136.08526611328125, 'rgb.min=', -225.90530395507812)
('rgb.max=', 135.87509155273438, 'rgb.min=', -225.96336364746094)
('rgb.max=', 136.00849914550781, 'rgb.min=', -226.14875793457031)
('rgb.max=', 135.68490600585938, 'rgb.min=', -225.952880859375)
('rgb.max=', 135.87255859375, 'rgb.min=', -225.92193603515625)
('rgb.max=', 135.80393981933594, 'rgb.min=', -225.88522338867188)
('rgb.max=', 136.0413818359375, 'rgb.min=', -226.03700256347656)
('rgb.max=', 135.95347595214844, 'rgb.min=', -225.87838745117188)
('rgb.max=', 135.86553955078125, 'rgb.min=', -226.06719970703125)
('rgb.max=', 136.07090759277344, 'rgb.min=', -225.7459716796875)
('rgb.max=', 135.9410400390625, 'rgb.min=', -226.15219116210938)
('rgb.max=', 135.9578857421875, 'rgb.min=', -225.82763671875)
('rgb.max=', 135.72052001953125, 'rgb.min=', -225.93988037109375)
('rgb.max=', 135.66712951660156, 'rgb.min=', -225.83297729492188)
('rgb.max=', 135.86984252929688, 'rgb.min=', -226.13510131835938)
('rgb.max=', 135.93019104003906, 'rgb.min=', -226.22831726074219)
('rgb.max=', 135.69731140136719, 'rgb.min=', -225.94635009765625)
('rgb.max=', 135.79266357421875, 'rgb.min=', -225.96513366699219)
('rgb.max=', 135.962890625, 'rgb.min=', -226.16651916503906)
('rgb.max=', 136.14096069335938, 'rgb.min=', -226.15080261230469)
('rgb.max=', 135.92665100097656, 'rgb.min=', -226.30203247070312)
('rgb.max=', 136.14042663574219, 'rgb.min=', -225.9915771484375)
('rgb.max=', 136.01882934570312, 'rgb.min=', -225.72714233398438)
('rgb.max=', 136.09468078613281, 'rgb.min=', -226.10231018066406)
('rgb.max=', 135.96296691894531, 'rgb.min=', -226.06236267089844)
('rgb.max=', 136.11357116699219, 'rgb.min=', -226.12123107910156)
('rgb.max=', 135.66079711914062, 'rgb.min=', -225.95437622070312)
('rgb.max=', 135.96044921875, 'rgb.min=', -226.05471801757812)
('rgb.max=', 136.00306701660156, 'rgb.min=', -225.9818115234375)
('rgb.max=', 136.11514282226562, 'rgb.min=', -225.86674499511719)
('rgb.max=', 136.04573059082031, 'rgb.min=', -226.18185424804688)
('rgb.max=', 135.80218505859375, 'rgb.min=', -225.8662109375)
('rgb.max=', 135.90505981445312, 'rgb.min=', -225.86102294921875)
('rgb.max=', 135.6707763671875, 'rgb.min=', -226.27531433105469)
('rgb.max=', 135.72239685058594, 'rgb.min=', -225.97601318359375)
('rgb.max=', 135.8421630859375, 'rgb.min=', -226.13809204101562)
('rgb.max=', 135.89778137207031, 'rgb.min=', -225.90963745117188)
('rgb.max=', 135.91751098632812, 'rgb.min=', -225.99734497070312)
('rgb.max=', 135.98735046386719, 'rgb.min=', -226.09358215332031)
('rgb.max=', 135.91633605957031, 'rgb.min=', -225.92253112792969)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.310279')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6941 ', 'GAN acc 0.5039', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5293', 'Total loss: 1.3873', 'for batch', 0)
('GAN loss 0.6980 ', 'GAN acc 0.4688', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3909', 'for batch', 1)
('GAN loss 0.6931 ', 'GAN acc 0.5234', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4590', 'Total loss: 1.3919', 'for batch', 2)
('GAN loss 0.6924 ', 'GAN acc 0.4961', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5156', 'Total loss: 1.3836', 'for batch', 3)
('GAN loss 0.6902 ', 'GAN acc 0.5469', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3861', 'for batch', 4)
('GAN loss 0.6875 ', 'GAN acc 0.5312', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5000', 'Total loss: 1.3783', 'for batch', 5)
('GAN loss 0.6870 ', 'GAN acc 0.5820', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4922', 'Total loss: 1.3819', 'for batch', 6)
('GAN loss 0.6859 ', 'GAN acc 0.5859', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4629', 'Total loss: 1.3843', 'for batch', 7)
('GAN loss 0.6820 ', 'GAN acc 0.6016', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4922', 'Total loss: 1.3760', 'for batch', 8)
('GAN loss 0.6890 ', 'GAN acc 0.5391', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5293', 'Total loss: 1.3825', 'for batch', 9)
('GAN loss 0.6948 ', 'GAN acc 0.4805', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4941', 'Total loss: 1.3885', 'for batch', 10)
('GAN loss 0.6874 ', 'GAN acc 0.5391', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4648', 'Total loss: 1.3853', 'for batch', 11)
('GAN loss 0.6867 ', 'GAN acc 0.5625', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5117', 'Total loss: 1.3810', 'for batch', 12)
('GAN loss 0.6933 ', 'GAN acc 0.5000', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5156', 'Total loss: 1.3871', 'for batch', 13)
('GAN loss 0.6932 ', 'GAN acc 0.5156', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5332', 'Total loss: 1.3837', 'for batch', 14)
('GAN loss 0.6886 ', 'GAN acc 0.5234', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3839', 'for batch', 15)
('GAN loss 0.6987 ', 'GAN acc 0.4609', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4902', 'Total loss: 1.3944', 'for batch', 16)
('GAN loss 0.6976 ', 'GAN acc 0.4570', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4551', 'Total loss: 1.3947', 'for batch', 17)
('GAN loss 0.7004 ', 'GAN acc 0.4531', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5078', 'Total loss: 1.3926', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52027321)
('DISCRIMINATOR_Imagem FAKE=', 0.51969409)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 135.99116516113281, 'rgb.min=', -225.76654052734375)
('rgb.max=', 135.90811157226562, 'rgb.min=', -226.02597045898438)
('rgb.max=', 136.12591552734375, 'rgb.min=', -225.92425537109375)
('rgb.max=', 135.98152160644531, 'rgb.min=', -226.05485534667969)
('rgb.max=', 136.10223388671875, 'rgb.min=', -225.92985534667969)
('rgb.max=', 136.17390441894531, 'rgb.min=', -226.51997375488281)
('rgb.max=', 135.83589172363281, 'rgb.min=', -226.14399719238281)
('rgb.max=', 135.94679260253906, 'rgb.min=', -225.93391418457031)
('rgb.max=', 135.855712890625, 'rgb.min=', -226.16519165039062)
('rgb.max=', 135.8001708984375, 'rgb.min=', -226.01258850097656)
('rgb.max=', 135.69273376464844, 'rgb.min=', -226.143310546875)
('rgb.max=', 135.844970703125, 'rgb.min=', -226.0648193359375)
('rgb.max=', 135.77064514160156, 'rgb.min=', -226.05314636230469)
('rgb.max=', 135.94674682617188, 'rgb.min=', -226.09390258789062)
('rgb.max=', 135.80397033691406, 'rgb.min=', -225.964599609375)
('rgb.max=', 135.77224731445312, 'rgb.min=', -226.05668640136719)
('rgb.max=', 135.82611083984375, 'rgb.min=', -225.95315551757812)
('rgb.max=', 135.90713500976562, 'rgb.min=', -225.83351135253906)
('rgb.max=', 135.90348815917969, 'rgb.min=', -226.09867858886719)
('rgb.max=', 135.95118713378906, 'rgb.min=', -226.3104248046875)
('rgb.max=', 136.04995727539062, 'rgb.min=', -225.91777038574219)
('rgb.max=', 136.14840698242188, 'rgb.min=', -225.91069030761719)
('rgb.max=', 136.125732421875, 'rgb.min=', -225.83871459960938)
('rgb.max=', 135.93080139160156, 'rgb.min=', -225.68447875976562)
('rgb.max=', 135.77470397949219, 'rgb.min=', -225.99960327148438)
('rgb.max=', 136.103515625, 'rgb.min=', -225.95150756835938)
('rgb.max=', 136.06440734863281, 'rgb.min=', -226.05036926269531)
('rgb.max=', 135.8333740234375, 'rgb.min=', -225.87422180175781)
('rgb.max=', 135.8948974609375, 'rgb.min=', -225.83903503417969)
('rgb.max=', 135.86970520019531, 'rgb.min=', -226.00985717773438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -226.07643127441406)
('rgb.max=', 135.85264587402344, 'rgb.min=', -225.94332885742188)
('rgb.max=', 135.99795532226562, 'rgb.min=', -226.08290100097656)
('rgb.max=', 135.88261413574219, 'rgb.min=', -226.0516357421875)
('rgb.max=', 135.8587646484375, 'rgb.min=', -226.03765869140625)
('rgb.max=', 136.11190795898438, 'rgb.min=', -225.93740844726562)
('rgb.max=', 136.12081909179688, 'rgb.min=', -225.98374938964844)
('rgb.max=', 136.07852172851562, 'rgb.min=', -226.12434387207031)
('rgb.max=', 135.95596313476562, 'rgb.min=', -225.92585754394531)
('rgb.max=', 135.94874572753906, 'rgb.min=', -226.00375366210938)
('rgb.max=', 135.72360229492188, 'rgb.min=', -225.86698913574219)
('rgb.max=', 135.95111083984375, 'rgb.min=', -226.09104919433594)
('rgb.max=', 135.905517578125, 'rgb.min=', -226.01377868652344)
('rgb.max=', 135.87384033203125, 'rgb.min=', -226.01307678222656)
('rgb.max=', 135.98313903808594, 'rgb.min=', -226.37139892578125)
('rgb.max=', 135.57682800292969, 'rgb.min=', -225.8787841796875)
('rgb.max=', 135.93559265136719, 'rgb.min=', -225.91401672363281)
('rgb.max=', 135.77116394042969, 'rgb.min=', -225.74063110351562)
('rgb.max=', 135.8704833984375, 'rgb.min=', -225.94808959960938)
('rgb.max=', 136.14677429199219, 'rgb.min=', -226.19631958007812)
('rgb.max=', 135.99967956542969, 'rgb.min=', -226.10903930664062)
('rgb.max=', 136.17861938476562, 'rgb.min=', -225.99313354492188)
('rgb.max=', 135.68157958984375, 'rgb.min=', -225.99699401855469)
('rgb.max=', 135.84339904785156, 'rgb.min=', -225.99444580078125)
('rgb.max=', 136.091796875, 'rgb.min=', -225.99246215820312)
('rgb.max=', 136.03617858886719, 'rgb.min=', -226.04876708984375)
('rgb.max=', 135.90388488769531, 'rgb.min=', -226.02168273925781)
('rgb.max=', 135.81442260742188, 'rgb.min=', -225.8984375)
('rgb.max=', 135.85578918457031, 'rgb.min=', -225.93501281738281)
('rgb.max=', 135.57998657226562, 'rgb.min=', -226.0819091796875)
('rgb.max=', 135.95578002929688, 'rgb.min=', -226.10121154785156)
('rgb.max=', 135.74952697753906, 'rgb.min=', -225.78831481933594)
('rgb.max=', 135.67807006835938, 'rgb.min=', -226.06169128417969)
('rgb.max=', 135.75289916992188, 'rgb.min=', -226.28262329101562)
('rgb.max=', 136.31965637207031, 'rgb.min=', -225.74192810058594)
('rgb.max=', 135.96939086914062, 'rgb.min=', -226.10250854492188)
('rgb.max=', 135.66690063476562, 'rgb.min=', -225.87208557128906)
('rgb.max=', 135.71420288085938, 'rgb.min=', -226.10737609863281)
('rgb.max=', 136.021484375, 'rgb.min=', -226.17610168457031)
('rgb.max=', 135.99945068359375, 'rgb.min=', -226.10879516601562)
('rgb.max=', 135.9791259765625, 'rgb.min=', -226.11692810058594)
('rgb.max=', 135.745361328125, 'rgb.min=', -226.05546569824219)
('rgb.max=', 135.88194274902344, 'rgb.min=', -226.20352172851562)
('rgb.max=', 135.95314025878906, 'rgb.min=', -226.10690307617188)
('rgb.max=', 135.87188720703125, 'rgb.min=', -225.74272155761719)
('rgb.max=', 136.08824157714844, 'rgb.min=', -226.00569152832031)
('rgb.max=', 136.22158813476562, 'rgb.min=', -226.20179748535156)
('rgb.max=', 136.04629516601562, 'rgb.min=', -225.76348876953125)
('rgb.max=', 135.75123596191406, 'rgb.min=', -226.05014038085938)
('rgb.max=', 135.92900085449219, 'rgb.min=', -225.88227844238281)
('rgb.max=', 135.97744750976562, 'rgb.min=', -225.57452392578125)
('rgb.max=', 135.83320617675781, 'rgb.min=', -225.9632568359375)
('rgb.max=', 135.81294250488281, 'rgb.min=', -225.97512817382812)
('rgb.max=', 135.96609497070312, 'rgb.min=', -225.97674560546875)
('rgb.max=', 135.97482299804688, 'rgb.min=', -226.21919250488281)
('rgb.max=', 135.87106323242188, 'rgb.min=', -226.03314208984375)
('rgb.max=', 136.00616455078125, 'rgb.min=', -225.803466796875)
('rgb.max=', 135.77388000488281, 'rgb.min=', -225.92254638671875)
('rgb.max=', 135.96527099609375, 'rgb.min=', -226.19287109375)
('rgb.max=', 135.60737609863281, 'rgb.min=', -225.68132019042969)
('rgb.max=', 135.83665466308594, 'rgb.min=', -226.00056457519531)
('rgb.max=', 135.7720947265625, 'rgb.min=', -226.17401123046875)
('rgb.max=', 135.84149169921875, 'rgb.min=', -226.30880737304688)
('rgb.max=', 135.73611450195312, 'rgb.min=', -225.89457702636719)
('rgb.max=', 135.78042602539062, 'rgb.min=', -225.73387145996094)
('rgb.max=', 136.09303283691406, 'rgb.min=', -225.81504821777344)
('rgb.max=', 135.86863708496094, 'rgb.min=', -225.90994262695312)
('rgb.max=', 135.98004150390625, 'rgb.min=', -226.35873413085938)
('rgb.max=', 135.77572631835938, 'rgb.min=', -226.12443542480469)
('rgb.max=', 135.9268798828125, 'rgb.min=', -225.98844909667969)
('rgb.max=', 135.880126953125, 'rgb.min=', -226.12818908691406)
('rgb.max=', 135.7271728515625, 'rgb.min=', -225.90495300292969)
('rgb.max=', 135.92585754394531, 'rgb.min=', -225.823486328125)
('rgb.max=', 135.88336181640625, 'rgb.min=', -225.9305419921875)
('rgb.max=', 135.90261840820312, 'rgb.min=', -225.82350158691406)
('rgb.max=', 136.14790344238281, 'rgb.min=', -226.07225036621094)
('rgb.max=', 135.94377136230469, 'rgb.min=', -226.040283203125)
('rgb.max=', 135.94781494140625, 'rgb.min=', -226.07887268066406)
('rgb.max=', 136.098876953125, 'rgb.min=', -225.97454833984375)
('rgb.max=', 135.92535400390625, 'rgb.min=', -225.90669250488281)
('rgb.max=', 135.95468139648438, 'rgb.min=', -225.96751403808594)
('rgb.max=', 136.15513610839844, 'rgb.min=', -225.91270446777344)
('rgb.max=', 135.93177795410156, 'rgb.min=', -225.77389526367188)
('rgb.max=', 135.91081237792969, 'rgb.min=', -225.74708557128906)
('rgb.max=', 135.85664367675781, 'rgb.min=', -226.01695251464844)
('rgb.max=', 135.83047485351562, 'rgb.min=', -226.3125)
('rgb.max=', 135.61581420898438, 'rgb.min=', -226.01850891113281)
('rgb.max=', 135.90060424804688, 'rgb.min=', -225.77859497070312)
('rgb.max=', 135.7923583984375, 'rgb.min=', -225.86921691894531)
('rgb.max=', 136.0318603515625, 'rgb.min=', -225.85585021972656)
('rgb.max=', 135.97952270507812, 'rgb.min=', -226.10427856445312)
('rgb.max=', 136.26092529296875, 'rgb.min=', -226.04986572265625)
('rgb.max=', 135.80654907226562, 'rgb.min=', -225.90249633789062)
('rgb.max=', 135.86618041992188, 'rgb.min=', -225.93415832519531)
('rgb.max=', 135.81622314453125, 'rgb.min=', -225.80003356933594)
('rgb.max=', 135.95730590820312, 'rgb.min=', -226.07215881347656)
('rgb.max=', 135.84408569335938, 'rgb.min=', -225.74850463867188)
('rgb.max=', 136.13389587402344, 'rgb.min=', -225.94117736816406)
('rgb.max=', 135.63516235351562, 'rgb.min=', -226.02056884765625)
('rgb.max=', 135.94706726074219, 'rgb.min=', -226.05499267578125)
('rgb.max=', 136.02456665039062, 'rgb.min=', -225.7303466796875)
('rgb.max=', 135.7362060546875, 'rgb.min=', -226.07505798339844)
('rgb.max=', 135.93817138671875, 'rgb.min=', -225.94876098632812)
('rgb.max=', 136.10939025878906, 'rgb.min=', -225.92031860351562)
('rgb.max=', 136.02680969238281, 'rgb.min=', -225.80940246582031)
('rgb.max=', 135.68304443359375, 'rgb.min=', -226.13493347167969)
('rgb.max=', 135.86216735839844, 'rgb.min=', -226.09652709960938)
('rgb.max=', 135.92066955566406, 'rgb.min=', -225.84083557128906)
('rgb.max=', 135.80491638183594, 'rgb.min=', -226.02366638183594)
('rgb.max=', 135.927001953125, 'rgb.min=', -225.91917419433594)
('rgb.max=', 135.86726379394531, 'rgb.min=', -225.83689880371094)
('rgb.max=', 136.07843017578125, 'rgb.min=', -225.89982604980469)
('rgb.max=', 135.72805786132812, 'rgb.min=', -226.07369995117188)
('rgb.max=', 136.15335083007812, 'rgb.min=', -225.90740966796875)
('rgb.max=', 135.94154357910156, 'rgb.min=', -226.0535888671875)
('rgb.max=', 136.13442993164062, 'rgb.min=', -225.79994201660156)
('rgb.max=', 135.87611389160156, 'rgb.min=', -225.835205078125)
('rgb.max=', 136.10047912597656, 'rgb.min=', -226.03912353515625)
('rgb.max=', 136.08003234863281, 'rgb.min=', -226.02261352539062)
('rgb.max=', 136.10179138183594, 'rgb.min=', -225.82514953613281)
('rgb.max=', 135.79766845703125, 'rgb.min=', -225.81538391113281)
('rgb.max=', 135.93206787109375, 'rgb.min=', -225.79705810546875)
('rgb.max=', 135.97018432617188, 'rgb.min=', -226.24000549316406)
('rgb.max=', 136.0174560546875, 'rgb.min=', -226.06159973144531)
('rgb.max=', 135.89054870605469, 'rgb.min=', -225.9442138671875)
('rgb.max=', 135.85722351074219, 'rgb.min=', -225.75578308105469)
('rgb.max=', 136.09873962402344, 'rgb.min=', -226.0360107421875)
('rgb.max=', 135.87255859375, 'rgb.min=', -225.80670166015625)
('rgb.max=', 135.77064514160156, 'rgb.min=', -226.15994262695312)
('rgb.max=', 135.69732666015625, 'rgb.min=', -225.75630187988281)
('rgb.max=', 135.85447692871094, 'rgb.min=', -225.72868347167969)
('rgb.max=', 135.92922973632812, 'rgb.min=', -226.04191589355469)
('rgb.max=', 135.89910888671875, 'rgb.min=', -225.93069458007812)
('rgb.max=', 135.73475646972656, 'rgb.min=', -225.92787170410156)
('rgb.max=', 136.17726135253906, 'rgb.min=', -226.03703308105469)
('rgb.max=', 136.02986145019531, 'rgb.min=', -225.73289489746094)
('rgb.max=', 136.01527404785156, 'rgb.min=', -226.11384582519531)
('rgb.max=', 135.62625122070312, 'rgb.min=', -225.86151123046875)
('rgb.max=', 136.16604614257812, 'rgb.min=', -226.06724548339844)
('rgb.max=', 136.01693725585938, 'rgb.min=', -225.99581909179688)
('rgb.max=', 135.77322387695312, 'rgb.min=', -225.99307250976562)
('rgb.max=', 136.05389404296875, 'rgb.min=', -225.94094848632812)
('rgb.max=', 135.99957275390625, 'rgb.min=', -225.96922302246094)
('rgb.max=', 135.99665832519531, 'rgb.min=', -226.01055908203125)
('rgb.max=', 135.9173583984375, 'rgb.min=', -225.98304748535156)
('rgb.max=', 136.08566284179688, 'rgb.min=', -226.08831787109375)
('rgb.max=', 136.00189208984375, 'rgb.min=', -226.07183837890625)
('rgb.max=', 135.80632019042969, 'rgb.min=', -226.07057189941406)
('rgb.max=', 135.74571228027344, 'rgb.min=', -225.99229431152344)
('rgb.max=', 135.77024841308594, 'rgb.min=', -225.74143981933594)
('rgb.max=', 135.86630249023438, 'rgb.min=', -226.16842651367188)
('rgb.max=', 136.0906982421875, 'rgb.min=', -225.99456787109375)
('rgb.max=', 135.95411682128906, 'rgb.min=', -225.93746948242188)
('rgb.max=', 136.08299255371094, 'rgb.min=', -225.73701477050781)
('rgb.max=', 136.21025085449219, 'rgb.min=', -225.85429382324219)
('rgb.max=', 135.93403625488281, 'rgb.min=', -226.00979614257812)
('rgb.max=', 135.86219787597656, 'rgb.min=', -225.97041320800781)
('rgb.max=', 135.89361572265625, 'rgb.min=', -225.92919921875)
('rgb.max=', 136.16317749023438, 'rgb.min=', -225.51087951660156)
('rgb.max=', 136.00527954101562, 'rgb.min=', -226.03858947753906)
('rgb.max=', 136.02224731445312, 'rgb.min=', -226.27638244628906)
('rgb.max=', 135.55029296875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.90855407714844, 'rgb.min=', -225.66349792480469)
('rgb.max=', 135.91114807128906, 'rgb.min=', -226.03038024902344)
('rgb.max=', 135.78045654296875, 'rgb.min=', -226.11691284179688)
('rgb.max=', 136.14776611328125, 'rgb.min=', -225.68148803710938)
('rgb.max=', 135.61373901367188, 'rgb.min=', -225.84342956542969)
('rgb.max=', 136.08805847167969, 'rgb.min=', -226.23469543457031)
('rgb.max=', 135.85446166992188, 'rgb.min=', -226.06581115722656)
('rgb.max=', 136.01742553710938, 'rgb.min=', -225.77590942382812)
('rgb.max=', 135.89814758300781, 'rgb.min=', -226.04364013671875)
('rgb.max=', 136.0341796875, 'rgb.min=', -225.93019104003906)
('rgb.max=', 135.87405395507812, 'rgb.min=', -226.190185546875)
('rgb.max=', 135.97967529296875, 'rgb.min=', -225.89468383789062)
('rgb.max=', 136.02900695800781, 'rgb.min=', -226.03707885742188)
('rgb.max=', 135.9268798828125, 'rgb.min=', -226.127685546875)
('rgb.max=', 136.11882019042969, 'rgb.min=', -226.09573364257812)
('rgb.max=', 135.77674865722656, 'rgb.min=', -225.81849670410156)
('rgb.max=', 136.12649536132812, 'rgb.min=', -225.79995727539062)
('rgb.max=', 136.06698608398438, 'rgb.min=', -225.76133728027344)
('rgb.max=', 136.03579711914062, 'rgb.min=', -225.90953063964844)
('rgb.max=', 135.81929016113281, 'rgb.min=', -226.09480285644531)
('rgb.max=', 135.91180419921875, 'rgb.min=', -225.8680419921875)
('rgb.max=', 136.13192749023438, 'rgb.min=', -226.02188110351562)
('rgb.max=', 135.8463134765625, 'rgb.min=', -225.77468872070312)
('rgb.max=', 135.97042846679688, 'rgb.min=', -225.86868286132812)
('rgb.max=', 136.15213012695312, 'rgb.min=', -225.88128662109375)
('rgb.max=', 135.86175537109375, 'rgb.min=', -225.95361328125)
('rgb.max=', 136.00065612792969, 'rgb.min=', -226.14425659179688)
('rgb.max=', 135.68586730957031, 'rgb.min=', -225.90367126464844)
('rgb.max=', 135.86367797851562, 'rgb.min=', -225.93931579589844)
('rgb.max=', 135.800537109375, 'rgb.min=', -225.86898803710938)
('rgb.max=', 136.01756286621094, 'rgb.min=', -226.19137573242188)
('rgb.max=', 136.00283813476562, 'rgb.min=', -225.86259460449219)
('rgb.max=', 135.85333251953125, 'rgb.min=', -226.06221008300781)
('rgb.max=', 136.12396240234375, 'rgb.min=', -225.73252868652344)
('rgb.max=', 135.93205261230469, 'rgb.min=', -226.096435546875)
('rgb.max=', 135.95010375976562, 'rgb.min=', -225.82762145996094)
('rgb.max=', 135.71682739257812, 'rgb.min=', -225.92800903320312)
('rgb.max=', 135.66734313964844, 'rgb.min=', -225.80528259277344)
('rgb.max=', 135.86021423339844, 'rgb.min=', -226.07435607910156)
('rgb.max=', 135.91978454589844, 'rgb.min=', -226.23612976074219)
('rgb.max=', 135.70140075683594, 'rgb.min=', -225.95806884765625)
('rgb.max=', 135.77413940429688, 'rgb.min=', -225.96354675292969)
('rgb.max=', 135.9632568359375, 'rgb.min=', -226.15969848632812)
('rgb.max=', 136.14907836914062, 'rgb.min=', -226.13911437988281)
('rgb.max=', 135.93531799316406, 'rgb.min=', -226.30415344238281)
('rgb.max=', 136.1527099609375, 'rgb.min=', -225.95890808105469)
('rgb.max=', 136.00689697265625, 'rgb.min=', -225.80537414550781)
('rgb.max=', 136.07858276367188, 'rgb.min=', -226.09700012207031)
('rgb.max=', 135.95735168457031, 'rgb.min=', -226.07550048828125)
('rgb.max=', 136.1083984375, 'rgb.min=', -226.08418273925781)
('rgb.max=', 135.65022277832031, 'rgb.min=', -225.94827270507812)
('rgb.max=', 135.95994567871094, 'rgb.min=', -226.12565612792969)
('rgb.max=', 135.99337768554688, 'rgb.min=', -225.93309020996094)
('rgb.max=', 136.11509704589844, 'rgb.min=', -225.85050964355469)
('rgb.max=', 136.054443359375, 'rgb.min=', -226.25520324707031)
('rgb.max=', 135.7803955078125, 'rgb.min=', -225.84332275390625)
('rgb.max=', 135.90225219726562, 'rgb.min=', -225.82911682128906)
('rgb.max=', 135.64749145507812, 'rgb.min=', -226.24618530273438)
('rgb.max=', 135.72262573242188, 'rgb.min=', -225.96890258789062)
('rgb.max=', 135.83370971679688, 'rgb.min=', -226.14080810546875)
('rgb.max=', 135.88909912109375, 'rgb.min=', -225.90713500976562)
('rgb.max=', 135.89419555664062, 'rgb.min=', -225.97714233398438)
('rgb.max=', 135.99192810058594, 'rgb.min=', -226.09440612792969)
('rgb.max=', 135.90667724609375, 'rgb.min=', -225.89199829101562)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.800801')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6955 ', 'GAN acc 0.4805', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4746', 'Total loss: 1.3919', 'for batch', 0)
('GAN loss 0.7020 ', 'GAN acc 0.4609', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4863', 'Total loss: 1.4010', 'for batch', 1)
('GAN loss 0.7035 ', 'GAN acc 0.4219', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5254', 'Total loss: 1.3979', 'for batch', 2)
('GAN loss 0.6968 ', 'GAN acc 0.4609', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5117', 'Total loss: 1.3884', 'for batch', 3)
('GAN loss 0.6957 ', 'GAN acc 0.4844', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5234', 'Total loss: 1.3889', 'for batch', 4)
('GAN loss 0.6925 ', 'GAN acc 0.4922', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4746', 'Total loss: 1.3898', 'for batch', 5)
('GAN loss 0.6865 ', 'GAN acc 0.5820', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5000', 'Total loss: 1.3809', 'for batch', 6)
('GAN loss 0.6853 ', 'GAN acc 0.5898', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4844', 'Total loss: 1.3787', 'for batch', 7)
('GAN loss 0.6844 ', 'GAN acc 0.6328', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4883', 'Total loss: 1.3772', 'for batch', 8)
('GAN loss 0.6813 ', 'GAN acc 0.6250', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4961', 'Total loss: 1.3778', 'for batch', 9)
('GAN loss 0.6876 ', 'GAN acc 0.5508', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4746', 'Total loss: 1.3811', 'for batch', 10)
('GAN loss 0.6901 ', 'GAN acc 0.5391', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5273', 'Total loss: 1.3823', 'for batch', 11)
('GAN loss 0.6884 ', 'GAN acc 0.5977', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3842', 'for batch', 12)
('GAN loss 0.6924 ', 'GAN acc 0.5430', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3862', 'for batch', 13)
('GAN loss 0.6901 ', 'GAN acc 0.5664', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5391', 'Total loss: 1.3832', 'for batch', 14)
('GAN loss 0.6859 ', 'GAN acc 0.6016', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4668', 'Total loss: 1.3818', 'for batch', 15)
('GAN loss 0.6902 ', 'GAN acc 0.5156', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5215', 'Total loss: 1.3816', 'for batch', 16)
('GAN loss 0.6990 ', 'GAN acc 0.4609', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4902', 'Total loss: 1.3949', 'for batch', 17)
('GAN loss 0.6967 ', 'GAN acc 0.4727', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4727', 'Total loss: 1.3940', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51973224)
('DISCRIMINATOR_Imagem FAKE=', 0.52057374)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 135.98622131347656, 'rgb.min=', -225.75663757324219)
('rgb.max=', 135.9212646484375, 'rgb.min=', -226.01560974121094)
('rgb.max=', 136.1173095703125, 'rgb.min=', -225.91923522949219)
('rgb.max=', 135.99046325683594, 'rgb.min=', -226.04263305664062)
('rgb.max=', 136.11517333984375, 'rgb.min=', -225.90141296386719)
('rgb.max=', 136.17027282714844, 'rgb.min=', -226.52937316894531)
('rgb.max=', 135.82730102539062, 'rgb.min=', -226.1263427734375)
('rgb.max=', 135.92625427246094, 'rgb.min=', -225.91329956054688)
('rgb.max=', 135.84469604492188, 'rgb.min=', -226.12721252441406)
('rgb.max=', 135.81242370605469, 'rgb.min=', -225.97964477539062)
('rgb.max=', 135.69212341308594, 'rgb.min=', -226.12763977050781)
('rgb.max=', 135.83795166015625, 'rgb.min=', -226.08329772949219)
('rgb.max=', 135.77426147460938, 'rgb.min=', -226.03903198242188)
('rgb.max=', 135.95458984375, 'rgb.min=', -226.08027648925781)
('rgb.max=', 135.79295349121094, 'rgb.min=', -225.92965698242188)
('rgb.max=', 135.77543640136719, 'rgb.min=', -226.09638977050781)
('rgb.max=', 135.81576538085938, 'rgb.min=', -225.97821044921875)
('rgb.max=', 135.9149169921875, 'rgb.min=', -225.8314208984375)
('rgb.max=', 135.91513061523438, 'rgb.min=', -226.10960388183594)
('rgb.max=', 135.95535278320312, 'rgb.min=', -226.30491638183594)
('rgb.max=', 136.05874633789062, 'rgb.min=', -225.91552734375)
('rgb.max=', 136.11398315429688, 'rgb.min=', -225.90959167480469)
('rgb.max=', 136.12020874023438, 'rgb.min=', -225.77011108398438)
('rgb.max=', 135.93972778320312, 'rgb.min=', -225.64410400390625)
('rgb.max=', 135.7728271484375, 'rgb.min=', -226.0181884765625)
('rgb.max=', 136.08070373535156, 'rgb.min=', -225.96343994140625)
('rgb.max=', 136.0880126953125, 'rgb.min=', -226.06793212890625)
('rgb.max=', 135.8162841796875, 'rgb.min=', -225.83934020996094)
('rgb.max=', 135.90805053710938, 'rgb.min=', -225.79585266113281)
('rgb.max=', 135.87013244628906, 'rgb.min=', -225.9990234375)
('rgb.max=', 135.92767333984375, 'rgb.min=', -225.99435424804688)
('rgb.max=', 135.84332275390625, 'rgb.min=', -225.90336608886719)
('rgb.max=', 136.0130615234375, 'rgb.min=', -226.11143493652344)
('rgb.max=', 135.88771057128906, 'rgb.min=', -226.02879333496094)
('rgb.max=', 135.86343383789062, 'rgb.min=', -226.04875183105469)
('rgb.max=', 136.06028747558594, 'rgb.min=', -225.93418884277344)
('rgb.max=', 136.081298828125, 'rgb.min=', -225.95608520507812)
('rgb.max=', 136.06556701660156, 'rgb.min=', -226.09169006347656)
('rgb.max=', 135.96014404296875, 'rgb.min=', -225.91853332519531)
('rgb.max=', 135.95252990722656, 'rgb.min=', -225.99041748046875)
('rgb.max=', 135.70742797851562, 'rgb.min=', -225.84535217285156)
('rgb.max=', 135.94703674316406, 'rgb.min=', -226.05360412597656)
('rgb.max=', 135.89305114746094, 'rgb.min=', -226.02816772460938)
('rgb.max=', 135.87129211425781, 'rgb.min=', -226.00892639160156)
('rgb.max=', 135.95590209960938, 'rgb.min=', -226.34735107421875)
('rgb.max=', 135.56991577148438, 'rgb.min=', -225.8726806640625)
('rgb.max=', 135.94586181640625, 'rgb.min=', -225.94232177734375)
('rgb.max=', 135.77865600585938, 'rgb.min=', -225.7296142578125)
('rgb.max=', 135.856201171875, 'rgb.min=', -225.92855834960938)
('rgb.max=', 136.11705017089844, 'rgb.min=', -226.09603881835938)
('rgb.max=', 135.981689453125, 'rgb.min=', -226.07725524902344)
('rgb.max=', 136.18386840820312, 'rgb.min=', -225.9718017578125)
('rgb.max=', 135.65740966796875, 'rgb.min=', -225.97315979003906)
('rgb.max=', 135.8123779296875, 'rgb.min=', -225.98033142089844)
('rgb.max=', 136.060546875, 'rgb.min=', -225.9833984375)
('rgb.max=', 136.00921630859375, 'rgb.min=', -226.04409790039062)
('rgb.max=', 135.88401794433594, 'rgb.min=', -226.01101684570312)
('rgb.max=', 135.81478881835938, 'rgb.min=', -225.85910034179688)
('rgb.max=', 135.84780883789062, 'rgb.min=', -225.92626953125)
('rgb.max=', 135.57470703125, 'rgb.min=', -226.0767822265625)
('rgb.max=', 135.93144226074219, 'rgb.min=', -226.11640930175781)
('rgb.max=', 135.7398681640625, 'rgb.min=', -225.76348876953125)
('rgb.max=', 135.67987060546875, 'rgb.min=', -226.11123657226562)
('rgb.max=', 135.75, 'rgb.min=', -226.25086975097656)
('rgb.max=', 136.32548522949219, 'rgb.min=', -225.71672058105469)
('rgb.max=', 135.9573974609375, 'rgb.min=', -226.05082702636719)
('rgb.max=', 135.65814208984375, 'rgb.min=', -225.85382080078125)
('rgb.max=', 135.702880859375, 'rgb.min=', -226.11331176757812)
('rgb.max=', 136.03793334960938, 'rgb.min=', -226.20054626464844)
('rgb.max=', 136.02851867675781, 'rgb.min=', -226.09291076660156)
('rgb.max=', 135.97019958496094, 'rgb.min=', -226.11390686035156)
('rgb.max=', 135.74090576171875, 'rgb.min=', -226.09898376464844)
('rgb.max=', 135.88594055175781, 'rgb.min=', -226.18905639648438)
('rgb.max=', 135.95127868652344, 'rgb.min=', -226.19024658203125)
('rgb.max=', 135.87606811523438, 'rgb.min=', -225.74812316894531)
('rgb.max=', 136.08970642089844, 'rgb.min=', -226.02061462402344)
('rgb.max=', 136.24420166015625, 'rgb.min=', -226.07237243652344)
('rgb.max=', 136.05349731445312, 'rgb.min=', -225.73121643066406)
('rgb.max=', 135.74519348144531, 'rgb.min=', -226.0540771484375)
('rgb.max=', 135.91751098632812, 'rgb.min=', -225.84330749511719)
('rgb.max=', 136.00262451171875, 'rgb.min=', -225.57905578613281)
('rgb.max=', 135.815185546875, 'rgb.min=', -225.94764709472656)
('rgb.max=', 135.81626892089844, 'rgb.min=', -225.95449829101562)
('rgb.max=', 135.97819519042969, 'rgb.min=', -226.00758361816406)
('rgb.max=', 135.97784423828125, 'rgb.min=', -226.24102783203125)
('rgb.max=', 135.85908508300781, 'rgb.min=', -226.00337219238281)
('rgb.max=', 136.0277099609375, 'rgb.min=', -225.79574584960938)
('rgb.max=', 135.76838684082031, 'rgb.min=', -225.91632080078125)
('rgb.max=', 135.9742431640625, 'rgb.min=', -226.16928100585938)
('rgb.max=', 135.59803771972656, 'rgb.min=', -225.65789794921875)
('rgb.max=', 135.84335327148438, 'rgb.min=', -225.99664306640625)
('rgb.max=', 135.77731323242188, 'rgb.min=', -226.15731811523438)
('rgb.max=', 135.81341552734375, 'rgb.min=', -226.27006530761719)
('rgb.max=', 135.72740173339844, 'rgb.min=', -225.91802978515625)
('rgb.max=', 135.77127075195312, 'rgb.min=', -225.72178649902344)
('rgb.max=', 136.0972900390625, 'rgb.min=', -225.83000183105469)
('rgb.max=', 135.86781311035156, 'rgb.min=', -225.88299560546875)
('rgb.max=', 135.97622680664062, 'rgb.min=', -226.33065795898438)
('rgb.max=', 135.76434326171875, 'rgb.min=', -226.10057067871094)
('rgb.max=', 135.93194580078125, 'rgb.min=', -225.95848083496094)
('rgb.max=', 135.87298583984375, 'rgb.min=', -226.10939025878906)
('rgb.max=', 135.70860290527344, 'rgb.min=', -225.87478637695312)
('rgb.max=', 135.93208312988281, 'rgb.min=', -225.810302734375)
('rgb.max=', 135.88973999023438, 'rgb.min=', -225.87420654296875)
('rgb.max=', 135.89515686035156, 'rgb.min=', -225.82856750488281)
('rgb.max=', 136.10684204101562, 'rgb.min=', -226.03790283203125)
('rgb.max=', 135.94639587402344, 'rgb.min=', -226.02186584472656)
('rgb.max=', 135.94863891601562, 'rgb.min=', -226.12890625)
('rgb.max=', 136.08425903320312, 'rgb.min=', -225.96513366699219)
('rgb.max=', 135.92866516113281, 'rgb.min=', -225.90029907226562)
('rgb.max=', 135.936767578125, 'rgb.min=', -225.91885375976562)
('rgb.max=', 136.11468505859375, 'rgb.min=', -225.87881469726562)
('rgb.max=', 135.93742370605469, 'rgb.min=', -225.77642822265625)
('rgb.max=', 135.91525268554688, 'rgb.min=', -225.73504638671875)
('rgb.max=', 135.845947265625, 'rgb.min=', -225.97300720214844)
('rgb.max=', 135.83171081542969, 'rgb.min=', -226.29820251464844)
('rgb.max=', 135.62689208984375, 'rgb.min=', -226.08329772949219)
('rgb.max=', 135.90257263183594, 'rgb.min=', -225.7740478515625)
('rgb.max=', 135.77691650390625, 'rgb.min=', -225.85942077636719)
('rgb.max=', 136.04193115234375, 'rgb.min=', -225.82608032226562)
('rgb.max=', 135.97018432617188, 'rgb.min=', -226.11021423339844)
('rgb.max=', 136.27261352539062, 'rgb.min=', -226.07844543457031)
('rgb.max=', 135.78935241699219, 'rgb.min=', -225.84866333007812)
('rgb.max=', 135.85343933105469, 'rgb.min=', -225.964599609375)
('rgb.max=', 135.81098937988281, 'rgb.min=', -225.7808837890625)
('rgb.max=', 135.94586181640625, 'rgb.min=', -226.043212890625)
('rgb.max=', 135.83380126953125, 'rgb.min=', -225.78512573242188)
('rgb.max=', 136.14309692382812, 'rgb.min=', -225.92465209960938)
('rgb.max=', 135.62054443359375, 'rgb.min=', -225.998291015625)
('rgb.max=', 135.94427490234375, 'rgb.min=', -226.11947631835938)
('rgb.max=', 136.07113647460938, 'rgb.min=', -225.75167846679688)
('rgb.max=', 135.74198913574219, 'rgb.min=', -226.0557861328125)
('rgb.max=', 135.9210205078125, 'rgb.min=', -225.91139221191406)
('rgb.max=', 136.11898803710938, 'rgb.min=', -225.82362365722656)
('rgb.max=', 136.024169921875, 'rgb.min=', -225.77470397949219)
('rgb.max=', 135.67364501953125, 'rgb.min=', -226.16397094726562)
('rgb.max=', 135.86123657226562, 'rgb.min=', -226.10038757324219)
('rgb.max=', 135.93475341796875, 'rgb.min=', -225.86515808105469)
('rgb.max=', 135.80613708496094, 'rgb.min=', -225.99368286132812)
('rgb.max=', 135.94024658203125, 'rgb.min=', -225.86488342285156)
('rgb.max=', 135.84696960449219, 'rgb.min=', -225.82066345214844)
('rgb.max=', 136.09663391113281, 'rgb.min=', -225.86776733398438)
('rgb.max=', 135.71742248535156, 'rgb.min=', -226.05192565917969)
('rgb.max=', 136.1683349609375, 'rgb.min=', -225.91752624511719)
('rgb.max=', 135.95210266113281, 'rgb.min=', -226.018798828125)
('rgb.max=', 136.11468505859375, 'rgb.min=', -225.74708557128906)
('rgb.max=', 135.86355590820312, 'rgb.min=', -225.81402587890625)
('rgb.max=', 136.0716552734375, 'rgb.min=', -225.99943542480469)
('rgb.max=', 136.0889892578125, 'rgb.min=', -226.00743103027344)
('rgb.max=', 136.12005615234375, 'rgb.min=', -225.82684326171875)
('rgb.max=', 135.80642700195312, 'rgb.min=', -225.79046630859375)
('rgb.max=', 135.94168090820312, 'rgb.min=', -225.78843688964844)
('rgb.max=', 135.9979248046875, 'rgb.min=', -226.29484558105469)
('rgb.max=', 136.01882934570312, 'rgb.min=', -226.07069396972656)
('rgb.max=', 135.90121459960938, 'rgb.min=', -225.91717529296875)
('rgb.max=', 135.85205078125, 'rgb.min=', -225.72990417480469)
('rgb.max=', 136.09085083007812, 'rgb.min=', -226.04583740234375)
('rgb.max=', 135.89089965820312, 'rgb.min=', -225.73872375488281)
('rgb.max=', 135.76493835449219, 'rgb.min=', -226.13226318359375)
('rgb.max=', 135.70681762695312, 'rgb.min=', -225.74012756347656)
('rgb.max=', 135.84963989257812, 'rgb.min=', -225.720703125)
('rgb.max=', 135.93385314941406, 'rgb.min=', -226.03456115722656)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.94384765625)
('rgb.max=', 135.72892761230469, 'rgb.min=', -225.909912109375)
('rgb.max=', 136.1474609375, 'rgb.min=', -225.99244689941406)
('rgb.max=', 136.04388427734375, 'rgb.min=', -225.74627685546875)
('rgb.max=', 135.99847412109375, 'rgb.min=', -226.16343688964844)
('rgb.max=', 135.63539123535156, 'rgb.min=', -225.80813598632812)
('rgb.max=', 136.12989807128906, 'rgb.min=', -226.09828186035156)
('rgb.max=', 136.04121398925781, 'rgb.min=', -226.00408935546875)
('rgb.max=', 135.76841735839844, 'rgb.min=', -225.99868774414062)
('rgb.max=', 136.06608581542969, 'rgb.min=', -225.95927429199219)
('rgb.max=', 136.009033203125, 'rgb.min=', -225.99461364746094)
('rgb.max=', 136.00344848632812, 'rgb.min=', -226.00869750976562)
('rgb.max=', 135.90718078613281, 'rgb.min=', -225.9769287109375)
('rgb.max=', 136.09616088867188, 'rgb.min=', -226.15077209472656)
('rgb.max=', 136.048095703125, 'rgb.min=', -226.12960815429688)
('rgb.max=', 135.78594970703125, 'rgb.min=', -226.05975341796875)
('rgb.max=', 135.738525390625, 'rgb.min=', -225.97808837890625)
('rgb.max=', 135.75033569335938, 'rgb.min=', -225.71815490722656)
('rgb.max=', 135.87838745117188, 'rgb.min=', -226.15264892578125)
('rgb.max=', 136.08940124511719, 'rgb.min=', -225.97219848632812)
('rgb.max=', 135.94996643066406, 'rgb.min=', -225.92506408691406)
('rgb.max=', 136.08213806152344, 'rgb.min=', -225.74394226074219)
('rgb.max=', 136.21957397460938, 'rgb.min=', -225.84513854980469)
('rgb.max=', 135.93984985351562, 'rgb.min=', -226.02536010742188)
('rgb.max=', 135.8551025390625, 'rgb.min=', -225.9498291015625)
('rgb.max=', 135.89022827148438, 'rgb.min=', -225.89891052246094)
('rgb.max=', 136.1240234375, 'rgb.min=', -225.50564575195312)
('rgb.max=', 136.01507568359375, 'rgb.min=', -226.04605102539062)
('rgb.max=', 135.99615478515625, 'rgb.min=', -226.25289916992188)
('rgb.max=', 135.52740478515625, 'rgb.min=', -225.73652648925781)
('rgb.max=', 135.91612243652344, 'rgb.min=', -225.66142272949219)
('rgb.max=', 135.91220092773438, 'rgb.min=', -225.99598693847656)
('rgb.max=', 135.786376953125, 'rgb.min=', -226.0830078125)
('rgb.max=', 136.12934875488281, 'rgb.min=', -225.67280578613281)
('rgb.max=', 135.59657287597656, 'rgb.min=', -225.79971313476562)
('rgb.max=', 136.03164672851562, 'rgb.min=', -226.21682739257812)
('rgb.max=', 135.86212158203125, 'rgb.min=', -226.05989074707031)
('rgb.max=', 135.97450256347656, 'rgb.min=', -225.78558349609375)
('rgb.max=', 135.90608215332031, 'rgb.min=', -226.043212890625)
('rgb.max=', 136.0062255859375, 'rgb.min=', -225.9234619140625)
('rgb.max=', 135.87126159667969, 'rgb.min=', -226.17927551269531)
('rgb.max=', 135.97238159179688, 'rgb.min=', -225.87699890136719)
('rgb.max=', 136.02674865722656, 'rgb.min=', -226.03758239746094)
('rgb.max=', 135.91635131835938, 'rgb.min=', -226.10038757324219)
('rgb.max=', 136.05201721191406, 'rgb.min=', -226.13385009765625)
('rgb.max=', 135.782470703125, 'rgb.min=', -225.81330871582031)
('rgb.max=', 136.11373901367188, 'rgb.min=', -225.78485107421875)
('rgb.max=', 136.02734375, 'rgb.min=', -225.74363708496094)
('rgb.max=', 136.0543212890625, 'rgb.min=', -225.89471435546875)
('rgb.max=', 135.82035827636719, 'rgb.min=', -226.0675048828125)
('rgb.max=', 135.90512084960938, 'rgb.min=', -225.82864379882812)
('rgb.max=', 136.11990356445312, 'rgb.min=', -225.98646545410156)
('rgb.max=', 135.84832763671875, 'rgb.min=', -225.75294494628906)
('rgb.max=', 135.966796875, 'rgb.min=', -225.86538696289062)
('rgb.max=', 136.10504150390625, 'rgb.min=', -225.82000732421875)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.97198486328125)
('rgb.max=', 135.97822570800781, 'rgb.min=', -226.13316345214844)
('rgb.max=', 135.67425537109375, 'rgb.min=', -225.86932373046875)
('rgb.max=', 135.87722778320312, 'rgb.min=', -225.9046630859375)
('rgb.max=', 135.79676818847656, 'rgb.min=', -225.84156799316406)
('rgb.max=', 136.017333984375, 'rgb.min=', -226.17239379882812)
('rgb.max=', 135.96168518066406, 'rgb.min=', -225.84283447265625)
('rgb.max=', 135.853759765625, 'rgb.min=', -226.01896667480469)
('rgb.max=', 136.08004760742188, 'rgb.min=', -225.71731567382812)
('rgb.max=', 135.91920471191406, 'rgb.min=', -226.0711669921875)
('rgb.max=', 135.92947387695312, 'rgb.min=', -225.78758239746094)
('rgb.max=', 135.70748901367188, 'rgb.min=', -225.91983032226562)
('rgb.max=', 135.65362548828125, 'rgb.min=', -225.78372192382812)
('rgb.max=', 135.85589599609375, 'rgb.min=', -226.06216430664062)
('rgb.max=', 135.9075927734375, 'rgb.min=', -226.21209716796875)
('rgb.max=', 135.68759155273438, 'rgb.min=', -225.93916320800781)
('rgb.max=', 135.75325012207031, 'rgb.min=', -225.95684814453125)
('rgb.max=', 135.95745849609375, 'rgb.min=', -226.10882568359375)
('rgb.max=', 136.12454223632812, 'rgb.min=', -226.11724853515625)
('rgb.max=', 135.93409729003906, 'rgb.min=', -226.2760009765625)
('rgb.max=', 136.123779296875, 'rgb.min=', -225.9261474609375)
('rgb.max=', 136.00459289550781, 'rgb.min=', -225.78544616699219)
('rgb.max=', 136.07516479492188, 'rgb.min=', -226.08128356933594)
('rgb.max=', 135.9622802734375, 'rgb.min=', -226.04547119140625)
('rgb.max=', 136.10816955566406, 'rgb.min=', -226.12255859375)
('rgb.max=', 135.63168334960938, 'rgb.min=', -225.91879272460938)
('rgb.max=', 135.97355651855469, 'rgb.min=', -226.16368103027344)
('rgb.max=', 135.99472045898438, 'rgb.min=', -225.91926574707031)
('rgb.max=', 136.09695434570312, 'rgb.min=', -225.84129333496094)
('rgb.max=', 135.99650573730469, 'rgb.min=', -226.1766357421875)
('rgb.max=', 135.80122375488281, 'rgb.min=', -225.84117126464844)
('rgb.max=', 135.90211486816406, 'rgb.min=', -225.82612609863281)
('rgb.max=', 135.64448547363281, 'rgb.min=', -226.22970581054688)
('rgb.max=', 135.71321105957031, 'rgb.min=', -225.93989562988281)
('rgb.max=', 135.83230590820312, 'rgb.min=', -226.16201782226562)
('rgb.max=', 135.90217590332031, 'rgb.min=', -225.88009643554688)
('rgb.max=', 135.8807373046875, 'rgb.min=', -225.95782470703125)
('rgb.max=', 135.97647094726562, 'rgb.min=', -226.06779479980469)
('rgb.max=', 135.92036437988281, 'rgb.min=', -225.83644104003906)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.397811')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6997 ', 'GAN acc 0.4414', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5098', 'Total loss: 1.3930', 'for batch', 0)
('GAN loss 0.6976 ', 'GAN acc 0.4883', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3914', 'for batch', 1)
('GAN loss 0.6946 ', 'GAN acc 0.4922', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5332', 'Total loss: 1.3882', 'for batch', 2)
('GAN loss 0.6912 ', 'GAN acc 0.5273', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4902', 'Total loss: 1.3859', 'for batch', 3)
('GAN loss 0.6934 ', 'GAN acc 0.5000', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4805', 'Total loss: 1.3895', 'for batch', 4)
('GAN loss 0.6920 ', 'GAN acc 0.5273', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4746', 'Total loss: 1.3901', 'for batch', 5)
('GAN loss 0.6924 ', 'GAN acc 0.4844', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4727', 'Total loss: 1.3884', 'for batch', 6)
('GAN loss 0.6935 ', 'GAN acc 0.5078', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4863', 'Total loss: 1.3884', 'for batch', 7)
('GAN loss 0.6866 ', 'GAN acc 0.5742', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4961', 'Total loss: 1.3807', 'for batch', 8)
('GAN loss 0.6895 ', 'GAN acc 0.5312', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5137', 'Total loss: 1.3801', 'for batch', 9)
('GAN loss 0.6912 ', 'GAN acc 0.5234', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4941', 'Total loss: 1.3872', 'for batch', 10)
('GAN loss 0.6895 ', 'GAN acc 0.5625', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4824', 'Total loss: 1.3841', 'for batch', 11)
('GAN loss 0.6876 ', 'GAN acc 0.5781', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4805', 'Total loss: 1.3829', 'for batch', 12)
('GAN loss 0.6961 ', 'GAN acc 0.4766', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3894', 'for batch', 13)
('GAN loss 0.6965 ', 'GAN acc 0.4648', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4727', 'Total loss: 1.3921', 'for batch', 14)
('GAN loss 0.6949 ', 'GAN acc 0.4961', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5098', 'Total loss: 1.3888', 'for batch', 15)
('GAN loss 0.6974 ', 'GAN acc 0.4297', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5215', 'Total loss: 1.3933', 'for batch', 16)
('GAN loss 0.6988 ', 'GAN acc 0.4414', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5039', 'Total loss: 1.3915', 'for batch', 17)
('GAN loss 0.7061 ', 'GAN acc 0.4180', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4863', 'Total loss: 1.4022', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51653051)
('DISCRIMINATOR_Imagem FAKE=', 0.51662207)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.00650024414062, 'rgb.min=', -225.77037048339844)
('rgb.max=', 135.89431762695312, 'rgb.min=', -226.04096984863281)
('rgb.max=', 136.14056396484375, 'rgb.min=', -225.95166015625)
('rgb.max=', 135.98910522460938, 'rgb.min=', -226.1124267578125)
('rgb.max=', 136.09109497070312, 'rgb.min=', -225.90225219726562)
('rgb.max=', 136.18875122070312, 'rgb.min=', -226.39761352539062)
('rgb.max=', 135.82850646972656, 'rgb.min=', -226.15882873535156)
('rgb.max=', 135.93339538574219, 'rgb.min=', -225.93034362792969)
('rgb.max=', 135.84280395507812, 'rgb.min=', -226.1407470703125)
('rgb.max=', 135.798095703125, 'rgb.min=', -226.06439208984375)
('rgb.max=', 135.68797302246094, 'rgb.min=', -226.17680358886719)
('rgb.max=', 135.83216857910156, 'rgb.min=', -226.00642395019531)
('rgb.max=', 135.7987060546875, 'rgb.min=', -226.11578369140625)
('rgb.max=', 135.92562866210938, 'rgb.min=', -226.07440185546875)
('rgb.max=', 135.79206848144531, 'rgb.min=', -226.01206970214844)
('rgb.max=', 135.767822265625, 'rgb.min=', -226.02919006347656)
('rgb.max=', 135.80601501464844, 'rgb.min=', -225.94912719726562)
('rgb.max=', 135.89521789550781, 'rgb.min=', -225.77336120605469)
('rgb.max=', 135.90484619140625, 'rgb.min=', -226.11824035644531)
('rgb.max=', 135.96112060546875, 'rgb.min=', -226.331787109375)
('rgb.max=', 136.07327270507812, 'rgb.min=', -225.92172241210938)
('rgb.max=', 136.15182495117188, 'rgb.min=', -225.91343688964844)
('rgb.max=', 136.12863159179688, 'rgb.min=', -225.81137084960938)
('rgb.max=', 135.88943481445312, 'rgb.min=', -225.62443542480469)
('rgb.max=', 135.75920104980469, 'rgb.min=', -225.94792175292969)
('rgb.max=', 136.1129150390625, 'rgb.min=', -226.00489807128906)
('rgb.max=', 136.12142944335938, 'rgb.min=', -226.00387573242188)
('rgb.max=', 135.87335205078125, 'rgb.min=', -225.93711853027344)
('rgb.max=', 135.90817260742188, 'rgb.min=', -225.86714172363281)
('rgb.max=', 135.85232543945312, 'rgb.min=', -226.00724792480469)
('rgb.max=', 135.9339599609375, 'rgb.min=', -226.00790405273438)
('rgb.max=', 135.82792663574219, 'rgb.min=', -225.90274047851562)
('rgb.max=', 135.9559326171875, 'rgb.min=', -226.06083679199219)
('rgb.max=', 135.87379455566406, 'rgb.min=', -225.95286560058594)
('rgb.max=', 135.88380432128906, 'rgb.min=', -226.01925659179688)
('rgb.max=', 136.07159423828125, 'rgb.min=', -225.94119262695312)
('rgb.max=', 136.16888427734375, 'rgb.min=', -225.89718627929688)
('rgb.max=', 136.08880615234375, 'rgb.min=', -225.99931335449219)
('rgb.max=', 135.9169921875, 'rgb.min=', -225.92364501953125)
('rgb.max=', 135.90936279296875, 'rgb.min=', -226.0010986328125)
('rgb.max=', 135.71189880371094, 'rgb.min=', -225.85684204101562)
('rgb.max=', 135.95358276367188, 'rgb.min=', -226.10612487792969)
('rgb.max=', 135.89404296875, 'rgb.min=', -226.00148010253906)
('rgb.max=', 135.85362243652344, 'rgb.min=', -225.93367004394531)
('rgb.max=', 135.96707153320312, 'rgb.min=', -226.38490295410156)
('rgb.max=', 135.57243347167969, 'rgb.min=', -225.88407897949219)
('rgb.max=', 135.95501708984375, 'rgb.min=', -225.901611328125)
('rgb.max=', 135.75672912597656, 'rgb.min=', -225.82418823242188)
('rgb.max=', 135.88458251953125, 'rgb.min=', -225.93667602539062)
('rgb.max=', 136.24557495117188, 'rgb.min=', -226.01948547363281)
('rgb.max=', 135.99311828613281, 'rgb.min=', -226.01376342773438)
('rgb.max=', 136.1611328125, 'rgb.min=', -225.97067260742188)
('rgb.max=', 135.70155334472656, 'rgb.min=', -226.01568603515625)
('rgb.max=', 135.81912231445312, 'rgb.min=', -226.08160400390625)
('rgb.max=', 136.09933471679688, 'rgb.min=', -225.99142456054688)
('rgb.max=', 136.10269165039062, 'rgb.min=', -226.05227661132812)
('rgb.max=', 135.89106750488281, 'rgb.min=', -226.00323486328125)
('rgb.max=', 135.80755615234375, 'rgb.min=', -225.94691467285156)
('rgb.max=', 135.84434509277344, 'rgb.min=', -225.92994689941406)
('rgb.max=', 135.57130432128906, 'rgb.min=', -226.14498901367188)
('rgb.max=', 135.94851684570312, 'rgb.min=', -226.02828979492188)
('rgb.max=', 135.74143981933594, 'rgb.min=', -225.79383850097656)
('rgb.max=', 135.70957946777344, 'rgb.min=', -226.00668334960938)
('rgb.max=', 135.74232482910156, 'rgb.min=', -226.29391479492188)
('rgb.max=', 136.27560424804688, 'rgb.min=', -225.72332763671875)
('rgb.max=', 135.947998046875, 'rgb.min=', -226.14373779296875)
('rgb.max=', 135.6591796875, 'rgb.min=', -225.84672546386719)
('rgb.max=', 135.7137451171875, 'rgb.min=', -226.02342224121094)
('rgb.max=', 135.97494506835938, 'rgb.min=', -226.08404541015625)
('rgb.max=', 136.0609130859375, 'rgb.min=', -226.07015991210938)
('rgb.max=', 136.00375366210938, 'rgb.min=', -226.01057434082031)
('rgb.max=', 135.73489379882812, 'rgb.min=', -225.97691345214844)
('rgb.max=', 135.89289855957031, 'rgb.min=', -226.23744201660156)
('rgb.max=', 135.95260620117188, 'rgb.min=', -226.06584167480469)
('rgb.max=', 135.87367248535156, 'rgb.min=', -225.73849487304688)
('rgb.max=', 136.04925537109375, 'rgb.min=', -225.98127746582031)
('rgb.max=', 136.17979431152344, 'rgb.min=', -226.10650634765625)
('rgb.max=', 136.00810241699219, 'rgb.min=', -225.73617553710938)
('rgb.max=', 135.74240112304688, 'rgb.min=', -226.01235961914062)
('rgb.max=', 135.91705322265625, 'rgb.min=', -225.89796447753906)
('rgb.max=', 135.99888610839844, 'rgb.min=', -225.59848022460938)
('rgb.max=', 135.81059265136719, 'rgb.min=', -225.89308166503906)
('rgb.max=', 135.79441833496094, 'rgb.min=', -226.02580261230469)
('rgb.max=', 135.96231079101562, 'rgb.min=', -225.95372009277344)
('rgb.max=', 135.95068359375, 'rgb.min=', -226.15789794921875)
('rgb.max=', 135.85791015625, 'rgb.min=', -226.05059814453125)
('rgb.max=', 135.971923828125, 'rgb.min=', -225.80111694335938)
('rgb.max=', 135.74946594238281, 'rgb.min=', -225.94126892089844)
('rgb.max=', 135.95684814453125, 'rgb.min=', -226.22340393066406)
('rgb.max=', 135.60220336914062, 'rgb.min=', -225.76223754882812)
('rgb.max=', 135.8272705078125, 'rgb.min=', -225.944580078125)
('rgb.max=', 135.7618408203125, 'rgb.min=', -226.20889282226562)
('rgb.max=', 135.8221435546875, 'rgb.min=', -226.32566833496094)
('rgb.max=', 135.733154296875, 'rgb.min=', -225.91310119628906)
('rgb.max=', 135.761962890625, 'rgb.min=', -225.76536560058594)
('rgb.max=', 136.05244445800781, 'rgb.min=', -225.80384826660156)
('rgb.max=', 135.8304443359375, 'rgb.min=', -225.87336730957031)
('rgb.max=', 135.92848205566406, 'rgb.min=', -226.36729431152344)
('rgb.max=', 135.76535034179688, 'rgb.min=', -226.18586730957031)
('rgb.max=', 135.9193115234375, 'rgb.min=', -226.0433349609375)
('rgb.max=', 135.8802490234375, 'rgb.min=', -226.14547729492188)
('rgb.max=', 135.71743774414062, 'rgb.min=', -225.90155029296875)
('rgb.max=', 135.87712097167969, 'rgb.min=', -225.82377624511719)
('rgb.max=', 135.8790283203125, 'rgb.min=', -225.95359802246094)
('rgb.max=', 135.89204406738281, 'rgb.min=', -225.82096862792969)
('rgb.max=', 136.15019226074219, 'rgb.min=', -225.92059326171875)
('rgb.max=', 135.91290283203125, 'rgb.min=', -226.06150817871094)
('rgb.max=', 135.9599609375, 'rgb.min=', -225.97218322753906)
('rgb.max=', 136.12518310546875, 'rgb.min=', -225.91769409179688)
('rgb.max=', 135.87167358398438, 'rgb.min=', -225.90089416503906)
('rgb.max=', 135.97232055664062, 'rgb.min=', -225.96699523925781)
('rgb.max=', 136.15737915039062, 'rgb.min=', -225.90557861328125)
('rgb.max=', 135.9375, 'rgb.min=', -225.76728820800781)
('rgb.max=', 135.93721008300781, 'rgb.min=', -225.7386474609375)
('rgb.max=', 135.84782409667969, 'rgb.min=', -225.9676513671875)
('rgb.max=', 135.82321166992188, 'rgb.min=', -226.3272705078125)
('rgb.max=', 135.63079833984375, 'rgb.min=', -225.97358703613281)
('rgb.max=', 135.85519409179688, 'rgb.min=', -225.779541015625)
('rgb.max=', 135.78045654296875, 'rgb.min=', -225.87425231933594)
('rgb.max=', 136.0672607421875, 'rgb.min=', -225.90699768066406)
('rgb.max=', 136.00959777832031, 'rgb.min=', -226.02850341796875)
('rgb.max=', 136.23335266113281, 'rgb.min=', -226.02850341796875)
('rgb.max=', 135.79409790039062, 'rgb.min=', -225.92465209960938)
('rgb.max=', 135.85411071777344, 'rgb.min=', -225.90818786621094)
('rgb.max=', 135.7999267578125, 'rgb.min=', -225.8690185546875)
('rgb.max=', 136.00665283203125, 'rgb.min=', -226.08682250976562)
('rgb.max=', 135.82142639160156, 'rgb.min=', -225.7501220703125)
('rgb.max=', 136.09342956542969, 'rgb.min=', -225.91465759277344)
('rgb.max=', 135.62635803222656, 'rgb.min=', -226.08905029296875)
('rgb.max=', 135.96121215820312, 'rgb.min=', -226.11671447753906)
('rgb.max=', 136.06257629394531, 'rgb.min=', -225.72247314453125)
('rgb.max=', 135.72212219238281, 'rgb.min=', -226.14186096191406)
('rgb.max=', 135.90664672851562, 'rgb.min=', -225.88081359863281)
('rgb.max=', 136.13900756835938, 'rgb.min=', -225.84266662597656)
('rgb.max=', 136.06939697265625, 'rgb.min=', -225.88101196289062)
('rgb.max=', 135.67625427246094, 'rgb.min=', -226.07301330566406)
('rgb.max=', 135.85704040527344, 'rgb.min=', -226.11428833007812)
('rgb.max=', 135.86433410644531, 'rgb.min=', -225.866455078125)
('rgb.max=', 135.798583984375, 'rgb.min=', -226.08946228027344)
('rgb.max=', 135.88880920410156, 'rgb.min=', -225.89689636230469)
('rgb.max=', 135.832763671875, 'rgb.min=', -225.83103942871094)
('rgb.max=', 136.04605102539062, 'rgb.min=', -225.87760925292969)
('rgb.max=', 135.7159423828125, 'rgb.min=', -226.09170532226562)
('rgb.max=', 136.17745971679688, 'rgb.min=', -225.89939880371094)
('rgb.max=', 135.91429138183594, 'rgb.min=', -226.11250305175781)
('rgb.max=', 136.13916015625, 'rgb.min=', -225.85209655761719)
('rgb.max=', 135.87118530273438, 'rgb.min=', -225.87236022949219)
('rgb.max=', 136.12870788574219, 'rgb.min=', -226.01536560058594)
('rgb.max=', 136.10208129882812, 'rgb.min=', -226.04595947265625)
('rgb.max=', 136.06346130371094, 'rgb.min=', -225.82443237304688)
('rgb.max=', 135.7965087890625, 'rgb.min=', -225.88676452636719)
('rgb.max=', 135.9068603515625, 'rgb.min=', -225.79331970214844)
('rgb.max=', 135.92623901367188, 'rgb.min=', -226.12034606933594)
('rgb.max=', 136.03468322753906, 'rgb.min=', -225.97698974609375)
('rgb.max=', 135.89431762695312, 'rgb.min=', -226.01272583007812)
('rgb.max=', 135.8394775390625, 'rgb.min=', -225.73551940917969)
('rgb.max=', 136.10995483398438, 'rgb.min=', -226.04508972167969)
('rgb.max=', 135.82843017578125, 'rgb.min=', -225.77983093261719)
('rgb.max=', 135.75823974609375, 'rgb.min=', -226.17831420898438)
('rgb.max=', 135.70274353027344, 'rgb.min=', -225.74713134765625)
('rgb.max=', 135.84584045410156, 'rgb.min=', -225.79405212402344)
('rgb.max=', 135.9207763671875, 'rgb.min=', -226.06072998046875)
('rgb.max=', 135.89384460449219, 'rgb.min=', -225.97285461425781)
('rgb.max=', 135.73139953613281, 'rgb.min=', -225.8909912109375)
('rgb.max=', 136.18251037597656, 'rgb.min=', -226.07716369628906)
('rgb.max=', 135.98464965820312, 'rgb.min=', -225.74101257324219)
('rgb.max=', 135.97293090820312, 'rgb.min=', -226.04011535644531)
('rgb.max=', 135.61688232421875, 'rgb.min=', -225.90733337402344)
('rgb.max=', 136.17039489746094, 'rgb.min=', -226.02655029296875)
('rgb.max=', 136.05168151855469, 'rgb.min=', -226.00241088867188)
('rgb.max=', 135.766845703125, 'rgb.min=', -225.92044067382812)
('rgb.max=', 136.10812377929688, 'rgb.min=', -225.94540405273438)
('rgb.max=', 135.95732116699219, 'rgb.min=', -225.98603820800781)
('rgb.max=', 136.02334594726562, 'rgb.min=', -225.92127990722656)
('rgb.max=', 135.90792846679688, 'rgb.min=', -225.9923095703125)
('rgb.max=', 136.11489868164062, 'rgb.min=', -226.06767272949219)
('rgb.max=', 136.0472412109375, 'rgb.min=', -226.03208923339844)
('rgb.max=', 135.7940673828125, 'rgb.min=', -225.98565673828125)
('rgb.max=', 135.73680114746094, 'rgb.min=', -225.947998046875)
('rgb.max=', 135.74612426757812, 'rgb.min=', -225.80563354492188)
('rgb.max=', 135.90974426269531, 'rgb.min=', -226.20358276367188)
('rgb.max=', 136.05229187011719, 'rgb.min=', -226.01817321777344)
('rgb.max=', 135.94483947753906, 'rgb.min=', -225.93588256835938)
('rgb.max=', 136.05953979492188, 'rgb.min=', -225.73051452636719)
('rgb.max=', 136.16929626464844, 'rgb.min=', -225.85476684570312)
('rgb.max=', 135.9345703125, 'rgb.min=', -225.90972900390625)
('rgb.max=', 135.84799194335938, 'rgb.min=', -226.04780578613281)
('rgb.max=', 135.88265991210938, 'rgb.min=', -225.95701599121094)
('rgb.max=', 136.20097351074219, 'rgb.min=', -225.50701904296875)
('rgb.max=', 136.04881286621094, 'rgb.min=', -225.93594360351562)
('rgb.max=', 136.01321411132812, 'rgb.min=', -226.30006408691406)
('rgb.max=', 135.53817749023438, 'rgb.min=', -225.83462524414062)
('rgb.max=', 135.91407775878906, 'rgb.min=', -225.66590881347656)
('rgb.max=', 135.89973449707031, 'rgb.min=', -226.07186889648438)
('rgb.max=', 135.77218627929688, 'rgb.min=', -226.1588134765625)
('rgb.max=', 136.1707763671875, 'rgb.min=', -225.65922546386719)
('rgb.max=', 135.62139892578125, 'rgb.min=', -225.89060974121094)
('rgb.max=', 136.12263488769531, 'rgb.min=', -226.2608642578125)
('rgb.max=', 135.85993957519531, 'rgb.min=', -225.93904113769531)
('rgb.max=', 135.97332763671875, 'rgb.min=', -225.79725646972656)
('rgb.max=', 135.891845703125, 'rgb.min=', -225.996826171875)
('rgb.max=', 136.02938842773438, 'rgb.min=', -225.92581176757812)
('rgb.max=', 135.8663330078125, 'rgb.min=', -226.24200439453125)
('rgb.max=', 135.96047973632812, 'rgb.min=', -225.95138549804688)
('rgb.max=', 136.06060791015625, 'rgb.min=', -225.96128845214844)
('rgb.max=', 135.90032958984375, 'rgb.min=', -226.16036987304688)
('rgb.max=', 136.0780029296875, 'rgb.min=', -226.052001953125)
('rgb.max=', 135.77366638183594, 'rgb.min=', -225.81655883789062)
('rgb.max=', 136.1553955078125, 'rgb.min=', -225.8465576171875)
('rgb.max=', 136.02473449707031, 'rgb.min=', -225.74786376953125)
('rgb.max=', 136.06704711914062, 'rgb.min=', -225.96763610839844)
('rgb.max=', 135.81680297851562, 'rgb.min=', -226.14674377441406)
('rgb.max=', 135.90089416503906, 'rgb.min=', -225.85020446777344)
('rgb.max=', 136.16029357910156, 'rgb.min=', -226.06182861328125)
('rgb.max=', 135.89019775390625, 'rgb.min=', -225.76939392089844)
('rgb.max=', 135.96359252929688, 'rgb.min=', -225.85845947265625)
('rgb.max=', 136.08805847167969, 'rgb.min=', -225.86201477050781)
('rgb.max=', 135.857421875, 'rgb.min=', -226.00625610351562)
('rgb.max=', 135.93638610839844, 'rgb.min=', -226.12205505371094)
('rgb.max=', 135.67755126953125, 'rgb.min=', -225.88545227050781)
('rgb.max=', 135.86114501953125, 'rgb.min=', -225.97230529785156)
('rgb.max=', 135.7913818359375, 'rgb.min=', -225.88763427734375)
('rgb.max=', 136.01568603515625, 'rgb.min=', -226.00787353515625)
('rgb.max=', 135.96246337890625, 'rgb.min=', -225.83004760742188)
('rgb.max=', 135.83992004394531, 'rgb.min=', -226.111572265625)
('rgb.max=', 136.08694458007812, 'rgb.min=', -225.72532653808594)
('rgb.max=', 135.92393493652344, 'rgb.min=', -226.14222717285156)
('rgb.max=', 135.90086364746094, 'rgb.min=', -225.8829345703125)
('rgb.max=', 135.70069885253906, 'rgb.min=', -225.88812255859375)
('rgb.max=', 135.68043518066406, 'rgb.min=', -225.81355285644531)
('rgb.max=', 135.85369873046875, 'rgb.min=', -226.10020446777344)
('rgb.max=', 135.8997802734375, 'rgb.min=', -226.28746032714844)
('rgb.max=', 135.71484375, 'rgb.min=', -225.88607788085938)
('rgb.max=', 135.76629638671875, 'rgb.min=', -225.92857360839844)
('rgb.max=', 135.94436645507812, 'rgb.min=', -226.15046691894531)
('rgb.max=', 136.16403198242188, 'rgb.min=', -226.19790649414062)
('rgb.max=', 135.96565246582031, 'rgb.min=', -226.35397338867188)
('rgb.max=', 136.16452026367188, 'rgb.min=', -225.97488403320312)
('rgb.max=', 136.04122924804688, 'rgb.min=', -225.78779602050781)
('rgb.max=', 136.10678100585938, 'rgb.min=', -226.15093994140625)
('rgb.max=', 135.94288635253906, 'rgb.min=', -226.12010192871094)
('rgb.max=', 136.14459228515625, 'rgb.min=', -226.0966796875)
('rgb.max=', 135.63613891601562, 'rgb.min=', -226.00376892089844)
('rgb.max=', 135.9744873046875, 'rgb.min=', -226.03282165527344)
('rgb.max=', 136.03021240234375, 'rgb.min=', -225.98345947265625)
('rgb.max=', 136.1373291015625, 'rgb.min=', -225.84866333007812)
('rgb.max=', 136.00318908691406, 'rgb.min=', -226.19291687011719)
('rgb.max=', 135.79238891601562, 'rgb.min=', -225.83448791503906)
('rgb.max=', 135.88392639160156, 'rgb.min=', -225.83779907226562)
('rgb.max=', 135.63441467285156, 'rgb.min=', -226.29866027832031)
('rgb.max=', 135.71133422851562, 'rgb.min=', -226.02642822265625)
('rgb.max=', 135.83384704589844, 'rgb.min=', -226.09053039550781)
('rgb.max=', 135.89083862304688, 'rgb.min=', -225.95486450195312)
('rgb.max=', 135.88690185546875, 'rgb.min=', -226.03263854980469)
('rgb.max=', 135.98211669921875, 'rgb.min=', -226.14402770996094)
('rgb.max=', 135.91647338867188, 'rgb.min=', -225.91256713867188)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.800037')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6985 ', 'GAN acc 0.4883', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4863', 'Total loss: 1.3967', 'for batch', 0)
('GAN loss 0.7018 ', 'GAN acc 0.4180', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5000', 'Total loss: 1.3954', 'for batch', 1)
('GAN loss 0.6992 ', 'GAN acc 0.4414', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5410', 'Total loss: 1.3905', 'for batch', 2)
('GAN loss 0.6948 ', 'GAN acc 0.4492', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4824', 'Total loss: 1.3897', 'for batch', 3)
('GAN loss 0.6928 ', 'GAN acc 0.4922', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4980', 'Total loss: 1.3853', 'for batch', 4)
('GAN loss 0.6936 ', 'GAN acc 0.4727', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4922', 'Total loss: 1.3905', 'for batch', 5)
('GAN loss 0.6906 ', 'GAN acc 0.5586', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4766', 'Total loss: 1.3885', 'for batch', 6)
('GAN loss 0.6851 ', 'GAN acc 0.5898', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4297', 'Total loss: 1.3833', 'for batch', 7)
('GAN loss 0.6879 ', 'GAN acc 0.5156', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4961', 'Total loss: 1.3808', 'for batch', 8)
('GAN loss 0.6830 ', 'GAN acc 0.6133', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4922', 'Total loss: 1.3766', 'for batch', 9)
('GAN loss 0.6850 ', 'GAN acc 0.5625', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.3800', 'for batch', 10)
('GAN loss 0.6823 ', 'GAN acc 0.6016', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5371', 'Total loss: 1.3743', 'for batch', 11)
('GAN loss 0.6866 ', 'GAN acc 0.5820', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4863', 'Total loss: 1.3806', 'for batch', 12)
('GAN loss 0.6903 ', 'GAN acc 0.5312', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5234', 'Total loss: 1.3830', 'for batch', 13)
('GAN loss 0.6934 ', 'GAN acc 0.5117', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5195', 'Total loss: 1.3840', 'for batch', 14)
('GAN loss 0.6987 ', 'GAN acc 0.4531', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5059', 'Total loss: 1.3917', 'for batch', 15)
('GAN loss 0.6984 ', 'GAN acc 0.4648', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4844', 'Total loss: 1.3932', 'for batch', 16)
('GAN loss 0.7013 ', 'GAN acc 0.4297', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4707', 'Total loss: 1.3961', 'for batch', 17)
('GAN loss 0.6998 ', 'GAN acc 0.4336', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4727', 'Total loss: 1.3947', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51581812)
('DISCRIMINATOR_Imagem FAKE=', 0.51639879)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.063232421875, 'rgb.min=', -225.79148864746094)
('rgb.max=', 135.90615844726562, 'rgb.min=', -225.92326354980469)
('rgb.max=', 136.14039611816406, 'rgb.min=', -225.90785217285156)
('rgb.max=', 136.06314086914062, 'rgb.min=', -226.07763671875)
('rgb.max=', 136.14744567871094, 'rgb.min=', -225.91519165039062)
('rgb.max=', 136.18450927734375, 'rgb.min=', -226.28872680664062)
('rgb.max=', 135.83616638183594, 'rgb.min=', -225.97215270996094)
('rgb.max=', 135.95286560058594, 'rgb.min=', -225.92597961425781)
('rgb.max=', 135.85751342773438, 'rgb.min=', -226.10552978515625)
('rgb.max=', 135.80548095703125, 'rgb.min=', -225.99249267578125)
('rgb.max=', 135.71682739257812, 'rgb.min=', -225.99951171875)
('rgb.max=', 135.839599609375, 'rgb.min=', -226.09233093261719)
('rgb.max=', 135.79855346679688, 'rgb.min=', -226.11076354980469)
('rgb.max=', 135.92901611328125, 'rgb.min=', -226.07568359375)
('rgb.max=', 135.79901123046875, 'rgb.min=', -225.94685363769531)
('rgb.max=', 135.78097534179688, 'rgb.min=', -226.05259704589844)
('rgb.max=', 135.8145751953125, 'rgb.min=', -225.96063232421875)
('rgb.max=', 135.9000244140625, 'rgb.min=', -225.81246948242188)
('rgb.max=', 135.9189453125, 'rgb.min=', -225.9171142578125)
('rgb.max=', 135.97842407226562, 'rgb.min=', -226.09341430664062)
('rgb.max=', 136.10993957519531, 'rgb.min=', -225.92625427246094)
('rgb.max=', 136.17582702636719, 'rgb.min=', -225.89396667480469)
('rgb.max=', 136.17990112304688, 'rgb.min=', -225.81277465820312)
('rgb.max=', 135.95669555664062, 'rgb.min=', -225.65773010253906)
('rgb.max=', 135.77980041503906, 'rgb.min=', -225.97549438476562)
('rgb.max=', 136.11248779296875, 'rgb.min=', -225.94264221191406)
('rgb.max=', 136.122314453125, 'rgb.min=', -226.01527404785156)
('rgb.max=', 135.86593627929688, 'rgb.min=', -225.88026428222656)
('rgb.max=', 135.91912841796875, 'rgb.min=', -225.81515502929688)
('rgb.max=', 135.89752197265625, 'rgb.min=', -226.00715637207031)
('rgb.max=', 136.00369262695312, 'rgb.min=', -225.98379516601562)
('rgb.max=', 135.83963012695312, 'rgb.min=', -225.91839599609375)
('rgb.max=', 136.0286865234375, 'rgb.min=', -226.08601379394531)
('rgb.max=', 135.8824462890625, 'rgb.min=', -225.96945190429688)
('rgb.max=', 135.89509582519531, 'rgb.min=', -226.03257751464844)
('rgb.max=', 136.09739685058594, 'rgb.min=', -225.94486999511719)
('rgb.max=', 136.13357543945312, 'rgb.min=', -225.93913269042969)
('rgb.max=', 136.09033203125, 'rgb.min=', -226.06214904785156)
('rgb.max=', 135.97398376464844, 'rgb.min=', -225.91023254394531)
('rgb.max=', 135.96563720703125, 'rgb.min=', -226.00294494628906)
('rgb.max=', 135.71586608886719, 'rgb.min=', -225.85650634765625)
('rgb.max=', 135.97758483886719, 'rgb.min=', -225.99479675292969)
('rgb.max=', 135.90011596679688, 'rgb.min=', -226.01763916015625)
('rgb.max=', 135.89741516113281, 'rgb.min=', -225.98828125)
('rgb.max=', 136.00859069824219, 'rgb.min=', -226.16459655761719)
('rgb.max=', 135.58203125, 'rgb.min=', -225.87486267089844)
('rgb.max=', 136.04170227050781, 'rgb.min=', -225.905029296875)
('rgb.max=', 135.80546569824219, 'rgb.min=', -225.75772094726562)
('rgb.max=', 135.927978515625, 'rgb.min=', -225.93435668945312)
('rgb.max=', 136.22601318359375, 'rgb.min=', -226.05314636230469)
('rgb.max=', 136.00447082519531, 'rgb.min=', -226.07562255859375)
('rgb.max=', 136.23387145996094, 'rgb.min=', -225.95930480957031)
('rgb.max=', 135.65740966796875, 'rgb.min=', -225.94338989257812)
('rgb.max=', 135.80647277832031, 'rgb.min=', -226.03257751464844)
('rgb.max=', 136.09890747070312, 'rgb.min=', -225.99893188476562)
('rgb.max=', 136.08334350585938, 'rgb.min=', -226.05116271972656)
('rgb.max=', 135.89129638671875, 'rgb.min=', -226.02035522460938)
('rgb.max=', 135.809814453125, 'rgb.min=', -225.9029541015625)
('rgb.max=', 135.85488891601562, 'rgb.min=', -225.93186950683594)
('rgb.max=', 135.57138061523438, 'rgb.min=', -226.05439758300781)
('rgb.max=', 135.95867919921875, 'rgb.min=', -226.07270812988281)
('rgb.max=', 135.74380493164062, 'rgb.min=', -225.8525390625)
('rgb.max=', 135.74490356445312, 'rgb.min=', -225.96235656738281)
('rgb.max=', 135.76121520996094, 'rgb.min=', -226.07510375976562)
('rgb.max=', 136.33511352539062, 'rgb.min=', -225.75685119628906)
('rgb.max=', 135.94956970214844, 'rgb.min=', -226.04006958007812)
('rgb.max=', 135.65863037109375, 'rgb.min=', -225.89131164550781)
('rgb.max=', 135.70571899414062, 'rgb.min=', -226.06536865234375)
('rgb.max=', 136.048583984375, 'rgb.min=', -226.16130065917969)
('rgb.max=', 136.07098388671875, 'rgb.min=', -226.08349609375)
('rgb.max=', 136.01200866699219, 'rgb.min=', -226.10514831542969)
('rgb.max=', 135.7491455078125, 'rgb.min=', -225.9832763671875)
('rgb.max=', 135.89302062988281, 'rgb.min=', -226.04890441894531)
('rgb.max=', 135.98062133789062, 'rgb.min=', -226.15901184082031)
('rgb.max=', 135.89114379882812, 'rgb.min=', -225.7442626953125)
('rgb.max=', 136.1058349609375, 'rgb.min=', -225.98672485351562)
('rgb.max=', 136.26345825195312, 'rgb.min=', -226.12423706054688)
('rgb.max=', 136.06544494628906, 'rgb.min=', -225.77426147460938)
('rgb.max=', 135.75357055664062, 'rgb.min=', -226.06414794921875)
('rgb.max=', 135.9130859375, 'rgb.min=', -225.8287353515625)
('rgb.max=', 136.03492736816406, 'rgb.min=', -225.61112976074219)
('rgb.max=', 135.83892822265625, 'rgb.min=', -225.9561767578125)
('rgb.max=', 135.84616088867188, 'rgb.min=', -225.93678283691406)
('rgb.max=', 135.9951171875, 'rgb.min=', -225.99652099609375)
('rgb.max=', 135.99639892578125, 'rgb.min=', -226.18699645996094)
('rgb.max=', 135.86454772949219, 'rgb.min=', -225.97137451171875)
('rgb.max=', 136.02523803710938, 'rgb.min=', -225.80859375)
('rgb.max=', 135.78074645996094, 'rgb.min=', -225.90415954589844)
('rgb.max=', 135.96293640136719, 'rgb.min=', -226.05487060546875)
('rgb.max=', 135.6114501953125, 'rgb.min=', -225.70835876464844)
('rgb.max=', 135.86619567871094, 'rgb.min=', -225.97747802734375)
('rgb.max=', 135.77400207519531, 'rgb.min=', -226.05960083007812)
('rgb.max=', 135.82232666015625, 'rgb.min=', -226.1317138671875)
('rgb.max=', 135.74299621582031, 'rgb.min=', -225.93312072753906)
('rgb.max=', 135.81613159179688, 'rgb.min=', -225.73985290527344)
('rgb.max=', 136.10910034179688, 'rgb.min=', -225.88609313964844)
('rgb.max=', 135.88937377929688, 'rgb.min=', -225.90106201171875)
('rgb.max=', 136.01689147949219, 'rgb.min=', -226.23448181152344)
('rgb.max=', 135.7689208984375, 'rgb.min=', -226.10049438476562)
('rgb.max=', 135.93324279785156, 'rgb.min=', -225.97372436523438)
('rgb.max=', 135.88516235351562, 'rgb.min=', -226.06904602050781)
('rgb.max=', 135.71870422363281, 'rgb.min=', -225.9012451171875)
('rgb.max=', 135.9473876953125, 'rgb.min=', -225.829345703125)
('rgb.max=', 135.89205932617188, 'rgb.min=', -225.90206909179688)
('rgb.max=', 135.89447021484375, 'rgb.min=', -225.842529296875)
('rgb.max=', 136.15818786621094, 'rgb.min=', -225.95477294921875)
('rgb.max=', 135.96098327636719, 'rgb.min=', -225.96875)
('rgb.max=', 135.96968078613281, 'rgb.min=', -226.04498291015625)
('rgb.max=', 136.10763549804688, 'rgb.min=', -225.94781494140625)
('rgb.max=', 135.94708251953125, 'rgb.min=', -225.89527893066406)
('rgb.max=', 135.98805236816406, 'rgb.min=', -225.94204711914062)
('rgb.max=', 136.16598510742188, 'rgb.min=', -225.91934204101562)
('rgb.max=', 135.93356323242188, 'rgb.min=', -225.76895141601562)
('rgb.max=', 135.97653198242188, 'rgb.min=', -225.80226135253906)
('rgb.max=', 135.85069274902344, 'rgb.min=', -226.03526306152344)
('rgb.max=', 135.84982299804688, 'rgb.min=', -226.12867736816406)
('rgb.max=', 135.62704467773438, 'rgb.min=', -225.94674682617188)
('rgb.max=', 135.92581176757812, 'rgb.min=', -225.78507995605469)
('rgb.max=', 135.80450439453125, 'rgb.min=', -225.87886047363281)
('rgb.max=', 136.1094970703125, 'rgb.min=', -225.86154174804688)
('rgb.max=', 136.02134704589844, 'rgb.min=', -226.01766967773438)
('rgb.max=', 136.29025268554688, 'rgb.min=', -226.08657836914062)
('rgb.max=', 135.79867553710938, 'rgb.min=', -225.90568542480469)
('rgb.max=', 135.85885620117188, 'rgb.min=', -225.95240783691406)
('rgb.max=', 135.8468017578125, 'rgb.min=', -225.81327819824219)
('rgb.max=', 135.96321105957031, 'rgb.min=', -225.95796203613281)
('rgb.max=', 135.82281494140625, 'rgb.min=', -225.7615966796875)
('rgb.max=', 136.16999816894531, 'rgb.min=', -225.95742797851562)
('rgb.max=', 135.62501525878906, 'rgb.min=', -226.01693725585938)
('rgb.max=', 135.99746704101562, 'rgb.min=', -226.02920532226562)
('rgb.max=', 136.13212585449219, 'rgb.min=', -225.734375)
('rgb.max=', 135.73667907714844, 'rgb.min=', -226.11265563964844)
('rgb.max=', 135.94821166992188, 'rgb.min=', -225.90283203125)
('rgb.max=', 136.17292785644531, 'rgb.min=', -225.83352661132812)
('rgb.max=', 136.08781433105469, 'rgb.min=', -225.81898498535156)
('rgb.max=', 135.67596435546875, 'rgb.min=', -226.05024719238281)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.94215393066406)
('rgb.max=', 135.96125793457031, 'rgb.min=', -225.87138366699219)
('rgb.max=', 135.82431030273438, 'rgb.min=', -226.01930236816406)
('rgb.max=', 135.96437072753906, 'rgb.min=', -225.86326599121094)
('rgb.max=', 135.87492370605469, 'rgb.min=', -225.82752990722656)
('rgb.max=', 136.11795043945312, 'rgb.min=', -225.85151672363281)
('rgb.max=', 135.72604370117188, 'rgb.min=', -225.93896484375)
('rgb.max=', 136.18362426757812, 'rgb.min=', -225.89497375488281)
('rgb.max=', 135.9207763671875, 'rgb.min=', -226.03288269042969)
('rgb.max=', 136.15888977050781, 'rgb.min=', -225.79551696777344)
('rgb.max=', 135.88212585449219, 'rgb.min=', -225.82188415527344)
('rgb.max=', 136.15859985351562, 'rgb.min=', -226.07565307617188)
('rgb.max=', 136.10968017578125, 'rgb.min=', -225.90184020996094)
('rgb.max=', 136.14810180664062, 'rgb.min=', -225.83799743652344)
('rgb.max=', 135.80853271484375, 'rgb.min=', -225.83065795898438)
('rgb.max=', 135.96273803710938, 'rgb.min=', -225.78596496582031)
('rgb.max=', 136.01544189453125, 'rgb.min=', -226.17796325683594)
('rgb.max=', 136.0330810546875, 'rgb.min=', -226.04692077636719)
('rgb.max=', 135.90142822265625, 'rgb.min=', -225.94514465332031)
('rgb.max=', 135.83731079101562, 'rgb.min=', -225.76605224609375)
('rgb.max=', 136.1170654296875, 'rgb.min=', -225.99746704101562)
('rgb.max=', 135.91400146484375, 'rgb.min=', -225.7520751953125)
('rgb.max=', 135.75994873046875, 'rgb.min=', -226.02618408203125)
('rgb.max=', 135.73648071289062, 'rgb.min=', -225.75361633300781)
('rgb.max=', 135.84628295898438, 'rgb.min=', -225.73820495605469)
('rgb.max=', 135.93525695800781, 'rgb.min=', -226.02978515625)
('rgb.max=', 135.91854858398438, 'rgb.min=', -225.93217468261719)
('rgb.max=', 135.75483703613281, 'rgb.min=', -225.94094848632812)
('rgb.max=', 136.17739868164062, 'rgb.min=', -226.04190063476562)
('rgb.max=', 136.06669616699219, 'rgb.min=', -225.74163818359375)
('rgb.max=', 136.01069641113281, 'rgb.min=', -226.00215148925781)
('rgb.max=', 135.64212036132812, 'rgb.min=', -225.85800170898438)
('rgb.max=', 136.1685791015625, 'rgb.min=', -225.98941040039062)
('rgb.max=', 136.06562805175781, 'rgb.min=', -226.0035400390625)
('rgb.max=', 135.78646850585938, 'rgb.min=', -225.96005249023438)
('rgb.max=', 136.09857177734375, 'rgb.min=', -225.91937255859375)
('rgb.max=', 136.02430725097656, 'rgb.min=', -226.02647399902344)
('rgb.max=', 136.01751708984375, 'rgb.min=', -225.97785949707031)
('rgb.max=', 135.92623901367188, 'rgb.min=', -225.96696472167969)
('rgb.max=', 136.15451049804688, 'rgb.min=', -226.07302856445312)
('rgb.max=', 136.05194091796875, 'rgb.min=', -225.9842529296875)
('rgb.max=', 135.80484008789062, 'rgb.min=', -226.05903625488281)
('rgb.max=', 135.73750305175781, 'rgb.min=', -226.01206970214844)
('rgb.max=', 135.76913452148438, 'rgb.min=', -225.74528503417969)
('rgb.max=', 135.900390625, 'rgb.min=', -226.09835815429688)
('rgb.max=', 136.10063171386719, 'rgb.min=', -225.923095703125)
('rgb.max=', 135.95065307617188, 'rgb.min=', -225.93328857421875)
('rgb.max=', 136.10209655761719, 'rgb.min=', -225.77767944335938)
('rgb.max=', 136.24366760253906, 'rgb.min=', -225.86592102050781)
('rgb.max=', 135.94082641601562, 'rgb.min=', -225.95538330078125)
('rgb.max=', 135.85153198242188, 'rgb.min=', -225.99601745605469)
('rgb.max=', 135.89253234863281, 'rgb.min=', -225.87857055664062)
('rgb.max=', 136.17121887207031, 'rgb.min=', -225.52824401855469)
('rgb.max=', 136.0523681640625, 'rgb.min=', -226.07160949707031)
('rgb.max=', 136.05685424804688, 'rgb.min=', -226.09162902832031)
('rgb.max=', 135.54345703125, 'rgb.min=', -225.79336547851562)
('rgb.max=', 135.92752075195312, 'rgb.min=', -225.70323181152344)
('rgb.max=', 135.90814208984375, 'rgb.min=', -226.00920104980469)
('rgb.max=', 135.78756713867188, 'rgb.min=', -226.09721374511719)
('rgb.max=', 136.15325927734375, 'rgb.min=', -225.67286682128906)
('rgb.max=', 135.60121154785156, 'rgb.min=', -225.81988525390625)
('rgb.max=', 136.10519409179688, 'rgb.min=', -226.08113098144531)
('rgb.max=', 135.86106872558594, 'rgb.min=', -226.01593017578125)
('rgb.max=', 136.01235961914062, 'rgb.min=', -225.80645751953125)
('rgb.max=', 135.90742492675781, 'rgb.min=', -226.01527404785156)
('rgb.max=', 136.03176879882812, 'rgb.min=', -225.92776489257812)
('rgb.max=', 135.883056640625, 'rgb.min=', -226.13870239257812)
('rgb.max=', 136.00132751464844, 'rgb.min=', -225.91307067871094)
('rgb.max=', 136.1097412109375, 'rgb.min=', -226.00692749023438)
('rgb.max=', 135.915283203125, 'rgb.min=', -226.10316467285156)
('rgb.max=', 136.09307861328125, 'rgb.min=', -226.11793518066406)
('rgb.max=', 135.83599853515625, 'rgb.min=', -225.81675720214844)
('rgb.max=', 136.15478515625, 'rgb.min=', -225.79115295410156)
('rgb.max=', 136.03680419921875, 'rgb.min=', -225.75003051757812)
('rgb.max=', 136.08979797363281, 'rgb.min=', -225.9293212890625)
('rgb.max=', 135.82826232910156, 'rgb.min=', -226.05999755859375)
('rgb.max=', 135.92449951171875, 'rgb.min=', -225.86224365234375)
('rgb.max=', 136.14369201660156, 'rgb.min=', -226.01286315917969)
('rgb.max=', 135.90237426757812, 'rgb.min=', -225.78114318847656)
('rgb.max=', 135.98529052734375, 'rgb.min=', -225.86874389648438)
('rgb.max=', 136.1065673828125, 'rgb.min=', -225.81956481933594)
('rgb.max=', 135.86679077148438, 'rgb.min=', -225.97265625)
('rgb.max=', 135.98899841308594, 'rgb.min=', -226.09255981445312)
('rgb.max=', 135.68426513671875, 'rgb.min=', -225.94822692871094)
('rgb.max=', 135.87265014648438, 'rgb.min=', -225.93641662597656)
('rgb.max=', 135.79452514648438, 'rgb.min=', -225.88371276855469)
('rgb.max=', 136.03065490722656, 'rgb.min=', -226.06216430664062)
('rgb.max=', 135.99351501464844, 'rgb.min=', -225.86166381835938)
('rgb.max=', 135.84724426269531, 'rgb.min=', -226.05874633789062)
('rgb.max=', 136.07685852050781, 'rgb.min=', -225.71475219726562)
('rgb.max=', 135.92990112304688, 'rgb.min=', -226.04060363769531)
('rgb.max=', 135.92445373535156, 'rgb.min=', -225.81718444824219)
('rgb.max=', 135.7137451171875, 'rgb.min=', -225.9420166015625)
('rgb.max=', 135.67338562011719, 'rgb.min=', -225.78858947753906)
('rgb.max=', 135.86572265625, 'rgb.min=', -226.01698303222656)
('rgb.max=', 135.9013671875, 'rgb.min=', -226.22340393066406)
('rgb.max=', 135.71441650390625, 'rgb.min=', -225.92803955078125)
('rgb.max=', 135.81059265136719, 'rgb.min=', -225.96336364746094)
('rgb.max=', 135.9595947265625, 'rgb.min=', -226.09870910644531)
('rgb.max=', 136.1650390625, 'rgb.min=', -226.15277099609375)
('rgb.max=', 135.93739318847656, 'rgb.min=', -226.28607177734375)
('rgb.max=', 136.14894104003906, 'rgb.min=', -225.93661499023438)
('rgb.max=', 136.06851196289062, 'rgb.min=', -225.77815246582031)
('rgb.max=', 136.1168212890625, 'rgb.min=', -226.1258544921875)
('rgb.max=', 135.94581604003906, 'rgb.min=', -226.05670166015625)
('rgb.max=', 136.17930603027344, 'rgb.min=', -226.14875793457031)
('rgb.max=', 135.63807678222656, 'rgb.min=', -225.95539855957031)
('rgb.max=', 136.00152587890625, 'rgb.min=', -226.08341979980469)
('rgb.max=', 136.08316040039062, 'rgb.min=', -225.93150329589844)
('rgb.max=', 136.12669372558594, 'rgb.min=', -225.86099243164062)
('rgb.max=', 135.98966979980469, 'rgb.min=', -226.11518859863281)
('rgb.max=', 135.81301879882812, 'rgb.min=', -225.84097290039062)
('rgb.max=', 135.90472412109375, 'rgb.min=', -225.82791137695312)
('rgb.max=', 135.6376953125, 'rgb.min=', -226.21186828613281)
('rgb.max=', 135.72882080078125, 'rgb.min=', -225.97805786132812)
('rgb.max=', 135.84732055664062, 'rgb.min=', -226.1025390625)
('rgb.max=', 135.89781188964844, 'rgb.min=', -225.91514587402344)
('rgb.max=', 135.97193908691406, 'rgb.min=', -225.98176574707031)
('rgb.max=', 135.99761962890625, 'rgb.min=', -226.06413269042969)
('rgb.max=', 135.96365356445312, 'rgb.min=', -225.88423156738281)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.255706')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6977 ', 'GAN acc 0.4492', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5000', 'Total loss: 1.3925', 'for batch', 0)
('GAN loss 0.7005 ', 'GAN acc 0.4336', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4863', 'Total loss: 1.3931', 'for batch', 1)
('GAN loss 0.6999 ', 'GAN acc 0.4531', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4980', 'Total loss: 1.3948', 'for batch', 2)
('GAN loss 0.6966 ', 'GAN acc 0.4922', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5098', 'Total loss: 1.3890', 'for batch', 3)
('GAN loss 0.6948 ', 'GAN acc 0.4922', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5273', 'Total loss: 1.3878', 'for batch', 4)
('GAN loss 0.6914 ', 'GAN acc 0.5391', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4805', 'Total loss: 1.3886', 'for batch', 5)
('GAN loss 0.6872 ', 'GAN acc 0.6055', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.3828', 'for batch', 6)
('GAN loss 0.6868 ', 'GAN acc 0.5703', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4922', 'Total loss: 1.3832', 'for batch', 7)
('GAN loss 0.6874 ', 'GAN acc 0.5898', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5059', 'Total loss: 1.3824', 'for batch', 8)
('GAN loss 0.6827 ', 'GAN acc 0.6016', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4902', 'Total loss: 1.3769', 'for batch', 9)
('GAN loss 0.6795 ', 'GAN acc 0.6250', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4922', 'Total loss: 1.3767', 'for batch', 10)
('GAN loss 0.6822 ', 'GAN acc 0.6406', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4492', 'Total loss: 1.3798', 'for batch', 11)
('GAN loss 0.6839 ', 'GAN acc 0.5859', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5020', 'Total loss: 1.3788', 'for batch', 12)
('GAN loss 0.6827 ', 'GAN acc 0.6055', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4941', 'Total loss: 1.3797', 'for batch', 13)
('GAN loss 0.6876 ', 'GAN acc 0.5938', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5215', 'Total loss: 1.3811', 'for batch', 14)
('GAN loss 0.6929 ', 'GAN acc 0.4961', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4922', 'Total loss: 1.3876', 'for batch', 15)
('GAN loss 0.6955 ', 'GAN acc 0.4570', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5020', 'Total loss: 1.3897', 'for batch', 16)
('GAN loss 0.6989 ', 'GAN acc 0.4297', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4980', 'Total loss: 1.3941', 'for batch', 17)
('GAN loss 0.6984 ', 'GAN acc 0.4492', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5000', 'Total loss: 1.3910', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51513195)
('DISCRIMINATOR_Imagem FAKE=', 0.51526129)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.0484619140625, 'rgb.min=', -225.76171875)
('rgb.max=', 135.89842224121094, 'rgb.min=', -226.03147888183594)
('rgb.max=', 136.201416015625, 'rgb.min=', -225.93418884277344)
('rgb.max=', 136.01902770996094, 'rgb.min=', -226.09571838378906)
('rgb.max=', 136.13389587402344, 'rgb.min=', -225.95681762695312)
('rgb.max=', 136.23118591308594, 'rgb.min=', -226.48323059082031)
('rgb.max=', 135.82801818847656, 'rgb.min=', -226.08921813964844)
('rgb.max=', 135.9637451171875, 'rgb.min=', -225.93083190917969)
('rgb.max=', 135.84925842285156, 'rgb.min=', -226.10359191894531)
('rgb.max=', 135.8094482421875, 'rgb.min=', -226.05522155761719)
('rgb.max=', 135.72427368164062, 'rgb.min=', -226.1031494140625)
('rgb.max=', 135.82955932617188, 'rgb.min=', -226.06593322753906)
('rgb.max=', 135.8211669921875, 'rgb.min=', -226.1148681640625)
('rgb.max=', 135.94790649414062, 'rgb.min=', -226.09419250488281)
('rgb.max=', 135.79116821289062, 'rgb.min=', -226.01806640625)
('rgb.max=', 135.78648376464844, 'rgb.min=', -226.1168212890625)
('rgb.max=', 135.81208801269531, 'rgb.min=', -226.04478454589844)
('rgb.max=', 135.90370178222656, 'rgb.min=', -225.84028625488281)
('rgb.max=', 135.93289184570312, 'rgb.min=', -226.06404113769531)
('rgb.max=', 135.96868896484375, 'rgb.min=', -226.25895690917969)
('rgb.max=', 136.12071228027344, 'rgb.min=', -225.91044616699219)
('rgb.max=', 136.22068786621094, 'rgb.min=', -225.87376403808594)
('rgb.max=', 136.1875, 'rgb.min=', -225.85969543457031)
('rgb.max=', 135.95089721679688, 'rgb.min=', -225.62237548828125)
('rgb.max=', 135.77659606933594, 'rgb.min=', -226.00518798828125)
('rgb.max=', 136.16937255859375, 'rgb.min=', -226.0020751953125)
('rgb.max=', 136.12228393554688, 'rgb.min=', -226.0565185546875)
('rgb.max=', 135.87045288085938, 'rgb.min=', -225.87789916992188)
('rgb.max=', 135.9091796875, 'rgb.min=', -225.85397338867188)
('rgb.max=', 135.94587707519531, 'rgb.min=', -225.99626159667969)
('rgb.max=', 135.95062255859375, 'rgb.min=', -225.96795654296875)
('rgb.max=', 135.83168029785156, 'rgb.min=', -225.88327026367188)
('rgb.max=', 136.02629089355469, 'rgb.min=', -226.04043579101562)
('rgb.max=', 135.87672424316406, 'rgb.min=', -225.98051452636719)
('rgb.max=', 135.87448120117188, 'rgb.min=', -226.02044677734375)
('rgb.max=', 136.07157897949219, 'rgb.min=', -225.93011474609375)
('rgb.max=', 136.17184448242188, 'rgb.min=', -225.9476318359375)
('rgb.max=', 136.13862609863281, 'rgb.min=', -226.07168579101562)
('rgb.max=', 135.9710693359375, 'rgb.min=', -225.90444946289062)
('rgb.max=', 135.96405029296875, 'rgb.min=', -226.00260925292969)
('rgb.max=', 135.70121765136719, 'rgb.min=', -225.83164978027344)
('rgb.max=', 135.97677612304688, 'rgb.min=', -226.04534912109375)
('rgb.max=', 135.88873291015625, 'rgb.min=', -225.94929504394531)
('rgb.max=', 135.89793395996094, 'rgb.min=', -225.99189758300781)
('rgb.max=', 136.06820678710938, 'rgb.min=', -226.30027770996094)
('rgb.max=', 135.56874084472656, 'rgb.min=', -225.87080383300781)
('rgb.max=', 136.01730346679688, 'rgb.min=', -225.91424560546875)
('rgb.max=', 135.79570007324219, 'rgb.min=', -225.76901245117188)
('rgb.max=', 135.93716430664062, 'rgb.min=', -225.92245483398438)
('rgb.max=', 136.261962890625, 'rgb.min=', -226.19914245605469)
('rgb.max=', 136.02572631835938, 'rgb.min=', -226.04991149902344)
('rgb.max=', 136.22433471679688, 'rgb.min=', -225.95767211914062)
('rgb.max=', 135.66378784179688, 'rgb.min=', -225.97956848144531)
('rgb.max=', 135.83184814453125, 'rgb.min=', -226.02687072753906)
('rgb.max=', 136.13946533203125, 'rgb.min=', -225.99746704101562)
('rgb.max=', 136.11622619628906, 'rgb.min=', -226.02493286132812)
('rgb.max=', 135.88409423828125, 'rgb.min=', -226.00572204589844)
('rgb.max=', 135.80712890625, 'rgb.min=', -225.95413208007812)
('rgb.max=', 135.84806823730469, 'rgb.min=', -225.91935729980469)
('rgb.max=', 135.56439208984375, 'rgb.min=', -226.1253662109375)
('rgb.max=', 135.99197387695312, 'rgb.min=', -226.10958862304688)
('rgb.max=', 135.73538208007812, 'rgb.min=', -225.76779174804688)
('rgb.max=', 135.7069091796875, 'rgb.min=', -226.12290954589844)
('rgb.max=', 135.72953796386719, 'rgb.min=', -226.21705627441406)
('rgb.max=', 136.35140991210938, 'rgb.min=', -225.76515197753906)
('rgb.max=', 135.9344482421875, 'rgb.min=', -226.11239624023438)
('rgb.max=', 135.65093994140625, 'rgb.min=', -225.85693359375)
('rgb.max=', 135.69622802734375, 'rgb.min=', -226.0689697265625)
('rgb.max=', 136.05354309082031, 'rgb.min=', -226.13722229003906)
('rgb.max=', 136.06251525878906, 'rgb.min=', -226.10179138183594)
('rgb.max=', 136.02023315429688, 'rgb.min=', -226.135498046875)
('rgb.max=', 135.75473022460938, 'rgb.min=', -226.11451721191406)
('rgb.max=', 135.90812683105469, 'rgb.min=', -226.16694641113281)
('rgb.max=', 135.97276306152344, 'rgb.min=', -226.18109130859375)
('rgb.max=', 135.88638305664062, 'rgb.min=', -225.73057556152344)
('rgb.max=', 136.10279846191406, 'rgb.min=', -225.95730590820312)
('rgb.max=', 136.26283264160156, 'rgb.min=', -226.118896484375)
('rgb.max=', 136.06340026855469, 'rgb.min=', -225.72413635253906)
('rgb.max=', 135.75791931152344, 'rgb.min=', -226.09504699707031)
('rgb.max=', 135.90283203125, 'rgb.min=', -225.84117126464844)
('rgb.max=', 136.03654479980469, 'rgb.min=', -225.59698486328125)
('rgb.max=', 135.83123779296875, 'rgb.min=', -225.8465576171875)
('rgb.max=', 135.83155822753906, 'rgb.min=', -226.004638671875)
('rgb.max=', 135.99710083007812, 'rgb.min=', -225.97500610351562)
('rgb.max=', 135.99652099609375, 'rgb.min=', -226.21104431152344)
('rgb.max=', 135.84721374511719, 'rgb.min=', -225.99148559570312)
('rgb.max=', 136.036865234375, 'rgb.min=', -225.80253601074219)
('rgb.max=', 135.77911376953125, 'rgb.min=', -225.87985229492188)
('rgb.max=', 135.96511840820312, 'rgb.min=', -226.15414428710938)
('rgb.max=', 135.6103515625, 'rgb.min=', -225.72688293457031)
('rgb.max=', 135.85958862304688, 'rgb.min=', -226.0050048828125)
('rgb.max=', 135.76332092285156, 'rgb.min=', -226.13473510742188)
('rgb.max=', 135.84048461914062, 'rgb.min=', -226.22093200683594)
('rgb.max=', 135.76020812988281, 'rgb.min=', -225.89021301269531)
('rgb.max=', 135.78427124023438, 'rgb.min=', -225.73733520507812)
('rgb.max=', 136.10260009765625, 'rgb.min=', -225.82112121582031)
('rgb.max=', 135.90605163574219, 'rgb.min=', -225.97319030761719)
('rgb.max=', 135.95559692382812, 'rgb.min=', -226.27510070800781)
('rgb.max=', 135.75405883789062, 'rgb.min=', -226.17021179199219)
('rgb.max=', 135.93684387207031, 'rgb.min=', -226.03361511230469)
('rgb.max=', 135.90449523925781, 'rgb.min=', -226.10734558105469)
('rgb.max=', 135.7030029296875, 'rgb.min=', -225.88029479980469)
('rgb.max=', 135.93975830078125, 'rgb.min=', -225.81941223144531)
('rgb.max=', 135.89959716796875, 'rgb.min=', -225.93330383300781)
('rgb.max=', 135.88543701171875, 'rgb.min=', -225.8475341796875)
('rgb.max=', 136.20730590820312, 'rgb.min=', -226.10092163085938)
('rgb.max=', 136.02203369140625, 'rgb.min=', -226.03739929199219)
('rgb.max=', 135.96611022949219, 'rgb.min=', -226.13888549804688)
('rgb.max=', 136.16668701171875, 'rgb.min=', -225.94140625)
('rgb.max=', 135.93798828125, 'rgb.min=', -225.87600708007812)
('rgb.max=', 135.97511291503906, 'rgb.min=', -225.90194702148438)
('rgb.max=', 136.21652221679688, 'rgb.min=', -225.93183898925781)
('rgb.max=', 135.96293640136719, 'rgb.min=', -225.74916076660156)
('rgb.max=', 135.94952392578125, 'rgb.min=', -225.733154296875)
('rgb.max=', 135.83929443359375, 'rgb.min=', -226.09512329101562)
('rgb.max=', 135.83442687988281, 'rgb.min=', -226.25639343261719)
('rgb.max=', 135.60115051269531, 'rgb.min=', -226.11386108398438)
('rgb.max=', 135.918701171875, 'rgb.min=', -225.77363586425781)
('rgb.max=', 135.78619384765625, 'rgb.min=', -225.84748840332031)
('rgb.max=', 136.09518432617188, 'rgb.min=', -225.88908386230469)
('rgb.max=', 136.0201416015625, 'rgb.min=', -226.12326049804688)
('rgb.max=', 136.27027893066406, 'rgb.min=', -226.10775756835938)
('rgb.max=', 135.78607177734375, 'rgb.min=', -225.9205322265625)
('rgb.max=', 135.83673095703125, 'rgb.min=', -226.02810668945312)
('rgb.max=', 135.82635498046875, 'rgb.min=', -225.81634521484375)
('rgb.max=', 135.97184753417969, 'rgb.min=', -226.02290344238281)
('rgb.max=', 135.82402038574219, 'rgb.min=', -225.74519348144531)
('rgb.max=', 136.17214965820312, 'rgb.min=', -225.999267578125)
('rgb.max=', 135.61674499511719, 'rgb.min=', -226.07960510253906)
('rgb.max=', 135.97052001953125, 'rgb.min=', -226.12689208984375)
('rgb.max=', 136.06887817382812, 'rgb.min=', -225.72874450683594)
('rgb.max=', 135.76490783691406, 'rgb.min=', -226.11579895019531)
('rgb.max=', 135.92987060546875, 'rgb.min=', -225.94847106933594)
('rgb.max=', 136.19686889648438, 'rgb.min=', -225.846923828125)
('rgb.max=', 136.11773681640625, 'rgb.min=', -225.82719421386719)
('rgb.max=', 135.67057800292969, 'rgb.min=', -226.21388244628906)
('rgb.max=', 135.85234069824219, 'rgb.min=', -226.17391967773438)
('rgb.max=', 135.95451354980469, 'rgb.min=', -225.83291625976562)
('rgb.max=', 135.81906127929688, 'rgb.min=', -226.06614685058594)
('rgb.max=', 135.95295715332031, 'rgb.min=', -225.86090087890625)
('rgb.max=', 135.86259460449219, 'rgb.min=', -225.80183410644531)
('rgb.max=', 136.11036682128906, 'rgb.min=', -225.89935302734375)
('rgb.max=', 135.71571350097656, 'rgb.min=', -226.04270935058594)
('rgb.max=', 136.23321533203125, 'rgb.min=', -226.0457763671875)
('rgb.max=', 135.9398193359375, 'rgb.min=', -226.09634399414062)
('rgb.max=', 136.21778869628906, 'rgb.min=', -225.7957763671875)
('rgb.max=', 135.87176513671875, 'rgb.min=', -225.859619140625)
('rgb.max=', 136.17546081542969, 'rgb.min=', -226.03977966308594)
('rgb.max=', 136.14791870117188, 'rgb.min=', -226.09323120117188)
('rgb.max=', 136.15463256835938, 'rgb.min=', -225.81454467773438)
('rgb.max=', 135.80682373046875, 'rgb.min=', -225.83955383300781)
('rgb.max=', 135.99510192871094, 'rgb.min=', -225.75906372070312)
('rgb.max=', 136.01605224609375, 'rgb.min=', -226.37046813964844)
('rgb.max=', 136.03643798828125, 'rgb.min=', -226.02874755859375)
('rgb.max=', 135.90483093261719, 'rgb.min=', -226.01275634765625)
('rgb.max=', 135.83451843261719, 'rgb.min=', -225.73652648925781)
('rgb.max=', 136.16891479492188, 'rgb.min=', -226.18438720703125)
('rgb.max=', 135.902587890625, 'rgb.min=', -225.75456237792969)
('rgb.max=', 135.75143432617188, 'rgb.min=', -226.11834716796875)
('rgb.max=', 135.72100830078125, 'rgb.min=', -225.72209167480469)
('rgb.max=', 135.83761596679688, 'rgb.min=', -225.74824523925781)
('rgb.max=', 135.92601013183594, 'rgb.min=', -226.058349609375)
('rgb.max=', 135.9071044921875, 'rgb.min=', -225.95603942871094)
('rgb.max=', 135.75936889648438, 'rgb.min=', -225.86972045898438)
('rgb.max=', 136.24032592773438, 'rgb.min=', -226.03280639648438)
('rgb.max=', 136.06288146972656, 'rgb.min=', -225.71214294433594)
('rgb.max=', 136.00279235839844, 'rgb.min=', -226.1650390625)
('rgb.max=', 135.62274169921875, 'rgb.min=', -225.88917541503906)
('rgb.max=', 136.22665405273438, 'rgb.min=', -226.09709167480469)
('rgb.max=', 136.06301879882812, 'rgb.min=', -225.99568176269531)
('rgb.max=', 135.782958984375, 'rgb.min=', -225.98576354980469)
('rgb.max=', 136.08578491210938, 'rgb.min=', -225.97145080566406)
('rgb.max=', 136.0205078125, 'rgb.min=', -225.98104858398438)
('rgb.max=', 136.00570678710938, 'rgb.min=', -226.01863098144531)
('rgb.max=', 135.922607421875, 'rgb.min=', -225.94465637207031)
('rgb.max=', 136.19100952148438, 'rgb.min=', -226.13764953613281)
('rgb.max=', 136.08572387695312, 'rgb.min=', -226.11415100097656)
('rgb.max=', 135.80596923828125, 'rgb.min=', -226.12953186035156)
('rgb.max=', 135.7281494140625, 'rgb.min=', -225.91439819335938)
('rgb.max=', 135.75521850585938, 'rgb.min=', -225.77206420898438)
('rgb.max=', 135.88642883300781, 'rgb.min=', -226.18136596679688)
('rgb.max=', 136.07337951660156, 'rgb.min=', -225.97091674804688)
('rgb.max=', 135.94027709960938, 'rgb.min=', -225.90943908691406)
('rgb.max=', 136.10792541503906, 'rgb.min=', -225.73860168457031)
('rgb.max=', 136.24356079101562, 'rgb.min=', -225.82209777832031)
('rgb.max=', 135.94483947753906, 'rgb.min=', -226.10081481933594)
('rgb.max=', 135.84220886230469, 'rgb.min=', -226.005126953125)
('rgb.max=', 135.89048767089844, 'rgb.min=', -225.93919372558594)
('rgb.max=', 136.23898315429688, 'rgb.min=', -225.52735900878906)
('rgb.max=', 136.04263305664062, 'rgb.min=', -226.0560302734375)
('rgb.max=', 136.09628295898438, 'rgb.min=', -226.22895812988281)
('rgb.max=', 135.55122375488281, 'rgb.min=', -225.80758666992188)
('rgb.max=', 135.90455627441406, 'rgb.min=', -225.65962219238281)
('rgb.max=', 135.89530944824219, 'rgb.min=', -226.06492614746094)
('rgb.max=', 135.79518127441406, 'rgb.min=', -226.15281677246094)
('rgb.max=', 136.19003295898438, 'rgb.min=', -225.66970825195312)
('rgb.max=', 135.61215209960938, 'rgb.min=', -225.81871032714844)
('rgb.max=', 136.11111450195312, 'rgb.min=', -226.1851806640625)
('rgb.max=', 135.86648559570312, 'rgb.min=', -226.08125305175781)
('rgb.max=', 136.02059936523438, 'rgb.min=', -225.76252746582031)
('rgb.max=', 135.90283203125, 'rgb.min=', -226.08711242675781)
('rgb.max=', 136.04954528808594, 'rgb.min=', -225.90827941894531)
('rgb.max=', 135.866943359375, 'rgb.min=', -226.2213134765625)
('rgb.max=', 136.0499267578125, 'rgb.min=', -225.93693542480469)
('rgb.max=', 136.10366821289062, 'rgb.min=', -226.01123046875)
('rgb.max=', 135.90087890625, 'rgb.min=', -226.17379760742188)
('rgb.max=', 136.08837890625, 'rgb.min=', -226.20301818847656)
('rgb.max=', 135.79330444335938, 'rgb.min=', -225.80181884765625)
('rgb.max=', 136.17729187011719, 'rgb.min=', -225.78767395019531)
('rgb.max=', 136.07710266113281, 'rgb.min=', -225.72840881347656)
('rgb.max=', 136.09695434570312, 'rgb.min=', -225.95729064941406)
('rgb.max=', 135.80035400390625, 'rgb.min=', -226.13037109375)
('rgb.max=', 135.94862365722656, 'rgb.min=', -225.85174560546875)
('rgb.max=', 136.17768859863281, 'rgb.min=', -226.06884765625)
('rgb.max=', 135.90473937988281, 'rgb.min=', -225.75439453125)
('rgb.max=', 135.97239685058594, 'rgb.min=', -225.84942626953125)
('rgb.max=', 136.13922119140625, 'rgb.min=', -225.79548645019531)
('rgb.max=', 135.87257385253906, 'rgb.min=', -225.99623107910156)
('rgb.max=', 135.98214721679688, 'rgb.min=', -226.16279602050781)
('rgb.max=', 135.6722412109375, 'rgb.min=', -225.92227172851562)
('rgb.max=', 135.88177490234375, 'rgb.min=', -225.96363830566406)
('rgb.max=', 135.78642272949219, 'rgb.min=', -225.88996887207031)
('rgb.max=', 136.0330810546875, 'rgb.min=', -226.28857421875)
('rgb.max=', 136.00750732421875, 'rgb.min=', -225.83132934570312)
('rgb.max=', 135.84219360351562, 'rgb.min=', -226.06643676757812)
('rgb.max=', 136.13288879394531, 'rgb.min=', -225.70835876464844)
('rgb.max=', 135.91192626953125, 'rgb.min=', -226.12351989746094)
('rgb.max=', 135.93856811523438, 'rgb.min=', -225.82347106933594)
('rgb.max=', 135.71182250976562, 'rgb.min=', -225.98806762695312)
('rgb.max=', 135.66751098632812, 'rgb.min=', -225.76937866210938)
('rgb.max=', 135.86076354980469, 'rgb.min=', -226.0848388671875)
('rgb.max=', 135.89169311523438, 'rgb.min=', -226.28080749511719)
('rgb.max=', 135.69540405273438, 'rgb.min=', -225.9237060546875)
('rgb.max=', 135.81256103515625, 'rgb.min=', -226.03715515136719)
('rgb.max=', 135.94549560546875, 'rgb.min=', -226.15628051757812)
('rgb.max=', 136.19804382324219, 'rgb.min=', -226.16291809082031)
('rgb.max=', 135.93818664550781, 'rgb.min=', -226.33879089355469)
('rgb.max=', 136.1883544921875, 'rgb.min=', -225.96553039550781)
('rgb.max=', 136.12294006347656, 'rgb.min=', -225.75950622558594)
('rgb.max=', 136.14662170410156, 'rgb.min=', -226.13894653320312)
('rgb.max=', 135.96849060058594, 'rgb.min=', -226.11320495605469)
('rgb.max=', 136.19520568847656, 'rgb.min=', -226.113037109375)
('rgb.max=', 135.64846801757812, 'rgb.min=', -225.96006774902344)
('rgb.max=', 135.9888916015625, 'rgb.min=', -226.23538208007812)
('rgb.max=', 136.08146667480469, 'rgb.min=', -225.93211364746094)
('rgb.max=', 136.1695556640625, 'rgb.min=', -225.85063171386719)
('rgb.max=', 136.00422668457031, 'rgb.min=', -226.27745056152344)
('rgb.max=', 135.81776428222656, 'rgb.min=', -225.82183837890625)
('rgb.max=', 135.90322875976562, 'rgb.min=', -225.8282470703125)
('rgb.max=', 135.61932373046875, 'rgb.min=', -226.28858947753906)
('rgb.max=', 135.73515319824219, 'rgb.min=', -225.98095703125)
('rgb.max=', 135.85031127929688, 'rgb.min=', -226.17262268066406)
('rgb.max=', 135.91415405273438, 'rgb.min=', -225.93365478515625)
('rgb.max=', 135.91650390625, 'rgb.min=', -226.01649475097656)
('rgb.max=', 135.98539733886719, 'rgb.min=', -226.12770080566406)
('rgb.max=', 135.93736267089844, 'rgb.min=', -225.89836120605469)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.834050')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6964 ', 'GAN acc 0.4453', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4863', 'Total loss: 1.3913', 'for batch', 0)
('GAN loss 0.7039 ', 'GAN acc 0.4023', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4746', 'Total loss: 1.3996', 'for batch', 1)
('GAN loss 0.6957 ', 'GAN acc 0.5078', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4824', 'Total loss: 1.3918', 'for batch', 2)
('GAN loss 0.6979 ', 'GAN acc 0.4883', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5215', 'Total loss: 1.3906', 'for batch', 3)
('GAN loss 0.6947 ', 'GAN acc 0.5352', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5234', 'Total loss: 1.3875', 'for batch', 4)
('GAN loss 0.6917 ', 'GAN acc 0.5391', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5234', 'Total loss: 1.3856', 'for batch', 5)
('GAN loss 0.6923 ', 'GAN acc 0.5391', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4668', 'Total loss: 1.3897', 'for batch', 6)
('GAN loss 0.6868 ', 'GAN acc 0.5742', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4746', 'Total loss: 1.3844', 'for batch', 7)
('GAN loss 0.6871 ', 'GAN acc 0.5703', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4805', 'Total loss: 1.3818', 'for batch', 8)
('GAN loss 0.6857 ', 'GAN acc 0.5664', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5098', 'Total loss: 1.3776', 'for batch', 9)
('GAN loss 0.6846 ', 'GAN acc 0.5859', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5117', 'Total loss: 1.3776', 'for batch', 10)
('GAN loss 0.6846 ', 'GAN acc 0.6016', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4844', 'Total loss: 1.3796', 'for batch', 11)
('GAN loss 0.6899 ', 'GAN acc 0.5234', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4824', 'Total loss: 1.3861', 'for batch', 12)
('GAN loss 0.6848 ', 'GAN acc 0.5938', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5117', 'Total loss: 1.3767', 'for batch', 13)
('GAN loss 0.6882 ', 'GAN acc 0.5430', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4805', 'Total loss: 1.3833', 'for batch', 14)
('GAN loss 0.6902 ', 'GAN acc 0.5703', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4902', 'Total loss: 1.3846', 'for batch', 15)
('GAN loss 0.6899 ', 'GAN acc 0.5273', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5098', 'Total loss: 1.3838', 'for batch', 16)
('GAN loss 0.6955 ', 'GAN acc 0.4375', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4863', 'Total loss: 1.3904', 'for batch', 17)
('GAN loss 0.6967 ', 'GAN acc 0.5000', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5215', 'Total loss: 1.3915', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5144363)
('DISCRIMINATOR_Imagem FAKE=', 0.51447874)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.07572937011719, 'rgb.min=', -225.78118896484375)
('rgb.max=', 135.90176391601562, 'rgb.min=', -226.04365539550781)
('rgb.max=', 136.15924072265625, 'rgb.min=', -225.919921875)
('rgb.max=', 136.00920104980469, 'rgb.min=', -226.08277893066406)
('rgb.max=', 136.16502380371094, 'rgb.min=', -225.93450927734375)
('rgb.max=', 136.21621704101562, 'rgb.min=', -226.41506958007812)
('rgb.max=', 135.82923889160156, 'rgb.min=', -226.15769958496094)
('rgb.max=', 135.9300537109375, 'rgb.min=', -225.96499633789062)
('rgb.max=', 135.87957763671875, 'rgb.min=', -226.08784484863281)
('rgb.max=', 135.80642700195312, 'rgb.min=', -226.05537414550781)
('rgb.max=', 135.73274230957031, 'rgb.min=', -226.17662048339844)
('rgb.max=', 135.83319091796875, 'rgb.min=', -226.04217529296875)
('rgb.max=', 135.79046630859375, 'rgb.min=', -226.11651611328125)
('rgb.max=', 135.94384765625, 'rgb.min=', -226.08885192871094)
('rgb.max=', 135.79399108886719, 'rgb.min=', -226.00634765625)
('rgb.max=', 135.77394104003906, 'rgb.min=', -226.0423583984375)
('rgb.max=', 135.81378173828125, 'rgb.min=', -226.01889038085938)
('rgb.max=', 135.89759826660156, 'rgb.min=', -225.83918762207031)
('rgb.max=', 135.91310119628906, 'rgb.min=', -226.10595703125)
('rgb.max=', 135.9495849609375, 'rgb.min=', -226.33818054199219)
('rgb.max=', 136.11468505859375, 'rgb.min=', -225.92800903320312)
('rgb.max=', 136.18862915039062, 'rgb.min=', -225.8946533203125)
('rgb.max=', 136.16778564453125, 'rgb.min=', -225.84233093261719)
('rgb.max=', 135.98423767089844, 'rgb.min=', -225.73771667480469)
('rgb.max=', 135.77311706542969, 'rgb.min=', -226.0404052734375)
('rgb.max=', 136.128173828125, 'rgb.min=', -225.98851013183594)
('rgb.max=', 136.12858581542969, 'rgb.min=', -226.06227111816406)
('rgb.max=', 135.8759765625, 'rgb.min=', -225.86955261230469)
('rgb.max=', 135.89659118652344, 'rgb.min=', -225.89103698730469)
('rgb.max=', 135.95489501953125, 'rgb.min=', -226.00741577148438)
('rgb.max=', 135.93403625488281, 'rgb.min=', -225.96736145019531)
('rgb.max=', 135.8426513671875, 'rgb.min=', -225.913818359375)
('rgb.max=', 136.04533386230469, 'rgb.min=', -226.09759521484375)
('rgb.max=', 135.86628723144531, 'rgb.min=', -226.03608703613281)
('rgb.max=', 135.90361022949219, 'rgb.min=', -226.05766296386719)
('rgb.max=', 136.05282592773438, 'rgb.min=', -225.94807434082031)
('rgb.max=', 136.13468933105469, 'rgb.min=', -226.04067993164062)
('rgb.max=', 136.093505859375, 'rgb.min=', -226.11085510253906)
('rgb.max=', 136.001953125, 'rgb.min=', -225.91159057617188)
('rgb.max=', 135.993896484375, 'rgb.min=', -225.99887084960938)
('rgb.max=', 135.71232604980469, 'rgb.min=', -225.86593627929688)
('rgb.max=', 135.9449462890625, 'rgb.min=', -226.09185791015625)
('rgb.max=', 135.89247131347656, 'rgb.min=', -225.97090148925781)
('rgb.max=', 135.93864440917969, 'rgb.min=', -226.01258850097656)
('rgb.max=', 135.98992919921875, 'rgb.min=', -226.37940979003906)
('rgb.max=', 135.578369140625, 'rgb.min=', -225.87803649902344)
('rgb.max=', 136.01397705078125, 'rgb.min=', -225.9375)
('rgb.max=', 135.80299377441406, 'rgb.min=', -225.75790405273438)
('rgb.max=', 135.93185424804688, 'rgb.min=', -225.96240234375)
('rgb.max=', 136.21038818359375, 'rgb.min=', -226.06471252441406)
('rgb.max=', 136.01373291015625, 'rgb.min=', -226.07839965820312)
('rgb.max=', 136.23683166503906, 'rgb.min=', -225.95866394042969)
('rgb.max=', 135.69816589355469, 'rgb.min=', -226.00370788574219)
('rgb.max=', 135.84713745117188, 'rgb.min=', -226.021484375)
('rgb.max=', 136.12336730957031, 'rgb.min=', -225.98262023925781)
('rgb.max=', 136.105712890625, 'rgb.min=', -226.04537963867188)
('rgb.max=', 135.88961791992188, 'rgb.min=', -226.00994873046875)
('rgb.max=', 135.80555725097656, 'rgb.min=', -225.97531127929688)
('rgb.max=', 135.85061645507812, 'rgb.min=', -225.9532470703125)
('rgb.max=', 135.57646179199219, 'rgb.min=', -226.12812805175781)
('rgb.max=', 135.98480224609375, 'rgb.min=', -226.06179809570312)
('rgb.max=', 135.76377868652344, 'rgb.min=', -225.77519226074219)
('rgb.max=', 135.67961120605469, 'rgb.min=', -226.04499816894531)
('rgb.max=', 135.73204040527344, 'rgb.min=', -226.29541015625)
('rgb.max=', 136.37310791015625, 'rgb.min=', -225.79269409179688)
('rgb.max=', 135.92495727539062, 'rgb.min=', -226.12532043457031)
('rgb.max=', 135.66336059570312, 'rgb.min=', -225.88465881347656)
('rgb.max=', 135.71438598632812, 'rgb.min=', -226.10176086425781)
('rgb.max=', 136.07164001464844, 'rgb.min=', -226.11637878417969)
('rgb.max=', 136.09716796875, 'rgb.min=', -226.12570190429688)
('rgb.max=', 136.0419921875, 'rgb.min=', -226.09716796875)
('rgb.max=', 135.7735595703125, 'rgb.min=', -226.08792114257812)
('rgb.max=', 135.88304138183594, 'rgb.min=', -226.23001098632812)
('rgb.max=', 135.95442199707031, 'rgb.min=', -226.13043212890625)
('rgb.max=', 135.92306518554688, 'rgb.min=', -225.7469482421875)
('rgb.max=', 136.0723876953125, 'rgb.min=', -225.99156188964844)
('rgb.max=', 136.26560974121094, 'rgb.min=', -226.05120849609375)
('rgb.max=', 136.08209228515625, 'rgb.min=', -225.82511901855469)
('rgb.max=', 135.7838134765625, 'rgb.min=', -226.05415344238281)
('rgb.max=', 135.90908813476562, 'rgb.min=', -225.89300537109375)
('rgb.max=', 136.06562805175781, 'rgb.min=', -225.61955261230469)
('rgb.max=', 135.833251953125, 'rgb.min=', -225.93162536621094)
('rgb.max=', 135.84107971191406, 'rgb.min=', -226.00767517089844)
('rgb.max=', 136.01773071289062, 'rgb.min=', -225.93963623046875)
('rgb.max=', 136.02059936523438, 'rgb.min=', -226.2576904296875)
('rgb.max=', 135.85287475585938, 'rgb.min=', -226.0467529296875)
('rgb.max=', 136.0543212890625, 'rgb.min=', -225.80351257324219)
('rgb.max=', 135.79396057128906, 'rgb.min=', -225.94523620605469)
('rgb.max=', 135.94989013671875, 'rgb.min=', -226.21939086914062)
('rgb.max=', 135.61396789550781, 'rgb.min=', -225.76405334472656)
('rgb.max=', 135.89544677734375, 'rgb.min=', -225.98893737792969)
('rgb.max=', 135.76408386230469, 'rgb.min=', -226.19380187988281)
('rgb.max=', 135.83929443359375, 'rgb.min=', -226.33456420898438)
('rgb.max=', 135.77540588378906, 'rgb.min=', -225.92219543457031)
('rgb.max=', 135.78123474121094, 'rgb.min=', -225.77687072753906)
('rgb.max=', 136.11747741699219, 'rgb.min=', -225.84243774414062)
('rgb.max=', 135.90774536132812, 'rgb.min=', -225.91053771972656)
('rgb.max=', 135.952392578125, 'rgb.min=', -226.37039184570312)
('rgb.max=', 135.76406860351562, 'rgb.min=', -226.17759704589844)
('rgb.max=', 135.92779541015625, 'rgb.min=', -226.03402709960938)
('rgb.max=', 135.87063598632812, 'rgb.min=', -226.12136840820312)
('rgb.max=', 135.71357727050781, 'rgb.min=', -225.90927124023438)
('rgb.max=', 135.97943115234375, 'rgb.min=', -225.82997131347656)
('rgb.max=', 135.88795471191406, 'rgb.min=', -225.92446899414062)
('rgb.max=', 135.89173889160156, 'rgb.min=', -225.81846618652344)
('rgb.max=', 136.18879699707031, 'rgb.min=', -226.01142883300781)
('rgb.max=', 136.02891540527344, 'rgb.min=', -226.04345703125)
('rgb.max=', 135.94744873046875, 'rgb.min=', -226.08625793457031)
('rgb.max=', 136.15606689453125, 'rgb.min=', -225.98558044433594)
('rgb.max=', 135.968505859375, 'rgb.min=', -225.88328552246094)
('rgb.max=', 135.9830322265625, 'rgb.min=', -225.96083068847656)
('rgb.max=', 136.18730163574219, 'rgb.min=', -225.90347290039062)
('rgb.max=', 135.94361877441406, 'rgb.min=', -225.77479553222656)
('rgb.max=', 135.978759765625, 'rgb.min=', -225.75318908691406)
('rgb.max=', 135.85134887695312, 'rgb.min=', -226.02345275878906)
('rgb.max=', 135.79850769042969, 'rgb.min=', -226.34234619140625)
('rgb.max=', 135.628662109375, 'rgb.min=', -226.07060241699219)
('rgb.max=', 135.96221923828125, 'rgb.min=', -225.77850341796875)
('rgb.max=', 135.78265380859375, 'rgb.min=', -225.87379455566406)
('rgb.max=', 136.06340026855469, 'rgb.min=', -225.87309265136719)
('rgb.max=', 136.04539489746094, 'rgb.min=', -226.11378479003906)
('rgb.max=', 136.28082275390625, 'rgb.min=', -226.04025268554688)
('rgb.max=', 135.79435729980469, 'rgb.min=', -225.93437194824219)
('rgb.max=', 135.83624267578125, 'rgb.min=', -225.98248291015625)
('rgb.max=', 135.8240966796875, 'rgb.min=', -225.8056640625)
('rgb.max=', 135.94635009765625, 'rgb.min=', -226.08016967773438)
('rgb.max=', 135.83074951171875, 'rgb.min=', -225.74237060546875)
('rgb.max=', 136.20217895507812, 'rgb.min=', -225.93302917480469)
('rgb.max=', 135.62701416015625, 'rgb.min=', -226.08126831054688)
('rgb.max=', 135.94401550292969, 'rgb.min=', -226.11509704589844)
('rgb.max=', 136.0853271484375, 'rgb.min=', -225.75059509277344)
('rgb.max=', 135.76667785644531, 'rgb.min=', -226.11541748046875)
('rgb.max=', 135.92477416992188, 'rgb.min=', -225.96377563476562)
('rgb.max=', 136.16444396972656, 'rgb.min=', -225.830322265625)
('rgb.max=', 136.03839111328125, 'rgb.min=', -225.82106018066406)
('rgb.max=', 135.69790649414062, 'rgb.min=', -226.13516235351562)
('rgb.max=', 135.8485107421875, 'rgb.min=', -226.23762512207031)
('rgb.max=', 135.99276733398438, 'rgb.min=', -225.86102294921875)
('rgb.max=', 135.7994384765625, 'rgb.min=', -226.06985473632812)
('rgb.max=', 136.00177001953125, 'rgb.min=', -225.90626525878906)
('rgb.max=', 135.85079956054688, 'rgb.min=', -225.8214111328125)
('rgb.max=', 136.12472534179688, 'rgb.min=', -225.89083862304688)
('rgb.max=', 135.72018432617188, 'rgb.min=', -226.08967590332031)
('rgb.max=', 136.16961669921875, 'rgb.min=', -225.95028686523438)
('rgb.max=', 135.93275451660156, 'rgb.min=', -226.10325622558594)
('rgb.max=', 136.19476318359375, 'rgb.min=', -225.82968139648438)
('rgb.max=', 135.86296081542969, 'rgb.min=', -225.84974670410156)
('rgb.max=', 136.12472534179688, 'rgb.min=', -226.02957153320312)
('rgb.max=', 136.12893676757812, 'rgb.min=', -226.074951171875)
('rgb.max=', 136.17770385742188, 'rgb.min=', -225.83161926269531)
('rgb.max=', 135.79930114746094, 'rgb.min=', -225.83065795898438)
('rgb.max=', 135.99624633789062, 'rgb.min=', -225.78012084960938)
('rgb.max=', 136.04843139648438, 'rgb.min=', -226.27873229980469)
('rgb.max=', 136.02284240722656, 'rgb.min=', -226.07427978515625)
('rgb.max=', 135.89010620117188, 'rgb.min=', -225.9815673828125)
('rgb.max=', 135.8333740234375, 'rgb.min=', -225.76815795898438)
('rgb.max=', 136.10362243652344, 'rgb.min=', -226.03877258300781)
('rgb.max=', 135.94320678710938, 'rgb.min=', -225.77198791503906)
('rgb.max=', 135.75822448730469, 'rgb.min=', -226.18312072753906)
('rgb.max=', 135.75637817382812, 'rgb.min=', -225.74891662597656)
('rgb.max=', 135.84355163574219, 'rgb.min=', -225.74575805664062)
('rgb.max=', 135.91748046875, 'rgb.min=', -226.05531311035156)
('rgb.max=', 135.89581298828125, 'rgb.min=', -225.94876098632812)
('rgb.max=', 135.77268981933594, 'rgb.min=', -225.94076538085938)
('rgb.max=', 136.228759765625, 'rgb.min=', -226.03955078125)
('rgb.max=', 136.0872802734375, 'rgb.min=', -225.76675415039062)
('rgb.max=', 136.01138305664062, 'rgb.min=', -226.14521789550781)
('rgb.max=', 135.62469482421875, 'rgb.min=', -225.87197875976562)
('rgb.max=', 136.20980834960938, 'rgb.min=', -226.07797241210938)
('rgb.max=', 136.095703125, 'rgb.min=', -225.99205017089844)
('rgb.max=', 135.81524658203125, 'rgb.min=', -226.02806091308594)
('rgb.max=', 136.11119079589844, 'rgb.min=', -225.98597717285156)
('rgb.max=', 136.05070495605469, 'rgb.min=', -225.98359680175781)
('rgb.max=', 135.9901123046875, 'rgb.min=', -226.020751953125)
('rgb.max=', 135.95404052734375, 'rgb.min=', -225.98757934570312)
('rgb.max=', 136.17576599121094, 'rgb.min=', -226.08531188964844)
('rgb.max=', 136.08349609375, 'rgb.min=', -226.13575744628906)
('rgb.max=', 135.78720092773438, 'rgb.min=', -226.05299377441406)
('rgb.max=', 135.73724365234375, 'rgb.min=', -225.98666381835938)
('rgb.max=', 135.75308227539062, 'rgb.min=', -225.76161193847656)
('rgb.max=', 135.8787841796875, 'rgb.min=', -226.18289184570312)
('rgb.max=', 136.04953002929688, 'rgb.min=', -226.01017761230469)
('rgb.max=', 135.95144653320312, 'rgb.min=', -225.93008422851562)
('rgb.max=', 136.1064453125, 'rgb.min=', -225.75088500976562)
('rgb.max=', 136.24844360351562, 'rgb.min=', -225.86309814453125)
('rgb.max=', 135.93539428710938, 'rgb.min=', -226.027099609375)
('rgb.max=', 135.84474182128906, 'rgb.min=', -226.00358581542969)
('rgb.max=', 135.88565063476562, 'rgb.min=', -225.94187927246094)
('rgb.max=', 136.20848083496094, 'rgb.min=', -225.5673828125)
('rgb.max=', 136.08912658691406, 'rgb.min=', -226.06434631347656)
('rgb.max=', 136.03129577636719, 'rgb.min=', -226.31103515625)
('rgb.max=', 135.54472351074219, 'rgb.min=', -225.82011413574219)
('rgb.max=', 135.93537902832031, 'rgb.min=', -225.68109130859375)
('rgb.max=', 135.89715576171875, 'rgb.min=', -226.06089782714844)
('rgb.max=', 135.78506469726562, 'rgb.min=', -226.15345764160156)
('rgb.max=', 136.17451477050781, 'rgb.min=', -225.67982482910156)
('rgb.max=', 135.5994873046875, 'rgb.min=', -225.80271911621094)
('rgb.max=', 136.10647583007812, 'rgb.min=', -226.2567138671875)
('rgb.max=', 135.85369873046875, 'rgb.min=', -226.14279174804688)
('rgb.max=', 136.02061462402344, 'rgb.min=', -225.79806518554688)
('rgb.max=', 135.89913940429688, 'rgb.min=', -226.06434631347656)
('rgb.max=', 136.04873657226562, 'rgb.min=', -225.94090270996094)
('rgb.max=', 135.86717224121094, 'rgb.min=', -226.23382568359375)
('rgb.max=', 136.05274963378906, 'rgb.min=', -225.92483520507812)
('rgb.max=', 136.06546020507812, 'rgb.min=', -226.01846313476562)
('rgb.max=', 135.89697265625, 'rgb.min=', -226.16981506347656)
('rgb.max=', 136.11654663085938, 'rgb.min=', -226.125)
('rgb.max=', 135.78865051269531, 'rgb.min=', -225.83076477050781)
('rgb.max=', 136.16255187988281, 'rgb.min=', -225.78565979003906)
('rgb.max=', 136.07736206054688, 'rgb.min=', -225.75595092773438)
('rgb.max=', 136.10012817382812, 'rgb.min=', -225.93817138671875)
('rgb.max=', 135.80308532714844, 'rgb.min=', -226.13980102539062)
('rgb.max=', 135.94085693359375, 'rgb.min=', -225.86721801757812)
('rgb.max=', 136.16178894042969, 'rgb.min=', -226.05204772949219)
('rgb.max=', 135.92787170410156, 'rgb.min=', -225.76036071777344)
('rgb.max=', 135.9501953125, 'rgb.min=', -225.8651123046875)
('rgb.max=', 136.12997436523438, 'rgb.min=', -225.78680419921875)
('rgb.max=', 135.86550903320312, 'rgb.min=', -225.98062133789062)
('rgb.max=', 135.95977783203125, 'rgb.min=', -226.10670471191406)
('rgb.max=', 135.682861328125, 'rgb.min=', -225.96923828125)
('rgb.max=', 135.87411499023438, 'rgb.min=', -225.94264221191406)
('rgb.max=', 135.79742431640625, 'rgb.min=', -225.89508056640625)
('rgb.max=', 136.04608154296875, 'rgb.min=', -226.23542785644531)
('rgb.max=', 136.00605773925781, 'rgb.min=', -225.87884521484375)
('rgb.max=', 135.83822631835938, 'rgb.min=', -226.05157470703125)
('rgb.max=', 136.13528442382812, 'rgb.min=', -225.72163391113281)
('rgb.max=', 135.90835571289062, 'rgb.min=', -226.13209533691406)
('rgb.max=', 135.94314575195312, 'rgb.min=', -225.80778503417969)
('rgb.max=', 135.71478271484375, 'rgb.min=', -225.9962158203125)
('rgb.max=', 135.67097473144531, 'rgb.min=', -225.78994750976562)
('rgb.max=', 135.85464477539062, 'rgb.min=', -226.09185791015625)
('rgb.max=', 135.89404296875, 'rgb.min=', -226.28294372558594)
('rgb.max=', 135.723876953125, 'rgb.min=', -225.94857788085938)
('rgb.max=', 135.81069946289062, 'rgb.min=', -225.99870300292969)
('rgb.max=', 135.94078063964844, 'rgb.min=', -226.13520812988281)
('rgb.max=', 136.18157958984375, 'rgb.min=', -226.158935546875)
('rgb.max=', 135.94140625, 'rgb.min=', -226.34652709960938)
('rgb.max=', 136.1566162109375, 'rgb.min=', -225.94851684570312)
('rgb.max=', 136.11109924316406, 'rgb.min=', -225.73948669433594)
('rgb.max=', 136.12045288085938, 'rgb.min=', -226.12495422363281)
('rgb.max=', 135.95909118652344, 'rgb.min=', -226.11634826660156)
('rgb.max=', 136.1309814453125, 'rgb.min=', -226.07827758789062)
('rgb.max=', 135.66049194335938, 'rgb.min=', -225.95822143554688)
('rgb.max=', 135.97976684570312, 'rgb.min=', -226.21598815917969)
('rgb.max=', 136.06893920898438, 'rgb.min=', -225.92665100097656)
('rgb.max=', 136.12921142578125, 'rgb.min=', -225.85092163085938)
('rgb.max=', 136.01789855957031, 'rgb.min=', -226.336669921875)
('rgb.max=', 135.7998046875, 'rgb.min=', -225.8385009765625)
('rgb.max=', 135.88969421386719, 'rgb.min=', -225.83186340332031)
('rgb.max=', 135.63037109375, 'rgb.min=', -226.29655456542969)
('rgb.max=', 135.72349548339844, 'rgb.min=', -225.97767639160156)
('rgb.max=', 135.83966064453125, 'rgb.min=', -226.18464660644531)
('rgb.max=', 135.91259765625, 'rgb.min=', -225.91661071777344)
('rgb.max=', 135.91569519042969, 'rgb.min=', -226.00938415527344)
('rgb.max=', 135.97161865234375, 'rgb.min=', -226.13642883300781)
('rgb.max=', 135.96421813964844, 'rgb.min=', -225.95390319824219)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.257367')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6971 ', 'GAN acc 0.4922', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4766', 'Total loss: 1.3932', 'for batch', 0)
('GAN loss 0.7017 ', 'GAN acc 0.4609', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5117', 'Total loss: 1.3954', 'for batch', 1)
('GAN loss 0.6937 ', 'GAN acc 0.4805', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5254', 'Total loss: 1.3869', 'for batch', 2)
('GAN loss 0.6963 ', 'GAN acc 0.4531', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5312', 'Total loss: 1.3890', 'for batch', 3)
('GAN loss 0.6910 ', 'GAN acc 0.5273', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4805', 'Total loss: 1.3864', 'for batch', 4)
('GAN loss 0.6956 ', 'GAN acc 0.5156', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4922', 'Total loss: 1.3885', 'for batch', 5)
('GAN loss 0.6900 ', 'GAN acc 0.5469', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4922', 'Total loss: 1.3830', 'for batch', 6)
('GAN loss 0.6858 ', 'GAN acc 0.5859', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5430', 'Total loss: 1.3778', 'for batch', 7)
('GAN loss 0.6894 ', 'GAN acc 0.5586', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5137', 'Total loss: 1.3835', 'for batch', 8)
('GAN loss 0.6933 ', 'GAN acc 0.4883', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5254', 'Total loss: 1.3862', 'for batch', 9)
('GAN loss 0.6876 ', 'GAN acc 0.5742', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5020', 'Total loss: 1.3816', 'for batch', 10)
('GAN loss 0.6855 ', 'GAN acc 0.5742', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5039', 'Total loss: 1.3784', 'for batch', 11)
('GAN loss 0.6901 ', 'GAN acc 0.5547', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4980', 'Total loss: 1.3847', 'for batch', 12)
('GAN loss 0.6894 ', 'GAN acc 0.5469', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4863', 'Total loss: 1.3833', 'for batch', 13)
('GAN loss 0.6934 ', 'GAN acc 0.4883', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5039', 'Total loss: 1.3882', 'for batch', 14)
('GAN loss 0.6927 ', 'GAN acc 0.5508', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5059', 'Total loss: 1.3861', 'for batch', 15)
('GAN loss 0.6995 ', 'GAN acc 0.4766', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4902', 'Total loss: 1.3931', 'for batch', 16)
('GAN loss 0.7022 ', 'GAN acc 0.4492', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4863', 'Total loss: 1.3969', 'for batch', 17)
('GAN loss 0.6990 ', 'GAN acc 0.4570', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4688', 'Total loss: 1.3934', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51213104)
('DISCRIMINATOR_Imagem FAKE=', 0.51212174)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.08378601074219, 'rgb.min=', -225.82876586914062)
('rgb.max=', 135.90457153320312, 'rgb.min=', -226.07206726074219)
('rgb.max=', 136.1351318359375, 'rgb.min=', -225.91929626464844)
('rgb.max=', 135.9935302734375, 'rgb.min=', -226.07649230957031)
('rgb.max=', 136.11782836914062, 'rgb.min=', -225.89030456542969)
('rgb.max=', 136.25570678710938, 'rgb.min=', -226.42903137207031)
('rgb.max=', 135.838623046875, 'rgb.min=', -226.16377258300781)
('rgb.max=', 135.94386291503906, 'rgb.min=', -225.94096374511719)
('rgb.max=', 135.8577880859375, 'rgb.min=', -226.08305358886719)
('rgb.max=', 135.80111694335938, 'rgb.min=', -226.052490234375)
('rgb.max=', 135.74996948242188, 'rgb.min=', -226.17092895507812)
('rgb.max=', 135.84156799316406, 'rgb.min=', -225.96855163574219)
('rgb.max=', 135.8037109375, 'rgb.min=', -226.09365844726562)
('rgb.max=', 135.91752624511719, 'rgb.min=', -226.01734924316406)
('rgb.max=', 135.80000305175781, 'rgb.min=', -226.00013732910156)
('rgb.max=', 135.77487182617188, 'rgb.min=', -225.9837646484375)
('rgb.max=', 135.8216552734375, 'rgb.min=', -225.916259765625)
('rgb.max=', 135.90042114257812, 'rgb.min=', -225.75692749023438)
('rgb.max=', 135.91726684570312, 'rgb.min=', -226.11351013183594)
('rgb.max=', 135.96809387207031, 'rgb.min=', -226.33634948730469)
('rgb.max=', 136.12362670898438, 'rgb.min=', -225.90069580078125)
('rgb.max=', 136.13015747070312, 'rgb.min=', -225.85133361816406)
('rgb.max=', 136.16766357421875, 'rgb.min=', -225.79705810546875)
('rgb.max=', 135.93980407714844, 'rgb.min=', -225.75239562988281)
('rgb.max=', 135.775146484375, 'rgb.min=', -225.92582702636719)
('rgb.max=', 136.12628173828125, 'rgb.min=', -225.98789978027344)
('rgb.max=', 136.16018676757812, 'rgb.min=', -225.98371887207031)
('rgb.max=', 135.92086791992188, 'rgb.min=', -225.86067199707031)
('rgb.max=', 135.90304565429688, 'rgb.min=', -225.81558227539062)
('rgb.max=', 135.86613464355469, 'rgb.min=', -225.99397277832031)
('rgb.max=', 135.93624877929688, 'rgb.min=', -225.93797302246094)
('rgb.max=', 135.8314208984375, 'rgb.min=', -225.90048217773438)
('rgb.max=', 135.99723815917969, 'rgb.min=', -226.03575134277344)
('rgb.max=', 135.87117004394531, 'rgb.min=', -225.95443725585938)
('rgb.max=', 135.88995361328125, 'rgb.min=', -225.94725036621094)
('rgb.max=', 136.08694458007812, 'rgb.min=', -225.92129516601562)
('rgb.max=', 136.1939697265625, 'rgb.min=', -225.88670349121094)
('rgb.max=', 136.10311889648438, 'rgb.min=', -226.01298522949219)
('rgb.max=', 135.95320129394531, 'rgb.min=', -225.87913513183594)
('rgb.max=', 135.94503784179688, 'rgb.min=', -225.97364807128906)
('rgb.max=', 135.71913146972656, 'rgb.min=', -225.83255004882812)
('rgb.max=', 135.96833801269531, 'rgb.min=', -226.09147644042969)
('rgb.max=', 135.89691162109375, 'rgb.min=', -225.94775390625)
('rgb.max=', 135.87765502929688, 'rgb.min=', -225.93231201171875)
('rgb.max=', 135.95945739746094, 'rgb.min=', -226.37403869628906)
('rgb.max=', 135.5714111328125, 'rgb.min=', -225.85893249511719)
('rgb.max=', 135.93998718261719, 'rgb.min=', -225.87284851074219)
('rgb.max=', 135.7591552734375, 'rgb.min=', -225.74267578125)
('rgb.max=', 135.91300964355469, 'rgb.min=', -225.94595336914062)
('rgb.max=', 136.26467895507812, 'rgb.min=', -226.00047302246094)
('rgb.max=', 135.95066833496094, 'rgb.min=', -225.96762084960938)
('rgb.max=', 136.23831176757812, 'rgb.min=', -225.95350646972656)
('rgb.max=', 135.71087646484375, 'rgb.min=', -226.01811218261719)
('rgb.max=', 135.80630493164062, 'rgb.min=', -226.02291870117188)
('rgb.max=', 136.05886840820312, 'rgb.min=', -225.97811889648438)
('rgb.max=', 136.11231994628906, 'rgb.min=', -226.01834106445312)
('rgb.max=', 135.9005126953125, 'rgb.min=', -225.99728393554688)
('rgb.max=', 135.81135559082031, 'rgb.min=', -225.92549133300781)
('rgb.max=', 135.8582763671875, 'rgb.min=', -225.92021179199219)
('rgb.max=', 135.58224487304688, 'rgb.min=', -226.1317138671875)
('rgb.max=', 135.93365478515625, 'rgb.min=', -225.97218322753906)
('rgb.max=', 135.75210571289062, 'rgb.min=', -225.77189636230469)
('rgb.max=', 135.6888427734375, 'rgb.min=', -225.93333435058594)
('rgb.max=', 135.74624633789062, 'rgb.min=', -226.29240417480469)
('rgb.max=', 136.32606506347656, 'rgb.min=', -225.81991577148438)
('rgb.max=', 135.91281127929688, 'rgb.min=', -226.13461303710938)
('rgb.max=', 135.6673583984375, 'rgb.min=', -225.81838989257812)
('rgb.max=', 135.71794128417969, 'rgb.min=', -225.96197509765625)
('rgb.max=', 136.02003479003906, 'rgb.min=', -226.028076171875)
('rgb.max=', 136.10282897949219, 'rgb.min=', -226.03518676757812)
('rgb.max=', 136.05235290527344, 'rgb.min=', -225.96379089355469)
('rgb.max=', 135.77423095703125, 'rgb.min=', -225.96002197265625)
('rgb.max=', 135.89967346191406, 'rgb.min=', -226.238525390625)
('rgb.max=', 135.97650146484375, 'rgb.min=', -226.11007690429688)
('rgb.max=', 135.88345336914062, 'rgb.min=', -225.72528076171875)
('rgb.max=', 136.02688598632812, 'rgb.min=', -225.95240783691406)
('rgb.max=', 136.21430969238281, 'rgb.min=', -226.00270080566406)
('rgb.max=', 136.04580688476562, 'rgb.min=', -225.83224487304688)
('rgb.max=', 135.74092102050781, 'rgb.min=', -225.93095397949219)
('rgb.max=', 135.90859985351562, 'rgb.min=', -225.91989135742188)
('rgb.max=', 136.07199096679688, 'rgb.min=', -225.71394348144531)
('rgb.max=', 135.81488037109375, 'rgb.min=', -225.82344055175781)
('rgb.max=', 135.79833984375, 'rgb.min=', -226.01007080078125)
('rgb.max=', 135.97831726074219, 'rgb.min=', -225.8963623046875)
('rgb.max=', 135.97854614257812, 'rgb.min=', -226.12367248535156)
('rgb.max=', 135.85111999511719, 'rgb.min=', -226.06552124023438)
('rgb.max=', 136.00546264648438, 'rgb.min=', -225.7725830078125)
('rgb.max=', 135.77336120605469, 'rgb.min=', -225.97319030761719)
('rgb.max=', 135.95834350585938, 'rgb.min=', -226.22254943847656)
('rgb.max=', 135.60702514648438, 'rgb.min=', -225.77728271484375)
('rgb.max=', 135.84368896484375, 'rgb.min=', -225.86720275878906)
('rgb.max=', 135.77166748046875, 'rgb.min=', -226.19947814941406)
('rgb.max=', 135.82379150390625, 'rgb.min=', -226.32298278808594)
('rgb.max=', 135.78114318847656, 'rgb.min=', -225.86882019042969)
('rgb.max=', 135.80108642578125, 'rgb.min=', -225.77262878417969)
('rgb.max=', 136.08006286621094, 'rgb.min=', -225.895751953125)
('rgb.max=', 135.86880493164062, 'rgb.min=', -225.87982177734375)
('rgb.max=', 135.95710754394531, 'rgb.min=', -226.34010314941406)
('rgb.max=', 135.77439880371094, 'rgb.min=', -226.18696594238281)
('rgb.max=', 135.9256591796875, 'rgb.min=', -226.0311279296875)
('rgb.max=', 135.87451171875, 'rgb.min=', -226.11114501953125)
('rgb.max=', 135.72090148925781, 'rgb.min=', -225.90602111816406)
('rgb.max=', 135.94049072265625, 'rgb.min=', -225.8062744140625)
('rgb.max=', 135.905517578125, 'rgb.min=', -225.92155456542969)
('rgb.max=', 135.89376831054688, 'rgb.min=', -225.78326416015625)
('rgb.max=', 136.15132141113281, 'rgb.min=', -225.90882873535156)
('rgb.max=', 135.94706726074219, 'rgb.min=', -226.04669189453125)
('rgb.max=', 135.95634460449219, 'rgb.min=', -226.05125427246094)
('rgb.max=', 136.12826538085938, 'rgb.min=', -225.91145324707031)
('rgb.max=', 135.93505859375, 'rgb.min=', -225.84407043457031)
('rgb.max=', 135.9970703125, 'rgb.min=', -225.94535827636719)
('rgb.max=', 136.13261413574219, 'rgb.min=', -225.87249755859375)
('rgb.max=', 135.92820739746094, 'rgb.min=', -225.76373291015625)
('rgb.max=', 135.9974365234375, 'rgb.min=', -225.72344970703125)
('rgb.max=', 135.85604858398438, 'rgb.min=', -225.97244262695312)
('rgb.max=', 135.82533264160156, 'rgb.min=', -226.33805847167969)
('rgb.max=', 135.63777160644531, 'rgb.min=', -225.97265625)
('rgb.max=', 135.91606140136719, 'rgb.min=', -225.76385498046875)
('rgb.max=', 135.78271484375, 'rgb.min=', -225.84754943847656)
('rgb.max=', 136.100341796875, 'rgb.min=', -225.86784362792969)
('rgb.max=', 136.05133056640625, 'rgb.min=', -225.9931640625)
('rgb.max=', 136.23417663574219, 'rgb.min=', -226.10133361816406)
('rgb.max=', 135.79904174804688, 'rgb.min=', -225.90750122070312)
('rgb.max=', 135.84751892089844, 'rgb.min=', -225.89210510253906)
('rgb.max=', 135.77870178222656, 'rgb.min=', -225.79957580566406)
('rgb.max=', 136.00596618652344, 'rgb.min=', -226.090087890625)
('rgb.max=', 135.82429504394531, 'rgb.min=', -225.74151611328125)
('rgb.max=', 136.15182495117188, 'rgb.min=', -225.86341857910156)
('rgb.max=', 135.63352966308594, 'rgb.min=', -226.08070373535156)
('rgb.max=', 135.97579956054688, 'rgb.min=', -226.11079406738281)
('rgb.max=', 136.12554931640625, 'rgb.min=', -225.76687622070312)
('rgb.max=', 135.72819519042969, 'rgb.min=', -226.09980773925781)
('rgb.max=', 135.96800231933594, 'rgb.min=', -225.91584777832031)
('rgb.max=', 136.16644287109375, 'rgb.min=', -225.80416870117188)
('rgb.max=', 136.04298400878906, 'rgb.min=', -225.80072021484375)
('rgb.max=', 135.69851684570312, 'rgb.min=', -226.06184387207031)
('rgb.max=', 135.85223388671875, 'rgb.min=', -226.10234069824219)
('rgb.max=', 135.94569396972656, 'rgb.min=', -225.81375122070312)
('rgb.max=', 135.81256103515625, 'rgb.min=', -226.06695556640625)
('rgb.max=', 135.963134765625, 'rgb.min=', -225.89143371582031)
('rgb.max=', 135.85400390625, 'rgb.min=', -225.79391479492188)
('rgb.max=', 136.10133361816406, 'rgb.min=', -225.96031188964844)
('rgb.max=', 135.72848510742188, 'rgb.min=', -226.11512756347656)
('rgb.max=', 136.17221069335938, 'rgb.min=', -225.87692260742188)
('rgb.max=', 135.90061950683594, 'rgb.min=', -226.09416198730469)
('rgb.max=', 136.182861328125, 'rgb.min=', -225.798095703125)
('rgb.max=', 135.8834228515625, 'rgb.min=', -225.82502746582031)
('rgb.max=', 136.1693115234375, 'rgb.min=', -225.97645568847656)
('rgb.max=', 136.11831665039062, 'rgb.min=', -226.081787109375)
('rgb.max=', 136.12919616699219, 'rgb.min=', -225.81770324707031)
('rgb.max=', 135.80596923828125, 'rgb.min=', -225.81666564941406)
('rgb.max=', 135.95468139648438, 'rgb.min=', -225.7750244140625)
('rgb.max=', 135.99699401855469, 'rgb.min=', -226.1488037109375)
('rgb.max=', 136.05911254882812, 'rgb.min=', -225.9749755859375)
('rgb.max=', 135.90304565429688, 'rgb.min=', -225.97846984863281)
('rgb.max=', 135.84849548339844, 'rgb.min=', -225.68821716308594)
('rgb.max=', 136.10316467285156, 'rgb.min=', -226.0218505859375)
('rgb.max=', 135.92947387695312, 'rgb.min=', -225.73077392578125)
('rgb.max=', 135.76695251464844, 'rgb.min=', -226.19682312011719)
('rgb.max=', 135.71827697753906, 'rgb.min=', -225.72381591796875)
('rgb.max=', 135.84910583496094, 'rgb.min=', -225.7255859375)
('rgb.max=', 135.93701171875, 'rgb.min=', -226.06944274902344)
('rgb.max=', 135.89666748046875, 'rgb.min=', -225.92897033691406)
('rgb.max=', 135.782958984375, 'rgb.min=', -225.86177062988281)
('rgb.max=', 136.18067932128906, 'rgb.min=', -225.99806213378906)
('rgb.max=', 136.04457092285156, 'rgb.min=', -225.77903747558594)
('rgb.max=', 136.02046203613281, 'rgb.min=', -226.02316284179688)
('rgb.max=', 135.63253784179688, 'rgb.min=', -225.85514831542969)
('rgb.max=', 136.14852905273438, 'rgb.min=', -225.98443603515625)
('rgb.max=', 136.102294921875, 'rgb.min=', -225.93563842773438)
('rgb.max=', 135.77790832519531, 'rgb.min=', -225.9053955078125)
('rgb.max=', 136.12109375, 'rgb.min=', -225.91642761230469)
('rgb.max=', 136.00714111328125, 'rgb.min=', -225.95405578613281)
('rgb.max=', 136.02601623535156, 'rgb.min=', -225.92640686035156)
('rgb.max=', 135.90673828125, 'rgb.min=', -225.96090698242188)
('rgb.max=', 136.15103149414062, 'rgb.min=', -226.01618957519531)
('rgb.max=', 136.10946655273438, 'rgb.min=', -226.00471496582031)
('rgb.max=', 135.8094482421875, 'rgb.min=', -225.94993591308594)
('rgb.max=', 135.74224853515625, 'rgb.min=', -225.93356323242188)
('rgb.max=', 135.76922607421875, 'rgb.min=', -225.75312805175781)
('rgb.max=', 135.95518493652344, 'rgb.min=', -226.19773864746094)
('rgb.max=', 136.00910949707031, 'rgb.min=', -226.02145385742188)
('rgb.max=', 135.95445251464844, 'rgb.min=', -225.90505981445312)
('rgb.max=', 136.08560180664062, 'rgb.min=', -225.74620056152344)
('rgb.max=', 136.21949768066406, 'rgb.min=', -225.84854125976562)
('rgb.max=', 135.9334716796875, 'rgb.min=', -225.94784545898438)
('rgb.max=', 135.84793090820312, 'rgb.min=', -225.98793029785156)
('rgb.max=', 135.88824462890625, 'rgb.min=', -225.93864440917969)
('rgb.max=', 136.22142028808594, 'rgb.min=', -225.5606689453125)
('rgb.max=', 136.09320068359375, 'rgb.min=', -225.91276550292969)
('rgb.max=', 136.02607727050781, 'rgb.min=', -226.30218505859375)
('rgb.max=', 135.57325744628906, 'rgb.min=', -225.83113098144531)
('rgb.max=', 135.91677856445312, 'rgb.min=', -225.65773010253906)
('rgb.max=', 135.9176025390625, 'rgb.min=', -226.05946350097656)
('rgb.max=', 135.78509521484375, 'rgb.min=', -226.15147399902344)
('rgb.max=', 136.16436767578125, 'rgb.min=', -225.62821960449219)
('rgb.max=', 135.59007263183594, 'rgb.min=', -225.79182434082031)
('rgb.max=', 136.13887023925781, 'rgb.min=', -226.25436401367188)
('rgb.max=', 135.86508178710938, 'rgb.min=', -225.98524475097656)
('rgb.max=', 136.01902770996094, 'rgb.min=', -225.754150390625)
('rgb.max=', 135.89263916015625, 'rgb.min=', -225.99128723144531)
('rgb.max=', 136.09063720703125, 'rgb.min=', -225.898193359375)
('rgb.max=', 135.87548828125, 'rgb.min=', -226.229736328125)
('rgb.max=', 135.96621704101562, 'rgb.min=', -225.92021179199219)
('rgb.max=', 136.01557922363281, 'rgb.min=', -225.93254089355469)
('rgb.max=', 135.89895629882812, 'rgb.min=', -226.17434692382812)
('rgb.max=', 136.12245178222656, 'rgb.min=', -226.10345458984375)
('rgb.max=', 135.80537414550781, 'rgb.min=', -225.80641174316406)
('rgb.max=', 136.16769409179688, 'rgb.min=', -225.76544189453125)
('rgb.max=', 136.03799438476562, 'rgb.min=', -225.73680114746094)
('rgb.max=', 136.07435607910156, 'rgb.min=', -225.93809509277344)
('rgb.max=', 135.81599426269531, 'rgb.min=', -226.1400146484375)
('rgb.max=', 135.9012451171875, 'rgb.min=', -225.86737060546875)
('rgb.max=', 136.10748291015625, 'rgb.min=', -226.05952453613281)
('rgb.max=', 135.91981506347656, 'rgb.min=', -225.764892578125)
('rgb.max=', 135.96076965332031, 'rgb.min=', -225.85235595703125)
('rgb.max=', 136.09274291992188, 'rgb.min=', -225.78884887695312)
('rgb.max=', 135.870361328125, 'rgb.min=', -225.97862243652344)
('rgb.max=', 135.91328430175781, 'rgb.min=', -226.11598205566406)
('rgb.max=', 135.6904296875, 'rgb.min=', -225.91688537597656)
('rgb.max=', 135.8671875, 'rgb.min=', -225.93788146972656)
('rgb.max=', 135.80406188964844, 'rgb.min=', -225.87960815429688)
('rgb.max=', 136.04566955566406, 'rgb.min=', -226.05731201171875)
('rgb.max=', 136.0020751953125, 'rgb.min=', -225.76936340332031)
('rgb.max=', 135.8350830078125, 'rgb.min=', -226.04512023925781)
('rgb.max=', 136.1009521484375, 'rgb.min=', -225.68109130859375)
('rgb.max=', 135.91581726074219, 'rgb.min=', -226.13200378417969)
('rgb.max=', 135.96693420410156, 'rgb.min=', -225.80410766601562)
('rgb.max=', 135.74336242675781, 'rgb.min=', -225.89433288574219)
('rgb.max=', 135.64262390136719, 'rgb.min=', -225.76998901367188)
('rgb.max=', 135.86222839355469, 'rgb.min=', -226.09370422363281)
('rgb.max=', 135.90170288085938, 'rgb.min=', -226.28225708007812)
('rgb.max=', 135.69607543945312, 'rgb.min=', -225.86015319824219)
('rgb.max=', 135.75277709960938, 'rgb.min=', -225.929443359375)
('rgb.max=', 135.93968200683594, 'rgb.min=', -226.11692810058594)
('rgb.max=', 136.13963317871094, 'rgb.min=', -226.15469360351562)
('rgb.max=', 135.96348571777344, 'rgb.min=', -226.3453369140625)
('rgb.max=', 136.12559509277344, 'rgb.min=', -225.95011901855469)
('rgb.max=', 136.05227661132812, 'rgb.min=', -225.72465515136719)
('rgb.max=', 136.06980895996094, 'rgb.min=', -226.12960815429688)
('rgb.max=', 135.93162536621094, 'rgb.min=', -226.11166381835938)
('rgb.max=', 136.0606689453125, 'rgb.min=', -225.99937438964844)
('rgb.max=', 135.66937255859375, 'rgb.min=', -225.94844055175781)
('rgb.max=', 135.97561645507812, 'rgb.min=', -226.04219055175781)
('rgb.max=', 136.02813720703125, 'rgb.min=', -225.91021728515625)
('rgb.max=', 136.13861083984375, 'rgb.min=', -225.82196044921875)
('rgb.max=', 136.00393676757812, 'rgb.min=', -226.21577453613281)
('rgb.max=', 135.79678344726562, 'rgb.min=', -225.81216430664062)
('rgb.max=', 135.90786743164062, 'rgb.min=', -225.80035400390625)
('rgb.max=', 135.63531494140625, 'rgb.min=', -226.30067443847656)
('rgb.max=', 135.74588012695312, 'rgb.min=', -225.9656982421875)
('rgb.max=', 135.85102844238281, 'rgb.min=', -226.06216430664062)
('rgb.max=', 135.89755249023438, 'rgb.min=', -225.91169738769531)
('rgb.max=', 135.89984130859375, 'rgb.min=', -226.00843811035156)
('rgb.max=', 135.99046325683594, 'rgb.min=', -226.13545227050781)
('rgb.max=', 135.93330383300781, 'rgb.min=', -225.901611328125)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:27.802868')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6986 ', 'GAN acc 0.4180', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5371', 'Total loss: 1.3895', 'for batch', 0)
('GAN loss 0.6966 ', 'GAN acc 0.4844', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4961', 'Total loss: 1.3923', 'for batch', 1)
('GAN loss 0.6910 ', 'GAN acc 0.5234', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5195', 'Total loss: 1.3833', 'for batch', 2)
('GAN loss 0.6901 ', 'GAN acc 0.5078', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5059', 'Total loss: 1.3834', 'for batch', 3)
('GAN loss 0.6915 ', 'GAN acc 0.5195', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4629', 'Total loss: 1.3889', 'for batch', 4)
('GAN loss 0.6883 ', 'GAN acc 0.5625', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4785', 'Total loss: 1.3838', 'for batch', 5)
('GAN loss 0.6846 ', 'GAN acc 0.6211', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5176', 'Total loss: 1.3778', 'for batch', 6)
('GAN loss 0.6879 ', 'GAN acc 0.5820', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5039', 'Total loss: 1.3820', 'for batch', 7)
('GAN loss 0.6868 ', 'GAN acc 0.5820', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5098', 'Total loss: 1.3791', 'for batch', 8)
('GAN loss 0.6891 ', 'GAN acc 0.5664', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4707', 'Total loss: 1.3841', 'for batch', 9)
('GAN loss 0.6922 ', 'GAN acc 0.5195', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5000', 'Total loss: 1.3834', 'for batch', 10)
('GAN loss 0.6872 ', 'GAN acc 0.5430', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4590', 'Total loss: 1.3819', 'for batch', 11)
('GAN loss 0.6913 ', 'GAN acc 0.5391', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5000', 'Total loss: 1.3858', 'for batch', 12)
('GAN loss 0.6912 ', 'GAN acc 0.5078', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5176', 'Total loss: 1.3846', 'for batch', 13)
('GAN loss 0.6965 ', 'GAN acc 0.4688', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5020', 'Total loss: 1.3900', 'for batch', 14)
('GAN loss 0.7011 ', 'GAN acc 0.4336', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5195', 'Total loss: 1.3929', 'for batch', 15)
('GAN loss 0.7006 ', 'GAN acc 0.3984', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4902', 'Total loss: 1.3950', 'for batch', 16)
('GAN loss 0.7015 ', 'GAN acc 0.4062', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4727', 'Total loss: 1.3951', 'for batch', 17)
('GAN loss 0.7058 ', 'GAN acc 0.3633', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5098', 'Total loss: 1.3999', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51211864)
('DISCRIMINATOR_Imagem FAKE=', 0.51201224)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.03669738769531, 'rgb.min=', -225.81437683105469)
('rgb.max=', 135.89485168457031, 'rgb.min=', -225.95979309082031)
('rgb.max=', 136.11822509765625, 'rgb.min=', -225.89302062988281)
('rgb.max=', 136.03378295898438, 'rgb.min=', -226.05975341796875)
('rgb.max=', 136.17457580566406, 'rgb.min=', -225.89630126953125)
('rgb.max=', 136.23643493652344, 'rgb.min=', -226.29078674316406)
('rgb.max=', 135.8233642578125, 'rgb.min=', -226.04933166503906)
('rgb.max=', 135.9627685546875, 'rgb.min=', -225.92802429199219)
('rgb.max=', 135.91145324707031, 'rgb.min=', -226.07052612304688)
('rgb.max=', 135.79716491699219, 'rgb.min=', -226.02581787109375)
('rgb.max=', 135.74310302734375, 'rgb.min=', -226.07479858398438)
('rgb.max=', 135.82408142089844, 'rgb.min=', -225.97911071777344)
('rgb.max=', 135.83383178710938, 'rgb.min=', -226.06132507324219)
('rgb.max=', 135.9376220703125, 'rgb.min=', -225.99542236328125)
('rgb.max=', 135.79048156738281, 'rgb.min=', -225.97268676757812)
('rgb.max=', 135.77999877929688, 'rgb.min=', -225.95326232910156)
('rgb.max=', 135.83767700195312, 'rgb.min=', -225.91288757324219)
('rgb.max=', 135.8944091796875, 'rgb.min=', -225.81434631347656)
('rgb.max=', 135.91844177246094, 'rgb.min=', -225.99517822265625)
('rgb.max=', 135.955322265625, 'rgb.min=', -226.20199584960938)
('rgb.max=', 136.11386108398438, 'rgb.min=', -225.92164611816406)
('rgb.max=', 136.13850402832031, 'rgb.min=', -225.8707275390625)
('rgb.max=', 136.11598205566406, 'rgb.min=', -225.77267456054688)
('rgb.max=', 136.01332092285156, 'rgb.min=', -225.78157043457031)
('rgb.max=', 135.76419067382812, 'rgb.min=', -225.93717956542969)
('rgb.max=', 136.07247924804688, 'rgb.min=', -225.96090698242188)
('rgb.max=', 136.16107177734375, 'rgb.min=', -226.03515625)
('rgb.max=', 135.90927124023438, 'rgb.min=', -225.82952880859375)
('rgb.max=', 135.87162780761719, 'rgb.min=', -225.78703308105469)
('rgb.max=', 135.90225219726562, 'rgb.min=', -225.99099731445312)
('rgb.max=', 135.91995239257812, 'rgb.min=', -225.9512939453125)
('rgb.max=', 135.88217163085938, 'rgb.min=', -225.89625549316406)
('rgb.max=', 136.07888793945312, 'rgb.min=', -226.05705261230469)
('rgb.max=', 135.8746337890625, 'rgb.min=', -225.97724914550781)
('rgb.max=', 135.92184448242188, 'rgb.min=', -225.95216369628906)
('rgb.max=', 136.044921875, 'rgb.min=', -225.92694091796875)
('rgb.max=', 136.19181823730469, 'rgb.min=', -225.97950744628906)
('rgb.max=', 136.03045654296875, 'rgb.min=', -226.03573608398438)
('rgb.max=', 136.02000427246094, 'rgb.min=', -225.91004943847656)
('rgb.max=', 136.01181030273438, 'rgb.min=', -225.99343872070312)
('rgb.max=', 135.70901489257812, 'rgb.min=', -225.83920288085938)
('rgb.max=', 135.93936157226562, 'rgb.min=', -226.0357666015625)
('rgb.max=', 135.89018249511719, 'rgb.min=', -225.99366760253906)
('rgb.max=', 135.939208984375, 'rgb.min=', -225.96278381347656)
('rgb.max=', 135.97505187988281, 'rgb.min=', -226.26899719238281)
('rgb.max=', 135.61180114746094, 'rgb.min=', -225.86280822753906)
('rgb.max=', 135.98539733886719, 'rgb.min=', -225.87852478027344)
('rgb.max=', 135.78910827636719, 'rgb.min=', -225.73310852050781)
('rgb.max=', 135.90042114257812, 'rgb.min=', -225.93907165527344)
('rgb.max=', 136.25482177734375, 'rgb.min=', -225.97238159179688)
('rgb.max=', 135.97364807128906, 'rgb.min=', -226.01997375488281)
('rgb.max=', 136.28436279296875, 'rgb.min=', -225.95121765136719)
('rgb.max=', 135.69631958007812, 'rgb.min=', -225.95854187011719)
('rgb.max=', 135.87393188476562, 'rgb.min=', -225.99806213378906)
('rgb.max=', 136.06437683105469, 'rgb.min=', -225.97705078125)
('rgb.max=', 136.10197448730469, 'rgb.min=', -226.03543090820312)
('rgb.max=', 135.90139770507812, 'rgb.min=', -225.99568176269531)
('rgb.max=', 135.80618286132812, 'rgb.min=', -225.89794921875)
('rgb.max=', 135.84175109863281, 'rgb.min=', -225.93153381347656)
('rgb.max=', 135.5682373046875, 'rgb.min=', -226.11627197265625)
('rgb.max=', 135.9256591796875, 'rgb.min=', -225.95492553710938)
('rgb.max=', 135.77830505371094, 'rgb.min=', -225.79953002929688)
('rgb.max=', 135.695068359375, 'rgb.min=', -225.89820861816406)
('rgb.max=', 135.73072814941406, 'rgb.min=', -226.17039489746094)
('rgb.max=', 136.37307739257812, 'rgb.min=', -225.81991577148438)
('rgb.max=', 135.88751220703125, 'rgb.min=', -226.13053894042969)
('rgb.max=', 135.68891906738281, 'rgb.min=', -225.85511779785156)
('rgb.max=', 135.70549011230469, 'rgb.min=', -226.00262451171875)
('rgb.max=', 136.10580444335938, 'rgb.min=', -226.09480285644531)
('rgb.max=', 136.12165832519531, 'rgb.min=', -225.97276306152344)
('rgb.max=', 135.99966430664062, 'rgb.min=', -225.97689819335938)
('rgb.max=', 135.80644226074219, 'rgb.min=', -225.95353698730469)
('rgb.max=', 135.88168334960938, 'rgb.min=', -226.11483764648438)
('rgb.max=', 135.964599609375, 'rgb.min=', -226.07968139648438)
('rgb.max=', 135.93222045898438, 'rgb.min=', -225.73567199707031)
('rgb.max=', 136.1148681640625, 'rgb.min=', -225.968505859375)
('rgb.max=', 136.33306884765625, 'rgb.min=', -225.97189331054688)
('rgb.max=', 136.08845520019531, 'rgb.min=', -225.87646484375)
('rgb.max=', 135.810791015625, 'rgb.min=', -225.92878723144531)
('rgb.max=', 135.90425109863281, 'rgb.min=', -225.83857727050781)
('rgb.max=', 136.07443237304688, 'rgb.min=', -225.66816711425781)
('rgb.max=', 135.83685302734375, 'rgb.min=', -225.88795471191406)
('rgb.max=', 135.84304809570312, 'rgb.min=', -225.98841857910156)
('rgb.max=', 136.02093505859375, 'rgb.min=', -225.90724182128906)
('rgb.max=', 136.01968383789062, 'rgb.min=', -226.19564819335938)
('rgb.max=', 135.846923828125, 'rgb.min=', -225.98515319824219)
('rgb.max=', 136.09632873535156, 'rgb.min=', -225.78369140625)
('rgb.max=', 135.78497314453125, 'rgb.min=', -225.88674926757812)
('rgb.max=', 135.94952392578125, 'rgb.min=', -226.11041259765625)
('rgb.max=', 135.64102172851562, 'rgb.min=', -225.75698852539062)
('rgb.max=', 135.91471862792969, 'rgb.min=', -225.87643432617188)
('rgb.max=', 135.7603759765625, 'rgb.min=', -226.10643005371094)
('rgb.max=', 135.81062316894531, 'rgb.min=', -226.23626708984375)
('rgb.max=', 135.77426147460938, 'rgb.min=', -225.86627197265625)
('rgb.max=', 135.780029296875, 'rgb.min=', -225.72792053222656)
('rgb.max=', 136.12992858886719, 'rgb.min=', -225.93121337890625)
('rgb.max=', 135.94648742675781, 'rgb.min=', -225.90144348144531)
('rgb.max=', 135.97314453125, 'rgb.min=', -226.26750183105469)
('rgb.max=', 135.76213073730469, 'rgb.min=', -226.16712951660156)
('rgb.max=', 135.91291809082031, 'rgb.min=', -226.0042724609375)
('rgb.max=', 135.88107299804688, 'rgb.min=', -226.12149047851562)
('rgb.max=', 135.71281433105469, 'rgb.min=', -225.91508483886719)
('rgb.max=', 136.01930236816406, 'rgb.min=', -225.80905151367188)
('rgb.max=', 135.9010009765625, 'rgb.min=', -225.90130615234375)
('rgb.max=', 135.88125610351562, 'rgb.min=', -225.7786865234375)
('rgb.max=', 136.17210388183594, 'rgb.min=', -225.96726989746094)
('rgb.max=', 135.94717407226562, 'rgb.min=', -226.02137756347656)
('rgb.max=', 135.95989990234375, 'rgb.min=', -225.97177124023438)
('rgb.max=', 136.11944580078125, 'rgb.min=', -225.87800598144531)
('rgb.max=', 136.02413940429688, 'rgb.min=', -225.86482238769531)
('rgb.max=', 135.9598388671875, 'rgb.min=', -225.90786743164062)
('rgb.max=', 136.14573669433594, 'rgb.min=', -225.90174865722656)
('rgb.max=', 135.93864440917969, 'rgb.min=', -225.755126953125)
('rgb.max=', 136.01446533203125, 'rgb.min=', -225.75883483886719)
('rgb.max=', 135.84739685058594, 'rgb.min=', -225.9349365234375)
('rgb.max=', 135.80128479003906, 'rgb.min=', -226.20169067382812)
('rgb.max=', 135.61329650878906, 'rgb.min=', -225.90121459960938)
('rgb.max=', 135.99343872070312, 'rgb.min=', -225.77156066894531)
('rgb.max=', 135.78111267089844, 'rgb.min=', -225.85334777832031)
('rgb.max=', 136.01365661621094, 'rgb.min=', -225.83871459960938)
('rgb.max=', 136.08770751953125, 'rgb.min=', -226.03550720214844)
('rgb.max=', 136.31867980957031, 'rgb.min=', -226.05461120605469)
('rgb.max=', 135.7926025390625, 'rgb.min=', -225.91624450683594)
('rgb.max=', 135.83717346191406, 'rgb.min=', -225.91850280761719)
('rgb.max=', 135.84970092773438, 'rgb.min=', -225.77250671386719)
('rgb.max=', 135.94082641601562, 'rgb.min=', -226.01275634765625)
('rgb.max=', 135.81021118164062, 'rgb.min=', -225.74143981933594)
('rgb.max=', 136.2342529296875, 'rgb.min=', -225.86227416992188)
('rgb.max=', 135.62120056152344, 'rgb.min=', -226.0584716796875)
('rgb.max=', 135.92605590820312, 'rgb.min=', -226.10292053222656)
('rgb.max=', 136.02969360351562, 'rgb.min=', -225.84068298339844)
('rgb.max=', 135.72706604003906, 'rgb.min=', -226.08453369140625)
('rgb.max=', 135.97036743164062, 'rgb.min=', -225.89642333984375)
('rgb.max=', 136.18760681152344, 'rgb.min=', -225.76278686523438)
('rgb.max=', 136.05335998535156, 'rgb.min=', -225.77909851074219)
('rgb.max=', 135.66755676269531, 'rgb.min=', -225.99888610839844)
('rgb.max=', 135.841064453125, 'rgb.min=', -226.02651977539062)
('rgb.max=', 136.03671264648438, 'rgb.min=', -225.833251953125)
('rgb.max=', 135.79940795898438, 'rgb.min=', -226.04377746582031)
('rgb.max=', 136.04025268554688, 'rgb.min=', -225.87551879882812)
('rgb.max=', 135.87530517578125, 'rgb.min=', -225.80862426757812)
('rgb.max=', 136.0638427734375, 'rgb.min=', -225.890380859375)
('rgb.max=', 135.7061767578125, 'rgb.min=', -226.02229309082031)
('rgb.max=', 136.16471862792969, 'rgb.min=', -225.8466796875)
('rgb.max=', 135.92501831054688, 'rgb.min=', -226.07449340820312)
('rgb.max=', 136.19841003417969, 'rgb.min=', -225.76101684570312)
('rgb.max=', 135.86471557617188, 'rgb.min=', -225.83653259277344)
('rgb.max=', 136.15875244140625, 'rgb.min=', -225.9932861328125)
('rgb.max=', 136.11270141601562, 'rgb.min=', -225.96859741210938)
('rgb.max=', 136.20115661621094, 'rgb.min=', -225.88188171386719)
('rgb.max=', 135.79646301269531, 'rgb.min=', -225.78431701660156)
('rgb.max=', 136.0379638671875, 'rgb.min=', -225.81132507324219)
('rgb.max=', 136.09223937988281, 'rgb.min=', -226.06259155273438)
('rgb.max=', 136.10261535644531, 'rgb.min=', -226.01779174804688)
('rgb.max=', 135.90753173828125, 'rgb.min=', -225.95018005371094)
('rgb.max=', 135.83842468261719, 'rgb.min=', -225.78834533691406)
('rgb.max=', 136.06243896484375, 'rgb.min=', -225.95726013183594)
('rgb.max=', 135.98529052734375, 'rgb.min=', -225.77091979980469)
('rgb.max=', 135.75421142578125, 'rgb.min=', -226.11935424804688)
('rgb.max=', 135.77713012695312, 'rgb.min=', -225.72373962402344)
('rgb.max=', 135.8353271484375, 'rgb.min=', -225.71485900878906)
('rgb.max=', 135.91542053222656, 'rgb.min=', -225.98138427734375)
('rgb.max=', 135.88711547851562, 'rgb.min=', -225.93133544921875)
('rgb.max=', 135.77206420898438, 'rgb.min=', -225.89315795898438)
('rgb.max=', 136.21160888671875, 'rgb.min=', -225.9444580078125)
('rgb.max=', 136.125244140625, 'rgb.min=', -225.83978271484375)
('rgb.max=', 135.97737121582031, 'rgb.min=', -226.01132202148438)
('rgb.max=', 135.64329528808594, 'rgb.min=', -225.82868957519531)
('rgb.max=', 136.14817810058594, 'rgb.min=', -226.00271606445312)
('rgb.max=', 136.11592102050781, 'rgb.min=', -225.95664978027344)
('rgb.max=', 135.83541870117188, 'rgb.min=', -225.92701721191406)
('rgb.max=', 136.1201171875, 'rgb.min=', -225.85940551757812)
('rgb.max=', 136.0775146484375, 'rgb.min=', -225.98483276367188)
('rgb.max=', 135.98222351074219, 'rgb.min=', -225.93362426757812)
('rgb.max=', 135.97528076171875, 'rgb.min=', -225.96990966796875)
('rgb.max=', 136.12973022460938, 'rgb.min=', -226.06477355957031)
('rgb.max=', 136.11073303222656, 'rgb.min=', -225.94863891601562)
('rgb.max=', 135.81231689453125, 'rgb.min=', -225.9603271484375)
('rgb.max=', 135.728759765625, 'rgb.min=', -225.96131896972656)
('rgb.max=', 135.75877380371094, 'rgb.min=', -225.72702026367188)
('rgb.max=', 135.96661376953125, 'rgb.min=', -226.18659973144531)
('rgb.max=', 136.0750732421875, 'rgb.min=', -225.94224548339844)
('rgb.max=', 135.9423828125, 'rgb.min=', -225.92521667480469)
('rgb.max=', 136.10395812988281, 'rgb.min=', -225.80021667480469)
('rgb.max=', 136.26084899902344, 'rgb.min=', -225.88162231445312)
('rgb.max=', 135.92111206054688, 'rgb.min=', -225.96456909179688)
('rgb.max=', 135.84170532226562, 'rgb.min=', -225.96141052246094)
('rgb.max=', 135.87535095214844, 'rgb.min=', -225.90827941894531)
('rgb.max=', 136.22103881835938, 'rgb.min=', -225.4896240234375)
('rgb.max=', 136.08061218261719, 'rgb.min=', -225.96672058105469)
('rgb.max=', 135.97979736328125, 'rgb.min=', -226.17816162109375)
('rgb.max=', 135.60525512695312, 'rgb.min=', -225.78453063964844)
('rgb.max=', 135.97512817382812, 'rgb.min=', -225.67112731933594)
('rgb.max=', 135.8936767578125, 'rgb.min=', -226.03726196289062)
('rgb.max=', 135.77593994140625, 'rgb.min=', -226.12318420410156)
('rgb.max=', 136.177978515625, 'rgb.min=', -225.62022399902344)
('rgb.max=', 135.593017578125, 'rgb.min=', -225.79095458984375)
('rgb.max=', 136.14317321777344, 'rgb.min=', -226.15150451660156)
('rgb.max=', 135.84677124023438, 'rgb.min=', -225.97471618652344)
('rgb.max=', 136.07255554199219, 'rgb.min=', -225.76483154296875)
('rgb.max=', 135.8922119140625, 'rgb.min=', -225.99221801757812)
('rgb.max=', 136.14205932617188, 'rgb.min=', -225.9208984375)
('rgb.max=', 135.8582763671875, 'rgb.min=', -226.21876525878906)
('rgb.max=', 135.98196411132812, 'rgb.min=', -225.90391540527344)
('rgb.max=', 136.03240966796875, 'rgb.min=', -225.99015808105469)
('rgb.max=', 135.89833068847656, 'rgb.min=', -226.14920043945312)
('rgb.max=', 136.13922119140625, 'rgb.min=', -226.08578491210938)
('rgb.max=', 135.83193969726562, 'rgb.min=', -225.81068420410156)
('rgb.max=', 136.12063598632812, 'rgb.min=', -225.78923034667969)
('rgb.max=', 136.0809326171875, 'rgb.min=', -225.73493957519531)
('rgb.max=', 136.03543090820312, 'rgb.min=', -225.91542053222656)
('rgb.max=', 135.79298400878906, 'rgb.min=', -226.12345886230469)
('rgb.max=', 135.95477294921875, 'rgb.min=', -225.874267578125)
('rgb.max=', 136.11178588867188, 'rgb.min=', -226.03431701660156)
('rgb.max=', 135.95994567871094, 'rgb.min=', -225.75691223144531)
('rgb.max=', 135.96563720703125, 'rgb.min=', -225.86148071289062)
('rgb.max=', 136.10377502441406, 'rgb.min=', -225.77847290039062)
('rgb.max=', 135.86460876464844, 'rgb.min=', -225.95675659179688)
('rgb.max=', 136.00555419921875, 'rgb.min=', -226.11744689941406)
('rgb.max=', 135.67584228515625, 'rgb.min=', -225.96067810058594)
('rgb.max=', 135.86943054199219, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.78958129882812, 'rgb.min=', -225.88356018066406)
('rgb.max=', 136.09048461914062, 'rgb.min=', -225.98020935058594)
('rgb.max=', 136.03089904785156, 'rgb.min=', -225.84638977050781)
('rgb.max=', 135.83364868164062, 'rgb.min=', -226.01448059082031)
('rgb.max=', 136.1090087890625, 'rgb.min=', -225.69538879394531)
('rgb.max=', 135.91033935546875, 'rgb.min=', -226.11911010742188)
('rgb.max=', 135.97015380859375, 'rgb.min=', -225.7703857421875)
('rgb.max=', 135.73857116699219, 'rgb.min=', -225.91790771484375)
('rgb.max=', 135.71762084960938, 'rgb.min=', -225.77070617675781)
('rgb.max=', 135.85531616210938, 'rgb.min=', -226.07467651367188)
('rgb.max=', 135.89080810546875, 'rgb.min=', -226.26414489746094)
('rgb.max=', 135.76994323730469, 'rgb.min=', -225.89820861816406)
('rgb.max=', 135.7833251953125, 'rgb.min=', -225.98320007324219)
('rgb.max=', 135.92819213867188, 'rgb.min=', -226.0908203125)
('rgb.max=', 136.11892700195312, 'rgb.min=', -226.13276672363281)
('rgb.max=', 135.98817443847656, 'rgb.min=', -226.3360595703125)
('rgb.max=', 136.12509155273438, 'rgb.min=', -225.92839050292969)
('rgb.max=', 136.11569213867188, 'rgb.min=', -225.74476623535156)
('rgb.max=', 136.05999755859375, 'rgb.min=', -226.11647033691406)
('rgb.max=', 135.96212768554688, 'rgb.min=', -226.087890625)
('rgb.max=', 136.109619140625, 'rgb.min=', -226.02195739746094)
('rgb.max=', 135.66629028320312, 'rgb.min=', -225.91203308105469)
('rgb.max=', 135.94113159179688, 'rgb.min=', -225.98945617675781)
('rgb.max=', 136.00048828125, 'rgb.min=', -225.91848754882812)
('rgb.max=', 136.09074401855469, 'rgb.min=', -225.8387451171875)
('rgb.max=', 135.96151733398438, 'rgb.min=', -226.12654113769531)
('rgb.max=', 135.84089660644531, 'rgb.min=', -225.81575012207031)
('rgb.max=', 135.92958068847656, 'rgb.min=', -225.82090759277344)
('rgb.max=', 135.62164306640625, 'rgb.min=', -226.28692626953125)
('rgb.max=', 135.74859619140625, 'rgb.min=', -225.92584228515625)
('rgb.max=', 135.83633422851562, 'rgb.min=', -226.04179382324219)
('rgb.max=', 135.90565490722656, 'rgb.min=', -225.88273620605469)
('rgb.max=', 135.9365234375, 'rgb.min=', -225.98619079589844)
('rgb.max=', 135.97018432617188, 'rgb.min=', -226.11940002441406)
('rgb.max=', 135.99688720703125, 'rgb.min=', -225.87142944335938)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79818725585938, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.86769104003906)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.77357482910156)
('rgb.max=', 135.66877746582031, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.84916687011719, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.89515686035156)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.78251647949219, 'rgb.min=', -225.78535461425781)
('rgb.max=', 135.89622497558594, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.61279296875)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.54220581054688)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76573181152344)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.7393798828125, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.79426574707031, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.75506591796875, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.6766357421875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.69232177734375, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.649169921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.52760314941406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.91191101074219, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.68447875976562, 'rgb.min=', -225.60102844238281)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88838195800781, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.86770629882812)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.73936462402344, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.60101318359375)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.72760009765625, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.64132690429688, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7119140625, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.59318542480469)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.73152160644531, 'rgb.min=', -225.85200500488281)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.63349914550781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.8648681640625, 'rgb.min=', -225.68731689453125)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.84133911132812, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.66769409179688)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.69906616210938)
('rgb.max=', 135.79034423828125, 'rgb.min=', -225.76182556152344)
('rgb.max=', 135.74720764160156, 'rgb.min=', -225.65592956542969)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.71977233886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.88839721679688, 'rgb.min=', -225.76966857910156)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.60603332519531, 'rgb.min=', -225.68730163574219)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.71583557128906, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.76290893554688, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.80996704101562, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88447570800781, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.72367858886719, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.71975708007812, 'rgb.min=', -225.79710388183594)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.79708862304688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.83633422851562)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.72259521484375)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.72257995605469)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.84524536132812, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.58250427246094, 'rgb.min=', -225.922607421875)
('rgb.max=', 135.75505065917969, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.774658203125, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.65594482421875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91084289550781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.85308837890625, 'rgb.min=', -225.8284912109375)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.7432861328125, 'rgb.min=', -225.78533935546875)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.80496215820312)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.65701293945312, 'rgb.min=', -225.80886840820312)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.78643798828125, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.84918212890625, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.76681518554688, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83348083496094, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.86485290527344, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.801025390625)
('rgb.max=', 135.75898742675781, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87947082519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87553405761719)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.76181030273438)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85984802246094)
('rgb.max=', 135.77859497070312, 'rgb.min=', -225.82455444335938)
('rgb.max=', 135.83740234375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.60887145996094)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.81280517578125)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.61387634277344, 'rgb.min=', -225.80888366699219)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.71476745605469)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.90299987792969)
('rgb.max=', 135.67662048339844, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.85592651367188)
('rgb.max=', 135.90408325195312, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.60211181640625, 'rgb.min=', -225.77751159667969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8912353515625)
('rgb.max=', 135.896240234375, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.74330139160156, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82456970214844)
('rgb.max=', 135.76289367675781, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.81672668457031)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.90692138671875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.87162780761719)
('rgb.max=', 135.82955932617188, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.73544311523438, 'rgb.min=', -225.89122009277344)
('rgb.max=', 135.74722290039062, 'rgb.min=', -225.84809875488281)
('rgb.max=', 135.80995178222656, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.78926086425781)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.8951416015625)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.83241271972656)
('rgb.max=', 135.86878967285156, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.88446044921875, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.58534240722656)
('rgb.max=', 135.88055419921875, 'rgb.min=', -225.84808349609375)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.57073974609375, 'rgb.min=', -225.64414978027344)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.7069091796875)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.84025573730469)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.63632202148438)
('rgb.max=', 135.47270202636719, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.68338012695312)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.83741760253906, 'rgb.min=', -225.78141784667969)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.90690612792969)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.92259216308594)
('rgb.max=', 135.89230346679688, 'rgb.min=', -225.80494689941406)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.91082763671875)
('rgb.max=', 135.900146484375, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.91474914550781)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.77749633789062)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.73043823242188)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.7696533203125)
('rgb.max=', 135.81388854980469, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.87271118164062, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.8060302734375, 'rgb.min=', -225.78143310546875)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.84416198730469)
('rgb.max=', 135.91192626953125, 'rgb.min=', -225.7030029296875)
('rgb.max=', 135.89231872558594, 'rgb.min=', -225.91868591308594)
('rgb.max=', 135.90798950195312, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.645263671875, 'rgb.min=', -225.86376953125)
('rgb.max=', 135.87269592285156, 'rgb.min=', -225.84417724609375)
('rgb.max=', 135.8021240234375, 'rgb.min=', -225.8323974609375)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.90016174316406, 'rgb.min=', -225.82063293457031)
('rgb.max=', 135.86093139648438, 'rgb.min=', -225.85986328125)
('rgb.max=', 135.90800476074219, 'rgb.min=', -225.72651672363281)
('rgb.max=', 135.91584777832031, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.85702514648438, 'rgb.min=', -225.85202026367188)
('rgb.max=', 135.62564086914062, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.63742065429688, 'rgb.min=', -225.79318237304688)
('rgb.max=', 135.87661743164062, 'rgb.min=', -225.88337707519531)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87945556640625)
('rgb.max=', 135.59036254882812, 'rgb.min=', -225.71083068847656)
('rgb.max=', 135.75112915039062, 'rgb.min=', -225.88729858398438)
('rgb.max=', 135.91975402832031, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.82847595214844)
('rgb.max=', 135.91583251953125, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.92652893066406)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.7657470703125)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.91976928710938, 'rgb.min=', -225.87554931640625)
('rgb.max=', 135.92367553710938, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.60604858398438, 'rgb.min=', -225.84024047851562)
('rgb.max=', 135.82565307617188, 'rgb.min=', -225.91476440429688)
('rgb.max=', 135.86094665527344, 'rgb.min=', -225.91867065429688)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.88339233398438)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.89907836914062)
('rgb.max=', 135.79428100585938, 'rgb.min=', -225.82064819335938)
('rgb.max=', 135.92759704589844, 'rgb.min=', -225.83631896972656)
('rgb.max=', 135.62957763671875, 'rgb.min=', -225.926513671875)
('rgb.max=', 135.70407104492188, 'rgb.min=', -225.69514465332031)
('rgb.max=', 135.82171630859375, 'rgb.min=', -225.90298461914062)
('rgb.max=', 135.90406799316406, 'rgb.min=', -225.74220275878906)
('rgb.max=', 135.8687744140625, 'rgb.min=', -225.77359008789062)
('rgb.max=', 135.9276123046875, 'rgb.min=', -225.87161254882812)
('rgb.max=', 135.81781005859375, 'rgb.min=', -225.77359008789062)
('Elapsed time in epoch = ', '0:00:28.336557')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7001 ', 'GAN acc 0.4570', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4883', 'Total loss: 1.3936', 'for batch', 0)
('GAN loss 0.7053 ', 'GAN acc 0.4180', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5059', 'Total loss: 1.3991', 'for batch', 1)
('GAN loss 0.7041 ', 'GAN acc 0.3789', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4570', 'Total loss: 1.4016', 'for batch', 2)
('GAN loss 0.7004 ', 'GAN acc 0.4141', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4609', 'Total loss: 1.3970', 'for batch', 3)
('GAN loss 0.6947 ', 'GAN acc 0.4492', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4902', 'Total loss: 1.3891', 'for batch', 4)
('GAN loss 0.6960 ', 'GAN acc 0.4453', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4980', 'Total loss: 1.3899', 'for batch', 5)
('GAN loss 0.6876 ', 'GAN acc 0.5664', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4902', 'Total loss: 1.3807', 'for batch', 6)
('GAN loss 0.6841 ', 'GAN acc 0.6406', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5020', 'Total loss: 1.3789', 'for batch', 7)
('GAN loss 0.6850 ', 'GAN acc 0.5938', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5117', 'Total loss: 1.3784', 'for batch', 8)
('GAN loss 0.6829 ', 'GAN acc 0.6094', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5195', 'Total loss: 1.3760', 'for batch', 9)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7490 ', 'GAN acc 0.5039', 'Discriminator loss 0.7460', 'Discriminator accuracy 0.4980', 'Total loss: 1.4950', 'for batch', 0)
('GAN loss 0.6940 ', 'GAN acc 0.5391', 'Discriminator loss 0.7709', 'Discriminator accuracy 0.5039', 'Total loss: 1.4649', 'for batch', 1)
('GAN loss 0.7790 ', 'GAN acc 0.5078', 'Discriminator loss 0.8003', 'Discriminator accuracy 0.4844', 'Total loss: 1.5793', 'for batch', 2)
('GAN loss 0.8858 ', 'GAN acc 0.3672', 'Discriminator loss 0.7549', 'Discriminator accuracy 0.5332', 'Total loss: 1.6407', 'for batch', 3)
('GAN loss 0.7832 ', 'GAN acc 0.4414', 'Discriminator loss 0.7691', 'Discriminator accuracy 0.4707', 'Total loss: 1.5523', 'for batch', 4)
('GAN loss 0.7417 ', 'GAN acc 0.5000', 'Discriminator loss 0.7744', 'Discriminator accuracy 0.4863', 'Total loss: 1.5162', 'for batch', 5)
('GAN loss 0.7449 ', 'GAN acc 0.4570', 'Discriminator loss 0.7108', 'Discriminator accuracy 0.5410', 'Total loss: 1.4557', 'for batch', 6)
('GAN loss 0.8165 ', 'GAN acc 0.4023', 'Discriminator loss 0.7146', 'Discriminator accuracy 0.5234', 'Total loss: 1.5311', 'for batch', 7)
('GAN loss 0.7906 ', 'GAN acc 0.3984', 'Discriminator loss 0.7234', 'Discriminator accuracy 0.5371', 'Total loss: 1.5139', 'for batch', 8)
('GAN loss 0.9089 ', 'GAN acc 0.2969', 'Discriminator loss 0.7212', 'Discriminator accuracy 0.5410', 'Total loss: 1.6301', 'for batch', 9)
('GAN loss 0.9839 ', 'GAN acc 0.2734', 'Discriminator loss 0.6599', 'Discriminator accuracy 0.5918', 'Total loss: 1.6438', 'for batch', 10)
('GAN loss 1.0379 ', 'GAN acc 0.2266', 'Discriminator loss 0.6612', 'Discriminator accuracy 0.6133', 'Total loss: 1.6991', 'for batch', 11)
('GAN loss 0.9753 ', 'GAN acc 0.2539', 'Discriminator loss 0.6072', 'Discriminator accuracy 0.6758', 'Total loss: 1.5825', 'for batch', 12)
('GAN loss 1.0720 ', 'GAN acc 0.1680', 'Discriminator loss 0.6030', 'Discriminator accuracy 0.7305', 'Total loss: 1.6749', 'for batch', 13)
('GAN loss 1.1454 ', 'GAN acc 0.1562', 'Discriminator loss 0.6219', 'Discriminator accuracy 0.6855', 'Total loss: 1.7673', 'for batch', 14)
('GAN loss 1.1567 ', 'GAN acc 0.1523', 'Discriminator loss 0.6380', 'Discriminator accuracy 0.6523', 'Total loss: 1.7946', 'for batch', 15)
('GAN loss 1.1129 ', 'GAN acc 0.2031', 'Discriminator loss 0.6238', 'Discriminator accuracy 0.6348', 'Total loss: 1.7367', 'for batch', 16)
('GAN loss 1.0878 ', 'GAN acc 0.2031', 'Discriminator loss 0.6014', 'Discriminator accuracy 0.6816', 'Total loss: 1.6892', 'for batch', 17)
('GAN loss 1.1988 ', 'GAN acc 0.1445', 'Discriminator loss 0.5833', 'Discriminator accuracy 0.7109', 'Total loss: 1.7821', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.78907412)
('DISCRIMINATOR_Imagem FAKE=', 0.59740138)
('Discriminator trained', 14, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:44.885413')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2009 ', 'GAN acc 0.1719', 'Discriminator loss 0.5695', 'Discriminator accuracy 0.7266', 'Total loss: 1.7704', 'for batch', 0)
('GAN loss 1.2201 ', 'GAN acc 0.1445', 'Discriminator loss 0.5482', 'Discriminator accuracy 0.7363', 'Total loss: 1.7683', 'for batch', 1)
('GAN loss 1.2593 ', 'GAN acc 0.1328', 'Discriminator loss 0.5001', 'Discriminator accuracy 0.8008', 'Total loss: 1.7594', 'for batch', 2)
('GAN loss 1.1734 ', 'GAN acc 0.1797', 'Discriminator loss 0.5035', 'Discriminator accuracy 0.8164', 'Total loss: 1.6769', 'for batch', 3)
('GAN loss 1.1819 ', 'GAN acc 0.1562', 'Discriminator loss 0.5090', 'Discriminator accuracy 0.8164', 'Total loss: 1.6909', 'for batch', 4)
('GAN loss 1.1865 ', 'GAN acc 0.1562', 'Discriminator loss 0.5327', 'Discriminator accuracy 0.7734', 'Total loss: 1.7192', 'for batch', 5)
('GAN loss 1.3908 ', 'GAN acc 0.0977', 'Discriminator loss 0.5449', 'Discriminator accuracy 0.7520', 'Total loss: 1.9357', 'for batch', 6)
('GAN loss 1.3859 ', 'GAN acc 0.0977', 'Discriminator loss 0.5324', 'Discriminator accuracy 0.7500', 'Total loss: 1.9183', 'for batch', 7)
('GAN loss 1.3401 ', 'GAN acc 0.1172', 'Discriminator loss 0.4977', 'Discriminator accuracy 0.8203', 'Total loss: 1.8378', 'for batch', 8)
('GAN loss 1.6688 ', 'GAN acc 0.0977', 'Discriminator loss 0.5637', 'Discriminator accuracy 0.7363', 'Total loss: 2.2325', 'for batch', 9)
('GAN loss 1.4391 ', 'GAN acc 0.1641', 'Discriminator loss 0.5639', 'Discriminator accuracy 0.6836', 'Total loss: 2.0031', 'for batch', 10)
('GAN loss 1.4239 ', 'GAN acc 0.1406', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.6230', 'Total loss: 2.0763', 'for batch', 11)
('GAN loss 1.4219 ', 'GAN acc 0.1758', 'Discriminator loss 0.6517', 'Discriminator accuracy 0.5625', 'Total loss: 2.0736', 'for batch', 12)
('GAN loss 1.3915 ', 'GAN acc 0.1523', 'Discriminator loss 0.5991', 'Discriminator accuracy 0.6660', 'Total loss: 1.9906', 'for batch', 13)
('GAN loss 1.2733 ', 'GAN acc 0.1992', 'Discriminator loss 0.5780', 'Discriminator accuracy 0.6777', 'Total loss: 1.8513', 'for batch', 14)
('GAN loss 1.4845 ', 'GAN acc 0.1289', 'Discriminator loss 0.6006', 'Discriminator accuracy 0.6914', 'Total loss: 2.0852', 'for batch', 15)
('GAN loss 1.4789 ', 'GAN acc 0.0938', 'Discriminator loss 0.5780', 'Discriminator accuracy 0.6719', 'Total loss: 2.0569', 'for batch', 16)
('GAN loss 1.2714 ', 'GAN acc 0.1758', 'Discriminator loss 0.5863', 'Discriminator accuracy 0.6523', 'Total loss: 1.8577', 'for batch', 17)
('GAN loss 1.4657 ', 'GAN acc 0.0938', 'Discriminator loss 0.5944', 'Discriminator accuracy 0.7031', 'Total loss: 2.0601', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.8599143)
('DISCRIMINATOR_Imagem FAKE=', 0.83289367)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.173491')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.3955 ', 'GAN acc 0.1328', 'Discriminator loss 0.6523', 'Discriminator accuracy 0.5801', 'Total loss: 2.0478', 'for batch', 0)
('GAN loss 1.1052 ', 'GAN acc 0.2969', 'Discriminator loss 0.6625', 'Discriminator accuracy 0.5723', 'Total loss: 1.7677', 'for batch', 1)
('GAN loss 1.1907 ', 'GAN acc 0.2188', 'Discriminator loss 0.6345', 'Discriminator accuracy 0.6152', 'Total loss: 1.8252', 'for batch', 2)
('GAN loss 1.1948 ', 'GAN acc 0.2266', 'Discriminator loss 0.6568', 'Discriminator accuracy 0.5977', 'Total loss: 1.8515', 'for batch', 3)
('GAN loss 0.9940 ', 'GAN acc 0.3633', 'Discriminator loss 0.6473', 'Discriminator accuracy 0.5820', 'Total loss: 1.6412', 'for batch', 4)
('GAN loss 1.0852 ', 'GAN acc 0.2852', 'Discriminator loss 0.6601', 'Discriminator accuracy 0.5938', 'Total loss: 1.7453', 'for batch', 5)
('GAN loss 1.0047 ', 'GAN acc 0.3438', 'Discriminator loss 0.6387', 'Discriminator accuracy 0.5781', 'Total loss: 1.6434', 'for batch', 6)
('GAN loss 1.0276 ', 'GAN acc 0.2734', 'Discriminator loss 0.6577', 'Discriminator accuracy 0.6035', 'Total loss: 1.6853', 'for batch', 7)
('GAN loss 0.9701 ', 'GAN acc 0.2852', 'Discriminator loss 0.6397', 'Discriminator accuracy 0.6133', 'Total loss: 1.6099', 'for batch', 8)
('GAN loss 0.9696 ', 'GAN acc 0.3008', 'Discriminator loss 0.6834', 'Discriminator accuracy 0.5430', 'Total loss: 1.6530', 'for batch', 9)
('GAN loss 0.9546 ', 'GAN acc 0.2695', 'Discriminator loss 0.6605', 'Discriminator accuracy 0.5898', 'Total loss: 1.6151', 'for batch', 10)
('GAN loss 0.8139 ', 'GAN acc 0.4219', 'Discriminator loss 0.6829', 'Discriminator accuracy 0.5430', 'Total loss: 1.4969', 'for batch', 11)
('GAN loss 0.8799 ', 'GAN acc 0.3438', 'Discriminator loss 0.6692', 'Discriminator accuracy 0.5879', 'Total loss: 1.5491', 'for batch', 12)
('GAN loss 0.8641 ', 'GAN acc 0.3594', 'Discriminator loss 0.6488', 'Discriminator accuracy 0.6152', 'Total loss: 1.5129', 'for batch', 13)
('GAN loss 0.8741 ', 'GAN acc 0.3711', 'Discriminator loss 0.6565', 'Discriminator accuracy 0.6016', 'Total loss: 1.5306', 'for batch', 14)
('GAN loss 0.8600 ', 'GAN acc 0.3750', 'Discriminator loss 0.6702', 'Discriminator accuracy 0.5645', 'Total loss: 1.5303', 'for batch', 15)
('GAN loss 0.7801 ', 'GAN acc 0.4062', 'Discriminator loss 0.6763', 'Discriminator accuracy 0.5742', 'Total loss: 1.4564', 'for batch', 16)
('GAN loss 0.8240 ', 'GAN acc 0.3789', 'Discriminator loss 0.6765', 'Discriminator accuracy 0.5703', 'Total loss: 1.5005', 'for batch', 17)
('GAN loss 0.7707 ', 'GAN acc 0.4805', 'Discriminator loss 0.6599', 'Discriminator accuracy 0.6055', 'Total loss: 1.4306', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.83806771)
('DISCRIMINATOR_Imagem FAKE=', 0.79009694)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.829083')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8006 ', 'GAN acc 0.4492', 'Discriminator loss 0.6599', 'Discriminator accuracy 0.6094', 'Total loss: 1.4605', 'for batch', 0)
('GAN loss 0.8122 ', 'GAN acc 0.3867', 'Discriminator loss 0.6572', 'Discriminator accuracy 0.6191', 'Total loss: 1.4694', 'for batch', 1)
('GAN loss 0.7988 ', 'GAN acc 0.4375', 'Discriminator loss 0.6606', 'Discriminator accuracy 0.5645', 'Total loss: 1.4594', 'for batch', 2)
('GAN loss 0.7474 ', 'GAN acc 0.4922', 'Discriminator loss 0.6676', 'Discriminator accuracy 0.6055', 'Total loss: 1.4149', 'for batch', 3)
('GAN loss 0.7525 ', 'GAN acc 0.4648', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.6328', 'Total loss: 1.4048', 'for batch', 4)
('GAN loss 0.7217 ', 'GAN acc 0.5312', 'Discriminator loss 0.6676', 'Discriminator accuracy 0.6016', 'Total loss: 1.3893', 'for batch', 5)
('GAN loss 0.7668 ', 'GAN acc 0.4531', 'Discriminator loss 0.6599', 'Discriminator accuracy 0.6035', 'Total loss: 1.4267', 'for batch', 6)
('GAN loss 0.7351 ', 'GAN acc 0.5000', 'Discriminator loss 0.6605', 'Discriminator accuracy 0.5898', 'Total loss: 1.3957', 'for batch', 7)
('GAN loss 0.7400 ', 'GAN acc 0.5000', 'Discriminator loss 0.6584', 'Discriminator accuracy 0.5879', 'Total loss: 1.3984', 'for batch', 8)
('GAN loss 0.6975 ', 'GAN acc 0.5469', 'Discriminator loss 0.6728', 'Discriminator accuracy 0.5605', 'Total loss: 1.3703', 'for batch', 9)
('GAN loss 0.7050 ', 'GAN acc 0.5273', 'Discriminator loss 0.6738', 'Discriminator accuracy 0.5723', 'Total loss: 1.3788', 'for batch', 10)
('GAN loss 0.7052 ', 'GAN acc 0.5820', 'Discriminator loss 0.6726', 'Discriminator accuracy 0.5586', 'Total loss: 1.3778', 'for batch', 11)
('GAN loss 0.6877 ', 'GAN acc 0.5703', 'Discriminator loss 0.6870', 'Discriminator accuracy 0.5410', 'Total loss: 1.3747', 'for batch', 12)
('GAN loss 0.7216 ', 'GAN acc 0.5195', 'Discriminator loss 0.6726', 'Discriminator accuracy 0.5898', 'Total loss: 1.3942', 'for batch', 13)
('GAN loss 0.7131 ', 'GAN acc 0.5898', 'Discriminator loss 0.6686', 'Discriminator accuracy 0.5664', 'Total loss: 1.3817', 'for batch', 14)
('GAN loss 0.6957 ', 'GAN acc 0.5547', 'Discriminator loss 0.6753', 'Discriminator accuracy 0.5859', 'Total loss: 1.3710', 'for batch', 15)
('GAN loss 0.7010 ', 'GAN acc 0.5430', 'Discriminator loss 0.6623', 'Discriminator accuracy 0.5820', 'Total loss: 1.3634', 'for batch', 16)
('GAN loss 0.7223 ', 'GAN acc 0.4961', 'Discriminator loss 0.6795', 'Discriminator accuracy 0.5449', 'Total loss: 1.4018', 'for batch', 17)
('GAN loss 0.7181 ', 'GAN acc 0.5078', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5391', 'Total loss: 1.4073', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.82492614)
('DISCRIMINATOR_Imagem FAKE=', 0.78134203)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.433333')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7411 ', 'GAN acc 0.5039', 'Discriminator loss 0.6733', 'Discriminator accuracy 0.5762', 'Total loss: 1.4144', 'for batch', 0)
('GAN loss 0.7019 ', 'GAN acc 0.5898', 'Discriminator loss 0.6826', 'Discriminator accuracy 0.5645', 'Total loss: 1.3845', 'for batch', 1)
('GAN loss 0.6732 ', 'GAN acc 0.6172', 'Discriminator loss 0.6867', 'Discriminator accuracy 0.5449', 'Total loss: 1.3598', 'for batch', 2)
('GAN loss 0.6696 ', 'GAN acc 0.6172', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.5156', 'Total loss: 1.3674', 'for batch', 3)
('GAN loss 0.6698 ', 'GAN acc 0.5820', 'Discriminator loss 0.7145', 'Discriminator accuracy 0.4883', 'Total loss: 1.3843', 'for batch', 4)
('GAN loss 0.6668 ', 'GAN acc 0.5703', 'Discriminator loss 0.7098', 'Discriminator accuracy 0.5020', 'Total loss: 1.3765', 'for batch', 5)
('GAN loss 0.6641 ', 'GAN acc 0.6250', 'Discriminator loss 0.7087', 'Discriminator accuracy 0.5000', 'Total loss: 1.3728', 'for batch', 6)
('GAN loss 0.6835 ', 'GAN acc 0.5625', 'Discriminator loss 0.7169', 'Discriminator accuracy 0.4512', 'Total loss: 1.4004', 'for batch', 7)
('GAN loss 0.6715 ', 'GAN acc 0.6328', 'Discriminator loss 0.7172', 'Discriminator accuracy 0.4961', 'Total loss: 1.3887', 'for batch', 8)
('GAN loss 0.6682 ', 'GAN acc 0.5820', 'Discriminator loss 0.7200', 'Discriminator accuracy 0.4746', 'Total loss: 1.3882', 'for batch', 9)
('GAN loss 0.6877 ', 'GAN acc 0.5312', 'Discriminator loss 0.7122', 'Discriminator accuracy 0.4961', 'Total loss: 1.3999', 'for batch', 10)
('GAN loss 0.6725 ', 'GAN acc 0.5781', 'Discriminator loss 0.7097', 'Discriminator accuracy 0.5020', 'Total loss: 1.3822', 'for batch', 11)
('GAN loss 0.6642 ', 'GAN acc 0.6406', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4980', 'Total loss: 1.3614', 'for batch', 12)
('GAN loss 0.6878 ', 'GAN acc 0.5625', 'Discriminator loss 0.7151', 'Discriminator accuracy 0.4570', 'Total loss: 1.4029', 'for batch', 13)
('GAN loss 0.6637 ', 'GAN acc 0.6172', 'Discriminator loss 0.7150', 'Discriminator accuracy 0.4688', 'Total loss: 1.3786', 'for batch', 14)
('GAN loss 0.6565 ', 'GAN acc 0.6094', 'Discriminator loss 0.7142', 'Discriminator accuracy 0.4902', 'Total loss: 1.3707', 'for batch', 15)
('GAN loss 0.6563 ', 'GAN acc 0.6484', 'Discriminator loss 0.7099', 'Discriminator accuracy 0.4688', 'Total loss: 1.3662', 'for batch', 16)
('GAN loss 0.6637 ', 'GAN acc 0.6406', 'Discriminator loss 0.7034', 'Discriminator accuracy 0.5215', 'Total loss: 1.3671', 'for batch', 17)
('GAN loss 0.6475 ', 'GAN acc 0.6758', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.5078', 'Total loss: 1.3480', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.75205946)
('DISCRIMINATOR_Imagem FAKE=', 0.73573112)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.996410')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6596 ', 'GAN acc 0.6211', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.5430', 'Total loss: 1.3616', 'for batch', 0)
('GAN loss 0.6713 ', 'GAN acc 0.5898', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4922', 'Total loss: 1.3744', 'for batch', 1)
('GAN loss 0.6480 ', 'GAN acc 0.6680', 'Discriminator loss 0.7115', 'Discriminator accuracy 0.4746', 'Total loss: 1.3596', 'for batch', 2)
('GAN loss 0.6500 ', 'GAN acc 0.6875', 'Discriminator loss 0.7103', 'Discriminator accuracy 0.4824', 'Total loss: 1.3603', 'for batch', 3)
('GAN loss 0.6377 ', 'GAN acc 0.7070', 'Discriminator loss 0.7056', 'Discriminator accuracy 0.4805', 'Total loss: 1.3433', 'for batch', 4)
('GAN loss 0.6616 ', 'GAN acc 0.6133', 'Discriminator loss 0.7097', 'Discriminator accuracy 0.4746', 'Total loss: 1.3712', 'for batch', 5)
('GAN loss 0.6599 ', 'GAN acc 0.6406', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5059', 'Total loss: 1.3568', 'for batch', 6)
('GAN loss 0.6589 ', 'GAN acc 0.6445', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.4922', 'Total loss: 1.3632', 'for batch', 7)
('GAN loss 0.6570 ', 'GAN acc 0.6406', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5273', 'Total loss: 1.3499', 'for batch', 8)
('GAN loss 0.6527 ', 'GAN acc 0.6797', 'Discriminator loss 0.7171', 'Discriminator accuracy 0.4531', 'Total loss: 1.3698', 'for batch', 9)
('GAN loss 0.6719 ', 'GAN acc 0.6055', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.4785', 'Total loss: 1.3760', 'for batch', 10)
('GAN loss 0.6691 ', 'GAN acc 0.6016', 'Discriminator loss 0.7129', 'Discriminator accuracy 0.4414', 'Total loss: 1.3820', 'for batch', 11)
('GAN loss 0.6724 ', 'GAN acc 0.5977', 'Discriminator loss 0.7098', 'Discriminator accuracy 0.4688', 'Total loss: 1.3822', 'for batch', 12)
('GAN loss 0.6569 ', 'GAN acc 0.6445', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.5195', 'Total loss: 1.3556', 'for batch', 13)
('GAN loss 0.6591 ', 'GAN acc 0.6562', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4941', 'Total loss: 1.3584', 'for batch', 14)
('GAN loss 0.6774 ', 'GAN acc 0.5547', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.5137', 'Total loss: 1.3784', 'for batch', 15)
('GAN loss 0.6938 ', 'GAN acc 0.5352', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5254', 'Total loss: 1.3873', 'for batch', 16)
('GAN loss 0.6781 ', 'GAN acc 0.5820', 'Discriminator loss 0.7078', 'Discriminator accuracy 0.4883', 'Total loss: 1.3860', 'for batch', 17)
('GAN loss 0.6656 ', 'GAN acc 0.6250', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4902', 'Total loss: 1.3675', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.68738234)
('DISCRIMINATOR_Imagem FAKE=', 0.682181)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.506881')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6731 ', 'GAN acc 0.6094', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5098', 'Total loss: 1.3660', 'for batch', 0)
('GAN loss 0.6662 ', 'GAN acc 0.6055', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4941', 'Total loss: 1.3655', 'for batch', 1)
('GAN loss 0.6761 ', 'GAN acc 0.5586', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4961', 'Total loss: 1.3722', 'for batch', 2)
('GAN loss 0.6710 ', 'GAN acc 0.6289', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4629', 'Total loss: 1.3726', 'for batch', 3)
('GAN loss 0.6758 ', 'GAN acc 0.5742', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4941', 'Total loss: 1.3776', 'for batch', 4)
('GAN loss 0.6868 ', 'GAN acc 0.5703', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.5312', 'Total loss: 1.3886', 'for batch', 5)
('GAN loss 0.6741 ', 'GAN acc 0.5742', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5020', 'Total loss: 1.3721', 'for batch', 6)
('GAN loss 0.6764 ', 'GAN acc 0.5781', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4922', 'Total loss: 1.3742', 'for batch', 7)
('GAN loss 0.6856 ', 'GAN acc 0.5469', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5098', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6916 ', 'GAN acc 0.5430', 'Discriminator loss 0.7049', 'Discriminator accuracy 0.4844', 'Total loss: 1.3964', 'for batch', 9)
('GAN loss 0.6814 ', 'GAN acc 0.5664', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4922', 'Total loss: 1.3839', 'for batch', 10)
('GAN loss 0.6805 ', 'GAN acc 0.5547', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5371', 'Total loss: 1.3738', 'for batch', 11)
('GAN loss 0.6772 ', 'GAN acc 0.5938', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.5195', 'Total loss: 1.3815', 'for batch', 12)
('GAN loss 0.6819 ', 'GAN acc 0.5430', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4805', 'Total loss: 1.3834', 'for batch', 13)
('GAN loss 0.6937 ', 'GAN acc 0.5469', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5215', 'Total loss: 1.3898', 'for batch', 14)
('GAN loss 0.7102 ', 'GAN acc 0.4766', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4707', 'Total loss: 1.4102', 'for batch', 15)
('GAN loss 0.7091 ', 'GAN acc 0.4727', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4707', 'Total loss: 1.4115', 'for batch', 16)
('GAN loss 0.7126 ', 'GAN acc 0.4570', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.5000', 'Total loss: 1.4164', 'for batch', 17)
('GAN loss 0.6977 ', 'GAN acc 0.4805', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4824', 'Total loss: 1.4013', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.64140278)
('DISCRIMINATOR_Imagem FAKE=', 0.64104056)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.078800')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6930 ', 'GAN acc 0.5430', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.5059', 'Total loss: 1.3968', 'for batch', 0)
('GAN loss 0.6965 ', 'GAN acc 0.5273', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4785', 'Total loss: 1.4002', 'for batch', 1)
('GAN loss 0.6912 ', 'GAN acc 0.5391', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4824', 'Total loss: 1.3918', 'for batch', 2)
('GAN loss 0.6822 ', 'GAN acc 0.5703', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5078', 'Total loss: 1.3764', 'for batch', 3)
('GAN loss 0.6845 ', 'GAN acc 0.5391', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5000', 'Total loss: 1.3785', 'for batch', 4)
('GAN loss 0.6820 ', 'GAN acc 0.5430', 'Discriminator loss 0.7034', 'Discriminator accuracy 0.4961', 'Total loss: 1.3855', 'for batch', 5)
('GAN loss 0.6795 ', 'GAN acc 0.5547', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.5000', 'Total loss: 1.3772', 'for batch', 6)
('GAN loss 0.6822 ', 'GAN acc 0.5703', 'Discriminator loss 0.6898', 'Discriminator accuracy 0.5117', 'Total loss: 1.3720', 'for batch', 7)
('GAN loss 0.6804 ', 'GAN acc 0.5781', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4961', 'Total loss: 1.3810', 'for batch', 8)
('GAN loss 0.6944 ', 'GAN acc 0.4961', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.5098', 'Total loss: 1.3939', 'for batch', 9)
('GAN loss 0.6965 ', 'GAN acc 0.5078', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.5059', 'Total loss: 1.3961', 'for batch', 10)
('GAN loss 0.6994 ', 'GAN acc 0.4844', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4766', 'Total loss: 1.4003', 'for batch', 11)
('GAN loss 0.7040 ', 'GAN acc 0.4727', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4922', 'Total loss: 1.4048', 'for batch', 12)
('GAN loss 0.6886 ', 'GAN acc 0.5547', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5156', 'Total loss: 1.3860', 'for batch', 13)
('GAN loss 0.6918 ', 'GAN acc 0.5391', 'Discriminator loss 0.7087', 'Discriminator accuracy 0.4531', 'Total loss: 1.4005', 'for batch', 14)
('GAN loss 0.6901 ', 'GAN acc 0.5469', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5098', 'Total loss: 1.3846', 'for batch', 15)
('GAN loss 0.7064 ', 'GAN acc 0.5078', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5195', 'Total loss: 1.4026', 'for batch', 16)
('GAN loss 0.6894 ', 'GAN acc 0.5625', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4863', 'Total loss: 1.3934', 'for batch', 17)
('GAN loss 0.6889 ', 'GAN acc 0.5469', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5195', 'Total loss: 1.3832', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.61441088)
('DISCRIMINATOR_Imagem FAKE=', 0.61694837)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.595868')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6867 ', 'GAN acc 0.5430', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.5098', 'Total loss: 1.3851', 'for batch', 0)
('GAN loss 0.7007 ', 'GAN acc 0.4609', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4824', 'Total loss: 1.4012', 'for batch', 1)
('GAN loss 0.7076 ', 'GAN acc 0.4570', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5293', 'Total loss: 1.4002', 'for batch', 2)
('GAN loss 0.6846 ', 'GAN acc 0.5625', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4727', 'Total loss: 1.3843', 'for batch', 3)
('GAN loss 0.6898 ', 'GAN acc 0.5664', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5078', 'Total loss: 1.3842', 'for batch', 4)
('GAN loss 0.6972 ', 'GAN acc 0.4844', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4570', 'Total loss: 1.4007', 'for batch', 5)
('GAN loss 0.6905 ', 'GAN acc 0.5391', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5039', 'Total loss: 1.3873', 'for batch', 6)
('GAN loss 0.6995 ', 'GAN acc 0.5156', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5195', 'Total loss: 1.3934', 'for batch', 7)
('GAN loss 0.6944 ', 'GAN acc 0.5234', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.5000', 'Total loss: 1.3932', 'for batch', 8)
('GAN loss 0.7013 ', 'GAN acc 0.4531', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5293', 'Total loss: 1.3944', 'for batch', 9)
('GAN loss 0.7010 ', 'GAN acc 0.4805', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4863', 'Total loss: 1.3993', 'for batch', 10)
('GAN loss 0.6955 ', 'GAN acc 0.5156', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4785', 'Total loss: 1.4022', 'for batch', 11)
('GAN loss 0.6805 ', 'GAN acc 0.5898', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4746', 'Total loss: 1.3827', 'for batch', 12)
('GAN loss 0.6763 ', 'GAN acc 0.6016', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4766', 'Total loss: 1.3792', 'for batch', 13)
('GAN loss 0.6852 ', 'GAN acc 0.5742', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.4648', 'Total loss: 1.3877', 'for batch', 14)
('GAN loss 0.7010 ', 'GAN acc 0.4570', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4980', 'Total loss: 1.3968', 'for batch', 15)
('GAN loss 0.7066 ', 'GAN acc 0.4492', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4824', 'Total loss: 1.4035', 'for batch', 16)
('GAN loss 0.7010 ', 'GAN acc 0.4844', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4590', 'Total loss: 1.4033', 'for batch', 17)
('GAN loss 0.7037 ', 'GAN acc 0.4609', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5098', 'Total loss: 1.3990', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58911705)
('DISCRIMINATOR_Imagem FAKE=', 0.5911504)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.098767')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6949 ', 'GAN acc 0.5273', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4902', 'Total loss: 1.3953', 'for batch', 0)
('GAN loss 0.6915 ', 'GAN acc 0.5586', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4727', 'Total loss: 1.3940', 'for batch', 1)
('GAN loss 0.6843 ', 'GAN acc 0.5742', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4688', 'Total loss: 1.3861', 'for batch', 2)
('GAN loss 0.6811 ', 'GAN acc 0.5859', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4902', 'Total loss: 1.3813', 'for batch', 3)
('GAN loss 0.6906 ', 'GAN acc 0.5352', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4688', 'Total loss: 1.3877', 'for batch', 4)
('GAN loss 0.6825 ', 'GAN acc 0.5742', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5195', 'Total loss: 1.3764', 'for batch', 5)
('GAN loss 0.6753 ', 'GAN acc 0.6016', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5039', 'Total loss: 1.3680', 'for batch', 6)
('GAN loss 0.6864 ', 'GAN acc 0.5195', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4961', 'Total loss: 1.3851', 'for batch', 7)
('GAN loss 0.6887 ', 'GAN acc 0.5195', 'Discriminator loss 0.6892', 'Discriminator accuracy 0.5645', 'Total loss: 1.3779', 'for batch', 8)
('GAN loss 0.6910 ', 'GAN acc 0.5391', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4434', 'Total loss: 1.3957', 'for batch', 9)
('GAN loss 0.6872 ', 'GAN acc 0.5547', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5156', 'Total loss: 1.3814', 'for batch', 10)
('GAN loss 0.6926 ', 'GAN acc 0.5039', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5195', 'Total loss: 1.3889', 'for batch', 11)
('GAN loss 0.6796 ', 'GAN acc 0.5781', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5156', 'Total loss: 1.3732', 'for batch', 12)
('GAN loss 0.6929 ', 'GAN acc 0.4883', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5137', 'Total loss: 1.3894', 'for batch', 13)
('GAN loss 0.6892 ', 'GAN acc 0.5703', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5371', 'Total loss: 1.3814', 'for batch', 14)
('GAN loss 0.7005 ', 'GAN acc 0.4570', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4922', 'Total loss: 1.3961', 'for batch', 15)
('GAN loss 0.7028 ', 'GAN acc 0.4688', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5430', 'Total loss: 1.3958', 'for batch', 16)
('GAN loss 0.7138 ', 'GAN acc 0.3984', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4766', 'Total loss: 1.4147', 'for batch', 17)
('GAN loss 0.7161 ', 'GAN acc 0.3906', 'Discriminator loss 0.7063', 'Discriminator accuracy 0.4473', 'Total loss: 1.4224', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.57233346)
('DISCRIMINATOR_Imagem FAKE=', 0.57346296)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.589110')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7027 ', 'GAN acc 0.4297', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5078', 'Total loss: 1.3978', 'for batch', 0)
('GAN loss 0.7008 ', 'GAN acc 0.4648', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.5000', 'Total loss: 1.4012', 'for batch', 1)
('GAN loss 0.7007 ', 'GAN acc 0.4531', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4668', 'Total loss: 1.4007', 'for batch', 2)
('GAN loss 0.6935 ', 'GAN acc 0.5430', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4980', 'Total loss: 1.3923', 'for batch', 3)
('GAN loss 0.6822 ', 'GAN acc 0.5977', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5254', 'Total loss: 1.3794', 'for batch', 4)
('GAN loss 0.6795 ', 'GAN acc 0.5938', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5410', 'Total loss: 1.3726', 'for batch', 5)
('GAN loss 0.6808 ', 'GAN acc 0.5820', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4902', 'Total loss: 1.3781', 'for batch', 6)
('GAN loss 0.6801 ', 'GAN acc 0.5781', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4980', 'Total loss: 1.3760', 'for batch', 7)
('GAN loss 0.6827 ', 'GAN acc 0.6016', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4785', 'Total loss: 1.3804', 'for batch', 8)
('GAN loss 0.6770 ', 'GAN acc 0.6211', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4883', 'Total loss: 1.3751', 'for batch', 9)
('GAN loss 0.6745 ', 'GAN acc 0.5898', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4902', 'Total loss: 1.3750', 'for batch', 10)
('GAN loss 0.6864 ', 'GAN acc 0.5508', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4785', 'Total loss: 1.3881', 'for batch', 11)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4902', 'Total loss: 1.3909', 'for batch', 12)
('GAN loss 0.6995 ', 'GAN acc 0.4961', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.5117', 'Total loss: 1.3984', 'for batch', 13)
('GAN loss 0.6959 ', 'GAN acc 0.5273', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4590', 'Total loss: 1.3990', 'for batch', 14)
('GAN loss 0.7027 ', 'GAN acc 0.4609', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4922', 'Total loss: 1.4008', 'for batch', 15)
('GAN loss 0.7058 ', 'GAN acc 0.4492', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4902', 'Total loss: 1.4056', 'for batch', 16)
('GAN loss 0.7053 ', 'GAN acc 0.4570', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4766', 'Total loss: 1.4060', 'for batch', 17)
('GAN loss 0.6896 ', 'GAN acc 0.5352', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5195', 'Total loss: 1.3827', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56390053)
('DISCRIMINATOR_Imagem FAKE=', 0.56491697)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.102654')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6910 ', 'GAN acc 0.5391', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5059', 'Total loss: 1.3869', 'for batch', 0)
('GAN loss 0.6879 ', 'GAN acc 0.5352', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5117', 'Total loss: 1.3822', 'for batch', 1)
('GAN loss 0.6884 ', 'GAN acc 0.5742', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4648', 'Total loss: 1.3923', 'for batch', 2)
('GAN loss 0.6833 ', 'GAN acc 0.5625', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4941', 'Total loss: 1.3808', 'for batch', 3)
('GAN loss 0.6848 ', 'GAN acc 0.5664', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4727', 'Total loss: 1.3849', 'for batch', 4)
('GAN loss 0.6848 ', 'GAN acc 0.5664', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5039', 'Total loss: 1.3792', 'for batch', 5)
('GAN loss 0.6816 ', 'GAN acc 0.5859', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5195', 'Total loss: 1.3737', 'for batch', 6)
('GAN loss 0.6814 ', 'GAN acc 0.6328', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5176', 'Total loss: 1.3771', 'for batch', 7)
('GAN loss 0.6826 ', 'GAN acc 0.5977', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4902', 'Total loss: 1.3797', 'for batch', 8)
('GAN loss 0.6833 ', 'GAN acc 0.6016', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4512', 'Total loss: 1.3847', 'for batch', 9)
('GAN loss 0.6907 ', 'GAN acc 0.5273', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4922', 'Total loss: 1.3869', 'for batch', 10)
('GAN loss 0.6872 ', 'GAN acc 0.5586', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4961', 'Total loss: 1.3839', 'for batch', 11)
('GAN loss 0.6847 ', 'GAN acc 0.5391', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4805', 'Total loss: 1.3829', 'for batch', 12)
('GAN loss 0.6851 ', 'GAN acc 0.5586', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4512', 'Total loss: 1.3829', 'for batch', 13)
('GAN loss 0.6871 ', 'GAN acc 0.5898', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4766', 'Total loss: 1.3868', 'for batch', 14)
('GAN loss 0.6814 ', 'GAN acc 0.5898', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4863', 'Total loss: 1.3756', 'for batch', 15)
('GAN loss 0.6868 ', 'GAN acc 0.5391', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4961', 'Total loss: 1.3811', 'for batch', 16)
('GAN loss 0.6967 ', 'GAN acc 0.4922', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4727', 'Total loss: 1.3984', 'for batch', 17)
('GAN loss 0.6948 ', 'GAN acc 0.5273', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5098', 'Total loss: 1.3916', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55196655)
('DISCRIMINATOR_Imagem FAKE=', 0.5523594)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.594616')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6968 ', 'GAN acc 0.5117', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4902', 'Total loss: 1.3943', 'for batch', 0)
('GAN loss 0.7028 ', 'GAN acc 0.5039', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5020', 'Total loss: 1.3979', 'for batch', 1)
('GAN loss 0.6977 ', 'GAN acc 0.4531', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4883', 'Total loss: 1.3934', 'for batch', 2)
('GAN loss 0.6920 ', 'GAN acc 0.5312', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4707', 'Total loss: 1.3895', 'for batch', 3)
('GAN loss 0.6887 ', 'GAN acc 0.5195', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4277', 'Total loss: 1.3900', 'for batch', 4)
('GAN loss 0.6830 ', 'GAN acc 0.5859', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4883', 'Total loss: 1.3804', 'for batch', 5)
('GAN loss 0.6804 ', 'GAN acc 0.5938', 'Discriminator loss 0.7026', 'Discriminator accuracy 0.4512', 'Total loss: 1.3830', 'for batch', 6)
('GAN loss 0.6835 ', 'GAN acc 0.5508', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5137', 'Total loss: 1.3784', 'for batch', 7)
('GAN loss 0.6839 ', 'GAN acc 0.6094', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4902', 'Total loss: 1.3782', 'for batch', 8)
('GAN loss 0.6841 ', 'GAN acc 0.5469', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5195', 'Total loss: 1.3767', 'for batch', 9)
('GAN loss 0.6834 ', 'GAN acc 0.5898', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5078', 'Total loss: 1.3752', 'for batch', 10)
('GAN loss 0.6868 ', 'GAN acc 0.5352', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4551', 'Total loss: 1.3883', 'for batch', 11)
('GAN loss 0.6821 ', 'GAN acc 0.5859', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4980', 'Total loss: 1.3764', 'for batch', 12)
('GAN loss 0.6795 ', 'GAN acc 0.6172', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5352', 'Total loss: 1.3727', 'for batch', 13)
('GAN loss 0.6819 ', 'GAN acc 0.5938', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4785', 'Total loss: 1.3819', 'for batch', 14)
('GAN loss 0.6941 ', 'GAN acc 0.5156', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5137', 'Total loss: 1.3898', 'for batch', 15)
('GAN loss 0.7038 ', 'GAN acc 0.4375', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5020', 'Total loss: 1.3988', 'for batch', 16)
('GAN loss 0.6945 ', 'GAN acc 0.5000', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5215', 'Total loss: 1.3870', 'for batch', 17)
('GAN loss 0.7053 ', 'GAN acc 0.4219', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4629', 'Total loss: 1.4056', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54562265)
('DISCRIMINATOR_Imagem FAKE=', 0.54634756)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.087328')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7027 ', 'GAN acc 0.4531', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5273', 'Total loss: 1.3965', 'for batch', 0)
('GAN loss 0.6989 ', 'GAN acc 0.4531', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5293', 'Total loss: 1.3932', 'for batch', 1)
('GAN loss 0.7008 ', 'GAN acc 0.4297', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4688', 'Total loss: 1.3964', 'for batch', 2)
('GAN loss 0.6884 ', 'GAN acc 0.5664', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4922', 'Total loss: 1.3820', 'for batch', 3)
('GAN loss 0.6881 ', 'GAN acc 0.5469', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4609', 'Total loss: 1.3874', 'for batch', 4)
('GAN loss 0.6818 ', 'GAN acc 0.6172', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4941', 'Total loss: 1.3764', 'for batch', 5)
('GAN loss 0.6820 ', 'GAN acc 0.5781', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4805', 'Total loss: 1.3766', 'for batch', 6)
('GAN loss 0.6824 ', 'GAN acc 0.5938', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5254', 'Total loss: 1.3759', 'for batch', 7)
('GAN loss 0.6783 ', 'GAN acc 0.6172', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4980', 'Total loss: 1.3728', 'for batch', 8)
('GAN loss 0.6764 ', 'GAN acc 0.6172', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5117', 'Total loss: 1.3730', 'for batch', 9)
('GAN loss 0.6880 ', 'GAN acc 0.5625', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5039', 'Total loss: 1.3829', 'for batch', 10)
('GAN loss 0.6935 ', 'GAN acc 0.4805', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.5000', 'Total loss: 1.3913', 'for batch', 11)
('GAN loss 0.6900 ', 'GAN acc 0.5508', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5137', 'Total loss: 1.3845', 'for batch', 12)
('GAN loss 0.6959 ', 'GAN acc 0.5117', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4492', 'Total loss: 1.3976', 'for batch', 13)
('GAN loss 0.6901 ', 'GAN acc 0.5586', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4785', 'Total loss: 1.3888', 'for batch', 14)
('GAN loss 0.7086 ', 'GAN acc 0.4375', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5059', 'Total loss: 1.4057', 'for batch', 15)
('GAN loss 0.6954 ', 'GAN acc 0.5195', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5137', 'Total loss: 1.3893', 'for batch', 16)
('GAN loss 0.6994 ', 'GAN acc 0.4727', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5156', 'Total loss: 1.3926', 'for batch', 17)
('GAN loss 0.7021 ', 'GAN acc 0.4766', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5098', 'Total loss: 1.3971', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53828478)
('DISCRIMINATOR_Imagem FAKE=', 0.53857386)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.598476')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6985 ', 'GAN acc 0.4648', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4805', 'Total loss: 1.3950', 'for batch', 0)
('GAN loss 0.7010 ', 'GAN acc 0.4609', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4785', 'Total loss: 1.3977', 'for batch', 1)
('GAN loss 0.6950 ', 'GAN acc 0.5039', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5078', 'Total loss: 1.3905', 'for batch', 2)
('GAN loss 0.6997 ', 'GAN acc 0.4648', 'Discriminator loss 0.6900', 'Discriminator accuracy 0.5215', 'Total loss: 1.3897', 'for batch', 3)
('GAN loss 0.6890 ', 'GAN acc 0.5430', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4922', 'Total loss: 1.3853', 'for batch', 4)
('GAN loss 0.6852 ', 'GAN acc 0.5508', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4902', 'Total loss: 1.3811', 'for batch', 5)
('GAN loss 0.6836 ', 'GAN acc 0.5859', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4863', 'Total loss: 1.3790', 'for batch', 6)
('GAN loss 0.6790 ', 'GAN acc 0.6055', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4980', 'Total loss: 1.3725', 'for batch', 7)
('GAN loss 0.6752 ', 'GAN acc 0.6172', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5020', 'Total loss: 1.3698', 'for batch', 8)
('GAN loss 0.6782 ', 'GAN acc 0.6211', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5059', 'Total loss: 1.3741', 'for batch', 9)
('GAN loss 0.6858 ', 'GAN acc 0.5508', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4922', 'Total loss: 1.3850', 'for batch', 10)
('GAN loss 0.6846 ', 'GAN acc 0.6172', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5078', 'Total loss: 1.3753', 'for batch', 11)
('GAN loss 0.6862 ', 'GAN acc 0.5586', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4922', 'Total loss: 1.3822', 'for batch', 12)
('GAN loss 0.6868 ', 'GAN acc 0.5625', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5117', 'Total loss: 1.3791', 'for batch', 13)
('GAN loss 0.6851 ', 'GAN acc 0.5977', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5273', 'Total loss: 1.3779', 'for batch', 14)
('GAN loss 0.6937 ', 'GAN acc 0.5156', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4648', 'Total loss: 1.3902', 'for batch', 15)
('GAN loss 0.6983 ', 'GAN acc 0.4805', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4629', 'Total loss: 1.3949', 'for batch', 16)
('GAN loss 0.7060 ', 'GAN acc 0.4062', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4766', 'Total loss: 1.4033', 'for batch', 17)
('GAN loss 0.7078 ', 'GAN acc 0.4180', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4844', 'Total loss: 1.4042', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53147435)
('DISCRIMINATOR_Imagem FAKE=', 0.53195566)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.152935')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7041 ', 'GAN acc 0.4102', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5469', 'Total loss: 1.3944', 'for batch', 0)
('GAN loss 0.7035 ', 'GAN acc 0.4297', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4941', 'Total loss: 1.3979', 'for batch', 1)
('GAN loss 0.6981 ', 'GAN acc 0.4961', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4805', 'Total loss: 1.3975', 'for batch', 2)
('GAN loss 0.6959 ', 'GAN acc 0.5039', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5254', 'Total loss: 1.3873', 'for batch', 3)
('GAN loss 0.6926 ', 'GAN acc 0.5234', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5000', 'Total loss: 1.3880', 'for batch', 4)
('GAN loss 0.6910 ', 'GAN acc 0.5156', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4922', 'Total loss: 1.3863', 'for batch', 5)
('GAN loss 0.6863 ', 'GAN acc 0.5703', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5273', 'Total loss: 1.3791', 'for batch', 6)
('GAN loss 0.6832 ', 'GAN acc 0.5703', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4902', 'Total loss: 1.3793', 'for batch', 7)
('GAN loss 0.6789 ', 'GAN acc 0.6250', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4727', 'Total loss: 1.3753', 'for batch', 8)
('GAN loss 0.6733 ', 'GAN acc 0.6523', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4766', 'Total loss: 1.3723', 'for batch', 9)
('GAN loss 0.6750 ', 'GAN acc 0.6680', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5293', 'Total loss: 1.3661', 'for batch', 10)
('GAN loss 0.6845 ', 'GAN acc 0.5977', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4766', 'Total loss: 1.3821', 'for batch', 11)
('GAN loss 0.6815 ', 'GAN acc 0.5859', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4648', 'Total loss: 1.3794', 'for batch', 12)
('GAN loss 0.6853 ', 'GAN acc 0.5430', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4746', 'Total loss: 1.3827', 'for batch', 13)
('GAN loss 0.6916 ', 'GAN acc 0.5117', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3851', 'for batch', 14)
('GAN loss 0.6923 ', 'GAN acc 0.5156', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5020', 'Total loss: 1.3854', 'for batch', 15)
('GAN loss 0.6985 ', 'GAN acc 0.4648', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5195', 'Total loss: 1.3927', 'for batch', 16)
('GAN loss 0.6981 ', 'GAN acc 0.4609', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4883', 'Total loss: 1.3914', 'for batch', 17)
('GAN loss 0.7033 ', 'GAN acc 0.4844', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5020', 'Total loss: 1.3975', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52967298)
('DISCRIMINATOR_Imagem FAKE=', 0.530406)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.617995')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7016 ', 'GAN acc 0.4336', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5059', 'Total loss: 1.3948', 'for batch', 0)
('GAN loss 0.7064 ', 'GAN acc 0.4141', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5234', 'Total loss: 1.4020', 'for batch', 1)
('GAN loss 0.7040 ', 'GAN acc 0.4414', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4883', 'Total loss: 1.3980', 'for batch', 2)
('GAN loss 0.6945 ', 'GAN acc 0.5039', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4863', 'Total loss: 1.3889', 'for batch', 3)
('GAN loss 0.6944 ', 'GAN acc 0.4766', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4883', 'Total loss: 1.3908', 'for batch', 4)
('GAN loss 0.6948 ', 'GAN acc 0.5000', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4609', 'Total loss: 1.3945', 'for batch', 5)
('GAN loss 0.6912 ', 'GAN acc 0.5469', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4980', 'Total loss: 1.3839', 'for batch', 6)
('GAN loss 0.6824 ', 'GAN acc 0.5703', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5059', 'Total loss: 1.3789', 'for batch', 7)
('GAN loss 0.6890 ', 'GAN acc 0.5742', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5098', 'Total loss: 1.3800', 'for batch', 8)
('GAN loss 0.6846 ', 'GAN acc 0.5938', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4824', 'Total loss: 1.3827', 'for batch', 9)
('GAN loss 0.6741 ', 'GAN acc 0.6836', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4844', 'Total loss: 1.3698', 'for batch', 10)
('GAN loss 0.6894 ', 'GAN acc 0.5391', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4941', 'Total loss: 1.3863', 'for batch', 11)
('GAN loss 0.6819 ', 'GAN acc 0.5859', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3764', 'for batch', 12)
('GAN loss 0.6872 ', 'GAN acc 0.5664', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5117', 'Total loss: 1.3806', 'for batch', 13)
('GAN loss 0.6913 ', 'GAN acc 0.5273', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5059', 'Total loss: 1.3842', 'for batch', 14)
('GAN loss 0.7002 ', 'GAN acc 0.4648', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4980', 'Total loss: 1.3958', 'for batch', 15)
('GAN loss 0.6948 ', 'GAN acc 0.5352', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4668', 'Total loss: 1.3930', 'for batch', 16)
('GAN loss 0.7009 ', 'GAN acc 0.4453', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5117', 'Total loss: 1.3940', 'for batch', 17)
('GAN loss 0.6952 ', 'GAN acc 0.4883', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5039', 'Total loss: 1.3898', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52722657)
('DISCRIMINATOR_Imagem FAKE=', 0.52741945)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.196497')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6983 ', 'GAN acc 0.4219', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5000', 'Total loss: 1.3938', 'for batch', 0)
('GAN loss 0.7016 ', 'GAN acc 0.4492', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4922', 'Total loss: 1.3964', 'for batch', 1)
('GAN loss 0.7004 ', 'GAN acc 0.4961', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5215', 'Total loss: 1.3943', 'for batch', 2)
('GAN loss 0.6917 ', 'GAN acc 0.5312', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5332', 'Total loss: 1.3833', 'for batch', 3)
('GAN loss 0.6939 ', 'GAN acc 0.5117', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4629', 'Total loss: 1.3904', 'for batch', 4)
('GAN loss 0.6905 ', 'GAN acc 0.5664', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5078', 'Total loss: 1.3826', 'for batch', 5)
('GAN loss 0.6841 ', 'GAN acc 0.5781', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5156', 'Total loss: 1.3762', 'for batch', 6)
('GAN loss 0.6833 ', 'GAN acc 0.5781', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4961', 'Total loss: 1.3760', 'for batch', 7)
('GAN loss 0.6881 ', 'GAN acc 0.5586', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5469', 'Total loss: 1.3778', 'for batch', 8)
('GAN loss 0.6877 ', 'GAN acc 0.5625', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5156', 'Total loss: 1.3795', 'for batch', 9)
('GAN loss 0.6919 ', 'GAN acc 0.5117', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4980', 'Total loss: 1.3870', 'for batch', 10)
('GAN loss 0.6890 ', 'GAN acc 0.5547', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3823', 'for batch', 11)
('GAN loss 0.6863 ', 'GAN acc 0.5625', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5312', 'Total loss: 1.3790', 'for batch', 12)
('GAN loss 0.6902 ', 'GAN acc 0.5312', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5098', 'Total loss: 1.3835', 'for batch', 13)
('GAN loss 0.6901 ', 'GAN acc 0.4727', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5137', 'Total loss: 1.3837', 'for batch', 14)
('GAN loss 0.6968 ', 'GAN acc 0.4648', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5215', 'Total loss: 1.3901', 'for batch', 15)
('GAN loss 0.6987 ', 'GAN acc 0.4531', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4824', 'Total loss: 1.3934', 'for batch', 16)
('GAN loss 0.6949 ', 'GAN acc 0.5195', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5293', 'Total loss: 1.3858', 'for batch', 17)
('GAN loss 0.6971 ', 'GAN acc 0.4766', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4941', 'Total loss: 1.3898', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52582687)
('DISCRIMINATOR_Imagem FAKE=', 0.52624393)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.609862')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5078', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5137', 'Total loss: 1.3876', 'for batch', 0)
('GAN loss 0.7002 ', 'GAN acc 0.4727', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5039', 'Total loss: 1.3941', 'for batch', 1)
('GAN loss 0.6941 ', 'GAN acc 0.4922', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4473', 'Total loss: 1.3917', 'for batch', 2)
('GAN loss 0.6941 ', 'GAN acc 0.4648', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5273', 'Total loss: 1.3862', 'for batch', 3)
('GAN loss 0.6925 ', 'GAN acc 0.5312', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3878', 'for batch', 4)
('GAN loss 0.6866 ', 'GAN acc 0.5742', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5039', 'Total loss: 1.3775', 'for batch', 5)
('GAN loss 0.6837 ', 'GAN acc 0.6250', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4883', 'Total loss: 1.3774', 'for batch', 6)
('GAN loss 0.6831 ', 'GAN acc 0.5820', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4648', 'Total loss: 1.3814', 'for batch', 7)
('GAN loss 0.6788 ', 'GAN acc 0.6094', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5215', 'Total loss: 1.3731', 'for batch', 8)
('GAN loss 0.6878 ', 'GAN acc 0.5742', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5293', 'Total loss: 1.3806', 'for batch', 9)
('GAN loss 0.6907 ', 'GAN acc 0.5391', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5137', 'Total loss: 1.3821', 'for batch', 10)
('GAN loss 0.6866 ', 'GAN acc 0.5820', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4648', 'Total loss: 1.3841', 'for batch', 11)
('GAN loss 0.6834 ', 'GAN acc 0.6016', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5215', 'Total loss: 1.3774', 'for batch', 12)
('GAN loss 0.6920 ', 'GAN acc 0.5078', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5039', 'Total loss: 1.3850', 'for batch', 13)
('GAN loss 0.6945 ', 'GAN acc 0.4805', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5293', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.6920 ', 'GAN acc 0.5391', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4844', 'Total loss: 1.3870', 'for batch', 15)
('GAN loss 0.6977 ', 'GAN acc 0.4648', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4785', 'Total loss: 1.3941', 'for batch', 16)
('GAN loss 0.7000 ', 'GAN acc 0.4219', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4824', 'Total loss: 1.3957', 'for batch', 17)
('GAN loss 0.7006 ', 'GAN acc 0.4492', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4805', 'Total loss: 1.3951', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52272177)
('DISCRIMINATOR_Imagem FAKE=', 0.52292913)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.686429')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6979 ', 'GAN acc 0.4570', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5020', 'Total loss: 1.3921', 'for batch', 0)
('GAN loss 0.7072 ', 'GAN acc 0.3672', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4688', 'Total loss: 1.4076', 'for batch', 1)
('GAN loss 0.7051 ', 'GAN acc 0.4492', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5000', 'Total loss: 1.4005', 'for batch', 2)
('GAN loss 0.6955 ', 'GAN acc 0.4922', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4980', 'Total loss: 1.3882', 'for batch', 3)
('GAN loss 0.6969 ', 'GAN acc 0.4766', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5332', 'Total loss: 1.3906', 'for batch', 4)
('GAN loss 0.6934 ', 'GAN acc 0.4844', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4922', 'Total loss: 1.3914', 'for batch', 5)
('GAN loss 0.6878 ', 'GAN acc 0.5586', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5039', 'Total loss: 1.3824', 'for batch', 6)
('GAN loss 0.6880 ', 'GAN acc 0.5586', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4785', 'Total loss: 1.3818', 'for batch', 7)
('GAN loss 0.6844 ', 'GAN acc 0.6055', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5156', 'Total loss: 1.3761', 'for batch', 8)
('GAN loss 0.6812 ', 'GAN acc 0.6094', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4941', 'Total loss: 1.3772', 'for batch', 9)
('GAN loss 0.6870 ', 'GAN acc 0.5898', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.4883', 'Total loss: 1.3786', 'for batch', 10)
('GAN loss 0.6904 ', 'GAN acc 0.5547', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5312', 'Total loss: 1.3812', 'for batch', 11)
('GAN loss 0.6885 ', 'GAN acc 0.5547', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4766', 'Total loss: 1.3835', 'for batch', 12)
('GAN loss 0.6870 ', 'GAN acc 0.5898', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3807', 'for batch', 13)
('GAN loss 0.6857 ', 'GAN acc 0.5820', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5195', 'Total loss: 1.3793', 'for batch', 14)
('GAN loss 0.6826 ', 'GAN acc 0.6172', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4668', 'Total loss: 1.3787', 'for batch', 15)
('GAN loss 0.6877 ', 'GAN acc 0.5312', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5117', 'Total loss: 1.3794', 'for batch', 16)
('GAN loss 0.6972 ', 'GAN acc 0.4727', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4961', 'Total loss: 1.3931', 'for batch', 17)
('GAN loss 0.6956 ', 'GAN acc 0.4883', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4668', 'Total loss: 1.3925', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51761466)
('DISCRIMINATOR_Imagem FAKE=', 0.51789612)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.179891')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7024 ', 'GAN acc 0.4570', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5449', 'Total loss: 1.3949', 'for batch', 0)
('GAN loss 0.6968 ', 'GAN acc 0.5000', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4785', 'Total loss: 1.3916', 'for batch', 1)
('GAN loss 0.6932 ', 'GAN acc 0.5195', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5352', 'Total loss: 1.3873', 'for batch', 2)
('GAN loss 0.6880 ', 'GAN acc 0.5508', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4863', 'Total loss: 1.3829', 'for batch', 3)
('GAN loss 0.6908 ', 'GAN acc 0.5391', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4570', 'Total loss: 1.3874', 'for batch', 4)
('GAN loss 0.6882 ', 'GAN acc 0.5469', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4824', 'Total loss: 1.3862', 'for batch', 5)
('GAN loss 0.6881 ', 'GAN acc 0.5391', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4961', 'Total loss: 1.3852', 'for batch', 6)
('GAN loss 0.6900 ', 'GAN acc 0.5508', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5059', 'Total loss: 1.3835', 'for batch', 7)
('GAN loss 0.6859 ', 'GAN acc 0.5547', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4902', 'Total loss: 1.3811', 'for batch', 8)
('GAN loss 0.6865 ', 'GAN acc 0.5977', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5020', 'Total loss: 1.3771', 'for batch', 9)
('GAN loss 0.6875 ', 'GAN acc 0.5586', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5059', 'Total loss: 1.3828', 'for batch', 10)
('GAN loss 0.6874 ', 'GAN acc 0.5742', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4531', 'Total loss: 1.3830', 'for batch', 11)
('GAN loss 0.6858 ', 'GAN acc 0.5820', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4883', 'Total loss: 1.3814', 'for batch', 12)
('GAN loss 0.6949 ', 'GAN acc 0.4688', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5059', 'Total loss: 1.3881', 'for batch', 13)
('GAN loss 0.6937 ', 'GAN acc 0.4883', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4668', 'Total loss: 1.3899', 'for batch', 14)
('GAN loss 0.6967 ', 'GAN acc 0.4727', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4922', 'Total loss: 1.3906', 'for batch', 15)
('GAN loss 0.6990 ', 'GAN acc 0.4688', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3941', 'for batch', 16)
('GAN loss 0.7005 ', 'GAN acc 0.4375', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5000', 'Total loss: 1.3923', 'for batch', 17)
('GAN loss 0.7068 ', 'GAN acc 0.3711', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4980', 'Total loss: 1.4016', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51445031)
('DISCRIMINATOR_Imagem FAKE=', 0.51489544)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.657884')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7021 ', 'GAN acc 0.4688', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4902', 'Total loss: 1.4003', 'for batch', 0)
('GAN loss 0.7042 ', 'GAN acc 0.4023', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5195', 'Total loss: 1.3976', 'for batch', 1)
('GAN loss 0.6990 ', 'GAN acc 0.4531', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5059', 'Total loss: 1.3907', 'for batch', 2)
('GAN loss 0.6941 ', 'GAN acc 0.4883', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4961', 'Total loss: 1.3887', 'for batch', 3)
('GAN loss 0.6920 ', 'GAN acc 0.5430', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5215', 'Total loss: 1.3853', 'for batch', 4)
('GAN loss 0.6912 ', 'GAN acc 0.5039', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4902', 'Total loss: 1.3891', 'for batch', 5)
('GAN loss 0.6880 ', 'GAN acc 0.5430', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4902', 'Total loss: 1.3854', 'for batch', 6)
('GAN loss 0.6826 ', 'GAN acc 0.6172', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4395', 'Total loss: 1.3806', 'for batch', 7)
('GAN loss 0.6857 ', 'GAN acc 0.5586', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4805', 'Total loss: 1.3792', 'for batch', 8)
('GAN loss 0.6821 ', 'GAN acc 0.5547', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5078', 'Total loss: 1.3752', 'for batch', 9)
('GAN loss 0.6830 ', 'GAN acc 0.6250', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4980', 'Total loss: 1.3792', 'for batch', 10)
('GAN loss 0.6828 ', 'GAN acc 0.6211', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3759', 'for batch', 11)
('GAN loss 0.6880 ', 'GAN acc 0.5742', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4766', 'Total loss: 1.3819', 'for batch', 12)
('GAN loss 0.6906 ', 'GAN acc 0.5078', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5020', 'Total loss: 1.3838', 'for batch', 13)
('GAN loss 0.6951 ', 'GAN acc 0.5000', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5352', 'Total loss: 1.3856', 'for batch', 14)
('GAN loss 0.7016 ', 'GAN acc 0.4219', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4727', 'Total loss: 1.3946', 'for batch', 15)
('GAN loss 0.6994 ', 'GAN acc 0.4141', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4902', 'Total loss: 1.3940', 'for batch', 16)
('GAN loss 0.7035 ', 'GAN acc 0.4023', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4844', 'Total loss: 1.3981', 'for batch', 17)
('GAN loss 0.6990 ', 'GAN acc 0.4844', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4727', 'Total loss: 1.3949', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51265806)
('DISCRIMINATOR_Imagem FAKE=', 0.51271892)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.119653')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6965 ', 'GAN acc 0.4336', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4824', 'Total loss: 1.3915', 'for batch', 0)
('GAN loss 0.6985 ', 'GAN acc 0.4570', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4746', 'Total loss: 1.3920', 'for batch', 1)
('GAN loss 0.6999 ', 'GAN acc 0.4453', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4902', 'Total loss: 1.3941', 'for batch', 2)
('GAN loss 0.6971 ', 'GAN acc 0.4570', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5410', 'Total loss: 1.3882', 'for batch', 3)
('GAN loss 0.6948 ', 'GAN acc 0.4805', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5137', 'Total loss: 1.3879', 'for batch', 4)
('GAN loss 0.6897 ', 'GAN acc 0.5430', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4746', 'Total loss: 1.3866', 'for batch', 5)
('GAN loss 0.6866 ', 'GAN acc 0.6172', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3830', 'for batch', 6)
('GAN loss 0.6853 ', 'GAN acc 0.6055', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4863', 'Total loss: 1.3825', 'for batch', 7)
('GAN loss 0.6856 ', 'GAN acc 0.5977', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4844', 'Total loss: 1.3815', 'for batch', 8)
('GAN loss 0.6827 ', 'GAN acc 0.6094', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4590', 'Total loss: 1.3779', 'for batch', 9)
('GAN loss 0.6807 ', 'GAN acc 0.6328', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4883', 'Total loss: 1.3776', 'for batch', 10)
('GAN loss 0.6822 ', 'GAN acc 0.6445', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4648', 'Total loss: 1.3798', 'for batch', 11)
('GAN loss 0.6834 ', 'GAN acc 0.5938', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5117', 'Total loss: 1.3775', 'for batch', 12)
('GAN loss 0.6833 ', 'GAN acc 0.5898', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4727', 'Total loss: 1.3807', 'for batch', 13)
('GAN loss 0.6887 ', 'GAN acc 0.5352', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5215', 'Total loss: 1.3813', 'for batch', 14)
('GAN loss 0.6928 ', 'GAN acc 0.4922', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4824', 'Total loss: 1.3873', 'for batch', 15)
('GAN loss 0.6952 ', 'GAN acc 0.5117', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3894', 'for batch', 16)
('GAN loss 0.6994 ', 'GAN acc 0.4219', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5039', 'Total loss: 1.3935', 'for batch', 17)
('GAN loss 0.6997 ', 'GAN acc 0.4531', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4961', 'Total loss: 1.3926', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51273632)
('DISCRIMINATOR_Imagem FAKE=', 0.5127182)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.693312')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6979 ', 'GAN acc 0.4531', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5273', 'Total loss: 1.3889', 'for batch', 0)
('GAN loss 0.7022 ', 'GAN acc 0.4570', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3980', 'for batch', 1)
('GAN loss 0.6915 ', 'GAN acc 0.5273', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4941', 'Total loss: 1.3892', 'for batch', 2)
('GAN loss 0.6936 ', 'GAN acc 0.5195', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5352', 'Total loss: 1.3864', 'for batch', 3)
('GAN loss 0.6933 ', 'GAN acc 0.4961', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5098', 'Total loss: 1.3863', 'for batch', 4)
('GAN loss 0.6865 ', 'GAN acc 0.6055', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5137', 'Total loss: 1.3798', 'for batch', 5)
('GAN loss 0.6856 ', 'GAN acc 0.6133', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4766', 'Total loss: 1.3817', 'for batch', 6)
('GAN loss 0.6830 ', 'GAN acc 0.6328', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4609', 'Total loss: 1.3811', 'for batch', 7)
('GAN loss 0.6827 ', 'GAN acc 0.6055', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4785', 'Total loss: 1.3781', 'for batch', 8)
('GAN loss 0.6819 ', 'GAN acc 0.6367', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5195', 'Total loss: 1.3742', 'for batch', 9)
('GAN loss 0.6831 ', 'GAN acc 0.6094', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4941', 'Total loss: 1.3766', 'for batch', 10)
('GAN loss 0.6841 ', 'GAN acc 0.6133', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4824', 'Total loss: 1.3793', 'for batch', 11)
('GAN loss 0.6921 ', 'GAN acc 0.4922', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4746', 'Total loss: 1.3874', 'for batch', 12)
('GAN loss 0.6877 ', 'GAN acc 0.5625', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5039', 'Total loss: 1.3798', 'for batch', 13)
('GAN loss 0.6891 ', 'GAN acc 0.5352', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4707', 'Total loss: 1.3834', 'for batch', 14)
('GAN loss 0.6901 ', 'GAN acc 0.5508', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5059', 'Total loss: 1.3854', 'for batch', 15)
('GAN loss 0.6949 ', 'GAN acc 0.5039', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4961', 'Total loss: 1.3891', 'for batch', 16)
('GAN loss 0.6993 ', 'GAN acc 0.4297', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4863', 'Total loss: 1.3933', 'for batch', 17)
('GAN loss 0.7000 ', 'GAN acc 0.4688', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5312', 'Total loss: 1.3937', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51024652)
('DISCRIMINATOR_Imagem FAKE=', 0.51061195)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.275917')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7008 ', 'GAN acc 0.4336', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4824', 'Total loss: 1.3965', 'for batch', 0)
('GAN loss 0.7084 ', 'GAN acc 0.3594', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5137', 'Total loss: 1.4017', 'for batch', 1)
('GAN loss 0.6971 ', 'GAN acc 0.4766', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5508', 'Total loss: 1.3887', 'for batch', 2)
('GAN loss 0.6981 ', 'GAN acc 0.4219', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5371', 'Total loss: 1.3911', 'for batch', 3)
('GAN loss 0.6937 ', 'GAN acc 0.5234', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5000', 'Total loss: 1.3894', 'for batch', 4)
('GAN loss 0.6945 ', 'GAN acc 0.4961', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5059', 'Total loss: 1.3873', 'for batch', 5)
('GAN loss 0.6893 ', 'GAN acc 0.5430', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4980', 'Total loss: 1.3823', 'for batch', 6)
('GAN loss 0.6855 ', 'GAN acc 0.6133', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5469', 'Total loss: 1.3770', 'for batch', 7)
('GAN loss 0.6873 ', 'GAN acc 0.5586', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5117', 'Total loss: 1.3810', 'for batch', 8)
('GAN loss 0.6887 ', 'GAN acc 0.5352', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5312', 'Total loss: 1.3803', 'for batch', 9)
('GAN loss 0.6845 ', 'GAN acc 0.5820', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4980', 'Total loss: 1.3791', 'for batch', 10)
('GAN loss 0.6822 ', 'GAN acc 0.6094', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5254', 'Total loss: 1.3735', 'for batch', 11)
('GAN loss 0.6850 ', 'GAN acc 0.6211', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4922', 'Total loss: 1.3789', 'for batch', 12)
('GAN loss 0.6857 ', 'GAN acc 0.6055', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4941', 'Total loss: 1.3791', 'for batch', 13)
('GAN loss 0.6927 ', 'GAN acc 0.5039', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5156', 'Total loss: 1.3858', 'for batch', 14)
('GAN loss 0.6927 ', 'GAN acc 0.5078', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3858', 'for batch', 15)
('GAN loss 0.7021 ', 'GAN acc 0.3906', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4766', 'Total loss: 1.3962', 'for batch', 16)
('GAN loss 0.7046 ', 'GAN acc 0.4062', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4902', 'Total loss: 1.3988', 'for batch', 17)
('GAN loss 0.7018 ', 'GAN acc 0.4492', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4727', 'Total loss: 1.3956', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50918269)
('DISCRIMINATOR_Imagem FAKE=', 0.50947535)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.626618')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7020 ', 'GAN acc 0.3984', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5566', 'Total loss: 1.3922', 'for batch', 0)
('GAN loss 0.7014 ', 'GAN acc 0.4297', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4648', 'Total loss: 1.3964', 'for batch', 1)
('GAN loss 0.6965 ', 'GAN acc 0.4375', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5527', 'Total loss: 1.3887', 'for batch', 2)
('GAN loss 0.6923 ', 'GAN acc 0.5234', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5039', 'Total loss: 1.3863', 'for batch', 3)
('GAN loss 0.6983 ', 'GAN acc 0.4492', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4863', 'Total loss: 1.3942', 'for batch', 4)
('GAN loss 0.6927 ', 'GAN acc 0.5117', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4590', 'Total loss: 1.3888', 'for batch', 5)
('GAN loss 0.6893 ', 'GAN acc 0.5898', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5254', 'Total loss: 1.3819', 'for batch', 6)
('GAN loss 0.6916 ', 'GAN acc 0.5234', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5137', 'Total loss: 1.3850', 'for batch', 7)
('GAN loss 0.6906 ', 'GAN acc 0.5430', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5117', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6896 ', 'GAN acc 0.5820', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4746', 'Total loss: 1.3848', 'for batch', 9)
('GAN loss 0.6917 ', 'GAN acc 0.5234', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5098', 'Total loss: 1.3830', 'for batch', 10)
('GAN loss 0.6860 ', 'GAN acc 0.5781', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4609', 'Total loss: 1.3804', 'for batch', 11)
('GAN loss 0.6882 ', 'GAN acc 0.5586', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5137', 'Total loss: 1.3814', 'for batch', 12)
('GAN loss 0.6883 ', 'GAN acc 0.5898', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4980', 'Total loss: 1.3812', 'for batch', 13)
('GAN loss 0.6920 ', 'GAN acc 0.5234', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4902', 'Total loss: 1.3860', 'for batch', 14)
('GAN loss 0.6949 ', 'GAN acc 0.4922', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5176', 'Total loss: 1.3877', 'for batch', 15)
('GAN loss 0.6906 ', 'GAN acc 0.5430', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5254', 'Total loss: 1.3850', 'for batch', 16)
('GAN loss 0.6935 ', 'GAN acc 0.4961', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4902', 'Total loss: 1.3864', 'for batch', 17)
('GAN loss 0.6994 ', 'GAN acc 0.4141', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5098', 'Total loss: 1.3938', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51034707)
('DISCRIMINATOR_Imagem FAKE=', 0.51031369)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.157865')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6922 ', 'GAN acc 0.5117', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4961', 'Total loss: 1.3867', 'for batch', 0)
('GAN loss 0.6999 ', 'GAN acc 0.4375', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5410', 'Total loss: 1.3929', 'for batch', 1)
('GAN loss 0.6998 ', 'GAN acc 0.4219', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4805', 'Total loss: 1.3961', 'for batch', 2)
('GAN loss 0.6984 ', 'GAN acc 0.4609', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4629', 'Total loss: 1.3965', 'for batch', 3)
('GAN loss 0.6939 ', 'GAN acc 0.4688', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5156', 'Total loss: 1.3880', 'for batch', 4)
('GAN loss 0.6951 ', 'GAN acc 0.4570', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5078', 'Total loss: 1.3890', 'for batch', 5)
('GAN loss 0.6837 ', 'GAN acc 0.6094', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4785', 'Total loss: 1.3771', 'for batch', 6)
('GAN loss 0.6830 ', 'GAN acc 0.6055', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4980', 'Total loss: 1.3772', 'for batch', 7)
('GAN loss 0.6835 ', 'GAN acc 0.6172', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4746', 'Total loss: 1.3774', 'for batch', 8)
('GAN loss 0.6807 ', 'GAN acc 0.6328', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4980', 'Total loss: 1.3748', 'for batch', 9)
('GAN loss 0.6824 ', 'GAN acc 0.6328', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5195', 'Total loss: 1.3768', 'for batch', 10)
('GAN loss 0.6853 ', 'GAN acc 0.6055', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4941', 'Total loss: 1.3796', 'for batch', 11)
('GAN loss 0.6917 ', 'GAN acc 0.5117', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4707', 'Total loss: 1.3880', 'for batch', 12)
('GAN loss 0.6960 ', 'GAN acc 0.4727', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4844', 'Total loss: 1.3915', 'for batch', 13)
('GAN loss 0.6985 ', 'GAN acc 0.4727', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4805', 'Total loss: 1.3953', 'for batch', 14)
('GAN loss 0.7070 ', 'GAN acc 0.3945', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5137', 'Total loss: 1.3994', 'for batch', 15)
('GAN loss 0.7075 ', 'GAN acc 0.3711', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4590', 'Total loss: 1.4026', 'for batch', 16)
('GAN loss 0.7098 ', 'GAN acc 0.3086', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5215', 'Total loss: 1.4052', 'for batch', 17)
('GAN loss 0.7062 ', 'GAN acc 0.3945', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5254', 'Total loss: 1.3979', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50562012)
('DISCRIMINATOR_Imagem FAKE=', 0.50569999)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.681715')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7033 ', 'GAN acc 0.4336', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5137', 'Total loss: 1.3966', 'for batch', 0)
('GAN loss 0.7032 ', 'GAN acc 0.4141', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4727', 'Total loss: 1.3998', 'for batch', 1)
('GAN loss 0.6965 ', 'GAN acc 0.4961', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4609', 'Total loss: 1.3939', 'for batch', 2)
('GAN loss 0.6937 ', 'GAN acc 0.4805', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4883', 'Total loss: 1.3905', 'for batch', 3)
('GAN loss 0.6899 ', 'GAN acc 0.5586', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4922', 'Total loss: 1.3849', 'for batch', 4)
('GAN loss 0.6864 ', 'GAN acc 0.5586', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.4980', 'Total loss: 1.3785', 'for batch', 5)
('GAN loss 0.6819 ', 'GAN acc 0.6328', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5078', 'Total loss: 1.3746', 'for batch', 6)
('GAN loss 0.6765 ', 'GAN acc 0.6562', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4844', 'Total loss: 1.3694', 'for batch', 7)
('GAN loss 0.6820 ', 'GAN acc 0.6367', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4590', 'Total loss: 1.3786', 'for batch', 8)
('GAN loss 0.6827 ', 'GAN acc 0.6641', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4707', 'Total loss: 1.3765', 'for batch', 9)
('GAN loss 0.6830 ', 'GAN acc 0.6367', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5195', 'Total loss: 1.3743', 'for batch', 10)
('GAN loss 0.6859 ', 'GAN acc 0.5977', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4902', 'Total loss: 1.3814', 'for batch', 11)
('GAN loss 0.6810 ', 'GAN acc 0.6406', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4902', 'Total loss: 1.3764', 'for batch', 12)
('GAN loss 0.6883 ', 'GAN acc 0.5312', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5176', 'Total loss: 1.3801', 'for batch', 13)
('GAN loss 0.6889 ', 'GAN acc 0.5586', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5059', 'Total loss: 1.3806', 'for batch', 14)
('GAN loss 0.6927 ', 'GAN acc 0.5156', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5156', 'Total loss: 1.3847', 'for batch', 15)
('GAN loss 0.6981 ', 'GAN acc 0.4492', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3919', 'for batch', 16)
('GAN loss 0.7056 ', 'GAN acc 0.3633', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5137', 'Total loss: 1.3993', 'for batch', 17)
('GAN loss 0.7051 ', 'GAN acc 0.3867', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4824', 'Total loss: 1.4007', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50559723)
('DISCRIMINATOR_Imagem FAKE=', 0.50559884)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.154691')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7075 ', 'GAN acc 0.3477', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5000', 'Total loss: 1.3995', 'for batch', 0)
('GAN loss 0.7089 ', 'GAN acc 0.3438', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4844', 'Total loss: 1.4047', 'for batch', 1)
('GAN loss 0.7029 ', 'GAN acc 0.3828', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5117', 'Total loss: 1.3976', 'for batch', 2)
('GAN loss 0.6973 ', 'GAN acc 0.4492', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3918', 'for batch', 3)
('GAN loss 0.7004 ', 'GAN acc 0.3906', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5137', 'Total loss: 1.3955', 'for batch', 4)
('GAN loss 0.6916 ', 'GAN acc 0.5273', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4746', 'Total loss: 1.3874', 'for batch', 5)
('GAN loss 0.6907 ', 'GAN acc 0.5508', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4766', 'Total loss: 1.3873', 'for batch', 6)
('GAN loss 0.6869 ', 'GAN acc 0.5586', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4980', 'Total loss: 1.3797', 'for batch', 7)
('GAN loss 0.6854 ', 'GAN acc 0.5938', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4941', 'Total loss: 1.3786', 'for batch', 8)
('GAN loss 0.6817 ', 'GAN acc 0.6250', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5586', 'Total loss: 1.3727', 'for batch', 9)
('GAN loss 0.6821 ', 'GAN acc 0.6289', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5176', 'Total loss: 1.3748', 'for batch', 10)
('GAN loss 0.6847 ', 'GAN acc 0.5938', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4824', 'Total loss: 1.3819', 'for batch', 11)
('GAN loss 0.6868 ', 'GAN acc 0.5625', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4980', 'Total loss: 1.3794', 'for batch', 12)
('GAN loss 0.6904 ', 'GAN acc 0.5586', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.4922', 'Total loss: 1.3828', 'for batch', 13)
('GAN loss 0.6913 ', 'GAN acc 0.5391', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5000', 'Total loss: 1.3853', 'for batch', 14)
('GAN loss 0.6891 ', 'GAN acc 0.5352', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4941', 'Total loss: 1.3823', 'for batch', 15)
('GAN loss 0.6919 ', 'GAN acc 0.5273', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4980', 'Total loss: 1.3880', 'for batch', 16)
('GAN loss 0.6984 ', 'GAN acc 0.4570', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4746', 'Total loss: 1.3941', 'for batch', 17)
('GAN loss 0.6965 ', 'GAN acc 0.4688', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4922', 'Total loss: 1.3899', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50626826)
('DISCRIMINATOR_Imagem FAKE=', 0.50681603)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.640857')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7040 ', 'GAN acc 0.3789', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4844', 'Total loss: 1.3991', 'for batch', 0)
('GAN loss 0.7003 ', 'GAN acc 0.4609', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4766', 'Total loss: 1.3933', 'for batch', 1)
('GAN loss 0.6982 ', 'GAN acc 0.4531', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4414', 'Total loss: 1.3951', 'for batch', 2)
('GAN loss 0.6967 ', 'GAN acc 0.4297', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5293', 'Total loss: 1.3894', 'for batch', 3)
('GAN loss 0.6946 ', 'GAN acc 0.5000', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4902', 'Total loss: 1.3886', 'for batch', 4)
('GAN loss 0.6960 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4902', 'Total loss: 1.3915', 'for batch', 5)
('GAN loss 0.6879 ', 'GAN acc 0.5898', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4609', 'Total loss: 1.3852', 'for batch', 6)
('GAN loss 0.6859 ', 'GAN acc 0.6055', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5215', 'Total loss: 1.3762', 'for batch', 7)
('GAN loss 0.6902 ', 'GAN acc 0.5195', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5137', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6884 ', 'GAN acc 0.5547', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4863', 'Total loss: 1.3825', 'for batch', 9)
('GAN loss 0.6856 ', 'GAN acc 0.5898', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4902', 'Total loss: 1.3788', 'for batch', 10)
('GAN loss 0.6863 ', 'GAN acc 0.5781', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4824', 'Total loss: 1.3811', 'for batch', 11)
('GAN loss 0.6871 ', 'GAN acc 0.5703', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5117', 'Total loss: 1.3792', 'for batch', 12)
('GAN loss 0.6848 ', 'GAN acc 0.6250', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4922', 'Total loss: 1.3781', 'for batch', 13)
('GAN loss 0.6854 ', 'GAN acc 0.5898', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5391', 'Total loss: 1.3763', 'for batch', 14)
('GAN loss 0.6889 ', 'GAN acc 0.5547', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4590', 'Total loss: 1.3880', 'for batch', 15)
('GAN loss 0.6944 ', 'GAN acc 0.4766', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4980', 'Total loss: 1.3873', 'for batch', 16)
('GAN loss 0.7007 ', 'GAN acc 0.4219', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4551', 'Total loss: 1.3979', 'for batch', 17)
('GAN loss 0.6997 ', 'GAN acc 0.4492', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5371', 'Total loss: 1.3931', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50647628)
('DISCRIMINATOR_Imagem FAKE=', 0.50655609)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.192573')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7016 ', 'GAN acc 0.4375', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4883', 'Total loss: 1.3954', 'for batch', 0)
('GAN loss 0.7020 ', 'GAN acc 0.3945', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4902', 'Total loss: 1.3954', 'for batch', 1)
('GAN loss 0.7000 ', 'GAN acc 0.4297', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3945', 'for batch', 2)
('GAN loss 0.6978 ', 'GAN acc 0.4648', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5000', 'Total loss: 1.3927', 'for batch', 3)
('GAN loss 0.6973 ', 'GAN acc 0.4375', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4902', 'Total loss: 1.3919', 'for batch', 4)
('GAN loss 0.6959 ', 'GAN acc 0.4648', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5059', 'Total loss: 1.3889', 'for batch', 5)
('GAN loss 0.6932 ', 'GAN acc 0.5195', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4746', 'Total loss: 1.3879', 'for batch', 6)
('GAN loss 0.6920 ', 'GAN acc 0.5195', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5215', 'Total loss: 1.3847', 'for batch', 7)
('GAN loss 0.6887 ', 'GAN acc 0.5703', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5059', 'Total loss: 1.3812', 'for batch', 8)
('GAN loss 0.6882 ', 'GAN acc 0.5781', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3830', 'for batch', 9)
('GAN loss 0.6882 ', 'GAN acc 0.5820', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5332', 'Total loss: 1.3812', 'for batch', 10)
('GAN loss 0.6868 ', 'GAN acc 0.5859', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5000', 'Total loss: 1.3803', 'for batch', 11)
('GAN loss 0.6866 ', 'GAN acc 0.5703', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5098', 'Total loss: 1.3798', 'for batch', 12)
('GAN loss 0.6912 ', 'GAN acc 0.5352', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4961', 'Total loss: 1.3834', 'for batch', 13)
('GAN loss 0.6879 ', 'GAN acc 0.5391', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4883', 'Total loss: 1.3824', 'for batch', 14)
('GAN loss 0.6968 ', 'GAN acc 0.4727', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4863', 'Total loss: 1.3909', 'for batch', 15)
('GAN loss 0.6954 ', 'GAN acc 0.4961', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4688', 'Total loss: 1.3914', 'for batch', 16)
('GAN loss 0.7022 ', 'GAN acc 0.4141', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5156', 'Total loss: 1.3974', 'for batch', 17)
('GAN loss 0.7046 ', 'GAN acc 0.3516', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4902', 'Total loss: 1.3973', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50296175)
('DISCRIMINATOR_Imagem FAKE=', 0.50324821)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.645298')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7067 ', 'GAN acc 0.3281', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4863', 'Total loss: 1.3999', 'for batch', 0)
('GAN loss 0.7092 ', 'GAN acc 0.3281', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4766', 'Total loss: 1.4041', 'for batch', 1)
('GAN loss 0.7046 ', 'GAN acc 0.3555', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4844', 'Total loss: 1.4000', 'for batch', 2)
('GAN loss 0.7030 ', 'GAN acc 0.3438', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5273', 'Total loss: 1.3951', 'for batch', 3)
('GAN loss 0.7004 ', 'GAN acc 0.4219', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5098', 'Total loss: 1.3925', 'for batch', 4)
('GAN loss 0.6895 ', 'GAN acc 0.5664', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5039', 'Total loss: 1.3832', 'for batch', 5)
('GAN loss 0.6942 ', 'GAN acc 0.5039', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5391', 'Total loss: 1.3858', 'for batch', 6)
('GAN loss 0.6873 ', 'GAN acc 0.5977', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5117', 'Total loss: 1.3791', 'for batch', 7)
('GAN loss 0.6858 ', 'GAN acc 0.6055', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4805', 'Total loss: 1.3808', 'for batch', 8)
('GAN loss 0.6844 ', 'GAN acc 0.6055', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4863', 'Total loss: 1.3784', 'for batch', 9)
('GAN loss 0.6830 ', 'GAN acc 0.6250', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4805', 'Total loss: 1.3763', 'for batch', 10)
('GAN loss 0.6850 ', 'GAN acc 0.6328', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5195', 'Total loss: 1.3776', 'for batch', 11)
('GAN loss 0.6796 ', 'GAN acc 0.6641', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4922', 'Total loss: 1.3732', 'for batch', 12)
('GAN loss 0.6821 ', 'GAN acc 0.6914', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5020', 'Total loss: 1.3767', 'for batch', 13)
('GAN loss 0.6797 ', 'GAN acc 0.6992', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4922', 'Total loss: 1.3742', 'for batch', 14)
('GAN loss 0.6852 ', 'GAN acc 0.6016', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4824', 'Total loss: 1.3805', 'for batch', 15)
('GAN loss 0.6903 ', 'GAN acc 0.5508', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3848', 'for batch', 16)
('GAN loss 0.6953 ', 'GAN acc 0.4727', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5078', 'Total loss: 1.3909', 'for batch', 17)
('GAN loss 0.6986 ', 'GAN acc 0.4570', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5176', 'Total loss: 1.3915', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50601029)
('DISCRIMINATOR_Imagem FAKE=', 0.50609738)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.227966')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7015 ', 'GAN acc 0.4023', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4961', 'Total loss: 1.3944', 'for batch', 0)
('GAN loss 0.7028 ', 'GAN acc 0.3750', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5137', 'Total loss: 1.3940', 'for batch', 1)
('GAN loss 0.7033 ', 'GAN acc 0.3672', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5059', 'Total loss: 1.3965', 'for batch', 2)
('GAN loss 0.7044 ', 'GAN acc 0.3750', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5117', 'Total loss: 1.3974', 'for batch', 3)
('GAN loss 0.7044 ', 'GAN acc 0.3711', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5098', 'Total loss: 1.3986', 'for batch', 4)
('GAN loss 0.6978 ', 'GAN acc 0.4023', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3909', 'for batch', 5)
('GAN loss 0.6997 ', 'GAN acc 0.4414', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4707', 'Total loss: 1.3953', 'for batch', 6)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5863', 'for batch', 2)
('GAN loss 0.8757 ', 'GAN acc 0.3984', 'Discriminator loss 0.7499', 'Discriminator accuracy 0.5254', 'Total loss: 1.6255', 'for batch', 3)
('GAN loss 0.8256 ', 'GAN acc 0.3828', 'Discriminator loss 0.7348', 'Discriminator accuracy 0.5039', 'Total loss: 1.5605', 'for batch', 4)
('GAN loss 0.7917 ', 'GAN acc 0.4180', 'Discriminator loss 0.7277', 'Discriminator accuracy 0.5273', 'Total loss: 1.5194', 'for batch', 5)
('GAN loss 0.7780 ', 'GAN acc 0.4414', 'Discriminator loss 0.6808', 'Discriminator accuracy 0.5898', 'Total loss: 1.4588', 'for batch', 6)
('GAN loss 0.8969 ', 'GAN acc 0.3164', 'Discriminator loss 0.6817', 'Discriminator accuracy 0.5918', 'Total loss: 1.5786', 'for batch', 7)
('GAN loss 0.9182 ', 'GAN acc 0.2852', 'Discriminator loss 0.6824', 'Discriminator accuracy 0.5723', 'Total loss: 1.6006', 'for batch', 8)
('GAN loss 0.9085 ', 'GAN acc 0.3164', 'Discriminator loss 0.7402', 'Discriminator accuracy 0.5137', 'Total loss: 1.6486', 'for batch', 9)
('GAN loss 0.9769 ', 'GAN acc 0.2461', 'Discriminator loss 0.6837', 'Discriminator accuracy 0.5957', 'Total loss: 1.6606', 'for batch', 10)
('GAN loss 0.9846 ', 'GAN acc 0.2461', 'Discriminator loss 0.6788', 'Discriminator accuracy 0.5938', 'Total loss: 1.6635', 'for batch', 11)
('GAN loss 0.9158 ', 'GAN acc 0.2891', 'Discriminator loss 0.6027', 'Discriminator accuracy 0.6895', 'Total loss: 1.5185', 'for batch', 12)
('GAN loss 0.9513 ', 'GAN acc 0.2266', 'Discriminator loss 0.5863', 'Discriminator accuracy 0.7422', 'Total loss: 1.5375', 'for batch', 13)
('GAN loss 0.9661 ', 'GAN acc 0.2422', 'Discriminator loss 0.5787', 'Discriminator accuracy 0.7344', 'Total loss: 1.5448', 'for batch', 14)
('GAN loss 1.0411 ', 'GAN acc 0.1914', 'Discriminator loss 0.5755', 'Discriminator accuracy 0.7402', 'Total loss: 1.6167', 'for batch', 15)
('GAN loss 1.0704 ', 'GAN acc 0.1914', 'Discriminator loss 0.5908', 'Discriminator accuracy 0.7188', 'Total loss: 1.6612', 'for batch', 16)
('GAN loss 1.1261 ', 'GAN acc 0.1797', 'Discriminator loss 0.5811', 'Discriminator accuracy 0.7129', 'Total loss: 1.7072', 'for batch', 17)
('GAN loss 1.1980 ', 'GAN acc 0.1797', 'Discriminator loss 0.5977', 'Discriminator accuracy 0.6836', 'Total loss: 1.7957', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.81063604)
('DISCRIMINATOR_Imagem FAKE=', 0.66230482)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:44.944549')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2048 ', 'GAN acc 0.1758', 'Discriminator loss 0.6162', 'Discriminator accuracy 0.6836', 'Total loss: 1.8210', 'for batch', 0)
('GAN loss 1.2225 ', 'GAN acc 0.1758', 'Discriminator loss 0.6144', 'Discriminator accuracy 0.6309', 'Total loss: 1.8369', 'for batch', 1)
('GAN loss 1.2598 ', 'GAN acc 0.1406', 'Discriminator loss 0.5833', 'Discriminator accuracy 0.7031', 'Total loss: 1.8432', 'for batch', 2)
('GAN loss 1.1169 ', 'GAN acc 0.2188', 'Discriminator loss 0.5898', 'Discriminator accuracy 0.6797', 'Total loss: 1.7067', 'for batch', 3)
('GAN loss 1.1829 ', 'GAN acc 0.2500', 'Discriminator loss 0.6231', 'Discriminator accuracy 0.6660', 'Total loss: 1.8060', 'for batch', 4)
('GAN loss 1.2291 ', 'GAN acc 0.1875', 'Discriminator loss 0.6448', 'Discriminator accuracy 0.6113', 'Total loss: 1.8739', 'for batch', 5)
('GAN loss 1.2904 ', 'GAN acc 0.1484', 'Discriminator loss 0.6296', 'Discriminator accuracy 0.6348', 'Total loss: 1.9200', 'for batch', 6)
('GAN loss 1.2424 ', 'GAN acc 0.1836', 'Discriminator loss 0.6310', 'Discriminator accuracy 0.5996', 'Total loss: 1.8734', 'for batch', 7)
('GAN loss 1.1524 ', 'GAN acc 0.2188', 'Discriminator loss 0.5887', 'Discriminator accuracy 0.6562', 'Total loss: 1.7411', 'for batch', 8)
('GAN loss 1.2925 ', 'GAN acc 0.1758', 'Discriminator loss 0.6378', 'Discriminator accuracy 0.6211', 'Total loss: 1.9303', 'for batch', 9)
('GAN loss 1.3263 ', 'GAN acc 0.1562', 'Discriminator loss 0.6150', 'Discriminator accuracy 0.6406', 'Total loss: 1.9413', 'for batch', 10)
('GAN loss 1.2271 ', 'GAN acc 0.2227', 'Discriminator loss 0.6437', 'Discriminator accuracy 0.5918', 'Total loss: 1.8708', 'for batch', 11)
('GAN loss 1.2445 ', 'GAN acc 0.1758', 'Discriminator loss 0.6482', 'Discriminator accuracy 0.5645', 'Total loss: 1.8928', 'for batch', 12)
('GAN loss 1.3097 ', 'GAN acc 0.1250', 'Discriminator loss 0.6144', 'Discriminator accuracy 0.6172', 'Total loss: 1.9241', 'for batch', 13)
('GAN loss 1.1240 ', 'GAN acc 0.2266', 'Discriminator loss 0.6021', 'Discriminator accuracy 0.6055', 'Total loss: 1.7261', 'for batch', 14)
('GAN loss 1.1673 ', 'GAN acc 0.1914', 'Discriminator loss 0.6349', 'Discriminator accuracy 0.6328', 'Total loss: 1.8022', 'for batch', 15)
('GAN loss 1.2614 ', 'GAN acc 0.1484', 'Discriminator loss 0.6209', 'Discriminator accuracy 0.6250', 'Total loss: 1.8823', 'for batch', 16)
('GAN loss 1.1025 ', 'GAN acc 0.2031', 'Discriminator loss 0.6389', 'Discriminator accuracy 0.5684', 'Total loss: 1.7414', 'for batch', 17)
('GAN loss 1.0084 ', 'GAN acc 0.2383', 'Discriminator loss 0.6239', 'Discriminator accuracy 0.6113', 'Total loss: 1.6323', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.80454093)
('DISCRIMINATOR_Imagem FAKE=', 0.78151757)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.247114')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.0395 ', 'GAN acc 0.2266', 'Discriminator loss 0.6723', 'Discriminator accuracy 0.5723', 'Total loss: 1.7119', 'for batch', 0)
('GAN loss 1.0261 ', 'GAN acc 0.2148', 'Discriminator loss 0.6520', 'Discriminator accuracy 0.5898', 'Total loss: 1.6781', 'for batch', 1)
('GAN loss 0.9556 ', 'GAN acc 0.2734', 'Discriminator loss 0.6432', 'Discriminator accuracy 0.6113', 'Total loss: 1.5989', 'for batch', 2)
('GAN loss 0.8538 ', 'GAN acc 0.3438', 'Discriminator loss 0.6580', 'Discriminator accuracy 0.5723', 'Total loss: 1.5117', 'for batch', 3)
('GAN loss 0.8587 ', 'GAN acc 0.4258', 'Discriminator loss 0.6511', 'Discriminator accuracy 0.6035', 'Total loss: 1.5098', 'for batch', 4)
('GAN loss 0.8066 ', 'GAN acc 0.4023', 'Discriminator loss 0.6631', 'Discriminator accuracy 0.5840', 'Total loss: 1.4697', 'for batch', 5)
('GAN loss 0.7616 ', 'GAN acc 0.4961', 'Discriminator loss 0.6514', 'Discriminator accuracy 0.5977', 'Total loss: 1.4129', 'for batch', 6)
('GAN loss 0.8286 ', 'GAN acc 0.4102', 'Discriminator loss 0.6608', 'Discriminator accuracy 0.6133', 'Total loss: 1.4894', 'for batch', 7)
('GAN loss 0.8260 ', 'GAN acc 0.4023', 'Discriminator loss 0.6430', 'Discriminator accuracy 0.6230', 'Total loss: 1.4690', 'for batch', 8)
('GAN loss 0.7816 ', 'GAN acc 0.4727', 'Discriminator loss 0.6736', 'Discriminator accuracy 0.5645', 'Total loss: 1.4552', 'for batch', 9)
('GAN loss 0.7771 ', 'GAN acc 0.4102', 'Discriminator loss 0.6701', 'Discriminator accuracy 0.5996', 'Total loss: 1.4472', 'for batch', 10)
('GAN loss 0.7118 ', 'GAN acc 0.5312', 'Discriminator loss 0.6846', 'Discriminator accuracy 0.5684', 'Total loss: 1.3965', 'for batch', 11)
('GAN loss 0.7294 ', 'GAN acc 0.5352', 'Discriminator loss 0.6835', 'Discriminator accuracy 0.5625', 'Total loss: 1.4129', 'for batch', 12)
('GAN loss 0.7264 ', 'GAN acc 0.4805', 'Discriminator loss 0.6644', 'Discriminator accuracy 0.5879', 'Total loss: 1.3908', 'for batch', 13)
('GAN loss 0.7066 ', 'GAN acc 0.5078', 'Discriminator loss 0.6727', 'Discriminator accuracy 0.5801', 'Total loss: 1.3793', 'for batch', 14)
('GAN loss 0.7077 ', 'GAN acc 0.5234', 'Discriminator loss 0.6749', 'Discriminator accuracy 0.5664', 'Total loss: 1.3826', 'for batch', 15)
('GAN loss 0.7250 ', 'GAN acc 0.4844', 'Discriminator loss 0.6620', 'Discriminator accuracy 0.5996', 'Total loss: 1.3871', 'for batch', 16)
('GAN loss 0.7748 ', 'GAN acc 0.4219', 'Discriminator loss 0.6720', 'Discriminator accuracy 0.6016', 'Total loss: 1.4468', 'for batch', 17)
('GAN loss 0.7224 ', 'GAN acc 0.5430', 'Discriminator loss 0.6655', 'Discriminator accuracy 0.5840', 'Total loss: 1.3879', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.81588674)
('DISCRIMINATOR_Imagem FAKE=', 0.76329094)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.932772')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6968 ', 'GAN acc 0.5664', 'Discriminator loss 0.6815', 'Discriminator accuracy 0.5801', 'Total loss: 1.3783', 'for batch', 0)
('GAN loss 0.6915 ', 'GAN acc 0.5430', 'Discriminator loss 0.6824', 'Discriminator accuracy 0.5898', 'Total loss: 1.3740', 'for batch', 1)
('GAN loss 0.7130 ', 'GAN acc 0.5430', 'Discriminator loss 0.6801', 'Discriminator accuracy 0.5684', 'Total loss: 1.3931', 'for batch', 2)
('GAN loss 0.6628 ', 'GAN acc 0.6016', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5371', 'Total loss: 1.3598', 'for batch', 3)
('GAN loss 0.6645 ', 'GAN acc 0.5977', 'Discriminator loss 0.6823', 'Discriminator accuracy 0.5723', 'Total loss: 1.3467', 'for batch', 4)
('GAN loss 0.6476 ', 'GAN acc 0.6289', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5469', 'Total loss: 1.3401', 'for batch', 5)
('GAN loss 0.6656 ', 'GAN acc 0.6484', 'Discriminator loss 0.6862', 'Discriminator accuracy 0.5547', 'Total loss: 1.3518', 'for batch', 6)
('GAN loss 0.6540 ', 'GAN acc 0.6406', 'Discriminator loss 0.6901', 'Discriminator accuracy 0.5391', 'Total loss: 1.3441', 'for batch', 7)
('GAN loss 0.6727 ', 'GAN acc 0.5820', 'Discriminator loss 0.6766', 'Discriminator accuracy 0.5234', 'Total loss: 1.3492', 'for batch', 8)
('GAN loss 0.6757 ', 'GAN acc 0.5898', 'Discriminator loss 0.6864', 'Discriminator accuracy 0.5332', 'Total loss: 1.3621', 'for batch', 9)
('GAN loss 0.6852 ', 'GAN acc 0.5586', 'Discriminator loss 0.6806', 'Discriminator accuracy 0.5527', 'Total loss: 1.3658', 'for batch', 10)
('GAN loss 0.7051 ', 'GAN acc 0.5859', 'Discriminator loss 0.6592', 'Discriminator accuracy 0.5977', 'Total loss: 1.3642', 'for batch', 11)
('GAN loss 0.7025 ', 'GAN acc 0.5781', 'Discriminator loss 0.6751', 'Discriminator accuracy 0.5645', 'Total loss: 1.3775', 'for batch', 12)
('GAN loss 0.7540 ', 'GAN acc 0.4219', 'Discriminator loss 0.6833', 'Discriminator accuracy 0.5781', 'Total loss: 1.4373', 'for batch', 13)
('GAN loss 0.7336 ', 'GAN acc 0.4805', 'Discriminator loss 0.6758', 'Discriminator accuracy 0.5449', 'Total loss: 1.4093', 'for batch', 14)
('GAN loss 0.6871 ', 'GAN acc 0.5820', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5254', 'Total loss: 1.3809', 'for batch', 15)
('GAN loss 0.7254 ', 'GAN acc 0.4922', 'Discriminator loss 0.6806', 'Discriminator accuracy 0.5527', 'Total loss: 1.4060', 'for batch', 16)
('GAN loss 0.7227 ', 'GAN acc 0.4883', 'Discriminator loss 0.7069', 'Discriminator accuracy 0.4922', 'Total loss: 1.4297', 'for batch', 17)
('GAN loss 0.7554 ', 'GAN acc 0.4062', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.5352', 'Total loss: 1.4571', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.75740528)
('DISCRIMINATOR_Imagem FAKE=', 0.75795269)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.482347')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7384 ', 'GAN acc 0.4336', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.5000', 'Total loss: 1.4397', 'for batch', 0)
('GAN loss 0.7409 ', 'GAN acc 0.4414', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.5078', 'Total loss: 1.4451', 'for batch', 1)
('GAN loss 0.7025 ', 'GAN acc 0.5234', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.5176', 'Total loss: 1.4050', 'for batch', 2)
('GAN loss 0.6828 ', 'GAN acc 0.5508', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5195', 'Total loss: 1.3774', 'for batch', 3)
('GAN loss 0.6684 ', 'GAN acc 0.5664', 'Discriminator loss 0.7127', 'Discriminator accuracy 0.4844', 'Total loss: 1.3811', 'for batch', 4)
('GAN loss 0.6744 ', 'GAN acc 0.5547', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.5039', 'Total loss: 1.3766', 'for batch', 5)
('GAN loss 0.6856 ', 'GAN acc 0.5781', 'Discriminator loss 0.7091', 'Discriminator accuracy 0.4844', 'Total loss: 1.3947', 'for batch', 6)
('GAN loss 0.7076 ', 'GAN acc 0.5234', 'Discriminator loss 0.7106', 'Discriminator accuracy 0.4883', 'Total loss: 1.4182', 'for batch', 7)
('GAN loss 0.6924 ', 'GAN acc 0.5508', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4922', 'Total loss: 1.3990', 'for batch', 8)
('GAN loss 0.6918 ', 'GAN acc 0.5273', 'Discriminator loss 0.7099', 'Discriminator accuracy 0.4746', 'Total loss: 1.4018', 'for batch', 9)
('GAN loss 0.7122 ', 'GAN acc 0.4844', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.5195', 'Total loss: 1.4125', 'for batch', 10)
('GAN loss 0.7034 ', 'GAN acc 0.5000', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.5254', 'Total loss: 1.4019', 'for batch', 11)
('GAN loss 0.7017 ', 'GAN acc 0.5117', 'Discriminator loss 0.6841', 'Discriminator accuracy 0.5488', 'Total loss: 1.3858', 'for batch', 12)
('GAN loss 0.7145 ', 'GAN acc 0.4648', 'Discriminator loss 0.7110', 'Discriminator accuracy 0.4512', 'Total loss: 1.4255', 'for batch', 13)
('GAN loss 0.6980 ', 'GAN acc 0.4883', 'Discriminator loss 0.7095', 'Discriminator accuracy 0.4883', 'Total loss: 1.4075', 'for batch', 14)
('GAN loss 0.6897 ', 'GAN acc 0.5352', 'Discriminator loss 0.7128', 'Discriminator accuracy 0.4805', 'Total loss: 1.4025', 'for batch', 15)
('GAN loss 0.6960 ', 'GAN acc 0.5312', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.5059', 'Total loss: 1.3992', 'for batch', 16)
('GAN loss 0.6932 ', 'GAN acc 0.5469', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.5195', 'Total loss: 1.3950', 'for batch', 17)
('GAN loss 0.6737 ', 'GAN acc 0.5742', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.5156', 'Total loss: 1.3731', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.70239782)
('DISCRIMINATOR_Imagem FAKE=', 0.69584471)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.008581')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6774 ', 'GAN acc 0.5547', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.5273', 'Total loss: 1.3775', 'for batch', 0)
('GAN loss 0.6864 ', 'GAN acc 0.5703', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4766', 'Total loss: 1.3876', 'for batch', 1)
('GAN loss 0.6717 ', 'GAN acc 0.5938', 'Discriminator loss 0.7052', 'Discriminator accuracy 0.4824', 'Total loss: 1.3769', 'for batch', 2)
('GAN loss 0.6679 ', 'GAN acc 0.6328', 'Discriminator loss 0.7097', 'Discriminator accuracy 0.4785', 'Total loss: 1.3776', 'for batch', 3)
('GAN loss 0.6580 ', 'GAN acc 0.6641', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4902', 'Total loss: 1.3616', 'for batch', 4)
('GAN loss 0.6832 ', 'GAN acc 0.5703', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.5020', 'Total loss: 1.3890', 'for batch', 5)
('GAN loss 0.6783 ', 'GAN acc 0.5977', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5137', 'Total loss: 1.3766', 'for batch', 6)
('GAN loss 0.6813 ', 'GAN acc 0.5703', 'Discriminator loss 0.7050', 'Discriminator accuracy 0.4590', 'Total loss: 1.3863', 'for batch', 7)
('GAN loss 0.6764 ', 'GAN acc 0.5977', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5312', 'Total loss: 1.3699', 'for batch', 8)
('GAN loss 0.6795 ', 'GAN acc 0.5898', 'Discriminator loss 0.7136', 'Discriminator accuracy 0.4648', 'Total loss: 1.3931', 'for batch', 9)
('GAN loss 0.6889 ', 'GAN acc 0.5664', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4688', 'Total loss: 1.3922', 'for batch', 10)
('GAN loss 0.6855 ', 'GAN acc 0.5430', 'Discriminator loss 0.7092', 'Discriminator accuracy 0.4570', 'Total loss: 1.3948', 'for batch', 11)
('GAN loss 0.6892 ', 'GAN acc 0.5391', 'Discriminator loss 0.7073', 'Discriminator accuracy 0.4707', 'Total loss: 1.3965', 'for batch', 12)
('GAN loss 0.6676 ', 'GAN acc 0.6055', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.5000', 'Total loss: 1.3672', 'for batch', 13)
('GAN loss 0.6715 ', 'GAN acc 0.6172', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4922', 'Total loss: 1.3675', 'for batch', 14)
('GAN loss 0.6783 ', 'GAN acc 0.5664', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4961', 'Total loss: 1.3815', 'for batch', 15)
('GAN loss 0.6935 ', 'GAN acc 0.5195', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5117', 'Total loss: 1.3887', 'for batch', 16)
('GAN loss 0.6830 ', 'GAN acc 0.5781', 'Discriminator loss 0.7053', 'Discriminator accuracy 0.4902', 'Total loss: 1.3883', 'for batch', 17)
('GAN loss 0.6822 ', 'GAN acc 0.5508', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4941', 'Total loss: 1.3829', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.64487648)
('DISCRIMINATOR_Imagem FAKE=', 0.642932)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.552161')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6824 ', 'GAN acc 0.5352', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4980', 'Total loss: 1.3765', 'for batch', 0)
('GAN loss 0.6713 ', 'GAN acc 0.6016', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.5059', 'Total loss: 1.3732', 'for batch', 1)
('GAN loss 0.6859 ', 'GAN acc 0.5312', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4902', 'Total loss: 1.3850', 'for batch', 2)
('GAN loss 0.6799 ', 'GAN acc 0.5898', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4707', 'Total loss: 1.3805', 'for batch', 3)
('GAN loss 0.6812 ', 'GAN acc 0.5703', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4844', 'Total loss: 1.3826', 'for batch', 4)
('GAN loss 0.6912 ', 'GAN acc 0.5469', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5137', 'Total loss: 1.3926', 'for batch', 5)
('GAN loss 0.6805 ', 'GAN acc 0.5859', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4844', 'Total loss: 1.3772', 'for batch', 6)
('GAN loss 0.6864 ', 'GAN acc 0.5430', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4844', 'Total loss: 1.3860', 'for batch', 7)
('GAN loss 0.6888 ', 'GAN acc 0.5430', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5117', 'Total loss: 1.3834', 'for batch', 8)
('GAN loss 0.7020 ', 'GAN acc 0.4883', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4707', 'Total loss: 1.4023', 'for batch', 9)
('GAN loss 0.6882 ', 'GAN acc 0.5469', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4707', 'Total loss: 1.3905', 'for batch', 10)
('GAN loss 0.6844 ', 'GAN acc 0.5430', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4980', 'Total loss: 1.3804', 'for batch', 11)
('GAN loss 0.6752 ', 'GAN acc 0.6172', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.5176', 'Total loss: 1.3789', 'for batch', 12)
('GAN loss 0.6782 ', 'GAN acc 0.5625', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4707', 'Total loss: 1.3788', 'for batch', 13)
('GAN loss 0.6828 ', 'GAN acc 0.5977', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5215', 'Total loss: 1.3784', 'for batch', 14)
('GAN loss 0.7015 ', 'GAN acc 0.5156', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4707', 'Total loss: 1.3986', 'for batch', 15)
('GAN loss 0.7072 ', 'GAN acc 0.4531', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.4746', 'Total loss: 1.4084', 'for batch', 16)
('GAN loss 0.7092 ', 'GAN acc 0.4883', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4902', 'Total loss: 1.4108', 'for batch', 17)
('GAN loss 0.7028 ', 'GAN acc 0.4375', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.4629', 'Total loss: 1.4053', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.60742104)
('DISCRIMINATOR_Imagem FAKE=', 0.60820532)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.110534')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6931 ', 'GAN acc 0.5234', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.4844', 'Total loss: 1.3974', 'for batch', 0)
('GAN loss 0.6933 ', 'GAN acc 0.5430', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.4688', 'Total loss: 1.3958', 'for batch', 1)
('GAN loss 0.6855 ', 'GAN acc 0.5508', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4863', 'Total loss: 1.3852', 'for batch', 2)
('GAN loss 0.6747 ', 'GAN acc 0.6016', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3687', 'for batch', 3)
('GAN loss 0.6768 ', 'GAN acc 0.5938', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4766', 'Total loss: 1.3714', 'for batch', 4)
('GAN loss 0.6763 ', 'GAN acc 0.6055', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4883', 'Total loss: 1.3778', 'for batch', 5)
('GAN loss 0.6740 ', 'GAN acc 0.6055', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4844', 'Total loss: 1.3709', 'for batch', 6)
('GAN loss 0.6839 ', 'GAN acc 0.5898', 'Discriminator loss 0.6877', 'Discriminator accuracy 0.5312', 'Total loss: 1.3716', 'for batch', 7)
('GAN loss 0.6800 ', 'GAN acc 0.5977', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4707', 'Total loss: 1.3776', 'for batch', 8)
('GAN loss 0.6932 ', 'GAN acc 0.5195', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4902', 'Total loss: 1.3899', 'for batch', 9)
('GAN loss 0.6962 ', 'GAN acc 0.5117', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4824', 'Total loss: 1.3946', 'for batch', 10)
('GAN loss 0.6955 ', 'GAN acc 0.4922', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4727', 'Total loss: 1.3957', 'for batch', 11)
('GAN loss 0.7004 ', 'GAN acc 0.5273', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4785', 'Total loss: 1.4014', 'for batch', 12)
('GAN loss 0.6855 ', 'GAN acc 0.5742', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4902', 'Total loss: 1.3835', 'for batch', 13)
('GAN loss 0.6895 ', 'GAN acc 0.5508', 'Discriminator loss 0.7067', 'Discriminator accuracy 0.4844', 'Total loss: 1.3962', 'for batch', 14)
('GAN loss 0.6835 ', 'GAN acc 0.5742', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5273', 'Total loss: 1.3762', 'for batch', 15)
('GAN loss 0.6966 ', 'GAN acc 0.5391', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4863', 'Total loss: 1.3937', 'for batch', 16)
('GAN loss 0.6854 ', 'GAN acc 0.5703', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.5020', 'Total loss: 1.3869', 'for batch', 17)
('GAN loss 0.6901 ', 'GAN acc 0.5625', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5137', 'Total loss: 1.3842', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58949029)
('DISCRIMINATOR_Imagem FAKE=', 0.59175408)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.660054')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6831 ', 'GAN acc 0.5586', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4961', 'Total loss: 1.3827', 'for batch', 0)
('GAN loss 0.6930 ', 'GAN acc 0.5547', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4883', 'Total loss: 1.3914', 'for batch', 1)
('GAN loss 0.7058 ', 'GAN acc 0.4297', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5195', 'Total loss: 1.3983', 'for batch', 2)
('GAN loss 0.6861 ', 'GAN acc 0.5469', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.5020', 'Total loss: 1.3852', 'for batch', 3)
('GAN loss 0.6898 ', 'GAN acc 0.5430', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4961', 'Total loss: 1.3841', 'for batch', 4)
('GAN loss 0.6981 ', 'GAN acc 0.5156', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4609', 'Total loss: 1.3999', 'for batch', 5)
('GAN loss 0.6886 ', 'GAN acc 0.5430', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5176', 'Total loss: 1.3834', 'for batch', 6)
('GAN loss 0.6937 ', 'GAN acc 0.5547', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5234', 'Total loss: 1.3865', 'for batch', 7)
('GAN loss 0.6856 ', 'GAN acc 0.5469', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4980', 'Total loss: 1.3850', 'for batch', 8)
('GAN loss 0.6966 ', 'GAN acc 0.4727', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5312', 'Total loss: 1.3895', 'for batch', 9)
('GAN loss 0.6913 ', 'GAN acc 0.5234', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4941', 'Total loss: 1.3891', 'for batch', 10)
('GAN loss 0.6922 ', 'GAN acc 0.5352', 'Discriminator loss 0.7040', 'Discriminator accuracy 0.4863', 'Total loss: 1.3962', 'for batch', 11)
('GAN loss 0.6819 ', 'GAN acc 0.6055', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4688', 'Total loss: 1.3849', 'for batch', 12)
('GAN loss 0.6794 ', 'GAN acc 0.5742', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.4688', 'Total loss: 1.3821', 'for batch', 13)
('GAN loss 0.6850 ', 'GAN acc 0.5859', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.5098', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.6990 ', 'GAN acc 0.4883', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4980', 'Total loss: 1.3951', 'for batch', 15)
('GAN loss 0.7018 ', 'GAN acc 0.4844', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5078', 'Total loss: 1.3955', 'for batch', 16)
('GAN loss 0.7007 ', 'GAN acc 0.4844', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4805', 'Total loss: 1.4026', 'for batch', 17)
('GAN loss 0.7021 ', 'GAN acc 0.4844', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4824', 'Total loss: 1.3999', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.57190639)
('DISCRIMINATOR_Imagem FAKE=', 0.57207489)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.088576')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6916 ', 'GAN acc 0.5430', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4863', 'Total loss: 1.3928', 'for batch', 0)
('GAN loss 0.6861 ', 'GAN acc 0.5781', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4629', 'Total loss: 1.3870', 'for batch', 1)
('GAN loss 0.6800 ', 'GAN acc 0.6055', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4805', 'Total loss: 1.3809', 'for batch', 2)
('GAN loss 0.6808 ', 'GAN acc 0.5898', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.5137', 'Total loss: 1.3793', 'for batch', 3)
('GAN loss 0.6866 ', 'GAN acc 0.5547', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4707', 'Total loss: 1.3839', 'for batch', 4)
('GAN loss 0.6815 ', 'GAN acc 0.6094', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5117', 'Total loss: 1.3728', 'for batch', 5)
('GAN loss 0.6800 ', 'GAN acc 0.5898', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4863', 'Total loss: 1.3737', 'for batch', 6)
('GAN loss 0.6867 ', 'GAN acc 0.5273', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4727', 'Total loss: 1.3853', 'for batch', 7)
('GAN loss 0.6896 ', 'GAN acc 0.5234', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5293', 'Total loss: 1.3817', 'for batch', 8)
('GAN loss 0.6968 ', 'GAN acc 0.4961', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.4531', 'Total loss: 1.3994', 'for batch', 9)
('GAN loss 0.6932 ', 'GAN acc 0.4961', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5195', 'Total loss: 1.3871', 'for batch', 10)
('GAN loss 0.7020 ', 'GAN acc 0.4531', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5195', 'Total loss: 1.3976', 'for batch', 11)
('GAN loss 0.6842 ', 'GAN acc 0.5625', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5000', 'Total loss: 1.3789', 'for batch', 12)
('GAN loss 0.6965 ', 'GAN acc 0.5078', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4980', 'Total loss: 1.3933', 'for batch', 13)
('GAN loss 0.6919 ', 'GAN acc 0.5547', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5254', 'Total loss: 1.3828', 'for batch', 14)
('GAN loss 0.7013 ', 'GAN acc 0.4688', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4961', 'Total loss: 1.3981', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.4492', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5195', 'Total loss: 1.3879', 'for batch', 16)
('GAN loss 0.7065 ', 'GAN acc 0.4453', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4844', 'Total loss: 1.4067', 'for batch', 17)
('GAN loss 0.7048 ', 'GAN acc 0.4766', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4590', 'Total loss: 1.4072', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55900466)
('DISCRIMINATOR_Imagem FAKE=', 0.55859131)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.631894')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5039', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4922', 'Total loss: 1.3901', 'for batch', 0)
('GAN loss 0.6903 ', 'GAN acc 0.5117', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4746', 'Total loss: 1.3899', 'for batch', 1)
('GAN loss 0.6969 ', 'GAN acc 0.4609', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4609', 'Total loss: 1.3961', 'for batch', 2)
('GAN loss 0.6923 ', 'GAN acc 0.5469', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4922', 'Total loss: 1.3912', 'for batch', 3)
('GAN loss 0.6857 ', 'GAN acc 0.5586', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5254', 'Total loss: 1.3803', 'for batch', 4)
('GAN loss 0.6838 ', 'GAN acc 0.6055', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5391', 'Total loss: 1.3773', 'for batch', 5)
('GAN loss 0.6864 ', 'GAN acc 0.5547', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4902', 'Total loss: 1.3818', 'for batch', 6)
('GAN loss 0.6819 ', 'GAN acc 0.5781', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5078', 'Total loss: 1.3787', 'for batch', 7)
('GAN loss 0.6886 ', 'GAN acc 0.5469', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5234', 'Total loss: 1.3848', 'for batch', 8)
('GAN loss 0.6804 ', 'GAN acc 0.6211', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4941', 'Total loss: 1.3762', 'for batch', 9)
('GAN loss 0.6803 ', 'GAN acc 0.5977', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4863', 'Total loss: 1.3806', 'for batch', 10)
('GAN loss 0.6892 ', 'GAN acc 0.5391', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4863', 'Total loss: 1.3889', 'for batch', 11)
('GAN loss 0.6970 ', 'GAN acc 0.5039', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5137', 'Total loss: 1.3906', 'for batch', 12)
('GAN loss 0.7049 ', 'GAN acc 0.4727', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4980', 'Total loss: 1.4013', 'for batch', 13)
('GAN loss 0.7058 ', 'GAN acc 0.4297', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4844', 'Total loss: 1.4056', 'for batch', 14)
('GAN loss 0.7060 ', 'GAN acc 0.4492', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4922', 'Total loss: 1.4028', 'for batch', 15)
('GAN loss 0.7077 ', 'GAN acc 0.4258', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4824', 'Total loss: 1.4064', 'for batch', 16)
('GAN loss 0.7048 ', 'GAN acc 0.4570', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4707', 'Total loss: 1.4037', 'for batch', 17)
('GAN loss 0.6908 ', 'GAN acc 0.5352', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5156', 'Total loss: 1.3837', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55162638)
('DISCRIMINATOR_Imagem FAKE=', 0.55152375)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.314752')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6944 ', 'GAN acc 0.5195', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4922', 'Total loss: 1.3879', 'for batch', 0)
('GAN loss 0.6865 ', 'GAN acc 0.5742', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5234', 'Total loss: 1.3799', 'for batch', 1)
('GAN loss 0.6886 ', 'GAN acc 0.5586', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4727', 'Total loss: 1.3883', 'for batch', 2)
('GAN loss 0.6830 ', 'GAN acc 0.5898', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4980', 'Total loss: 1.3787', 'for batch', 3)
('GAN loss 0.6862 ', 'GAN acc 0.5820', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4902', 'Total loss: 1.3853', 'for batch', 4)
('GAN loss 0.6840 ', 'GAN acc 0.5508', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3804', 'for batch', 5)
('GAN loss 0.6837 ', 'GAN acc 0.5664', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5039', 'Total loss: 1.3759', 'for batch', 6)
('GAN loss 0.6859 ', 'GAN acc 0.6055', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4844', 'Total loss: 1.3820', 'for batch', 7)
('GAN loss 0.6876 ', 'GAN acc 0.5586', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5195', 'Total loss: 1.3844', 'for batch', 8)
('GAN loss 0.6814 ', 'GAN acc 0.6094', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4648', 'Total loss: 1.3804', 'for batch', 9)
('GAN loss 0.6938 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4902', 'Total loss: 1.3899', 'for batch', 10)
('GAN loss 0.6887 ', 'GAN acc 0.5703', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4844', 'Total loss: 1.3834', 'for batch', 11)
('GAN loss 0.6866 ', 'GAN acc 0.5547', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5039', 'Total loss: 1.3838', 'for batch', 12)
('GAN loss 0.6851 ', 'GAN acc 0.5625', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4531', 'Total loss: 1.3871', 'for batch', 13)
('GAN loss 0.6920 ', 'GAN acc 0.5625', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4688', 'Total loss: 1.3903', 'for batch', 14)
('GAN loss 0.6888 ', 'GAN acc 0.5586', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5332', 'Total loss: 1.3805', 'for batch', 15)
('GAN loss 0.6905 ', 'GAN acc 0.5391', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5078', 'Total loss: 1.3857', 'for batch', 16)
('GAN loss 0.6986 ', 'GAN acc 0.4531', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4688', 'Total loss: 1.3988', 'for batch', 17)
('GAN loss 0.6968 ', 'GAN acc 0.4883', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4805', 'Total loss: 1.3947', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54379648)
('DISCRIMINATOR_Imagem FAKE=', 0.54354089)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.633163')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6950 ', 'GAN acc 0.4805', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4941', 'Total loss: 1.3908', 'for batch', 0)
('GAN loss 0.7025 ', 'GAN acc 0.4766', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5352', 'Total loss: 1.3966', 'for batch', 1)
('GAN loss 0.7013 ', 'GAN acc 0.4375', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4961', 'Total loss: 1.3958', 'for batch', 2)
('GAN loss 0.6939 ', 'GAN acc 0.5312', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4922', 'Total loss: 1.3914', 'for batch', 3)
('GAN loss 0.6888 ', 'GAN acc 0.5469', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4492', 'Total loss: 1.3903', 'for batch', 4)
('GAN loss 0.6879 ', 'GAN acc 0.5586', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4805', 'Total loss: 1.3841', 'for batch', 5)
('GAN loss 0.6831 ', 'GAN acc 0.5625', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4434', 'Total loss: 1.3878', 'for batch', 6)
('GAN loss 0.6849 ', 'GAN acc 0.5508', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4902', 'Total loss: 1.3777', 'for batch', 7)
('GAN loss 0.6879 ', 'GAN acc 0.5391', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4941', 'Total loss: 1.3831', 'for batch', 8)
('GAN loss 0.6872 ', 'GAN acc 0.5391', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5195', 'Total loss: 1.3820', 'for batch', 9)
('GAN loss 0.6870 ', 'GAN acc 0.5430', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4844', 'Total loss: 1.3803', 'for batch', 10)
('GAN loss 0.6901 ', 'GAN acc 0.5352', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4570', 'Total loss: 1.3885', 'for batch', 11)
('GAN loss 0.6857 ', 'GAN acc 0.5664', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4883', 'Total loss: 1.3795', 'for batch', 12)
('GAN loss 0.6852 ', 'GAN acc 0.5859', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3781', 'for batch', 13)
('GAN loss 0.6842 ', 'GAN acc 0.5664', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4668', 'Total loss: 1.3814', 'for batch', 14)
('GAN loss 0.6945 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4863', 'Total loss: 1.3901', 'for batch', 15)
('GAN loss 0.7042 ', 'GAN acc 0.4648', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4688', 'Total loss: 1.4014', 'for batch', 16)
('GAN loss 0.6930 ', 'GAN acc 0.5156', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5176', 'Total loss: 1.3841', 'for batch', 17)
('GAN loss 0.7041 ', 'GAN acc 0.4414', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4688', 'Total loss: 1.4049', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53954089)
('DISCRIMINATOR_Imagem FAKE=', 0.53964794)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.194400')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7007 ', 'GAN acc 0.4883', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5176', 'Total loss: 1.3965', 'for batch', 0)
('GAN loss 0.6946 ', 'GAN acc 0.5156', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4941', 'Total loss: 1.3903', 'for batch', 1)
('GAN loss 0.6960 ', 'GAN acc 0.4766', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5020', 'Total loss: 1.3895', 'for batch', 2)
('GAN loss 0.6877 ', 'GAN acc 0.5820', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5176', 'Total loss: 1.3811', 'for batch', 3)
('GAN loss 0.6899 ', 'GAN acc 0.5273', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4570', 'Total loss: 1.3885', 'for batch', 4)
('GAN loss 0.6854 ', 'GAN acc 0.5664', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4785', 'Total loss: 1.3800', 'for batch', 5)
('GAN loss 0.6868 ', 'GAN acc 0.5625', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4707', 'Total loss: 1.3817', 'for batch', 6)
('GAN loss 0.6865 ', 'GAN acc 0.5625', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4922', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6811 ', 'GAN acc 0.6016', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3756', 'for batch', 8)
('GAN loss 0.6791 ', 'GAN acc 0.6328', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4980', 'Total loss: 1.3762', 'for batch', 9)
('GAN loss 0.6877 ', 'GAN acc 0.5469', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4863', 'Total loss: 1.3829', 'for batch', 10)
('GAN loss 0.6914 ', 'GAN acc 0.5039', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5000', 'Total loss: 1.3897', 'for batch', 11)
('GAN loss 0.6880 ', 'GAN acc 0.5625', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4902', 'Total loss: 1.3831', 'for batch', 12)
('GAN loss 0.6943 ', 'GAN acc 0.5000', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4316', 'Total loss: 1.3964', 'for batch', 13)
('GAN loss 0.6898 ', 'GAN acc 0.5508', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4785', 'Total loss: 1.3872', 'for batch', 14)
('GAN loss 0.7111 ', 'GAN acc 0.3906', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4902', 'Total loss: 1.4073', 'for batch', 15)
('GAN loss 0.6979 ', 'GAN acc 0.5156', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5039', 'Total loss: 1.3930', 'for batch', 16)
('GAN loss 0.7037 ', 'GAN acc 0.4062', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3975', 'for batch', 17)
('GAN loss 0.7049 ', 'GAN acc 0.4414', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5078', 'Total loss: 1.4000', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53209317)
('DISCRIMINATOR_Imagem FAKE=', 0.53183055)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.658627')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6998 ', 'GAN acc 0.4492', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4746', 'Total loss: 1.3965', 'for batch', 0)
('GAN loss 0.6995 ', 'GAN acc 0.4766', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5000', 'Total loss: 1.3958', 'for batch', 1)
('GAN loss 0.6941 ', 'GAN acc 0.4922', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4844', 'Total loss: 1.3896', 'for batch', 2)
('GAN loss 0.6977 ', 'GAN acc 0.4609', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5352', 'Total loss: 1.3889', 'for batch', 3)
('GAN loss 0.6889 ', 'GAN acc 0.5273', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4824', 'Total loss: 1.3845', 'for batch', 4)
('GAN loss 0.6837 ', 'GAN acc 0.5664', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4824', 'Total loss: 1.3801', 'for batch', 5)
('GAN loss 0.6833 ', 'GAN acc 0.5859', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5117', 'Total loss: 1.3780', 'for batch', 6)
('GAN loss 0.6810 ', 'GAN acc 0.5977', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5020', 'Total loss: 1.3750', 'for batch', 7)
('GAN loss 0.6749 ', 'GAN acc 0.6133', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4980', 'Total loss: 1.3706', 'for batch', 8)
('GAN loss 0.6769 ', 'GAN acc 0.6641', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4902', 'Total loss: 1.3742', 'for batch', 9)
('GAN loss 0.6851 ', 'GAN acc 0.5625', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4570', 'Total loss: 1.3837', 'for batch', 10)
('GAN loss 0.6839 ', 'GAN acc 0.5859', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4961', 'Total loss: 1.3761', 'for batch', 11)
('GAN loss 0.6870 ', 'GAN acc 0.5664', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4766', 'Total loss: 1.3821', 'for batch', 12)
('GAN loss 0.6894 ', 'GAN acc 0.5664', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5215', 'Total loss: 1.3832', 'for batch', 13)
('GAN loss 0.6893 ', 'GAN acc 0.5391', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5215', 'Total loss: 1.3819', 'for batch', 14)
('GAN loss 0.6948 ', 'GAN acc 0.5117', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4668', 'Total loss: 1.3910', 'for batch', 15)
('GAN loss 0.6999 ', 'GAN acc 0.4922', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4805', 'Total loss: 1.3974', 'for batch', 16)
('GAN loss 0.7067 ', 'GAN acc 0.3984', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4941', 'Total loss: 1.4036', 'for batch', 17)
('GAN loss 0.7105 ', 'GAN acc 0.3711', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4746', 'Total loss: 1.4054', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52587539)
('DISCRIMINATOR_Imagem FAKE=', 0.52615297)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.246129')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7033 ', 'GAN acc 0.4062', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5215', 'Total loss: 1.3940', 'for batch', 0)
('GAN loss 0.7017 ', 'GAN acc 0.4219', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4883', 'Total loss: 1.3955', 'for batch', 1)
('GAN loss 0.6991 ', 'GAN acc 0.4844', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4844', 'Total loss: 1.3967', 'for batch', 2)
('GAN loss 0.6939 ', 'GAN acc 0.5000', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5000', 'Total loss: 1.3874', 'for batch', 3)
('GAN loss 0.6888 ', 'GAN acc 0.5703', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4980', 'Total loss: 1.3826', 'for batch', 4)
('GAN loss 0.6859 ', 'GAN acc 0.5469', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3792', 'for batch', 5)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 230.0, 'yuv.min=', 13.0)
('yuv.max=', 253.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 35.0)
('yuv.max=', 241.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 228.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 80.0)
('yuv.max=', 212.0, 'yuv.min=', 21.0)
('yuv.max=', 161.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 9.0)
('yuv.max=', 233.0, 'yuv.min=', 16.0)
('yuv.max=', 243.0, 'yuv.min=', 69.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 212.0, 'yuv.min=', 51.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 199.0, 'yuv.min=', 12.0)
('yuv.max=', 245.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 39.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 228.0, 'yuv.min=', 62.0)
('yuv.max=', 247.0, 'yuv.min=', 9.0)
('yuv.max=', 231.0, 'yuv.min=', 29.0)
('yuv.max=', 242.0, 'yuv.min=', 14.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 201.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 28.0)
('yuv.max=', 195.0, 'yuv.min=', 23.0)
('yuv.max=', 196.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 195.0, 'yuv.min=', 22.0)
('yuv.max=', 238.0, 'yuv.min=', 43.0)
('yuv.max=', 222.0, 'yuv.min=', 24.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 18.0)
('yuv.max=', 231.0, 'yuv.min=', 12.0)
('yuv.max=', 216.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 222.0, 'yuv.min=', 22.0)
('yuv.max=', 253.0, 'yuv.min=', 31.0)
('yuv.max=', 235.0, 'yuv.min=', 14.0)
('yuv.max=', 236.0, 'yuv.min=', 30.0)
('yuv.max=', 210.0, 'yuv.min=', 26.0)
('yuv.max=', 246.0, 'yuv.min=', 2.0)
('yuv.max=', 253.0, 'yuv.min=', 18.0)
('yuv.max=', 206.0, 'yuv.min=', 15.0)
('yuv.max=', 227.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 247.0, 'yuv.min=', 25.0)
('yuv.max=', 253.0, 'yuv.min=', 21.0)
('yuv.max=', 196.0, 'yuv.min=', 23.0)
('yuv.max=', 167.0, 'yuv.min=', 23.0)
('yuv.max=', 242.0, 'yuv.min=', 22.0)
('yuv.max=', 212.0, 'yuv.min=', 31.0)
('yuv.max=', 244.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 212.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 149.0, 'yuv.min=', 11.0)
('yuv.max=', 233.0, 'yuv.min=', 5.0)
('yuv.max=', 242.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 41.0)
('yuv.max=', 172.0, 'yuv.min=', 12.0)
('yuv.max=', 189.0, 'yuv.min=', 11.0)
('yuv.max=', 217.0, 'yuv.min=', 13.0)
('yuv.max=', 251.0, 'yuv.min=', 23.0)
('yuv.max=', 193.0, 'yuv.min=', 51.0)
('yuv.max=', 245.0, 'yuv.min=', 42.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 39.0)
('yuv.max=', 238.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 234.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 15.0)
('yuv.max=', 250.0, 'yuv.min=', 10.0)
('yuv.max=', 244.0, 'yuv.min=', 42.0)
('yuv.max=', 220.0, 'yuv.min=', 47.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 217.0, 'yuv.min=', 3.0)
('yuv.max=', 239.0, 'yuv.min=', 36.0)
('yuv.max=', 194.0, 'yuv.min=', 10.0)
('yuv.max=', 217.0, 'yuv.min=', 4.0)
('yuv.max=', 241.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 53.0)
('yuv.max=', 241.0, 'yuv.min=', 35.0)
('yuv.max=', 235.0, 'yuv.min=', 17.0)
('yuv.max=', 206.0, 'yuv.min=', 39.0)
('yuv.max=', 223.0, 'yuv.min=', 28.0)
('yuv.max=', 201.0, 'yuv.min=', 48.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 228.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 225.0, 'yuv.min=', 52.0)
('yuv.max=', 235.0, 'yuv.min=', 40.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 186.0, 'yuv.min=', 50.0)
('yuv.max=', 168.0, 'yuv.min=', 24.0)
('yuv.max=', 246.0, 'yuv.min=', 35.0)
('yuv.max=', 219.0, 'yuv.min=', 59.0)
('yuv.max=', 254.0, 'yuv.min=', 24.0)
('yuv.max=', 194.0, 'yuv.min=', 33.0)
('yuv.max=', 219.0, 'yuv.min=', 41.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 188.0, 'yuv.min=', 23.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 190.0, 'yuv.min=', 14.0)
('yuv.max=', 236.0, 'yuv.min=', 30.0)
('yuv.max=', 248.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 19.0)
('yuv.max=', 221.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 65.0)
('yuv.max=', 251.0, 'yuv.min=', 5.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 238.0, 'yuv.min=', 14.0)
('yuv.max=', 198.0, 'yuv.min=', 28.0)
('yuv.max=', 172.0, 'yuv.min=', 77.0)
('yuv.max=', 246.0, 'yuv.min=', 23.0)
('yuv.max=', 254.0, 'yuv.min=', 61.0)
('yuv.max=', 224.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 245.0, 'yuv.min=', 37.0)
('yuv.max=', 233.0, 'yuv.min=', 7.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 37.0)
('yuv.max=', 235.0, 'yuv.min=', 21.0)
('yuv.max=', 231.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 187.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 236.0, 'yuv.min=', 31.0)
('yuv.max=', 222.0, 'yuv.min=', 32.0)
('yuv.max=', 202.0, 'yuv.min=', 8.0)
('yuv.max=', 238.0, 'yuv.min=', 0.0)
('yuv.max=', 242.0, 'yuv.min=', 76.0)
('yuv.max=', 249.0, 'yuv.min=', 27.0)
('yuv.max=', 216.0, 'yuv.min=', 5.0)
('yuv.max=', 244.0, 'yuv.min=', 35.0)
('yuv.max=', 231.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 3.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 15.0)
('yuv.max=', 206.0, 'yuv.min=', 39.0)
('yuv.max=', 249.0, 'yuv.min=', 2.0)
('yuv.max=', 207.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 15.0)
('yuv.max=', 214.0, 'yuv.min=', 22.0)
('yuv.max=', 252.0, 'yuv.min=', 51.0)
('yuv.max=', 248.0, 'yuv.min=', 1.0)
('yuv.max=', 232.0, 'yuv.min=', 25.0)
('yuv.max=', 207.0, 'yuv.min=', 50.0)
('yuv.max=', 240.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 6.0)
('yuv.max=', 244.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 54.0)
('yuv.max=', 230.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 208.0, 'yuv.min=', 51.0)
('yuv.max=', 215.0, 'yuv.min=', 28.0)
('yuv.max=', 243.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 1.0)
('yuv.max=', 244.0, 'yuv.min=', 5.0)
('yuv.max=', 229.0, 'yuv.min=', 68.0)
('yuv.max=', 241.0, 'yuv.min=', 35.0)
('yuv.max=', 245.0, 'yuv.min=', 22.0)
('yuv.max=', 244.0, 'yuv.min=', 19.0)
('yuv.max=', 226.0, 'yuv.min=', 13.0)
('yuv.max=', 215.0, 'yuv.min=', 24.0)
('yuv.max=', 242.0, 'yuv.min=', 32.0)
('yuv.max=', 234.0, 'yuv.min=', 11.0)
('yuv.max=', 198.0, 'yuv.min=', 92.0)
('yuv.max=', 231.0, 'yuv.min=', 39.0)
('yuv.max=', 164.0, 'yuv.min=', 20.0)
('yuv.max=', 249.0, 'yuv.min=', 27.0)
('yuv.max=', 228.0, 'yuv.min=', 33.0)
('yuv.max=', 244.0, 'yuv.min=', 12.0)
('yuv.max=', 233.0, 'yuv.min=', 67.0)
('yuv.max=', 211.0, 'yuv.min=', 10.0)
('yuv.max=', 252.0, 'yuv.min=', 5.0)
('yuv.max=', 204.0, 'yuv.min=', 38.0)
('yuv.max=', 252.0, 'yuv.min=', 56.0)
('yuv.max=', 220.0, 'yuv.min=', 53.0)
('yuv.max=', 214.0, 'yuv.min=', 34.0)
('yuv.max=', 204.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 244.0, 'yuv.min=', 40.0)
('yuv.max=', 233.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 13.0)
('yuv.max=', 214.0, 'yuv.min=', 31.0)
('yuv.max=', 213.0, 'yuv.min=', 49.0)
('yuv.max=', 219.0, 'yuv.min=', 19.0)
('yuv.max=', 222.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 16.0)
('yuv.max=', 186.0, 'yuv.min=', 74.0)
('yuv.max=', 239.0, 'yuv.min=', 14.0)
('yuv.max=', 206.0, 'yuv.min=', 8.0)
('yuv.max=', 231.0, 'yuv.min=', 17.0)
('yuv.max=', 191.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 242.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 25.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 222.0, 'yuv.min=', 35.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 209.0, 'yuv.min=', 24.0)
('yuv.max=', 247.0, 'yuv.min=', 3.0)
('yuv.max=', 216.0, 'yuv.min=', 80.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 240.0, 'yuv.min=', 12.0)
('yuv.max=', 241.0, 'yuv.min=', 4.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 212.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 25.0)
('yuv.max=', 245.0, 'yuv.min=', 5.0)
('yuv.max=', 170.0, 'yuv.min=', 33.0)
('yuv.max=', 226.0, 'yuv.min=', 85.0)
('yuv.max=', 254.0, 'yuv.min=', 20.0)
('yuv.max=', 252.0, 'yuv.min=', 38.0)
('yuv.max=', 231.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 245.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 241.0, 'yuv.min=', 30.0)
('yuv.max=', 244.0, 'yuv.min=', 1.0)
('yuv.max=', 229.0, 'yuv.min=', 11.0)
('yuv.max=', 248.0, 'yuv.min=', 31.0)
('yuv.max=', 224.0, 'yuv.min=', 18.0)
('yuv.max=', 249.0, 'yuv.min=', 20.0)
('yuv.max=', 199.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 229.0, 'yuv.min=', 40.0)
('yuv.max=', 249.0, 'yuv.min=', 25.0)
('yuv.max=', 241.0, 'yuv.min=', 55.0)
('yuv.max=', 238.0, 'yuv.min=', 2.0)
('yuv.max=', 235.0, 'yuv.min=', 45.0)
('yuv.max=', 208.0, 'yuv.min=', 14.0)
('yuv.max=', 242.0, 'yuv.min=', 16.0)
('yuv.max=', 231.0, 'yuv.min=', 39.0)
('yuv.max=', 229.0, 'yuv.min=', 5.0)
('yuv.max=', 218.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 29.0)
('yuv.max=', 234.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 215.0, 'yuv.min=', 48.0)
('yuv.max=', 216.0, 'yuv.min=', 6.0)
('yuv.max=', 229.0, 'yuv.min=', 92.0)
('yuv.max=', 231.0, 'yuv.min=', 42.0)
('yuv.max=', 242.0, 'yuv.min=', 10.0)
('yuv.max=', 178.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 247.0, 'yuv.min=', 12.0)
('yuv.max=', 235.0, 'yuv.min=', 12.0)
('yuv.max=', 210.0, 'yuv.min=', 14.0)
('yuv.max=', 243.0, 'yuv.min=', 27.0)
('yuv.max=', 190.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 4.0)
('yuv.max=', 191.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 238.0, 'yuv.min=', 13.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 204.0, 'yuv.min=', 0.0)
('yuv.max=', 234.0, 'yuv.min=', 75.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 216.0, 'yuv.min=', 64.0)
('yuv.max=', 206.0, 'yuv.min=', 30.0)
('yuv.max=', 211.0, 'yuv.min=', 19.0)
('yuv.max=', 226.0, 'yuv.min=', 5.0)
('yuv.max=', 206.0, 'yuv.min=', 54.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 248.0, 'yuv.min=', 15.0)
('yuv.max=', 253.0, 'yuv.min=', 58.0)
('yuv.max=', 244.0, 'yuv.min=', 39.0)
('yuv.max=', 250.0, 'yuv.min=', 9.0)
('yuv.max=', 250.0, 'yuv.min=', 3.0)
('yuv.max=', 204.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 233.0, 'yuv.min=', 35.0)
('yuv.max=', 212.0, 'yuv.min=', 7.0)
('yuv.max=', 198.0, 'yuv.min=', 1.0)
('yuv.max=', 229.0, 'yuv.min=', 7.0)
('yuv.max=', 174.0, 'yuv.min=', 8.0)
('yuv.max=', 247.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 238.0, 'yuv.min=', 15.0)
('yuv.max=', 163.0, 'yuv.min=', 23.0)
('yuv.max=', 250.0, 'yuv.min=', 37.0)
('yuv.max=', 235.0, 'yuv.min=', 2.0)
('yuv.max=', 228.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 59.0)
('yuv.max=', 252.0, 'yuv.min=', 44.0)
('yuv.max=', 238.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 245.0, 'yuv.min=', 3.0)
('yuv.max=', 222.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 241.0, 'yuv.min=', 65.0)
('yuv.max=', 179.0, 'yuv.min=', 34.0)
('yuv.max=', 208.0, 'yuv.min=', 47.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 25.0)
('yuv.max=', 230.0, 'yuv.min=', 47.0)
('yuv.max=', 235.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 7.0)
('yuv.max=', 229.0, 'yuv.min=', 22.0)
('yuv.max=', 239.0, 'yuv.min=', 7.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 241.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 34.0)
('yuv.max=', 217.0, 'yuv.min=', 37.0)
('yuv.max=', 226.0, 'yuv.min=', 32.0)
('yuv.max=', 244.0, 'yuv.min=', 49.0)
('yuv.max=', 162.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 5.0)
('yuv.max=', 229.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 22.0)
('yuv.max=', 238.0, 'yuv.min=', 28.0)
('yuv.max=', 253.0, 'yuv.min=', 29.0)
('yuv.max=', 250.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 247.0, 'yuv.min=', 55.0)
('yuv.max=', 242.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 2.0)
('yuv.max=', 243.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 234.0, 'yuv.min=', 12.0)
('yuv.max=', 242.0, 'yuv.min=', 17.0)
('yuv.max=', 208.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 250.0, 'yuv.min=', 47.0)
('yuv.max=', 239.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 150.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 223.0, 'yuv.min=', 21.0)
('yuv.max=', 238.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 6.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 234.0, 'yuv.min=', 10.0)
('yuv.max=', 200.0, 'yuv.min=', 40.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 18.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 222.0, 'yuv.min=', 39.0)
('yuv.max=', 199.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 6.0)
('yuv.max=', 226.0, 'yuv.min=', 22.0)
('yuv.max=', 186.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 212.0, 'yuv.min=', 38.0)
('yuv.max=', 215.0, 'yuv.min=', 39.0)
('yuv.max=', 226.0, 'yuv.min=', 3.0)
('yuv.max=', 251.0, 'yuv.min=', 6.0)
('yuv.max=', 247.0, 'yuv.min=', 32.0)
('yuv.max=', 246.0, 'yuv.min=', 30.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 8.0)
('yuv.max=', 240.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 24.0)
('yuv.max=', 209.0, 'yuv.min=', 11.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 7.0)
('yuv.max=', 245.0, 'yuv.min=', 2.0)
('yuv.max=', 238.0, 'yuv.min=', 22.0)
('yuv.max=', 179.0, 'yuv.min=', 72.0)
('yuv.max=', 232.0, 'yuv.min=', 31.0)
('yuv.max=', 248.0, 'yuv.min=', 6.0)
('yuv.max=', 254.0, 'yuv.min=', 15.0)
('yuv.max=', 233.0, 'yuv.min=', 34.0)
('yuv.max=', 252.0, 'yuv.min=', 7.0)
('yuv.max=', 243.0, 'yuv.min=', 26.0)
('yuv.max=', 237.0, 'yuv.min=', 44.0)
('yuv.max=', 192.0, 'yuv.min=', 15.0)
('yuv.max=', 197.0, 'yuv.min=', 9.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 26.0)
('yuv.max=', 175.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 13.0)
('yuv.max=', 193.0, 'yuv.min=', 7.0)
('yuv.max=', 208.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 162.0, 'yuv.min=', 47.0)
('yuv.max=', 205.0, 'yuv.min=', 24.0)
('yuv.max=', 227.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 242.0, 'yuv.min=', 35.0)
('yuv.max=', 239.0, 'yuv.min=', 7.0)
('yuv.max=', 220.0, 'yuv.min=', 32.0)
('yuv.max=', 217.0, 'yuv.min=', 6.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 201.0, 'yuv.min=', 13.0)
('yuv.max=', 245.0, 'yuv.min=', 33.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 18.0)
('yuv.max=', 249.0, 'yuv.min=', 52.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 38.0)
('yuv.max=', 212.0, 'yuv.min=', 56.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 20.0)
('yuv.max=', 151.0, 'yuv.min=', 2.0)
('yuv.max=', 232.0, 'yuv.min=', 3.0)
('yuv.max=', 252.0, 'yuv.min=', 51.0)
('yuv.max=', 185.0, 'yuv.min=', 26.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 196.0, 'yuv.min=', 21.0)
('yuv.max=', 219.0, 'yuv.min=', 27.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 240.0, 'yuv.min=', 39.0)
('yuv.max=', 253.0, 'yuv.min=', 9.0)
('yuv.max=', 227.0, 'yuv.min=', 42.0)
('yuv.max=', 253.0, 'yuv.min=', 27.0)
('yuv.max=', 214.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 244.0, 'yuv.min=', 4.0)
('yuv.max=', 225.0, 'yuv.min=', 15.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 219.0, 'yuv.min=', 95.0)
('yuv.max=', 241.0, 'yuv.min=', 18.0)
('yuv.max=', 216.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 249.0, 'yuv.min=', 60.0)
('yuv.max=', 191.0, 'yuv.min=', 25.0)
('yuv.max=', 242.0, 'yuv.min=', 57.0)
('yuv.max=', 200.0, 'yuv.min=', 19.0)
('yuv.max=', 216.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 248.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 13.0)
('yuv.max=', 220.0, 'yuv.min=', 80.0)
('yuv.max=', 245.0, 'yuv.min=', 76.0)
('yuv.max=', 205.0, 'yuv.min=', 19.0)
('yuv.max=', 211.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 243.0, 'yuv.min=', 15.0)
('yuv.max=', 222.0, 'yuv.min=', 73.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 214.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 234.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 253.0, 'yuv.min=', 63.0)
('yuv.max=', 243.0, 'yuv.min=', 16.0)
('yuv.max=', 229.0, 'yuv.min=', 26.0)
('yuv.max=', 224.0, 'yuv.min=', 0.0)
('yuv.max=', 202.0, 'yuv.min=', 7.0)
('yuv.max=', 224.0, 'yuv.min=', 4.0)
('yuv.max=', 225.0, 'yuv.min=', 6.0)
('yuv.max=', 249.0, 'yuv.min=', 40.0)
('yuv.max=', 221.0, 'yuv.min=', 4.0)
('yuv.max=', 237.0, 'yuv.min=', 37.0)
('yuv.max=', 202.0, 'yuv.min=', 37.0)
('yuv.max=', 128.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 251.0, 'yuv.min=', 31.0)
('yuv.max=', 212.0, 'yuv.min=', 64.0)
('yuv.max=', 207.0, 'yuv.min=', 14.0)
('yuv.max=', 230.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 41.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 237.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 21.0)
('yuv.max=', 245.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 251.0, 'yuv.min=', 110.0)
('yuv.max=', 207.0, 'yuv.min=', 10.0)
('yuv.max=', 250.0, 'yuv.min=', 35.0)
('yuv.max=', 239.0, 'yuv.min=', 42.0)
('yuv.max=', 221.0, 'yuv.min=', 13.0)
('yuv.max=', 231.0, 'yuv.min=', 14.0)
('yuv.max=', 249.0, 'yuv.min=', 49.0)
('yuv.max=', 238.0, 'yuv.min=', 33.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 251.0, 'yuv.min=', 39.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 252.0, 'yuv.min=', 17.0)
('yuv.max=', 198.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 201.0, 'yuv.min=', 85.0)
('yuv.max=', 187.0, 'yuv.min=', 19.0)
('yuv.max=', 153.0, 'yuv.min=', 13.0)
('yuv.max=', 236.0, 'yuv.min=', 13.0)
('yuv.max=', 230.0, 'yuv.min=', 4.0)
('yuv.max=', 252.0, 'yuv.min=', 15.0)
('yuv.max=', 219.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 63.0)
('yuv.max=', 211.0, 'yuv.min=', 35.0)
('yuv.max=', 217.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 207.0, 'yuv.min=', 18.0)
('yuv.max=', 233.0, 'yuv.min=', 71.0)
('yuv.max=', 220.0, 'yuv.min=', 68.0)
('yuv.max=', 244.0, 'yuv.min=', 12.0)
('yuv.max=', 241.0, 'yuv.min=', 26.0)
('yuv.max=', 254.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 249.0, 'yuv.min=', 13.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 56.0)
('yuv.max=', 242.0, 'yuv.min=', 25.0)
('yuv.max=', 212.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 253.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 32.0)
('yuv.max=', 176.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 15.0)
('yuv.max=', 168.0, 'yuv.min=', 13.0)
('yuv.max=', 199.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 214.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 253.0, 'yuv.min=', 39.0)
('yuv.max=', 202.0, 'yuv.min=', 19.0)
('yuv.max=', 244.0, 'yuv.min=', 10.0)
('yuv.max=', 238.0, 'yuv.min=', 66.0)
('yuv.max=', 229.0, 'yuv.min=', 83.0)
('yuv.max=', 251.0, 'yuv.min=', 3.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 37.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 49.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 84.0)
('yuv.max=', 211.0, 'yuv.min=', 4.0)
('yuv.max=', 203.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 58.0)
('yuv.max=', 245.0, 'yuv.min=', 12.0)
('yuv.max=', 231.0, 'yuv.min=', 51.0)
('yuv.max=', 169.0, 'yuv.min=', 31.0)
('yuv.max=', 250.0, 'yuv.min=', 43.0)
('yuv.max=', 208.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 22.0)
('yuv.max=', 252.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 76.0)
('yuv.max=', 247.0, 'yuv.min=', 3.0)
('yuv.max=', 221.0, 'yuv.min=', 25.0)
('yuv.max=', 247.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 246.0, 'yuv.min=', 37.0)
('yuv.max=', 234.0, 'yuv.min=', 3.0)
('yuv.max=', 241.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 253.0, 'yuv.min=', 36.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 158.0, 'yuv.min=', 2.0)
('yuv.max=', 180.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 9.0)
('yuv.max=', 227.0, 'yuv.min=', 28.0)
('yuv.max=', 243.0, 'yuv.min=', 26.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 235.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 220.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 19.0)
('yuv.max=', 213.0, 'yuv.min=', 82.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 181.0, 'yuv.min=', 11.0)
('yuv.max=', 186.0, 'yuv.min=', 18.0)
('yuv.max=', 239.0, 'yuv.min=', 65.0)
('yuv.max=', 225.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 158.0, 'yuv.min=', 21.0)
('yuv.max=', 215.0, 'yuv.min=', 12.0)
('yuv.max=', 203.0, 'yuv.min=', 34.0)
('yuv.max=', 237.0, 'yuv.min=', 21.0)
('yuv.max=', 185.0, 'yuv.min=', 31.0)
('yuv.max=', 248.0, 'yuv.min=', 22.0)
('yuv.max=', 251.0, 'yuv.min=', 70.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 40.0)
('yuv.max=', 242.0, 'yuv.min=', 25.0)
('yuv.max=', 228.0, 'yuv.min=', 7.0)
('yuv.max=', 251.0, 'yuv.min=', 15.0)
('yuv.max=', 215.0, 'yuv.min=', 44.0)
('yuv.max=', 207.0, 'yuv.min=', 50.0)
('yuv.max=', 229.0, 'yuv.min=', 23.0)
('yuv.max=', 205.0, 'yuv.min=', 54.0)
('yuv.max=', 204.0, 'yuv.min=', 29.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 173.0, 'yuv.min=', 7.0)
('yuv.max=', 246.0, 'yuv.min=', 27.0)
('yuv.max=', 241.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 17.0)
('yuv.max=', 229.0, 'yuv.min=', 58.0)
('yuv.max=', 250.0, 'yuv.min=', 30.0)
('yuv.max=', 248.0, 'yuv.min=', 25.0)
('yuv.max=', 240.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 2.0)
('yuv.max=', 253.0, 'yuv.min=', 38.0)
('yuv.max=', 236.0, 'yuv.min=', 40.0)
('yuv.max=', 247.0, 'yuv.min=', 6.0)
('yuv.max=', 207.0, 'yuv.min=', 32.0)
('yuv.max=', 238.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 201.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 25.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 253.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 44.0)
('yuv.max=', 221.0, 'yuv.min=', 5.0)
('yuv.max=', 219.0, 'yuv.min=', 48.0)
('yuv.max=', 240.0, 'yuv.min=', 41.0)
('yuv.max=', 244.0, 'yuv.min=', 7.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 253.0, 'yuv.min=', 23.0)
('yuv.max=', 222.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 244.0, 'yuv.min=', 54.0)
('yuv.max=', 220.0, 'yuv.min=', 18.0)
('yuv.max=', 192.0, 'yuv.min=', 7.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 211.0, 'yuv.min=', 7.0)
('yuv.max=', 174.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 53.0)
('yuv.max=', 233.0, 'yuv.min=', 77.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 247.0, 'yuv.min=', 3.0)
('yuv.max=', 206.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 209.0, 'yuv.min=', 31.0)
('yuv.max=', 252.0, 'yuv.min=', 21.0)
('yuv.max=', 249.0, 'yuv.min=', 35.0)
('yuv.max=', 239.0, 'yuv.min=', 7.0)
('yuv.max=', 249.0, 'yuv.min=', 7.0)
('yuv.max=', 243.0, 'yuv.min=', 76.0)
('yuv.max=', 229.0, 'yuv.min=', 10.0)
('yuv.max=', 253.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 227.0, 'yuv.min=', 31.0)
('yuv.max=', 246.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 241.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 237.0, 'yuv.min=', 33.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 232.0, 'yuv.min=', 59.0)
('yuv.max=', 218.0, 'yuv.min=', 6.0)
('yuv.max=', 230.0, 'yuv.min=', 18.0)
('yuv.max=', 149.0, 'yuv.min=', 46.0)
('yuv.max=', 208.0, 'yuv.min=', 22.0)
('yuv.max=', 250.0, 'yuv.min=', 46.0)
('yuv.max=', 243.0, 'yuv.min=', 9.0)
('yuv.max=', 195.0, 'yuv.min=', 17.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 236.0, 'yuv.min=', 36.0)
('yuv.max=', 235.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 218.0, 'yuv.min=', 50.0)
('yuv.max=', 247.0, 'yuv.min=', 8.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 252.0, 'yuv.min=', 39.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 42.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 195.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 25.0)
('yuv.max=', 244.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 246.0, 'yuv.min=', 9.0)
('yuv.max=', 236.0, 'yuv.min=', 4.0)
('yuv.max=', 207.0, 'yuv.min=', 14.0)
('yuv.max=', 251.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 88.0)
('yuv.max=', 237.0, 'yuv.min=', 17.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 254.0, 'yuv.min=', 29.0)
('yuv.max=', 240.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 17.0)
('yuv.max=', 250.0, 'yuv.min=', 7.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 194.0, 'yuv.min=', 5.0)
('yuv.max=', 229.0, 'yuv.min=', 9.0)
('yuv.max=', 241.0, 'yuv.min=', 20.0)
('yuv.max=', 204.0, 'yuv.min=', 22.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 62.0)
('yuv.max=', 230.0, 'yuv.min=', 18.0)
('yuv.max=', 230.0, 'yuv.min=', 18.0)
('yuv.max=', 240.0, 'yuv.min=', 4.0)
('yuv.max=', 239.0, 'yuv.min=', 62.0)
('yuv.max=', 238.0, 'yuv.min=', 4.0)
('yuv.max=', 227.0, 'yuv.min=', 15.0)
('yuv.max=', 254.0, 'yuv.min=', 42.0)
('yuv.max=', 227.0, 'yuv.min=', 4.0)
('yuv.max=', 206.0, 'yuv.min=', 5.0)
('yuv.max=', 230.0, 'yuv.min=', 7.0)
('yuv.max=', 196.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 225.0, 'yuv.min=', 2.0)
('yuv.max=', 171.0, 'yuv.min=', 62.0)
('yuv.max=', 247.0, 'yuv.min=', 42.0)
('yuv.max=', 187.0, 'yuv.min=', 60.0)
('yuv.max=', 242.0, 'yuv.min=', 47.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 25.0)
('yuv.max=', 206.0, 'yuv.min=', 45.0)
('yuv.max=', 244.0, 'yuv.min=', 15.0)
('yuv.max=', 229.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 235.0, 'yuv.min=', 28.0)
('yuv.max=', 249.0, 'yuv.min=', 1.0)
('yuv.max=', 162.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 253.0, 'yuv.min=', 20.0)
('yuv.max=', 246.0, 'yuv.min=', 5.0)
('yuv.max=', 242.0, 'yuv.min=', 9.0)
('yuv.max=', 244.0, 'yuv.min=', 2.0)
('yuv.max=', 180.0, 'yuv.min=', 66.0)
('yuv.max=', 236.0, 'yuv.min=', 33.0)
('yuv.max=', 195.0, 'yuv.min=', 16.0)
('yuv.max=', 212.0, 'yuv.min=', 10.0)
('yuv.max=', 227.0, 'yuv.min=', 46.0)
('yuv.max=', 235.0, 'yuv.min=', 0.0)
('yuv.max=', 235.0, 'yuv.min=', 7.0)
('yuv.max=', 206.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 249.0, 'yuv.min=', 46.0)
('yuv.max=', 225.0, 'yuv.min=', 11.0)
('yuv.max=', 244.0, 'yuv.min=', 37.0)
('yuv.max=', 252.0, 'yuv.min=', 72.0)
('yuv.max=', 248.0, 'yuv.min=', 62.0)
('yuv.max=', 255.0, 'yuv.min=', 57.0)
('yuv.max=', 221.0, 'yuv.min=', 12.0)
('yuv.max=', 247.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 226.0, 'yuv.min=', 15.0)
('yuv.max=', 202.0, 'yuv.min=', 34.0)
('yuv.max=', 248.0, 'yuv.min=', 50.0)
('yuv.max=', 221.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 253.0, 'yuv.min=', 46.0)
('yuv.max=', 244.0, 'yuv.min=', 45.0)
('yuv.max=', 163.0, 'yuv.min=', 52.0)
('yuv.max=', 194.0, 'yuv.min=', 28.0)
('yuv.max=', 224.0, 'yuv.min=', 25.0)
('yuv.max=', 232.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 250.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 244.0, 'yuv.min=', 19.0)
('yuv.max=', 237.0, 'yuv.min=', 67.0)
('yuv.max=', 247.0, 'yuv.min=', 52.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 225.0, 'yuv.min=', 47.0)
('yuv.max=', 212.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 211.0, 'yuv.min=', 9.0)
('yuv.max=', 243.0, 'yuv.min=', 6.0)
('yuv.max=', 231.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 9.0)
('yuv.max=', 239.0, 'yuv.min=', 19.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 57.0)
('yuv.max=', 252.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 239.0, 'yuv.min=', 9.0)
('yuv.max=', 234.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 14.0)
('yuv.max=', 156.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 238.0, 'yuv.min=', 49.0)
('yuv.max=', 200.0, 'yuv.min=', 4.0)
('yuv.max=', 238.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 248.0, 'yuv.min=', 32.0)
('yuv.max=', 222.0, 'yuv.min=', 42.0)
('yuv.max=', 230.0, 'yuv.min=', 59.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 218.0, 'yuv.min=', 92.0)
('yuv.max=', 234.0, 'yuv.min=', 26.0)
('yuv.max=', 234.0, 'yuv.min=', 32.0)
('yuv.max=', 215.0, 'yuv.min=', 33.0)
('yuv.max=', 247.0, 'yuv.min=', 52.0)
('yuv.max=', 223.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 141.0, 'yuv.min=', 11.0)
('yuv.max=', 249.0, 'yuv.min=', 60.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 237.0, 'yuv.min=', 38.0)
('yuv.max=', 243.0, 'yuv.min=', 46.0)
('yuv.max=', 224.0, 'yuv.min=', 24.0)
('yuv.max=', 188.0, 'yuv.min=', 23.0)
('yuv.max=', 245.0, 'yuv.min=', 32.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 243.0, 'yuv.min=', 41.0)
('yuv.max=', 208.0, 'yuv.min=', 27.0)
('yuv.max=', 202.0, 'yuv.min=', 44.0)
('yuv.max=', 247.0, 'yuv.min=', 33.0)
('yuv.max=', 237.0, 'yuv.min=', 38.0)
('yuv.max=', 234.0, 'yuv.min=', 28.0)
('yuv.max=', 248.0, 'yuv.min=', 17.0)
('yuv.max=', 214.0, 'yuv.min=', 18.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 229.0, 'yuv.min=', 45.0)
('yuv.max=', 149.0, 'yuv.min=', 5.0)
('yuv.max=', 206.0, 'yuv.min=', 21.0)
('yuv.max=', 224.0, 'yuv.min=', 28.0)
('yuv.max=', 250.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 36.0)
('yuv.max=', 207.0, 'yuv.min=', 15.0)
('yuv.max=', 169.0, 'yuv.min=', 47.0)
('yuv.max=', 241.0, 'yuv.min=', 24.0)
('yuv.max=', 225.0, 'yuv.min=', 52.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 168.0, 'yuv.min=', 8.0)
('yuv.max=', 188.0, 'yuv.min=', 16.0)
('yuv.max=', 238.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 74.0)
('yuv.max=', 195.0, 'yuv.min=', 17.0)
('yuv.max=', 218.0, 'yuv.min=', 27.0)
('yuv.max=', 238.0, 'yuv.min=', 49.0)
('yuv.max=', 238.0, 'yuv.min=', 15.0)
('yuv.max=', 210.0, 'yuv.min=', 21.0)
('yuv.max=', 180.0, 'yuv.min=', 46.0)
('yuv.max=', 221.0, 'yuv.min=', 43.0)
('yuv.max=', 190.0, 'yuv.min=', 41.0)
('yuv.max=', 242.0, 'yuv.min=', 5.0)
('yuv.max=', 236.0, 'yuv.min=', 50.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 219.0, 'yuv.min=', 60.0)
('yuv.max=', 210.0, 'yuv.min=', 0.0)
('yuv.max=', 242.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 34.0)
('yuv.max=', 245.0, 'yuv.min=', 9.0)
('yuv.max=', 204.0, 'yuv.min=', 11.0)
('yuv.max=', 211.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 1.0)
('yuv.max=', 220.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 234.0, 'yuv.min=', 12.0)
('yuv.max=', 248.0, 'yuv.min=', 27.0)
('yuv.max=', 223.0, 'yuv.min=', 1.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 212.0, 'yuv.min=', 47.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 168.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 235.0, 'yuv.min=', 20.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 215.0, 'yuv.min=', 21.0)
('yuv.max=', 200.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 250.0, 'yuv.min=', 14.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 27.0)
('yuv.max=', 188.0, 'yuv.min=', 1.0)
('yuv.max=', 213.0, 'yuv.min=', 26.0)
('yuv.max=', 232.0, 'yuv.min=', 19.0)
('yuv.max=', 213.0, 'yuv.min=', 43.0)
('yuv.max=', 185.0, 'yuv.min=', 47.0)
('yuv.max=', 168.0, 'yuv.min=', 27.0)
('yuv.max=', 249.0, 'yuv.min=', 6.0)
('yuv.max=', 250.0, 'yuv.min=', 6.0)
('yuv.max=', 226.0, 'yuv.min=', 42.0)
('yuv.max=', 254.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 77.0)
('yuv.max=', 237.0, 'yuv.min=', 32.0)
('yuv.max=', 207.0, 'yuv.min=', 34.0)
('yuv.max=', 198.0, 'yuv.min=', 34.0)
('yuv.max=', 231.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 249.0, 'yuv.min=', 21.0)
('yuv.max=', 249.0, 'yuv.min=', 1.0)
('yuv.max=', 210.0, 'yuv.min=', 26.0)
('yuv.max=', 192.0, 'yuv.min=', 0.0)
('yuv.max=', 213.0, 'yuv.min=', 46.0)
('yuv.max=', 231.0, 'yuv.min=', 30.0)
('yuv.max=', 227.0, 'yuv.min=', 7.0)
('yuv.max=', 249.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 55.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 107.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 67.0)
('yuv.max=', 242.0, 'yuv.min=', 45.0)
('yuv.max=', 236.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 241.0, 'yuv.min=', 52.0)
('yuv.max=', 254.0, 'yuv.min=', 26.0)
('yuv.max=', 202.0, 'yuv.min=', 62.0)
('yuv.max=', 227.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 226.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 49.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 183.0, 'yuv.min=', 31.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 150.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 234.0, 'yuv.min=', 11.0)
('yuv.max=', 235.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 73.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 193.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 20.0)
('yuv.max=', 234.0, 'yuv.min=', 31.0)
('yuv.max=', 251.0, 'yuv.min=', 12.0)
('yuv.max=', 239.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 216.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 216.0, 'yuv.min=', 44.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 203.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 118.0)
('yuv.max=', 210.0, 'yuv.min=', 23.0)
('yuv.max=', 195.0, 'yuv.min=', 27.0)
('yuv.max=', 216.0, 'yuv.min=', 24.0)
('yuv.max=', 229.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 244.0, 'yuv.min=', 22.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 252.0, 'yuv.min=', 22.0)
('yuv.max=', 240.0, 'yuv.min=', 12.0)
('yuv.max=', 242.0, 'yuv.min=', 28.0)
('yuv.max=', 236.0, 'yuv.min=', 107.0)
('yuv.max=', 246.0, 'yuv.min=', 33.0)
('yuv.max=', 208.0, 'yuv.min=', 8.0)
('yuv.max=', 194.0, 'yuv.min=', 58.0)
('yuv.max=', 246.0, 'yuv.min=', 56.0)
('yuv.max=', 231.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 75.0)
('yuv.max=', 239.0, 'yuv.min=', 35.0)
('yuv.max=', 251.0, 'yuv.min=', 13.0)
('yuv.max=', 231.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 187.0, 'yuv.min=', 22.0)
('yuv.max=', 248.0, 'yuv.min=', 18.0)
('yuv.max=', 240.0, 'yuv.min=', 33.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 16.0)
('yuv.max=', 220.0, 'yuv.min=', 39.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 236.0, 'yuv.min=', 4.0)
('yuv.max=', 219.0, 'yuv.min=', 8.0)
('yuv.max=', 207.0, 'yuv.min=', 22.0)
('yuv.max=', 212.0, 'yuv.min=', 41.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 252.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 206.0, 'yuv.min=', 16.0)
('yuv.max=', 233.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 6.0)
('yuv.max=', 185.0, 'yuv.min=', 10.0)
('yuv.max=', 222.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 215.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 41.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 9.0)
('yuv.max=', 190.0, 'yuv.min=', 13.0)
('yuv.max=', 206.0, 'yuv.min=', 35.0)
('yuv.max=', 198.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 15.0)
('yuv.max=', 199.0, 'yuv.min=', 38.0)
('yuv.max=', 227.0, 'yuv.min=', 15.0)
('yuv.max=', 192.0, 'yuv.min=', 29.0)
('yuv.max=', 253.0, 'yuv.min=', 31.0)
('yuv.max=', 221.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 246.0, 'yuv.min=', 34.0)
('yuv.max=', 250.0, 'yuv.min=', 83.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 100.0)
('yuv.max=', 219.0, 'yuv.min=', 32.0)
('yuv.max=', 248.0, 'yuv.min=', 61.0)
('yuv.max=', 246.0, 'yuv.min=', 10.0)
('yuv.max=', 243.0, 'yuv.min=', 18.0)
('yuv.max=', 241.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 15.0)
('yuv.max=', 254.0, 'yuv.min=', 31.0)
('yuv.max=', 237.0, 'yuv.min=', 1.0)
('yuv.max=', 184.0, 'yuv.min=', 15.0)
('yuv.max=', 226.0, 'yuv.min=', 32.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 249.0, 'yuv.min=', 18.0)
('yuv.max=', 226.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 250.0, 'yuv.min=', 93.0)
('yuv.max=', 244.0, 'yuv.min=', 43.0)
('yuv.max=', 251.0, 'yuv.min=', 35.0)
('yuv.max=', 253.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 80.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 10.0)
('yuv.max=', 249.0, 'yuv.min=', 3.0)
('yuv.max=', 247.0, 'yuv.min=', 21.0)
('yuv.max=', 216.0, 'yuv.min=', 5.0)
('yuv.max=', 198.0, 'yuv.min=', 30.0)
('yuv.max=', 245.0, 'yuv.min=', 35.0)
('yuv.max=', 239.0, 'yuv.min=', 12.0)
('yuv.max=', 212.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 1.0)
('yuv.max=', 247.0, 'yuv.min=', 24.0)
('yuv.max=', 249.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 77.0)
('yuv.max=', 186.0, 'yuv.min=', 33.0)
('yuv.max=', 242.0, 'yuv.min=', 19.0)
('yuv.max=', 234.0, 'yuv.min=', 16.0)
('yuv.max=', 239.0, 'yuv.min=', 40.0)
('yuv.max=', 192.0, 'yuv.min=', 33.0)
('yuv.max=', 248.0, 'yuv.min=', 36.0)
('yuv.max=', 167.0, 'yuv.min=', 24.0)
('yuv.max=', 236.0, 'yuv.min=', 63.0)
('yuv.max=', 160.0, 'yuv.min=', 44.0)
('yuv.max=', 243.0, 'yuv.min=', 10.0)
('yuv.max=', 233.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 197.0, 'yuv.min=', 26.0)
('yuv.max=', 242.0, 'yuv.min=', 32.0)
('yuv.max=', 244.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 207.0, 'yuv.min=', 53.0)
('yuv.max=', 254.0, 'yuv.min=', 50.0)
('yuv.max=', 242.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 233.0, 'yuv.min=', 80.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 24.0)
('yuv.max=', 242.0, 'yuv.min=', 49.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 21.0)
('yuv.max=', 251.0, 'yuv.min=', 14.0)
('yuv.max=', 238.0, 'yuv.min=', 70.0)
('yuv.max=', 222.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 206.0, 'yuv.min=', 36.0)
('yuv.max=', 244.0, 'yuv.min=', 25.0)
('yuv.max=', 236.0, 'yuv.min=', 69.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 5.0)
('yuv.max=', 225.0, 'yuv.min=', 7.0)
('yuv.max=', 215.0, 'yuv.min=', 59.0)
('yuv.max=', 254.0, 'yuv.min=', 14.0)
('yuv.max=', 238.0, 'yuv.min=', 2.0)
('yuv.max=', 242.0, 'yuv.min=', 9.0)
('yuv.max=', 203.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 24.0)
('yuv.max=', 249.0, 'yuv.min=', 117.0)
('yuv.max=', 189.0, 'yuv.min=', 53.0)
('yuv.max=', 237.0, 'yuv.min=', 16.0)
('yuv.max=', 253.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 175.0, 'yuv.min=', 34.0)
('yuv.max=', 238.0, 'yuv.min=', 51.0)
('yuv.max=', 233.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 41.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 13.0)
('yuv.max=', 193.0, 'yuv.min=', 18.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 206.0, 'yuv.min=', 0.0)
('yuv.max=', 156.0, 'yuv.min=', 54.0)
('yuv.max=', 205.0, 'yuv.min=', 37.0)
('yuv.max=', 201.0, 'yuv.min=', 34.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 44.0)
('yuv.max=', 246.0, 'yuv.min=', 3.0)
('yuv.max=', 159.0, 'yuv.min=', 38.0)
('yuv.max=', 251.0, 'yuv.min=', 43.0)
('yuv.max=', 243.0, 'yuv.min=', 40.0)
('yuv.max=', 246.0, 'yuv.min=', 7.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 210.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 30.0)
('yuv.max=', 250.0, 'yuv.min=', 5.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 20.0)
('yuv.max=', 211.0, 'yuv.min=', 16.0)
('yuv.max=', 227.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 32.0)
('yuv.max=', 149.0, 'yuv.min=', 14.0)
('yuv.max=', 247.0, 'yuv.min=', 31.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 229.0, 'yuv.min=', 60.0)
('yuv.max=', 254.0, 'yuv.min=', 37.0)
('yuv.max=', 252.0, 'yuv.min=', 55.0)
('yuv.max=', 240.0, 'yuv.min=', 29.0)
('yuv.max=', 241.0, 'yuv.min=', 51.0)
('yuv.max=', 214.0, 'yuv.min=', 52.0)
('yuv.max=', 247.0, 'yuv.min=', 25.0)
('yuv.max=', 190.0, 'yuv.min=', 29.0)
('yuv.max=', 213.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 189.0, 'yuv.min=', 12.0)
('yuv.max=', 251.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 18.0)
('yuv.max=', 225.0, 'yuv.min=', 31.0)
('yuv.max=', 252.0, 'yuv.min=', 7.0)
('yuv.max=', 232.0, 'yuv.min=', 62.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 38.0)
('yuv.max=', 170.0, 'yuv.min=', 19.0)
('yuv.max=', 247.0, 'yuv.min=', 16.0)
('yuv.max=', 251.0, 'yuv.min=', 12.0)
('yuv.max=', 192.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 239.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 73.0)
('yuv.max=', 230.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 233.0, 'yuv.min=', 10.0)
('yuv.max=', 230.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 252.0, 'yuv.min=', 74.0)
('yuv.max=', 207.0, 'yuv.min=', 9.0)
('yuv.max=', 252.0, 'yuv.min=', 6.0)
('yuv.max=', 196.0, 'yuv.min=', 20.0)
('yuv.max=', 252.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 230.0, 'yuv.min=', 9.0)
('yuv.max=', 239.0, 'yuv.min=', 11.0)
('yuv.max=', 204.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 56.0)
('yuv.max=', 174.0, 'yuv.min=', 5.0)
('yuv.max=', 249.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 213.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 188.0, 'yuv.min=', 5.0)
('yuv.max=', 226.0, 'yuv.min=', 20.0)
('yuv.max=', 212.0, 'yuv.min=', 90.0)
('yuv.max=', 230.0, 'yuv.min=', 24.0)
('yuv.max=', 214.0, 'yuv.min=', 23.0)
('yuv.max=', 182.0, 'yuv.min=', 23.0)
('yuv.max=', 219.0, 'yuv.min=', 18.0)
('yuv.max=', 248.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 69.0)
('yuv.max=', 224.0, 'yuv.min=', 24.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 182.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 192.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 233.0, 'yuv.min=', 35.0)
('yuv.max=', 236.0, 'yuv.min=', 22.0)
('yuv.max=', 205.0, 'yuv.min=', 51.0)
('yuv.max=', 243.0, 'yuv.min=', 22.0)
('yuv.max=', 231.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 65.0)
('yuv.max=', 235.0, 'yuv.min=', 36.0)
('yuv.max=', 184.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 250.0, 'yuv.min=', 27.0)
('yuv.max=', 181.0, 'yuv.min=', 64.0)
('yuv.max=', 243.0, 'yuv.min=', 30.0)
('yuv.max=', 253.0, 'yuv.min=', 64.0)
('yuv.max=', 203.0, 'yuv.min=', 10.0)
('yuv.max=', 252.0, 'yuv.min=', 68.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 212.0, 'yuv.min=', 16.0)
('yuv.max=', 206.0, 'yuv.min=', 94.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 222.0, 'yuv.min=', 40.0)
('yuv.max=', 239.0, 'yuv.min=', 66.0)
('yuv.max=', 226.0, 'yuv.min=', 67.0)
('yuv.max=', 232.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 240.0, 'yuv.min=', 39.0)
('yuv.max=', 237.0, 'yuv.min=', 34.0)
('yuv.max=', 242.0, 'yuv.min=', 52.0)
('yuv.max=', 221.0, 'yuv.min=', 53.0)
('yuv.max=', 236.0, 'yuv.min=', 29.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 6.0)
('yuv.max=', 219.0, 'yuv.min=', 56.0)
('yuv.max=', 254.0, 'yuv.min=', 30.0)
('yuv.max=', 242.0, 'yuv.min=', 12.0)
('yuv.max=', 185.0, 'yuv.min=', 16.0)
('yuv.max=', 238.0, 'yuv.min=', 20.0)
('yuv.max=', 236.0, 'yuv.min=', 16.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 249.0, 'yuv.min=', 10.0)
('yuv.max=', 199.0, 'yuv.min=', 15.0)
('yuv.max=', 222.0, 'yuv.min=', 36.0)
('yuv.max=', 234.0, 'yuv.min=', 30.0)
('yuv.max=', 210.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 32.0)
('yuv.max=', 218.0, 'yuv.min=', 37.0)
('yuv.max=', 235.0, 'yuv.min=', 9.0)
('yuv.max=', 222.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 15.0)
('yuv.max=', 223.0, 'yuv.min=', 6.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 223.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 247.0, 'yuv.min=', 32.0)
('yuv.max=', 226.0, 'yuv.min=', 9.0)
('yuv.max=', 223.0, 'yuv.min=', 14.0)
('yuv.max=', 220.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 234.0, 'yuv.min=', 15.0)
('yuv.max=', 224.0, 'yuv.min=', 24.0)
('yuv.max=', 234.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 179.0, 'yuv.min=', 11.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 230.0, 'yuv.min=', 21.0)
('yuv.max=', 227.0, 'yuv.min=', 66.0)
('yuv.max=', 208.0, 'yuv.min=', 51.0)
('yuv.max=', 253.0, 'yuv.min=', 39.0)
('yuv.max=', 244.0, 'yuv.min=', 73.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 234.0, 'yuv.min=', 6.0)
('yuv.max=', 249.0, 'yuv.min=', 6.0)
('yuv.max=', 253.0, 'yuv.min=', 20.0)
('yuv.max=', 236.0, 'yuv.min=', 15.0)
('yuv.max=', 245.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 208.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 222.0, 'yuv.min=', 31.0)
('yuv.max=', 228.0, 'yuv.min=', 58.0)
('yuv.max=', 228.0, 'yuv.min=', 43.0)
('yuv.max=', 192.0, 'yuv.min=', 29.0)
('yuv.max=', 229.0, 'yuv.min=', 10.0)
('yuv.max=', 216.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 236.0, 'yuv.min=', 29.0)
('yuv.max=', 174.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 39.0)
('yuv.max=', 202.0, 'yuv.min=', 102.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 240.0, 'yuv.min=', 38.0)
('yuv.max=', 224.0, 'yuv.min=', 25.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 239.0, 'yuv.min=', 11.0)
('yuv.max=', 234.0, 'yuv.min=', 33.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 186.0, 'yuv.min=', 23.0)
('yuv.max=', 227.0, 'yuv.min=', 57.0)
('yuv.max=', 223.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 26.0)
('yuv.max=', 239.0, 'yuv.min=', 1.0)
('yuv.max=', 245.0, 'yuv.min=', 5.0)
('yuv.max=', 231.0, 'yuv.min=', 13.0)
('yuv.max=', 169.0, 'yuv.min=', 35.0)
('yuv.max=', 226.0, 'yuv.min=', 86.0)
('yuv.max=', 176.0, 'yuv.min=', 69.0)
('yuv.max=', 255.0, 'yuv.min=', 57.0)
('yuv.max=', 253.0, 'yuv.min=', 28.0)
('yuv.max=', 246.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 24.0)
('yuv.max=', 235.0, 'yuv.min=', 17.0)
('yuv.max=', 246.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 207.0, 'yuv.min=', 77.0)
('yuv.max=', 174.0, 'yuv.min=', 22.0)
('yuv.max=', 253.0, 'yuv.min=', 12.0)
('yuv.max=', 215.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 251.0, 'yuv.min=', 11.0)
('yuv.max=', 250.0, 'yuv.min=', 48.0)
('yuv.max=', 233.0, 'yuv.min=', 77.0)
('yuv.max=', 217.0, 'yuv.min=', 13.0)
('yuv.max=', 235.0, 'yuv.min=', 27.0)
('yuv.max=', 253.0, 'yuv.min=', 74.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 246.0, 'yuv.min=', 21.0)
('yuv.max=', 238.0, 'yuv.min=', 37.0)
('yuv.max=', 239.0, 'yuv.min=', 29.0)
('yuv.max=', 252.0, 'yuv.min=', 37.0)
('yuv.max=', 200.0, 'yuv.min=', 41.0)
('yuv.max=', 243.0, 'yuv.min=', 19.0)
('yuv.max=', 207.0, 'yuv.min=', 21.0)
('yuv.max=', 211.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 243.0, 'yuv.min=', 33.0)
('yuv.max=', 246.0, 'yuv.min=', 16.0)
('yuv.max=', 240.0, 'yuv.min=', 33.0)
('yuv.max=', 179.0, 'yuv.min=', 13.0)
('yuv.max=', 225.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 190.0, 'yuv.min=', 31.0)
('yuv.max=', 222.0, 'yuv.min=', 29.0)
('yuv.max=', 231.0, 'yuv.min=', 1.0)
('yuv.max=', 164.0, 'yuv.min=', 22.0)
('yuv.max=', 239.0, 'yuv.min=', 57.0)
('yuv.max=', 245.0, 'yuv.min=', 34.0)
('yuv.max=', 240.0, 'yuv.min=', 57.0)
('yuv.max=', 249.0, 'yuv.min=', 16.0)
('yuv.max=', 247.0, 'yuv.min=', 13.0)
('yuv.max=', 210.0, 'yuv.min=', 3.0)
('yuv.max=', 217.0, 'yuv.min=', 66.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 212.0, 'yuv.min=', 24.0)
('yuv.max=', 242.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 230.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 70.0)
('yuv.max=', 206.0, 'yuv.min=', 58.0)
('yuv.max=', 215.0, 'yuv.min=', 50.0)
('yuv.max=', 233.0, 'yuv.min=', 22.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 250.0, 'yuv.min=', 66.0)
('yuv.max=', 234.0, 'yuv.min=', 18.0)
('yuv.max=', 228.0, 'yuv.min=', 49.0)
('yuv.max=', 224.0, 'yuv.min=', 3.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 82.0)
('yuv.max=', 218.0, 'yuv.min=', 19.0)
('yuv.max=', 243.0, 'yuv.min=', 16.0)
('yuv.max=', 236.0, 'yuv.min=', 37.0)
('yuv.max=', 200.0, 'yuv.min=', 29.0)
('yuv.max=', 231.0, 'yuv.min=', 29.0)
('yuv.max=', 247.0, 'yuv.min=', 8.0)
('yuv.max=', 158.0, 'yuv.min=', 23.0)
('yuv.max=', 251.0, 'yuv.min=', 28.0)
('yuv.max=', 172.0, 'yuv.min=', 21.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 228.0, 'yuv.min=', 32.0)
('yuv.max=', 214.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 9.0)
('yuv.max=', 242.0, 'yuv.min=', 1.0)
('yuv.max=', 238.0, 'yuv.min=', 34.0)
('yuv.max=', 234.0, 'yuv.min=', 25.0)
('yuv.max=', 171.0, 'yuv.min=', 20.0)
('yuv.max=', 228.0, 'yuv.min=', 26.0)
('yuv.max=', 249.0, 'yuv.min=', 36.0)
('yuv.max=', 239.0, 'yuv.min=', 9.0)
('yuv.max=', 218.0, 'yuv.min=', 31.0)
('yuv.max=', 250.0, 'yuv.min=', 23.0)
('yuv.max=', 203.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 182.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 26.0)
('yuv.max=', 248.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 252.0, 'yuv.min=', 37.0)
('yuv.max=', 226.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 63.0)
('yuv.max=', 215.0, 'yuv.min=', 30.0)
('yuv.max=', 212.0, 'yuv.min=', 58.0)
('yuv.max=', 243.0, 'yuv.min=', 9.0)
('yuv.max=', 226.0, 'yuv.min=', 24.0)
('yuv.max=', 223.0, 'yuv.min=', 54.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 218.0, 'yuv.min=', 62.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 245.0, 'yuv.min=', 23.0)
('yuv.max=', 236.0, 'yuv.min=', 60.0)
('yuv.max=', 242.0, 'yuv.min=', 50.0)
('yuv.max=', 248.0, 'yuv.min=', 11.0)
('yuv.max=', 245.0, 'yuv.min=', 18.0)
('yuv.max=', 236.0, 'yuv.min=', 40.0)
('yuv.max=', 236.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 43.0)
('yuv.max=', 226.0, 'yuv.min=', 57.0)
('yuv.max=', 219.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 230.0, 'yuv.min=', 48.0)
('yuv.max=', 174.0, 'yuv.min=', 21.0)
('yuv.max=', 239.0, 'yuv.min=', 3.0)
('yuv.max=', 236.0, 'yuv.min=', 10.0)
('yuv.max=', 254.0, 'yuv.min=', 38.0)
('yuv.max=', 201.0, 'yuv.min=', 24.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 207.0, 'yuv.min=', 11.0)
('yuv.max=', 248.0, 'yuv.min=', 30.0)
('yuv.max=', 244.0, 'yuv.min=', 29.0)
('yuv.max=', 192.0, 'yuv.min=', 49.0)
('yuv.max=', 241.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 243.0, 'yuv.min=', 55.0)
('yuv.max=', 219.0, 'yuv.min=', 28.0)
('yuv.max=', 213.0, 'yuv.min=', 18.0)
('yuv.max=', 227.0, 'yuv.min=', 16.0)
('yuv.max=', 248.0, 'yuv.min=', 25.0)
('yuv.max=', 197.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 233.0, 'yuv.min=', 68.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 195.0, 'yuv.min=', 24.0)
('yuv.max=', 242.0, 'yuv.min=', 20.0)
('yuv.max=', 248.0, 'yuv.min=', 44.0)
('yuv.max=', 248.0, 'yuv.min=', 10.0)
('yuv.max=', 154.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 39.0)
('yuv.max=', 241.0, 'yuv.min=', 44.0)
('yuv.max=', 225.0, 'yuv.min=', 27.0)
('yuv.max=', 242.0, 'yuv.min=', 67.0)
('yuv.max=', 246.0, 'yuv.min=', 25.0)
('yuv.max=', 227.0, 'yuv.min=', 11.0)
('yuv.max=', 248.0, 'yuv.min=', 21.0)
('yuv.max=', 240.0, 'yuv.min=', 19.0)
('yuv.max=', 188.0, 'yuv.min=', 1.0)
('yuv.max=', 221.0, 'yuv.min=', 11.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 243.0, 'yuv.min=', 20.0)
('yuv.max=', 235.0, 'yuv.min=', 15.0)
('yuv.max=', 248.0, 'yuv.min=', 36.0)
('yuv.max=', 196.0, 'yuv.min=', 27.0)
('yuv.max=', 242.0, 'yuv.min=', 25.0)
('yuv.max=', 248.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 242.0, 'yuv.min=', 51.0)
('yuv.max=', 236.0, 'yuv.min=', 18.0)
('yuv.max=', 212.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 253.0, 'yuv.min=', 23.0)
('yuv.max=', 250.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 223.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 245.0, 'yuv.min=', 4.0)
('yuv.max=', 226.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 40.0)
('yuv.max=', 199.0, 'yuv.min=', 25.0)
('yuv.max=', 225.0, 'yuv.min=', 54.0)
('yuv.max=', 241.0, 'yuv.min=', 29.0)
('yuv.max=', 230.0, 'yuv.min=', 42.0)
('yuv.max=', 230.0, 'yuv.min=', 71.0)
('yuv.max=', 231.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 204.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 206.0, 'yuv.min=', 16.0)
('yuv.max=', 243.0, 'yuv.min=', 41.0)
('yuv.max=', 194.0, 'yuv.min=', 22.0)
('yuv.max=', 254.0, 'yuv.min=', 59.0)
('yuv.max=', 192.0, 'yuv.min=', 31.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 219.0, 'yuv.min=', 29.0)
('yuv.max=', 212.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 14.0)
('yuv.max=', 199.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 195.0, 'yuv.min=', 11.0)
('yuv.max=', 193.0, 'yuv.min=', 47.0)
('yuv.max=', 150.0, 'yuv.min=', 54.0)
('yuv.max=', 243.0, 'yuv.min=', 58.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 247.0, 'yuv.min=', 48.0)
('yuv.max=', 252.0, 'yuv.min=', 25.0)
('yuv.max=', 214.0, 'yuv.min=', 65.0)
('yuv.max=', 232.0, 'yuv.min=', 18.0)
('yuv.max=', 190.0, 'yuv.min=', 17.0)
('yuv.max=', 209.0, 'yuv.min=', 15.0)
('yuv.max=', 218.0, 'yuv.min=', 41.0)
('yuv.max=', 232.0, 'yuv.min=', 48.0)
('yuv.max=', 183.0, 'yuv.min=', 61.0)
('yuv.max=', 232.0, 'yuv.min=', 50.0)
('yuv.max=', 247.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 60.0)
('yuv.max=', 178.0, 'yuv.min=', 20.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 235.0, 'yuv.min=', 9.0)
('yuv.max=', 223.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 249.0, 'yuv.min=', 27.0)
('yuv.max=', 200.0, 'yuv.min=', 8.0)
('yuv.max=', 146.0, 'yuv.min=', 25.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 236.0, 'yuv.min=', 20.0)
('yuv.max=', 202.0, 'yuv.min=', 20.0)
('yuv.max=', 227.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 22.0)
('yuv.max=', 237.0, 'yuv.min=', 4.0)
('yuv.max=', 250.0, 'yuv.min=', 26.0)
('yuv.max=', 249.0, 'yuv.min=', 21.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 235.0, 'yuv.min=', 50.0)
('yuv.max=', 169.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 41.0)
('yuv.max=', 208.0, 'yuv.min=', 17.0)
('yuv.max=', 206.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 40.0)
('yuv.max=', 231.0, 'yuv.min=', 38.0)
('yuv.max=', 243.0, 'yuv.min=', 11.0)
('yuv.max=', 234.0, 'yuv.min=', 40.0)
('yuv.max=', 252.0, 'yuv.min=', 78.0)
('yuv.max=', 188.0, 'yuv.min=', 49.0)
('yuv.max=', 225.0, 'yuv.min=', 48.0)
('yuv.max=', 247.0, 'yuv.min=', 6.0)
('yuv.max=', 244.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 247.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 232.0, 'yuv.min=', 33.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 68.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 247.0, 'yuv.min=', 4.0)
('yuv.max=', 224.0, 'yuv.min=', 4.0)
('yuv.max=', 227.0, 'yuv.min=', 10.0)
('yuv.max=', 251.0, 'yuv.min=', 42.0)
('yuv.max=', 162.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 49.0)
('yuv.max=', 253.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 187.0, 'yuv.min=', 27.0)
('yuv.max=', 170.0, 'yuv.min=', 11.0)
('yuv.max=', 220.0, 'yuv.min=', 29.0)
('yuv.max=', 218.0, 'yuv.min=', 13.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 182.0, 'yuv.min=', 9.0)
('yuv.max=', 240.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 248.0, 'yuv.min=', 33.0)
('yuv.max=', 219.0, 'yuv.min=', 43.0)
('yuv.max=', 252.0, 'yuv.min=', 3.0)
('yuv.max=', 187.0, 'yuv.min=', 27.0)
('yuv.max=', 251.0, 'yuv.min=', 32.0)
('yuv.max=', 233.0, 'yuv.min=', 20.0)
('yuv.max=', 226.0, 'yuv.min=', 16.0)
('yuv.max=', 243.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 56.0)
('yuv.max=', 230.0, 'yuv.min=', 64.0)
('yuv.max=', 235.0, 'yuv.min=', 27.0)
('yuv.max=', 241.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 250.0, 'yuv.min=', 11.0)
('yuv.max=', 236.0, 'yuv.min=', 59.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 224.0, 'yuv.min=', 13.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 233.0, 'yuv.min=', 15.0)
('yuv.max=', 189.0, 'yuv.min=', 19.0)
('yuv.max=', 165.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 241.0, 'yuv.min=', 11.0)
('yuv.max=', 187.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 249.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 187.0, 'yuv.min=', 39.0)
('yuv.max=', 251.0, 'yuv.min=', 46.0)
('yuv.max=', 210.0, 'yuv.min=', 86.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 203.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 22.0)
('yuv.max=', 219.0, 'yuv.min=', 29.0)
('yuv.max=', 247.0, 'yuv.min=', 34.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 239.0, 'yuv.min=', 36.0)
('yuv.max=', 211.0, 'yuv.min=', 11.0)
('yuv.max=', 240.0, 'yuv.min=', 32.0)
('yuv.max=', 239.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 19.0)
('yuv.max=', 212.0, 'yuv.min=', 32.0)
('yuv.max=', 190.0, 'yuv.min=', 23.0)
('yuv.max=', 235.0, 'yuv.min=', 46.0)
('yuv.max=', 203.0, 'yuv.min=', 23.0)
('yuv.max=', 235.0, 'yuv.min=', 11.0)
('yuv.max=', 194.0, 'yuv.min=', 20.0)
('yuv.max=', 240.0, 'yuv.min=', 92.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 209.0, 'yuv.min=', 48.0)
('yuv.max=', 227.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 23.0)
('yuv.max=', 242.0, 'yuv.min=', 46.0)
('yuv.max=', 208.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 9.0)
('yuv.max=', 235.0, 'yuv.min=', 20.0)
('yuv.max=', 236.0, 'yuv.min=', 2.0)
('yuv.max=', 241.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 179.0, 'yuv.min=', 0.0)
('yuv.max=', 201.0, 'yuv.min=', 41.0)
('yuv.max=', 224.0, 'yuv.min=', 24.0)
('yuv.max=', 248.0, 'yuv.min=', 8.0)
('yuv.max=', 237.0, 'yuv.min=', 78.0)
('yuv.max=', 212.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 200.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 248.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 216.0, 'yuv.min=', 41.0)
('yuv.max=', 243.0, 'yuv.min=', 51.0)
('yuv.max=', 253.0, 'yuv.min=', 55.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 242.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 25.0)
('yuv.max=', 245.0, 'yuv.min=', 34.0)
('yuv.max=', 203.0, 'yuv.min=', 6.0)
('yuv.max=', 225.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 227.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 242.0, 'yuv.min=', 2.0)
('yuv.max=', 196.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 244.0, 'yuv.min=', 20.0)
('yuv.max=', 254.0, 'yuv.min=', 26.0)
('yuv.max=', 245.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 252.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 245.0, 'yuv.min=', 15.0)
('yuv.max=', 239.0, 'yuv.min=', 33.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 196.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 6.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 211.0, 'yuv.min=', 39.0)
('yuv.max=', 231.0, 'yuv.min=', 32.0)
('yuv.max=', 196.0, 'yuv.min=', 40.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 236.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 235.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 233.0, 'yuv.min=', 10.0)
('yuv.max=', 254.0, 'yuv.min=', 36.0)
('yuv.max=', 205.0, 'yuv.min=', 34.0)
('yuv.max=', 183.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 230.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 217.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 236.0, 'yuv.min=', 11.0)
('yuv.max=', 205.0, 'yuv.min=', 24.0)
('yuv.max=', 225.0, 'yuv.min=', 51.0)
('yuv.max=', 238.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 231.0, 'yuv.min=', 35.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 252.0, 'yuv.min=', 42.0)
('yuv.max=', 245.0, 'yuv.min=', 22.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 19.0)
('yuv.max=', 203.0, 'yuv.min=', 9.0)
('yuv.max=', 225.0, 'yuv.min=', 29.0)
('yuv.max=', 186.0, 'yuv.min=', 1.0)
('yuv.max=', 240.0, 'yuv.min=', 21.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 238.0, 'yuv.min=', 17.0)
('yuv.max=', 243.0, 'yuv.min=', 11.0)
('yuv.max=', 216.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 190.0, 'yuv.min=', 4.0)
('yuv.max=', 202.0, 'yuv.min=', 13.0)
('yuv.max=', 204.0, 'yuv.min=', 37.0)
('yuv.max=', 178.0, 'yuv.min=', 39.0)
('yuv.max=', 241.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 13.0)
('yuv.max=', 199.0, 'yuv.min=', 6.0)
('yuv.max=', 245.0, 'yuv.min=', 28.0)
('yuv.max=', 209.0, 'yuv.min=', 21.0)
('yuv.max=', 238.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 26.0)
('yuv.max=', 234.0, 'yuv.min=', 37.0)
('yuv.max=', 226.0, 'yuv.min=', 12.0)
('yuv.max=', 208.0, 'yuv.min=', 23.0)
('yuv.max=', 219.0, 'yuv.min=', 29.0)
('yuv.max=', 247.0, 'yuv.min=', 48.0)
('yuv.max=', 237.0, 'yuv.min=', 8.0)
('yuv.max=', 223.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 16.0)
('yuv.max=', 234.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 216.0, 'yuv.min=', 18.0)
('yuv.max=', 236.0, 'yuv.min=', 26.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 220.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 20.0)
('yuv.max=', 234.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 10.0)
('yuv.max=', 226.0, 'yuv.min=', 54.0)
('yuv.max=', 241.0, 'yuv.min=', 36.0)
('yuv.max=', 226.0, 'yuv.min=', 2.0)
('yuv.max=', 211.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 201.0, 'yuv.min=', 17.0)
('yuv.max=', 226.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 169.0, 'yuv.min=', 14.0)
('yuv.max=', 189.0, 'yuv.min=', 72.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 163.0, 'yuv.min=', 42.0)
('yuv.max=', 253.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 251.0, 'yuv.min=', 5.0)
('yuv.max=', 225.0, 'yuv.min=', 57.0)
('yuv.max=', 252.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 208.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 59.0)
('yuv.max=', 250.0, 'yuv.min=', 38.0)
('yuv.max=', 236.0, 'yuv.min=', 32.0)
('yuv.max=', 201.0, 'yuv.min=', 61.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 200.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 160.0, 'yuv.min=', 10.0)
('yuv.max=', 254.0, 'yuv.min=', 28.0)
('yuv.max=', 225.0, 'yuv.min=', 36.0)
('yuv.max=', 229.0, 'yuv.min=', 5.0)
('yuv.max=', 250.0, 'yuv.min=', 4.0)
('yuv.max=', 189.0, 'yuv.min=', 7.0)
('yuv.max=', 237.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 55.0)
('yuv.max=', 250.0, 'yuv.min=', 8.0)
('yuv.max=', 215.0, 'yuv.min=', 76.0)
('yuv.max=', 245.0, 'yuv.min=', 30.0)
('yuv.max=', 155.0, 'yuv.min=', 47.0)
('yuv.max=', 218.0, 'yuv.min=', 9.0)
('yuv.max=', 217.0, 'yuv.min=', 1.0)
('yuv.max=', 194.0, 'yuv.min=', 15.0)
('yuv.max=', 251.0, 'yuv.min=', 48.0)
('yuv.max=', 246.0, 'yuv.min=', 38.0)
('yuv.max=', 238.0, 'yuv.min=', 10.0)
('yuv.max=', 216.0, 'yuv.min=', 13.0)
('yuv.max=', 203.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 16.0)
('yuv.max=', 224.0, 'yuv.min=', 32.0)
('yuv.max=', 250.0, 'yuv.min=', 35.0)
('yuv.max=', 181.0, 'yuv.min=', 19.0)
('yuv.max=', 202.0, 'yuv.min=', 35.0)
('yuv.max=', 250.0, 'yuv.min=', 33.0)
('yuv.max=', 250.0, 'yuv.min=', 19.0)
('yuv.max=', 223.0, 'yuv.min=', 43.0)
('yuv.max=', 231.0, 'yuv.min=', 32.0)
('yuv.max=', 242.0, 'yuv.min=', 3.0)
('yuv.max=', 248.0, 'yuv.min=', 32.0)
('yuv.max=', 239.0, 'yuv.min=', 6.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 139.0, 'yuv.min=', 10.0)
('yuv.max=', 243.0, 'yuv.min=', 6.0)
('yuv.max=', 247.0, 'yuv.min=', 29.0)
('yuv.max=', 238.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 11.0)
('yuv.max=', 248.0, 'yuv.min=', 29.0)
('yuv.max=', 250.0, 'yuv.min=', 7.0)
('yuv.max=', 221.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 209.0, 'yuv.min=', 11.0)
('yuv.max=', 213.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 252.0, 'yuv.min=', 30.0)
('yuv.max=', 216.0, 'yuv.min=', 57.0)
('yuv.max=', 196.0, 'yuv.min=', 18.0)
('yuv.max=', 236.0, 'yuv.min=', 25.0)
('yuv.max=', 248.0, 'yuv.min=', 36.0)
('yuv.max=', 253.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 224.0, 'yuv.min=', 28.0)
('yuv.max=', 205.0, 'yuv.min=', 36.0)
('yuv.max=', 212.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 190.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 29.0)
('yuv.max=', 211.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 245.0, 'yuv.min=', 25.0)
('yuv.max=', 192.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 245.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 219.0, 'yuv.min=', 60.0)
('yuv.max=', 244.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 197.0, 'yuv.min=', 36.0)
('yuv.max=', 210.0, 'yuv.min=', 22.0)
('yuv.max=', 199.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 16.0)
('yuv.max=', 244.0, 'yuv.min=', 17.0)
('yuv.max=', 251.0, 'yuv.min=', 12.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 37.0)
('yuv.max=', 182.0, 'yuv.min=', 23.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 226.0, 'yuv.min=', 12.0)
('yuv.max=', 164.0, 'yuv.min=', 37.0)
('yuv.max=', 205.0, 'yuv.min=', 21.0)
('yuv.max=', 227.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 254.0, 'yuv.min=', 65.0)
('yuv.max=', 237.0, 'yuv.min=', 3.0)
('yuv.max=', 229.0, 'yuv.min=', 8.0)
('yuv.max=', 191.0, 'yuv.min=', 23.0)
('yuv.max=', 238.0, 'yuv.min=', 19.0)
('yuv.max=', 254.0, 'yuv.min=', 23.0)
('yuv.max=', 241.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 204.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 242.0, 'yuv.min=', 31.0)
('yuv.max=', 199.0, 'yuv.min=', 99.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 208.0, 'yuv.min=', 28.0)
('yuv.max=', 252.0, 'yuv.min=', 19.0)
('yuv.max=', 177.0, 'yuv.min=', 7.0)
('yuv.max=', 239.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 10.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 36.0)
('yuv.max=', 233.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 231.0, 'yuv.min=', 16.0)
('yuv.max=', 245.0, 'yuv.min=', 24.0)
('yuv.max=', 241.0, 'yuv.min=', 32.0)
('yuv.max=', 245.0, 'yuv.min=', 15.0)
('yuv.max=', 242.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 180.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 51.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 232.0, 'yuv.min=', 50.0)
('yuv.max=', 242.0, 'yuv.min=', 32.0)
('yuv.max=', 202.0, 'yuv.min=', 17.0)
('yuv.max=', 228.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 201.0, 'yuv.min=', 6.0)
('yuv.max=', 250.0, 'yuv.min=', 35.0)
('yuv.max=', 226.0, 'yuv.min=', 2.0)
('yuv.max=', 245.0, 'yuv.min=', 4.0)
('yuv.max=', 211.0, 'yuv.min=', 39.0)
('yuv.max=', 254.0, 'yuv.min=', 47.0)
('yuv.max=', 221.0, 'yuv.min=', 6.0)
('yuv.max=', 224.0, 'yuv.min=', 73.0)
('yuv.max=', 253.0, 'yuv.min=', 3.0)
('yuv.max=', 218.0, 'yuv.min=', 34.0)
('yuv.max=', 253.0, 'yuv.min=', 28.0)
('yuv.max=', 249.0, 'yuv.min=', 7.0)
('yuv.max=', 209.0, 'yuv.min=', 63.0)
('yuv.max=', 209.0, 'yuv.min=', 6.0)
('yuv.max=', 241.0, 'yuv.min=', 21.0)
('yuv.max=', 240.0, 'yuv.min=', 42.0)
('yuv.max=', 196.0, 'yuv.min=', 5.0)
('yuv.max=', 186.0, 'yuv.min=', 25.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 35.0)
('yuv.max=', 225.0, 'yuv.min=', 44.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 231.0, 'yuv.min=', 10.0)
('yuv.max=', 167.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 191.0, 'yuv.min=', 89.0)
('yuv.max=', 248.0, 'yuv.min=', 59.0)
('yuv.max=', 223.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 216.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 70.0)
('yuv.max=', 202.0, 'yuv.min=', 34.0)
('yuv.max=', 250.0, 'yuv.min=', 13.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 23.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 230.0, 'yuv.min=', 3.0)
('yuv.max=', 214.0, 'yuv.min=', 16.0)
('yuv.max=', 252.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 177.0, 'yuv.min=', 10.0)
('yuv.max=', 239.0, 'yuv.min=', 48.0)
('yuv.max=', 232.0, 'yuv.min=', 9.0)
('yuv.max=', 158.0, 'yuv.min=', 38.0)
('yuv.max=', 223.0, 'yuv.min=', 43.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 234.0, 'yuv.min=', 3.0)
('yuv.max=', 221.0, 'yuv.min=', 27.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 204.0, 'yuv.min=', 37.0)
('yuv.max=', 239.0, 'yuv.min=', 19.0)
('yuv.max=', 240.0, 'yuv.min=', 61.0)
('yuv.max=', 235.0, 'yuv.min=', 25.0)
('yuv.max=', 227.0, 'yuv.min=', 54.0)
('yuv.max=', 247.0, 'yuv.min=', 11.0)
('yuv.max=', 213.0, 'yuv.min=', 18.0)
('yuv.max=', 186.0, 'yuv.min=', 22.0)
('yuv.max=', 191.0, 'yuv.min=', 15.0)
('yuv.max=', 251.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 205.0, 'yuv.min=', 29.0)
('yuv.max=', 242.0, 'yuv.min=', 10.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 251.0, 'yuv.min=', 38.0)
('yuv.max=', 202.0, 'yuv.min=', 76.0)
('yuv.max=', 177.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 230.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 222.0, 'yuv.min=', 21.0)
('yuv.max=', 236.0, 'yuv.min=', 1.0)
('yuv.max=', 215.0, 'yuv.min=', 36.0)
('yuv.max=', 232.0, 'yuv.min=', 17.0)
('yuv.max=', 222.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 233.0, 'yuv.min=', 28.0)
('yuv.max=', 210.0, 'yuv.min=', 18.0)
('yuv.max=', 219.0, 'yuv.min=', 3.0)
('yuv.max=', 207.0, 'yuv.min=', 38.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 178.0, 'yuv.min=', 62.0)
('yuv.max=', 219.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 209.0, 'yuv.min=', 48.0)
('yuv.max=', 227.0, 'yuv.min=', 12.0)
('yuv.max=', 221.0, 'yuv.min=', 1.0)
('yuv.max=', 219.0, 'yuv.min=', 86.0)
('yuv.max=', 250.0, 'yuv.min=', 13.0)
('yuv.max=', 254.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 217.0, 'yuv.min=', 12.0)
('yuv.max=', 240.0, 'yuv.min=', 31.0)
('yuv.max=', 206.0, 'yuv.min=', 17.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 215.0, 'yuv.min=', 48.0)
('yuv.max=', 242.0, 'yuv.min=', 20.0)
('yuv.max=', 225.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 205.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 251.0, 'yuv.min=', 21.0)
('yuv.max=', 215.0, 'yuv.min=', 11.0)
('yuv.max=', 241.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 249.0, 'yuv.min=', 41.0)
('yuv.max=', 254.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 239.0, 'yuv.min=', 11.0)
('yuv.max=', 237.0, 'yuv.min=', 42.0)
('yuv.max=', 254.0, 'yuv.min=', 13.0)
('yuv.max=', 250.0, 'yuv.min=', 25.0)
('yuv.max=', 236.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 107.0)
('yuv.max=', 245.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 162.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 248.0, 'yuv.min=', 42.0)
('yuv.max=', 164.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 82.0)
('yuv.max=', 216.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 246.0, 'yuv.min=', 10.0)
('yuv.max=', 205.0, 'yuv.min=', 0.0)
('yuv.max=', 190.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 246.0, 'yuv.min=', 46.0)
('yuv.max=', 224.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 60.0)
('yuv.max=', 227.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 45.0)
('yuv.max=', 212.0, 'yuv.min=', 6.0)
('yuv.max=', 250.0, 'yuv.min=', 32.0)
('yuv.max=', 239.0, 'yuv.min=', 9.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 59.0)
('yuv.max=', 201.0, 'yuv.min=', 9.0)
('yuv.max=', 237.0, 'yuv.min=', 13.0)
('yuv.max=', 236.0, 'yuv.min=', 10.0)
('yuv.max=', 244.0, 'yuv.min=', 1.0)
('yuv.max=', 233.0, 'yuv.min=', 29.0)
('yuv.max=', 247.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 214.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 203.0, 'yuv.min=', 1.0)
('yuv.max=', 243.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 28.0)
('yuv.max=', 244.0, 'yuv.min=', 8.0)
('yuv.max=', 206.0, 'yuv.min=', 44.0)
('yuv.max=', 225.0, 'yuv.min=', 26.0)
('yuv.max=', 226.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 249.0, 'yuv.min=', 10.0)
('yuv.max=', 215.0, 'yuv.min=', 5.0)
('yuv.max=', 217.0, 'yuv.min=', 61.0)
('yuv.max=', 247.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 250.0, 'yuv.min=', 11.0)
('yuv.max=', 198.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 207.0, 'yuv.min=', 61.0)
('yuv.max=', 184.0, 'yuv.min=', 8.0)
('yuv.max=', 249.0, 'yuv.min=', 8.0)
('yuv.max=', 193.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 216.0, 'yuv.min=', 13.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 208.0, 'yuv.min=', 46.0)
('yuv.max=', 204.0, 'yuv.min=', 14.0)
('yuv.max=', 222.0, 'yuv.min=', 16.0)
('yuv.max=', 214.0, 'yuv.min=', 7.0)
('yuv.max=', 230.0, 'yuv.min=', 2.0)
('yuv.max=', 231.0, 'yuv.min=', 40.0)
('yuv.max=', 214.0, 'yuv.min=', 0.0)
('yuv.max=', 229.0, 'yuv.min=', 20.0)
('yuv.max=', 212.0, 'yuv.min=', 5.0)
('yuv.max=', 249.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 188.0, 'yuv.min=', 26.0)
('yuv.max=', 237.0, 'yuv.min=', 16.0)
('yuv.max=', 189.0, 'yuv.min=', 15.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 219.0, 'yuv.min=', 6.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 14.0)
('yuv.max=', 240.0, 'yuv.min=', 35.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 168.0, 'yuv.min=', 21.0)
('yuv.max=', 248.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 243.0, 'yuv.min=', 15.0)
('yuv.max=', 231.0, 'yuv.min=', 7.0)
('yuv.max=', 141.0, 'yuv.min=', 10.0)
('yuv.max=', 169.0, 'yuv.min=', 24.0)
('yuv.max=', 221.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 220.0, 'yuv.min=', 9.0)
('yuv.max=', 228.0, 'yuv.min=', 32.0)
('yuv.max=', 204.0, 'yuv.min=', 30.0)
('yuv.max=', 215.0, 'yuv.min=', 28.0)
('yuv.max=', 215.0, 'yuv.min=', 49.0)
('yuv.max=', 230.0, 'yuv.min=', 20.0)
('yuv.max=', 254.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 222.0, 'yuv.min=', 18.0)
('yuv.max=', 253.0, 'yuv.min=', 36.0)
('yuv.max=', 234.0, 'yuv.min=', 7.0)
('yuv.max=', 244.0, 'yuv.min=', 29.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 244.0, 'yuv.min=', 63.0)
('yuv.max=', 199.0, 'yuv.min=', 9.0)
('yuv.max=', 223.0, 'yuv.min=', 0.0)
('yuv.max=', 193.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 165.0, 'yuv.min=', 1.0)
('yuv.max=', 219.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 27.0)
('yuv.max=', 195.0, 'yuv.min=', 80.0)
('yuv.max=', 231.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 50.0)
('yuv.max=', 203.0, 'yuv.min=', 26.0)
('yuv.max=', 235.0, 'yuv.min=', 3.0)
('yuv.max=', 234.0, 'yuv.min=', 14.0)
('yuv.max=', 215.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 246.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 23.0)
('yuv.max=', 228.0, 'yuv.min=', 2.0)
('yuv.max=', 211.0, 'yuv.min=', 26.0)
('yuv.max=', 183.0, 'yuv.min=', 2.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 3.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 245.0, 'yuv.min=', 41.0)
('yuv.max=', 225.0, 'yuv.min=', 26.0)
('yuv.max=', 239.0, 'yuv.min=', 18.0)
('yuv.max=', 245.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 174.0, 'yuv.min=', 3.0)
('yuv.max=', 203.0, 'yuv.min=', 7.0)
('yuv.max=', 253.0, 'yuv.min=', 51.0)
('yuv.max=', 176.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 21.0)
('yuv.max=', 181.0, 'yuv.min=', 39.0)
('yuv.max=', 193.0, 'yuv.min=', 46.0)
('yuv.max=', 216.0, 'yuv.min=', 23.0)
('yuv.max=', 226.0, 'yuv.min=', 34.0)
('yuv.max=', 243.0, 'yuv.min=', 8.0)
('yuv.max=', 211.0, 'yuv.min=', 44.0)
('yuv.max=', 226.0, 'yuv.min=', 26.0)
('yuv.max=', 237.0, 'yuv.min=', 18.0)
('yuv.max=', 223.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 231.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 211.0, 'yuv.min=', 24.0)
('yuv.max=', 240.0, 'yuv.min=', 47.0)
('yuv.max=', 175.0, 'yuv.min=', 35.0)
('yuv.max=', 218.0, 'yuv.min=', 16.0)
('yuv.max=', 234.0, 'yuv.min=', 69.0)
('yuv.max=', 255.0, 'yuv.min=', 74.0)
('yuv.max=', 251.0, 'yuv.min=', 4.0)
('yuv.max=', 186.0, 'yuv.min=', 51.0)
('yuv.max=', 227.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 195.0, 'yuv.min=', 13.0)
('yuv.max=', 217.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 236.0, 'yuv.min=', 21.0)
('yuv.max=', 249.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 193.0, 'yuv.min=', 81.0)
('yuv.max=', 165.0, 'yuv.min=', 17.0)
('yuv.max=', 161.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 37.0)
('yuv.max=', 252.0, 'yuv.min=', 15.0)
('yuv.max=', 208.0, 'yuv.min=', 0.0)
('yuv.max=', 208.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 25.0)
('yuv.max=', 250.0, 'yuv.min=', 27.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 209.0, 'yuv.min=', 34.0)
('yuv.max=', 239.0, 'yuv.min=', 67.0)
('yuv.max=', 230.0, 'yuv.min=', 14.0)
('yuv.max=', 194.0, 'yuv.min=', 26.0)
('yuv.max=', 166.0, 'yuv.min=', 71.0)
('yuv.max=', 243.0, 'yuv.min=', 15.0)
('yuv.max=', 229.0, 'yuv.min=', 62.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 0.0)
('yuv.max=', 173.0, 'yuv.min=', 77.0)
('yuv.max=', 239.0, 'yuv.min=', 18.0)
('yuv.max=', 250.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 34.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 220.0, 'yuv.min=', 17.0)
('yuv.max=', 206.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 234.0, 'yuv.min=', 32.0)
('yuv.max=', 235.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 238.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 21.0)
('yuv.max=', 237.0, 'yuv.min=', 17.0)
('yuv.max=', 210.0, 'yuv.min=', 9.0)
('yuv.max=', 209.0, 'yuv.min=', 52.0)
('yuv.max=', 243.0, 'yuv.min=', 3.0)
('yuv.max=', 252.0, 'yuv.min=', 38.0)
('yuv.max=', 223.0, 'yuv.min=', 0.0)
('yuv.max=', 235.0, 'yuv.min=', 12.0)
('yuv.max=', 238.0, 'yuv.min=', 49.0)
('yuv.max=', 230.0, 'yuv.min=', 8.0)
('yuv.max=', 231.0, 'yuv.min=', 1.0)
('yuv.max=', 234.0, 'yuv.min=', 32.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 241.0, 'yuv.min=', 72.0)
('yuv.max=', 206.0, 'yuv.min=', 14.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 177.0, 'yuv.min=', 21.0)
('yuv.max=', 250.0, 'yuv.min=', 22.0)
('yuv.max=', 209.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 247.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 222.0, 'yuv.min=', 20.0)
('yuv.max=', 216.0, 'yuv.min=', 39.0)
('yuv.max=', 243.0, 'yuv.min=', 1.0)
('yuv.max=', 211.0, 'yuv.min=', 18.0)
('yuv.max=', 202.0, 'yuv.min=', 40.0)
('yuv.max=', 247.0, 'yuv.min=', 51.0)
('yuv.max=', 248.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 235.0, 'yuv.min=', 31.0)
('yuv.max=', 221.0, 'yuv.min=', 67.0)
('yuv.max=', 211.0, 'yuv.min=', 50.0)
('yuv.max=', 234.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 228.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 249.0, 'yuv.min=', 74.0)
('yuv.max=', 231.0, 'yuv.min=', 18.0)
('yuv.max=', 238.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 249.0, 'yuv.min=', 34.0)
('yuv.max=', 215.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 79.0)
('yuv.max=', 255.0, 'yuv.min=', 59.0)
('yuv.max=', 246.0, 'yuv.min=', 8.0)
('yuv.max=', 221.0, 'yuv.min=', 13.0)
('yuv.max=', 227.0, 'yuv.min=', 2.0)
('yuv.max=', 198.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 251.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 64.0)
('yuv.max=', 238.0, 'yuv.min=', 55.0)
('yuv.max=', 230.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 193.0, 'yuv.min=', 6.0)
('yuv.max=', 246.0, 'yuv.min=', 6.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 188.0, 'yuv.min=', 71.0)
('yuv.max=', 251.0, 'yuv.min=', 55.0)
('yuv.max=', 232.0, 'yuv.min=', 14.0)
('yuv.max=', 159.0, 'yuv.min=', 20.0)
('yuv.max=', 228.0, 'yuv.min=', 14.0)
('yuv.max=', 240.0, 'yuv.min=', 37.0)
('yuv.max=', 231.0, 'yuv.min=', 5.0)
('yuv.max=', 234.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 56.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 219.0, 'yuv.min=', 10.0)
('yuv.max=', 203.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 54.0)
('yuv.max=', 231.0, 'yuv.min=', 39.0)
('yuv.max=', 229.0, 'yuv.min=', 27.0)
('yuv.max=', 246.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 242.0, 'yuv.min=', 14.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 240.0, 'yuv.min=', 15.0)
('yuv.max=', 179.0, 'yuv.min=', 6.0)
('yuv.max=', 198.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 204.0, 'yuv.min=', 21.0)
('yuv.max=', 253.0, 'yuv.min=', 39.0)
('yuv.max=', 204.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 176.0, 'yuv.min=', 27.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 237.0, 'yuv.min=', 10.0)
('yuv.max=', 241.0, 'yuv.min=', 43.0)
('yuv.max=', 235.0, 'yuv.min=', 24.0)
('yuv.max=', 175.0, 'yuv.min=', 8.0)
('yuv.max=', 240.0, 'yuv.min=', 39.0)
('yuv.max=', 233.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 27.0)
('yuv.max=', 176.0, 'yuv.min=', 17.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 240.0, 'yuv.min=', 31.0)
('yuv.max=', 177.0, 'yuv.min=', 84.0)
('yuv.max=', 210.0, 'yuv.min=', 1.0)
('yuv.max=', 234.0, 'yuv.min=', 12.0)
('yuv.max=', 146.0, 'yuv.min=', 10.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 246.0, 'yuv.min=', 5.0)
('yuv.max=', 244.0, 'yuv.min=', 30.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 230.0, 'yuv.min=', 37.0)
('yuv.max=', 231.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 230.0, 'yuv.min=', 17.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 237.0, 'yuv.min=', 43.0)
('yuv.max=', 244.0, 'yuv.min=', 27.0)
('yuv.max=', 240.0, 'yuv.min=', 8.0)
('yuv.max=', 213.0, 'yuv.min=', 53.0)
('yuv.max=', 244.0, 'yuv.min=', 63.0)
('yuv.max=', 169.0, 'yuv.min=', 25.0)
('yuv.max=', 230.0, 'yuv.min=', 29.0)
('yuv.max=', 185.0, 'yuv.min=', 20.0)
('yuv.max=', 252.0, 'yuv.min=', 19.0)
('yuv.max=', 248.0, 'yuv.min=', 27.0)
('yuv.max=', 228.0, 'yuv.min=', 27.0)
('yuv.max=', 216.0, 'yuv.min=', 10.0)
('yuv.max=', 236.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 227.0, 'yuv.min=', 29.0)
('yuv.max=', 212.0, 'yuv.min=', 26.0)
('yuv.max=', 239.0, 'yuv.min=', 60.0)
('yuv.max=', 187.0, 'yuv.min=', 14.0)
('yuv.max=', 217.0, 'yuv.min=', 7.0)
('yuv.max=', 213.0, 'yuv.min=', 18.0)
('yuv.max=', 233.0, 'yuv.min=', 10.0)
('yuv.max=', 238.0, 'yuv.min=', 16.0)
('yuv.max=', 217.0, 'yuv.min=', 17.0)
('yuv.max=', 184.0, 'yuv.min=', 60.0)
('yuv.max=', 248.0, 'yuv.min=', 30.0)
('yuv.max=', 253.0, 'yuv.min=', 31.0)
('yuv.max=', 193.0, 'yuv.min=', 3.0)
('yuv.max=', 234.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 235.0, 'yuv.min=', 28.0)
('yuv.max=', 214.0, 'yuv.min=', 11.0)
('yuv.max=', 253.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 249.0, 'yuv.min=', 26.0)
('yuv.max=', 221.0, 'yuv.min=', 30.0)
('yuv.max=', 253.0, 'yuv.min=', 38.0)
('yuv.max=', 240.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 236.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 222.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 248.0, 'yuv.min=', 26.0)
('yuv.max=', 171.0, 'yuv.min=', 27.0)
('yuv.max=', 214.0, 'yuv.min=', 21.0)
('yuv.max=', 253.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 82.0)
('yuv.max=', 180.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 196.0, 'yuv.min=', 45.0)
('yuv.max=', 231.0, 'yuv.min=', 13.0)
('yuv.max=', 242.0, 'yuv.min=', 27.0)
('yuv.max=', 251.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 41.0)
('yuv.max=', 205.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 222.0, 'yuv.min=', 45.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 210.0, 'yuv.min=', 43.0)
('yuv.max=', 215.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 189.0, 'yuv.min=', 15.0)
('yuv.max=', 193.0, 'yuv.min=', 38.0)
('yuv.max=', 230.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 25.0)
('yuv.max=', 236.0, 'yuv.min=', 29.0)
('yuv.max=', 234.0, 'yuv.min=', 50.0)
('yuv.max=', 248.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 229.0, 'yuv.min=', 50.0)
('yuv.max=', 234.0, 'yuv.min=', 19.0)
('yuv.max=', 200.0, 'yuv.min=', 30.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 226.0, 'yuv.min=', 58.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 252.0, 'yuv.min=', 14.0)
('yuv.max=', 181.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 239.0, 'yuv.min=', 11.0)
('yuv.max=', 197.0, 'yuv.min=', 2.0)
('yuv.max=', 241.0, 'yuv.min=', 9.0)
('yuv.max=', 243.0, 'yuv.min=', 50.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 247.0, 'yuv.min=', 67.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 227.0, 'yuv.min=', 17.0)
('yuv.max=', 246.0, 'yuv.min=', 7.0)
('yuv.max=', 254.0, 'yuv.min=', 51.0)
('yuv.max=', 184.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 242.0, 'yuv.min=', 44.0)
('yuv.max=', 244.0, 'yuv.min=', 55.0)
('yuv.max=', 225.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 24.0)
('yuv.max=', 220.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 65.0)
('yuv.max=', 224.0, 'yuv.min=', 12.0)
('yuv.max=', 209.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 2.0)
('yuv.max=', 236.0, 'yuv.min=', 21.0)
('yuv.max=', 221.0, 'yuv.min=', 84.0)
('yuv.max=', 231.0, 'yuv.min=', 20.0)
('yuv.max=', 209.0, 'yuv.min=', 18.0)
('yuv.max=', 217.0, 'yuv.min=', 12.0)
('yuv.max=', 244.0, 'yuv.min=', 12.0)
('yuv.max=', 216.0, 'yuv.min=', 8.0)
('yuv.max=', 248.0, 'yuv.min=', 31.0)
('yuv.max=', 186.0, 'yuv.min=', 24.0)
('yuv.max=', 249.0, 'yuv.min=', 21.0)
('yuv.max=', 211.0, 'yuv.min=', 44.0)
('yuv.max=', 233.0, 'yuv.min=', 15.0)
('yuv.max=', 240.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 53.0)
('yuv.max=', 166.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 234.0, 'yuv.min=', 39.0)
('yuv.max=', 235.0, 'yuv.min=', 21.0)
('yuv.max=', 237.0, 'yuv.min=', 50.0)
('yuv.max=', 237.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 204.0, 'yuv.min=', 24.0)
('yuv.max=', 224.0, 'yuv.min=', 25.0)
('yuv.max=', 221.0, 'yuv.min=', 36.0)
('yuv.max=', 168.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 193.0, 'yuv.min=', 44.0)
('yuv.max=', 242.0, 'yuv.min=', 52.0)
('yuv.max=', 230.0, 'yuv.min=', 23.0)
('yuv.max=', 210.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 24.0)
('yuv.max=', 244.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 241.0, 'yuv.min=', 12.0)
('yuv.max=', 245.0, 'yuv.min=', 90.0)
('yuv.max=', 251.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 253.0, 'yuv.min=', 6.0)
('yuv.max=', 228.0, 'yuv.min=', 45.0)
('yuv.max=', 234.0, 'yuv.min=', 3.0)
('yuv.max=', 245.0, 'yuv.min=', 96.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 248.0, 'yuv.min=', 8.0)
('yuv.max=', 251.0, 'yuv.min=', 37.0)
('yuv.max=', 253.0, 'yuv.min=', 47.0)
('yuv.max=', 238.0, 'yuv.min=', 37.0)
('yuv.max=', 211.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 225.0, 'yuv.min=', 39.0)
('yuv.max=', 160.0, 'yuv.min=', 16.0)
('yuv.max=', 231.0, 'yuv.min=', 25.0)
('yuv.max=', 224.0, 'yuv.min=', 58.0)
('yuv.max=', 219.0, 'yuv.min=', 46.0)
('yuv.max=', 253.0, 'yuv.min=', 25.0)
('yuv.max=', 236.0, 'yuv.min=', 34.0)
('yuv.max=', 179.0, 'yuv.min=', 61.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 206.0, 'yuv.min=', 48.0)
('yuv.max=', 223.0, 'yuv.min=', 22.0)
('yuv.max=', 243.0, 'yuv.min=', 21.0)
('yuv.max=', 224.0, 'yuv.min=', 11.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 44.0)
('yuv.max=', 188.0, 'yuv.min=', 38.0)
('yuv.max=', 235.0, 'yuv.min=', 38.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 203.0, 'yuv.min=', 31.0)
('yuv.max=', 236.0, 'yuv.min=', 33.0)
('yuv.max=', 249.0, 'yuv.min=', 34.0)
('yuv.max=', 247.0, 'yuv.min=', 10.0)
('yuv.max=', 246.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 22.0)
('yuv.max=', 207.0, 'yuv.min=', 23.0)
('yuv.max=', 212.0, 'yuv.min=', 16.0)
('yuv.max=', 212.0, 'yuv.min=', 23.0)
('yuv.max=', 233.0, 'yuv.min=', 4.0)
('yuv.max=', 214.0, 'yuv.min=', 41.0)
('yuv.max=', 244.0, 'yuv.min=', 17.0)
('yuv.max=', 229.0, 'yuv.min=', 32.0)
('yuv.max=', 253.0, 'yuv.min=', 30.0)
('yuv.max=', 214.0, 'yuv.min=', 51.0)
('yuv.max=', 249.0, 'yuv.min=', 10.0)
('yuv.max=', 245.0, 'yuv.min=', 47.0)
('yuv.max=', 247.0, 'yuv.min=', 2.0)
('yuv.max=', 253.0, 'yuv.min=', 61.0)
('yuv.max=', 237.0, 'yuv.min=', 31.0)
('yuv.max=', 195.0, 'yuv.min=', 55.0)
('yuv.max=', 221.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 17.0)
('yuv.max=', 217.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 20.0)
('yuv.max=', 242.0, 'yuv.min=', 18.0)
('yuv.max=', 241.0, 'yuv.min=', 37.0)
('yuv.max=', 187.0, 'yuv.min=', 64.0)
('yuv.max=', 230.0, 'yuv.min=', 20.0)
('yuv.max=', 230.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 200.0, 'yuv.min=', 22.0)
('yuv.max=', 137.0, 'yuv.min=', 13.0)
('yuv.max=', 251.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 154.0, 'yuv.min=', 21.0)
('yuv.max=', 209.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 233.0, 'yuv.min=', 44.0)
('yuv.max=', 249.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 202.0, 'yuv.min=', 67.0)
('yuv.max=', 232.0, 'yuv.min=', 23.0)
('yuv.max=', 253.0, 'yuv.min=', 40.0)
('yuv.max=', 254.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 15.0)
('yuv.max=', 239.0, 'yuv.min=', 49.0)
('yuv.max=', 233.0, 'yuv.min=', 23.0)
('yuv.max=', 240.0, 'yuv.min=', 8.0)
('yuv.max=', 235.0, 'yuv.min=', 19.0)
('yuv.max=', 246.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 252.0, 'yuv.min=', 20.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 166.0, 'yuv.min=', 85.0)
('yuv.max=', 141.0, 'yuv.min=', 54.0)
('yuv.max=', 196.0, 'yuv.min=', 29.0)
('yuv.max=', 185.0, 'yuv.min=', 31.0)
('yuv.max=', 254.0, 'yuv.min=', 37.0)
('yuv.max=', 234.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 216.0, 'yuv.min=', 0.0)
('yuv.max=', 232.0, 'yuv.min=', 23.0)
('yuv.max=', 197.0, 'yuv.min=', 51.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 223.0, 'yuv.min=', 3.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 208.0, 'yuv.min=', 38.0)
('yuv.max=', 252.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 247.0, 'yuv.min=', 22.0)
('yuv.max=', 230.0, 'yuv.min=', 51.0)
('yuv.max=', 243.0, 'yuv.min=', 25.0)
('yuv.max=', 251.0, 'yuv.min=', 23.0)
('yuv.max=', 247.0, 'yuv.min=', 26.0)
('yuv.max=', 250.0, 'yuv.min=', 18.0)
('yuv.max=', 252.0, 'yuv.min=', 2.0)
('yuv.max=', 214.0, 'yuv.min=', 39.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 212.0, 'yuv.min=', 29.0)
('yuv.max=', 216.0, 'yuv.min=', 19.0)
('yuv.max=', 254.0, 'yuv.min=', 42.0)
('yuv.max=', 186.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 179.0, 'yuv.min=', 18.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 241.0, 'yuv.min=', 15.0)
('yuv.max=', 202.0, 'yuv.min=', 26.0)
('yuv.max=', 187.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 223.0, 'yuv.min=', 51.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 247.0, 'yuv.min=', 8.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 247.0, 'yuv.min=', 52.0)
('yuv.max=', 241.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 56.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 220.0, 'yuv.min=', 61.0)
('yuv.max=', 206.0, 'yuv.min=', 77.0)
('yuv.max=', 205.0, 'yuv.min=', 9.0)
('yuv.max=', 254.0, 'yuv.min=', 88.0)
('yuv.max=', 239.0, 'yuv.min=', 30.0)
('yuv.max=', 177.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 247.0, 'yuv.min=', 48.0)
('yuv.max=', 211.0, 'yuv.min=', 12.0)
('yuv.max=', 231.0, 'yuv.min=', 27.0)
('yuv.max=', 237.0, 'yuv.min=', 40.0)
('yuv.max=', 222.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 28.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 230.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 218.0, 'yuv.min=', 18.0)
('yuv.max=', 234.0, 'yuv.min=', 55.0)
('yuv.max=', 230.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 224.0, 'yuv.min=', 23.0)
('yuv.max=', 248.0, 'yuv.min=', 103.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 174.0, 'yuv.min=', 7.0)
('yuv.max=', 245.0, 'yuv.min=', 3.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 180.0, 'yuv.min=', 8.0)
('yuv.max=', 252.0, 'yuv.min=', 40.0)
('yuv.max=', 253.0, 'yuv.min=', 5.0)
('yuv.max=', 226.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 52.0)
('yuv.max=', 205.0, 'yuv.min=', 74.0)
('yuv.max=', 228.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 59.0)
('yuv.max=', 233.0, 'yuv.min=', 3.0)
('yuv.max=', 238.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 74.0)
('yuv.max=', 235.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 210.0, 'yuv.min=', 34.0)
('yuv.max=', 227.0, 'yuv.min=', 38.0)
('yuv.max=', 228.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 30.0)
('yuv.max=', 226.0, 'yuv.min=', 83.0)
('yuv.max=', 202.0, 'yuv.min=', 8.0)
('yuv.max=', 232.0, 'yuv.min=', 10.0)
('yuv.max=', 228.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 24.0)
('yuv.max=', 230.0, 'yuv.min=', 25.0)
('yuv.max=', 216.0, 'yuv.min=', 13.0)
('yuv.max=', 243.0, 'yuv.min=', 46.0)
('yuv.max=', 235.0, 'yuv.min=', 37.0)
('yuv.max=', 212.0, 'yuv.min=', 57.0)
('yuv.max=', 241.0, 'yuv.min=', 37.0)
('yuv.max=', 225.0, 'yuv.min=', 49.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 45.0)
('yuv.max=', 229.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 5.0)
('yuv.max=', 253.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 71.0)
('yuv.max=', 252.0, 'yuv.min=', 6.0)
('yuv.max=', 230.0, 'yuv.min=', 16.0)
('yuv.max=', 223.0, 'yuv.min=', 27.0)
('yuv.max=', 250.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 187.0, 'yuv.min=', 34.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 204.0, 'yuv.min=', 10.0)
('yuv.max=', 241.0, 'yuv.min=', 23.0)
('yuv.max=', 254.0, 'yuv.min=', 36.0)
('yuv.max=', 205.0, 'yuv.min=', 56.0)
('yuv.max=', 225.0, 'yuv.min=', 33.0)
('yuv.max=', 248.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 66.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 216.0, 'yuv.min=', 21.0)
('yuv.max=', 242.0, 'yuv.min=', 17.0)
('yuv.max=', 233.0, 'yuv.min=', 42.0)
('yuv.max=', 233.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 20.0)
('yuv.max=', 240.0, 'yuv.min=', 23.0)
('yuv.max=', 237.0, 'yuv.min=', 51.0)
('yuv.max=', 237.0, 'yuv.min=', 7.0)
('yuv.max=', 211.0, 'yuv.min=', 31.0)
('yuv.max=', 239.0, 'yuv.min=', 5.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 208.0, 'yuv.min=', 41.0)
('yuv.max=', 232.0, 'yuv.min=', 37.0)
('yuv.max=', 242.0, 'yuv.min=', 17.0)
('yuv.max=', 225.0, 'yuv.min=', 7.0)
('yuv.max=', 168.0, 'yuv.min=', 46.0)
('yuv.max=', 223.0, 'yuv.min=', 41.0)
('yuv.max=', 242.0, 'yuv.min=', 31.0)
('yuv.max=', 227.0, 'yuv.min=', 39.0)
('yuv.max=', 248.0, 'yuv.min=', 7.0)
('yuv.max=', 225.0, 'yuv.min=', 25.0)
('yuv.max=', 210.0, 'yuv.min=', 2.0)
('yuv.max=', 198.0, 'yuv.min=', 67.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 188.0, 'yuv.min=', 43.0)
('yuv.max=', 225.0, 'yuv.min=', 92.0)
('yuv.max=', 201.0, 'yuv.min=', 76.0)
('yuv.max=', 186.0, 'yuv.min=', 10.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 239.0, 'yuv.min=', 36.0)
('yuv.max=', 245.0, 'yuv.min=', 8.0)
('yuv.max=', 198.0, 'yuv.min=', 44.0)
('yuv.max=', 214.0, 'yuv.min=', 49.0)
('yuv.max=', 244.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 206.0, 'yuv.min=', 37.0)
('yuv.max=', 246.0, 'yuv.min=', 34.0)
('yuv.max=', 243.0, 'yuv.min=', 8.0)
('yuv.max=', 224.0, 'yuv.min=', 59.0)
('yuv.max=', 231.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 23.0)
('yuv.max=', 237.0, 'yuv.min=', 56.0)
('yuv.max=', 226.0, 'yuv.min=', 62.0)
('yuv.max=', 181.0, 'yuv.min=', 12.0)
('yuv.max=', 243.0, 'yuv.min=', 32.0)
('yuv.max=', 192.0, 'yuv.min=', 13.0)
('yuv.max=', 224.0, 'yuv.min=', 34.0)
('yuv.max=', 190.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 30.0)
('yuv.max=', 193.0, 'yuv.min=', 18.0)
('yuv.max=', 247.0, 'yuv.min=', 39.0)
('yuv.max=', 239.0, 'yuv.min=', 9.0)
('yuv.max=', 236.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 193.0, 'yuv.min=', 37.0)
('yuv.max=', 202.0, 'yuv.min=', 13.0)
('yuv.max=', 237.0, 'yuv.min=', 49.0)
('yuv.max=', 200.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 18.0)
('yuv.max=', 235.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 58.0)
('yuv.max=', 237.0, 'yuv.min=', 35.0)
('yuv.max=', 225.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 203.0, 'yuv.min=', 15.0)
('yuv.max=', 251.0, 'yuv.min=', 14.0)
('yuv.max=', 236.0, 'yuv.min=', 17.0)
('yuv.max=', 250.0, 'yuv.min=', 1.0)
('yuv.max=', 221.0, 'yuv.min=', 6.0)
('yuv.max=', 167.0, 'yuv.min=', 14.0)
('yuv.max=', 222.0, 'yuv.min=', 3.0)
('yuv.max=', 228.0, 'yuv.min=', 48.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 185.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 226.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 25.0)
('yuv.max=', 229.0, 'yuv.min=', 31.0)
('yuv.max=', 180.0, 'yuv.min=', 18.0)
('yuv.max=', 254.0, 'yuv.min=', 11.0)
('yuv.max=', 151.0, 'yuv.min=', 10.0)
('yuv.max=', 210.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 83.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 242.0, 'yuv.min=', 29.0)
('yuv.max=', 252.0, 'yuv.min=', 27.0)
('yuv.max=', 250.0, 'yuv.min=', 50.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 223.0, 'yuv.min=', 17.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 177.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 240.0, 'yuv.min=', 11.0)
('yuv.max=', 240.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 251.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 46.0)
('yuv.max=', 253.0, 'yuv.min=', 10.0)
('yuv.max=', 182.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 252.0, 'yuv.min=', 12.0)
('yuv.max=', 220.0, 'yuv.min=', 29.0)
('yuv.max=', 244.0, 'yuv.min=', 49.0)
('yuv.max=', 214.0, 'yuv.min=', 7.0)
('yuv.max=', 229.0, 'yuv.min=', 20.0)
('yuv.max=', 231.0, 'yuv.min=', 25.0)
('yuv.max=', 252.0, 'yuv.min=', 32.0)
('yuv.max=', 243.0, 'yuv.min=', 22.0)
('yuv.max=', 178.0, 'yuv.min=', 43.0)
('yuv.max=', 245.0, 'yuv.min=', 29.0)
('yuv.max=', 236.0, 'yuv.min=', 31.0)
('yuv.max=', 246.0, 'yuv.min=', 67.0)
('yuv.max=', 249.0, 'yuv.min=', 73.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 229.0, 'yuv.min=', 23.0)
('yuv.max=', 245.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 239.0, 'yuv.min=', 6.0)
('yuv.max=', 250.0, 'yuv.min=', 2.0)
('yuv.max=', 225.0, 'yuv.min=', 15.0)
('yuv.max=', 197.0, 'yuv.min=', 64.0)
('yuv.max=', 213.0, 'yuv.min=', 3.0)
('yuv.max=', 239.0, 'yuv.min=', 0.0)
('yuv.max=', 215.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 224.0, 'yuv.min=', 19.0)
('yuv.max=', 214.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 249.0, 'yuv.min=', 36.0)
('yuv.max=', 228.0, 'yuv.min=', 55.0)
('yuv.max=', 201.0, 'yuv.min=', 21.0)
('yuv.max=', 225.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 230.0, 'yuv.min=', 2.0)
('yuv.max=', 205.0, 'yuv.min=', 5.0)
('yuv.max=', 228.0, 'yuv.min=', 65.0)
('yuv.max=', 234.0, 'yuv.min=', 27.0)
('yuv.max=', 252.0, 'yuv.min=', 17.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 188.0, 'yuv.min=', 33.0)
('yuv.max=', 145.0, 'yuv.min=', 6.0)
('yuv.max=', 230.0, 'yuv.min=', 49.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 244.0, 'yuv.min=', 27.0)
('yuv.max=', 178.0, 'yuv.min=', 55.0)
('yuv.max=', 242.0, 'yuv.min=', 4.0)
('yuv.max=', 240.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 86.0)
('yuv.max=', 167.0, 'yuv.min=', 33.0)
('yuv.max=', 219.0, 'yuv.min=', 2.0)
('yuv.max=', 234.0, 'yuv.min=', 20.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 34.0)
('yuv.max=', 228.0, 'yuv.min=', 26.0)
('yuv.max=', 238.0, 'yuv.min=', 23.0)
('yuv.max=', 241.0, 'yuv.min=', 11.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 211.0, 'yuv.min=', 1.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 181.0, 'yuv.min=', 41.0)
('yuv.max=', 250.0, 'yuv.min=', 5.0)
('yuv.max=', 249.0, 'yuv.min=', 19.0)
('yuv.max=', 247.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 34.0)
('yuv.max=', 242.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 220.0, 'yuv.min=', 23.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 197.0, 'yuv.min=', 13.0)
('yuv.max=', 199.0, 'yuv.min=', 37.0)
('yuv.max=', 197.0, 'yuv.min=', 29.0)
('yuv.max=', 201.0, 'yuv.min=', 54.0)
('yuv.max=', 177.0, 'yuv.min=', 28.0)
('yuv.max=', 202.0, 'yuv.min=', 48.0)
('yuv.max=', 240.0, 'yuv.min=', 0.0)
('yuv.max=', 209.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 53.0)
('yuv.max=', 249.0, 'yuv.min=', 26.0)
('yuv.max=', 248.0, 'yuv.min=', 26.0)
('yuv.max=', 216.0, 'yuv.min=', 37.0)
('yuv.max=', 209.0, 'yuv.min=', 52.0)
('yuv.max=', 180.0, 'yuv.min=', 14.0)
('yuv.max=', 237.0, 'yuv.min=', 34.0)
('yuv.max=', 231.0, 'yuv.min=', 51.0)
('yuv.max=', 254.0, 'yuv.min=', 31.0)
('yuv.max=', 227.0, 'yuv.min=', 5.0)
('yuv.max=', 242.0, 'yuv.min=', 6.0)
('yuv.max=', 227.0, 'yuv.min=', 10.0)
('yuv.max=', 241.0, 'yuv.min=', 5.0)
('yuv.max=', 173.0, 'yuv.min=', 8.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 216.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 109.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 245.0, 'yuv.min=', 11.0)
('yuv.max=', 252.0, 'yuv.min=', 76.0)
('yuv.max=', 238.0, 'yuv.min=', 12.0)
('yuv.max=', 204.0, 'yuv.min=', 63.0)
('yuv.max=', 215.0, 'yuv.min=', 0.0)
('yuv.max=', 210.0, 'yuv.min=', 28.0)
('yuv.max=', 239.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 195.0, 'yuv.min=', 66.0)
('yuv.max=', 223.0, 'yuv.min=', 41.0)
('yuv.max=', 235.0, 'yuv.min=', 50.0)
('yuv.max=', 188.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 201.0, 'yuv.min=', 8.0)
('yuv.max=', 230.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 241.0, 'yuv.min=', 58.0)
('yuv.max=', 206.0, 'yuv.min=', 24.0)
('yuv.max=', 213.0, 'yuv.min=', 26.0)
('yuv.max=', 233.0, 'yuv.min=', 6.0)
('yuv.max=', 233.0, 'yuv.min=', 25.0)
('yuv.max=', 247.0, 'yuv.min=', 72.0)
('yuv.max=', 255.0, 'yuv.min=', 79.0)
('yuv.max=', 233.0, 'yuv.min=', 37.0)
('yuv.max=', 200.0, 'yuv.min=', 46.0)
('yuv.max=', 234.0, 'yuv.min=', 3.0)
('yuv.max=', 254.0, 'yuv.min=', 62.0)
('yuv.max=', 195.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 23.0)
('yuv.max=', 240.0, 'yuv.min=', 23.0)
('yuv.max=', 240.0, 'yuv.min=', 43.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 169.0, 'yuv.min=', 26.0)
('yuv.max=', 210.0, 'yuv.min=', 51.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 249.0, 'yuv.min=', 19.0)
('yuv.max=', 223.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 249.0, 'yuv.min=', 46.0)
('yuv.max=', 251.0, 'yuv.min=', 37.0)
('yuv.max=', 179.0, 'yuv.min=', 47.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 222.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 214.0, 'yuv.min=', 32.0)
('yuv.max=', 186.0, 'yuv.min=', 32.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 230.0, 'yuv.min=', 19.0)
('yuv.max=', 246.0, 'yuv.min=', 27.0)
('yuv.max=', 252.0, 'yuv.min=', 49.0)
('yuv.max=', 237.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 220.0, 'yuv.min=', 26.0)
('yuv.max=', 221.0, 'yuv.min=', 0.0)
('yuv.max=', 228.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 233.0, 'yuv.min=', 3.0)
('yuv.max=', 252.0, 'yuv.min=', 5.0)
('yuv.max=', 223.0, 'yuv.min=', 54.0)
('yuv.max=', 253.0, 'yuv.min=', 33.0)
('yuv.max=', 186.0, 'yuv.min=', 54.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 216.0, 'yuv.min=', 21.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 79.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 238.0, 'yuv.min=', 22.0)
('yuv.max=', 244.0, 'yuv.min=', 26.0)
('yuv.max=', 235.0, 'yuv.min=', 9.0)
('yuv.max=', 198.0, 'yuv.min=', 15.0)
('yuv.max=', 226.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 221.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 18.0)
('yuv.max=', 234.0, 'yuv.min=', 3.0)
('yuv.max=', 243.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 68.0)
('yuv.max=', 171.0, 'yuv.min=', 9.0)
('yuv.max=', 174.0, 'yuv.min=', 21.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 247.0, 'yuv.min=', 56.0)
('yuv.max=', 210.0, 'yuv.min=', 9.0)
('yuv.max=', 219.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 10.0)
('yuv.max=', 200.0, 'yuv.min=', 57.0)
('yuv.max=', 224.0, 'yuv.min=', 15.0)
('yuv.max=', 220.0, 'yuv.min=', 28.0)
('yuv.max=', 228.0, 'yuv.min=', 44.0)
('yuv.max=', 241.0, 'yuv.min=', 42.0)
('yuv.max=', 235.0, 'yuv.min=', 24.0)
('yuv.max=', 223.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 24.0)
('yuv.max=', 179.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 246.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 242.0, 'yuv.min=', 35.0)
('yuv.max=', 182.0, 'yuv.min=', 27.0)
('yuv.max=', 243.0, 'yuv.min=', 28.0)
('yuv.max=', 248.0, 'yuv.min=', 7.0)
('yuv.max=', 227.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 3.0)
('yuv.max=', 245.0, 'yuv.min=', 31.0)
('yuv.max=', 249.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 217.0, 'yuv.min=', 28.0)
('yuv.max=', 229.0, 'yuv.min=', 48.0)
('yuv.max=', 233.0, 'yuv.min=', 16.0)
('yuv.max=', 166.0, 'yuv.min=', 40.0)
('yuv.max=', 233.0, 'yuv.min=', 67.0)
('yuv.max=', 236.0, 'yuv.min=', 26.0)
('yuv.max=', 213.0, 'yuv.min=', 42.0)
('yuv.max=', 233.0, 'yuv.min=', 48.0)
('yuv.max=', 170.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 29.0)
('yuv.max=', 241.0, 'yuv.min=', 52.0)
('yuv.max=', 251.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 226.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 56.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 37.0)
('yuv.max=', 242.0, 'yuv.min=', 22.0)
('yuv.max=', 242.0, 'yuv.min=', 47.0)
('yuv.max=', 194.0, 'yuv.min=', 3.0)
('yuv.max=', 198.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 196.0, 'yuv.min=', 18.0)
('yuv.max=', 217.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 32.0)
('yuv.max=', 228.0, 'yuv.min=', 26.0)
('yuv.max=', 209.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 238.0, 'yuv.min=', 40.0)
('yuv.max=', 219.0, 'yuv.min=', 6.0)
('yuv.max=', 224.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 239.0, 'yuv.min=', 41.0)
('yuv.max=', 216.0, 'yuv.min=', 70.0)
('yuv.max=', 233.0, 'yuv.min=', 19.0)
('yuv.max=', 187.0, 'yuv.min=', 36.0)
('yuv.max=', 237.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 247.0, 'yuv.min=', 2.0)
('yuv.max=', 248.0, 'yuv.min=', 32.0)
('yuv.max=', 234.0, 'yuv.min=', 19.0)
('yuv.max=', 225.0, 'yuv.min=', 20.0)
('yuv.max=', 224.0, 'yuv.min=', 12.0)
('yuv.max=', 239.0, 'yuv.min=', 13.0)
('yuv.max=', 228.0, 'yuv.min=', 38.0)
('yuv.max=', 248.0, 'yuv.min=', 74.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 56.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 195.0, 'yuv.min=', 32.0)
('yuv.max=', 241.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 220.0, 'yuv.min=', 17.0)
('yuv.max=', 226.0, 'yuv.min=', 32.0)
('yuv.max=', 246.0, 'yuv.min=', 34.0)
('yuv.max=', 252.0, 'yuv.min=', 34.0)
('yuv.max=', 245.0, 'yuv.min=', 31.0)
('yuv.max=', 245.0, 'yuv.min=', 50.0)
('yuv.max=', 224.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 209.0, 'yuv.min=', 5.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 2.0)
('yuv.max=', 232.0, 'yuv.min=', 49.0)
('yuv.max=', 236.0, 'yuv.min=', 48.0)
('yuv.max=', 250.0, 'yuv.min=', 5.0)
('yuv.max=', 236.0, 'yuv.min=', 35.0)
('yuv.max=', 214.0, 'yuv.min=', 6.0)
('yuv.max=', 185.0, 'yuv.min=', 20.0)
('yuv.max=', 247.0, 'yuv.min=', 24.0)
('yuv.max=', 212.0, 'yuv.min=', 38.0)
('yuv.max=', 228.0, 'yuv.min=', 0.0)
('yuv.max=', 235.0, 'yuv.min=', 34.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 241.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 108.0)
('yuv.max=', 245.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 27.0)
('yuv.max=', 234.0, 'yuv.min=', 10.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 30.0)
('yuv.max=', 205.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 206.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 240.0, 'yuv.min=', 3.0)
('yuv.max=', 213.0, 'yuv.min=', 39.0)
('yuv.max=', 249.0, 'yuv.min=', 58.0)
('yuv.max=', 214.0, 'yuv.min=', 30.0)
('yuv.max=', 250.0, 'yuv.min=', 72.0)
('yuv.max=', 242.0, 'yuv.min=', 17.0)
('yuv.max=', 248.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 199.0, 'yuv.min=', 42.0)
('yuv.max=', 227.0, 'yuv.min=', 21.0)
('yuv.max=', 224.0, 'yuv.min=', 11.0)
('yuv.max=', 240.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 161.0, 'yuv.min=', 10.0)
('yuv.max=', 248.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 245.0, 'yuv.min=', 29.0)
('yuv.max=', 237.0, 'yuv.min=', 2.0)
('yuv.max=', 160.0, 'yuv.min=', 39.0)
('yuv.max=', 234.0, 'yuv.min=', 9.0)
('yuv.max=', 161.0, 'yuv.min=', 36.0)
('yuv.max=', 242.0, 'yuv.min=', 3.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 173.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 240.0, 'yuv.min=', 7.0)
('yuv.max=', 223.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 225.0, 'yuv.min=', 60.0)
('yuv.max=', 205.0, 'yuv.min=', 2.0)
('yuv.max=', 213.0, 'yuv.min=', 27.0)
('yuv.max=', 245.0, 'yuv.min=', 13.0)
('yuv.max=', 240.0, 'yuv.min=', 33.0)
('yuv.max=', 250.0, 'yuv.min=', 46.0)
('yuv.max=', 254.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 64.0)
('yuv.max=', 243.0, 'yuv.min=', 9.0)
('yuv.max=', 207.0, 'yuv.min=', 58.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 248.0, 'yuv.min=', 54.0)
('yuv.max=', 240.0, 'yuv.min=', 5.0)
('yuv.max=', 230.0, 'yuv.min=', 15.0)
('yuv.max=', 236.0, 'yuv.min=', 18.0)
('yuv.max=', 254.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 24.0)
('yuv.max=', 218.0, 'yuv.min=', 9.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 228.0, 'yuv.min=', 49.0)
('yuv.max=', 201.0, 'yuv.min=', 54.0)
('yuv.max=', 254.0, 'yuv.min=', 33.0)
('yuv.max=', 246.0, 'yuv.min=', 32.0)
('yuv.max=', 238.0, 'yuv.min=', 45.0)
('yuv.max=', 202.0, 'yuv.min=', 42.0)
('yuv.max=', 247.0, 'yuv.min=', 32.0)
('yuv.max=', 245.0, 'yuv.min=', 6.0)
('yuv.max=', 162.0, 'yuv.min=', 9.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 206.0, 'yuv.min=', 4.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 250.0, 'yuv.min=', 44.0)
('yuv.max=', 239.0, 'yuv.min=', 2.0)
('yuv.max=', 237.0, 'yuv.min=', 3.0)
('yuv.max=', 241.0, 'yuv.min=', 25.0)
('yuv.max=', 232.0, 'yuv.min=', 53.0)
('yuv.max=', 239.0, 'yuv.min=', 24.0)
('yuv.max=', 182.0, 'yuv.min=', 52.0)
('yuv.max=', 184.0, 'yuv.min=', 83.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 212.0, 'yuv.min=', 33.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 254.0, 'yuv.min=', 24.0)
('yuv.max=', 223.0, 'yuv.min=', 52.0)
('yuv.max=', 253.0, 'yuv.min=', 6.0)
('yuv.max=', 241.0, 'yuv.min=', 53.0)
('yuv.max=', 189.0, 'yuv.min=', 38.0)
('yuv.max=', 237.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 16.0)
('yuv.max=', 211.0, 'yuv.min=', 12.0)
('yuv.max=', 233.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 207.0, 'yuv.min=', 50.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 201.0, 'yuv.min=', 22.0)
('yuv.max=', 199.0, 'yuv.min=', 16.0)
('yuv.max=', 245.0, 'yuv.min=', 16.0)
('yuv.max=', 246.0, 'yuv.min=', 50.0)
('yuv.max=', 248.0, 'yuv.min=', 62.0)
('yuv.max=', 222.0, 'yuv.min=', 27.0)
('yuv.max=', 198.0, 'yuv.min=', 32.0)
('yuv.max=', 253.0, 'yuv.min=', 12.0)
('yuv.max=', 210.0, 'yuv.min=', 31.0)
('yuv.max=', 238.0, 'yuv.min=', 34.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 56.0)
('yuv.max=', 254.0, 'yuv.min=', 13.0)
('yuv.max=', 226.0, 'yuv.min=', 22.0)
('yuv.max=', 200.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 166.0, 'yuv.min=', 19.0)
('yuv.max=', 252.0, 'yuv.min=', 3.0)
('yuv.max=', 241.0, 'yuv.min=', 25.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 216.0, 'yuv.min=', 12.0)
('yuv.max=', 246.0, 'yuv.min=', 15.0)
('yuv.max=', 197.0, 'yuv.min=', 49.0)
('yuv.max=', 194.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 224.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 219.0, 'yuv.min=', 22.0)
('yuv.max=', 248.0, 'yuv.min=', 52.0)
('yuv.max=', 215.0, 'yuv.min=', 46.0)
('yuv.max=', 184.0, 'yuv.min=', 46.0)
('yuv.max=', 192.0, 'yuv.min=', 21.0)
('yuv.max=', 224.0, 'yuv.min=', 32.0)
('yuv.max=', 229.0, 'yuv.min=', 10.0)
('yuv.max=', 136.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 1.0)
('yuv.max=', 231.0, 'yuv.min=', 1.0)
('yuv.max=', 228.0, 'yuv.min=', 60.0)
('yuv.max=', 216.0, 'yuv.min=', 13.0)
('yuv.max=', 208.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 234.0, 'yuv.min=', 66.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 57.0)
('yuv.max=', 234.0, 'yuv.min=', 65.0)
('yuv.max=', 208.0, 'yuv.min=', 45.0)
('yuv.max=', 181.0, 'yuv.min=', 1.0)
('yuv.max=', 233.0, 'yuv.min=', 9.0)
('yuv.max=', 248.0, 'yuv.min=', 19.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 16.0)
('yuv.max=', 210.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 228.0, 'yuv.min=', 22.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 234.0, 'yuv.min=', 21.0)
('yuv.max=', 182.0, 'yuv.min=', 29.0)
('yuv.max=', 214.0, 'yuv.min=', 27.0)
('yuv.max=', 210.0, 'yuv.min=', 19.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 222.0, 'yuv.min=', 16.0)
('yuv.max=', 205.0, 'yuv.min=', 60.0)
('yuv.max=', 216.0, 'yuv.min=', 22.0)
('yuv.max=', 246.0, 'yuv.min=', 31.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 55.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 249.0, 'yuv.min=', 19.0)
('yuv.max=', 231.0, 'yuv.min=', 45.0)
('yuv.max=', 213.0, 'yuv.min=', 32.0)
('yuv.max=', 251.0, 'yuv.min=', 5.0)
('yuv.max=', 228.0, 'yuv.min=', 55.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 186.0, 'yuv.min=', 5.0)
('yuv.max=', 182.0, 'yuv.min=', 22.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 14.0)
('yuv.max=', 233.0, 'yuv.min=', 5.0)
('yuv.max=', 223.0, 'yuv.min=', 9.0)
('yuv.max=', 237.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 245.0, 'yuv.min=', 26.0)
('yuv.max=', 240.0, 'yuv.min=', 25.0)
('yuv.max=', 217.0, 'yuv.min=', 15.0)
('yuv.max=', 226.0, 'yuv.min=', 34.0)
('yuv.max=', 229.0, 'yuv.min=', 46.0)
('yuv.max=', 194.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 12.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 191.0, 'yuv.min=', 29.0)
('yuv.max=', 254.0, 'yuv.min=', 31.0)
('yuv.max=', 254.0, 'yuv.min=', 22.0)
('yuv.max=', 242.0, 'yuv.min=', 10.0)
('yuv.max=', 240.0, 'yuv.min=', 13.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 249.0, 'yuv.min=', 20.0)
('yuv.max=', 198.0, 'yuv.min=', 13.0)
('yuv.max=', 250.0, 'yuv.min=', 54.0)
('yuv.max=', 245.0, 'yuv.min=', 31.0)
('yuv.max=', 250.0, 'yuv.min=', 42.0)
('yuv.max=', 175.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 190.0, 'yuv.min=', 35.0)
('yuv.max=', 249.0, 'yuv.min=', 36.0)
('yuv.max=', 205.0, 'yuv.min=', 55.0)
('yuv.max=', 251.0, 'yuv.min=', 68.0)
('yuv.max=', 232.0, 'yuv.min=', 24.0)
('yuv.max=', 221.0, 'yuv.min=', 36.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 227.0, 'yuv.min=', 62.0)
('yuv.max=', 226.0, 'yuv.min=', 40.0)
('yuv.max=', 212.0, 'yuv.min=', 5.0)
('yuv.max=', 210.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 246.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 27.0)
('yuv.max=', 222.0, 'yuv.min=', 32.0)
('yuv.max=', 250.0, 'yuv.min=', 34.0)
('yuv.max=', 225.0, 'yuv.min=', 48.0)
('yuv.max=', 200.0, 'yuv.min=', 68.0)
('yuv.max=', 141.0, 'yuv.min=', 12.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 218.0, 'yuv.min=', 34.0)
('yuv.max=', 236.0, 'yuv.min=', 53.0)
('yuv.max=', 245.0, 'yuv.min=', 53.0)
('yuv.max=', 233.0, 'yuv.min=', 29.0)
('yuv.max=', 245.0, 'yuv.min=', 48.0)
('yuv.max=', 247.0, 'yuv.min=', 34.0)
('yuv.max=', 249.0, 'yuv.min=', 7.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 250.0, 'yuv.min=', 3.0)
('yuv.max=', 184.0, 'yuv.min=', 21.0)
('yuv.max=', 245.0, 'yuv.min=', 29.0)
('yuv.max=', 250.0, 'yuv.min=', 17.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 239.0, 'yuv.min=', 16.0)
('yuv.max=', 250.0, 'yuv.min=', 54.0)
('yuv.max=', 185.0, 'yuv.min=', 33.0)
('yuv.max=', 200.0, 'yuv.min=', 33.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 229.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 49.0)
('yuv.max=', 252.0, 'yuv.min=', 57.0)
('yuv.max=', 249.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 52.0)
('yuv.max=', 236.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 222.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 243.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 237.0, 'yuv.min=', 22.0)
('yuv.max=', 243.0, 'yuv.min=', 24.0)
('yuv.max=', 247.0, 'yuv.min=', 47.0)
('yuv.max=', 250.0, 'yuv.min=', 4.0)
('yuv.max=', 229.0, 'yuv.min=', 32.0)
('yuv.max=', 233.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 68.0)
('yuv.max=', 215.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 202.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 238.0, 'yuv.min=', 48.0)
('yuv.max=', 240.0, 'yuv.min=', 15.0)
('yuv.max=', 237.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 175.0, 'yuv.min=', 55.0)
('yuv.max=', 254.0, 'yuv.min=', 25.0)
('yuv.max=', 179.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 34.0)
('yuv.max=', 254.0, 'yuv.min=', 40.0)
('yuv.max=', 237.0, 'yuv.min=', 3.0)
('yuv.max=', 218.0, 'yuv.min=', 13.0)
('yuv.max=', 248.0, 'yuv.min=', 17.0)
('yuv.max=', 244.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 251.0, 'yuv.min=', 46.0)
('yuv.max=', 245.0, 'yuv.min=', 80.0)
('yuv.max=', 249.0, 'yuv.min=', 6.0)
('yuv.max=', 217.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 16.0)
('yuv.max=', 250.0, 'yuv.min=', 32.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 210.0, 'yuv.min=', 55.0)
('yuv.max=', 251.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 196.0, 'yuv.min=', 15.0)
('yuv.max=', 171.0, 'yuv.min=', 17.0)
('yuv.max=', 249.0, 'yuv.min=', 2.0)
('yuv.max=', 162.0, 'yuv.min=', 18.0)
('yuv.max=', 227.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 50.0)
('yuv.max=', 187.0, 'yuv.min=', 8.0)
('yuv.max=', 242.0, 'yuv.min=', 3.0)
('yuv.max=', 228.0, 'yuv.min=', 0.0)
('yuv.max=', 251.0, 'yuv.min=', 19.0)
('yuv.max=', 252.0, 'yuv.min=', 40.0)
('yuv.max=', 240.0, 'yuv.min=', 6.0)
('yuv.max=', 246.0, 'yuv.min=', 28.0)
('yuv.max=', 221.0, 'yuv.min=', 30.0)
('yuv.max=', 226.0, 'yuv.min=', 4.0)
('yuv.max=', 226.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 219.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 202.0, 'yuv.min=', 72.0)
('yuv.max=', 255.0, 'yuv.min=', 59.0)
('yuv.max=', 205.0, 'yuv.min=', 19.0)
('yuv.max=', 221.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 17.0)
('yuv.max=', 209.0, 'yuv.min=', 46.0)
('yuv.max=', 233.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 212.0, 'yuv.min=', 39.0)
('yuv.max=', 237.0, 'yuv.min=', 41.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 216.0, 'yuv.min=', 1.0)
('yuv.max=', 168.0, 'yuv.min=', 19.0)
('yuv.max=', 239.0, 'yuv.min=', 12.0)
('yuv.max=', 252.0, 'yuv.min=', 56.0)
('yuv.max=', 230.0, 'yuv.min=', 88.0)
('yuv.max=', 252.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 248.0, 'yuv.min=', 5.0)
('yuv.max=', 245.0, 'yuv.min=', 4.0)
('yuv.max=', 247.0, 'yuv.min=', 16.0)
('yuv.max=', 242.0, 'yuv.min=', 49.0)
('yuv.max=', 205.0, 'yuv.min=', 64.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 6.0)
('yuv.max=', 238.0, 'yuv.min=', 48.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 201.0, 'yuv.min=', 2.0)
('yuv.max=', 210.0, 'yuv.min=', 31.0)
('yuv.max=', 194.0, 'yuv.min=', 31.0)
('yuv.max=', 233.0, 'yuv.min=', 13.0)
('yuv.max=', 225.0, 'yuv.min=', 5.0)
('yuv.max=', 196.0, 'yuv.min=', 63.0)
('yuv.max=', 181.0, 'yuv.min=', 37.0)
('yuv.max=', 251.0, 'yuv.min=', 29.0)
('yuv.max=', 233.0, 'yuv.min=', 60.0)
('yuv.max=', 219.0, 'yuv.min=', 7.0)
('yuv.max=', 244.0, 'yuv.min=', 18.0)
('yuv.max=', 248.0, 'yuv.min=', 1.0)
('yuv.max=', 193.0, 'yuv.min=', 35.0)
('yuv.max=', 203.0, 'yuv.min=', 28.0)
('yuv.max=', 177.0, 'yuv.min=', 4.0)
('yuv.max=', 241.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 223.0, 'yuv.min=', 45.0)
('yuv.max=', 235.0, 'yuv.min=', 11.0)
('yuv.max=', 203.0, 'yuv.min=', 28.0)
('yuv.max=', 182.0, 'yuv.min=', 27.0)
('yuv.max=', 172.0, 'yuv.min=', 58.0)
('yuv.max=', 177.0, 'yuv.min=', 17.0)
('yuv.max=', 234.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 241.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 184.0, 'yuv.min=', 38.0)
('yuv.max=', 211.0, 'yuv.min=', 13.0)
('yuv.max=', 230.0, 'yuv.min=', 3.0)
('yuv.max=', 220.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 252.0, 'yuv.min=', 9.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 200.0, 'yuv.min=', 45.0)
('yuv.max=', 194.0, 'yuv.min=', 16.0)
('yuv.max=', 230.0, 'yuv.min=', 2.0)
('yuv.max=', 244.0, 'yuv.min=', 17.0)
('yuv.max=', 184.0, 'yuv.min=', 1.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 18.0)
('yuv.max=', 236.0, 'yuv.min=', 44.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 54.0)
('yuv.max=', 238.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 227.0, 'yuv.min=', 43.0)
('yuv.max=', 185.0, 'yuv.min=', 36.0)
('yuv.max=', 197.0, 'yuv.min=', 39.0)
('yuv.max=', 254.0, 'yuv.min=', 23.0)
('yuv.max=', 209.0, 'yuv.min=', 11.0)
('yuv.max=', 240.0, 'yuv.min=', 46.0)
('yuv.max=', 194.0, 'yuv.min=', 39.0)
('yuv.max=', 238.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 250.0, 'yuv.min=', 7.0)
('yuv.max=', 208.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 238.0, 'yuv.min=', 25.0)
('yuv.max=', 214.0, 'yuv.min=', 10.0)
('yuv.max=', 227.0, 'yuv.min=', 11.0)
('yuv.max=', 225.0, 'yuv.min=', 16.0)
('yuv.max=', 236.0, 'yuv.min=', 14.0)
('yuv.max=', 225.0, 'yuv.min=', 21.0)
('yuv.max=', 188.0, 'yuv.min=', 33.0)
('yuv.max=', 218.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 251.0, 'yuv.min=', 47.0)
('yuv.max=', 250.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 246.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 233.0, 'yuv.min=', 1.0)
('yuv.max=', 247.0, 'yuv.min=', 2.0)
('yuv.max=', 226.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 207.0, 'yuv.min=', 53.0)
('yuv.max=', 240.0, 'yuv.min=', 16.0)
('yuv.max=', 243.0, 'yuv.min=', 3.0)
('yuv.max=', 225.0, 'yuv.min=', 22.0)
('yuv.max=', 195.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 3.0)
('yuv.max=', 245.0, 'yuv.min=', 28.0)
('yuv.max=', 251.0, 'yuv.min=', 9.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 48.0)
('yuv.max=', 243.0, 'yuv.min=', 36.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 252.0, 'yuv.min=', 55.0)
('yuv.max=', 235.0, 'yuv.min=', 14.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 247.0, 'yuv.min=', 32.0)
('yuv.max=', 245.0, 'yuv.min=', 40.0)
('yuv.max=', 224.0, 'yuv.min=', 0.0)
('yuv.max=', 207.0, 'yuv.min=', 14.0)
('yuv.max=', 206.0, 'yuv.min=', 20.0)
('yuv.max=', 228.0, 'yuv.min=', 22.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 201.0, 'yuv.min=', 25.0)
('yuv.max=', 218.0, 'yuv.min=', 15.0)
('yuv.max=', 237.0, 'yuv.min=', 13.0)
('yuv.max=', 248.0, 'yuv.min=', 46.0)
('yuv.max=', 235.0, 'yuv.min=', 6.0)
('yuv.max=', 243.0, 'yuv.min=', 30.0)
('yuv.max=', 225.0, 'yuv.min=', 22.0)
('yuv.max=', 245.0, 'yuv.min=', 5.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 235.0, 'yuv.min=', 9.0)
('yuv.max=', 228.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 46.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 149.0, 'yuv.min=', 4.0)
('yuv.max=', 212.0, 'yuv.min=', 78.0)
('yuv.max=', 217.0, 'yuv.min=', 37.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 228.0, 'yuv.min=', 16.0)
('yuv.max=', 253.0, 'yuv.min=', 22.0)
('yuv.max=', 242.0, 'yuv.min=', 55.0)
('yuv.max=', 238.0, 'yuv.min=', 39.0)
('yuv.max=', 226.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 187.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 27.0)
('yuv.max=', 249.0, 'yuv.min=', 13.0)
('yuv.max=', 227.0, 'yuv.min=', 5.0)
('yuv.max=', 234.0, 'yuv.min=', 16.0)
('yuv.max=', 227.0, 'yuv.min=', 28.0)
('yuv.max=', 206.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 236.0, 'yuv.min=', 28.0)
('yuv.max=', 252.0, 'yuv.min=', 6.0)
('yuv.max=', 207.0, 'yuv.min=', 42.0)
('yuv.max=', 237.0, 'yuv.min=', 30.0)
('yuv.max=', 226.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 237.0, 'yuv.min=', 34.0)
('yuv.max=', 182.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 39.0)
('yuv.max=', 224.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 97.0)
('yuv.max=', 231.0, 'yuv.min=', 6.0)
('yuv.max=', 233.0, 'yuv.min=', 12.0)
('yuv.max=', 221.0, 'yuv.min=', 31.0)
('yuv.max=', 247.0, 'yuv.min=', 44.0)
('yuv.max=', 236.0, 'yuv.min=', 8.0)
('yuv.max=', 240.0, 'yuv.min=', 46.0)
('yuv.max=', 222.0, 'yuv.min=', 27.0)
('yuv.max=', 212.0, 'yuv.min=', 63.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 216.0, 'yuv.min=', 26.0)
('yuv.max=', 229.0, 'yuv.min=', 14.0)
('yuv.max=', 185.0, 'yuv.min=', 39.0)
('yuv.max=', 174.0, 'yuv.min=', 17.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 234.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 44.0)
('yuv.max=', 156.0, 'yuv.min=', 50.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 40.0)
('yuv.max=', 211.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 32.0)
('yuv.max=', 228.0, 'yuv.min=', 21.0)
('yuv.max=', 216.0, 'yuv.min=', 33.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 163.0, 'yuv.min=', 4.0)
('yuv.max=', 213.0, 'yuv.min=', 46.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 253.0, 'yuv.min=', 26.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 238.0, 'yuv.min=', 31.0)
('yuv.max=', 226.0, 'yuv.min=', 16.0)
('yuv.max=', 203.0, 'yuv.min=', 3.0)
('yuv.max=', 210.0, 'yuv.min=', 13.0)
('yuv.max=', 222.0, 'yuv.min=', 32.0)
('yuv.max=', 193.0, 'yuv.min=', 29.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 24.0)
('yuv.max=', 167.0, 'yuv.min=', 13.0)
('yuv.max=', 195.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 66.0)
('yuv.max=', 249.0, 'yuv.min=', 16.0)
('yuv.max=', 245.0, 'yuv.min=', 67.0)
('yuv.max=', 208.0, 'yuv.min=', 65.0)
('yuv.max=', 190.0, 'yuv.min=', 28.0)
('yuv.max=', 232.0, 'yuv.min=', 51.0)
('yuv.max=', 220.0, 'yuv.min=', 20.0)
('yuv.max=', 254.0, 'yuv.min=', 63.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 37.0)
('yuv.max=', 203.0, 'yuv.min=', 43.0)
('yuv.max=', 251.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 6.0)
('yuv.max=', 216.0, 'yuv.min=', 2.0)
('yuv.max=', 244.0, 'yuv.min=', 47.0)
('yuv.max=', 210.0, 'yuv.min=', 6.0)
('yuv.max=', 221.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 3.0)
('yuv.max=', 241.0, 'yuv.min=', 25.0)
('yuv.max=', 188.0, 'yuv.min=', 58.0)
('yuv.max=', 248.0, 'yuv.min=', 65.0)
('yuv.max=', 227.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 240.0, 'yuv.min=', 22.0)
('yuv.max=', 250.0, 'yuv.min=', 6.0)
('yuv.max=', 249.0, 'yuv.min=', 1.0)
('yuv.max=', 211.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 9.0)
('yuv.max=', 252.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 244.0, 'yuv.min=', 43.0)
('yuv.max=', 166.0, 'yuv.min=', 36.0)
('yuv.max=', 251.0, 'yuv.min=', 35.0)
('yuv.max=', 253.0, 'yuv.min=', 11.0)
('yuv.max=', 249.0, 'yuv.min=', 23.0)
('yuv.max=', 243.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 214.0, 'yuv.min=', 33.0)
('yuv.max=', 243.0, 'yuv.min=', 29.0)
('yuv.max=', 252.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 52.0)
('yuv.max=', 216.0, 'yuv.min=', 17.0)
('yuv.max=', 207.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 181.0, 'yuv.min=', 10.0)
('yuv.max=', 181.0, 'yuv.min=', 44.0)
('yuv.max=', 190.0, 'yuv.min=', 16.0)
('yuv.max=', 251.0, 'yuv.min=', 62.0)
('yuv.max=', 247.0, 'yuv.min=', 23.0)
('yuv.max=', 222.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 230.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 236.0, 'yuv.min=', 36.0)
('yuv.max=', 240.0, 'yuv.min=', 11.0)
('yuv.max=', 219.0, 'yuv.min=', 16.0)
('yuv.max=', 196.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 20.0)
('yuv.max=', 195.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 244.0, 'yuv.min=', 1.0)
('yuv.max=', 244.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 201.0, 'yuv.min=', 58.0)
('yuv.max=', 208.0, 'yuv.min=', 33.0)
('yuv.max=', 144.0, 'yuv.min=', 9.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 225.0, 'yuv.min=', 61.0)
('yuv.max=', 228.0, 'yuv.min=', 3.0)
('yuv.max=', 177.0, 'yuv.min=', 74.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 240.0, 'yuv.min=', 11.0)
('yuv.max=', 245.0, 'yuv.min=', 3.0)
('yuv.max=', 199.0, 'yuv.min=', 17.0)
('yuv.max=', 166.0, 'yuv.min=', 10.0)
('yuv.max=', 232.0, 'yuv.min=', 60.0)
('yuv.max=', 252.0, 'yuv.min=', 77.0)
('yuv.max=', 178.0, 'yuv.min=', 30.0)
('yuv.max=', 248.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 198.0, 'yuv.min=', 30.0)
('yuv.max=', 246.0, 'yuv.min=', 7.0)
('yuv.max=', 223.0, 'yuv.min=', 16.0)
('yuv.max=', 231.0, 'yuv.min=', 24.0)
('yuv.max=', 209.0, 'yuv.min=', 12.0)
('yuv.max=', 238.0, 'yuv.min=', 45.0)
('yuv.max=', 238.0, 'yuv.min=', 17.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 241.0, 'yuv.min=', 0.0)
('yuv.max=', 226.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 242.0, 'yuv.min=', 19.0)
('yuv.max=', 250.0, 'yuv.min=', 37.0)
('yuv.max=', 240.0, 'yuv.min=', 9.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 230.0, 'yuv.min=', 43.0)
('yuv.max=', 241.0, 'yuv.min=', 70.0)
('yuv.max=', 226.0, 'yuv.min=', 23.0)
('yuv.max=', 244.0, 'yuv.min=', 5.0)
('yuv.max=', 240.0, 'yuv.min=', 55.0)
('yuv.max=', 250.0, 'yuv.min=', 34.0)
('yuv.max=', 231.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 4.0)
('yuv.max=', 231.0, 'yuv.min=', 36.0)
('yuv.max=', 216.0, 'yuv.min=', 25.0)
('yuv.max=', 237.0, 'yuv.min=', 16.0)
('yuv.max=', 251.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 63.0)
('yuv.max=', 216.0, 'yuv.min=', 20.0)
('yuv.max=', 202.0, 'yuv.min=', 6.0)
('yuv.max=', 233.0, 'yuv.min=', 22.0)
('yuv.max=', 242.0, 'yuv.min=', 44.0)
('yuv.max=', 194.0, 'yuv.min=', 45.0)
('yuv.max=', 245.0, 'yuv.min=', 38.0)
('yuv.max=', 253.0, 'yuv.min=', 9.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 252.0, 'yuv.min=', 3.0)
('yuv.max=', 159.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 73.0)
('yuv.max=', 246.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 199.0, 'yuv.min=', 29.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 252.0, 'yuv.min=', 28.0)
('yuv.max=', 244.0, 'yuv.min=', 8.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 231.0, 'yuv.min=', 10.0)
('yuv.max=', 251.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 157.0, 'yuv.min=', 20.0)
('yuv.max=', 246.0, 'yuv.min=', 40.0)
('yuv.max=', 251.0, 'yuv.min=', 39.0)
('yuv.max=', 239.0, 'yuv.min=', 27.0)
('yuv.max=', 225.0, 'yuv.min=', 34.0)
('yuv.max=', 176.0, 'yuv.min=', 74.0)
('yuv.max=', 213.0, 'yuv.min=', 9.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 78.0)
('yuv.max=', 208.0, 'yuv.min=', 11.0)
('yuv.max=', 250.0, 'yuv.min=', 34.0)
('yuv.max=', 156.0, 'yuv.min=', 59.0)
('yuv.max=', 229.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 39.0)
('yuv.max=', 173.0, 'yuv.min=', 13.0)
('yuv.max=', 210.0, 'yuv.min=', 18.0)
('yuv.max=', 241.0, 'yuv.min=', 22.0)
('yuv.max=', 248.0, 'yuv.min=', 10.0)
('yuv.max=', 249.0, 'yuv.min=', 25.0)
('yuv.max=', 234.0, 'yuv.min=', 51.0)
('yuv.max=', 238.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 10.0)
('yuv.max=', 221.0, 'yuv.min=', 21.0)
('yuv.max=', 240.0, 'yuv.min=', 29.0)
('yuv.max=', 221.0, 'yuv.min=', 20.0)
('yuv.max=', 231.0, 'yuv.min=', 5.0)
('yuv.max=', 237.0, 'yuv.min=', 20.0)
('yuv.max=', 230.0, 'yuv.min=', 10.0)
('yuv.max=', 243.0, 'yuv.min=', 26.0)
('yuv.max=', 230.0, 'yuv.min=', 2.0)
('yuv.max=', 249.0, 'yuv.min=', 43.0)
('yuv.max=', 178.0, 'yuv.min=', 57.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 174.0, 'yuv.min=', 53.0)
('yuv.max=', 243.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 240.0, 'yuv.min=', 27.0)
('yuv.max=', 249.0, 'yuv.min=', 11.0)
('yuv.max=', 204.0, 'yuv.min=', 21.0)
('yuv.max=', 253.0, 'yuv.min=', 44.0)
('yuv.max=', 176.0, 'yuv.min=', 26.0)
('yuv.max=', 151.0, 'yuv.min=', 3.0)
('yuv.max=', 247.0, 'yuv.min=', 8.0)
('yuv.max=', 235.0, 'yuv.min=', 32.0)
('yuv.max=', 243.0, 'yuv.min=', 2.0)
('yuv.max=', 233.0, 'yuv.min=', 28.0)
('yuv.max=', 187.0, 'yuv.min=', 3.0)
('yuv.max=', 248.0, 'yuv.min=', 7.0)
('yuv.max=', 198.0, 'yuv.min=', 25.0)
('yuv.max=', 228.0, 'yuv.min=', 54.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 220.0, 'yuv.min=', 50.0)
('yuv.max=', 247.0, 'yuv.min=', 20.0)
('yuv.max=', 238.0, 'yuv.min=', 9.0)
('yuv.max=', 211.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 228.0, 'yuv.min=', 45.0)
('yuv.max=', 197.0, 'yuv.min=', 18.0)
('yuv.max=', 233.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 235.0, 'yuv.min=', 10.0)
('yuv.max=', 251.0, 'yuv.min=', 5.0)
('yuv.max=', 242.0, 'yuv.min=', 28.0)
('yuv.max=', 231.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 242.0, 'yuv.min=', 70.0)
('yuv.max=', 184.0, 'yuv.min=', 52.0)
('yuv.max=', 246.0, 'yuv.min=', 91.0)
('yuv.max=', 238.0, 'yuv.min=', 30.0)
('yuv.max=', 238.0, 'yuv.min=', 56.0)
('yuv.max=', 247.0, 'yuv.min=', 30.0)
('yuv.max=', 203.0, 'yuv.min=', 6.0)
('yuv.max=', 207.0, 'yuv.min=', 37.0)
('yuv.max=', 223.0, 'yuv.min=', 49.0)
('yuv.max=', 237.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 247.0, 'yuv.min=', 14.0)
('yuv.max=', 218.0, 'yuv.min=', 24.0)
('yuv.max=', 228.0, 'yuv.min=', 87.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 23.0)
('yuv.max=', 249.0, 'yuv.min=', 22.0)
('yuv.max=', 252.0, 'yuv.min=', 3.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 243.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 152.0, 'yuv.min=', 41.0)
('yuv.max=', 246.0, 'yuv.min=', 51.0)
('yuv.max=', 238.0, 'yuv.min=', 2.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 231.0, 'yuv.min=', 3.0)
('yuv.max=', 244.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 64.0)
('yuv.max=', 231.0, 'yuv.min=', 61.0)
('yuv.max=', 200.0, 'yuv.min=', 85.0)
('yuv.max=', 241.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 202.0, 'yuv.min=', 21.0)
('yuv.max=', 244.0, 'yuv.min=', 40.0)
('yuv.max=', 189.0, 'yuv.min=', 19.0)
('yuv.max=', 187.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 253.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 234.0, 'yuv.min=', 25.0)
('yuv.max=', 250.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 211.0, 'yuv.min=', 18.0)
('yuv.max=', 253.0, 'yuv.min=', 15.0)
('yuv.max=', 182.0, 'yuv.min=', 16.0)
('yuv.max=', 244.0, 'yuv.min=', 24.0)
('yuv.max=', 243.0, 'yuv.min=', 32.0)
('yuv.max=', 243.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 71.0)
('yuv.max=', 250.0, 'yuv.min=', 17.0)
('yuv.max=', 223.0, 'yuv.min=', 29.0)
('yuv.max=', 234.0, 'yuv.min=', 9.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 243.0, 'yuv.min=', 28.0)
('yuv.max=', 254.0, 'yuv.min=', 40.0)
('yuv.max=', 220.0, 'yuv.min=', 39.0)
('yuv.max=', 169.0, 'yuv.min=', 4.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 222.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 238.0, 'yuv.min=', 62.0)
('yuv.max=', 241.0, 'yuv.min=', 8.0)
('yuv.max=', 254.0, 'yuv.min=', 56.0)
('yuv.max=', 232.0, 'yuv.min=', 22.0)
('yuv.max=', 235.0, 'yuv.min=', 6.0)
('yuv.max=', 240.0, 'yuv.min=', 14.0)
('yuv.max=', 247.0, 'yuv.min=', 22.0)
('yuv.max=', 248.0, 'yuv.min=', 68.0)
('yuv.max=', 244.0, 'yuv.min=', 56.0)
('yuv.max=', 254.0, 'yuv.min=', 48.0)
('yuv.max=', 219.0, 'yuv.min=', 23.0)
('yuv.max=', 250.0, 'yuv.min=', 4.0)
('yuv.max=', 247.0, 'yuv.min=', 30.0)
('yuv.max=', 237.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 215.0, 'yuv.min=', 42.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 80.0)
('yuv.max=', 246.0, 'yuv.min=', 43.0)
('yuv.max=', 237.0, 'yuv.min=', 33.0)
('yuv.max=', 249.0, 'yuv.min=', 44.0)
('yuv.max=', 226.0, 'yuv.min=', 17.0)
('yuv.max=', 234.0, 'yuv.min=', 32.0)
('yuv.max=', 218.0, 'yuv.min=', 36.0)
('yuv.max=', 234.0, 'yuv.min=', 34.0)
('yuv.max=', 251.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 203.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 246.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 236.0, 'yuv.min=', 7.0)
('yuv.max=', 204.0, 'yuv.min=', 6.0)
('yuv.max=', 218.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 56.0)
('yuv.max=', 246.0, 'yuv.min=', 23.0)
('yuv.max=', 232.0, 'yuv.min=', 0.0)
('yuv.max=', 211.0, 'yuv.min=', 1.0)
('yuv.max=', 248.0, 'yuv.min=', 39.0)
('yuv.max=', 244.0, 'yuv.min=', 15.0)
('yuv.max=', 236.0, 'yuv.min=', 8.0)
('yuv.max=', 246.0, 'yuv.min=', 17.0)
('yuv.max=', 252.0, 'yuv.min=', 26.0)
('yuv.max=', 240.0, 'yuv.min=', 44.0)
('yuv.max=', 191.0, 'yuv.min=', 16.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 21.0)
('yuv.max=', 244.0, 'yuv.min=', 28.0)
('yuv.max=', 149.0, 'yuv.min=', 19.0)
('yuv.max=', 217.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 243.0, 'yuv.min=', 43.0)
('yuv.max=', 153.0, 'yuv.min=', 2.0)
('yuv.max=', 196.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 14.0)
('yuv.max=', 237.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 209.0, 'yuv.min=', 44.0)
('yuv.max=', 228.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 249.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 237.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 214.0, 'yuv.min=', 47.0)
('yuv.max=', 220.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 236.0, 'yuv.min=', 18.0)
('yuv.max=', 197.0, 'yuv.min=', 10.0)
('yuv.max=', 237.0, 'yuv.min=', 77.0)
('yuv.max=', 222.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 70.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 234.0, 'yuv.min=', 42.0)
('yuv.max=', 172.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 34.0)
('yuv.max=', 220.0, 'yuv.min=', 30.0)
('yuv.max=', 215.0, 'yuv.min=', 4.0)
('yuv.max=', 178.0, 'yuv.min=', 9.0)
('yuv.max=', 180.0, 'yuv.min=', 55.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 252.0, 'yuv.min=', 23.0)
('yuv.max=', 210.0, 'yuv.min=', 25.0)
('yuv.max=', 244.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 207.0, 'yuv.min=', 68.0)
('yuv.max=', 240.0, 'yuv.min=', 39.0)
('yuv.max=', 165.0, 'yuv.min=', 51.0)
('yuv.max=', 239.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 40.0)
('yuv.max=', 248.0, 'yuv.min=', 23.0)
('yuv.max=', 241.0, 'yuv.min=', 17.0)
('yuv.max=', 253.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 37.0)
('yuv.max=', 233.0, 'yuv.min=', 34.0)
('yuv.max=', 226.0, 'yuv.min=', 55.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 24.0)
('yuv.max=', 138.0, 'yuv.min=', 6.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 254.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 235.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 243.0, 'yuv.min=', 4.0)
('yuv.max=', 248.0, 'yuv.min=', 20.0)
('yuv.max=', 220.0, 'yuv.min=', 55.0)
('yuv.max=', 248.0, 'yuv.min=', 4.0)
('yuv.max=', 238.0, 'yuv.min=', 41.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 2.0)
('yuv.max=', 215.0, 'yuv.min=', 16.0)
('yuv.max=', 156.0, 'yuv.min=', 26.0)
('yuv.max=', 212.0, 'yuv.min=', 28.0)
('yuv.max=', 210.0, 'yuv.min=', 45.0)
('yuv.max=', 214.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 228.0, 'yuv.min=', 14.0)
('yuv.max=', 139.0, 'yuv.min=', 4.0)
('yuv.max=', 231.0, 'yuv.min=', 10.0)
('yuv.max=', 155.0, 'yuv.min=', 34.0)
('yuv.max=', 241.0, 'yuv.min=', 5.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 216.0, 'yuv.min=', 15.0)
('yuv.max=', 215.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 33.0)
('yuv.max=', 233.0, 'yuv.min=', 7.0)
('yuv.max=', 244.0, 'yuv.min=', 61.0)
('yuv.max=', 207.0, 'yuv.min=', 48.0)
('yuv.max=', 246.0, 'yuv.min=', 71.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 251.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 232.0, 'yuv.min=', 5.0)
('yuv.max=', 207.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 189.0, 'yuv.min=', 13.0)
('yuv.max=', 245.0, 'yuv.min=', 14.0)
('yuv.max=', 218.0, 'yuv.min=', 47.0)
('yuv.max=', 181.0, 'yuv.min=', 7.0)
('yuv.max=', 248.0, 'yuv.min=', 1.0)
('yuv.max=', 235.0, 'yuv.min=', 6.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 224.0, 'yuv.min=', 52.0)
('yuv.max=', 246.0, 'yuv.min=', 37.0)
('yuv.max=', 198.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 15.0)
('yuv.max=', 233.0, 'yuv.min=', 21.0)
('yuv.max=', 217.0, 'yuv.min=', 119.0)
('yuv.max=', 252.0, 'yuv.min=', 31.0)
('yuv.max=', 238.0, 'yuv.min=', 17.0)
('yuv.max=', 243.0, 'yuv.min=', 20.0)
('yuv.max=', 217.0, 'yuv.min=', 11.0)
('yuv.max=', 237.0, 'yuv.min=', 33.0)
('yuv.max=', 225.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 218.0, 'yuv.min=', 3.0)
('yuv.max=', 202.0, 'yuv.min=', 12.0)
('yuv.max=', 237.0, 'yuv.min=', 1.0)
('yuv.max=', 217.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 217.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 196.0, 'yuv.min=', 10.0)
('yuv.max=', 251.0, 'yuv.min=', 34.0)
('yuv.max=', 250.0, 'yuv.min=', 27.0)
('yuv.max=', 244.0, 'yuv.min=', 16.0)
('yuv.max=', 236.0, 'yuv.min=', 48.0)
('yuv.max=', 217.0, 'yuv.min=', 33.0)
('yuv.max=', 243.0, 'yuv.min=', 2.0)
('yuv.max=', 230.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 252.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 240.0, 'yuv.min=', 16.0)
('yuv.max=', 252.0, 'yuv.min=', 14.0)
('yuv.max=', 237.0, 'yuv.min=', 4.0)
('yuv.max=', 205.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 234.0, 'yuv.min=', 32.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 159.0, 'yuv.min=', 43.0)
('yuv.max=', 248.0, 'yuv.min=', 56.0)
('yuv.max=', 238.0, 'yuv.min=', 2.0)
('yuv.max=', 246.0, 'yuv.min=', 11.0)
('yuv.max=', 234.0, 'yuv.min=', 48.0)
('yuv.max=', 209.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 11.0)
('yuv.max=', 213.0, 'yuv.min=', 8.0)
('yuv.max=', 215.0, 'yuv.min=', 37.0)
('yuv.max=', 209.0, 'yuv.min=', 10.0)
('yuv.max=', 250.0, 'yuv.min=', 21.0)
('yuv.max=', 245.0, 'yuv.min=', 29.0)
('yuv.max=', 187.0, 'yuv.min=', 12.0)
('yuv.max=', 200.0, 'yuv.min=', 30.0)
('yuv.max=', 242.0, 'yuv.min=', 15.0)
('yuv.max=', 235.0, 'yuv.min=', 37.0)
('yuv.max=', 237.0, 'yuv.min=', 56.0)
('yuv.max=', 180.0, 'yuv.min=', 19.0)
('yuv.max=', 247.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 24.0)
('yuv.max=', 239.0, 'yuv.min=', 31.0)
('yuv.max=', 241.0, 'yuv.min=', 26.0)
('yuv.max=', 209.0, 'yuv.min=', 12.0)
('yuv.max=', 196.0, 'yuv.min=', 14.0)
('yuv.max=', 209.0, 'yuv.min=', 0.0)
('yuv.max=', 152.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 184.0, 'yuv.min=', 7.0)
('yuv.max=', 237.0, 'yuv.min=', 5.0)
('yuv.max=', 189.0, 'yuv.min=', 2.0)
('yuv.max=', 232.0, 'yuv.min=', 10.0)
('yuv.max=', 229.0, 'yuv.min=', 38.0)
('yuv.max=', 217.0, 'yuv.min=', 1.0)
('yuv.max=', 247.0, 'yuv.min=', 23.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 56.0)
('yuv.max=', 245.0, 'yuv.min=', 63.0)
('yuv.max=', 218.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 208.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 203.0, 'yuv.min=', 19.0)
('yuv.max=', 145.0, 'yuv.min=', 20.0)
('yuv.max=', 242.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 227.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 13.0)
('yuv.max=', 251.0, 'yuv.min=', 29.0)
('yuv.max=', 244.0, 'yuv.min=', 2.0)
('yuv.max=', 212.0, 'yuv.min=', 81.0)
('yuv.max=', 251.0, 'yuv.min=', 81.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 231.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 58.0)
('yuv.max=', 231.0, 'yuv.min=', 7.0)
('yuv.max=', 251.0, 'yuv.min=', 19.0)
('yuv.max=', 182.0, 'yuv.min=', 1.0)
('yuv.max=', 230.0, 'yuv.min=', 32.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 226.0, 'yuv.min=', 63.0)
('yuv.max=', 146.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 59.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 220.0, 'yuv.min=', 17.0)
('yuv.max=', 230.0, 'yuv.min=', 4.0)
('yuv.max=', 244.0, 'yuv.min=', 75.0)
('yuv.max=', 248.0, 'yuv.min=', 15.0)
('yuv.max=', 236.0, 'yuv.min=', 17.0)
('yuv.max=', 243.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 245.0, 'yuv.min=', 8.0)
('yuv.max=', 174.0, 'yuv.min=', 45.0)
('yuv.max=', 246.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 66.0)
('yuv.max=', 189.0, 'yuv.min=', 44.0)
('yuv.max=', 165.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 247.0, 'yuv.min=', 40.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 250.0, 'yuv.min=', 27.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 22.0)
('yuv.max=', 245.0, 'yuv.min=', 34.0)
('yuv.max=', 173.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 79.0)
('yuv.max=', 251.0, 'yuv.min=', 9.0)
('yuv.max=', 194.0, 'yuv.min=', 7.0)
('yuv.max=', 235.0, 'yuv.min=', 9.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 219.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 217.0, 'yuv.min=', 0.0)
('yuv.max=', 226.0, 'yuv.min=', 10.0)
('yuv.max=', 230.0, 'yuv.min=', 15.0)
('yuv.max=', 246.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 19.0)
('yuv.max=', 248.0, 'yuv.min=', 12.0)
('yuv.max=', 247.0, 'yuv.min=', 13.0)
('yuv.max=', 250.0, 'yuv.min=', 2.0)
('yuv.max=', 237.0, 'yuv.min=', 28.0)
('yuv.max=', 254.0, 'yuv.min=', 49.0)
('yuv.max=', 157.0, 'yuv.min=', 22.0)
('yuv.max=', 177.0, 'yuv.min=', 36.0)
('yuv.max=', 159.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 39.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 226.0, 'yuv.min=', 43.0)
('yuv.max=', 156.0, 'yuv.min=', 38.0)
('yuv.max=', 200.0, 'yuv.min=', 30.0)
('yuv.max=', 253.0, 'yuv.min=', 75.0)
('yuv.max=', 255.0, 'yuv.min=', 74.0)
('yuv.max=', 227.0, 'yuv.min=', 12.0)
('yuv.max=', 158.0, 'yuv.min=', 7.0)
('yuv.max=', 246.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 253.0, 'yuv.min=', 3.0)
('yuv.max=', 250.0, 'yuv.min=', 5.0)
('yuv.max=', 231.0, 'yuv.min=', 0.0)
('yuv.max=', 226.0, 'yuv.min=', 13.0)
('yuv.max=', 247.0, 'yuv.min=', 72.0)
('yuv.max=', 225.0, 'yuv.min=', 56.0)
('yuv.max=', 244.0, 'yuv.min=', 19.0)
('yuv.max=', 172.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 172.0, 'yuv.min=', 34.0)
('yuv.max=', 227.0, 'yuv.min=', 32.0)
('yuv.max=', 226.0, 'yuv.min=', 36.0)
('yuv.max=', 234.0, 'yuv.min=', 36.0)
('yuv.max=', 245.0, 'yuv.min=', 12.0)
('yuv.max=', 241.0, 'yuv.min=', 92.0)
('yuv.max=', 196.0, 'yuv.min=', 46.0)
('yuv.max=', 229.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 27.0)
('yuv.max=', 250.0, 'yuv.min=', 19.0)
('yuv.max=', 239.0, 'yuv.min=', 6.0)
('yuv.max=', 254.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 188.0, 'yuv.min=', 41.0)
('yuv.max=', 238.0, 'yuv.min=', 52.0)
('yuv.max=', 253.0, 'yuv.min=', 32.0)
('yuv.max=', 220.0, 'yuv.min=', 32.0)
('yuv.max=', 238.0, 'yuv.min=', 14.0)
('yuv.max=', 210.0, 'yuv.min=', 7.0)
('yuv.max=', 248.0, 'yuv.min=', 22.0)
('yuv.max=', 243.0, 'yuv.min=', 35.0)
('yuv.max=', 213.0, 'yuv.min=', 10.0)
('yuv.max=', 215.0, 'yuv.min=', 0.0)
('yuv.max=', 242.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 19.0)
('yuv.max=', 231.0, 'yuv.min=', 9.0)
('yuv.max=', 203.0, 'yuv.min=', 8.0)
('yuv.max=', 253.0, 'yuv.min=', 43.0)
('yuv.max=', 225.0, 'yuv.min=', 40.0)
('yuv.max=', 228.0, 'yuv.min=', 33.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 254.0, 'yuv.min=', 37.0)
('yuv.max=', 223.0, 'yuv.min=', 43.0)
('yuv.max=', 206.0, 'yuv.min=', 18.0)
('yuv.max=', 245.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 211.0, 'yuv.min=', 21.0)
('yuv.max=', 240.0, 'yuv.min=', 47.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 247.0, 'yuv.min=', 14.0)
('yuv.max=', 229.0, 'yuv.min=', 25.0)
('yuv.max=', 235.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 15.0)
('yuv.max=', 250.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 182.0, 'yuv.min=', 62.0)
('yuv.max=', 232.0, 'yuv.min=', 13.0)
('yuv.max=', 210.0, 'yuv.min=', 5.0)
('yuv.max=', 186.0, 'yuv.min=', 9.0)
('yuv.max=', 186.0, 'yuv.min=', 22.0)
('yuv.max=', 251.0, 'yuv.min=', 51.0)
('yuv.max=', 242.0, 'yuv.min=', 52.0)
('yuv.max=', 215.0, 'yuv.min=', 46.0)
('yuv.max=', 246.0, 'yuv.min=', 32.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 23.0)
('yuv.max=', 253.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 21.0)
('yuv.max=', 184.0, 'yuv.min=', 41.0)
('yuv.max=', 246.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 145.0, 'yuv.min=', 41.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 229.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 250.0, 'yuv.min=', 41.0)
('yuv.max=', 238.0, 'yuv.min=', 41.0)
('yuv.max=', 251.0, 'yuv.min=', 15.0)
('yuv.max=', 200.0, 'yuv.min=', 25.0)
('yuv.max=', 235.0, 'yuv.min=', 16.0)
('yuv.max=', 188.0, 'yuv.min=', 11.0)
('yuv.max=', 225.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 249.0, 'yuv.min=', 35.0)
('yuv.max=', 253.0, 'yuv.min=', 18.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 26.0)
('yuv.max=', 213.0, 'yuv.min=', 3.0)
('yuv.max=', 170.0, 'yuv.min=', 36.0)
('yuv.max=', 239.0, 'yuv.min=', 4.0)
('yuv.max=', 200.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 235.0, 'yuv.min=', 12.0)
('yuv.max=', 237.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 25.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 161.0, 'yuv.min=', 29.0)
('yuv.max=', 211.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 24.0)
('yuv.max=', 224.0, 'yuv.min=', 15.0)
('yuv.max=', 235.0, 'yuv.min=', 13.0)
('yuv.max=', 236.0, 'yuv.min=', 9.0)
('yuv.max=', 249.0, 'yuv.min=', 29.0)
('yuv.max=', 204.0, 'yuv.min=', 44.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 245.0, 'yuv.min=', 37.0)
('yuv.max=', 216.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 29.0)
('yuv.max=', 180.0, 'yuv.min=', 7.0)
('yuv.max=', 229.0, 'yuv.min=', 15.0)
('yuv.max=', 165.0, 'yuv.min=', 25.0)
('yuv.max=', 243.0, 'yuv.min=', 90.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 182.0, 'yuv.min=', 31.0)
('yuv.max=', 245.0, 'yuv.min=', 2.0)
('yuv.max=', 242.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 234.0, 'yuv.min=', 10.0)
('yuv.max=', 241.0, 'yuv.min=', 5.0)
('yuv.max=', 218.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 19.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 244.0, 'yuv.min=', 5.0)
('yuv.max=', 230.0, 'yuv.min=', 6.0)
('yuv.max=', 174.0, 'yuv.min=', 41.0)
('yuv.max=', 195.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 55.0)
('yuv.max=', 249.0, 'yuv.min=', 10.0)
('yuv.max=', 245.0, 'yuv.min=', 58.0)
('yuv.max=', 207.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 174.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 29.0)
('yuv.max=', 230.0, 'yuv.min=', 20.0)
('yuv.max=', 205.0, 'yuv.min=', 43.0)
('yuv.max=', 247.0, 'yuv.min=', 32.0)
('yuv.max=', 238.0, 'yuv.min=', 46.0)
('yuv.max=', 216.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 244.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 71.0)
('yuv.max=', 242.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 242.0, 'yuv.min=', 0.0)
('yuv.max=', 178.0, 'yuv.min=', 17.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 234.0, 'yuv.min=', 24.0)
('yuv.max=', 190.0, 'yuv.min=', 36.0)
('yuv.max=', 176.0, 'yuv.min=', 12.0)
('yuv.max=', 248.0, 'yuv.min=', 24.0)
('yuv.max=', 235.0, 'yuv.min=', 19.0)
('yuv.max=', 225.0, 'yuv.min=', 15.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 254.0, 'yuv.min=', 52.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 243.0, 'yuv.min=', 11.0)
('yuv.max=', 238.0, 'yuv.min=', 18.0)
('yuv.max=', 220.0, 'yuv.min=', 9.0)
('yuv.max=', 240.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 54.0)
('yuv.max=', 195.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 245.0, 'yuv.min=', 2.0)
('yuv.max=', 245.0, 'yuv.min=', 10.0)
('yuv.max=', 216.0, 'yuv.min=', 15.0)
('yuv.max=', 239.0, 'yuv.min=', 43.0)
('yuv.max=', 236.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 253.0, 'yuv.min=', 30.0)
('yuv.max=', 247.0, 'yuv.min=', 46.0)
('yuv.max=', 255.0, 'yuv.min=', 78.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 247.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 172.0, 'yuv.min=', 55.0)
('yuv.max=', 247.0, 'yuv.min=', 5.0)
('yuv.max=', 239.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 5.0)
('yuv.max=', 201.0, 'yuv.min=', 21.0)
('yuv.max=', 252.0, 'yuv.min=', 15.0)
('yuv.max=', 244.0, 'yuv.min=', 1.0)
('yuv.max=', 253.0, 'yuv.min=', 10.0)
('yuv.max=', 202.0, 'yuv.min=', 15.0)
('yuv.max=', 249.0, 'yuv.min=', 59.0)
('yuv.max=', 224.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 207.0, 'yuv.min=', 0.0)
('yuv.max=', 235.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 22.0)
('yuv.max=', 215.0, 'yuv.min=', 65.0)
('yuv.max=', 193.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 233.0, 'yuv.min=', 2.0)
('yuv.max=', 244.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 213.0, 'yuv.min=', 8.0)
('yuv.max=', 204.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 241.0, 'yuv.min=', 29.0)
('yuv.max=', 205.0, 'yuv.min=', 41.0)
('yuv.max=', 230.0, 'yuv.min=', 38.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 14.0)
('yuv.max=', 242.0, 'yuv.min=', 21.0)
('yuv.max=', 226.0, 'yuv.min=', 57.0)
('yuv.max=', 254.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 222.0, 'yuv.min=', 20.0)
('yuv.max=', 230.0, 'yuv.min=', 40.0)
('yuv.max=', 215.0, 'yuv.min=', 47.0)
('yuv.max=', 185.0, 'yuv.min=', 13.0)
('yuv.max=', 248.0, 'yuv.min=', 19.0)
('yuv.max=', 204.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 200.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 10.0)
('yuv.max=', 220.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 6.0)
('yuv.max=', 195.0, 'yuv.min=', 25.0)
('yuv.max=', 249.0, 'yuv.min=', 36.0)
('yuv.max=', 220.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 45.0)
('yuv.max=', 247.0, 'yuv.min=', 15.0)
('yuv.max=', 224.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 222.0, 'yuv.min=', 41.0)
('yuv.max=', 224.0, 'yuv.min=', 19.0)
('yuv.max=', 231.0, 'yuv.min=', 56.0)
('yuv.max=', 182.0, 'yuv.min=', 28.0)
('yuv.max=', 236.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 200.0, 'yuv.min=', 20.0)
('yuv.max=', 202.0, 'yuv.min=', 35.0)
('yuv.max=', 216.0, 'yuv.min=', 3.0)
('yuv.max=', 221.0, 'yuv.min=', 29.0)
('yuv.max=', 253.0, 'yuv.min=', 5.0)
('yuv.max=', 250.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 29.0)
('yuv.max=', 222.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 248.0, 'yuv.min=', 31.0)
('yuv.max=', 252.0, 'yuv.min=', 26.0)
('yuv.max=', 235.0, 'yuv.min=', 55.0)
('yuv.max=', 249.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 240.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 224.0, 'yuv.min=', 27.0)
('yuv.max=', 251.0, 'yuv.min=', 2.0)
('yuv.max=', 229.0, 'yuv.min=', 12.0)
('yuv.max=', 217.0, 'yuv.min=', 44.0)
('yuv.max=', 187.0, 'yuv.min=', 19.0)
('yuv.max=', 227.0, 'yuv.min=', 7.0)
('yuv.max=', 213.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 19.0)
('yuv.max=', 220.0, 'yuv.min=', 13.0)
('yuv.max=', 214.0, 'yuv.min=', 15.0)
('yuv.max=', 218.0, 'yuv.min=', 16.0)
('yuv.max=', 245.0, 'yuv.min=', 53.0)
('yuv.max=', 251.0, 'yuv.min=', 25.0)
('yuv.max=', 254.0, 'yuv.min=', 15.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 80.0)
('yuv.max=', 233.0, 'yuv.min=', 76.0)
('yuv.max=', 212.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 41.0)
('yuv.max=', 238.0, 'yuv.min=', 47.0)
('yuv.max=', 207.0, 'yuv.min=', 6.0)
('yuv.max=', 253.0, 'yuv.min=', 16.0)
('yuv.max=', 220.0, 'yuv.min=', 3.0)
('yuv.max=', 221.0, 'yuv.min=', 9.0)
('yuv.max=', 241.0, 'yuv.min=', 15.0)
('yuv.max=', 211.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 249.0, 'yuv.min=', 22.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 199.0, 'yuv.min=', 24.0)
('yuv.max=', 187.0, 'yuv.min=', 0.0)
('yuv.max=', 192.0, 'yuv.min=', 41.0)
('yuv.max=', 255.0, 'yuv.min=', 55.0)
('yuv.max=', 237.0, 'yuv.min=', 13.0)
('yuv.max=', 204.0, 'yuv.min=', 37.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 153.0, 'yuv.min=', 23.0)
('yuv.max=', 241.0, 'yuv.min=', 22.0)
('yuv.max=', 183.0, 'yuv.min=', 59.0)
('yuv.max=', 215.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 16.0)
('yuv.max=', 179.0, 'yuv.min=', 8.0)
('yuv.max=', 196.0, 'yuv.min=', 41.0)
('yuv.max=', 239.0, 'yuv.min=', 10.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 12.0)
('yuv.max=', 222.0, 'yuv.min=', 44.0)
('yuv.max=', 231.0, 'yuv.min=', 8.0)
('yuv.max=', 159.0, 'yuv.min=', 13.0)
('yuv.max=', 247.0, 'yuv.min=', 18.0)
('yuv.max=', 200.0, 'yuv.min=', 54.0)
('yuv.max=', 222.0, 'yuv.min=', 15.0)
('yuv.max=', 200.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 81.0)
('yuv.max=', 249.0, 'yuv.min=', 1.0)
('yuv.max=', 183.0, 'yuv.min=', 28.0)
('yuv.max=', 197.0, 'yuv.min=', 11.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 212.0, 'yuv.min=', 4.0)
('yuv.max=', 241.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 233.0, 'yuv.min=', 47.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 209.0, 'yuv.min=', 57.0)
('yuv.max=', 171.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 31.0)
('yuv.max=', 242.0, 'yuv.min=', 78.0)
('yuv.max=', 218.0, 'yuv.min=', 39.0)
('yuv.max=', 205.0, 'yuv.min=', 69.0)
('yuv.max=', 229.0, 'yuv.min=', 25.0)
('yuv.max=', 210.0, 'yuv.min=', 2.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 247.0, 'yuv.min=', 33.0)
('yuv.max=', 197.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 49.0)
('yuv.max=', 177.0, 'yuv.min=', 72.0)
('yuv.max=', 178.0, 'yuv.min=', 15.0)
('yuv.max=', 207.0, 'yuv.min=', 12.0)
('yuv.max=', 206.0, 'yuv.min=', 18.0)
('yuv.max=', 203.0, 'yuv.min=', 25.0)
('yuv.max=', 205.0, 'yuv.min=', 50.0)
('yuv.max=', 222.0, 'yuv.min=', 39.0)
('yuv.max=', 225.0, 'yuv.min=', 11.0)
('yuv.max=', 247.0, 'yuv.min=', 1.0)
('yuv.max=', 215.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 54.0)
('yuv.max=', 239.0, 'yuv.min=', 13.0)
('yuv.max=', 204.0, 'yuv.min=', 9.0)
('yuv.max=', 198.0, 'yuv.min=', 18.0)
('yuv.max=', 243.0, 'yuv.min=', 38.0)
('yuv.max=', 244.0, 'yuv.min=', 47.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 238.0, 'yuv.min=', 18.0)
('yuv.max=', 252.0, 'yuv.min=', 32.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 206.0, 'yuv.min=', 25.0)
('yuv.max=', 242.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 251.0, 'yuv.min=', 40.0)
('yuv.max=', 235.0, 'yuv.min=', 31.0)
('yuv.max=', 234.0, 'yuv.min=', 33.0)
('yuv.max=', 220.0, 'yuv.min=', 21.0)
('yuv.max=', 177.0, 'yuv.min=', 2.0)
('yuv.max=', 207.0, 'yuv.min=', 34.0)
('yuv.max=', 220.0, 'yuv.min=', 23.0)
('yuv.max=', 249.0, 'yuv.min=', 63.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 9.0)
('yuv.max=', 221.0, 'yuv.min=', 40.0)
('yuv.max=', 235.0, 'yuv.min=', 15.0)
('yuv.max=', 204.0, 'yuv.min=', 44.0)
('yuv.max=', 251.0, 'yuv.min=', 17.0)
('yuv.max=', 231.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 31.0)
('yuv.max=', 185.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 252.0, 'yuv.min=', 18.0)
('yuv.max=', 221.0, 'yuv.min=', 45.0)
('yuv.max=', 233.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 243.0, 'yuv.min=', 17.0)
('yuv.max=', 210.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 14.0)
('yuv.max=', 218.0, 'yuv.min=', 28.0)
('yuv.max=', 233.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 209.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 247.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 252.0, 'yuv.min=', 42.0)
('yuv.max=', 242.0, 'yuv.min=', 10.0)
('yuv.max=', 234.0, 'yuv.min=', 30.0)
('yuv.max=', 218.0, 'yuv.min=', 39.0)
('yuv.max=', 228.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 248.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 233.0, 'yuv.min=', 29.0)
('yuv.max=', 228.0, 'yuv.min=', 28.0)
('yuv.max=', 173.0, 'yuv.min=', 27.0)
('yuv.max=', 234.0, 'yuv.min=', 44.0)
('yuv.max=', 246.0, 'yuv.min=', 19.0)
('yuv.max=', 246.0, 'yuv.min=', 42.0)
('yuv.max=', 189.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 223.0, 'yuv.min=', 32.0)
('yuv.max=', 240.0, 'yuv.min=', 6.0)
('yuv.max=', 170.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 238.0, 'yuv.min=', 5.0)
('yuv.max=', 210.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 215.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 245.0, 'yuv.min=', 6.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 251.0, 'yuv.min=', 14.0)
('yuv.max=', 224.0, 'yuv.min=', 15.0)
('yuv.max=', 204.0, 'yuv.min=', 10.0)
('yuv.max=', 210.0, 'yuv.min=', 48.0)
('yuv.max=', 221.0, 'yuv.min=', 24.0)
('yuv.max=', 250.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 239.0, 'yuv.min=', 56.0)
('yuv.max=', 240.0, 'yuv.min=', 26.0)
('yuv.max=', 250.0, 'yuv.min=', 20.0)
('yuv.max=', 233.0, 'yuv.min=', 34.0)
('yuv.max=', 245.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 91.0)
('yuv.max=', 246.0, 'yuv.min=', 22.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 164.0, 'yuv.min=', 58.0)
('yuv.max=', 250.0, 'yuv.min=', 60.0)
('yuv.max=', 254.0, 'yuv.min=', 52.0)
('yuv.max=', 213.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 163.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 241.0, 'yuv.min=', 15.0)
('yuv.max=', 232.0, 'yuv.min=', 35.0)
('yuv.max=', 247.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 243.0, 'yuv.min=', 5.0)
('yuv.max=', 245.0, 'yuv.min=', 28.0)
('yuv.max=', 250.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 217.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 238.0, 'yuv.min=', 44.0)
('yuv.max=', 248.0, 'yuv.min=', 42.0)
('yuv.max=', 226.0, 'yuv.min=', 23.0)
('yuv.max=', 241.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 224.0, 'yuv.min=', 34.0)
('yuv.max=', 254.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 61.0)
('yuv.max=', 243.0, 'yuv.min=', 8.0)
('yuv.max=', 250.0, 'yuv.min=', 6.0)
('yuv.max=', 186.0, 'yuv.min=', 23.0)
('yuv.max=', 240.0, 'yuv.min=', 53.0)
('yuv.max=', 223.0, 'yuv.min=', 23.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 240.0, 'yuv.min=', 17.0)
('yuv.max=', 250.0, 'yuv.min=', 47.0)
('yuv.max=', 249.0, 'yuv.min=', 25.0)
('yuv.max=', 238.0, 'yuv.min=', 43.0)
('yuv.max=', 182.0, 'yuv.min=', 28.0)
('yuv.max=', 176.0, 'yuv.min=', 32.0)
('yuv.max=', 239.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 187.0, 'yuv.min=', 30.0)
('yuv.max=', 209.0, 'yuv.min=', 8.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 250.0, 'yuv.min=', 58.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 23.0)
('yuv.max=', 254.0, 'yuv.min=', 3.0)
('yuv.max=', 210.0, 'yuv.min=', 35.0)
('yuv.max=', 229.0, 'yuv.min=', 2.0)
('yuv.max=', 236.0, 'yuv.min=', 6.0)
('yuv.max=', 253.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 217.0, 'yuv.min=', 24.0)
('yuv.max=', 253.0, 'yuv.min=', 18.0)
('yuv.max=', 176.0, 'yuv.min=', 2.0)
('yuv.max=', 201.0, 'yuv.min=', 47.0)
('yuv.max=', 228.0, 'yuv.min=', 10.0)
('yuv.max=', 244.0, 'yuv.min=', 59.0)
('yuv.max=', 239.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 9.0)
('yuv.max=', 227.0, 'yuv.min=', 33.0)
('yuv.max=', 172.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 252.0, 'yuv.min=', 9.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 245.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 246.0, 'yuv.min=', 34.0)
('yuv.max=', 203.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 249.0, 'yuv.min=', 26.0)
('yuv.max=', 224.0, 'yuv.min=', 21.0)
('yuv.max=', 229.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 67.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 177.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 47.0)
('yuv.max=', 246.0, 'yuv.min=', 36.0)
('yuv.max=', 184.0, 'yuv.min=', 16.0)
('yuv.max=', 223.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 232.0, 'yuv.min=', 4.0)
('yuv.max=', 230.0, 'yuv.min=', 8.0)
('yuv.max=', 247.0, 'yuv.min=', 33.0)
('yuv.max=', 254.0, 'yuv.min=', 31.0)
('yuv.max=', 247.0, 'yuv.min=', 22.0)
('yuv.max=', 251.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 56.0)
('yuv.max=', 169.0, 'yuv.min=', 14.0)
('yuv.max=', 248.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 40.0)
('yuv.max=', 221.0, 'yuv.min=', 56.0)
('yuv.max=', 232.0, 'yuv.min=', 24.0)
('yuv.max=', 254.0, 'yuv.min=', 49.0)
('yuv.max=', 246.0, 'yuv.min=', 39.0)
('yuv.max=', 239.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 14.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 9.0)
('yuv.max=', 255.0, 'yuv.min=', 52.0)
('yuv.max=', 210.0, 'yuv.min=', 4.0)
('yuv.max=', 217.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 239.0, 'yuv.min=', 61.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 235.0, 'yuv.min=', 12.0)
('yuv.max=', 239.0, 'yuv.min=', 42.0)
('yuv.max=', 221.0, 'yuv.min=', 14.0)
('yuv.max=', 236.0, 'yuv.min=', 74.0)
('yuv.max=', 247.0, 'yuv.min=', 54.0)
('yuv.max=', 238.0, 'yuv.min=', 8.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 236.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 21.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 194.0, 'yuv.min=', 14.0)
('yuv.max=', 241.0, 'yuv.min=', 56.0)
('yuv.max=', 252.0, 'yuv.min=', 20.0)
('yuv.max=', 195.0, 'yuv.min=', 14.0)
('yuv.max=', 227.0, 'yuv.min=', 51.0)
('yuv.max=', 229.0, 'yuv.min=', 9.0)
('yuv.max=', 176.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 220.0, 'yuv.min=', 10.0)
('yuv.max=', 238.0, 'yuv.min=', 82.0)
('yuv.max=', 228.0, 'yuv.min=', 52.0)
('yuv.max=', 232.0, 'yuv.min=', 35.0)
('yuv.max=', 228.0, 'yuv.min=', 16.0)
('yuv.max=', 228.0, 'yuv.min=', 28.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 235.0, 'yuv.min=', 8.0)
('yuv.max=', 214.0, 'yuv.min=', 35.0)
('yuv.max=', 215.0, 'yuv.min=', 13.0)
('yuv.max=', 232.0, 'yuv.min=', 62.0)
('yuv.max=', 217.0, 'yuv.min=', 38.0)
('yuv.max=', 236.0, 'yuv.min=', 45.0)
('yuv.max=', 194.0, 'yuv.min=', 5.0)
('yuv.max=', 224.0, 'yuv.min=', 83.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 24.0)
('yuv.max=', 225.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 245.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 172.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 249.0, 'yuv.min=', 45.0)
('yuv.max=', 238.0, 'yuv.min=', 74.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 238.0, 'yuv.min=', 41.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 239.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 26.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 229.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 211.0, 'yuv.min=', 25.0)
('yuv.max=', 235.0, 'yuv.min=', 40.0)
('yuv.max=', 254.0, 'yuv.min=', 46.0)
('yuv.max=', 246.0, 'yuv.min=', 2.0)
('yuv.max=', 244.0, 'yuv.min=', 11.0)
('yuv.max=', 208.0, 'yuv.min=', 17.0)
('yuv.max=', 234.0, 'yuv.min=', 13.0)
('yuv.max=', 254.0, 'yuv.min=', 17.0)
('yuv.max=', 234.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 249.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 207.0, 'yuv.min=', 5.0)
('yuv.max=', 249.0, 'yuv.min=', 60.0)
('yuv.max=', 244.0, 'yuv.min=', 1.0)
('yuv.max=', 251.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 198.0, 'yuv.min=', 13.0)
('yuv.max=', 195.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 66.0)
('yuv.max=', 182.0, 'yuv.min=', 58.0)
('yuv.max=', 251.0, 'yuv.min=', 70.0)
('yuv.max=', 247.0, 'yuv.min=', 17.0)
('yuv.max=', 227.0, 'yuv.min=', 35.0)
('yuv.max=', 245.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 224.0, 'yuv.min=', 60.0)
('yuv.max=', 229.0, 'yuv.min=', 22.0)
('yuv.max=', 168.0, 'yuv.min=', 15.0)
('yuv.max=', 218.0, 'yuv.min=', 35.0)
('yuv.max=', 212.0, 'yuv.min=', 29.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 38.0)
('yuv.max=', 223.0, 'yuv.min=', 1.0)
('yuv.max=', 209.0, 'yuv.min=', 22.0)
('yuv.max=', 241.0, 'yuv.min=', 8.0)
('yuv.max=', 253.0, 'yuv.min=', 22.0)
('yuv.max=', 145.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 18.0)
('yuv.max=', 235.0, 'yuv.min=', 1.0)
('yuv.max=', 241.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 10.0)
('yuv.max=', 246.0, 'yuv.min=', 37.0)
('yuv.max=', 231.0, 'yuv.min=', 11.0)
('yuv.max=', 226.0, 'yuv.min=', 28.0)
('yuv.max=', 239.0, 'yuv.min=', 52.0)
('yuv.max=', 230.0, 'yuv.min=', 9.0)
('yuv.max=', 217.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 78.0)
('yuv.max=', 241.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 3.0)
('yuv.max=', 206.0, 'yuv.min=', 18.0)
('yuv.max=', 249.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 216.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 115.0)
('yuv.max=', 213.0, 'yuv.min=', 0.0)
('yuv.max=', 228.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 209.0, 'yuv.min=', 89.0)
('yuv.max=', 227.0, 'yuv.min=', 14.0)
('yuv.max=', 250.0, 'yuv.min=', 11.0)
('yuv.max=', 248.0, 'yuv.min=', 53.0)
('yuv.max=', 225.0, 'yuv.min=', 8.0)
('yuv.max=', 231.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 225.0, 'yuv.min=', 11.0)
('yuv.max=', 252.0, 'yuv.min=', 20.0)
('yuv.max=', 218.0, 'yuv.min=', 48.0)
('yuv.max=', 252.0, 'yuv.min=', 26.0)
('yuv.max=', 234.0, 'yuv.min=', 12.0)
('yuv.max=', 250.0, 'yuv.min=', 1.0)
('yuv.max=', 230.0, 'yuv.min=', 28.0)
('yuv.max=', 243.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 10.0)
('yuv.max=', 208.0, 'yuv.min=', 11.0)
('yuv.max=', 197.0, 'yuv.min=', 27.0)
('yuv.max=', 251.0, 'yuv.min=', 20.0)
('yuv.max=', 211.0, 'yuv.min=', 33.0)
('yuv.max=', 220.0, 'yuv.min=', 0.0)
('yuv.max=', 247.0, 'yuv.min=', 4.0)
('yuv.max=', 237.0, 'yuv.min=', 59.0)
('yuv.max=', 227.0, 'yuv.min=', 28.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 191.0, 'yuv.min=', 79.0)
('yuv.max=', 238.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 29.0)
('yuv.max=', 248.0, 'yuv.min=', 32.0)
('yuv.max=', 224.0, 'yuv.min=', 10.0)
('yuv.max=', 249.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 219.0, 'yuv.min=', 47.0)
('yuv.max=', 238.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 15.0)
('yuv.max=', 221.0, 'yuv.min=', 38.0)
('yuv.max=', 237.0, 'yuv.min=', 45.0)
('yuv.max=', 213.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 199.0, 'yuv.min=', 36.0)
('yuv.max=', 199.0, 'yuv.min=', 30.0)
('yuv.max=', 252.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 214.0, 'yuv.min=', 6.0)
('yuv.max=', 165.0, 'yuv.min=', 25.0)
('yuv.max=', 218.0, 'yuv.min=', 11.0)
('yuv.max=', 238.0, 'yuv.min=', 29.0)
('yuv.max=', 150.0, 'yuv.min=', 26.0)
('yuv.max=', 232.0, 'yuv.min=', 50.0)
('yuv.max=', 254.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 227.0, 'yuv.min=', 4.0)
('yuv.max=', 244.0, 'yuv.min=', 7.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 194.0, 'yuv.min=', 0.0)
('yuv.max=', 202.0, 'yuv.min=', 33.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 221.0, 'yuv.min=', 42.0)
('yuv.max=', 235.0, 'yuv.min=', 45.0)
('yuv.max=', 229.0, 'yuv.min=', 10.0)
('yuv.max=', 209.0, 'yuv.min=', 29.0)
('yuv.max=', 252.0, 'yuv.min=', 48.0)
('yuv.max=', 251.0, 'yuv.min=', 30.0)
('yuv.max=', 228.0, 'yuv.min=', 10.0)
('yuv.max=', 247.0, 'yuv.min=', 15.0)
('yuv.max=', 232.0, 'yuv.min=', 34.0)
('yuv.max=', 255.0, 'yuv.min=', 67.0)
('yuv.max=', 238.0, 'yuv.min=', 70.0)
('yuv.max=', 248.0, 'yuv.min=', 8.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 225.0, 'yuv.min=', 48.0)
('yuv.max=', 247.0, 'yuv.min=', 15.0)
('yuv.max=', 238.0, 'yuv.min=', 7.0)
('yuv.max=', 183.0, 'yuv.min=', 2.0)
('yuv.max=', 229.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 250.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 204.0, 'yuv.min=', 42.0)
('yuv.max=', 241.0, 'yuv.min=', 33.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 234.0, 'yuv.min=', 12.0)
('yuv.max=', 224.0, 'yuv.min=', 27.0)
('yuv.max=', 253.0, 'yuv.min=', 23.0)
('yuv.max=', 231.0, 'yuv.min=', 16.0)
('yuv.max=', 200.0, 'yuv.min=', 30.0)
('yuv.max=', 254.0, 'yuv.min=', 37.0)
('yuv.max=', 197.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 193.0, 'yuv.min=', 48.0)
('yuv.max=', 244.0, 'yuv.min=', 15.0)
('yuv.max=', 167.0, 'yuv.min=', 59.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 234.0, 'yuv.min=', 8.0)
('yuv.max=', 236.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 254.0, 'yuv.min=', 33.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 21.0)
('yuv.max=', 236.0, 'yuv.min=', 7.0)
('yuv.max=', 180.0, 'yuv.min=', 50.0)
('yuv.max=', 205.0, 'yuv.min=', 24.0)
('yuv.max=', 242.0, 'yuv.min=', 71.0)
('yuv.max=', 236.0, 'yuv.min=', 89.0)
('yuv.max=', 227.0, 'yuv.min=', 60.0)
('yuv.max=', 211.0, 'yuv.min=', 21.0)
('yuv.max=', 243.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 29.0)
('yuv.max=', 250.0, 'yuv.min=', 9.0)
('yuv.max=', 198.0, 'yuv.min=', 6.0)
('yuv.max=', 223.0, 'yuv.min=', 33.0)
('yuv.max=', 244.0, 'yuv.min=', 16.0)
('yuv.max=', 225.0, 'yuv.min=', 7.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 218.0, 'yuv.min=', 63.0)
('yuv.max=', 237.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 71.0)
('yuv.max=', 253.0, 'yuv.min=', 8.0)
('yuv.max=', 179.0, 'yuv.min=', 76.0)
('yuv.max=', 251.0, 'yuv.min=', 31.0)
('yuv.max=', 254.0, 'yuv.min=', 18.0)
('yuv.max=', 212.0, 'yuv.min=', 4.0)
('yuv.max=', 246.0, 'yuv.min=', 25.0)
('yuv.max=', 253.0, 'yuv.min=', 16.0)
('yuv.max=', 204.0, 'yuv.min=', 29.0)
('yuv.max=', 210.0, 'yuv.min=', 22.0)
('yuv.max=', 225.0, 'yuv.min=', 15.0)
('yuv.max=', 220.0, 'yuv.min=', 35.0)
('yuv.max=', 243.0, 'yuv.min=', 34.0)
('yuv.max=', 210.0, 'yuv.min=', 74.0)
('yuv.max=', 212.0, 'yuv.min=', 25.0)
('yuv.max=', 191.0, 'yuv.min=', 51.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 225.0, 'yuv.min=', 15.0)
('yuv.max=', 225.0, 'yuv.min=', 11.0)
('yuv.max=', 254.0, 'yuv.min=', 20.0)
('yuv.max=', 176.0, 'yuv.min=', 50.0)
('yuv.max=', 252.0, 'yuv.min=', 16.0)
('yuv.max=', 240.0, 'yuv.min=', 63.0)
('yuv.max=', 254.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 246.0, 'yuv.min=', 15.0)
('yuv.max=', 237.0, 'yuv.min=', 6.0)
('yuv.max=', 178.0, 'yuv.min=', 31.0)
('yuv.max=', 239.0, 'yuv.min=', 9.0)
('yuv.max=', 209.0, 'yuv.min=', 23.0)
('yuv.max=', 199.0, 'yuv.min=', 5.0)
('yuv.max=', 247.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 3.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 191.0, 'yuv.min=', 6.0)
('yuv.max=', 240.0, 'yuv.min=', 36.0)
('yuv.max=', 196.0, 'yuv.min=', 0.0)
('yuv.max=', 238.0, 'yuv.min=', 9.0)
('yuv.max=', 210.0, 'yuv.min=', 42.0)
('yuv.max=', 241.0, 'yuv.min=', 6.0)
('yuv.max=', 232.0, 'yuv.min=', 52.0)
('yuv.max=', 234.0, 'yuv.min=', 28.0)
('yuv.max=', 227.0, 'yuv.min=', 8.0)
('yuv.max=', 197.0, 'yuv.min=', 47.0)
('yuv.max=', 221.0, 'yuv.min=', 12.0)
('yuv.max=', 253.0, 'yuv.min=', 32.0)
('yuv.max=', 213.0, 'yuv.min=', 6.0)
('yuv.max=', 243.0, 'yuv.min=', 21.0)
('yuv.max=', 253.0, 'yuv.min=', 3.0)
('yuv.max=', 208.0, 'yuv.min=', 42.0)
('yuv.max=', 230.0, 'yuv.min=', 51.0)
('yuv.max=', 248.0, 'yuv.min=', 31.0)
('yuv.max=', 238.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 52.0)
('yuv.max=', 248.0, 'yuv.min=', 35.0)
('yuv.max=', 253.0, 'yuv.min=', 21.0)
('yuv.max=', 236.0, 'yuv.min=', 50.0)
('yuv.max=', 245.0, 'yuv.min=', 15.0)
('yuv.max=', 206.0, 'yuv.min=', 6.0)
('yuv.max=', 219.0, 'yuv.min=', 60.0)
('yuv.max=', 187.0, 'yuv.min=', 30.0)
('yuv.max=', 190.0, 'yuv.min=', 30.0)
('yuv.max=', 251.0, 'yuv.min=', 1.0)
('yuv.max=', 192.0, 'yuv.min=', 9.0)
('yuv.max=', 211.0, 'yuv.min=', 29.0)
('yuv.max=', 240.0, 'yuv.min=', 52.0)
('yuv.max=', 255.0, 'yuv.min=', 35.0)
('yuv.max=', 246.0, 'yuv.min=', 6.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 243.0, 'yuv.min=', 71.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 242.0, 'yuv.min=', 8.0)
('yuv.max=', 193.0, 'yuv.min=', 50.0)
('yuv.max=', 235.0, 'yuv.min=', 40.0)
('yuv.max=', 200.0, 'yuv.min=', 32.0)
('yuv.max=', 247.0, 'yuv.min=', 61.0)
('yuv.max=', 245.0, 'yuv.min=', 7.0)
('yuv.max=', 246.0, 'yuv.min=', 36.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 233.0, 'yuv.min=', 69.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 240.0, 'yuv.min=', 26.0)
('yuv.max=', 246.0, 'yuv.min=', 34.0)
('yuv.max=', 244.0, 'yuv.min=', 9.0)
('yuv.max=', 232.0, 'yuv.min=', 8.0)
('yuv.max=', 183.0, 'yuv.min=', 58.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 253.0, 'yuv.min=', 60.0)
('yuv.max=', 238.0, 'yuv.min=', 15.0)
('yuv.max=', 227.0, 'yuv.min=', 2.0)
('yuv.max=', 217.0, 'yuv.min=', 56.0)
('yuv.max=', 228.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 13.0)
('yuv.max=', 203.0, 'yuv.min=', 15.0)
('yuv.max=', 203.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 11.0)
('yuv.max=', 246.0, 'yuv.min=', 1.0)
('yuv.max=', 174.0, 'yuv.min=', 71.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 211.0, 'yuv.min=', 15.0)
('yuv.max=', 249.0, 'yuv.min=', 46.0)
('yuv.max=', 180.0, 'yuv.min=', 18.0)
('yuv.max=', 248.0, 'yuv.min=', 22.0)
('yuv.max=', 181.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 209.0, 'yuv.min=', 0.0)
('yuv.max=', 249.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 231.0, 'yuv.min=', 32.0)
('yuv.max=', 222.0, 'yuv.min=', 16.0)
('yuv.max=', 254.0, 'yuv.min=', 5.0)
('yuv.max=', 197.0, 'yuv.min=', 20.0)
('yuv.max=', 245.0, 'yuv.min=', 35.0)
('yuv.max=', 193.0, 'yuv.min=', 39.0)
('yuv.max=', 190.0, 'yuv.min=', 12.0)
('yuv.max=', 226.0, 'yuv.min=', 2.0)
('yuv.max=', 202.0, 'yuv.min=', 18.0)
('yuv.max=', 250.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 61.0)
('yuv.max=', 196.0, 'yuv.min=', 48.0)
('yuv.max=', 224.0, 'yuv.min=', 3.0)
('yuv.max=', 177.0, 'yuv.min=', 18.0)
('yuv.max=', 248.0, 'yuv.min=', 11.0)
('yuv.max=', 192.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 249.0, 'yuv.min=', 17.0)
('yuv.max=', 249.0, 'yuv.min=', 66.0)
('yuv.max=', 232.0, 'yuv.min=', 26.0)
('yuv.max=', 241.0, 'yuv.min=', 12.0)
('yuv.max=', 169.0, 'yuv.min=', 14.0)
('yuv.max=', 209.0, 'yuv.min=', 14.0)
('yuv.max=', 248.0, 'yuv.min=', 43.0)
('yuv.max=', 229.0, 'yuv.min=', 15.0)
('yuv.max=', 194.0, 'yuv.min=', 38.0)
('yuv.max=', 243.0, 'yuv.min=', 47.0)
('yuv.max=', 250.0, 'yuv.min=', 69.0)
('yuv.max=', 233.0, 'yuv.min=', 37.0)
('yuv.max=', 233.0, 'yuv.min=', 28.0)
('yuv.max=', 243.0, 'yuv.min=', 10.0)
('yuv.max=', 180.0, 'yuv.min=', 40.0)
('yuv.max=', 222.0, 'yuv.min=', 22.0)
('yuv.max=', 241.0, 'yuv.min=', 51.0)
('yuv.max=', 178.0, 'yuv.min=', 1.0)
('yuv.max=', 225.0, 'yuv.min=', 31.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 11.0)
('yuv.max=', 152.0, 'yuv.min=', 21.0)
('yuv.max=', 246.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 37.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 217.0, 'yuv.min=', 60.0)
('yuv.max=', 250.0, 'yuv.min=', 8.0)
('yuv.max=', 249.0, 'yuv.min=', 40.0)
('yuv.max=', 229.0, 'yuv.min=', 0.0)
('yuv.max=', 220.0, 'yuv.min=', 28.0)
('yuv.max=', 250.0, 'yuv.min=', 93.0)
('yuv.max=', 218.0, 'yuv.min=', 34.0)
('yuv.max=', 249.0, 'yuv.min=', 28.0)
('yuv.max=', 236.0, 'yuv.min=', 1.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 160.0, 'yuv.min=', 30.0)
('yuv.max=', 252.0, 'yuv.min=', 43.0)
('yuv.max=', 252.0, 'yuv.min=', 11.0)
('yuv.max=', 177.0, 'yuv.min=', 61.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 209.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 187.0, 'yuv.min=', 25.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 244.0, 'yuv.min=', 17.0)
('yuv.max=', 238.0, 'yuv.min=', 3.0)
('yuv.max=', 234.0, 'yuv.min=', 22.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 246.0, 'yuv.min=', 61.0)
('yuv.max=', 228.0, 'yuv.min=', 1.0)
('yuv.max=', 215.0, 'yuv.min=', 28.0)
('yuv.max=', 241.0, 'yuv.min=', 14.0)
('yuv.max=', 247.0, 'yuv.min=', 66.0)
('yuv.max=', 185.0, 'yuv.min=', 65.0)
('yuv.max=', 253.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 253.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 167.0, 'yuv.min=', 4.0)
('yuv.max=', 227.0, 'yuv.min=', 38.0)
('yuv.max=', 241.0, 'yuv.min=', 34.0)
('yuv.max=', 200.0, 'yuv.min=', 75.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 223.0, 'yuv.min=', 19.0)
('yuv.max=', 242.0, 'yuv.min=', 33.0)
('yuv.max=', 227.0, 'yuv.min=', 29.0)
('yuv.max=', 253.0, 'yuv.min=', 13.0)
('yuv.max=', 232.0, 'yuv.min=', 22.0)
('yuv.max=', 195.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 246.0, 'yuv.min=', 2.0)
('yuv.max=', 248.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 184.0, 'yuv.min=', 5.0)
('yuv.max=', 245.0, 'yuv.min=', 53.0)
('yuv.max=', 253.0, 'yuv.min=', 9.0)
('yuv.max=', 215.0, 'yuv.min=', 35.0)
('yuv.max=', 228.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 26.0)
('yuv.max=', 253.0, 'yuv.min=', 35.0)
('yuv.max=', 234.0, 'yuv.min=', 56.0)
('yuv.max=', 213.0, 'yuv.min=', 31.0)
('yuv.max=', 251.0, 'yuv.min=', 5.0)
('yuv.max=', 199.0, 'yuv.min=', 25.0)
('yuv.max=', 239.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 42.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 250.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 53.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 216.0, 'yuv.min=', 16.0)
('yuv.max=', 193.0, 'yuv.min=', 8.0)
('yuv.max=', 239.0, 'yuv.min=', 17.0)
('yuv.max=', 174.0, 'yuv.min=', 28.0)
('yuv.max=', 240.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 65.0)
('yuv.max=', 242.0, 'yuv.min=', 50.0)
('yuv.max=', 246.0, 'yuv.min=', 14.0)
('yuv.max=', 229.0, 'yuv.min=', 67.0)
('yuv.max=', 207.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 246.0, 'yuv.min=', 24.0)
('yuv.max=', 251.0, 'yuv.min=', 35.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 209.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 14.0)
('yuv.max=', 245.0, 'yuv.min=', 6.0)
('yuv.max=', 224.0, 'yuv.min=', 6.0)
('yuv.max=', 199.0, 'yuv.min=', 25.0)
('yuv.max=', 242.0, 'yuv.min=', 55.0)
('yuv.max=', 224.0, 'yuv.min=', 22.0)
('yuv.max=', 244.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 33.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 23.0)
('yuv.max=', 208.0, 'yuv.min=', 12.0)
('yuv.max=', 178.0, 'yuv.min=', 34.0)
('yuv.max=', 180.0, 'yuv.min=', 75.0)
('yuv.max=', 255.0, 'yuv.min=', 24.0)
('yuv.max=', 174.0, 'yuv.min=', 51.0)
('yuv.max=', 235.0, 'yuv.min=', 24.0)
('yuv.max=', 247.0, 'yuv.min=', 11.0)
('yuv.max=', 249.0, 'yuv.min=', 109.0)
('yuv.max=', 179.0, 'yuv.min=', 38.0)
('yuv.max=', 225.0, 'yuv.min=', 61.0)
('yuv.max=', 230.0, 'yuv.min=', 22.0)
('yuv.max=', 239.0, 'yuv.min=', 97.0)
('yuv.max=', 246.0, 'yuv.min=', 7.0)
('yuv.max=', 163.0, 'yuv.min=', 13.0)
('yuv.max=', 249.0, 'yuv.min=', 30.0)
('yuv.max=', 243.0, 'yuv.min=', 13.0)
('yuv.max=', 162.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 16.0)
('yuv.max=', 238.0, 'yuv.min=', 14.0)
('yuv.max=', 254.0, 'yuv.min=', 59.0)
('yuv.max=', 207.0, 'yuv.min=', 34.0)
('yuv.max=', 243.0, 'yuv.min=', 48.0)
('yuv.max=', 245.0, 'yuv.min=', 23.0)
('yuv.max=', 186.0, 'yuv.min=', 49.0)
('yuv.max=', 201.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 43.0)
('yuv.max=', 248.0, 'yuv.min=', 28.0)
('yuv.max=', 244.0, 'yuv.min=', 77.0)
('yuv.max=', 217.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 195.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 244.0, 'yuv.min=', 80.0)
('yuv.max=', 220.0, 'yuv.min=', 15.0)
('yuv.max=', 255.0, 'yuv.min=', 62.0)
('yuv.max=', 245.0, 'yuv.min=', 40.0)
('yuv.max=', 200.0, 'yuv.min=', 5.0)
('yuv.max=', 233.0, 'yuv.min=', 13.0)
('yuv.max=', 172.0, 'yuv.min=', 30.0)
('yuv.max=', 234.0, 'yuv.min=', 1.0)
('yuv.max=', 237.0, 'yuv.min=', 16.0)
('yuv.max=', 217.0, 'yuv.min=', 39.0)
('yuv.max=', 230.0, 'yuv.min=', 15.0)
('yuv.max=', 206.0, 'yuv.min=', 10.0)
('yuv.max=', 242.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 14.0)
('yuv.max=', 233.0, 'yuv.min=', 25.0)
('yuv.max=', 154.0, 'yuv.min=', 42.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 242.0, 'yuv.min=', 3.0)
('yuv.max=', 180.0, 'yuv.min=', 5.0)
('yuv.max=', 176.0, 'yuv.min=', 3.0)
('yuv.max=', 214.0, 'yuv.min=', 4.0)
('yuv.max=', 203.0, 'yuv.min=', 32.0)
('yuv.max=', 231.0, 'yuv.min=', 3.0)
('yuv.max=', 248.0, 'yuv.min=', 1.0)
('yuv.max=', 242.0, 'yuv.min=', 32.0)
('yuv.max=', 254.0, 'yuv.min=', 8.0)
('yuv.max=', 201.0, 'yuv.min=', 35.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 215.0, 'yuv.min=', 49.0)
('yuv.max=', 253.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 238.0, 'yuv.min=', 49.0)
('yuv.max=', 238.0, 'yuv.min=', 41.0)
('yuv.max=', 250.0, 'yuv.min=', 46.0)
('yuv.max=', 228.0, 'yuv.min=', 50.0)
('yuv.max=', 255.0, 'yuv.min=', 6.0)
('yuv.max=', 240.0, 'yuv.min=', 38.0)
('yuv.max=', 218.0, 'yuv.min=', 26.0)
('yuv.max=', 240.0, 'yuv.min=', 40.0)
('yuv.max=', 249.0, 'yuv.min=', 25.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 190.0, 'yuv.min=', 52.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 244.0, 'yuv.min=', 21.0)
('yuv.max=', 215.0, 'yuv.min=', 31.0)
('yuv.max=', 228.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 38.0)
('yuv.max=', 185.0, 'yuv.min=', 24.0)
('yuv.max=', 231.0, 'yuv.min=', 13.0)
('yuv.max=', 240.0, 'yuv.min=', 1.0)
('yuv.max=', 253.0, 'yuv.min=', 21.0)
('yuv.max=', 243.0, 'yuv.min=', 56.0)
('yuv.max=', 253.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 223.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 31.0)
('yuv.max=', 160.0, 'yuv.min=', 29.0)
('yuv.max=', 255.0, 'yuv.min=', 36.0)
('yuv.max=', 239.0, 'yuv.min=', 16.0)
('yuv.max=', 235.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 4.0)
('yuv.max=', 254.0, 'yuv.min=', 27.0)
('yuv.max=', 166.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 245.0, 'yuv.min=', 67.0)
('yuv.max=', 215.0, 'yuv.min=', 32.0)
('yuv.max=', 187.0, 'yuv.min=', 51.0)
('yuv.max=', 250.0, 'yuv.min=', 41.0)
('yuv.max=', 242.0, 'yuv.min=', 61.0)
('yuv.max=', 254.0, 'yuv.min=', 10.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 246.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 25.0)
('yuv.max=', 236.0, 'yuv.min=', 12.0)
('yuv.max=', 254.0, 'yuv.min=', 54.0)
('yuv.max=', 198.0, 'yuv.min=', 10.0)
('yuv.max=', 207.0, 'yuv.min=', 3.0)
('yuv.max=', 204.0, 'yuv.min=', 11.0)
('yuv.max=', 232.0, 'yuv.min=', 42.0)
('yuv.max=', 253.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 24.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 252.0, 'yuv.min=', 0.0)
('yuv.max=', 230.0, 'yuv.min=', 1.0)
('yuv.max=', 227.0, 'yuv.min=', 2.0)
('yuv.max=', 219.0, 'yuv.min=', 29.0)
('yuv.max=', 242.0, 'yuv.min=', 66.0)
('yuv.max=', 215.0, 'yuv.min=', 45.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 198.0, 'yuv.min=', 35.0)
('yuv.max=', 217.0, 'yuv.min=', 13.0)
('yuv.max=', 225.0, 'yuv.min=', 22.0)
('yuv.max=', 247.0, 'yuv.min=', 49.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 229.0, 'yuv.min=', 5.0)
('yuv.max=', 217.0, 'yuv.min=', 38.0)
('yuv.max=', 129.0, 'yuv.min=', 5.0)
('yuv.max=', 253.0, 'yuv.min=', 34.0)
('yuv.max=', 254.0, 'yuv.min=', 47.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 211.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 252.0, 'yuv.min=', 8.0)
('yuv.max=', 230.0, 'yuv.min=', 59.0)
('yuv.max=', 249.0, 'yuv.min=', 4.0)
('yuv.max=', 235.0, 'yuv.min=', 31.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 253.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 251.0, 'yuv.min=', 20.0)
('yuv.max=', 246.0, 'yuv.min=', 26.0)
('yuv.max=', 252.0, 'yuv.min=', 1.0)
('yuv.max=', 165.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 51.0)
('yuv.max=', 249.0, 'yuv.min=', 30.0)
('yuv.max=', 235.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 224.0, 'yuv.min=', 4.0)
('yuv.max=', 241.0, 'yuv.min=', 21.0)
('yuv.max=', 182.0, 'yuv.min=', 23.0)
('yuv.max=', 243.0, 'yuv.min=', 72.0)
('yuv.max=', 212.0, 'yuv.min=', 56.0)
('yuv.max=', 224.0, 'yuv.min=', 40.0)
('yuv.max=', 214.0, 'yuv.min=', 63.0)
('yuv.max=', 249.0, 'yuv.min=', 26.0)
('yuv.max=', 229.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 26.0)
('yuv.max=', 228.0, 'yuv.min=', 11.0)
('yuv.max=', 205.0, 'yuv.min=', 4.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 165.0, 'yuv.min=', 14.0)
('yuv.max=', 233.0, 'yuv.min=', 25.0)
('yuv.max=', 229.0, 'yuv.min=', 22.0)
('yuv.max=', 252.0, 'yuv.min=', 43.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 247.0, 'yuv.min=', 5.0)
('yuv.max=', 224.0, 'yuv.min=', 75.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 192.0, 'yuv.min=', 72.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 216.0, 'yuv.min=', 51.0)
('yuv.max=', 252.0, 'yuv.min=', 13.0)
('yuv.max=', 199.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 241.0, 'yuv.min=', 12.0)
('yuv.max=', 199.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 81.0)
('yuv.max=', 171.0, 'yuv.min=', 25.0)
('yuv.max=', 240.0, 'yuv.min=', 16.0)
('yuv.max=', 234.0, 'yuv.min=', 84.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 236.0, 'yuv.min=', 11.0)
('yuv.max=', 204.0, 'yuv.min=', 4.0)
('yuv.max=', 189.0, 'yuv.min=', 39.0)
('yuv.max=', 217.0, 'yuv.min=', 13.0)
('yuv.max=', 252.0, 'yuv.min=', 25.0)
('yuv.max=', 238.0, 'yuv.min=', 19.0)
('yuv.max=', 171.0, 'yuv.min=', 22.0)
('yuv.max=', 183.0, 'yuv.min=', 26.0)
('yuv.max=', 207.0, 'yuv.min=', 40.0)
('yuv.max=', 236.0, 'yuv.min=', 12.0)
('yuv.max=', 208.0, 'yuv.min=', 4.0)
('yuv.max=', 239.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 72.0)
('yuv.max=', 246.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 232.0, 'yuv.min=', 38.0)
('yuv.max=', 251.0, 'yuv.min=', 51.0)
('yuv.max=', 253.0, 'yuv.min=', 54.0)
('yuv.max=', 221.0, 'yuv.min=', 25.0)
('yuv.max=', 243.0, 'yuv.min=', 6.0)
('yuv.max=', 246.0, 'yuv.min=', 37.0)
('yuv.max=', 231.0, 'yuv.min=', 5.0)
('yuv.max=', 206.0, 'yuv.min=', 11.0)
('yuv.max=', 223.0, 'yuv.min=', 67.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 229.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 205.0, 'yuv.min=', 39.0)
('yuv.max=', 233.0, 'yuv.min=', 15.0)
('yuv.max=', 163.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 218.0, 'yuv.min=', 23.0)
('yuv.max=', 223.0, 'yuv.min=', 50.0)
('yuv.max=', 255.0, 'yuv.min=', 18.0)
('yuv.max=', 243.0, 'yuv.min=', 112.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 93.0)
('yuv.max=', 238.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 20.0)
('yuv.max=', 249.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 222.0, 'yuv.min=', 20.0)
('yuv.max=', 242.0, 'yuv.min=', 22.0)
('yuv.max=', 245.0, 'yuv.min=', 19.0)
('yuv.max=', 253.0, 'yuv.min=', 95.0)
('yuv.max=', 255.0, 'yuv.min=', 68.0)
('yuv.max=', 223.0, 'yuv.min=', 19.0)
('yuv.max=', 251.0, 'yuv.min=', 13.0)
('yuv.max=', 242.0, 'yuv.min=', 2.0)
('yuv.max=', 242.0, 'yuv.min=', 3.0)
('yuv.max=', 230.0, 'yuv.min=', 7.0)
('yuv.max=', 224.0, 'yuv.min=', 35.0)
('yuv.max=', 204.0, 'yuv.min=', 31.0)
('yuv.max=', 224.0, 'yuv.min=', 27.0)
('yuv.max=', 241.0, 'yuv.min=', 44.0)
('yuv.max=', 231.0, 'yuv.min=', 19.0)
('yuv.max=', 168.0, 'yuv.min=', 8.0)
('yuv.max=', 237.0, 'yuv.min=', 16.0)
('yuv.max=', 214.0, 'yuv.min=', 35.0)
('yuv.max=', 182.0, 'yuv.min=', 3.0)
('yuv.max=', 243.0, 'yuv.min=', 84.0)
('yuv.max=', 224.0, 'yuv.min=', 12.0)
('yuv.max=', 251.0, 'yuv.min=', 25.0)
('yuv.max=', 251.0, 'yuv.min=', 54.0)
('yuv.max=', 190.0, 'yuv.min=', 29.0)
('yuv.max=', 209.0, 'yuv.min=', 26.0)
('yuv.max=', 240.0, 'yuv.min=', 52.0)
('yuv.max=', 153.0, 'yuv.min=', 42.0)
('yuv.max=', 224.0, 'yuv.min=', 49.0)
('yuv.max=', 241.0, 'yuv.min=', 17.0)
('yuv.max=', 226.0, 'yuv.min=', 27.0)
('yuv.max=', 248.0, 'yuv.min=', 2.0)
('yuv.max=', 232.0, 'yuv.min=', 19.0)
('yuv.max=', 208.0, 'yuv.min=', 30.0)
('yuv.max=', 251.0, 'yuv.min=', 10.0)
('yuv.max=', 224.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 2.0)
('yuv.max=', 250.0, 'yuv.min=', 11.0)
('yuv.max=', 196.0, 'yuv.min=', 80.0)
('yuv.max=', 196.0, 'yuv.min=', 10.0)
('yuv.max=', 210.0, 'yuv.min=', 6.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 198.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 244.0, 'yuv.min=', 52.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 202.0, 'yuv.min=', 49.0)
('yuv.max=', 205.0, 'yuv.min=', 32.0)
('yuv.max=', 239.0, 'yuv.min=', 0.0)
('yuv.max=', 202.0, 'yuv.min=', 60.0)
('yuv.max=', 255.0, 'yuv.min=', 48.0)
('yuv.max=', 234.0, 'yuv.min=', 18.0)
('yuv.max=', 239.0, 'yuv.min=', 8.0)
('yuv.max=', 254.0, 'yuv.min=', 28.0)
('yuv.max=', 250.0, 'yuv.min=', 59.0)
('yuv.max=', 244.0, 'yuv.min=', 29.0)
('yuv.max=', 251.0, 'yuv.min=', 27.0)
('yuv.max=', 202.0, 'yuv.min=', 0.0)
('yuv.max=', 233.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 194.0, 'yuv.min=', 37.0)
('yuv.max=', 201.0, 'yuv.min=', 3.0)
('yuv.max=', 226.0, 'yuv.min=', 39.0)
('yuv.max=', 248.0, 'yuv.min=', 62.0)
('yuv.max=', 253.0, 'yuv.min=', 7.0)
('yuv.max=', 247.0, 'yuv.min=', 12.0)
('yuv.max=', 235.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 58.0)
('yuv.max=', 238.0, 'yuv.min=', 47.0)
('yuv.max=', 209.0, 'yuv.min=', 17.0)
('yuv.max=', 249.0, 'yuv.min=', 14.0)
('yuv.max=', 222.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 15.0)
('yuv.max=', 180.0, 'yuv.min=', 33.0)
('yuv.max=', 249.0, 'yuv.min=', 2.0)
('yuv.max=', 199.0, 'yuv.min=', 16.0)
('yuv.max=', 200.0, 'yuv.min=', 39.0)
('yuv.max=', 254.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 33.0)
('yuv.max=', 215.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 12.0)
('yuv.max=', 255.0, 'yuv.min=', 21.0)
('yuv.max=', 210.0, 'yuv.min=', 25.0)
('yuv.max=', 205.0, 'yuv.min=', 13.0)
('yuv.max=', 237.0, 'yuv.min=', 44.0)
('yuv.max=', 254.0, 'yuv.min=', 49.0)
('yuv.max=', 229.0, 'yuv.min=', 41.0)
('yuv.max=', 245.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 11.0)
('yuv.max=', 255.0, 'yuv.min=', 44.0)
('yuv.max=', 211.0, 'yuv.min=', 25.0)
('yuv.max=', 200.0, 'yuv.min=', 31.0)
('yuv.max=', 212.0, 'yuv.min=', 42.0)
('yuv.max=', 197.0, 'yuv.min=', 20.0)
('yuv.max=', 225.0, 'yuv.min=', 6.0)
('yuv.max=', 251.0, 'yuv.min=', 22.0)
('yuv.max=', 254.0, 'yuv.min=', 76.0)
('yuv.max=', 248.0, 'yuv.min=', 12.0)
('yuv.max=', 175.0, 'yuv.min=', 32.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 184.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 21.0)
('yuv.max=', 242.0, 'yuv.min=', 26.0)
('yuv.max=', 255.0, 'yuv.min=', 29.0)
('yuv.max=', 199.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 37.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 80.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 248.0, 'yuv.min=', 9.0)
('yuv.max=', 197.0, 'yuv.min=', 43.0)
('yuv.max=', 228.0, 'yuv.min=', 13.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 250.0, 'yuv.min=', 10.0)
('yuv.max=', 161.0, 'yuv.min=', 35.0)
('yuv.max=', 221.0, 'yuv.min=', 28.0)
('yuv.max=', 179.0, 'yuv.min=', 9.0)
('yuv.max=', 253.0, 'yuv.min=', 20.0)
('yuv.max=', 241.0, 'yuv.min=', 15.0)
('yuv.max=', 207.0, 'yuv.min=', 1.0)
('yuv.max=', 245.0, 'yuv.min=', 1.0)
('yuv.max=', 234.0, 'yuv.min=', 19.0)
('yuv.max=', 254.0, 'yuv.min=', 31.0)
('yuv.max=', 253.0, 'yuv.min=', 33.0)
('yuv.max=', 255.0, 'yuv.min=', 41.0)
('yuv.max=', 204.0, 'yuv.min=', 39.0)
('yuv.max=', 253.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 21.0)
('yuv.max=', 218.0, 'yuv.min=', 12.0)
('yuv.max=', 238.0, 'yuv.min=', 6.0)
('yuv.max=', 239.0, 'yuv.min=', 6.0)
('yuv.max=', 237.0, 'yuv.min=', 39.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 247.0, 'yuv.min=', 44.0)
('yuv.max=', 254.0, 'yuv.min=', 15.0)
('yuv.max=', 246.0, 'yuv.min=', 19.0)
('yuv.max=', 246.0, 'yuv.min=', 24.0)
('yuv.max=', 233.0, 'yuv.min=', 35.0)
('yuv.max=', 249.0, 'yuv.min=', 12.0)
('yuv.max=', 246.0, 'yuv.min=', 5.0)
('yuv.max=', 252.0, 'yuv.min=', 75.0)
('yuv.max=', 255.0, 'yuv.min=', 27.0)
('yuv.max=', 248.0, 'yuv.min=', 19.0)
('yuv.max=', 234.0, 'yuv.min=', 15.0)
('yuv.max=', 225.0, 'yuv.min=', 7.0)
('yuv.max=', 240.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 253.0, 'yuv.min=', 4.0)
('yuv.max=', 235.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 1.0)
('yuv.max=', 243.0, 'yuv.min=', 24.0)
('yuv.max=', 240.0, 'yuv.min=', 1.0)
('yuv.max=', 217.0, 'yuv.min=', 19.0)
('yuv.max=', 205.0, 'yuv.min=', 68.0)
('yuv.max=', 223.0, 'yuv.min=', 55.0)
('yuv.max=', 242.0, 'yuv.min=', 7.0)
('yuv.max=', 203.0, 'yuv.min=', 32.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 227.0, 'yuv.min=', 0.0)
('yuv.max=', 252.0, 'yuv.min=', 59.0)
('yuv.max=', 236.0, 'yuv.min=', 10.0)
('yuv.max=', 158.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 71.0)
('yuv.max=', 184.0, 'yuv.min=', 12.0)
('yuv.max=', 225.0, 'yuv.min=', 21.0)
('yuv.max=', 195.0, 'yuv.min=', 59.0)
('yuv.max=', 228.0, 'yuv.min=', 2.0)
('yuv.max=', 252.0, 'yuv.min=', 75.0)
('yuv.max=', 174.0, 'yuv.min=', 5.0)
('yuv.max=', 255.0, 'yuv.min=', 54.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 245.0, 'yuv.min=', 2.0)
('yuv.max=', 232.0, 'yuv.min=', 18.0)
('yuv.max=', 196.0, 'yuv.min=', 34.0)
('yuv.max=', 180.0, 'yuv.min=', 46.0)
('yuv.max=', 252.0, 'yuv.min=', 67.0)
('yuv.max=', 250.0, 'yuv.min=', 9.0)
('yuv.max=', 235.0, 'yuv.min=', 40.0)
('yuv.max=', 255.0, 'yuv.min=', 32.0)
('yuv.max=', 236.0, 'yuv.min=', 15.0)
('yuv.max=', 230.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 221.0, 'yuv.min=', 22.0)
('yuv.max=', 222.0, 'yuv.min=', 19.0)
('yuv.max=', 222.0, 'yuv.min=', 47.0)
('yuv.max=', 239.0, 'yuv.min=', 10.0)
('yuv.max=', 244.0, 'yuv.min=', 91.0)
('yuv.max=', 236.0, 'yuv.min=', 36.0)
('yuv.max=', 238.0, 'yuv.min=', 18.0)
('yuv.max=', 255.0, 'yuv.min=', 4.0)
('yuv.max=', 237.0, 'yuv.min=', 42.0)
('yuv.max=', 228.0, 'yuv.min=', 2.0)
('yuv.max=', 161.0, 'yuv.min=', 28.0)
('yuv.max=', 196.0, 'yuv.min=', 16.0)
('yuv.max=', 247.0, 'yuv.min=', 44.0)
('yuv.max=', 236.0, 'yuv.min=', 35.0)
('yuv.max=', 234.0, 'yuv.min=', 18.0)
('yuv.max=', 244.0, 'yuv.min=', 69.0)
('yuv.max=', 203.0, 'yuv.min=', 24.0)
('yuv.max=', 220.0, 'yuv.min=', 15.0)
('yuv.max=', 246.0, 'yuv.min=', 10.0)
('yuv.max=', 229.0, 'yuv.min=', 1.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 243.0, 'yuv.min=', 47.0)
('yuv.max=', 240.0, 'yuv.min=', 19.0)
('yuv.max=', 204.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 44.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 17.0)
('yuv.max=', 230.0, 'yuv.min=', 54.0)
('yuv.max=', 255.0, 'yuv.min=', 10.0)
('yuv.max=', 217.0, 'yuv.min=', 58.0)
('yuv.max=', 214.0, 'yuv.min=', 50.0)
('yuv.max=', 235.0, 'yuv.min=', 22.0)
('yuv.max=', 254.0, 'yuv.min=', 15.0)
('yuv.max=', 228.0, 'yuv.min=', 32.0)
('yuv.max=', 225.0, 'yuv.min=', 45.0)
('yuv.max=', 255.0, 'yuv.min=', 26.0)
('yuv.max=', 191.0, 'yuv.min=', 68.0)
('yuv.max=', 254.0, 'yuv.min=', 7.0)
('yuv.max=', 248.0, 'yuv.min=', 0.0)
('yuv.max=', 171.0, 'yuv.min=', 19.0)
('yuv.max=', 189.0, 'yuv.min=', 20.0)
('yuv.max=', 216.0, 'yuv.min=', 30.0)
('yuv.max=', 233.0, 'yuv.min=', 8.0)
('yuv.max=', 225.0, 'yuv.min=', 44.0)
('yuv.max=', 218.0, 'yuv.min=', 12.0)
('yuv.max=', 249.0, 'yuv.min=', 29.0)
('yuv.max=', 205.0, 'yuv.min=', 6.0)
('yuv.max=', 240.0, 'yuv.min=', 19.0)
('yuv.max=', 213.0, 'yuv.min=', 6.0)
('yuv.max=', 238.0, 'yuv.min=', 66.0)
('yuv.max=', 255.0, 'yuv.min=', 43.0)
('yuv.max=', 187.0, 'yuv.min=', 48.0)
('yuv.max=', 210.0, 'yuv.min=', 4.0)
('yuv.max=', 177.0, 'yuv.min=', 21.0)
('yuv.max=', 252.0, 'yuv.min=', 23.0)
('yuv.max=', 210.0, 'yuv.min=', 18.0)
('yuv.max=', 242.0, 'yuv.min=', 45.0)
('yuv.max=', 254.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 46.0)
('yuv.max=', 251.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 248.0, 'yuv.min=', 3.0)
('yuv.max=', 251.0, 'yuv.min=', 67.0)
('yuv.max=', 249.0, 'yuv.min=', 33.0)
('yuv.max=', 237.0, 'yuv.min=', 71.0)
('yuv.max=', 168.0, 'yuv.min=', 16.0)
('yuv.max=', 255.0, 'yuv.min=', 23.0)
('yuv.max=', 255.0, 'yuv.min=', 16.0)
('yuv.max=', 239.0, 'yuv.min=', 8.0)
('yuv.max=', 206.0, 'yuv.min=', 44.0)
('yuv.max=', 228.0, 'yuv.min=', 25.0)
('yuv.max=', 209.0, 'yuv.min=', 10.0)
('yuv.max=', 205.0, 'yuv.min=', 30.0)
('yuv.max=', 255.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 19.0)
('yuv.max=', 236.0, 'yuv.min=', 57.0)
('yuv.max=', 255.0, 'yuv.min=', 5.0)
('yuv.max=', 250.0, 'yuv.min=', 5.0)
('yuv.max=', 228.0, 'yuv.min=', 8.0)
('yuv.max=', 255.0, 'yuv.min=', 7.0)
('yuv.max=', 183.0, 'yuv.min=', 45.0)
('yuv.max=', 199.0, 'yuv.min=', 24.0)
('yuv.max=', 227.0, 'yuv.min=', 25.0)
('yuv.max=', 215.0, 'yuv.min=', 46.0)
('yuv.max=', 250.0, 'yuv.min=', 24.0)
('yuv.max=', 160.0, 'yuv.min=', 13.0)
('yuv.max=', 244.0, 'yuv.min=', 23.0)
('yuv.max=', 248.0, 'yuv.min=', 17.0)
('yuv.max=', 237.0, 'yuv.min=', 0.0)
('yuv.max=', 239.0, 'yuv.min=', 0.0)
('yuv.max=', 220.0, 'yuv.min=', 25.0)
('yuv.max=', 252.0, 'yuv.min=', 43.0)
('yuv.max=', 177.0, 'yuv.min=', 70.0)
('yuv.max=', 255.0, 'yuv.min=', 53.0)
('yuv.max=', 253.0, 'yuv.min=', 59.0)
('yuv.max=', 206.0, 'yuv.min=', 66.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 214.0, 'yuv.min=', 36.0)
('yuv.max=', 255.0, 'yuv.min=', 81.0)
('yuv.max=', 236.0, 'yuv.min=', 63.0)
('yuv.max=', 236.0, 'yuv.min=', 83.0)
('yuv.max=', 246.0, 'yuv.min=', 30.0)
('yuv.max=', 193.0, 'yuv.min=', 26.0)
('yuv.max=', 236.0, 'yuv.min=', 10.0)
('yuv.max=', 234.0, 'yuv.min=', 27.0)
('yuv.max=', 204.0, 'yuv.min=', 67.0)
('yuv.max=', 253.0, 'yuv.min=', 6.0)
('yuv.max=', 245.0, 'yuv.min=', 14.0)
('yuv.max=', 222.0, 'yuv.min=', 26.0)
('yuv.max=', 208.0, 'yuv.min=', 28.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 230.0, 'yuv.min=', 9.0)
('yuv.max=', 173.0, 'yuv.min=', 20.0)
('yuv.max=', 255.0, 'yuv.min=', 8.0)
('yuv.max=', 228.0, 'yuv.min=', 19.0)
('yuv.max=', 239.0, 'yuv.min=', 1.0)
('yuv.max=', 249.0, 'yuv.min=', 17.0)
('yuv.max=', 255.0, 'yuv.min=', 45.0)
('yuv.max=', 197.0, 'yuv.min=', 16.0)
('yuv.max=', 240.0, 'yuv.min=', 8.0)
('yuv.max=', 170.0, 'yuv.min=', 34.0)
('yuv.max=', 248.0, 'yuv.min=', 23.0)
('yuv.max=', 251.0, 'yuv.min=', 34.0)
('yuv.max=', 243.0, 'yuv.min=', 0.0)
('yuv.max=', 255.0, 'yuv.min=', 3.0)
('yuv.max=', 229.0, 'yuv.min=', 55.0)
('yuv.max=', 215.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 36.0)
('yuv.max=', 208.0, 'yuv.min=', 14.0)
('yuv.max=', 253.0, 'yuv.min=', 19.0)
('yuv.max=', 196.0, 'yuv.min=', 7.0)
('yuv.max=', 243.0, 'yuv.min=', 32.0)
('yuv.max=', 195.0, 'yuv.min=', 37.0)
('yuv.max=', 255.0, 'yuv.min=', 30.0)
('yuv.max=', 190.0, 'yuv.min=', 22.0)
('yuv.max=', 255.0, 'yuv.min=', 11.0)
('yuv.max=', 251.0, 'yuv.min=', 19.0)
('yuv.max=', 239.0, 'yuv.min=', 54.0)
('yuv.max=', 166.0, 'yuv.min=', 20.0)
('yuv.max=', 210.0, 'yuv.min=', 43.0)
('yuv.max=', 249.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 1.0)
('yuv.max=', 218.0, 'yuv.min=', 31.0)
('yuv.max=', 197.0, 'yuv.min=', 41.0)
('yuv.max=', 250.0, 'yuv.min=', 58.0)
('yuv.max=', 246.0, 'yuv.min=', 42.0)
('yuv.max=', 241.0, 'yuv.min=', 12.0)
('yuv.max=', 204.0, 'yuv.min=', 11.0)
('yuv.max=', 246.0, 'yuv.min=', 12.0)
('yuv.max=', 245.0, 'yuv.min=', 32.0)
('yuv.max=', 248.0, 'yuv.min=', 7.0)
('yuv.max=', 217.0, 'yuv.min=', 19.0)
('yuv.max=', 239.0, 'yuv.min=', 13.0)
('yuv.max=', 238.0, 'yuv.min=', 28.0)
('yuv.max=', 190.0, 'yuv.min=', 34.0)
('yuv.max=', 225.0, 'yuv.min=', 57.0)
('yuv.max=', 223.0, 'yuv.min=', 9.0)
('yuv.max=', 234.0, 'yuv.min=', 0.0)
('yuv.max=', 231.0, 'yuv.min=', 0.0)
('yuv.max=', 236.0, 'yuv.min=', 62.0)
('yuv.max=', 239.0, 'yuv.min=', 2.0)
('yuv.max=', 247.0, 'yuv.min=', 1.0)
('yuv.max=', 246.0, 'yuv.min=', 33.0)
('yuv.max=', 251.0, 'yuv.min=', 0.0)
('yuv.max=', 254.0, 'yuv.min=', 48.0)
('yuv.max=', 240.0, 'yuv.min=', 14.0)
('yuv.max=', 255.0, 'yuv.min=', 56.0)
('yuv.max=', 252.0, 'yuv.min=', 35.0)
('yuv.max=', 249.0, 'yuv.min=', 19.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
('yuv.max=', 250.0, 'yuv.min=', 1.0)
('yuv.max=', 219.0, 'yuv.min=', 1.0)
('yuv.max=', 250.0, 'yuv.min=', 12.0)
('yuv.max=', 247.0, 'yuv.min=', 28.0)
('yuv.max=', 245.0, 'yuv.min=', 0.0)
('yuv.max=', 241.0, 'yuv.min=', 13.0)
('yuv.max=', 234.0, 'yuv.min=', 2.0)
('yuv.max=', 255.0, 'yuv.min=', 0.0)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5862', 'for batch', 2)
('GAN loss 0.8769 ', 'GAN acc 0.3906', 'Discriminator loss 0.7498', 'Discriminator accuracy 0.5312', 'Total loss: 1.6267', 'for batch', 3)
('GAN loss 0.8242 ', 'GAN acc 0.3828', 'Discriminator loss 0.7353', 'Discriminator accuracy 0.5156', 'Total loss: 1.5595', 'for batch', 4)
('GAN loss 0.7860 ', 'GAN acc 0.4258', 'Discriminator loss 0.7289', 'Discriminator accuracy 0.5234', 'Total loss: 1.5149', 'for batch', 5)
('GAN loss 0.7771 ', 'GAN acc 0.4492', 'Discriminator loss 0.6814', 'Discriminator accuracy 0.5938', 'Total loss: 1.4584', 'for batch', 6)
('GAN loss 0.8911 ', 'GAN acc 0.3320', 'Discriminator loss 0.6715', 'Discriminator accuracy 0.5957', 'Total loss: 1.5626', 'for batch', 7)
('GAN loss 0.9226 ', 'GAN acc 0.3008', 'Discriminator loss 0.6828', 'Discriminator accuracy 0.5938', 'Total loss: 1.6053', 'for batch', 8)
('GAN loss 0.9052 ', 'GAN acc 0.3359', 'Discriminator loss 0.7226', 'Discriminator accuracy 0.5254', 'Total loss: 1.6278', 'for batch', 9)
('GAN loss 0.9698 ', 'GAN acc 0.2734', 'Discriminator loss 0.6666', 'Discriminator accuracy 0.5957', 'Total loss: 1.6364', 'for batch', 10)
('GAN loss 0.9890 ', 'GAN acc 0.2383', 'Discriminator loss 0.6744', 'Discriminator accuracy 0.6016', 'Total loss: 1.6635', 'for batch', 11)
('GAN loss 1.0142 ', 'GAN acc 0.2266', 'Discriminator loss 0.5846', 'Discriminator accuracy 0.7227', 'Total loss: 1.5988', 'for batch', 12)
('GAN loss 1.0931 ', 'GAN acc 0.1875', 'Discriminator loss 0.5810', 'Discriminator accuracy 0.7480', 'Total loss: 1.6741', 'for batch', 13)
('GAN loss 1.1536 ', 'GAN acc 0.1602', 'Discriminator loss 0.5632', 'Discriminator accuracy 0.7344', 'Total loss: 1.7169', 'for batch', 14)
('GAN loss 1.1609 ', 'GAN acc 0.1680', 'Discriminator loss 0.5629', 'Discriminator accuracy 0.7480', 'Total loss: 1.7238', 'for batch', 15)
('GAN loss 1.1358 ', 'GAN acc 0.1758', 'Discriminator loss 0.5694', 'Discriminator accuracy 0.7383', 'Total loss: 1.7052', 'for batch', 16)
('GAN loss 1.1067 ', 'GAN acc 0.1875', 'Discriminator loss 0.5680', 'Discriminator accuracy 0.7344', 'Total loss: 1.6747', 'for batch', 17)
('GAN loss 1.1054 ', 'GAN acc 0.2344', 'Discriminator loss 0.5922', 'Discriminator accuracy 0.7109', 'Total loss: 1.6977', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.8224293)
('DISCRIMINATOR_Imagem FAKE=', 0.64638317)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 135.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('Elapsed time in epoch = ', '0:00:45.324463')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.0463 ', 'GAN acc 0.2656', 'Discriminator loss 0.6003', 'Discriminator accuracy 0.7129', 'Total loss: 1.6466', 'for batch', 0)
('GAN loss 1.1778 ', 'GAN acc 0.1992', 'Discriminator loss 0.6050', 'Discriminator accuracy 0.6934', 'Total loss: 1.7828', 'for batch', 1)
('GAN loss 1.2304 ', 'GAN acc 0.1602', 'Discriminator loss 0.5554', 'Discriminator accuracy 0.7266', 'Total loss: 1.7858', 'for batch', 2)
('GAN loss 1.1217 ', 'GAN acc 0.2344', 'Discriminator loss 0.5574', 'Discriminator accuracy 0.7148', 'Total loss: 1.6791', 'for batch', 3)
('GAN loss 1.1224 ', 'GAN acc 0.2109', 'Discriminator loss 0.5690', 'Discriminator accuracy 0.7461', 'Total loss: 1.6914', 'for batch', 4)
('GAN loss 1.1905 ', 'GAN acc 0.1836', 'Discriminator loss 0.5729', 'Discriminator accuracy 0.7129', 'Total loss: 1.7634', 'for batch', 5)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5862', 'for batch', 2)
('GAN loss 0.8809 ', 'GAN acc 0.3711', 'Discriminator loss 0.7492', 'Discriminator accuracy 0.5312', 'Total loss: 1.6301', 'for batch', 3)
('GAN loss 0.8289 ', 'GAN acc 0.3945', 'Discriminator loss 0.7362', 'Discriminator accuracy 0.5156', 'Total loss: 1.5652', 'for batch', 4)
('GAN loss 0.7874 ', 'GAN acc 0.4297', 'Discriminator loss 0.7313', 'Discriminator accuracy 0.5312', 'Total loss: 1.5187', 'for batch', 5)
('GAN loss 0.7895 ', 'GAN acc 0.4531', 'Discriminator loss 0.6836', 'Discriminator accuracy 0.5918', 'Total loss: 1.4731', 'for batch', 6)
('GAN loss 0.9171 ', 'GAN acc 0.3008', 'Discriminator loss 0.6811', 'Discriminator accuracy 0.5859', 'Total loss: 1.5983', 'for batch', 7)
('GAN loss 0.9512 ', 'GAN acc 0.2422', 'Discriminator loss 0.6761', 'Discriminator accuracy 0.5977', 'Total loss: 1.6273', 'for batch', 8)
('GAN loss 0.9848 ', 'GAN acc 0.2305', 'Discriminator loss 0.6609', 'Discriminator accuracy 0.5957', 'Total loss: 1.6456', 'for batch', 9)
('GAN loss 0.9693 ', 'GAN acc 0.2500', 'Discriminator loss 0.6311', 'Discriminator accuracy 0.6426', 'Total loss: 1.6004', 'for batch', 10)
('GAN loss 0.9452 ', 'GAN acc 0.2734', 'Discriminator loss 0.6717', 'Discriminator accuracy 0.6094', 'Total loss: 1.6169', 'for batch', 11)
('GAN loss 0.9885 ', 'GAN acc 0.2148', 'Discriminator loss 0.5948', 'Discriminator accuracy 0.7188', 'Total loss: 1.5834', 'for batch', 12)
('GAN loss 1.0351 ', 'GAN acc 0.1875', 'Discriminator loss 0.5963', 'Discriminator accuracy 0.7168', 'Total loss: 1.6315', 'for batch', 13)
('GAN loss 1.0470 ', 'GAN acc 0.1797', 'Discriminator loss 0.5816', 'Discriminator accuracy 0.7227', 'Total loss: 1.6286', 'for batch', 14)
('GAN loss 1.0919 ', 'GAN acc 0.1445', 'Discriminator loss 0.5601', 'Discriminator accuracy 0.7520', 'Total loss: 1.6520', 'for batch', 15)
('GAN loss 1.1132 ', 'GAN acc 0.1914', 'Discriminator loss 0.5242', 'Discriminator accuracy 0.7969', 'Total loss: 1.6374', 'for batch', 16)
('GAN loss 1.2106 ', 'GAN acc 0.1211', 'Discriminator loss 0.5025', 'Discriminator accuracy 0.8184', 'Total loss: 1.7131', 'for batch', 17)
('GAN loss 1.2504 ', 'GAN acc 0.1172', 'Discriminator loss 0.4948', 'Discriminator accuracy 0.7988', 'Total loss: 1.7452', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.86619568)
('DISCRIMINATOR_Imagem FAKE=', 0.62756401)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('b.shape=', (256, 3, 32, 32))
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 135.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('rgb.max=', 136.0, 'rgb.min=', 0.0)
('Elapsed time in epoch = ', '0:00:44.905074')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2444 ', 'GAN acc 0.1680', 'Discriminator loss 0.5218', 'Discriminator accuracy 0.8105', 'Total loss: 1.7662', 'for batch', 0)
('GAN loss 1.3307 ', 'GAN acc 0.0977', 'Discriminator loss 0.5476', 'Discriminator accuracy 0.7383', 'Total loss: 1.8782', 'for batch', 1)
('GAN loss 1.1774 ', 'GAN acc 0.1484', 'Discriminator loss 0.5377', 'Discriminator accuracy 0.7578', 'Total loss: 1.7151', 'for batch', 2)
('GAN loss 1.0306 ', 'GAN acc 0.1992', 'Discriminator loss 0.5712', 'Discriminator accuracy 0.7441', 'Total loss: 1.6019', 'for batch', 3)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5862', 'for batch', 2)
('GAN loss 0.8774 ', 'GAN acc 0.3828', 'Discriminator loss 0.7499', 'Discriminator accuracy 0.5312', 'Total loss: 1.6274', 'for batch', 3)
('GAN loss 0.8237 ', 'GAN acc 0.3945', 'Discriminator loss 0.7321', 'Discriminator accuracy 0.5137', 'Total loss: 1.5558', 'for batch', 4)
('GAN loss 0.7856 ', 'GAN acc 0.4375', 'Discriminator loss 0.7258', 'Discriminator accuracy 0.5273', 'Total loss: 1.5115', 'for batch', 5)
('GAN loss 0.7778 ', 'GAN acc 0.4531', 'Discriminator loss 0.6857', 'Discriminator accuracy 0.5801', 'Total loss: 1.4634', 'for batch', 6)
('GAN loss 0.9094 ', 'GAN acc 0.3008', 'Discriminator loss 0.6812', 'Discriminator accuracy 0.5820', 'Total loss: 1.5906', 'for batch', 7)
('GAN loss 0.9117 ', 'GAN acc 0.3203', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5605', 'Total loss: 1.6076', 'for batch', 8)
('GAN loss 0.9389 ', 'GAN acc 0.2656', 'Discriminator loss 0.7258', 'Discriminator accuracy 0.5176', 'Total loss: 1.6647', 'for batch', 9)
('GAN loss 0.9711 ', 'GAN acc 0.2500', 'Discriminator loss 0.6813', 'Discriminator accuracy 0.5918', 'Total loss: 1.6524', 'for batch', 10)
('GAN loss 0.9731 ', 'GAN acc 0.2461', 'Discriminator loss 0.6767', 'Discriminator accuracy 0.5996', 'Total loss: 1.6498', 'for batch', 11)
('GAN loss 0.9302 ', 'GAN acc 0.2695', 'Discriminator loss 0.5956', 'Discriminator accuracy 0.7031', 'Total loss: 1.5258', 'for batch', 12)
('GAN loss 0.9673 ', 'GAN acc 0.2148', 'Discriminator loss 0.5823', 'Discriminator accuracy 0.7383', 'Total loss: 1.5496', 'for batch', 13)
('GAN loss 0.9829 ', 'GAN acc 0.2266', 'Discriminator loss 0.5935', 'Discriminator accuracy 0.7227', 'Total loss: 1.5764', 'for batch', 14)
('GAN loss 1.0557 ', 'GAN acc 0.1836', 'Discriminator loss 0.5950', 'Discriminator accuracy 0.7266', 'Total loss: 1.6508', 'for batch', 15)
('GAN loss 1.0923 ', 'GAN acc 0.1836', 'Discriminator loss 0.6214', 'Discriminator accuracy 0.7109', 'Total loss: 1.7136', 'for batch', 16)
('GAN loss 1.1191 ', 'GAN acc 0.1719', 'Discriminator loss 0.6290', 'Discriminator accuracy 0.6504', 'Total loss: 1.7481', 'for batch', 17)
('GAN loss 1.1349 ', 'GAN acc 0.1719', 'Discriminator loss 0.6231', 'Discriminator accuracy 0.6660', 'Total loss: 1.7579', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.78314745)
('DISCRIMINATOR_Imagem FAKE=', 0.66273487)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:44.768596')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.1071 ', 'GAN acc 0.2266', 'Discriminator loss 0.6316', 'Discriminator accuracy 0.6523', 'Total loss: 1.7387', 'for batch', 0)
('GAN loss 1.1837 ', 'GAN acc 0.1836', 'Discriminator loss 0.6306', 'Discriminator accuracy 0.6406', 'Total loss: 1.8143', 'for batch', 1)
('GAN loss 1.3157 ', 'GAN acc 0.1250', 'Discriminator loss 0.5984', 'Discriminator accuracy 0.6797', 'Total loss: 1.9140', 'for batch', 2)
('GAN loss 1.1330 ', 'GAN acc 0.1875', 'Discriminator loss 0.5837', 'Discriminator accuracy 0.6562', 'Total loss: 1.7167', 'for batch', 3)
('GAN loss 1.0604 ', 'GAN acc 0.2383', 'Discriminator loss 0.5938', 'Discriminator accuracy 0.6992', 'Total loss: 1.6542', 'for batch', 4)
('GAN loss 1.1999 ', 'GAN acc 0.1875', 'Discriminator loss 0.6323', 'Discriminator accuracy 0.6523', 'Total loss: 1.8322', 'for batch', 5)
('GAN loss 1.2847 ', 'GAN acc 0.1367', 'Discriminator loss 0.6172', 'Discriminator accuracy 0.6562', 'Total loss: 1.9019', 'for batch', 6)
('GAN loss 1.2452 ', 'GAN acc 0.1758', 'Discriminator loss 0.6291', 'Discriminator accuracy 0.6035', 'Total loss: 1.8743', 'for batch', 7)
('GAN loss 1.1752 ', 'GAN acc 0.1836', 'Discriminator loss 0.6129', 'Discriminator accuracy 0.6133', 'Total loss: 1.7881', 'for batch', 8)
('GAN loss 1.2131 ', 'GAN acc 0.1875', 'Discriminator loss 0.6545', 'Discriminator accuracy 0.5898', 'Total loss: 1.8676', 'for batch', 9)
('GAN loss 1.2349 ', 'GAN acc 0.1484', 'Discriminator loss 0.6429', 'Discriminator accuracy 0.6230', 'Total loss: 1.8778', 'for batch', 10)
('GAN loss 1.1684 ', 'GAN acc 0.2109', 'Discriminator loss 0.6340', 'Discriminator accuracy 0.5996', 'Total loss: 1.8023', 'for batch', 11)
('GAN loss 1.1530 ', 'GAN acc 0.1953', 'Discriminator loss 0.6248', 'Discriminator accuracy 0.6016', 'Total loss: 1.7777', 'for batch', 12)
('GAN loss 1.2329 ', 'GAN acc 0.1445', 'Discriminator loss 0.5985', 'Discriminator accuracy 0.6699', 'Total loss: 1.8314', 'for batch', 13)
('GAN loss 1.1800 ', 'GAN acc 0.2070', 'Discriminator loss 0.6062', 'Discriminator accuracy 0.6387', 'Total loss: 1.7862', 'for batch', 14)
('GAN loss 1.2194 ', 'GAN acc 0.1445', 'Discriminator loss 0.6129', 'Discriminator accuracy 0.6504', 'Total loss: 1.8323', 'for batch', 15)
('GAN loss 1.1949 ', 'GAN acc 0.1367', 'Discriminator loss 0.6160', 'Discriminator accuracy 0.6426', 'Total loss: 1.8110', 'for batch', 16)
('GAN loss 1.1097 ', 'GAN acc 0.2188', 'Discriminator loss 0.6205', 'Discriminator accuracy 0.6035', 'Total loss: 1.7302', 'for batch', 17)
('GAN loss 1.1036 ', 'GAN acc 0.1953', 'Discriminator loss 0.6284', 'Discriminator accuracy 0.6191', 'Total loss: 1.7320', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.79172331)
('DISCRIMINATOR_Imagem FAKE=', 0.72525012)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:27.171512')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.0907 ', 'GAN acc 0.1953', 'Discriminator loss 0.6472', 'Discriminator accuracy 0.6133', 'Total loss: 1.7379', 'for batch', 0)
('GAN loss 0.9517 ', 'GAN acc 0.3203', 'Discriminator loss 0.6331', 'Discriminator accuracy 0.6211', 'Total loss: 1.5848', 'for batch', 1)
('GAN loss 0.9534 ', 'GAN acc 0.3398', 'Discriminator loss 0.6276', 'Discriminator accuracy 0.6621', 'Total loss: 1.5810', 'for batch', 2)
('GAN loss 0.8725 ', 'GAN acc 0.3477', 'Discriminator loss 0.6345', 'Discriminator accuracy 0.6309', 'Total loss: 1.5070', 'for batch', 3)
('GAN loss 0.8708 ', 'GAN acc 0.3789', 'Discriminator loss 0.6356', 'Discriminator accuracy 0.6602', 'Total loss: 1.5064', 'for batch', 4)
('GAN loss 0.8010 ', 'GAN acc 0.4023', 'Discriminator loss 0.6543', 'Discriminator accuracy 0.6250', 'Total loss: 1.4553', 'for batch', 5)
('GAN loss 0.7709 ', 'GAN acc 0.4805', 'Discriminator loss 0.6442', 'Discriminator accuracy 0.6250', 'Total loss: 1.4151', 'for batch', 6)
('GAN loss 0.7912 ', 'GAN acc 0.4375', 'Discriminator loss 0.6509', 'Discriminator accuracy 0.6426', 'Total loss: 1.4421', 'for batch', 7)
('GAN loss 0.7818 ', 'GAN acc 0.4414', 'Discriminator loss 0.6328', 'Discriminator accuracy 0.6387', 'Total loss: 1.4146', 'for batch', 8)
('GAN loss 0.7682 ', 'GAN acc 0.4766', 'Discriminator loss 0.6495', 'Discriminator accuracy 0.6426', 'Total loss: 1.4177', 'for batch', 9)
('GAN loss 0.7527 ', 'GAN acc 0.4648', 'Discriminator loss 0.6577', 'Discriminator accuracy 0.6348', 'Total loss: 1.4104', 'for batch', 10)
('GAN loss 0.6957 ', 'GAN acc 0.5391', 'Discriminator loss 0.6620', 'Discriminator accuracy 0.6152', 'Total loss: 1.3577', 'for batch', 11)
('GAN loss 0.7197 ', 'GAN acc 0.5273', 'Discriminator loss 0.6546', 'Discriminator accuracy 0.6289', 'Total loss: 1.3743', 'for batch', 12)
('GAN loss 0.7637 ', 'GAN acc 0.4922', 'Discriminator loss 0.6223', 'Discriminator accuracy 0.6562', 'Total loss: 1.3860', 'for batch', 13)
('GAN loss 0.7780 ', 'GAN acc 0.5039', 'Discriminator loss 0.6354', 'Discriminator accuracy 0.6348', 'Total loss: 1.4134', 'for batch', 14)
('GAN loss 0.7830 ', 'GAN acc 0.4492', 'Discriminator loss 0.6376', 'Discriminator accuracy 0.6426', 'Total loss: 1.4206', 'for batch', 15)
('GAN loss 0.7714 ', 'GAN acc 0.4883', 'Discriminator loss 0.6531', 'Discriminator accuracy 0.6270', 'Total loss: 1.4245', 'for batch', 16)
('GAN loss 0.7970 ', 'GAN acc 0.4531', 'Discriminator loss 0.6457', 'Discriminator accuracy 0.6367', 'Total loss: 1.4427', 'for batch', 17)
('GAN loss 0.7009 ', 'GAN acc 0.6094', 'Discriminator loss 0.6520', 'Discriminator accuracy 0.6152', 'Total loss: 1.3529', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.84768653)
('DISCRIMINATOR_Imagem FAKE=', 0.73735261)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:27.752248')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7265 ', 'GAN acc 0.5820', 'Discriminator loss 0.6543', 'Discriminator accuracy 0.6055', 'Total loss: 1.3808', 'for batch', 0)
('GAN loss 0.7605 ', 'GAN acc 0.4844', 'Discriminator loss 0.6519', 'Discriminator accuracy 0.6250', 'Total loss: 1.4124', 'for batch', 1)
('GAN loss 0.7884 ', 'GAN acc 0.4570', 'Discriminator loss 0.6467', 'Discriminator accuracy 0.6289', 'Total loss: 1.4351', 'for batch', 2)
('GAN loss 0.7483 ', 'GAN acc 0.5703', 'Discriminator loss 0.6551', 'Discriminator accuracy 0.6055', 'Total loss: 1.4034', 'for batch', 3)
('GAN loss 0.7390 ', 'GAN acc 0.5352', 'Discriminator loss 0.6503', 'Discriminator accuracy 0.6133', 'Total loss: 1.3893', 'for batch', 4)
('GAN loss 0.7268 ', 'GAN acc 0.5586', 'Discriminator loss 0.6479', 'Discriminator accuracy 0.6133', 'Total loss: 1.3747', 'for batch', 5)
('GAN loss 0.8585 ', 'GAN acc 0.4414', 'Discriminator loss 0.6368', 'Discriminator accuracy 0.6367', 'Total loss: 1.4954', 'for batch', 6)
('GAN loss 0.8501 ', 'GAN acc 0.4062', 'Discriminator loss 0.6420', 'Discriminator accuracy 0.6270', 'Total loss: 1.4920', 'for batch', 7)
('GAN loss 0.8204 ', 'GAN acc 0.4492', 'Discriminator loss 0.6214', 'Discriminator accuracy 0.6465', 'Total loss: 1.4418', 'for batch', 8)
('GAN loss 0.7595 ', 'GAN acc 0.5352', 'Discriminator loss 0.6566', 'Discriminator accuracy 0.5918', 'Total loss: 1.4161', 'for batch', 9)
('GAN loss 0.7616 ', 'GAN acc 0.5117', 'Discriminator loss 0.6431', 'Discriminator accuracy 0.6152', 'Total loss: 1.4047', 'for batch', 10)
('GAN loss 0.7077 ', 'GAN acc 0.5664', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.5859', 'Total loss: 1.3601', 'for batch', 11)
('GAN loss 0.7161 ', 'GAN acc 0.6016', 'Discriminator loss 0.6670', 'Discriminator accuracy 0.5879', 'Total loss: 1.3830', 'for batch', 12)
('GAN loss 0.7670 ', 'GAN acc 0.4766', 'Discriminator loss 0.6561', 'Discriminator accuracy 0.6172', 'Total loss: 1.4231', 'for batch', 13)
('GAN loss 0.7890 ', 'GAN acc 0.5273', 'Discriminator loss 0.6425', 'Discriminator accuracy 0.5996', 'Total loss: 1.4315', 'for batch', 14)
('GAN loss 0.8182 ', 'GAN acc 0.5195', 'Discriminator loss 0.6441', 'Discriminator accuracy 0.6289', 'Total loss: 1.4622', 'for batch', 15)
('GAN loss 0.9228 ', 'GAN acc 0.3555', 'Discriminator loss 0.6274', 'Discriminator accuracy 0.6387', 'Total loss: 1.5502', 'for batch', 16)
('GAN loss 0.9016 ', 'GAN acc 0.3906', 'Discriminator loss 0.6609', 'Discriminator accuracy 0.5977', 'Total loss: 1.5625', 'for batch', 17)
('GAN loss 0.8445 ', 'GAN acc 0.4297', 'Discriminator loss 0.6755', 'Discriminator accuracy 0.5547', 'Total loss: 1.5200', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.81845468)
('DISCRIMINATOR_Imagem FAKE=', 0.76595861)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:27.363816')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8384 ', 'GAN acc 0.4453', 'Discriminator loss 0.6687', 'Discriminator accuracy 0.5742', 'Total loss: 1.5071', 'for batch', 0)
('GAN loss 0.8616 ', 'GAN acc 0.4297', 'Discriminator loss 0.6555', 'Discriminator accuracy 0.5938', 'Total loss: 1.5171', 'for batch', 1)
('GAN loss 0.7965 ', 'GAN acc 0.4844', 'Discriminator loss 0.6668', 'Discriminator accuracy 0.5762', 'Total loss: 1.4633', 'for batch', 2)
('GAN loss 0.7975 ', 'GAN acc 0.3906', 'Discriminator loss 0.6695', 'Discriminator accuracy 0.5762', 'Total loss: 1.4670', 'for batch', 3)
('GAN loss 0.7773 ', 'GAN acc 0.4375', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5449', 'Total loss: 1.4687', 'for batch', 4)
('GAN loss 0.7546 ', 'GAN acc 0.4766', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5371', 'Total loss: 1.4451', 'for batch', 5)
('GAN loss 0.7726 ', 'GAN acc 0.4180', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.5137', 'Total loss: 1.4747', 'for batch', 6)
('GAN loss 0.8034 ', 'GAN acc 0.3711', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.5234', 'Total loss: 1.5052', 'for batch', 7)
('GAN loss 0.7682 ', 'GAN acc 0.3906', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4980', 'Total loss: 1.4704', 'for batch', 8)
('GAN loss 0.7571 ', 'GAN acc 0.4648', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.5312', 'Total loss: 1.4578', 'for batch', 9)
('GAN loss 0.7981 ', 'GAN acc 0.3633', 'Discriminator loss 0.7153', 'Discriminator accuracy 0.5059', 'Total loss: 1.5134', 'for batch', 10)
('GAN loss 0.7657 ', 'GAN acc 0.3711', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.5215', 'Total loss: 1.4679', 'for batch', 11)
('GAN loss 0.7539 ', 'GAN acc 0.3828', 'Discriminator loss 0.6866', 'Discriminator accuracy 0.5586', 'Total loss: 1.4405', 'for batch', 12)
('GAN loss 0.7698 ', 'GAN acc 0.3672', 'Discriminator loss 0.7196', 'Discriminator accuracy 0.4434', 'Total loss: 1.4895', 'for batch', 13)
('GAN loss 0.7357 ', 'GAN acc 0.3945', 'Discriminator loss 0.7194', 'Discriminator accuracy 0.4785', 'Total loss: 1.4551', 'for batch', 14)
('GAN loss 0.7222 ', 'GAN acc 0.4688', 'Discriminator loss 0.7158', 'Discriminator accuracy 0.4629', 'Total loss: 1.4381', 'for batch', 15)
('GAN loss 0.7395 ', 'GAN acc 0.4258', 'Discriminator loss 0.7060', 'Discriminator accuracy 0.4883', 'Total loss: 1.4456', 'for batch', 16)
('GAN loss 0.7565 ', 'GAN acc 0.3555', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.5059', 'Total loss: 1.4604', 'for batch', 17)
('GAN loss 0.7148 ', 'GAN acc 0.4883', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.5469', 'Total loss: 1.4189', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.73023206)
('DISCRIMINATOR_Imagem FAKE=', 0.73761719)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:27.963538')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7168 ', 'GAN acc 0.4375', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.5195', 'Total loss: 1.4184', 'for batch', 0)
('GAN loss 0.7263 ', 'GAN acc 0.4531', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.5195', 'Total loss: 1.4287', 'for batch', 1)
('GAN loss 0.7111 ', 'GAN acc 0.5039', 'Discriminator loss 0.7136', 'Discriminator accuracy 0.4629', 'Total loss: 1.4246', 'for batch', 2)
('GAN loss 0.7129 ', 'GAN acc 0.4688', 'Discriminator loss 0.7093', 'Discriminator accuracy 0.4941', 'Total loss: 1.4222', 'for batch', 3)
('GAN loss 0.6958 ', 'GAN acc 0.5117', 'Discriminator loss 0.7055', 'Discriminator accuracy 0.4785', 'Total loss: 1.4013', 'for batch', 4)
('GAN loss 0.7157 ', 'GAN acc 0.4531', 'Discriminator loss 0.7054', 'Discriminator accuracy 0.5020', 'Total loss: 1.4211', 'for batch', 5)
('GAN loss 0.7045 ', 'GAN acc 0.5039', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4980', 'Total loss: 1.4028', 'for batch', 6)
('GAN loss 0.7027 ', 'GAN acc 0.5195', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.5020', 'Total loss: 1.4050', 'for batch', 7)
('GAN loss 0.6940 ', 'GAN acc 0.5195', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5293', 'Total loss: 1.3860', 'for batch', 8)
('GAN loss 0.6921 ', 'GAN acc 0.5312', 'Discriminator loss 0.7151', 'Discriminator accuracy 0.4746', 'Total loss: 1.4073', 'for batch', 9)
('GAN loss 0.7030 ', 'GAN acc 0.5039', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4922', 'Total loss: 1.4047', 'for batch', 10)
('GAN loss 0.6958 ', 'GAN acc 0.4922', 'Discriminator loss 0.7138', 'Discriminator accuracy 0.4629', 'Total loss: 1.4096', 'for batch', 11)
('GAN loss 0.6974 ', 'GAN acc 0.5039', 'Discriminator loss 0.7072', 'Discriminator accuracy 0.4941', 'Total loss: 1.4046', 'for batch', 12)
('GAN loss 0.6814 ', 'GAN acc 0.5820', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5410', 'Total loss: 1.3776', 'for batch', 13)
('GAN loss 0.6859 ', 'GAN acc 0.5508', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5234', 'Total loss: 1.3793', 'for batch', 14)
('GAN loss 0.6981 ', 'GAN acc 0.5156', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4902', 'Total loss: 1.4005', 'for batch', 15)
('GAN loss 0.7029 ', 'GAN acc 0.4883', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5312', 'Total loss: 1.3981', 'for batch', 16)
('GAN loss 0.6924 ', 'GAN acc 0.5273', 'Discriminator loss 0.7072', 'Discriminator accuracy 0.4609', 'Total loss: 1.3996', 'for batch', 17)
('GAN loss 0.6853 ', 'GAN acc 0.5664', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4980', 'Total loss: 1.3853', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.67735875)
('DISCRIMINATOR_Imagem FAKE=', 0.67787987)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('b.shape=', (256, 3, 32, 32))
('b.shape=', (256, 3, 32, 32))
('Elapsed time in epoch = ', '0:00:27.482253')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6924 ', 'GAN acc 0.5078', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5508', 'Total loss: 1.3838', 'for batch', 0)
('GAN loss 0.6778 ', 'GAN acc 0.5859', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.5195', 'Total loss: 1.3770', 'for batch', 1)
('GAN loss 0.7027 ', 'GAN acc 0.4961', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.5020', 'Total loss: 1.4004', 'for batch', 2)
('GAN loss 0.6943 ', 'GAN acc 0.5039', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4863', 'Total loss: 1.3945', 'for batch', 3)
('GAN loss 0.6924 ', 'GAN acc 0.5234', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4941', 'Total loss: 1.3938', 'for batch', 4)
('GAN loss 0.6979 ', 'GAN acc 0.5156', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4902', 'Total loss: 1.3987', 'for batch', 5)
('GAN loss 0.6811 ', 'GAN acc 0.5625', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5137', 'Total loss: 1.3759', 'for batch', 6)
('GAN loss 0.6907 ', 'GAN acc 0.5000', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4844', 'Total loss: 1.3904', 'for batch', 7)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5862', 'for batch', 2)
('GAN loss 0.8806 ', 'GAN acc 0.3867', 'Discriminator loss 0.7497', 'Discriminator accuracy 0.5293', 'Total loss: 1.6302', 'for batch', 3)
('GAN loss 0.8238 ', 'GAN acc 0.4023', 'Discriminator loss 0.7360', 'Discriminator accuracy 0.4980', 'Total loss: 1.5598', 'for batch', 4)
('GAN loss 0.7878 ', 'GAN acc 0.4141', 'Discriminator loss 0.7298', 'Discriminator accuracy 0.5254', 'Total loss: 1.5176', 'for batch', 5)
('GAN loss 0.7788 ', 'GAN acc 0.4531', 'Discriminator loss 0.6875', 'Discriminator accuracy 0.5898', 'Total loss: 1.4662', 'for batch', 6)
('GAN loss 0.9138 ', 'GAN acc 0.3242', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5664', 'Total loss: 1.6054', 'for batch', 7)
('GAN loss 0.9428 ', 'GAN acc 0.2656', 'Discriminator loss 0.7071', 'Discriminator accuracy 0.5625', 'Total loss: 1.6499', 'for batch', 8)
('GAN loss 0.9545 ', 'GAN acc 0.2773', 'Discriminator loss 0.7368', 'Discriminator accuracy 0.5020', 'Total loss: 1.6913', 'for batch', 9)
('GAN loss 0.9799 ', 'GAN acc 0.2578', 'Discriminator loss 0.6757', 'Discriminator accuracy 0.5684', 'Total loss: 1.6556', 'for batch', 10)
('GAN loss 1.0058 ', 'GAN acc 0.2305', 'Discriminator loss 0.6635', 'Discriminator accuracy 0.5977', 'Total loss: 1.6694', 'for batch', 11)
('GAN loss 0.9374 ', 'GAN acc 0.2539', 'Discriminator loss 0.5925', 'Discriminator accuracy 0.7285', 'Total loss: 1.5300', 'for batch', 12)
('GAN loss 0.9918 ', 'GAN acc 0.2422', 'Discriminator loss 0.6000', 'Discriminator accuracy 0.7168', 'Total loss: 1.5918', 'for batch', 13)
('GAN loss 0.9949 ', 'GAN acc 0.2773', 'Discriminator loss 0.6216', 'Discriminator accuracy 0.7090', 'Total loss: 1.6165', 'for batch', 14)
('GAN loss 1.0516 ', 'GAN acc 0.1992', 'Discriminator loss 0.6408', 'Discriminator accuracy 0.6562', 'Total loss: 1.6924', 'for batch', 15)
('GAN loss 1.0798 ', 'GAN acc 0.1719', 'Discriminator loss 0.6207', 'Discriminator accuracy 0.6719', 'Total loss: 1.7005', 'for batch', 16)
('GAN loss 1.0713 ', 'GAN acc 0.2188', 'Discriminator loss 0.5905', 'Discriminator accuracy 0.7051', 'Total loss: 1.6619', 'for batch', 17)
('GAN loss 1.0470 ', 'GAN acc 0.2227', 'Discriminator loss 0.5700', 'Discriminator accuracy 0.7305', 'Total loss: 1.6169', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.82490283)
('DISCRIMINATOR_Imagem FAKE=', 0.61421299)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86446607, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.21568628)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89019608, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83529413, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8392157, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.20784314)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.3137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.29803923)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83137256, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.011764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82745099, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78039217, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.75294119, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.21568628)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92941177, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.14509805)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.60000002, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71764708, 'yuv.min=', 0.23137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.7019608, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.76862746, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92941177, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90588236, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.62352943, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78431374, 'yuv.min=', 0.21176471)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78431374, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.31764707)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71764708, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.77254903, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83137256, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.22352941)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.67058825, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.30588236)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80392158, 'yuv.min=', 0.27058825)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.77254903, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.19215687)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69411767, 'yuv.min=', 0.28235295)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69803923, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80784315, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.79607844, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80392158, 'yuv.min=', 0.19607843)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.88235295, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.21176471)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.7764706, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80784315, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.15686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.082352944)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69411767, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.24705882)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.15686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90588236, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.72549021, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.17647059)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.2)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9254902, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.26274511)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.078431375)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.11764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.11372549)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.67843139, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.74117649, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87450981, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.66666669, 'yuv.min=', 0.14509805)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.1882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.21960784)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.078431375)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.14117648)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.35686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.64313728, 'yuv.min=', 0.22745098)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.23529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.20392157)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83529413, 'yuv.min=', 0.082352944)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.23921569)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.63921571, 'yuv.min=', 0.14117648)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90980393, 'yuv.min=', 0.13725491)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.88627452, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.23921569)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.72941178, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.20784314)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87450981, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71372551, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.6901961, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.11764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.22745098)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.011764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.13725491)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9254902, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.6901961, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78823531, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.23137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89019608, 'yuv.min=', 0.12941177)
('Elapsed time in epoch = ', '0:00:44.872557')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9915 ', 'GAN acc 0.2539', 'Discriminator loss 0.5553', 'Discriminator accuracy 0.7656', 'Total loss: 1.5467', 'for batch', 0)
('GAN loss 1.1498 ', 'GAN acc 0.1719', 'Discriminator loss 0.5927', 'Discriminator accuracy 0.7324', 'Total loss: 1.7425', 'for batch', 1)
('GAN loss 1.3252 ', 'GAN acc 0.1445', 'Discriminator loss 0.5273', 'Discriminator accuracy 0.7734', 'Total loss: 1.8525', 'for batch', 2)
('GAN loss 1.2132 ', 'GAN acc 0.2148', 'Discriminator loss 0.5626', 'Discriminator accuracy 0.7129', 'Total loss: 1.7758', 'for batch', 3)
('GAN loss 1.2221 ', 'GAN acc 0.1992', 'Discriminator loss 0.5754', 'Discriminator accuracy 0.7109', 'Total loss: 1.7975', 'for batch', 4)
('GAN loss 1.2359 ', 'GAN acc 0.2070', 'Discriminator loss 0.6040', 'Discriminator accuracy 0.6816', 'Total loss: 1.8399', 'for batch', 5)
('GAN loss 1.4362 ', 'GAN acc 0.1484', 'Discriminator loss 0.6130', 'Discriminator accuracy 0.6582', 'Total loss: 2.0492', 'for batch', 6)
('GAN loss 1.3813 ', 'GAN acc 0.1172', 'Discriminator loss 0.6613', 'Discriminator accuracy 0.5820', 'Total loss: 2.0425', 'for batch', 7)
('GAN loss 1.1208 ', 'GAN acc 0.2305', 'Discriminator loss 0.6217', 'Discriminator accuracy 0.5957', 'Total loss: 1.7425', 'for batch', 8)
('GAN loss 1.1195 ', 'GAN acc 0.2344', 'Discriminator loss 0.6489', 'Discriminator accuracy 0.6230', 'Total loss: 1.7684', 'for batch', 9)
('GAN loss 1.2376 ', 'GAN acc 0.1875', 'Discriminator loss 0.6395', 'Discriminator accuracy 0.6172', 'Total loss: 1.8771', 'for batch', 10)
('GAN loss 1.2498 ', 'GAN acc 0.1836', 'Discriminator loss 0.6455', 'Discriminator accuracy 0.5859', 'Total loss: 1.8954', 'for batch', 11)
('GAN loss 1.1838 ', 'GAN acc 0.1992', 'Discriminator loss 0.6259', 'Discriminator accuracy 0.5996', 'Total loss: 1.8097', 'for batch', 12)
('GAN loss 1.3073 ', 'GAN acc 0.1641', 'Discriminator loss 0.5991', 'Discriminator accuracy 0.6602', 'Total loss: 1.9063', 'for batch', 13)
('GAN loss 1.2898 ', 'GAN acc 0.1250', 'Discriminator loss 0.5969', 'Discriminator accuracy 0.6211', 'Total loss: 1.8867', 'for batch', 14)
('GAN loss 1.1799 ', 'GAN acc 0.1953', 'Discriminator loss 0.6053', 'Discriminator accuracy 0.6699', 'Total loss: 1.7852', 'for batch', 15)
('GAN loss 1.1966 ', 'GAN acc 0.1797', 'Discriminator loss 0.5900', 'Discriminator accuracy 0.6875', 'Total loss: 1.7866', 'for batch', 16)
('GAN loss 1.1845 ', 'GAN acc 0.1875', 'Discriminator loss 0.6030', 'Discriminator accuracy 0.6641', 'Total loss: 1.7875', 'for batch', 17)
('GAN loss 1.2482 ', 'GAN acc 0.1602', 'Discriminator loss 0.6099', 'Discriminator accuracy 0.6758', 'Total loss: 1.8581', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.80490249)
('DISCRIMINATOR_Imagem FAKE=', 0.76019543)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.21568628)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89019608, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83529413, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8392157, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.20784314)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.3137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.29803923)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83137256, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.011764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82745099, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78039217, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.75294119, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.21568628)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92941177, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.14509805)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.60000002, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71764708, 'yuv.min=', 0.23137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.7019608, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.76862746, 'yuv.min=', 0.16078432)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92941177, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90588236, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.62352943, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78431374, 'yuv.min=', 0.21176471)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78431374, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.31764707)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71764708, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.77254903, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83137256, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.22352941)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.67058825, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.30588236)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80392158, 'yuv.min=', 0.27058825)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.77254903, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.19215687)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69411767, 'yuv.min=', 0.28235295)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69803923, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.047058824)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80784315, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.79607844, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80392158, 'yuv.min=', 0.19607843)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87058824, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.88235295, 'yuv.min=', 0.043137256)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.21176471)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.7764706, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80784315, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.15686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.082352944)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.69411767, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81176472, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86274511, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.24705882)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.15686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.92156863, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90588236, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.72549021, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.17647059)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.2)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9254902, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.26274511)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.078431375)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94901961, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.11764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.85490197, 'yuv.min=', 0.15294118)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.11372549)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.67843139, 'yuv.min=', 0.10588235)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.91764706, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.074509807)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.74117649, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87450981, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.66666669, 'yuv.min=', 0.14509805)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.84313726, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.054901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.80000001, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.1882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.86666667, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.21960784)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.078431375)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9137255, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.14117648)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.35686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96470588, 'yuv.min=', 0.086274512)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.64313728, 'yuv.min=', 0.22745098)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.23529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.20392157)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.83529413, 'yuv.min=', 0.082352944)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.23921569)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.63921571, 'yuv.min=', 0.14117648)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.050980393)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.90980393, 'yuv.min=', 0.13725491)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96862745, 'yuv.min=', 0.062745102)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.019607844)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.96078432, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.015686275)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.14901961)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.17254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97254902, 'yuv.min=', 0.16470589)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.88627452, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94509804, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87843138, 'yuv.min=', 0.13333334)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98431373, 'yuv.min=', 0.23921569)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95294118, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.72941178, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.20784314)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.87450981, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.12941177)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.94117647, 'yuv.min=', 0.06666667)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.97647059, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93333334, 'yuv.min=', 0.16862746)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.71372551, 'yuv.min=', 0.10980392)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.6901961, 'yuv.min=', 0.1254902)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.10196079)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.73333335, 'yuv.min=', 0.11764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.81960785, 'yuv.min=', 0.031372551)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.098039217)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.0039215689)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98039216, 'yuv.min=', 0.22745098)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.0)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.98823529, 'yuv.min=', 0.090196081)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99607843, 'yuv.min=', 0.011764706)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.82352942, 'yuv.min=', 0.13725491)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89803922, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.9254902, 'yuv.min=', 0.023529412)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.05882353)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.027450981)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.8509804, 'yuv.min=', 0.094117649)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.99215686, 'yuv.min=', 0.070588239)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.6901961, 'yuv.min=', 0.0078431377)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.78823531, 'yuv.min=', 0.18431373)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89411765, 'yuv.min=', 0.039215688)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.95686275, 'yuv.min=', 0.23137255)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.93725491, 'yuv.min=', 0.12156863)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 1.0, 'yuv.min=', 0.035294119)
('yuv.shape=', (32, 32, 3))
('yuv.max=', 0.89019608, 'yuv.min=', 0.12941177)
('Elapsed time in epoch = ', '0:00:27.241798')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2115 ', 'GAN acc 0.1719', 'Discriminator loss 0.6638', 'Discriminator accuracy 0.5703', 'Total loss: 1.8753', 'for batch', 0)
('GAN loss 1.0913 ', 'GAN acc 0.2344', 'Discriminator loss 0.6395', 'Discriminator accuracy 0.5938', 'Total loss: 1.7309', 'for batch', 1)
----------------------------------
('Training with dataset based on class - ', 'airplane', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             0           lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7491 ', 'GAN acc 0.5039', 'Discriminator loss 0.7455', 'Discriminator accuracy 0.5020', 'Total loss: 1.4946', 'for batch', 0)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.7746', 'Discriminator accuracy 0.5059', 'Total loss: 1.4667', 'for batch', 1)
('GAN loss 0.7813 ', 'GAN acc 0.5000', 'Discriminator loss 0.8049', 'Discriminator accuracy 0.4844', 'Total loss: 1.5863', 'for batch', 2)
('GAN loss 0.8743 ', 'GAN acc 0.3945', 'Discriminator loss 0.7495', 'Discriminator accuracy 0.5332', 'Total loss: 1.6238', 'for batch', 3)
('GAN loss 0.8213 ', 'GAN acc 0.3906', 'Discriminator loss 0.7351', 'Discriminator accuracy 0.5117', 'Total loss: 1.5564', 'for batch', 4)
('GAN loss 0.7846 ', 'GAN acc 0.4258', 'Discriminator loss 0.7295', 'Discriminator accuracy 0.5234', 'Total loss: 1.5141', 'for batch', 5)
('GAN loss 0.7794 ', 'GAN acc 0.4492', 'Discriminator loss 0.6878', 'Discriminator accuracy 0.5859', 'Total loss: 1.4672', 'for batch', 6)
('GAN loss 0.8935 ', 'GAN acc 0.3203', 'Discriminator loss 0.6851', 'Discriminator accuracy 0.5762', 'Total loss: 1.5786', 'for batch', 7)
('GAN loss 0.9929 ', 'GAN acc 0.2266', 'Discriminator loss 0.6759', 'Discriminator accuracy 0.5938', 'Total loss: 1.6688', 'for batch', 8)
('GAN loss 1.0238 ', 'GAN acc 0.2109', 'Discriminator loss 0.6479', 'Discriminator accuracy 0.6094', 'Total loss: 1.6716', 'for batch', 9)
('GAN loss 0.9939 ', 'GAN acc 0.2070', 'Discriminator loss 0.6239', 'Discriminator accuracy 0.6660', 'Total loss: 1.6178', 'for batch', 10)
('GAN loss 1.0716 ', 'GAN acc 0.1406', 'Discriminator loss 0.5945', 'Discriminator accuracy 0.7188', 'Total loss: 1.6660', 'for batch', 11)
('GAN loss 1.0575 ', 'GAN acc 0.2188', 'Discriminator loss 0.5591', 'Discriminator accuracy 0.7539', 'Total loss: 1.6166', 'for batch', 12)
('GAN loss 1.2116 ', 'GAN acc 0.1133', 'Discriminator loss 0.5564', 'Discriminator accuracy 0.7617', 'Total loss: 1.7681', 'for batch', 13)
('GAN loss 1.3110 ', 'GAN acc 0.0938', 'Discriminator loss 0.5551', 'Discriminator accuracy 0.7402', 'Total loss: 1.8661', 'for batch', 14)
('GAN loss 1.2284 ', 'GAN acc 0.1367', 'Discriminator loss 0.5478', 'Discriminator accuracy 0.7461', 'Total loss: 1.7762', 'for batch', 15)
('GAN loss 1.1327 ', 'GAN acc 0.1953', 'Discriminator loss 0.5543', 'Discriminator accuracy 0.7598', 'Total loss: 1.6870', 'for batch', 16)
('GAN loss 1.1562 ', 'GAN acc 0.1875', 'Discriminator loss 0.5656', 'Discriminator accuracy 0.7402', 'Total loss: 1.7218', 'for batch', 17)
('GAN loss 1.2514 ', 'GAN acc 0.1445', 'Discriminator loss 0.5592', 'Discriminator accuracy 0.7422', 'Total loss: 1.8106', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.83950335)
('DISCRIMINATOR_Imagem FAKE=', 0.62250584)
('Discriminator trained', 11, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.132289')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2496 ', 'GAN acc 0.1758', 'Discriminator loss 0.5494', 'Discriminator accuracy 0.7520', 'Total loss: 1.7990', 'for batch', 0)
('GAN loss 1.1792 ', 'GAN acc 0.1875', 'Discriminator loss 0.5587', 'Discriminator accuracy 0.7266', 'Total loss: 1.7379', 'for batch', 1)
('GAN loss 1.2484 ', 'GAN acc 0.1211', 'Discriminator loss 0.4988', 'Discriminator accuracy 0.7910', 'Total loss: 1.7472', 'for batch', 2)
('GAN loss 1.1749 ', 'GAN acc 0.1797', 'Discriminator loss 0.4853', 'Discriminator accuracy 0.8047', 'Total loss: 1.6602', 'for batch', 3)
('GAN loss 1.4238 ', 'GAN acc 0.1172', 'Discriminator loss 0.4982', 'Discriminator accuracy 0.8184', 'Total loss: 1.9220', 'for batch', 4)
('GAN loss 1.4036 ', 'GAN acc 0.1406', 'Discriminator loss 0.5219', 'Discriminator accuracy 0.7676', 'Total loss: 1.9255', 'for batch', 5)
('GAN loss 1.4178 ', 'GAN acc 0.1172', 'Discriminator loss 0.4983', 'Discriminator accuracy 0.7891', 'Total loss: 1.9161', 'for batch', 6)
('GAN loss 1.4220 ', 'GAN acc 0.1250', 'Discriminator loss 0.5032', 'Discriminator accuracy 0.7871', 'Total loss: 1.9252', 'for batch', 7)
('GAN loss 1.3832 ', 'GAN acc 0.1406', 'Discriminator loss 0.4886', 'Discriminator accuracy 0.8145', 'Total loss: 1.8718', 'for batch', 8)
('GAN loss 1.7337 ', 'GAN acc 0.1094', 'Discriminator loss 0.6801', 'Discriminator accuracy 0.6523', 'Total loss: 2.4138', 'for batch', 9)
('GAN loss 1.3197 ', 'GAN acc 0.2305', 'Discriminator loss 0.6692', 'Discriminator accuracy 0.5684', 'Total loss: 1.9889', 'for batch', 10)
('GAN loss 1.0829 ', 'GAN acc 0.3359', 'Discriminator loss 0.6632', 'Discriminator accuracy 0.6016', 'Total loss: 1.7462', 'for batch', 11)
('GAN loss 1.3677 ', 'GAN acc 0.1758', 'Discriminator loss 0.6727', 'Discriminator accuracy 0.5898', 'Total loss: 2.0404', 'for batch', 12)
('GAN loss 1.5602 ', 'GAN acc 0.1172', 'Discriminator loss 0.6262', 'Discriminator accuracy 0.6230', 'Total loss: 2.1864', 'for batch', 13)
('GAN loss 1.2236 ', 'GAN acc 0.2617', 'Discriminator loss 0.6329', 'Discriminator accuracy 0.5918', 'Total loss: 1.8565', 'for batch', 14)
('GAN loss 1.1838 ', 'GAN acc 0.2305', 'Discriminator loss 0.6526', 'Discriminator accuracy 0.6211', 'Total loss: 1.8364', 'for batch', 15)
('GAN loss 1.2931 ', 'GAN acc 0.1562', 'Discriminator loss 0.6232', 'Discriminator accuracy 0.6250', 'Total loss: 1.9163', 'for batch', 16)
('GAN loss 1.2133 ', 'GAN acc 0.1953', 'Discriminator loss 0.6100', 'Discriminator accuracy 0.6328', 'Total loss: 1.8233', 'for batch', 17)
('GAN loss 1.1526 ', 'GAN acc 0.1992', 'Discriminator loss 0.5883', 'Discriminator accuracy 0.6758', 'Total loss: 1.7409', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.86190057)
('DISCRIMINATOR_Imagem FAKE=', 0.81907374)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.343654')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 1.2596 ', 'GAN acc 0.1758', 'Discriminator loss 0.6429', 'Discriminator accuracy 0.5957', 'Total loss: 1.9025', 'for batch', 0)
('GAN loss 1.2991 ', 'GAN acc 0.1719', 'Discriminator loss 0.6365', 'Discriminator accuracy 0.6094', 'Total loss: 1.9356', 'for batch', 1)
('GAN loss 1.1534 ', 'GAN acc 0.2344', 'Discriminator loss 0.6269', 'Discriminator accuracy 0.5859', 'Total loss: 1.7804', 'for batch', 2)
('GAN loss 1.0423 ', 'GAN acc 0.2734', 'Discriminator loss 0.6541', 'Discriminator accuracy 0.5938', 'Total loss: 1.6964', 'for batch', 3)
('GAN loss 1.0633 ', 'GAN acc 0.3398', 'Discriminator loss 0.6502', 'Discriminator accuracy 0.6094', 'Total loss: 1.7135', 'for batch', 4)
('GAN loss 1.0434 ', 'GAN acc 0.2617', 'Discriminator loss 0.6553', 'Discriminator accuracy 0.5820', 'Total loss: 1.6987', 'for batch', 5)
('GAN loss 0.9899 ', 'GAN acc 0.3203', 'Discriminator loss 0.6317', 'Discriminator accuracy 0.6055', 'Total loss: 1.6216', 'for batch', 6)
('GAN loss 1.0584 ', 'GAN acc 0.2656', 'Discriminator loss 0.6639', 'Discriminator accuracy 0.5879', 'Total loss: 1.7224', 'for batch', 7)
('GAN loss 1.0116 ', 'GAN acc 0.2578', 'Discriminator loss 0.6262', 'Discriminator accuracy 0.6387', 'Total loss: 1.6378', 'for batch', 8)
('GAN loss 0.9845 ', 'GAN acc 0.3047', 'Discriminator loss 0.6652', 'Discriminator accuracy 0.5762', 'Total loss: 1.6497', 'for batch', 9)
('GAN loss 0.9883 ', 'GAN acc 0.2812', 'Discriminator loss 0.6402', 'Discriminator accuracy 0.6133', 'Total loss: 1.6286', 'for batch', 10)
('GAN loss 0.8340 ', 'GAN acc 0.4180', 'Discriminator loss 0.6575', 'Discriminator accuracy 0.5898', 'Total loss: 1.4915', 'for batch', 11)
('GAN loss 0.8702 ', 'GAN acc 0.4023', 'Discriminator loss 0.6516', 'Discriminator accuracy 0.5977', 'Total loss: 1.5219', 'for batch', 12)
('GAN loss 0.9164 ', 'GAN acc 0.2969', 'Discriminator loss 0.6433', 'Discriminator accuracy 0.6309', 'Total loss: 1.5597', 'for batch', 13)
('GAN loss 0.9826 ', 'GAN acc 0.3125', 'Discriminator loss 0.6505', 'Discriminator accuracy 0.5977', 'Total loss: 1.6331', 'for batch', 14)
('GAN loss 0.9418 ', 'GAN acc 0.3008', 'Discriminator loss 0.6540', 'Discriminator accuracy 0.5879', 'Total loss: 1.5958', 'for batch', 15)
('GAN loss 0.8607 ', 'GAN acc 0.3867', 'Discriminator loss 0.6654', 'Discriminator accuracy 0.5762', 'Total loss: 1.5261', 'for batch', 16)
('GAN loss 0.8906 ', 'GAN acc 0.3516', 'Discriminator loss 0.6665', 'Discriminator accuracy 0.6035', 'Total loss: 1.5571', 'for batch', 17)
('GAN loss 0.8549 ', 'GAN acc 0.3945', 'Discriminator loss 0.6574', 'Discriminator accuracy 0.6055', 'Total loss: 1.5123', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.83597434)
('DISCRIMINATOR_Imagem FAKE=', 0.7915675)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.040692')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8186 ', 'GAN acc 0.4258', 'Discriminator loss 0.6630', 'Discriminator accuracy 0.6055', 'Total loss: 1.4815', 'for batch', 0)
('GAN loss 0.8391 ', 'GAN acc 0.3711', 'Discriminator loss 0.6609', 'Discriminator accuracy 0.6152', 'Total loss: 1.5000', 'for batch', 1)
('GAN loss 0.8501 ', 'GAN acc 0.4219', 'Discriminator loss 0.6561', 'Discriminator accuracy 0.5938', 'Total loss: 1.5062', 'for batch', 2)
('GAN loss 0.7756 ', 'GAN acc 0.4414', 'Discriminator loss 0.6773', 'Discriminator accuracy 0.5781', 'Total loss: 1.4529', 'for batch', 3)
('GAN loss 0.7645 ', 'GAN acc 0.4766', 'Discriminator loss 0.6606', 'Discriminator accuracy 0.6152', 'Total loss: 1.4251', 'for batch', 4)
('GAN loss 0.7312 ', 'GAN acc 0.5117', 'Discriminator loss 0.6754', 'Discriminator accuracy 0.5703', 'Total loss: 1.4066', 'for batch', 5)
('GAN loss 0.7824 ', 'GAN acc 0.4414', 'Discriminator loss 0.6708', 'Discriminator accuracy 0.5957', 'Total loss: 1.4531', 'for batch', 6)
('GAN loss 0.7601 ', 'GAN acc 0.4336', 'Discriminator loss 0.6670', 'Discriminator accuracy 0.5781', 'Total loss: 1.4271', 'for batch', 7)
('GAN loss 0.7566 ', 'GAN acc 0.4336', 'Discriminator loss 0.6524', 'Discriminator accuracy 0.6055', 'Total loss: 1.4090', 'for batch', 8)
('GAN loss 0.7221 ', 'GAN acc 0.5547', 'Discriminator loss 0.6657', 'Discriminator accuracy 0.5898', 'Total loss: 1.3878', 'for batch', 9)
('GAN loss 0.7928 ', 'GAN acc 0.4453', 'Discriminator loss 0.6395', 'Discriminator accuracy 0.6348', 'Total loss: 1.4323', 'for batch', 10)
('GAN loss 0.7359 ', 'GAN acc 0.5469', 'Discriminator loss 0.6501', 'Discriminator accuracy 0.6074', 'Total loss: 1.3860', 'for batch', 11)
('GAN loss 0.7477 ', 'GAN acc 0.5156', 'Discriminator loss 0.6583', 'Discriminator accuracy 0.6152', 'Total loss: 1.4060', 'for batch', 12)
('GAN loss 0.8198 ', 'GAN acc 0.3945', 'Discriminator loss 0.6614', 'Discriminator accuracy 0.6113', 'Total loss: 1.4812', 'for batch', 13)
('GAN loss 0.7613 ', 'GAN acc 0.4766', 'Discriminator loss 0.6659', 'Discriminator accuracy 0.5586', 'Total loss: 1.4272', 'for batch', 14)
('GAN loss 0.7244 ', 'GAN acc 0.5625', 'Discriminator loss 0.6733', 'Discriminator accuracy 0.5801', 'Total loss: 1.3977', 'for batch', 15)
('GAN loss 0.7026 ', 'GAN acc 0.5703', 'Discriminator loss 0.6590', 'Discriminator accuracy 0.5898', 'Total loss: 1.3616', 'for batch', 16)
('GAN loss 0.6864 ', 'GAN acc 0.5859', 'Discriminator loss 0.6711', 'Discriminator accuracy 0.5684', 'Total loss: 1.3575', 'for batch', 17)
('GAN loss 0.6992 ', 'GAN acc 0.5664', 'Discriminator loss 0.6809', 'Discriminator accuracy 0.5488', 'Total loss: 1.3801', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.84330261)
('DISCRIMINATOR_Imagem FAKE=', 0.78448796)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.574556')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7139 ', 'GAN acc 0.5820', 'Discriminator loss 0.6832', 'Discriminator accuracy 0.5645', 'Total loss: 1.3971', 'for batch', 0)
('GAN loss 0.7128 ', 'GAN acc 0.5352', 'Discriminator loss 0.6794', 'Discriminator accuracy 0.5859', 'Total loss: 1.3922', 'for batch', 1)
('GAN loss 0.6667 ', 'GAN acc 0.6133', 'Discriminator loss 0.6848', 'Discriminator accuracy 0.5566', 'Total loss: 1.3515', 'for batch', 2)
('GAN loss 0.6282 ', 'GAN acc 0.7227', 'Discriminator loss 0.6849', 'Discriminator accuracy 0.5312', 'Total loss: 1.3130', 'for batch', 3)
('GAN loss 0.6050 ', 'GAN acc 0.7383', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5293', 'Total loss: 1.3003', 'for batch', 4)
('GAN loss 0.6185 ', 'GAN acc 0.7344', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5527', 'Total loss: 1.3091', 'for batch', 5)
('GAN loss 0.6603 ', 'GAN acc 0.6523', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5508', 'Total loss: 1.3511', 'for batch', 6)
('GAN loss 0.6796 ', 'GAN acc 0.6016', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5195', 'Total loss: 1.3742', 'for batch', 7)
('GAN loss 0.6626 ', 'GAN acc 0.6523', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5508', 'Total loss: 1.3608', 'for batch', 8)
('GAN loss 0.6543 ', 'GAN acc 0.6445', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.5293', 'Total loss: 1.3520', 'for batch', 9)
('GAN loss 0.6677 ', 'GAN acc 0.5938', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.5215', 'Total loss: 1.3736', 'for batch', 10)
('GAN loss 0.6846 ', 'GAN acc 0.5820', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5391', 'Total loss: 1.3776', 'for batch', 11)
('GAN loss 0.6722 ', 'GAN acc 0.6133', 'Discriminator loss 0.6799', 'Discriminator accuracy 0.5527', 'Total loss: 1.3521', 'for batch', 12)
('GAN loss 0.6993 ', 'GAN acc 0.5117', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.4961', 'Total loss: 1.4035', 'for batch', 13)
('GAN loss 0.6667 ', 'GAN acc 0.6406', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.4961', 'Total loss: 1.3725', 'for batch', 14)
('GAN loss 0.6809 ', 'GAN acc 0.5820', 'Discriminator loss 0.7115', 'Discriminator accuracy 0.4922', 'Total loss: 1.3925', 'for batch', 15)
('GAN loss 0.6683 ', 'GAN acc 0.6406', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.5312', 'Total loss: 1.3701', 'for batch', 16)
('GAN loss 0.6734 ', 'GAN acc 0.5938', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.5293', 'Total loss: 1.3764', 'for batch', 17)
('GAN loss 0.6671 ', 'GAN acc 0.6094', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5391', 'Total loss: 1.3625', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.778974)
('DISCRIMINATOR_Imagem FAKE=', 0.76296127)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.154351')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6804 ', 'GAN acc 0.5742', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.5352', 'Total loss: 1.3820', 'for batch', 0)
('GAN loss 0.7048 ', 'GAN acc 0.5391', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4980', 'Total loss: 1.4005', 'for batch', 1)
('GAN loss 0.6696 ', 'GAN acc 0.6016', 'Discriminator loss 0.7079', 'Discriminator accuracy 0.4941', 'Total loss: 1.3774', 'for batch', 2)
('GAN loss 0.6601 ', 'GAN acc 0.6172', 'Discriminator loss 0.7144', 'Discriminator accuracy 0.4883', 'Total loss: 1.3745', 'for batch', 3)
('GAN loss 0.6449 ', 'GAN acc 0.6641', 'Discriminator loss 0.7061', 'Discriminator accuracy 0.4961', 'Total loss: 1.3511', 'for batch', 4)
('GAN loss 0.6725 ', 'GAN acc 0.5938', 'Discriminator loss 0.7064', 'Discriminator accuracy 0.5020', 'Total loss: 1.3789', 'for batch', 5)
('GAN loss 0.6754 ', 'GAN acc 0.5859', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.5176', 'Total loss: 1.3733', 'for batch', 6)
('GAN loss 0.6876 ', 'GAN acc 0.5625', 'Discriminator loss 0.7069', 'Discriminator accuracy 0.4902', 'Total loss: 1.3945', 'for batch', 7)
('GAN loss 0.6816 ', 'GAN acc 0.5664', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5391', 'Total loss: 1.3759', 'for batch', 8)
('GAN loss 0.6750 ', 'GAN acc 0.5859', 'Discriminator loss 0.7217', 'Discriminator accuracy 0.4336', 'Total loss: 1.3967', 'for batch', 9)
('GAN loss 0.6867 ', 'GAN acc 0.5625', 'Discriminator loss 0.7057', 'Discriminator accuracy 0.4766', 'Total loss: 1.3923', 'for batch', 10)
('GAN loss 0.6769 ', 'GAN acc 0.5781', 'Discriminator loss 0.7166', 'Discriminator accuracy 0.4492', 'Total loss: 1.3935', 'for batch', 11)
('GAN loss 0.6791 ', 'GAN acc 0.5391', 'Discriminator loss 0.7123', 'Discriminator accuracy 0.4648', 'Total loss: 1.3914', 'for batch', 12)
('GAN loss 0.6647 ', 'GAN acc 0.6016', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.5215', 'Total loss: 1.3620', 'for batch', 13)
('GAN loss 0.6770 ', 'GAN acc 0.5781', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5156', 'Total loss: 1.3741', 'for batch', 14)
('GAN loss 0.6944 ', 'GAN acc 0.5117', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4961', 'Total loss: 1.3992', 'for batch', 15)
('GAN loss 0.7063 ', 'GAN acc 0.4766', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.4018', 'for batch', 16)
('GAN loss 0.6807 ', 'GAN acc 0.5469', 'Discriminator loss 0.7079', 'Discriminator accuracy 0.4863', 'Total loss: 1.3886', 'for batch', 17)
('GAN loss 0.6758 ', 'GAN acc 0.5938', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.4961', 'Total loss: 1.3786', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.70799756)
('DISCRIMINATOR_Imagem FAKE=', 0.70621628)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.646131')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6865 ', 'GAN acc 0.5547', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5137', 'Total loss: 1.3791', 'for batch', 0)
('GAN loss 0.6796 ', 'GAN acc 0.5820', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.5156', 'Total loss: 1.3818', 'for batch', 1)
('GAN loss 0.6982 ', 'GAN acc 0.4766', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.4883', 'Total loss: 1.3995', 'for batch', 2)
('GAN loss 0.6817 ', 'GAN acc 0.6055', 'Discriminator loss 0.7045', 'Discriminator accuracy 0.4707', 'Total loss: 1.3862', 'for batch', 3)
('GAN loss 0.6788 ', 'GAN acc 0.5781', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4941', 'Total loss: 1.3790', 'for batch', 4)
('GAN loss 0.6864 ', 'GAN acc 0.5312', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.5059', 'Total loss: 1.3905', 'for batch', 5)
('GAN loss 0.6697 ', 'GAN acc 0.5781', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4824', 'Total loss: 1.3681', 'for batch', 6)
('GAN loss 0.6869 ', 'GAN acc 0.5156', 'Discriminator loss 0.7024', 'Discriminator accuracy 0.4766', 'Total loss: 1.3893', 'for batch', 7)
('GAN loss 0.6904 ', 'GAN acc 0.5273', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5195', 'Total loss: 1.3875', 'for batch', 8)
('GAN loss 0.7031 ', 'GAN acc 0.4922', 'Discriminator loss 0.7036', 'Discriminator accuracy 0.4844', 'Total loss: 1.4067', 'for batch', 9)
('GAN loss 0.6910 ', 'GAN acc 0.5117', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.4902', 'Total loss: 1.3951', 'for batch', 10)
('GAN loss 0.6837 ', 'GAN acc 0.5625', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5137', 'Total loss: 1.3805', 'for batch', 11)
('GAN loss 0.6766 ', 'GAN acc 0.5938', 'Discriminator loss 0.7087', 'Discriminator accuracy 0.4785', 'Total loss: 1.3853', 'for batch', 12)
('GAN loss 0.6834 ', 'GAN acc 0.5547', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.5059', 'Total loss: 1.3875', 'for batch', 13)
('GAN loss 0.6877 ', 'GAN acc 0.5938', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5293', 'Total loss: 1.3851', 'for batch', 14)
('GAN loss 0.7097 ', 'GAN acc 0.5039', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4883', 'Total loss: 1.4103', 'for batch', 15)
('GAN loss 0.7199 ', 'GAN acc 0.4570', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.5020', 'Total loss: 1.4213', 'for batch', 16)
('GAN loss 0.7170 ', 'GAN acc 0.4258', 'Discriminator loss 0.7084', 'Discriminator accuracy 0.4824', 'Total loss: 1.4254', 'for batch', 17)
('GAN loss 0.7054 ', 'GAN acc 0.4648', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.4707', 'Total loss: 1.4098', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.65676057)
('DISCRIMINATOR_Imagem FAKE=', 0.65638393)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.238053')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6980 ', 'GAN acc 0.5117', 'Discriminator loss 0.7061', 'Discriminator accuracy 0.4863', 'Total loss: 1.4041', 'for batch', 0)
('GAN loss 0.7018 ', 'GAN acc 0.5234', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.4785', 'Total loss: 1.4077', 'for batch', 1)
('GAN loss 0.6887 ', 'GAN acc 0.5273', 'Discriminator loss 0.7034', 'Discriminator accuracy 0.4766', 'Total loss: 1.3921', 'for batch', 2)
('GAN loss 0.6742 ', 'GAN acc 0.6250', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3697', 'for batch', 3)
('GAN loss 0.6745 ', 'GAN acc 0.5703', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5137', 'Total loss: 1.3699', 'for batch', 4)
('GAN loss 0.6750 ', 'GAN acc 0.6172', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.4902', 'Total loss: 1.3778', 'for batch', 5)
('GAN loss 0.6773 ', 'GAN acc 0.5898', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4902', 'Total loss: 1.3760', 'for batch', 6)
('GAN loss 0.6893 ', 'GAN acc 0.5234', 'Discriminator loss 0.6878', 'Discriminator accuracy 0.5234', 'Total loss: 1.3772', 'for batch', 7)
('GAN loss 0.6814 ', 'GAN acc 0.5977', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4863', 'Total loss: 1.3825', 'for batch', 8)
('GAN loss 0.6946 ', 'GAN acc 0.5156', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.5000', 'Total loss: 1.3953', 'for batch', 9)
('GAN loss 0.7020 ', 'GAN acc 0.4844', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4902', 'Total loss: 1.4004', 'for batch', 10)
('GAN loss 0.6998 ', 'GAN acc 0.4883', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4805', 'Total loss: 1.4014', 'for batch', 11)
('GAN loss 0.6999 ', 'GAN acc 0.5000', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.4629', 'Total loss: 1.4034', 'for batch', 12)
('GAN loss 0.6862 ', 'GAN acc 0.5898', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5039', 'Total loss: 1.3855', 'for batch', 13)
('GAN loss 0.6844 ', 'GAN acc 0.5664', 'Discriminator loss 0.7098', 'Discriminator accuracy 0.4590', 'Total loss: 1.3942', 'for batch', 14)
('GAN loss 0.6812 ', 'GAN acc 0.5938', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5098', 'Total loss: 1.3787', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.5117', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4902', 'Total loss: 1.3979', 'for batch', 16)
('GAN loss 0.6802 ', 'GAN acc 0.5898', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.4648', 'Total loss: 1.3860', 'for batch', 17)
('GAN loss 0.6892 ', 'GAN acc 0.5430', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5098', 'Total loss: 1.3844', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.62407583)
('DISCRIMINATOR_Imagem FAKE=', 0.62741983)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.722375')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6923 ', 'GAN acc 0.5234', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.4902', 'Total loss: 1.3951', 'for batch', 0)
('GAN loss 0.7051 ', 'GAN acc 0.4844', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4863', 'Total loss: 1.4039', 'for batch', 1)
('GAN loss 0.7171 ', 'GAN acc 0.4492', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5273', 'Total loss: 1.4094', 'for batch', 2)
('GAN loss 0.6871 ', 'GAN acc 0.5430', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4863', 'Total loss: 1.3886', 'for batch', 3)
('GAN loss 0.6853 ', 'GAN acc 0.5664', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5059', 'Total loss: 1.3807', 'for batch', 4)
('GAN loss 0.6909 ', 'GAN acc 0.5430', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4590', 'Total loss: 1.3947', 'for batch', 5)
('GAN loss 0.6783 ', 'GAN acc 0.6016', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5078', 'Total loss: 1.3720', 'for batch', 6)
('GAN loss 0.6901 ', 'GAN acc 0.5312', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5254', 'Total loss: 1.3848', 'for batch', 7)
('GAN loss 0.6881 ', 'GAN acc 0.5312', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.5137', 'Total loss: 1.3883', 'for batch', 8)
('GAN loss 0.7054 ', 'GAN acc 0.4883', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5195', 'Total loss: 1.3976', 'for batch', 9)
('GAN loss 0.7025 ', 'GAN acc 0.4727', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.5078', 'Total loss: 1.4008', 'for batch', 10)
('GAN loss 0.7082 ', 'GAN acc 0.4531', 'Discriminator loss 0.7068', 'Discriminator accuracy 0.4707', 'Total loss: 1.4150', 'for batch', 11)
('GAN loss 0.6837 ', 'GAN acc 0.5742', 'Discriminator loss 0.7052', 'Discriminator accuracy 0.4648', 'Total loss: 1.3888', 'for batch', 12)
('GAN loss 0.6851 ', 'GAN acc 0.5430', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4883', 'Total loss: 1.3889', 'for batch', 13)
('GAN loss 0.6876 ', 'GAN acc 0.5742', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4727', 'Total loss: 1.3889', 'for batch', 14)
('GAN loss 0.7025 ', 'GAN acc 0.4805', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4805', 'Total loss: 1.3977', 'for batch', 15)
('GAN loss 0.7061 ', 'GAN acc 0.4805', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5020', 'Total loss: 1.4012', 'for batch', 16)
('GAN loss 0.6976 ', 'GAN acc 0.4883', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4746', 'Total loss: 1.4013', 'for batch', 17)
('GAN loss 0.6955 ', 'GAN acc 0.5117', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4961', 'Total loss: 1.3937', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.59891737)
('DISCRIMINATOR_Imagem FAKE=', 0.60073304)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.223837')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6915 ', 'GAN acc 0.4922', 'Discriminator loss 0.7046', 'Discriminator accuracy 0.4941', 'Total loss: 1.3961', 'for batch', 0)
('GAN loss 0.6897 ', 'GAN acc 0.5391', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4668', 'Total loss: 1.3936', 'for batch', 1)
('GAN loss 0.6878 ', 'GAN acc 0.5625', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4883', 'Total loss: 1.3884', 'for batch', 2)
('GAN loss 0.6823 ', 'GAN acc 0.5664', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.5078', 'Total loss: 1.3819', 'for batch', 3)
('GAN loss 0.6893 ', 'GAN acc 0.5664', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4648', 'Total loss: 1.3855', 'for batch', 4)
('GAN loss 0.6774 ', 'GAN acc 0.5977', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5059', 'Total loss: 1.3707', 'for batch', 5)
('GAN loss 0.6732 ', 'GAN acc 0.6367', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4883', 'Total loss: 1.3665', 'for batch', 6)
('GAN loss 0.6824 ', 'GAN acc 0.5664', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.5039', 'Total loss: 1.3828', 'for batch', 7)
('GAN loss 0.6852 ', 'GAN acc 0.5312', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5176', 'Total loss: 1.3777', 'for batch', 8)
('GAN loss 0.6919 ', 'GAN acc 0.5078', 'Discriminator loss 0.7050', 'Discriminator accuracy 0.4629', 'Total loss: 1.3969', 'for batch', 9)
('GAN loss 0.6911 ', 'GAN acc 0.5000', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5078', 'Total loss: 1.3871', 'for batch', 10)
('GAN loss 0.7017 ', 'GAN acc 0.4883', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5137', 'Total loss: 1.3980', 'for batch', 11)
('GAN loss 0.6823 ', 'GAN acc 0.5430', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4961', 'Total loss: 1.3769', 'for batch', 12)
('GAN loss 0.7002 ', 'GAN acc 0.5039', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.5020', 'Total loss: 1.3975', 'for batch', 13)
('GAN loss 0.6945 ', 'GAN acc 0.5234', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5039', 'Total loss: 1.3873', 'for batch', 14)
('GAN loss 0.7071 ', 'GAN acc 0.4375', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4727', 'Total loss: 1.4074', 'for batch', 15)
('GAN loss 0.7059 ', 'GAN acc 0.4648', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5234', 'Total loss: 1.4006', 'for batch', 16)
('GAN loss 0.7132 ', 'GAN acc 0.4375', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.4805', 'Total loss: 1.4144', 'for batch', 17)
('GAN loss 0.7119 ', 'GAN acc 0.4531', 'Discriminator loss 0.7066', 'Discriminator accuracy 0.4453', 'Total loss: 1.4186', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.57995605)
('DISCRIMINATOR_Imagem FAKE=', 0.58065945)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.679951')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6984 ', 'GAN acc 0.4805', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4863', 'Total loss: 1.3968', 'for batch', 0)
('GAN loss 0.6971 ', 'GAN acc 0.4805', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4668', 'Total loss: 1.3977', 'for batch', 1)
('GAN loss 0.7029 ', 'GAN acc 0.4414', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4629', 'Total loss: 1.4045', 'for batch', 2)
('GAN loss 0.6966 ', 'GAN acc 0.5078', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4766', 'Total loss: 1.3983', 'for batch', 3)
('GAN loss 0.6822 ', 'GAN acc 0.5820', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4902', 'Total loss: 1.3789', 'for batch', 4)
('GAN loss 0.6783 ', 'GAN acc 0.6211', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5371', 'Total loss: 1.3727', 'for batch', 5)
('GAN loss 0.6803 ', 'GAN acc 0.5781', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4844', 'Total loss: 1.3768', 'for batch', 6)
('GAN loss 0.6759 ', 'GAN acc 0.6016', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4980', 'Total loss: 1.3732', 'for batch', 7)
('GAN loss 0.6821 ', 'GAN acc 0.6094', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5254', 'Total loss: 1.3794', 'for batch', 8)
('GAN loss 0.6764 ', 'GAN acc 0.6094', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.5000', 'Total loss: 1.3732', 'for batch', 9)
('GAN loss 0.6758 ', 'GAN acc 0.6367', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.4844', 'Total loss: 1.3805', 'for batch', 10)
('GAN loss 0.6875 ', 'GAN acc 0.5352', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4961', 'Total loss: 1.3895', 'for batch', 11)
('GAN loss 0.6966 ', 'GAN acc 0.4883', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3926', 'for batch', 12)
('GAN loss 0.7053 ', 'GAN acc 0.4648', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5078', 'Total loss: 1.4014', 'for batch', 13)
('GAN loss 0.7051 ', 'GAN acc 0.4531', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4785', 'Total loss: 1.4083', 'for batch', 14)
('GAN loss 0.7080 ', 'GAN acc 0.4258', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4746', 'Total loss: 1.4068', 'for batch', 15)
('GAN loss 0.7097 ', 'GAN acc 0.4297', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4590', 'Total loss: 1.4113', 'for batch', 16)
('GAN loss 0.7073 ', 'GAN acc 0.4531', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4590', 'Total loss: 1.4075', 'for batch', 17)
('GAN loss 0.6916 ', 'GAN acc 0.5273', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5566', 'Total loss: 1.3844', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56740904)
('DISCRIMINATOR_Imagem FAKE=', 0.56909323)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.222455')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6907 ', 'GAN acc 0.5391', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5000', 'Total loss: 1.3876', 'for batch', 0)
('GAN loss 0.6867 ', 'GAN acc 0.5508', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5156', 'Total loss: 1.3801', 'for batch', 1)
('GAN loss 0.6905 ', 'GAN acc 0.5352', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.4629', 'Total loss: 1.3931', 'for batch', 2)
('GAN loss 0.6819 ', 'GAN acc 0.6016', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4980', 'Total loss: 1.3799', 'for batch', 3)
('GAN loss 0.6791 ', 'GAN acc 0.6016', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4551', 'Total loss: 1.3801', 'for batch', 4)
('GAN loss 0.6742 ', 'GAN acc 0.6289', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4844', 'Total loss: 1.3703', 'for batch', 5)
('GAN loss 0.6777 ', 'GAN acc 0.5742', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5039', 'Total loss: 1.3695', 'for batch', 6)
('GAN loss 0.6789 ', 'GAN acc 0.6094', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4883', 'Total loss: 1.3749', 'for batch', 7)
('GAN loss 0.6819 ', 'GAN acc 0.5742', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4980', 'Total loss: 1.3784', 'for batch', 8)
('GAN loss 0.6793 ', 'GAN acc 0.6406', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4707', 'Total loss: 1.3800', 'for batch', 9)
('GAN loss 0.6929 ', 'GAN acc 0.5039', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5020', 'Total loss: 1.3890', 'for batch', 10)
('GAN loss 0.6911 ', 'GAN acc 0.5469', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3871', 'for batch', 11)
('GAN loss 0.6869 ', 'GAN acc 0.5273', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4766', 'Total loss: 1.3855', 'for batch', 12)
('GAN loss 0.6887 ', 'GAN acc 0.5469', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4395', 'Total loss: 1.3902', 'for batch', 13)
('GAN loss 0.6925 ', 'GAN acc 0.5273', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4512', 'Total loss: 1.3919', 'for batch', 14)
('GAN loss 0.6921 ', 'GAN acc 0.5547', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5195', 'Total loss: 1.3838', 'for batch', 15)
('GAN loss 0.6946 ', 'GAN acc 0.5078', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4922', 'Total loss: 1.3911', 'for batch', 16)
('GAN loss 0.7005 ', 'GAN acc 0.4414', 'Discriminator loss 0.7028', 'Discriminator accuracy 0.4668', 'Total loss: 1.4034', 'for batch', 17)
('GAN loss 0.6954 ', 'GAN acc 0.4922', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5000', 'Total loss: 1.3917', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55769628)
('DISCRIMINATOR_Imagem FAKE=', 0.55900109)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.712975')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6959 ', 'GAN acc 0.4922', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4902', 'Total loss: 1.3929', 'for batch', 0)
('GAN loss 0.7041 ', 'GAN acc 0.4375', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5195', 'Total loss: 1.3993', 'for batch', 1)
('GAN loss 0.7015 ', 'GAN acc 0.4375', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4766', 'Total loss: 1.3970', 'for batch', 2)
('GAN loss 0.6943 ', 'GAN acc 0.5352', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4727', 'Total loss: 1.3929', 'for batch', 3)
('GAN loss 0.6863 ', 'GAN acc 0.5586', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4453', 'Total loss: 1.3872', 'for batch', 4)
('GAN loss 0.6842 ', 'GAN acc 0.5781', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4844', 'Total loss: 1.3814', 'for batch', 5)
('GAN loss 0.6800 ', 'GAN acc 0.5938', 'Discriminator loss 0.7049', 'Discriminator accuracy 0.4492', 'Total loss: 1.3848', 'for batch', 6)
('GAN loss 0.6801 ', 'GAN acc 0.5703', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5215', 'Total loss: 1.3728', 'for batch', 7)
('GAN loss 0.6819 ', 'GAN acc 0.5859', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5000', 'Total loss: 1.3764', 'for batch', 8)
('GAN loss 0.6834 ', 'GAN acc 0.5469', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5137', 'Total loss: 1.3788', 'for batch', 9)
('GAN loss 0.6861 ', 'GAN acc 0.5469', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4648', 'Total loss: 1.3804', 'for batch', 10)
('GAN loss 0.6918 ', 'GAN acc 0.5195', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4688', 'Total loss: 1.3925', 'for batch', 11)
('GAN loss 0.6836 ', 'GAN acc 0.5938', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4883', 'Total loss: 1.3779', 'for batch', 12)
('GAN loss 0.6843 ', 'GAN acc 0.5820', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5059', 'Total loss: 1.3781', 'for batch', 13)
('GAN loss 0.6856 ', 'GAN acc 0.5508', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4531', 'Total loss: 1.3846', 'for batch', 14)
('GAN loss 0.7009 ', 'GAN acc 0.4805', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4883', 'Total loss: 1.3982', 'for batch', 15)
('GAN loss 0.7098 ', 'GAN acc 0.4297', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4844', 'Total loss: 1.4071', 'for batch', 16)
('GAN loss 0.6970 ', 'GAN acc 0.4727', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5234', 'Total loss: 1.3895', 'for batch', 17)
('GAN loss 0.7097 ', 'GAN acc 0.3828', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.4531', 'Total loss: 1.4116', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55043471)
('DISCRIMINATOR_Imagem FAKE=', 0.55193955)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.239338')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6994 ', 'GAN acc 0.5039', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5117', 'Total loss: 1.3960', 'for batch', 0)
('GAN loss 0.6979 ', 'GAN acc 0.4609', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4941', 'Total loss: 1.3938', 'for batch', 1)
('GAN loss 0.6984 ', 'GAN acc 0.4648', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4883', 'Total loss: 1.3943', 'for batch', 2)
('GAN loss 0.6848 ', 'GAN acc 0.5977', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5000', 'Total loss: 1.3807', 'for batch', 3)
('GAN loss 0.6853 ', 'GAN acc 0.5742', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4707', 'Total loss: 1.3852', 'for batch', 4)
('GAN loss 0.6792 ', 'GAN acc 0.6211', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4980', 'Total loss: 1.3738', 'for batch', 5)
('GAN loss 0.6779 ', 'GAN acc 0.6094', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3725', 'for batch', 6)
('GAN loss 0.6801 ', 'GAN acc 0.6172', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5020', 'Total loss: 1.3735', 'for batch', 7)
('GAN loss 0.6743 ', 'GAN acc 0.6562', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5078', 'Total loss: 1.3674', 'for batch', 8)
('GAN loss 0.6745 ', 'GAN acc 0.6367', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4902', 'Total loss: 1.3729', 'for batch', 9)
('GAN loss 0.6871 ', 'GAN acc 0.5703', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4727', 'Total loss: 1.3842', 'for batch', 10)
('GAN loss 0.6943 ', 'GAN acc 0.4805', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4961', 'Total loss: 1.3924', 'for batch', 11)
('GAN loss 0.6874 ', 'GAN acc 0.5547', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3827', 'for batch', 12)
('GAN loss 0.6996 ', 'GAN acc 0.4609', 'Discriminator loss 0.7030', 'Discriminator accuracy 0.4297', 'Total loss: 1.4026', 'for batch', 13)
('GAN loss 0.6952 ', 'GAN acc 0.5117', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4727', 'Total loss: 1.3933', 'for batch', 14)
('GAN loss 0.7159 ', 'GAN acc 0.3867', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4980', 'Total loss: 1.4120', 'for batch', 15)
('GAN loss 0.7016 ', 'GAN acc 0.4570', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5156', 'Total loss: 1.3959', 'for batch', 16)
('GAN loss 0.7052 ', 'GAN acc 0.4141', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5215', 'Total loss: 1.3986', 'for batch', 17)
('GAN loss 0.7063 ', 'GAN acc 0.4570', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5059', 'Total loss: 1.4028', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54220206)
('DISCRIMINATOR_Imagem FAKE=', 0.54304701)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.704936')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7032 ', 'GAN acc 0.4531', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5000', 'Total loss: 1.4002', 'for batch', 0)
('GAN loss 0.7034 ', 'GAN acc 0.4414', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4902', 'Total loss: 1.4008', 'for batch', 1)
('GAN loss 0.6985 ', 'GAN acc 0.4492', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5078', 'Total loss: 1.3935', 'for batch', 2)
('GAN loss 0.7002 ', 'GAN acc 0.4492', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5215', 'Total loss: 1.3914', 'for batch', 3)
('GAN loss 0.6916 ', 'GAN acc 0.5156', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5059', 'Total loss: 1.3877', 'for batch', 4)
('GAN loss 0.6798 ', 'GAN acc 0.5859', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4863', 'Total loss: 1.3749', 'for batch', 5)
('GAN loss 0.6770 ', 'GAN acc 0.6250', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3704', 'for batch', 6)
('GAN loss 0.6729 ', 'GAN acc 0.6484', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4863', 'Total loss: 1.3680', 'for batch', 7)
('GAN loss 0.6700 ', 'GAN acc 0.6523', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4922', 'Total loss: 1.3663', 'for batch', 8)
('GAN loss 0.6706 ', 'GAN acc 0.6953', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4941', 'Total loss: 1.3670', 'for batch', 9)
('GAN loss 0.6822 ', 'GAN acc 0.5938', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4590', 'Total loss: 1.3826', 'for batch', 10)
('GAN loss 0.6839 ', 'GAN acc 0.6211', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5059', 'Total loss: 1.3758', 'for batch', 11)
('GAN loss 0.6863 ', 'GAN acc 0.5391', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4648', 'Total loss: 1.3833', 'for batch', 12)
('GAN loss 0.6921 ', 'GAN acc 0.5469', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5117', 'Total loss: 1.3856', 'for batch', 13)
('GAN loss 0.6914 ', 'GAN acc 0.5508', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5078', 'Total loss: 1.3871', 'for batch', 14)
('GAN loss 0.7013 ', 'GAN acc 0.4414', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4688', 'Total loss: 1.3969', 'for batch', 15)
('GAN loss 0.7051 ', 'GAN acc 0.4258', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4844', 'Total loss: 1.4042', 'for batch', 16)
('GAN loss 0.7113 ', 'GAN acc 0.4141', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5020', 'Total loss: 1.4088', 'for batch', 17)
('GAN loss 0.7122 ', 'GAN acc 0.3750', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.4064', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53630728)
('DISCRIMINATOR_Imagem FAKE=', 0.53731382)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.322747')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7046 ', 'GAN acc 0.3984', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5332', 'Total loss: 1.3956', 'for batch', 0)
('GAN loss 0.7077 ', 'GAN acc 0.4102', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5059', 'Total loss: 1.4011', 'for batch', 1)
('GAN loss 0.6998 ', 'GAN acc 0.4727', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4844', 'Total loss: 1.3990', 'for batch', 2)
('GAN loss 0.6944 ', 'GAN acc 0.4961', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4883', 'Total loss: 1.3899', 'for batch', 3)
('GAN loss 0.6885 ', 'GAN acc 0.5586', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4980', 'Total loss: 1.3825', 'for batch', 4)
('GAN loss 0.6828 ', 'GAN acc 0.5859', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3779', 'for batch', 5)
('GAN loss 0.6818 ', 'GAN acc 0.6094', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5430', 'Total loss: 1.3713', 'for batch', 6)
('GAN loss 0.6777 ', 'GAN acc 0.6094', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5234', 'Total loss: 1.3727', 'for batch', 7)
('GAN loss 0.6747 ', 'GAN acc 0.6289', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4805', 'Total loss: 1.3712', 'for batch', 8)
('GAN loss 0.6718 ', 'GAN acc 0.6758', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4746', 'Total loss: 1.3699', 'for batch', 9)
('GAN loss 0.6742 ', 'GAN acc 0.6523', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5410', 'Total loss: 1.3649', 'for batch', 10)
('GAN loss 0.6863 ', 'GAN acc 0.5664', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4941', 'Total loss: 1.3827', 'for batch', 11)
('GAN loss 0.6829 ', 'GAN acc 0.5898', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4922', 'Total loss: 1.3797', 'for batch', 12)
('GAN loss 0.6860 ', 'GAN acc 0.5664', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4629', 'Total loss: 1.3832', 'for batch', 13)
('GAN loss 0.6966 ', 'GAN acc 0.4805', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4980', 'Total loss: 1.3910', 'for batch', 14)
('GAN loss 0.6963 ', 'GAN acc 0.5156', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5078', 'Total loss: 1.3895', 'for batch', 15)
('GAN loss 0.7048 ', 'GAN acc 0.4492', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5352', 'Total loss: 1.3992', 'for batch', 16)
('GAN loss 0.7045 ', 'GAN acc 0.4062', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4922', 'Total loss: 1.4000', 'for batch', 17)
('GAN loss 0.7075 ', 'GAN acc 0.4531', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5156', 'Total loss: 1.4025', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53404975)
('DISCRIMINATOR_Imagem FAKE=', 0.53520316)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.733128')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7043 ', 'GAN acc 0.4180', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5254', 'Total loss: 1.3972', 'for batch', 0)
('GAN loss 0.7117 ', 'GAN acc 0.3984', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5234', 'Total loss: 1.4061', 'for batch', 1)
('GAN loss 0.7075 ', 'GAN acc 0.4102', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5059', 'Total loss: 1.4030', 'for batch', 2)
('GAN loss 0.6936 ', 'GAN acc 0.5078', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4785', 'Total loss: 1.3886', 'for batch', 3)
('GAN loss 0.6931 ', 'GAN acc 0.5430', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4941', 'Total loss: 1.3899', 'for batch', 4)
('GAN loss 0.6887 ', 'GAN acc 0.5469', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4414', 'Total loss: 1.3876', 'for batch', 5)
('GAN loss 0.6870 ', 'GAN acc 0.5625', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5254', 'Total loss: 1.3789', 'for batch', 6)
('GAN loss 0.6778 ', 'GAN acc 0.6289', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4980', 'Total loss: 1.3752', 'for batch', 7)
('GAN loss 0.6803 ', 'GAN acc 0.6484', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3733', 'for batch', 8)
('GAN loss 0.6797 ', 'GAN acc 0.6250', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4590', 'Total loss: 1.3778', 'for batch', 9)
('GAN loss 0.6699 ', 'GAN acc 0.7148', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4902', 'Total loss: 1.3652', 'for batch', 10)
('GAN loss 0.6866 ', 'GAN acc 0.5781', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4863', 'Total loss: 1.3840', 'for batch', 11)
('GAN loss 0.6803 ', 'GAN acc 0.6016', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5020', 'Total loss: 1.3757', 'for batch', 12)
('GAN loss 0.6866 ', 'GAN acc 0.5938', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4961', 'Total loss: 1.3812', 'for batch', 13)
('GAN loss 0.6892 ', 'GAN acc 0.5273', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5020', 'Total loss: 1.3835', 'for batch', 14)
('GAN loss 0.6997 ', 'GAN acc 0.4727', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4883', 'Total loss: 1.3945', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.4766', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4805', 'Total loss: 1.3952', 'for batch', 16)
('GAN loss 0.7021 ', 'GAN acc 0.4727', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5234', 'Total loss: 1.3950', 'for batch', 17)
('GAN loss 0.6971 ', 'GAN acc 0.4883', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5117', 'Total loss: 1.3909', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53271461)
('DISCRIMINATOR_Imagem FAKE=', 0.53348213)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.242107')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7019 ', 'GAN acc 0.4531', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5059', 'Total loss: 1.3978', 'for batch', 0)
('GAN loss 0.7087 ', 'GAN acc 0.4023', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5156', 'Total loss: 1.4012', 'for batch', 1)
('GAN loss 0.7082 ', 'GAN acc 0.4102', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5234', 'Total loss: 1.4007', 'for batch', 2)
('GAN loss 0.6966 ', 'GAN acc 0.4727', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4941', 'Total loss: 1.3899', 'for batch', 3)
('GAN loss 0.6951 ', 'GAN acc 0.5039', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4727', 'Total loss: 1.3932', 'for batch', 4)
('GAN loss 0.6911 ', 'GAN acc 0.5508', 'Discriminator loss 0.6892', 'Discriminator accuracy 0.5469', 'Total loss: 1.3803', 'for batch', 5)
('GAN loss 0.6841 ', 'GAN acc 0.5898', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5312', 'Total loss: 1.3756', 'for batch', 6)
('GAN loss 0.6804 ', 'GAN acc 0.6094', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5332', 'Total loss: 1.3715', 'for batch', 7)
('GAN loss 0.6850 ', 'GAN acc 0.5820', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5391', 'Total loss: 1.3759', 'for batch', 8)
('GAN loss 0.6797 ', 'GAN acc 0.6445', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5195', 'Total loss: 1.3730', 'for batch', 9)
('GAN loss 0.6814 ', 'GAN acc 0.6016', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5059', 'Total loss: 1.3750', 'for batch', 10)
('GAN loss 0.6822 ', 'GAN acc 0.6328', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5059', 'Total loss: 1.3775', 'for batch', 11)
('GAN loss 0.6799 ', 'GAN acc 0.6016', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4902', 'Total loss: 1.3754', 'for batch', 12)
('GAN loss 0.6869 ', 'GAN acc 0.5625', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4980', 'Total loss: 1.3816', 'for batch', 13)
('GAN loss 0.6886 ', 'GAN acc 0.5391', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3834', 'for batch', 14)
('GAN loss 0.7040 ', 'GAN acc 0.4219', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3973', 'for batch', 15)
('GAN loss 0.7078 ', 'GAN acc 0.4102', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4980', 'Total loss: 1.4022', 'for batch', 16)
('GAN loss 0.7011 ', 'GAN acc 0.4453', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5059', 'Total loss: 1.3939', 'for batch', 17)
('GAN loss 0.7041 ', 'GAN acc 0.4219', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4961', 'Total loss: 1.3980', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53070676)
('DISCRIMINATOR_Imagem FAKE=', 0.53155833)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.787275')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7010 ', 'GAN acc 0.4570', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4961', 'Total loss: 1.3944', 'for batch', 0)
('GAN loss 0.7055 ', 'GAN acc 0.4023', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5020', 'Total loss: 1.4005', 'for batch', 1)
('GAN loss 0.6985 ', 'GAN acc 0.5117', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4727', 'Total loss: 1.3961', 'for batch', 2)
('GAN loss 0.6945 ', 'GAN acc 0.4766', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5254', 'Total loss: 1.3867', 'for batch', 3)
('GAN loss 0.6901 ', 'GAN acc 0.5312', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4941', 'Total loss: 1.3852', 'for batch', 4)
('GAN loss 0.6853 ', 'GAN acc 0.5742', 'Discriminator loss 0.6894', 'Discriminator accuracy 0.5273', 'Total loss: 1.3748', 'for batch', 5)
('GAN loss 0.6834 ', 'GAN acc 0.6016', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5020', 'Total loss: 1.3768', 'for batch', 6)
('GAN loss 0.6840 ', 'GAN acc 0.5820', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4629', 'Total loss: 1.3823', 'for batch', 7)
('GAN loss 0.6754 ', 'GAN acc 0.6406', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5273', 'Total loss: 1.3684', 'for batch', 8)
('GAN loss 0.6843 ', 'GAN acc 0.6133', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4980', 'Total loss: 1.3783', 'for batch', 9)
('GAN loss 0.6867 ', 'GAN acc 0.6016', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3806', 'for batch', 10)
('GAN loss 0.6832 ', 'GAN acc 0.5859', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4785', 'Total loss: 1.3811', 'for batch', 11)
('GAN loss 0.6831 ', 'GAN acc 0.5859', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4941', 'Total loss: 1.3778', 'for batch', 12)
('GAN loss 0.6893 ', 'GAN acc 0.5156', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4961', 'Total loss: 1.3822', 'for batch', 13)
('GAN loss 0.6933 ', 'GAN acc 0.5039', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5156', 'Total loss: 1.3849', 'for batch', 14)
('GAN loss 0.6938 ', 'GAN acc 0.4844', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4805', 'Total loss: 1.3902', 'for batch', 15)
('GAN loss 0.7001 ', 'GAN acc 0.4688', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4707', 'Total loss: 1.3968', 'for batch', 16)
('GAN loss 0.7006 ', 'GAN acc 0.4570', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4727', 'Total loss: 1.3984', 'for batch', 17)
('GAN loss 0.7064 ', 'GAN acc 0.4219', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.4020', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52829599)
('DISCRIMINATOR_Imagem FAKE=', 0.52869922)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.825150')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7000 ', 'GAN acc 0.4648', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5195', 'Total loss: 1.3933', 'for batch', 0)
('GAN loss 0.7075 ', 'GAN acc 0.3711', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4727', 'Total loss: 1.4070', 'for batch', 1)
('GAN loss 0.7050 ', 'GAN acc 0.4219', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4766', 'Total loss: 1.4005', 'for batch', 2)
('GAN loss 0.6967 ', 'GAN acc 0.4922', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5039', 'Total loss: 1.3884', 'for batch', 3)
('GAN loss 0.6977 ', 'GAN acc 0.4688', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5254', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6905 ', 'GAN acc 0.5273', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4941', 'Total loss: 1.3867', 'for batch', 5)
('GAN loss 0.6857 ', 'GAN acc 0.6055', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4883', 'Total loss: 1.3813', 'for batch', 6)
('GAN loss 0.6819 ', 'GAN acc 0.6523', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4980', 'Total loss: 1.3746', 'for batch', 7)
('GAN loss 0.6787 ', 'GAN acc 0.6523', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4805', 'Total loss: 1.3709', 'for batch', 8)
('GAN loss 0.6762 ', 'GAN acc 0.6562', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4922', 'Total loss: 1.3731', 'for batch', 9)
('GAN loss 0.6818 ', 'GAN acc 0.6016', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5117', 'Total loss: 1.3752', 'for batch', 10)
('GAN loss 0.6868 ', 'GAN acc 0.5703', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5117', 'Total loss: 1.3795', 'for batch', 11)
('GAN loss 0.6852 ', 'GAN acc 0.5898', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3806', 'for batch', 12)
('GAN loss 0.6906 ', 'GAN acc 0.5469', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3842', 'for batch', 13)
('GAN loss 0.6897 ', 'GAN acc 0.5195', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5371', 'Total loss: 1.3837', 'for batch', 14)
('GAN loss 0.6873 ', 'GAN acc 0.5977', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4785', 'Total loss: 1.3830', 'for batch', 15)
('GAN loss 0.6931 ', 'GAN acc 0.5234', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5273', 'Total loss: 1.3847', 'for batch', 16)
('GAN loss 0.6991 ', 'GAN acc 0.4648', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4746', 'Total loss: 1.3961', 'for batch', 17)
('GAN loss 0.6991 ', 'GAN acc 0.4531', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4727', 'Total loss: 1.3969', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52479458)
('DISCRIMINATOR_Imagem FAKE=', 0.52529693)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.266376')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7011 ', 'GAN acc 0.4453', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5000', 'Total loss: 1.3952', 'for batch', 0)
('GAN loss 0.7002 ', 'GAN acc 0.4922', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4941', 'Total loss: 1.3935', 'for batch', 1)
('GAN loss 0.6955 ', 'GAN acc 0.5000', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5352', 'Total loss: 1.3891', 'for batch', 2)
('GAN loss 0.6918 ', 'GAN acc 0.5195', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4824', 'Total loss: 1.3872', 'for batch', 3)
('GAN loss 0.6890 ', 'GAN acc 0.5234', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4902', 'Total loss: 1.3858', 'for batch', 4)
('GAN loss 0.6851 ', 'GAN acc 0.5820', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4766', 'Total loss: 1.3839', 'for batch', 5)
('GAN loss 0.6836 ', 'GAN acc 0.5938', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4707', 'Total loss: 1.3811', 'for batch', 6)
('GAN loss 0.6853 ', 'GAN acc 0.5469', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4941', 'Total loss: 1.3810', 'for batch', 7)
('GAN loss 0.6797 ', 'GAN acc 0.6367', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4766', 'Total loss: 1.3753', 'for batch', 8)
('GAN loss 0.6813 ', 'GAN acc 0.5977', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5059', 'Total loss: 1.3730', 'for batch', 9)
('GAN loss 0.6851 ', 'GAN acc 0.5625', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3801', 'for batch', 10)
('GAN loss 0.6843 ', 'GAN acc 0.6094', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4863', 'Total loss: 1.3794', 'for batch', 11)
('GAN loss 0.6844 ', 'GAN acc 0.5938', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4824', 'Total loss: 1.3802', 'for batch', 12)
('GAN loss 0.6937 ', 'GAN acc 0.4766', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5000', 'Total loss: 1.3878', 'for batch', 13)
('GAN loss 0.6935 ', 'GAN acc 0.5039', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4648', 'Total loss: 1.3894', 'for batch', 14)
('GAN loss 0.7003 ', 'GAN acc 0.4258', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4941', 'Total loss: 1.3941', 'for batch', 15)
('GAN loss 0.7014 ', 'GAN acc 0.4141', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3968', 'for batch', 16)
('GAN loss 0.7007 ', 'GAN acc 0.4219', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5000', 'Total loss: 1.3940', 'for batch', 17)
('GAN loss 0.7063 ', 'GAN acc 0.3984', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4746', 'Total loss: 1.4036', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52018809)
('DISCRIMINATOR_Imagem FAKE=', 0.52067065)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.785228')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7045 ', 'GAN acc 0.4414', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4824', 'Total loss: 1.4029', 'for batch', 0)
('GAN loss 0.7049 ', 'GAN acc 0.3984', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3980', 'for batch', 1)
('GAN loss 0.7014 ', 'GAN acc 0.4023', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5137', 'Total loss: 1.3924', 'for batch', 2)
('GAN loss 0.6949 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4805', 'Total loss: 1.3911', 'for batch', 3)
('GAN loss 0.6901 ', 'GAN acc 0.5703', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3832', 'for batch', 4)
('GAN loss 0.6892 ', 'GAN acc 0.5547', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4824', 'Total loss: 1.3871', 'for batch', 5)
('GAN loss 0.6866 ', 'GAN acc 0.5664', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4746', 'Total loss: 1.3843', 'for batch', 6)
('GAN loss 0.6784 ', 'GAN acc 0.6797', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4570', 'Total loss: 1.3770', 'for batch', 7)
('GAN loss 0.6814 ', 'GAN acc 0.6211', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5039', 'Total loss: 1.3752', 'for batch', 8)
('GAN loss 0.6782 ', 'GAN acc 0.6406', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4941', 'Total loss: 1.3712', 'for batch', 9)
('GAN loss 0.6800 ', 'GAN acc 0.6445', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4824', 'Total loss: 1.3773', 'for batch', 10)
('GAN loss 0.6778 ', 'GAN acc 0.6602', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5215', 'Total loss: 1.3712', 'for batch', 11)
('GAN loss 0.6841 ', 'GAN acc 0.6172', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4746', 'Total loss: 1.3788', 'for batch', 12)
('GAN loss 0.6887 ', 'GAN acc 0.5430', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5059', 'Total loss: 1.3828', 'for batch', 13)
('GAN loss 0.6936 ', 'GAN acc 0.5078', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5234', 'Total loss: 1.3844', 'for batch', 14)
('GAN loss 0.7015 ', 'GAN acc 0.4141', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4883', 'Total loss: 1.3943', 'for batch', 15)
('GAN loss 0.6990 ', 'GAN acc 0.4453', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3940', 'for batch', 16)
('GAN loss 0.7046 ', 'GAN acc 0.3789', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4766', 'Total loss: 1.3994', 'for batch', 17)
('GAN loss 0.7016 ', 'GAN acc 0.4297', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3967', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51931369)
('DISCRIMINATOR_Imagem FAKE=', 0.51972193)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.243918')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7002 ', 'GAN acc 0.4414', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3955', 'for batch', 0)
('GAN loss 0.7024 ', 'GAN acc 0.4453', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4688', 'Total loss: 1.3959', 'for batch', 1)
('GAN loss 0.7035 ', 'GAN acc 0.4062', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4902', 'Total loss: 1.3980', 'for batch', 2)
('GAN loss 0.6988 ', 'GAN acc 0.4727', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5059', 'Total loss: 1.3919', 'for batch', 3)
('GAN loss 0.6981 ', 'GAN acc 0.4609', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6905 ', 'GAN acc 0.5391', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4746', 'Total loss: 1.3871', 'for batch', 5)
('GAN loss 0.6865 ', 'GAN acc 0.6133', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4902', 'Total loss: 1.3826', 'for batch', 6)
('GAN loss 0.6867 ', 'GAN acc 0.5781', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4707', 'Total loss: 1.3839', 'for batch', 7)
('GAN loss 0.6869 ', 'GAN acc 0.5938', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4980', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6822 ', 'GAN acc 0.6094', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4844', 'Total loss: 1.3769', 'for batch', 9)
('GAN loss 0.6787 ', 'GAN acc 0.6250', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4824', 'Total loss: 1.3756', 'for batch', 10)
('GAN loss 0.6821 ', 'GAN acc 0.6211', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4531', 'Total loss: 1.3799', 'for batch', 11)
('GAN loss 0.6844 ', 'GAN acc 0.5781', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5059', 'Total loss: 1.3805', 'for batch', 12)
('GAN loss 0.6828 ', 'GAN acc 0.5977', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4609', 'Total loss: 1.3809', 'for batch', 13)
('GAN loss 0.6885 ', 'GAN acc 0.5391', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5176', 'Total loss: 1.3820', 'for batch', 14)
('GAN loss 0.6914 ', 'GAN acc 0.5195', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3862', 'for batch', 15)
('GAN loss 0.6963 ', 'GAN acc 0.5000', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5078', 'Total loss: 1.3914', 'for batch', 16)
('GAN loss 0.6988 ', 'GAN acc 0.4688', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4727', 'Total loss: 1.3951', 'for batch', 17)
('GAN loss 0.6986 ', 'GAN acc 0.4766', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5059', 'Total loss: 1.3907', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.517654)
('DISCRIMINATOR_Imagem FAKE=', 0.51745278)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.973177')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6976 ', 'GAN acc 0.4727', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3917', 'for batch', 0)
('GAN loss 0.7036 ', 'GAN acc 0.4180', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4785', 'Total loss: 1.4001', 'for batch', 1)
('GAN loss 0.6963 ', 'GAN acc 0.5078', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4961', 'Total loss: 1.3912', 'for batch', 2)
('GAN loss 0.6982 ', 'GAN acc 0.4805', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5273', 'Total loss: 1.3900', 'for batch', 3)
('GAN loss 0.6939 ', 'GAN acc 0.4883', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5371', 'Total loss: 1.3878', 'for batch', 4)
('GAN loss 0.6909 ', 'GAN acc 0.5117', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5352', 'Total loss: 1.3849', 'for batch', 5)
('GAN loss 0.6866 ', 'GAN acc 0.5977', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4805', 'Total loss: 1.3838', 'for batch', 6)
('GAN loss 0.6859 ', 'GAN acc 0.5898', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4648', 'Total loss: 1.3828', 'for batch', 7)
('GAN loss 0.6831 ', 'GAN acc 0.6367', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4766', 'Total loss: 1.3778', 'for batch', 8)
('GAN loss 0.6832 ', 'GAN acc 0.6094', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5234', 'Total loss: 1.3751', 'for batch', 9)
('GAN loss 0.6808 ', 'GAN acc 0.6094', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3746', 'for batch', 10)
('GAN loss 0.6821 ', 'GAN acc 0.6250', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4727', 'Total loss: 1.3779', 'for batch', 11)
('GAN loss 0.6882 ', 'GAN acc 0.5469', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4883', 'Total loss: 1.3841', 'for batch', 12)
('GAN loss 0.6827 ', 'GAN acc 0.5977', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5410', 'Total loss: 1.3741', 'for batch', 13)
('GAN loss 0.6865 ', 'GAN acc 0.5430', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4902', 'Total loss: 1.3823', 'for batch', 14)
('GAN loss 0.6870 ', 'GAN acc 0.5508', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5020', 'Total loss: 1.3830', 'for batch', 15)
('GAN loss 0.6913 ', 'GAN acc 0.5156', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5156', 'Total loss: 1.3859', 'for batch', 16)
('GAN loss 0.6992 ', 'GAN acc 0.4414', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4648', 'Total loss: 1.3939', 'for batch', 17)
('GAN loss 0.6989 ', 'GAN acc 0.4766', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5176', 'Total loss: 1.3926', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51675451)
('DISCRIMINATOR_Imagem FAKE=', 0.51726067)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.199115')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7006 ', 'GAN acc 0.4297', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3958', 'for batch', 0)
('GAN loss 0.7088 ', 'GAN acc 0.3633', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5020', 'Total loss: 1.4017', 'for batch', 1)
('GAN loss 0.6998 ', 'GAN acc 0.4375', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5293', 'Total loss: 1.3921', 'for batch', 2)
('GAN loss 0.7014 ', 'GAN acc 0.4141', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5586', 'Total loss: 1.3946', 'for batch', 3)
('GAN loss 0.6952 ', 'GAN acc 0.5000', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5176', 'Total loss: 1.3913', 'for batch', 4)
('GAN loss 0.6968 ', 'GAN acc 0.4883', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3906', 'for batch', 5)
('GAN loss 0.6930 ', 'GAN acc 0.5039', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5156', 'Total loss: 1.3859', 'for batch', 6)
('GAN loss 0.6880 ', 'GAN acc 0.5625', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5371', 'Total loss: 1.3804', 'for batch', 7)
('GAN loss 0.6876 ', 'GAN acc 0.5859', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5117', 'Total loss: 1.3813', 'for batch', 8)
('GAN loss 0.6878 ', 'GAN acc 0.5508', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5254', 'Total loss: 1.3799', 'for batch', 9)
('GAN loss 0.6824 ', 'GAN acc 0.6055', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3769', 'for batch', 10)
('GAN loss 0.6809 ', 'GAN acc 0.6133', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5332', 'Total loss: 1.3724', 'for batch', 11)
('GAN loss 0.6825 ', 'GAN acc 0.6133', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3764', 'for batch', 12)
('GAN loss 0.6843 ', 'GAN acc 0.5938', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4863', 'Total loss: 1.3784', 'for batch', 13)
('GAN loss 0.6897 ', 'GAN acc 0.5000', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4961', 'Total loss: 1.3849', 'for batch', 14)
('GAN loss 0.6906 ', 'GAN acc 0.5742', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5215', 'Total loss: 1.3832', 'for batch', 15)
('GAN loss 0.6983 ', 'GAN acc 0.4648', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4883', 'Total loss: 1.3917', 'for batch', 16)
('GAN loss 0.7008 ', 'GAN acc 0.4414', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3954', 'for batch', 17)
('GAN loss 0.7014 ', 'GAN acc 0.4297', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4707', 'Total loss: 1.3962', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51463413)
('DISCRIMINATOR_Imagem FAKE=', 0.51485032)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.746822')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7016 ', 'GAN acc 0.4180', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5215', 'Total loss: 1.3938', 'for batch', 0)
('GAN loss 0.7027 ', 'GAN acc 0.3945', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5059', 'Total loss: 1.3967', 'for batch', 1)
('GAN loss 0.6975 ', 'GAN acc 0.4766', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5176', 'Total loss: 1.3898', 'for batch', 2)
('GAN loss 0.6919 ', 'GAN acc 0.5234', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4922', 'Total loss: 1.3863', 'for batch', 3)
('GAN loss 0.6938 ', 'GAN acc 0.4922', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4668', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6872 ', 'GAN acc 0.5859', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4844', 'Total loss: 1.3838', 'for batch', 5)
('GAN loss 0.6825 ', 'GAN acc 0.6680', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3753', 'for batch', 6)
('GAN loss 0.6875 ', 'GAN acc 0.5859', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3810', 'for batch', 7)
('GAN loss 0.6866 ', 'GAN acc 0.6094', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5234', 'Total loss: 1.3784', 'for batch', 8)
('GAN loss 0.6811 ', 'GAN acc 0.6680', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4668', 'Total loss: 1.3766', 'for batch', 9)
('GAN loss 0.6858 ', 'GAN acc 0.5586', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5215', 'Total loss: 1.3766', 'for batch', 10)
('GAN loss 0.6811 ', 'GAN acc 0.6016', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5020', 'Total loss: 1.3750', 'for batch', 11)
('GAN loss 0.6856 ', 'GAN acc 0.5938', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4883', 'Total loss: 1.3795', 'for batch', 12)
('GAN loss 0.6870 ', 'GAN acc 0.5586', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4980', 'Total loss: 1.3818', 'for batch', 13)
('GAN loss 0.6907 ', 'GAN acc 0.5469', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5059', 'Total loss: 1.3851', 'for batch', 14)
('GAN loss 0.6959 ', 'GAN acc 0.5039', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5156', 'Total loss: 1.3877', 'for batch', 15)
('GAN loss 0.6963 ', 'GAN acc 0.4531', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5137', 'Total loss: 1.3912', 'for batch', 16)
('GAN loss 0.6978 ', 'GAN acc 0.4844', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4824', 'Total loss: 1.3916', 'for batch', 17)
('GAN loss 0.7025 ', 'GAN acc 0.3828', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4980', 'Total loss: 1.3967', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51421845)
('DISCRIMINATOR_Imagem FAKE=', 0.51484305)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.243349')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7014 ', 'GAN acc 0.4219', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5059', 'Total loss: 1.3942', 'for batch', 0)
('GAN loss 0.7066 ', 'GAN acc 0.3984', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5195', 'Total loss: 1.3995', 'for batch', 1)
('GAN loss 0.7063 ', 'GAN acc 0.3516', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4512', 'Total loss: 1.4038', 'for batch', 2)
('GAN loss 0.7034 ', 'GAN acc 0.3945', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4727', 'Total loss: 1.4016', 'for batch', 3)
('GAN loss 0.6975 ', 'GAN acc 0.4297', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4922', 'Total loss: 1.3918', 'for batch', 4)
('GAN loss 0.6954 ', 'GAN acc 0.4844', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4824', 'Total loss: 1.3898', 'for batch', 5)
('GAN loss 0.6859 ', 'GAN acc 0.5898', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4941', 'Total loss: 1.3794', 'for batch', 6)
('GAN loss 0.6831 ', 'GAN acc 0.6172', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5098', 'Total loss: 1.3779', 'for batch', 7)
('GAN loss 0.6838 ', 'GAN acc 0.6094', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5234', 'Total loss: 1.3759', 'for batch', 8)
('GAN loss 0.6806 ', 'GAN acc 0.6172', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5234', 'Total loss: 1.3734', 'for batch', 9)
('GAN loss 0.6818 ', 'GAN acc 0.6562', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5254', 'Total loss: 1.3749', 'for batch', 10)
('GAN loss 0.6805 ', 'GAN acc 0.6602', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4648', 'Total loss: 1.3760', 'for batch', 11)
('GAN loss 0.6871 ', 'GAN acc 0.6016', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4551', 'Total loss: 1.3836', 'for batch', 12)
('GAN loss 0.6931 ', 'GAN acc 0.5312', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5137', 'Total loss: 1.3884', 'for batch', 13)
('GAN loss 0.6952 ', 'GAN acc 0.5039', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4941', 'Total loss: 1.3910', 'for batch', 14)
('GAN loss 0.7039 ', 'GAN acc 0.3906', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5195', 'Total loss: 1.3961', 'for batch', 15)
('GAN loss 0.7063 ', 'GAN acc 0.3594', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4727', 'Total loss: 1.4019', 'for batch', 16)
('GAN loss 0.7068 ', 'GAN acc 0.3516', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5098', 'Total loss: 1.4029', 'for batch', 17)
('GAN loss 0.7026 ', 'GAN acc 0.4219', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5039', 'Total loss: 1.3949', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51340073)
('DISCRIMINATOR_Imagem FAKE=', 0.51349825)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.743678')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7002 ', 'GAN acc 0.4297', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4863', 'Total loss: 1.3942', 'for batch', 0)
('GAN loss 0.7055 ', 'GAN acc 0.4258', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4805', 'Total loss: 1.4022', 'for batch', 1)
('GAN loss 0.7009 ', 'GAN acc 0.4336', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4609', 'Total loss: 1.3975', 'for batch', 2)
('GAN loss 0.6994 ', 'GAN acc 0.4492', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4766', 'Total loss: 1.3957', 'for batch', 3)
('GAN loss 0.6925 ', 'GAN acc 0.5234', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4805', 'Total loss: 1.3881', 'for batch', 4)
('GAN loss 0.6916 ', 'GAN acc 0.5742', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4961', 'Total loss: 1.3841', 'for batch', 5)
('GAN loss 0.6881 ', 'GAN acc 0.5586', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5293', 'Total loss: 1.3793', 'for batch', 6)
('GAN loss 0.6812 ', 'GAN acc 0.6641', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4922', 'Total loss: 1.3743', 'for batch', 7)
('GAN loss 0.6845 ', 'GAN acc 0.6172', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4531', 'Total loss: 1.3822', 'for batch', 8)
('GAN loss 0.6837 ', 'GAN acc 0.6094', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4961', 'Total loss: 1.3777', 'for batch', 9)
('GAN loss 0.6833 ', 'GAN acc 0.6211', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5410', 'Total loss: 1.3732', 'for batch', 10)
('GAN loss 0.6855 ', 'GAN acc 0.6016', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4707', 'Total loss: 1.3816', 'for batch', 11)
('GAN loss 0.6809 ', 'GAN acc 0.6602', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5137', 'Total loss: 1.3751', 'for batch', 12)
('GAN loss 0.6876 ', 'GAN acc 0.5742', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5391', 'Total loss: 1.3801', 'for batch', 13)
('GAN loss 0.6873 ', 'GAN acc 0.5820', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5137', 'Total loss: 1.3791', 'for batch', 14)
('GAN loss 0.6933 ', 'GAN acc 0.4570', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5293', 'Total loss: 1.3862', 'for batch', 15)
('GAN loss 0.6992 ', 'GAN acc 0.4375', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5371', 'Total loss: 1.3928', 'for batch', 16)
('GAN loss 0.7046 ', 'GAN acc 0.3867', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5332', 'Total loss: 1.3992', 'for batch', 17)
('GAN loss 0.7053 ', 'GAN acc 0.3711', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4863', 'Total loss: 1.4012', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51191121)
('DISCRIMINATOR_Imagem FAKE=', 0.51156718)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.267531')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7088 ', 'GAN acc 0.3359', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5078', 'Total loss: 1.4003', 'for batch', 0)
('GAN loss 0.7089 ', 'GAN acc 0.3398', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4688', 'Total loss: 1.4037', 'for batch', 1)
('GAN loss 0.7038 ', 'GAN acc 0.3750', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5234', 'Total loss: 1.3979', 'for batch', 2)
('GAN loss 0.7004 ', 'GAN acc 0.4141', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4941', 'Total loss: 1.3951', 'for batch', 3)
('GAN loss 0.7012 ', 'GAN acc 0.3984', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5059', 'Total loss: 1.3972', 'for batch', 4)
('GAN loss 0.6916 ', 'GAN acc 0.5195', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4668', 'Total loss: 1.3873', 'for batch', 5)
('GAN loss 0.6892 ', 'GAN acc 0.5469', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4453', 'Total loss: 1.3870', 'for batch', 6)
('GAN loss 0.6854 ', 'GAN acc 0.5820', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4727', 'Total loss: 1.3790', 'for batch', 7)
('GAN loss 0.6827 ', 'GAN acc 0.6289', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4824', 'Total loss: 1.3765', 'for batch', 8)
('GAN loss 0.6773 ', 'GAN acc 0.6602', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5312', 'Total loss: 1.3690', 'for batch', 9)
('GAN loss 0.6773 ', 'GAN acc 0.6797', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5195', 'Total loss: 1.3704', 'for batch', 10)
('GAN loss 0.6779 ', 'GAN acc 0.6797', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4688', 'Total loss: 1.3754', 'for batch', 11)
('GAN loss 0.6793 ', 'GAN acc 0.6641', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5000', 'Total loss: 1.3735', 'for batch', 12)
('GAN loss 0.6839 ', 'GAN acc 0.6133', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4688', 'Total loss: 1.3790', 'for batch', 13)
('GAN loss 0.6851 ', 'GAN acc 0.5859', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5078', 'Total loss: 1.3803', 'for batch', 14)
('GAN loss 0.6876 ', 'GAN acc 0.5742', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5020', 'Total loss: 1.3818', 'for batch', 15)
('GAN loss 0.6907 ', 'GAN acc 0.5312', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4688', 'Total loss: 1.3869', 'for batch', 16)
('GAN loss 0.6981 ', 'GAN acc 0.4727', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5000', 'Total loss: 1.3948', 'for batch', 17)
('GAN loss 0.6969 ', 'GAN acc 0.4375', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4863', 'Total loss: 1.3906', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51399863)
('DISCRIMINATOR_Imagem FAKE=', 0.51415241)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.776773')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7056 ', 'GAN acc 0.3828', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.4014', 'for batch', 0)
('GAN loss 0.7042 ', 'GAN acc 0.4180', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5078', 'Total loss: 1.3968', 'for batch', 1)
('GAN loss 0.7046 ', 'GAN acc 0.3867', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4570', 'Total loss: 1.4011', 'for batch', 2)
('GAN loss 0.7013 ', 'GAN acc 0.4023', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4922', 'Total loss: 1.3953', 'for batch', 3)
('GAN loss 0.6972 ', 'GAN acc 0.4766', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4961', 'Total loss: 1.3919', 'for batch', 4)
('GAN loss 0.6988 ', 'GAN acc 0.4453', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4805', 'Total loss: 1.3949', 'for batch', 5)
('GAN loss 0.6949 ', 'GAN acc 0.4688', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4648', 'Total loss: 1.3919', 'for batch', 6)
('GAN loss 0.6902 ', 'GAN acc 0.5508', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5234', 'Total loss: 1.3815', 'for batch', 7)
('GAN loss 0.6931 ', 'GAN acc 0.4844', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5293', 'Total loss: 1.3846', 'for batch', 8)
('GAN loss 0.6913 ', 'GAN acc 0.5273', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3854', 'for batch', 9)
('GAN loss 0.6893 ', 'GAN acc 0.5195', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5020', 'Total loss: 1.3831', 'for batch', 10)
('GAN loss 0.6886 ', 'GAN acc 0.5469', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4629', 'Total loss: 1.3835', 'for batch', 11)
('GAN loss 0.6873 ', 'GAN acc 0.5859', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5039', 'Total loss: 1.3800', 'for batch', 12)
('GAN loss 0.6855 ', 'GAN acc 0.5977', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4902', 'Total loss: 1.3809', 'for batch', 13)
('GAN loss 0.6851 ', 'GAN acc 0.6016', 'Discriminator loss 0.6900', 'Discriminator accuracy 0.5332', 'Total loss: 1.3751', 'for batch', 14)
('GAN loss 0.6878 ', 'GAN acc 0.5703', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4668', 'Total loss: 1.3867', 'for batch', 15)
('GAN loss 0.6926 ', 'GAN acc 0.5195', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4941', 'Total loss: 1.3860', 'for batch', 16)
('GAN loss 0.6984 ', 'GAN acc 0.4609', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4531', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.6994 ', 'GAN acc 0.4336', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5137', 'Total loss: 1.3929', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51348215)
('DISCRIMINATOR_Imagem FAKE=', 0.5142234)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.319531')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7015 ', 'GAN acc 0.4375', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4961', 'Total loss: 1.3951', 'for batch', 0)
('GAN loss 0.7039 ', 'GAN acc 0.3516', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3977', 'for batch', 1)
('GAN loss 0.7007 ', 'GAN acc 0.4180', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5117', 'Total loss: 1.3955', 'for batch', 2)
('GAN loss 0.6983 ', 'GAN acc 0.4844', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5098', 'Total loss: 1.3929', 'for batch', 3)
('GAN loss 0.6975 ', 'GAN acc 0.4219', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4668', 'Total loss: 1.3936', 'for batch', 4)
('GAN loss 0.6956 ', 'GAN acc 0.5156', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5117', 'Total loss: 1.3890', 'for batch', 5)
('GAN loss 0.6947 ', 'GAN acc 0.5078', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4941', 'Total loss: 1.3879', 'for batch', 6)
('GAN loss 0.6935 ', 'GAN acc 0.4922', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3868', 'for batch', 7)
('GAN loss 0.6878 ', 'GAN acc 0.5703', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4824', 'Total loss: 1.3815', 'for batch', 8)
('GAN loss 0.6871 ', 'GAN acc 0.6055', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4941', 'Total loss: 1.3811', 'for batch', 9)
('GAN loss 0.6890 ', 'GAN acc 0.5547', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3830', 'for batch', 10)
('GAN loss 0.6839 ', 'GAN acc 0.6289', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4902', 'Total loss: 1.3778', 'for batch', 11)
('GAN loss 0.6832 ', 'GAN acc 0.5977', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4805', 'Total loss: 1.3772', 'for batch', 12)
('GAN loss 0.6848 ', 'GAN acc 0.6016', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.4961', 'Total loss: 1.3772', 'for batch', 13)
('GAN loss 0.6841 ', 'GAN acc 0.5977', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4863', 'Total loss: 1.3783', 'for batch', 14)
('GAN loss 0.6912 ', 'GAN acc 0.5469', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4766', 'Total loss: 1.3873', 'for batch', 15)
('GAN loss 0.6923 ', 'GAN acc 0.5234', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4453', 'Total loss: 1.3885', 'for batch', 16)
('GAN loss 0.6933 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4805', 'Total loss: 1.3888', 'for batch', 17)
('GAN loss 0.6985 ', 'GAN acc 0.4336', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5371', 'Total loss: 1.3902', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51074392)
('DISCRIMINATOR_Imagem FAKE=', 0.5109483)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.755954')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7027 ', 'GAN acc 0.3516', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4824', 'Total loss: 1.3974', 'for batch', 0)
('GAN loss 0.7046 ', 'GAN acc 0.3828', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4824', 'Total loss: 1.3993', 'for batch', 1)
('GAN loss 0.7042 ', 'GAN acc 0.4023', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4883', 'Total loss: 1.3996', 'for batch', 2)
('GAN loss 0.7036 ', 'GAN acc 0.3516', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5469', 'Total loss: 1.3947', 'for batch', 3)
('GAN loss 0.7003 ', 'GAN acc 0.4062', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5176', 'Total loss: 1.3914', 'for batch', 4)
('GAN loss 0.6914 ', 'GAN acc 0.5195', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5039', 'Total loss: 1.3853', 'for batch', 5)
('GAN loss 0.6925 ', 'GAN acc 0.5156', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5215', 'Total loss: 1.3850', 'for batch', 6)
('GAN loss 0.6877 ', 'GAN acc 0.5820', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5332', 'Total loss: 1.3805', 'for batch', 7)
('GAN loss 0.6877 ', 'GAN acc 0.6211', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4668', 'Total loss: 1.3827', 'for batch', 8)
('GAN loss 0.6852 ', 'GAN acc 0.6211', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4902', 'Total loss: 1.3790', 'for batch', 9)
('GAN loss 0.6852 ', 'GAN acc 0.6016', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4844', 'Total loss: 1.3790', 'for batch', 10)
('GAN loss 0.6865 ', 'GAN acc 0.6133', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3802', 'for batch', 11)
('GAN loss 0.6803 ', 'GAN acc 0.6641', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4590', 'Total loss: 1.3738', 'for batch', 12)
('GAN loss 0.6844 ', 'GAN acc 0.6602', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4922', 'Total loss: 1.3778', 'for batch', 13)
('GAN loss 0.6820 ', 'GAN acc 0.6719', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4785', 'Total loss: 1.3764', 'for batch', 14)
('GAN loss 0.6878 ', 'GAN acc 0.5781', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4883', 'Total loss: 1.3843', 'for batch', 15)
('GAN loss 0.6940 ', 'GAN acc 0.4766', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5078', 'Total loss: 1.3885', 'for batch', 16)
('GAN loss 0.6980 ', 'GAN acc 0.4258', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4980', 'Total loss: 1.3933', 'for batch', 17)
('GAN loss 0.6981 ', 'GAN acc 0.4414', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5254', 'Total loss: 1.3901', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51056784)
('DISCRIMINATOR_Imagem FAKE=', 0.51111448)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.340783')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7048 ', 'GAN acc 0.3594', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5098', 'Total loss: 1.3972', 'for batch', 0)
('GAN loss 0.7032 ', 'GAN acc 0.3867', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5020', 'Total loss: 1.3947', 'for batch', 1)
('GAN loss 0.7041 ', 'GAN acc 0.3594', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3975', 'for batch', 2)
('GAN loss 0.7040 ', 'GAN acc 0.3828', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5156', 'Total loss: 1.3975', 'for batch', 3)
('GAN loss 0.7042 ', 'GAN acc 0.3828', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4727', 'Total loss: 1.4005', 'for batch', 4)
('GAN loss 0.6986 ', 'GAN acc 0.4336', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5039', 'Total loss: 1.3916', 'for batch', 5)
('GAN loss 0.6972 ', 'GAN acc 0.4336', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4629', 'Total loss: 1.3919', 'for batch', 6)
('GAN loss 0.6897 ', 'GAN acc 0.5273', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5117', 'Total loss: 1.3836', 'for batch', 7)
('GAN loss 0.6884 ', 'GAN acc 0.5859', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5293', 'Total loss: 1.3802', 'for batch', 8)
('GAN loss 0.6884 ', 'GAN acc 0.5859', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4746', 'Total loss: 1.3825', 'for batch', 9)
('GAN loss 0.6870 ', 'GAN acc 0.5859', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4863', 'Total loss: 1.3816', 'for batch', 10)
('GAN loss 0.6847 ', 'GAN acc 0.6172', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4922', 'Total loss: 1.3784', 'for batch', 11)
('GAN loss 0.6850 ', 'GAN acc 0.6250', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5176', 'Total loss: 1.3783', 'for batch', 12)
('GAN loss 0.6858 ', 'GAN acc 0.6016', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4863', 'Total loss: 1.3807', 'for batch', 13)
('GAN loss 0.6852 ', 'GAN acc 0.6094', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5059', 'Total loss: 1.3773', 'for batch', 14)
('GAN loss 0.6895 ', 'GAN acc 0.5586', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5293', 'Total loss: 1.3804', 'for batch', 15)
('GAN loss 0.6915 ', 'GAN acc 0.5273', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4824', 'Total loss: 1.3869', 'for batch', 16)
('GAN loss 0.6958 ', 'GAN acc 0.4609', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4531', 'Total loss: 1.3912', 'for batch', 17)
('GAN loss 0.6919 ', 'GAN acc 0.4922', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5371', 'Total loss: 1.3844', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51090294)
('DISCRIMINATOR_Imagem FAKE=', 0.51061147)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.804721')
----------------------------------
('Epoch', 34, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6960 ', 'GAN acc 0.4805', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5234', 'Total loss: 1.3879', 'for batch', 0)
('GAN loss 0.6964 ', 'GAN acc 0.4805', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5059', 'Total loss: 1.3903', 'for batch', 1)
('GAN loss 0.6951 ', 'GAN acc 0.4961', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5254', 'Total loss: 1.3877', 'for batch', 2)
('GAN loss 0.6947 ', 'GAN acc 0.5117', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5156', 'Total loss: 1.3888', 'for batch', 3)
('GAN loss 0.6887 ', 'GAN acc 0.5859', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4785', 'Total loss: 1.3834', 'for batch', 4)
('GAN loss 0.6930 ', 'GAN acc 0.5156', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4434', 'Total loss: 1.3905', 'for batch', 5)
('GAN loss 0.6891 ', 'GAN acc 0.5781', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4844', 'Total loss: 1.3823', 'for batch', 6)
('GAN loss 0.6852 ', 'GAN acc 0.6289', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3789', 'for batch', 7)
('GAN loss 0.6855 ', 'GAN acc 0.6055', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4824', 'Total loss: 1.3795', 'for batch', 8)
('GAN loss 0.6888 ', 'GAN acc 0.5312', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4727', 'Total loss: 1.3839', 'for batch', 9)
('GAN loss 0.6879 ', 'GAN acc 0.5742', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5039', 'Total loss: 1.3824', 'for batch', 10)
('GAN loss 0.6932 ', 'GAN acc 0.5078', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4902', 'Total loss: 1.3888', 'for batch', 11)
('GAN loss 0.6888 ', 'GAN acc 0.5664', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4727', 'Total loss: 1.3837', 'for batch', 12)
('GAN loss 0.6885 ', 'GAN acc 0.5586', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4863', 'Total loss: 1.3830', 'for batch', 13)
('GAN loss 0.6916 ', 'GAN acc 0.5234', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5195', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.6934 ', 'GAN acc 0.5391', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4785', 'Total loss: 1.3894', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.4531', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5039', 'Total loss: 1.3906', 'for batch', 16)
('GAN loss 0.6973 ', 'GAN acc 0.4883', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5117', 'Total loss: 1.3916', 'for batch', 17)
('GAN loss 0.6997 ', 'GAN acc 0.4336', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5293', 'Total loss: 1.3917', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50973505)
('DISCRIMINATOR_Imagem FAKE=', 0.50978601)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.381667')
----------------------------------
('Epoch', 35, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7006 ', 'GAN acc 0.4219', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4707', 'Total loss: 1.3941', 'for batch', 0)
('GAN loss 0.7049 ', 'GAN acc 0.3555', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5039', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.7019 ', 'GAN acc 0.3789', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3968', 'for batch', 2)
('GAN loss 0.7020 ', 'GAN acc 0.3477', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4883', 'Total loss: 1.3971', 'for batch', 3)
('GAN loss 0.6983 ', 'GAN acc 0.4336', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4824', 'Total loss: 1.3920', 'for batch', 4)
('GAN loss 0.6947 ', 'GAN acc 0.4961', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4805', 'Total loss: 1.3901', 'for batch', 5)
('GAN loss 0.6901 ', 'GAN acc 0.5469', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5078', 'Total loss: 1.3843', 'for batch', 6)
('GAN loss 0.6891 ', 'GAN acc 0.5742', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4824', 'Total loss: 1.3828', 'for batch', 7)
('GAN loss 0.6897 ', 'GAN acc 0.5664', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5059', 'Total loss: 1.3821', 'for batch', 8)
('GAN loss 0.6879 ', 'GAN acc 0.5898', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4941', 'Total loss: 1.3810', 'for batch', 9)
('GAN loss 0.6878 ', 'GAN acc 0.5703', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5098', 'Total loss: 1.3824', 'for batch', 10)
('GAN loss 0.6884 ', 'GAN acc 0.5742', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5059', 'Total loss: 1.3807', 'for batch', 11)
('GAN loss 0.6860 ', 'GAN acc 0.5859', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4863', 'Total loss: 1.3794', 'for batch', 12)
('GAN loss 0.6880 ', 'GAN acc 0.5703', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5059', 'Total loss: 1.3811', 'for batch', 13)
('GAN loss 0.6877 ', 'GAN acc 0.5625', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4961', 'Total loss: 1.3817', 'for batch', 14)
('GAN loss 0.6883 ', 'GAN acc 0.5547', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5215', 'Total loss: 1.3806', 'for batch', 15)
('GAN loss 0.6917 ', 'GAN acc 0.5547', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4766', 'Total loss: 1.3874', 'for batch', 16)
('GAN loss 0.6929 ', 'GAN acc 0.5312', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4941', 'Total loss: 1.3875', 'for batch', 17)
('GAN loss 0.6953 ', 'GAN acc 0.5000', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5234', 'Total loss: 1.3861', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51072723)
('DISCRIMINATOR_Imagem FAKE=', 0.51117259)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.834813')
----------------------------------
('Epoch', 36, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6981 ', 'GAN acc 0.4414', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5195', 'Total loss: 1.3899', 'for batch', 0)
('GAN loss 0.6993 ', 'GAN acc 0.4805', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4941', 'Total loss: 1.3931', 'for batch', 1)
('GAN loss 0.7035 ', 'GAN acc 0.3438', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5176', 'Total loss: 1.3968', 'for batch', 2)
('GAN loss 0.6988 ', 'GAN acc 0.4336', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4922', 'Total loss: 1.3931', 'for batch', 3)
('GAN loss 0.6999 ', 'GAN acc 0.4062', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4961', 'Total loss: 1.3936', 'for batch', 4)
('GAN loss 0.6958 ', 'GAN acc 0.4609', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4707', 'Total loss: 1.3913', 'for batch', 5)
('GAN loss 0.6954 ', 'GAN acc 0.4766', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5020', 'Total loss: 1.3883', 'for batch', 6)
('GAN loss 0.6904 ', 'GAN acc 0.5430', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5098', 'Total loss: 1.3831', 'for batch', 7)
('GAN loss 0.6910 ', 'GAN acc 0.5156', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5098', 'Total loss: 1.3852', 'for batch', 8)
('GAN loss 0.6887 ', 'GAN acc 0.5742', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4805', 'Total loss: 1.3836', 'for batch', 9)
('GAN loss 0.6843 ', 'GAN acc 0.6562', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5137', 'Total loss: 1.3781', 'for batch', 10)
('GAN loss 0.6894 ', 'GAN acc 0.5547', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5176', 'Total loss: 1.3827', 'for batch', 11)
('GAN loss 0.6866 ', 'GAN acc 0.5859', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4727', 'Total loss: 1.3814', 'for batch', 12)
('GAN loss 0.6892 ', 'GAN acc 0.6055', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4824', 'Total loss: 1.3847', 'for batch', 13)
('GAN loss 0.6883 ', 'GAN acc 0.5625', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4961', 'Total loss: 1.3831', 'for batch', 14)
('GAN loss 0.6904 ', 'GAN acc 0.5508', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4766', 'Total loss: 1.3860', 'for batch', 15)
('GAN loss 0.6941 ', 'GAN acc 0.4922', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5293', 'Total loss: 1.3866', 'for batch', 16)
('GAN loss 0.6913 ', 'GAN acc 0.5273', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5098', 'Total loss: 1.3853', 'for batch', 17)
('GAN loss 0.6983 ', 'GAN acc 0.4570', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4844', 'Total loss: 1.3934', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50978309)
('DISCRIMINATOR_Imagem FAKE=', 0.51017451)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.298252')
----------------------------------
('Epoch', 37, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6983 ', 'GAN acc 0.4805', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4844', 'Total loss: 1.3923', 'for batch', 0)
('GAN loss 0.7004 ', 'GAN acc 0.4492', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4609', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.7030 ', 'GAN acc 0.3906', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4473', 'Total loss: 1.4009', 'for batch', 2)
('GAN loss 0.6956 ', 'GAN acc 0.4688', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4688', 'Total loss: 1.3905', 'for batch', 3)
('GAN loss 0.6970 ', 'GAN acc 0.4414', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4824', 'Total loss: 1.3923', 'for batch', 4)
('GAN loss 0.6970 ', 'GAN acc 0.4883', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5234', 'Total loss: 1.3907', 'for batch', 5)
('GAN loss 0.6909 ', 'GAN acc 0.5586', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5234', 'Total loss: 1.3831', 'for batch', 6)
('GAN loss 0.6922 ', 'GAN acc 0.5391', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5078', 'Total loss: 1.3853', 'for batch', 7)
('GAN loss 0.6906 ', 'GAN acc 0.5664', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5039', 'Total loss: 1.3835', 'for batch', 8)
('GAN loss 0.6917 ', 'GAN acc 0.5156', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4980', 'Total loss: 1.3852', 'for batch', 9)
('GAN loss 0.6874 ', 'GAN acc 0.5859', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5078', 'Total loss: 1.3808', 'for batch', 10)
('GAN loss 0.6900 ', 'GAN acc 0.5273', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4805', 'Total loss: 1.3847', 'for batch', 11)
('GAN loss 0.6871 ', 'GAN acc 0.5703', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4961', 'Total loss: 1.3817', 'for batch', 12)
('GAN loss 0.6904 ', 'GAN acc 0.5234', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4668', 'Total loss: 1.3867', 'for batch', 13)
('GAN loss 0.6929 ', 'GAN acc 0.5234', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5059', 'Total loss: 1.3866', 'for batch', 14)
('GAN loss 0.6955 ', 'GAN acc 0.4961', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5000', 'Total loss: 1.3896', 'for batch', 15)
('GAN loss 0.6974 ', 'GAN acc 0.4531', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4629', 'Total loss: 1.3935', 'for batch', 16)
('GAN loss 0.7035 ', 'GAN acc 0.3750', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5234', 'Total loss: 1.3963', 'for batch', 17)
('GAN loss 0.7048 ', 'GAN acc 0.3672', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5098', 'Total loss: 1.3984', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50730991)
('DISCRIMINATOR_Imagem FAKE=', 0.50792974)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.859765')
----------------------------------
('Epoch', 38, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7041 ', 'GAN acc 0.3711', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5293', 'Total loss: 1.3961', 'for batch', 0)
('GAN loss 0.7102 ', 'GAN acc 0.3086', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4883', 'Total loss: 1.4031', 'for batch', 1)
('GAN loss 0.7051 ', 'GAN acc 0.3398', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4961', 'Total loss: 1.3998', 'for batch', 2)
('GAN loss 0.6996 ', 'GAN acc 0.4141', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5156', 'Total loss: 1.3928', 'for batch', 3)
('GAN loss 0.6963 ', 'GAN acc 0.4297', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5020', 'Total loss: 1.3908', 'for batch', 4)
('GAN loss 0.6972 ', 'GAN acc 0.4570', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4785', 'Total loss: 1.3921', 'for batch', 5)
('GAN loss 0.6917 ', 'GAN acc 0.5234', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5117', 'Total loss: 1.3843', 'for batch', 6)
('GAN loss 0.6865 ', 'GAN acc 0.5938', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5176', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6863 ', 'GAN acc 0.6211', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5098', 'Total loss: 1.3792', 'for batch', 8)
('GAN loss 0.6856 ', 'GAN acc 0.6211', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5293', 'Total loss: 1.3760', 'for batch', 9)
('GAN loss 0.6857 ', 'GAN acc 0.6016', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5098', 'Total loss: 1.3794', 'for batch', 10)
('GAN loss 0.6836 ', 'GAN acc 0.6367', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5117', 'Total loss: 1.3753', 'for batch', 11)
('GAN loss 0.6831 ', 'GAN acc 0.6484', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4746', 'Total loss: 1.3777', 'for batch', 12)
('GAN loss 0.6864 ', 'GAN acc 0.5820', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5078', 'Total loss: 1.3786', 'for batch', 13)
('GAN loss 0.6859 ', 'GAN acc 0.6016', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3804', 'for batch', 14)
('GAN loss 0.6873 ', 'GAN acc 0.5664', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4805', 'Total loss: 1.3811', 'for batch', 15)
('GAN loss 0.6898 ', 'GAN acc 0.5469', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5254', 'Total loss: 1.3831', 'for batch', 16)
('GAN loss 0.6938 ', 'GAN acc 0.5000', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3872', 'for batch', 17)
('GAN loss 0.6958 ', 'GAN acc 0.4609', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5078', 'Total loss: 1.3885', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5098846)
('DISCRIMINATOR_Imagem FAKE=', 0.51001537)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.325473')
----------------------------------
('Epoch', 39, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6958 ', 'GAN acc 0.4844', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4805', 'Total loss: 1.3912', 'for batch', 0)
('GAN loss 0.7002 ', 'GAN acc 0.3906', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5000', 'Total loss: 1.3928', 'for batch', 1)
('GAN loss 0.7004 ', 'GAN acc 0.3945', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5352', 'Total loss: 1.3918', 'for batch', 2)
('GAN loss 0.6973 ', 'GAN acc 0.4570', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4727', 'Total loss: 1.3931', 'for batch', 3)
('GAN loss 0.6927 ', 'GAN acc 0.5430', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5156', 'Total loss: 1.3872', 'for batch', 4)
('GAN loss 0.6903 ', 'GAN acc 0.5703', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4688', 'Total loss: 1.3846', 'for batch', 5)
('GAN loss 0.6910 ', 'GAN acc 0.5469', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5156', 'Total loss: 1.3835', 'for batch', 6)
('GAN loss 0.6883 ', 'GAN acc 0.5625', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3817', 'for batch', 7)
('GAN loss 0.6862 ', 'GAN acc 0.6406', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5391', 'Total loss: 1.3779', 'for batch', 8)
('GAN loss 0.6854 ', 'GAN acc 0.6250', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5059', 'Total loss: 1.3793', 'for batch', 9)
('GAN loss 0.6867 ', 'GAN acc 0.6055', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4941', 'Total loss: 1.3804', 'for batch', 10)
('GAN loss 0.6857 ', 'GAN acc 0.6562', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4805', 'Total loss: 1.3816', 'for batch', 11)
('GAN loss 0.6844 ', 'GAN acc 0.6562', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5137', 'Total loss: 1.3769', 'for batch', 12)
('GAN loss 0.6850 ', 'GAN acc 0.6094', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4785', 'Total loss: 1.3788', 'for batch', 13)
('GAN loss 0.6862 ', 'GAN acc 0.6016', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4980', 'Total loss: 1.3805', 'for batch', 14)
('GAN loss 0.6907 ', 'GAN acc 0.5469', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4785', 'Total loss: 1.3860', 'for batch', 15)
('GAN loss 0.6934 ', 'GAN acc 0.4883', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4883', 'Total loss: 1.3865', 'for batch', 16)
('GAN loss 0.6952 ', 'GAN acc 0.4609', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4824', 'Total loss: 1.3896', 'for batch', 17)
('GAN loss 0.7021 ', 'GAN acc 0.3750', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5254', 'Total loss: 1.3939', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50872767)
('DISCRIMINATOR_Imagem FAKE=', 0.50920969)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.776787')
----------------------------------
('Epoch', 40, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7007 ', 'GAN acc 0.3594', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4629', 'Total loss: 1.3966', 'for batch', 0)
('GAN loss 0.7030 ', 'GAN acc 0.3555', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4570', 'Total loss: 1.3998', 'for batch', 1)
('GAN loss 0.7044 ', 'GAN acc 0.3477', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4941', 'Total loss: 1.3986', 'for batch', 2)
('GAN loss 0.7013 ', 'GAN acc 0.4102', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4922', 'Total loss: 1.3959', 'for batch', 3)
('GAN loss 0.6969 ', 'GAN acc 0.4688', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5273', 'Total loss: 1.3894', 'for batch', 4)
('GAN loss 0.6933 ', 'GAN acc 0.5195', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5312', 'Total loss: 1.3851', 'for batch', 5)
('GAN loss 0.6914 ', 'GAN acc 0.5625', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4961', 'Total loss: 1.3847', 'for batch', 6)
('GAN loss 0.6890 ', 'GAN acc 0.5742', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4902', 'Total loss: 1.3841', 'for batch', 7)
('GAN loss 0.6945 ', 'GAN acc 0.4766', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4824', 'Total loss: 1.3896', 'for batch', 8)
('GAN loss 0.6889 ', 'GAN acc 0.5938', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5117', 'Total loss: 1.3833', 'for batch', 9)
('GAN loss 0.6948 ', 'GAN acc 0.4688', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3877', 'for batch', 10)
('GAN loss 0.6925 ', 'GAN acc 0.5312', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5156', 'Total loss: 1.3857', 'for batch', 11)
('GAN loss 0.6887 ', 'GAN acc 0.5820', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4668', 'Total loss: 1.3836', 'for batch', 12)
('GAN loss 0.6873 ', 'GAN acc 0.5586', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4688', 'Total loss: 1.3824', 'for batch', 13)
('GAN loss 0.6893 ', 'GAN acc 0.5820', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5273', 'Total loss: 1.3814', 'for batch', 14)
('GAN loss 0.6923 ', 'GAN acc 0.4961', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5195', 'Total loss: 1.3847', 'for batch', 15)
('GAN loss 0.6922 ', 'GAN acc 0.5273', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4824', 'Total loss: 1.3872', 'for batch', 16)
('GAN loss 0.6946 ', 'GAN acc 0.4883', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5332', 'Total loss: 1.3859', 'for batch', 17)
('GAN loss 0.6968 ', 'GAN acc 0.4258', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5078', 'Total loss: 1.3908', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50975829)
('DISCRIMINATOR_Imagem FAKE=', 0.51007992)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.867586')
----------------------------------
('Epoch', 41, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6988 ', 'GAN acc 0.4531', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3918', 'for batch', 0)
('GAN loss 0.7012 ', 'GAN acc 0.4102', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5000', 'Total loss: 1.3944', 'for batch', 1)
('GAN loss 0.7012 ', 'GAN acc 0.4141', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4824', 'Total loss: 1.3956', 'for batch', 2)
('GAN loss 0.7015 ', 'GAN acc 0.4023', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5215', 'Total loss: 1.3947', 'for batch', 3)
('GAN loss 0.6992 ', 'GAN acc 0.4336', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5156', 'Total loss: 1.3928', 'for batch', 4)
('GAN loss 0.6933 ', 'GAN acc 0.5117', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4902', 'Total loss: 1.3871', 'for batch', 5)
('GAN loss 0.6895 ', 'GAN acc 0.5820', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5059', 'Total loss: 1.3818', 'for batch', 6)
('GAN loss 0.6895 ', 'GAN acc 0.5781', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5020', 'Total loss: 1.3823', 'for batch', 7)
('GAN loss 0.6875 ', 'GAN acc 0.6133', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5117', 'Total loss: 1.3809', 'for batch', 8)
('GAN loss 0.6842 ', 'GAN acc 0.6367', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5137', 'Total loss: 1.3773', 'for batch', 9)
('GAN loss 0.6806 ', 'GAN acc 0.6836', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4824', 'Total loss: 1.3749', 'for batch', 10)
('GAN loss 0.6832 ', 'GAN acc 0.6328', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5000', 'Total loss: 1.3761', 'for batch', 11)
('GAN loss 0.6840 ', 'GAN acc 0.6719', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5020', 'Total loss: 1.3770', 'for batch', 12)
('GAN loss 0.6891 ', 'GAN acc 0.5508', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5312', 'Total loss: 1.3806', 'for batch', 13)
('GAN loss 0.6833 ', 'GAN acc 0.6484', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5195', 'Total loss: 1.3763', 'for batch', 14)
('GAN loss 0.6914 ', 'GAN acc 0.5352', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4844', 'Total loss: 1.3852', 'for batch', 15)
('GAN loss 0.6922 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4609', 'Total loss: 1.3883', 'for batch', 16)
('GAN loss 0.6964 ', 'GAN acc 0.4453', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4902', 'Total loss: 1.3914', 'for batch', 17)
('GAN loss 0.6970 ', 'GAN acc 0.4492', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5332', 'Total loss: 1.3903', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50935948)
('DISCRIMINATOR_Imagem FAKE=', 0.50966769)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.295145')
----------------------------------
('Epoch', 42, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7004 ', 'GAN acc 0.4570', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5137', 'Total loss: 1.3930', 'for batch', 0)
('GAN loss 0.7047 ', 'GAN acc 0.3711', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5098', 'Total loss: 1.3975', 'for batch', 1)
('GAN loss 0.7025 ', 'GAN acc 0.3633', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4883', 'Total loss: 1.3969', 'for batch', 2)
('GAN loss 0.7055 ', 'GAN acc 0.3047', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5020', 'Total loss: 1.4007', 'for batch', 3)
('GAN loss 0.6990 ', 'GAN acc 0.3867', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5176', 'Total loss: 1.3920', 'for batch', 4)
('GAN loss 0.6955 ', 'GAN acc 0.4883', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4785', 'Total loss: 1.3896', 'for batch', 5)
('GAN loss 0.6973 ', 'GAN acc 0.4141', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5039', 'Total loss: 1.3916', 'for batch', 6)
('GAN loss 0.6918 ', 'GAN acc 0.5234', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5078', 'Total loss: 1.3852', 'for batch', 7)
('GAN loss 0.6889 ', 'GAN acc 0.5781', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4746', 'Total loss: 1.3830', 'for batch', 8)
('GAN loss 0.6886 ', 'GAN acc 0.5703', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.4844', 'Total loss: 1.3815', 'for batch', 9)
('GAN loss 0.6914 ', 'GAN acc 0.5469', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5098', 'Total loss: 1.3846', 'for batch', 10)
('GAN loss 0.6862 ', 'GAN acc 0.6211', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5059', 'Total loss: 1.3795', 'for batch', 11)
('GAN loss 0.6882 ', 'GAN acc 0.5977', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5039', 'Total loss: 1.3802', 'for batch', 12)
('GAN loss 0.6894 ', 'GAN acc 0.5586', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4883', 'Total loss: 1.3839', 'for batch', 13)
('GAN loss 0.6905 ', 'GAN acc 0.5664', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5156', 'Total loss: 1.3844', 'for batch', 14)
('GAN loss 0.6931 ', 'GAN acc 0.5000', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4863', 'Total loss: 1.3882', 'for batch', 15)
('GAN loss 0.6971 ', 'GAN acc 0.4297', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5059', 'Total loss: 1.3922', 'for batch', 16)
('GAN loss 0.6974 ', 'GAN acc 0.4453', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5098', 'Total loss: 1.3894', 'for batch', 17)
('GAN loss 0.6976 ', 'GAN acc 0.4375', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4688', 'Total loss: 1.3926', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50796175)
('DISCRIMINATOR_Imagem FAKE=', 0.50827402)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.838525')
----------------------------------
('Epoch', 43, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6996 ', 'GAN acc 0.4453', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3942', 'for batch', 0)
('GAN loss 0.7030 ', 'GAN acc 0.3828', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4902', 'Total loss: 1.3975', 'for batch', 1)
('GAN loss 0.7025 ', 'GAN acc 0.3477', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5078', 'Total loss: 1.3955', 'for batch', 2)
('GAN loss 0.6993 ', 'GAN acc 0.4141', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5000', 'Total loss: 1.3931', 'for batch', 3)
('GAN loss 0.6953 ', 'GAN acc 0.4375', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4785', 'Total loss: 1.3905', 'for batch', 4)
('GAN loss 0.6937 ', 'GAN acc 0.4805', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.3879', 'for batch', 5)
('GAN loss 0.6944 ', 'GAN acc 0.4883', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5508', 'Total loss: 1.3856', 'for batch', 6)
('GAN loss 0.6945 ', 'GAN acc 0.5000', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5000', 'Total loss: 1.3881', 'for batch', 7)
('GAN loss 0.6873 ', 'GAN acc 0.5977', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5234', 'Total loss: 1.3795', 'for batch', 8)
('GAN loss 0.6874 ', 'GAN acc 0.5742', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4863', 'Total loss: 1.3808', 'for batch', 9)
('GAN loss 0.6880 ', 'GAN acc 0.5781', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5156', 'Total loss: 1.3814', 'for batch', 10)
('GAN loss 0.6906 ', 'GAN acc 0.5430', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5039', 'Total loss: 1.3840', 'for batch', 11)
('GAN loss 0.6884 ', 'GAN acc 0.5586', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4902', 'Total loss: 1.3811', 'for batch', 12)
('GAN loss 0.6907 ', 'GAN acc 0.5703', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4785', 'Total loss: 1.3852', 'for batch', 13)
('GAN loss 0.6872 ', 'GAN acc 0.5859', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4805', 'Total loss: 1.3823', 'for batch', 14)
('GAN loss 0.6889 ', 'GAN acc 0.5469', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4863', 'Total loss: 1.3834', 'for batch', 15)
('GAN loss 0.6924 ', 'GAN acc 0.5000', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4727', 'Total loss: 1.3875', 'for batch', 16)
('GAN loss 0.6929 ', 'GAN acc 0.5117', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4629', 'Total loss: 1.3888', 'for batch', 17)
('GAN loss 0.6930 ', 'GAN acc 0.5586', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4609', 'Total loss: 1.3869', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50964195)
('DISCRIMINATOR_Imagem FAKE=', 0.50941479)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.224190')
----------------------------------
('Epoch', 44, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6963 ', 'GAN acc 0.4805', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5000', 'Total loss: 1.3900', 'for batch', 0)
('GAN loss 0.6974 ', 'GAN acc 0.4297', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5410', 'Total loss: 1.3891', 'for batch', 1)
('GAN loss 0.6957 ', 'GAN acc 0.4180', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5254', 'Total loss: 1.3866', 'for batch', 2)
('GAN loss 0.6956 ', 'GAN acc 0.4688', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5176', 'Total loss: 1.3882', 'for batch', 3)
('GAN loss 0.6924 ', 'GAN acc 0.5273', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5352', 'Total loss: 1.3850', 'for batch', 4)
('GAN loss 0.6979 ', 'GAN acc 0.4336', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4746', 'Total loss: 1.3932', 'for batch', 5)
('GAN loss 0.6937 ', 'GAN acc 0.4609', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5059', 'Total loss: 1.3856', 'for batch', 6)
('GAN loss 0.6908 ', 'GAN acc 0.5039', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5078', 'Total loss: 1.3851', 'for batch', 7)
('GAN loss 0.6909 ', 'GAN acc 0.5586', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5254', 'Total loss: 1.3839', 'for batch', 8)
('GAN loss 0.6890 ', 'GAN acc 0.5586', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4609', 'Total loss: 1.3833', 'for batch', 9)
('GAN loss 0.6897 ', 'GAN acc 0.5664', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5391', 'Total loss: 1.3827', 'for batch', 10)
('GAN loss 0.6898 ', 'GAN acc 0.5547', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5020', 'Total loss: 1.3838', 'for batch', 11)
('GAN loss 0.6900 ', 'GAN acc 0.5508', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4707', 'Total loss: 1.3841', 'for batch', 12)
('GAN loss 0.6876 ', 'GAN acc 0.5781', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5352', 'Total loss: 1.3799', 'for batch', 13)
('GAN loss 0.6937 ', 'GAN acc 0.5117', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5000', 'Total loss: 1.3876', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.4961', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4961', 'Total loss: 1.3859', 'for batch', 15)
('GAN loss 0.6978 ', 'GAN acc 0.4062', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4785', 'Total loss: 1.3919', 'for batch', 16)
('GAN loss 0.6949 ', 'GAN acc 0.4609', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5020', 'Total loss: 1.3888', 'for batch', 17)
('GAN loss 0.6942 ', 'GAN acc 0.4805', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5234', 'Total loss: 1.3873', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50953823)
('DISCRIMINATOR_Imagem FAKE=', 0.5096516)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.873955')
----------------------------------
('Epoch', 45, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6926 ', 'GAN acc 0.4805', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5098', 'Total loss: 1.3852', 'for batch', 0)
('GAN loss 0.6991 ', 'GAN acc 0.4414', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4668', 'Total loss: 1.3951', 'for batch', 1)
('GAN loss 0.6983 ', 'GAN acc 0.4375', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4668', 'Total loss: 1.3942', 'for batch', 2)
('GAN loss 0.6986 ', 'GAN acc 0.3867', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4512', 'Total loss: 1.3937', 'for batch', 3)
('GAN loss 0.6970 ', 'GAN acc 0.4297', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4688', 'Total loss: 1.3909', 'for batch', 4)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4941', 'Total loss: 1.3884', 'for batch', 5)
('GAN loss 0.6930 ', 'GAN acc 0.5078', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3868', 'for batch', 6)
('GAN loss 0.6938 ', 'GAN acc 0.4570', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5039', 'Total loss: 1.3871', 'for batch', 7)
('GAN loss 0.6937 ', 'GAN acc 0.5078', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4766', 'Total loss: 1.3877', 'for batch', 8)
('GAN loss 0.6913 ', 'GAN acc 0.5312', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5078', 'Total loss: 1.3849', 'for batch', 9)
('GAN loss 0.6897 ', 'GAN acc 0.5547', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3831', 'for batch', 10)
('GAN loss 0.6914 ', 'GAN acc 0.5195', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5352', 'Total loss: 1.3839', 'for batch', 11)
('GAN loss 0.6894 ', 'GAN acc 0.5625', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3833', 'for batch', 12)
('GAN loss 0.6877 ', 'GAN acc 0.5664', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5254', 'Total loss: 1.3812', 'for batch', 13)
('GAN loss 0.6925 ', 'GAN acc 0.5117', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4629', 'Total loss: 1.3873', 'for batch', 14)
('GAN loss 0.6936 ', 'GAN acc 0.5156', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4766', 'Total loss: 1.3894', 'for batch', 15)
('GAN loss 0.6952 ', 'GAN acc 0.4805', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5156', 'Total loss: 1.3873', 'for batch', 16)
('GAN loss 0.6929 ', 'GAN acc 0.5195', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4863', 'Total loss: 1.3871', 'for batch', 17)
('GAN loss 0.6954 ', 'GAN acc 0.4805', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5137', 'Total loss: 1.3887', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50755471)
('DISCRIMINATOR_Imagem FAKE=', 0.50789005)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.303600')
----------------------------------
('Epoch', 46, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6988 ', 'GAN acc 0.4414', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4941', 'Total loss: 1.3918', 'for batch', 0)
('GAN loss 0.7007 ', 'GAN acc 0.3945', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4727', 'Total loss: 1.3953', 'for batch', 1)
('GAN loss 0.7016 ', 'GAN acc 0.3945', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5078', 'Total loss: 1.3945', 'for batch', 2)
('GAN loss 0.6984 ', 'GAN acc 0.4180', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3925', 'for batch', 3)
('GAN loss 0.6959 ', 'GAN acc 0.4570', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5137', 'Total loss: 1.3883', 'for batch', 4)
('GAN loss 0.6929 ', 'GAN acc 0.5234', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5000', 'Total loss: 1.3851', 'for batch', 5)
('GAN loss 0.6886 ', 'GAN acc 0.5742', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5039', 'Total loss: 1.3820', 'for batch', 6)
('GAN loss 0.6896 ', 'GAN acc 0.5391', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5078', 'Total loss: 1.3834', 'for batch', 7)
('GAN loss 0.6883 ', 'GAN acc 0.5781', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5156', 'Total loss: 1.3826', 'for batch', 8)
('GAN loss 0.6884 ', 'GAN acc 0.5898', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5000', 'Total loss: 1.3828', 'for batch', 9)
('GAN loss 0.6911 ', 'GAN acc 0.5156', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5215', 'Total loss: 1.3839', 'for batch', 10)
('GAN loss 0.6852 ', 'GAN acc 0.6602', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5000', 'Total loss: 1.3786', 'for batch', 11)
('GAN loss 0.6837 ', 'GAN acc 0.6484', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4609', 'Total loss: 1.3791', 'for batch', 12)
('GAN loss 0.6867 ', 'GAN acc 0.5898', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5254', 'Total loss: 1.3781', 'for batch', 13)
('GAN loss 0.6867 ', 'GAN acc 0.5977', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4824', 'Total loss: 1.3816', 'for batch', 14)
('GAN loss 0.6908 ', 'GAN acc 0.5352', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5000', 'Total loss: 1.3841', 'for batch', 15)
('GAN loss 0.6911 ', 'GAN acc 0.5664', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4629', 'Total loss: 1.3863', 'for batch', 16)
('GAN loss 0.6899 ', 'GAN acc 0.5586', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4766', 'Total loss: 1.3849', 'for batch', 17)
('GAN loss 0.6961 ', 'GAN acc 0.4727', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5137', 'Total loss: 1.3896', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50925207)
('DISCRIMINATOR_Imagem FAKE=', 0.50992614)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.761699')
----------------------------------
('Epoch', 47, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6962 ', 'GAN acc 0.4688', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4629', 'Total loss: 1.3912', 'for batch', 0)
('GAN loss 0.7001 ', 'GAN acc 0.3906', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5156', 'Total loss: 1.3917', 'for batch', 1)
('GAN loss 0.7018 ', 'GAN acc 0.3867', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5430', 'Total loss: 1.3939', 'for batch', 2)
('GAN loss 0.6992 ', 'GAN acc 0.4023', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4453', 'Total loss: 1.3947', 'for batch', 3)
('GAN loss 0.6962 ', 'GAN acc 0.4492', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4863', 'Total loss: 1.3900', 'for batch', 4)
('GAN loss 0.6949 ', 'GAN acc 0.4766', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4961', 'Total loss: 1.3903', 'for batch', 5)
('GAN loss 0.6952 ', 'GAN acc 0.4414', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5273', 'Total loss: 1.3891', 'for batch', 6)
('GAN loss 0.6920 ', 'GAN acc 0.5469', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5234', 'Total loss: 1.3844', 'for batch', 7)
('GAN loss 0.6928 ', 'GAN acc 0.5078', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5176', 'Total loss: 1.3860', 'for batch', 8)
('GAN loss 0.6914 ', 'GAN acc 0.5508', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5312', 'Total loss: 1.3831', 'for batch', 9)
('GAN loss 0.6907 ', 'GAN acc 0.5586', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4707', 'Total loss: 1.3854', 'for batch', 10)
('GAN loss 0.6894 ', 'GAN acc 0.5742', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4473', 'Total loss: 1.3848', 'for batch', 11)
('GAN loss 0.6916 ', 'GAN acc 0.4922', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4766', 'Total loss: 1.3854', 'for batch', 12)
('GAN loss 0.6901 ', 'GAN acc 0.5391', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4688', 'Total loss: 1.3837', 'for batch', 13)
('GAN loss 0.6917 ', 'GAN acc 0.5469', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5137', 'Total loss: 1.3848', 'for batch', 14)
('GAN loss 0.6936 ', 'GAN acc 0.5039', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5215', 'Total loss: 1.3873', 'for batch', 15)
('GAN loss 0.6945 ', 'GAN acc 0.4648', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4570', 'Total loss: 1.3895', 'for batch', 16)
('GAN loss 0.6926 ', 'GAN acc 0.5234', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3865', 'for batch', 17)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4805', 'Total loss: 1.3890', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50678486)
('DISCRIMINATOR_Imagem FAKE=', 0.50683808)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.344677')
----------------------------------
('Epoch', 48, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7001 ', 'GAN acc 0.4102', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4844', 'Total loss: 1.3931', 'for batch', 0)
('GAN loss 0.6976 ', 'GAN acc 0.4414', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4844', 'Total loss: 1.3921', 'for batch', 1)
('GAN loss 0.6985 ', 'GAN acc 0.3828', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5000', 'Total loss: 1.3930', 'for batch', 2)
('GAN loss 0.6949 ', 'GAN acc 0.4961', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5078', 'Total loss: 1.3891', 'for batch', 3)
('GAN loss 0.6973 ', 'GAN acc 0.4453', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4941', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6920 ', 'GAN acc 0.5391', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4883', 'Total loss: 1.3850', 'for batch', 5)
('GAN loss 0.6923 ', 'GAN acc 0.5156', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4824', 'Total loss: 1.3865', 'for batch', 6)
('GAN loss 0.6897 ', 'GAN acc 0.5703', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4902', 'Total loss: 1.3849', 'for batch', 7)
('GAN loss 0.6865 ', 'GAN acc 0.6250', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5312', 'Total loss: 1.3794', 'for batch', 8)
('GAN loss 0.6894 ', 'GAN acc 0.5625', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5098', 'Total loss: 1.3814', 'for batch', 9)
('GAN loss 0.6866 ', 'GAN acc 0.5820', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5098', 'Total loss: 1.3796', 'for batch', 10)
('GAN loss 0.6878 ', 'GAN acc 0.5859', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5176', 'Total loss: 1.3797', 'for batch', 11)
('GAN loss 0.6848 ', 'GAN acc 0.6445', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4883', 'Total loss: 1.3776', 'for batch', 12)
('GAN loss 0.6887 ', 'GAN acc 0.5859', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4941', 'Total loss: 1.3828', 'for batch', 13)
('GAN loss 0.6897 ', 'GAN acc 0.5703', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4785', 'Total loss: 1.3847', 'for batch', 14)
('GAN loss 0.6924 ', 'GAN acc 0.5117', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5254', 'Total loss: 1.3853', 'for batch', 15)
('GAN loss 0.6912 ', 'GAN acc 0.5195', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4941', 'Total loss: 1.3852', 'for batch', 16)
('GAN loss 0.6968 ', 'GAN acc 0.4336', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5234', 'Total loss: 1.3912', 'for batch', 17)
('GAN loss 0.6985 ', 'GAN acc 0.4219', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4863', 'Total loss: 1.3930', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50683939)
('DISCRIMINATOR_Imagem FAKE=', 0.50776899)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.864525')
----------------------------------
('Epoch', 49, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6976 ', 'GAN acc 0.4453', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4922', 'Total loss: 1.3907', 'for batch', 0)
('GAN loss 0.7034 ', 'GAN acc 0.3828', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5176', 'Total loss: 1.3971', 'for batch', 1)
('GAN loss 0.6990 ', 'GAN acc 0.4102', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3924', 'for batch', 2)
('GAN loss 0.6973 ', 'GAN acc 0.4688', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5000', 'Total loss: 1.3910', 'for batch', 3)
('GAN loss 0.6941 ', 'GAN acc 0.5156', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5098', 'Total loss: 1.3872', 'for batch', 4)
('GAN loss 0.6949 ', 'GAN acc 0.4688', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5371', 'Total loss: 1.3869', 'for batch', 5)
('GAN loss 0.6926 ', 'GAN acc 0.5039', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5195', 'Total loss: 1.3853', 'for batch', 6)
('GAN loss 0.6876 ', 'GAN acc 0.6172', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4922', 'Total loss: 1.3807', 'for batch', 7)
('GAN loss 0.6890 ', 'GAN acc 0.5898', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5000', 'Total loss: 1.3820', 'for batch', 8)
('GAN loss 0.6924 ', 'GAN acc 0.5000', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5156', 'Total loss: 1.3853', 'for batch', 9)
('GAN loss 0.6857 ', 'GAN acc 0.6250', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4688', 'Total loss: 1.3806', 'for batch', 10)
('GAN loss 0.6884 ', 'GAN acc 0.5820', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4746', 'Total loss: 1.3831', 'for batch', 11)
('GAN loss 0.6892 ', 'GAN acc 0.5781', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4629', 'Total loss: 1.3842', 'for batch', 12)
('GAN loss 0.6891 ', 'GAN acc 0.6016', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4922', 'Total loss: 1.3825', 'for batch', 13)
('GAN loss 0.6865 ', 'GAN acc 0.6445', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5215', 'Total loss: 1.3789', 'for batch', 14)
('GAN loss 0.6960 ', 'GAN acc 0.5078', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5176', 'Total loss: 1.3885', 'for batch', 15)
('GAN loss 0.6967 ', 'GAN acc 0.4570', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4824', 'Total loss: 1.3898', 'for batch', 16)
('GAN loss 0.6978 ', 'GAN acc 0.4219', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4980', 'Total loss: 1.3908', 'for batch', 17)
('GAN loss 0.6974 ', 'GAN acc 0.4336', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4531', 'Total loss: 1.3937', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50660902)
('DISCRIMINATOR_Imagem FAKE=', 0.50679642)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.273804')
----------------------------------
('Epoch', 50, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6990 ', 'GAN acc 0.4102', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5000', 'Total loss: 1.3912', 'for batch', 0)
('GAN loss 0.6992 ', 'GAN acc 0.4492', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5176', 'Total loss: 1.3918', 'for batch', 1)
('GAN loss 0.7016 ', 'GAN acc 0.3672', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4863', 'Total loss: 1.3954', 'for batch', 2)
('GAN loss 0.7005 ', 'GAN acc 0.4531', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5137', 'Total loss: 1.3932', 'for batch', 3)
('GAN loss 0.6971 ', 'GAN acc 0.4219', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3906', 'for batch', 4)
('GAN loss 0.6987 ', 'GAN acc 0.4258', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5371', 'Total loss: 1.3915', 'for batch', 5)
('GAN loss 0.6929 ', 'GAN acc 0.5078', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4688', 'Total loss: 1.3877', 'for batch', 6)
('GAN loss 0.6915 ', 'GAN acc 0.5234', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5273', 'Total loss: 1.3848', 'for batch', 7)
('GAN loss 0.6901 ', 'GAN acc 0.5547', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5273', 'Total loss: 1.3820', 'for batch', 8)
('GAN loss 0.6900 ', 'GAN acc 0.5430', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4785', 'Total loss: 1.3835', 'for batch', 9)
('GAN loss 0.6897 ', 'GAN acc 0.5781', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5312', 'Total loss: 1.3832', 'for batch', 10)
('GAN loss 0.6898 ', 'GAN acc 0.5938', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5215', 'Total loss: 1.3819', 'for batch', 11)
('GAN loss 0.6904 ', 'GAN acc 0.5625', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4805', 'Total loss: 1.3841', 'for batch', 12)
('GAN loss 0.6900 ', 'GAN acc 0.5742', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5020', 'Total loss: 1.3846', 'for batch', 13)
('GAN loss 0.6896 ', 'GAN acc 0.5664', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4766', 'Total loss: 1.3832', 'for batch', 14)
('GAN loss 0.6887 ', 'GAN acc 0.5664', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4590', 'Total loss: 1.3842', 'for batch', 15)
('GAN loss 0.6900 ', 'GAN acc 0.5391', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4551', 'Total loss: 1.3848', 'for batch', 16)
('GAN loss 0.6918 ', 'GAN acc 0.5352', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4727', 'Total loss: 1.3866', 'for batch', 17)
('GAN loss 0.6913 ', 'GAN acc 0.5469', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5000', 'Total loss: 1.3842', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50781798)
('DISCRIMINATOR_Imagem FAKE=', 0.50790179)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.819407')
----------------------------------
End of training
Saving histograms
----------------------------------
('Total samples = ', 5000, ' Batch size =', 256, ' Epochs = ', 50)
('Generator loss 0.6913 ', 'Discriminator loss 0.6930', 'Total: 1.3842')
----------------------------------
---DISCRIMINATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_1 (Convolution2D)  (None, 16, 16, 16)    304         convolution2d_input_1[0][0]      
____________________________________________________________________________________________________
leakyrelu_1 (LeakyReLU)          (None, 16, 16, 16)    0           convolution2d_1[0][0]            
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_1[0][0]                
____________________________________________________________________________________________________
convolution2d_2 (Convolution2D)  (None, 32, 8, 8)      4640        dropout_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_2 (LeakyReLU)          (None, 32, 8, 8)      0           convolution2d_2[0][0]            
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_2[0][0]                
____________________________________________________________________________________________________
convolution2d_3 (Convolution2D)  (None, 64, 4, 4)      18496       dropout_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_3 (LeakyReLU)          (None, 64, 4, 4)      0           convolution2d_3[0][0]            
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_3[0][0]                
____________________________________________________________________________________________________
convolution2d_4 (Convolution2D)  (None, 128, 2, 2)     73856       dropout_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_4 (LeakyReLU)          (None, 128, 2, 2)     0           convolution2d_4[0][0]            
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_4[0][0]                
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 512)           0           dropout_4[0][0]                  
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 256)           131328      flatten_1[0][0]                  
____________________________________________________________________________________________________
leakyrelu_5 (LeakyReLU)          (None, 256)           0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 256)           0           leakyrelu_5[0][0]                
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 1)             257         dropout_5[0][0]                  
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
None
----------------------------------
---GENERATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_5 (Convolution2D)  (None, 32, 32, 32)    320         convolution2d_input_2[0][0]      
____________________________________________________________________________________________________
leakyrelu_6 (LeakyReLU)          (None, 32, 32, 32)    0           convolution2d_5[0][0]            
____________________________________________________________________________________________________
convolution2d_6 (Convolution2D)  (None, 64, 32, 32)    18496       leakyrelu_6[0][0]                
____________________________________________________________________________________________________
batchnormalization_1 (BatchNormal(None, 64, 32, 32)    128         convolution2d_6[0][0]            
____________________________________________________________________________________________________
leakyrelu_7 (LeakyReLU)          (None, 64, 32, 32)    0           batchnormalization_1[0][0]       
____________________________________________________________________________________________________
convolution2d_7 (Convolution2D)  (None, 128, 32, 32)   73856       leakyrelu_7[0][0]                
____________________________________________________________________________________________________
batchnormalization_2 (BatchNormal(None, 128, 32, 32)   256         convolution2d_7[0][0]            
____________________________________________________________________________________________________
leakyrelu_8 (LeakyReLU)          (None, 128, 32, 32)   0           batchnormalization_2[0][0]       
____________________________________________________________________________________________________
convolution2d_8 (Convolution2D)  (None, 256, 32, 32)   295168      leakyrelu_8[0][0]                
____________________________________________________________________________________________________
batchnormalization_3 (BatchNormal(None, 256, 32, 32)   512         convolution2d_8[0][0]            
____________________________________________________________________________________________________
leakyrelu_9 (LeakyReLU)          (None, 256, 32, 32)   0           batchnormalization_3[0][0]       
____________________________________________________________________________________________________
convolution2d_9 (Convolution2D)  (None, 256, 32, 32)   590080      leakyrelu_9[0][0]                
____________________________________________________________________________________________________
batchnormalization_4 (BatchNormal(None, 256, 32, 32)   512         convolution2d_9[0][0]            
____________________________________________________________________________________________________
leakyrelu_10 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_4[0][0]       
____________________________________________________________________________________________________
convolution2d_10 (Convolution2D) (None, 128, 32, 32)   295040      leakyrelu_10[0][0]               
____________________________________________________________________________________________________
batchnormalization_5 (BatchNormal(None, 128, 32, 32)   256         convolution2d_10[0][0]           
____________________________________________________________________________________________________
leakyrelu_11 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_5[0][0]       
____________________________________________________________________________________________________
convolution2d_11 (Convolution2D) (None, 64, 32, 32)    73792       leakyrelu_11[0][0]               
____________________________________________________________________________________________________
batchnormalization_6 (BatchNormal(None, 64, 32, 32)    128         convolution2d_11[0][0]           
____________________________________________________________________________________________________
leakyrelu_12 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_6[0][0]       
____________________________________________________________________________________________________
convolution2d_12 (Convolution2D) (None, 32, 32, 32)    18464       leakyrelu_12[0][0]               
____________________________________________________________________________________________________
batchnormalization_7 (BatchNormal(None, 32, 32, 32)    64          convolution2d_12[0][0]           
____________________________________________________________________________________________________
leakyrelu_13 (LeakyReLU)         (None, 32, 32, 32)    0           batchnormalization_7[0][0]       
____________________________________________________________________________________________________
convolution2d_13 (Convolution2D) (None, 2, 32, 32)     578         leakyrelu_13[0][0]               
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 2, 32, 32)     0           convolution2d_13[0][0]           
====================================================================================================
Total params: 1367650
____________________________________________________________________________________________________
None
----------------------------------
---GAN---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_2 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 1)             228881      lambda_1[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
None
----------------------------------
('Training with dataset based on class - ', 'automobile', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_5 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_4 (Sequential)        (None, 1)             0           lambda_2[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_14 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_3[0][0]      
____________________________________________________________________________________________________
leakyrelu_14 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_14[0][0]           
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_14[0][0]               
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 32, 8, 8)      4640        dropout_6[0][0]                  
____________________________________________________________________________________________________
leakyrelu_15 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_15[0][0]           
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_15[0][0]               
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 64, 4, 4)      18496       dropout_7[0][0]                  
____________________________________________________________________________________________________
leakyrelu_16 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_16[0][0]               
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 128, 2, 2)     73856       dropout_8[0][0]                  
____________________________________________________________________________________________________
leakyrelu_17 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_17[0][0]           
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_17[0][0]               
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 512)           0           dropout_9[0][0]                  
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 256)           131328      flatten_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_18 (LeakyReLU)         (None, 256)           0           dense_3[0][0]                    
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 256)           0           leakyrelu_18[0][0]               
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 1)             257         dropout_10[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.5869 ', 'GAN acc 0.7305', 'Discriminator loss 0.7932', 'Discriminator accuracy 0.4551', 'Total loss: 1.3801', 'for batch', 0)
('GAN loss 0.5360 ', 'GAN acc 0.7656', 'Discriminator loss 0.8268', 'Discriminator accuracy 0.4727', 'Total loss: 1.3628', 'for batch', 1)
('GAN loss 0.6623 ', 'GAN acc 0.6445', 'Discriminator loss 0.8136', 'Discriminator accuracy 0.5020', 'Total loss: 1.4759', 'for batch', 2)
('GAN loss 0.7406 ', 'GAN acc 0.4805', 'Discriminator loss 0.7619', 'Discriminator accuracy 0.5234', 'Total loss: 1.5025', 'for batch', 3)
('GAN loss 0.7393 ', 'GAN acc 0.4922', 'Discriminator loss 0.7499', 'Discriminator accuracy 0.5293', 'Total loss: 1.4891', 'for batch', 4)
('GAN loss 0.8233 ', 'GAN acc 0.4219', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5723', 'Total loss: 1.5129', 'for batch', 5)
('GAN loss 0.8545 ', 'GAN acc 0.4023', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.6094', 'Total loss: 1.5479', 'for batch', 6)
('GAN loss 0.8954 ', 'GAN acc 0.3438', 'Discriminator loss 0.6829', 'Discriminator accuracy 0.6055', 'Total loss: 1.5783', 'for batch', 7)
('GAN loss 1.0068 ', 'GAN acc 0.2812', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.5918', 'Total loss: 1.7111', 'for batch', 8)
('GAN loss 1.0312 ', 'GAN acc 0.3086', 'Discriminator loss 0.6468', 'Discriminator accuracy 0.6328', 'Total loss: 1.6780', 'for batch', 9)
('GAN loss 0.9787 ', 'GAN acc 0.3047', 'Discriminator loss 0.6423', 'Discriminator accuracy 0.6289', 'Total loss: 1.6210', 'for batch', 10)
('GAN loss 1.1230 ', 'GAN acc 0.2305', 'Discriminator loss 0.6694', 'Discriminator accuracy 0.6387', 'Total loss: 1.7924', 'for batch', 11)
('GAN loss 1.2025 ', 'GAN acc 0.1953', 'Discriminator loss 0.6222', 'Discriminator accuracy 0.6660', 'Total loss: 1.8247', 'for batch', 12)
('GAN loss 1.2143 ', 'GAN acc 0.1992', 'Discriminator loss 0.6043', 'Discriminator accuracy 0.6895', 'Total loss: 1.8187', 'for batch', 13)
('GAN loss 1.2457 ', 'GAN acc 0.2227', 'Discriminator loss 0.6053', 'Discriminator accuracy 0.6738', 'Total loss: 1.8510', 'for batch', 14)
('GAN loss 1.2460 ', 'GAN acc 0.2344', 'Discriminator loss 0.6056', 'Discriminator accuracy 0.7012', 'Total loss: 1.8515', 'for batch', 15)
('GAN loss 1.2084 ', 'GAN acc 0.2539', 'Discriminator loss 0.6170', 'Discriminator accuracy 0.6680', 'Total loss: 1.8254', 'for batch', 16)
('GAN loss 1.2794 ', 'GAN acc 0.1992', 'Discriminator loss 0.6093', 'Discriminator accuracy 0.6660', 'Total loss: 1.8887', 'for batch', 17)
('GAN loss 1.2050 ', 'GAN acc 0.2227', 'Discriminator loss 0.5972', 'Discriminator accuracy 0.6836', 'Total loss: 1.8022', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.85289842)
('DISCRIMINATOR_Imagem FAKE=', 0.72105479)
('Discriminator trained', 13, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:45.738070')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.3631 ', 'GAN acc 0.1875', 'Discriminator loss 0.6266', 'Discriminator accuracy 0.6582', 'Total loss: 1.9897', 'for batch', 0)
('GAN loss 1.4109 ', 'GAN acc 0.1641', 'Discriminator loss 0.6261', 'Discriminator accuracy 0.6406', 'Total loss: 2.0371', 'for batch', 1)
('GAN loss 1.1715 ', 'GAN acc 0.2891', 'Discriminator loss 0.6329', 'Discriminator accuracy 0.5918', 'Total loss: 1.8044', 'for batch', 2)
('GAN loss 1.1673 ', 'GAN acc 0.2734', 'Discriminator loss 0.6306', 'Discriminator accuracy 0.6406', 'Total loss: 1.7979', 'for batch', 3)
('GAN loss 1.2669 ', 'GAN acc 0.2227', 'Discriminator loss 0.6364', 'Discriminator accuracy 0.6484', 'Total loss: 1.9032', 'for batch', 4)
('GAN loss 1.1762 ', 'GAN acc 0.2266', 'Discriminator loss 0.6060', 'Discriminator accuracy 0.6504', 'Total loss: 1.7821', 'for batch', 5)
('GAN loss 1.1458 ', 'GAN acc 0.2383', 'Discriminator loss 0.6362', 'Discriminator accuracy 0.6582', 'Total loss: 1.7820', 'for batch', 6)
('GAN loss 1.1832 ', 'GAN acc 0.2344', 'Discriminator loss 0.6475', 'Discriminator accuracy 0.6348', 'Total loss: 1.8307', 'for batch', 7)
('GAN loss 1.0367 ', 'GAN acc 0.2891', 'Discriminator loss 0.6231', 'Discriminator accuracy 0.6328', 'Total loss: 1.6598', 'for batch', 8)
('GAN loss 1.0603 ', 'GAN acc 0.2734', 'Discriminator loss 0.6438', 'Discriminator accuracy 0.6211', 'Total loss: 1.7041', 'for batch', 9)
('GAN loss 1.0469 ', 'GAN acc 0.2773', 'Discriminator loss 0.6389', 'Discriminator accuracy 0.6230', 'Total loss: 1.6858', 'for batch', 10)
('GAN loss 0.9532 ', 'GAN acc 0.3828', 'Discriminator loss 0.6616', 'Discriminator accuracy 0.6055', 'Total loss: 1.6148', 'for batch', 11)
('GAN loss 0.8034 ', 'GAN acc 0.4688', 'Discriminator loss 0.6443', 'Discriminator accuracy 0.6133', 'Total loss: 1.4477', 'for batch', 12)
('GAN loss 0.7527 ', 'GAN acc 0.5039', 'Discriminator loss 0.6652', 'Discriminator accuracy 0.6074', 'Total loss: 1.4179', 'for batch', 13)
('GAN loss 0.8212 ', 'GAN acc 0.4414', 'Discriminator loss 0.6641', 'Discriminator accuracy 0.6016', 'Total loss: 1.4853', 'for batch', 14)
('GAN loss 0.8098 ', 'GAN acc 0.4688', 'Discriminator loss 0.6373', 'Discriminator accuracy 0.6465', 'Total loss: 1.4471', 'for batch', 15)
('GAN loss 0.7217 ', 'GAN acc 0.5469', 'Discriminator loss 0.6847', 'Discriminator accuracy 0.5566', 'Total loss: 1.4064', 'for batch', 16)
('GAN loss 0.7022 ', 'GAN acc 0.5781', 'Discriminator loss 0.6493', 'Discriminator accuracy 0.5996', 'Total loss: 1.3515', 'for batch', 17)
('GAN loss 0.7530 ', 'GAN acc 0.5625', 'Discriminator loss 0.6596', 'Discriminator accuracy 0.6172', 'Total loss: 1.4126', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.88137794)
('DISCRIMINATOR_Imagem FAKE=', 0.76800877)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.656152')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7544 ', 'GAN acc 0.4766', 'Discriminator loss 0.6638', 'Discriminator accuracy 0.5703', 'Total loss: 1.4182', 'for batch', 0)
('GAN loss 0.7216 ', 'GAN acc 0.5430', 'Discriminator loss 0.6622', 'Discriminator accuracy 0.6113', 'Total loss: 1.3838', 'for batch', 1)
('GAN loss 0.7428 ', 'GAN acc 0.5547', 'Discriminator loss 0.6575', 'Discriminator accuracy 0.5977', 'Total loss: 1.4003', 'for batch', 2)
('GAN loss 0.7231 ', 'GAN acc 0.5703', 'Discriminator loss 0.6625', 'Discriminator accuracy 0.6191', 'Total loss: 1.3856', 'for batch', 3)
('GAN loss 0.7461 ', 'GAN acc 0.5312', 'Discriminator loss 0.6678', 'Discriminator accuracy 0.5957', 'Total loss: 1.4139', 'for batch', 4)
('GAN loss 0.7237 ', 'GAN acc 0.5508', 'Discriminator loss 0.6476', 'Discriminator accuracy 0.6230', 'Total loss: 1.3713', 'for batch', 5)
('GAN loss 0.7104 ', 'GAN acc 0.5820', 'Discriminator loss 0.6495', 'Discriminator accuracy 0.5977', 'Total loss: 1.3600', 'for batch', 6)
('GAN loss 0.6916 ', 'GAN acc 0.6133', 'Discriminator loss 0.6492', 'Discriminator accuracy 0.5957', 'Total loss: 1.3408', 'for batch', 7)
('GAN loss 0.7096 ', 'GAN acc 0.5859', 'Discriminator loss 0.6535', 'Discriminator accuracy 0.6035', 'Total loss: 1.3631', 'for batch', 8)
('GAN loss 0.7377 ', 'GAN acc 0.5273', 'Discriminator loss 0.6316', 'Discriminator accuracy 0.6387', 'Total loss: 1.3693', 'for batch', 9)
('GAN loss 0.7190 ', 'GAN acc 0.5703', 'Discriminator loss 0.6453', 'Discriminator accuracy 0.6113', 'Total loss: 1.3643', 'for batch', 10)
('GAN loss 0.7244 ', 'GAN acc 0.5664', 'Discriminator loss 0.6509', 'Discriminator accuracy 0.5898', 'Total loss: 1.3753', 'for batch', 11)
('GAN loss 0.7965 ', 'GAN acc 0.5039', 'Discriminator loss 0.6783', 'Discriminator accuracy 0.5762', 'Total loss: 1.4747', 'for batch', 12)
('GAN loss 0.7929 ', 'GAN acc 0.4883', 'Discriminator loss 0.6652', 'Discriminator accuracy 0.5898', 'Total loss: 1.4581', 'for batch', 13)
('GAN loss 0.7279 ', 'GAN acc 0.5938', 'Discriminator loss 0.6653', 'Discriminator accuracy 0.5586', 'Total loss: 1.3932', 'for batch', 14)
('GAN loss 0.6754 ', 'GAN acc 0.6641', 'Discriminator loss 0.6681', 'Discriminator accuracy 0.5879', 'Total loss: 1.3435', 'for batch', 15)
('GAN loss 0.7181 ', 'GAN acc 0.5703', 'Discriminator loss 0.6717', 'Discriminator accuracy 0.5547', 'Total loss: 1.3898', 'for batch', 16)
('GAN loss 0.7451 ', 'GAN acc 0.5312', 'Discriminator loss 0.6719', 'Discriminator accuracy 0.5684', 'Total loss: 1.4170', 'for batch', 17)
('GAN loss 0.7264 ', 'GAN acc 0.5742', 'Discriminator loss 0.6587', 'Discriminator accuracy 0.5859', 'Total loss: 1.3851', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.85562807)
('DISCRIMINATOR_Imagem FAKE=', 0.76243699)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.234821')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7657 ', 'GAN acc 0.4805', 'Discriminator loss 0.6599', 'Discriminator accuracy 0.5820', 'Total loss: 1.4257', 'for batch', 0)
('GAN loss 0.7810 ', 'GAN acc 0.5000', 'Discriminator loss 0.6637', 'Discriminator accuracy 0.5840', 'Total loss: 1.4447', 'for batch', 1)
('GAN loss 0.7756 ', 'GAN acc 0.5742', 'Discriminator loss 0.6511', 'Discriminator accuracy 0.6035', 'Total loss: 1.4268', 'for batch', 2)
('GAN loss 0.7705 ', 'GAN acc 0.5234', 'Discriminator loss 0.6425', 'Discriminator accuracy 0.6074', 'Total loss: 1.4130', 'for batch', 3)
('GAN loss 0.7891 ', 'GAN acc 0.5078', 'Discriminator loss 0.6696', 'Discriminator accuracy 0.5723', 'Total loss: 1.4587', 'for batch', 4)
('GAN loss 0.7717 ', 'GAN acc 0.5273', 'Discriminator loss 0.6603', 'Discriminator accuracy 0.5840', 'Total loss: 1.4320', 'for batch', 5)
('GAN loss 0.7570 ', 'GAN acc 0.5000', 'Discriminator loss 0.6618', 'Discriminator accuracy 0.5801', 'Total loss: 1.4188', 'for batch', 6)
('GAN loss 0.7561 ', 'GAN acc 0.5117', 'Discriminator loss 0.6796', 'Discriminator accuracy 0.5566', 'Total loss: 1.4358', 'for batch', 7)
('GAN loss 0.7901 ', 'GAN acc 0.5352', 'Discriminator loss 0.6666', 'Discriminator accuracy 0.5977', 'Total loss: 1.4567', 'for batch', 8)
('GAN loss 0.7856 ', 'GAN acc 0.4961', 'Discriminator loss 0.6644', 'Discriminator accuracy 0.5781', 'Total loss: 1.4500', 'for batch', 9)
('GAN loss 0.7573 ', 'GAN acc 0.5781', 'Discriminator loss 0.6684', 'Discriminator accuracy 0.5664', 'Total loss: 1.4257', 'for batch', 10)
('GAN loss 0.7678 ', 'GAN acc 0.5352', 'Discriminator loss 0.6590', 'Discriminator accuracy 0.6055', 'Total loss: 1.4268', 'for batch', 11)
('GAN loss 0.7616 ', 'GAN acc 0.5234', 'Discriminator loss 0.6768', 'Discriminator accuracy 0.5508', 'Total loss: 1.4384', 'for batch', 12)
('GAN loss 0.7843 ', 'GAN acc 0.4570', 'Discriminator loss 0.6807', 'Discriminator accuracy 0.5508', 'Total loss: 1.4650', 'for batch', 13)
('GAN loss 0.8084 ', 'GAN acc 0.4727', 'Discriminator loss 0.6757', 'Discriminator accuracy 0.5547', 'Total loss: 1.4841', 'for batch', 14)
('GAN loss 0.8032 ', 'GAN acc 0.4961', 'Discriminator loss 0.6540', 'Discriminator accuracy 0.6035', 'Total loss: 1.4572', 'for batch', 15)
('GAN loss 0.7447 ', 'GAN acc 0.5078', 'Discriminator loss 0.6824', 'Discriminator accuracy 0.5645', 'Total loss: 1.4272', 'for batch', 16)
('GAN loss 0.7677 ', 'GAN acc 0.5000', 'Discriminator loss 0.6802', 'Discriminator accuracy 0.5625', 'Total loss: 1.4478', 'for batch', 17)
('GAN loss 0.7710 ', 'GAN acc 0.5078', 'Discriminator loss 0.6877', 'Discriminator accuracy 0.5508', 'Total loss: 1.4587', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.7971428)
('DISCRIMINATOR_Imagem FAKE=', 0.76174986)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.702232')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7966 ', 'GAN acc 0.5234', 'Discriminator loss 0.6809', 'Discriminator accuracy 0.5527', 'Total loss: 1.4775', 'for batch', 0)
('GAN loss 0.7593 ', 'GAN acc 0.4531', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5078', 'Total loss: 1.4521', 'for batch', 1)
('GAN loss 0.8552 ', 'GAN acc 0.3906', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.5176', 'Total loss: 1.5573', 'for batch', 2)
('GAN loss 0.8092 ', 'GAN acc 0.4258', 'Discriminator loss 0.6878', 'Discriminator accuracy 0.5371', 'Total loss: 1.4970', 'for batch', 3)
('GAN loss 0.7975 ', 'GAN acc 0.4023', 'Discriminator loss 0.7164', 'Discriminator accuracy 0.4824', 'Total loss: 1.5140', 'for batch', 4)
('GAN loss 0.7575 ', 'GAN acc 0.4336', 'Discriminator loss 0.7172', 'Discriminator accuracy 0.5098', 'Total loss: 1.4747', 'for batch', 5)
('GAN loss 0.7331 ', 'GAN acc 0.4609', 'Discriminator loss 0.7074', 'Discriminator accuracy 0.5293', 'Total loss: 1.4405', 'for batch', 6)
('GAN loss 0.7879 ', 'GAN acc 0.4180', 'Discriminator loss 0.7062', 'Discriminator accuracy 0.5215', 'Total loss: 1.4941', 'for batch', 7)
('GAN loss 0.8107 ', 'GAN acc 0.4023', 'Discriminator loss 0.7126', 'Discriminator accuracy 0.5020', 'Total loss: 1.5233', 'for batch', 8)
('GAN loss 0.8081 ', 'GAN acc 0.3320', 'Discriminator loss 0.7224', 'Discriminator accuracy 0.4902', 'Total loss: 1.5306', 'for batch', 9)
('GAN loss 0.8018 ', 'GAN acc 0.3672', 'Discriminator loss 0.7160', 'Discriminator accuracy 0.4590', 'Total loss: 1.5177', 'for batch', 10)
('GAN loss 0.7941 ', 'GAN acc 0.3906', 'Discriminator loss 0.7132', 'Discriminator accuracy 0.4824', 'Total loss: 1.5072', 'for batch', 11)
('GAN loss 0.8325 ', 'GAN acc 0.3086', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5410', 'Total loss: 1.5284', 'for batch', 12)
('GAN loss 0.8201 ', 'GAN acc 0.3633', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.5254', 'Total loss: 1.5217', 'for batch', 13)
('GAN loss 0.8383 ', 'GAN acc 0.3125', 'Discriminator loss 0.7167', 'Discriminator accuracy 0.4883', 'Total loss: 1.5550', 'for batch', 14)
('GAN loss 0.8061 ', 'GAN acc 0.3047', 'Discriminator loss 0.7304', 'Discriminator accuracy 0.4707', 'Total loss: 1.5365', 'for batch', 15)
('GAN loss 0.8053 ', 'GAN acc 0.3281', 'Discriminator loss 0.7088', 'Discriminator accuracy 0.4961', 'Total loss: 1.5141', 'for batch', 16)
('GAN loss 0.8008 ', 'GAN acc 0.3359', 'Discriminator loss 0.7225', 'Discriminator accuracy 0.4570', 'Total loss: 1.5233', 'for batch', 17)
('GAN loss 0.8216 ', 'GAN acc 0.2773', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4922', 'Total loss: 1.5254', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.68433827)
('DISCRIMINATOR_Imagem FAKE=', 0.71457046)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.359853')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7882 ', 'GAN acc 0.3516', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.5371', 'Total loss: 1.4882', 'for batch', 0)
('GAN loss 0.7730 ', 'GAN acc 0.3945', 'Discriminator loss 0.7143', 'Discriminator accuracy 0.5078', 'Total loss: 1.4873', 'for batch', 1)
('GAN loss 0.8095 ', 'GAN acc 0.3086', 'Discriminator loss 0.7084', 'Discriminator accuracy 0.5000', 'Total loss: 1.5179', 'for batch', 2)
('GAN loss 0.8033 ', 'GAN acc 0.3125', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.5254', 'Total loss: 1.5007', 'for batch', 3)
('GAN loss 0.7992 ', 'GAN acc 0.3203', 'Discriminator loss 0.7268', 'Discriminator accuracy 0.4434', 'Total loss: 1.5261', 'for batch', 4)
('GAN loss 0.7713 ', 'GAN acc 0.3789', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5195', 'Total loss: 1.4693', 'for batch', 5)
('GAN loss 0.7345 ', 'GAN acc 0.4219', 'Discriminator loss 0.7079', 'Discriminator accuracy 0.4941', 'Total loss: 1.4424', 'for batch', 6)
('GAN loss 0.7729 ', 'GAN acc 0.3359', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.5098', 'Total loss: 1.4756', 'for batch', 7)
('GAN loss 0.7634 ', 'GAN acc 0.3555', 'Discriminator loss 0.7125', 'Discriminator accuracy 0.4629', 'Total loss: 1.4759', 'for batch', 8)
('GAN loss 0.7523 ', 'GAN acc 0.3633', 'Discriminator loss 0.7054', 'Discriminator accuracy 0.5059', 'Total loss: 1.4577', 'for batch', 9)
('GAN loss 0.7587 ', 'GAN acc 0.3477', 'Discriminator loss 0.7134', 'Discriminator accuracy 0.4844', 'Total loss: 1.4721', 'for batch', 10)
('GAN loss 0.7517 ', 'GAN acc 0.4258', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5410', 'Total loss: 1.4499', 'for batch', 11)
('GAN loss 0.7403 ', 'GAN acc 0.4141', 'Discriminator loss 0.7121', 'Discriminator accuracy 0.4766', 'Total loss: 1.4524', 'for batch', 12)
('GAN loss 0.7327 ', 'GAN acc 0.4336', 'Discriminator loss 0.7031', 'Discriminator accuracy 0.4844', 'Total loss: 1.4358', 'for batch', 13)
('GAN loss 0.7419 ', 'GAN acc 0.4492', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.5273', 'Total loss: 1.4419', 'for batch', 14)
('GAN loss 0.7251 ', 'GAN acc 0.4844', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5176', 'Total loss: 1.4195', 'for batch', 15)
('GAN loss 0.7375 ', 'GAN acc 0.4023', 'Discriminator loss 0.7050', 'Discriminator accuracy 0.4727', 'Total loss: 1.4425', 'for batch', 16)
('GAN loss 0.7386 ', 'GAN acc 0.4023', 'Discriminator loss 0.7066', 'Discriminator accuracy 0.4922', 'Total loss: 1.4452', 'for batch', 17)
('GAN loss 0.7331 ', 'GAN acc 0.4219', 'Discriminator loss 0.7105', 'Discriminator accuracy 0.5078', 'Total loss: 1.4436', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.64273572)
('DISCRIMINATOR_Imagem FAKE=', 0.64830875)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.846448')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7025 ', 'GAN acc 0.5195', 'Discriminator loss 0.7143', 'Discriminator accuracy 0.4766', 'Total loss: 1.4168', 'for batch', 0)
('GAN loss 0.7058 ', 'GAN acc 0.4844', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.4707', 'Total loss: 1.4101', 'for batch', 1)
('GAN loss 0.7034 ', 'GAN acc 0.4766', 'Discriminator loss 0.7154', 'Discriminator accuracy 0.4570', 'Total loss: 1.4188', 'for batch', 2)
('GAN loss 0.7234 ', 'GAN acc 0.4531', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.5000', 'Total loss: 1.4238', 'for batch', 3)
('GAN loss 0.7299 ', 'GAN acc 0.4141', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5312', 'Total loss: 1.4215', 'for batch', 4)
('GAN loss 0.7404 ', 'GAN acc 0.3789', 'Discriminator loss 0.7054', 'Discriminator accuracy 0.4844', 'Total loss: 1.4459', 'for batch', 5)
('GAN loss 0.7119 ', 'GAN acc 0.5078', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.4883', 'Total loss: 1.4161', 'for batch', 6)
('GAN loss 0.7077 ', 'GAN acc 0.4609', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.5195', 'Total loss: 1.4134', 'for batch', 7)
('GAN loss 0.6987 ', 'GAN acc 0.5117', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.5020', 'Total loss: 1.3961', 'for batch', 8)
('GAN loss 0.6965 ', 'GAN acc 0.5352', 'Discriminator loss 0.7049', 'Discriminator accuracy 0.4844', 'Total loss: 1.4015', 'for batch', 9)
('GAN loss 0.7010 ', 'GAN acc 0.5000', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.5000', 'Total loss: 1.4023', 'for batch', 10)
('GAN loss 0.7029 ', 'GAN acc 0.4961', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4980', 'Total loss: 1.4062', 'for batch', 11)
('GAN loss 0.7180 ', 'GAN acc 0.4414', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5156', 'Total loss: 1.4132', 'for batch', 12)
('GAN loss 0.7344 ', 'GAN acc 0.3867', 'Discriminator loss 0.7040', 'Discriminator accuracy 0.4785', 'Total loss: 1.4384', 'for batch', 13)
('GAN loss 0.7300 ', 'GAN acc 0.3945', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.5000', 'Total loss: 1.4339', 'for batch', 14)
('GAN loss 0.6974 ', 'GAN acc 0.5117', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5039', 'Total loss: 1.3984', 'for batch', 15)
('GAN loss 0.7101 ', 'GAN acc 0.4766', 'Discriminator loss 0.7060', 'Discriminator accuracy 0.4766', 'Total loss: 1.4162', 'for batch', 16)
('GAN loss 0.6950 ', 'GAN acc 0.5273', 'Discriminator loss 0.7056', 'Discriminator accuracy 0.4961', 'Total loss: 1.4005', 'for batch', 17)
('GAN loss 0.7090 ', 'GAN acc 0.4844', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.5039', 'Total loss: 1.4093', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.61842519)
('DISCRIMINATOR_Imagem FAKE=', 0.62051493)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.516905')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7005 ', 'GAN acc 0.5430', 'Discriminator loss 0.7053', 'Discriminator accuracy 0.4766', 'Total loss: 1.4058', 'for batch', 0)
('GAN loss 0.6880 ', 'GAN acc 0.5586', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5098', 'Total loss: 1.3856', 'for batch', 1)
('GAN loss 0.7069 ', 'GAN acc 0.4844', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4863', 'Total loss: 1.4068', 'for batch', 2)
('GAN loss 0.7119 ', 'GAN acc 0.5039', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.5059', 'Total loss: 1.4121', 'for batch', 3)
('GAN loss 0.7053 ', 'GAN acc 0.4883', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4883', 'Total loss: 1.4075', 'for batch', 4)
('GAN loss 0.7092 ', 'GAN acc 0.4805', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.5117', 'Total loss: 1.4078', 'for batch', 5)
('GAN loss 0.6937 ', 'GAN acc 0.5430', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4922', 'Total loss: 1.3930', 'for batch', 6)
('GAN loss 0.6978 ', 'GAN acc 0.4805', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4902', 'Total loss: 1.3951', 'for batch', 7)
('GAN loss 0.6847 ', 'GAN acc 0.5664', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4844', 'Total loss: 1.3849', 'for batch', 8)
('GAN loss 0.6845 ', 'GAN acc 0.5547', 'Discriminator loss 0.7084', 'Discriminator accuracy 0.4746', 'Total loss: 1.3929', 'for batch', 9)
('GAN loss 0.7020 ', 'GAN acc 0.4883', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5176', 'Total loss: 1.3971', 'for batch', 10)
('GAN loss 0.6881 ', 'GAN acc 0.5742', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.5078', 'Total loss: 1.3880', 'for batch', 11)
('GAN loss 0.7030 ', 'GAN acc 0.4922', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5137', 'Total loss: 1.3972', 'for batch', 12)
('GAN loss 0.6961 ', 'GAN acc 0.5117', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.5215', 'Total loss: 1.3933', 'for batch', 13)
('GAN loss 0.7106 ', 'GAN acc 0.4648', 'Discriminator loss 0.7084', 'Discriminator accuracy 0.4785', 'Total loss: 1.4190', 'for batch', 14)
('GAN loss 0.6985 ', 'GAN acc 0.4766', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5039', 'Total loss: 1.3956', 'for batch', 15)
('GAN loss 0.6955 ', 'GAN acc 0.5195', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.4863', 'Total loss: 1.3993', 'for batch', 16)
('GAN loss 0.6935 ', 'GAN acc 0.5156', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4922', 'Total loss: 1.3897', 'for batch', 17)
('GAN loss 0.7080 ', 'GAN acc 0.5391', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4863', 'Total loss: 1.4052', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.59275502)
('DISCRIMINATOR_Imagem FAKE=', 0.59446555)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.819294')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7038 ', 'GAN acc 0.4805', 'Discriminator loss 0.6843', 'Discriminator accuracy 0.5449', 'Total loss: 1.3882', 'for batch', 0)
('GAN loss 0.7108 ', 'GAN acc 0.4531', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5234', 'Total loss: 1.4092', 'for batch', 1)
('GAN loss 0.7073 ', 'GAN acc 0.4922', 'Discriminator loss 0.7084', 'Discriminator accuracy 0.4453', 'Total loss: 1.4157', 'for batch', 2)
('GAN loss 0.7141 ', 'GAN acc 0.4297', 'Discriminator loss 0.7030', 'Discriminator accuracy 0.4844', 'Total loss: 1.4171', 'for batch', 3)
('GAN loss 0.7069 ', 'GAN acc 0.4609', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4902', 'Total loss: 1.4079', 'for batch', 4)
('GAN loss 0.6939 ', 'GAN acc 0.4961', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5273', 'Total loss: 1.3875', 'for batch', 5)
('GAN loss 0.6916 ', 'GAN acc 0.5234', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.5137', 'Total loss: 1.3932', 'for batch', 6)
('GAN loss 0.6797 ', 'GAN acc 0.5977', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4707', 'Total loss: 1.3804', 'for batch', 7)
('GAN loss 0.6877 ', 'GAN acc 0.5312', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5078', 'Total loss: 1.3830', 'for batch', 8)
('GAN loss 0.6853 ', 'GAN acc 0.5898', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4883', 'Total loss: 1.3868', 'for batch', 9)
('GAN loss 0.6929 ', 'GAN acc 0.5195', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5312', 'Total loss: 1.3883', 'for batch', 10)
('GAN loss 0.6887 ', 'GAN acc 0.5352', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4883', 'Total loss: 1.3891', 'for batch', 11)
('GAN loss 0.7070 ', 'GAN acc 0.4531', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4922', 'Total loss: 1.4074', 'for batch', 12)
('GAN loss 0.7018 ', 'GAN acc 0.5000', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4980', 'Total loss: 1.4041', 'for batch', 13)
('GAN loss 0.7033 ', 'GAN acc 0.4648', 'Discriminator loss 0.7063', 'Discriminator accuracy 0.4805', 'Total loss: 1.4096', 'for batch', 14)
('GAN loss 0.7051 ', 'GAN acc 0.4688', 'Discriminator loss 0.7100', 'Discriminator accuracy 0.4648', 'Total loss: 1.4150', 'for batch', 15)
('GAN loss 0.7055 ', 'GAN acc 0.4531', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4980', 'Total loss: 1.4065', 'for batch', 16)
('GAN loss 0.6972 ', 'GAN acc 0.4922', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5039', 'Total loss: 1.3934', 'for batch', 17)
('GAN loss 0.6895 ', 'GAN acc 0.5391', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4766', 'Total loss: 1.3917', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58282769)
('DISCRIMINATOR_Imagem FAKE=', 0.58224642)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.380374')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6990 ', 'GAN acc 0.5078', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.5020', 'Total loss: 1.3988', 'for batch', 0)
('GAN loss 0.6866 ', 'GAN acc 0.5430', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4824', 'Total loss: 1.3885', 'for batch', 1)
('GAN loss 0.6882 ', 'GAN acc 0.5430', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5000', 'Total loss: 1.3875', 'for batch', 2)
('GAN loss 0.7030 ', 'GAN acc 0.5000', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.5039', 'Total loss: 1.4015', 'for batch', 3)
('GAN loss 0.6940 ', 'GAN acc 0.5312', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.5078', 'Total loss: 1.3938', 'for batch', 4)
('GAN loss 0.6946 ', 'GAN acc 0.5156', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4941', 'Total loss: 1.3916', 'for batch', 5)
('GAN loss 0.6885 ', 'GAN acc 0.5234', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.5059', 'Total loss: 1.3877', 'for batch', 6)
('GAN loss 0.6837 ', 'GAN acc 0.5586', 'Discriminator loss 0.7030', 'Discriminator accuracy 0.4844', 'Total loss: 1.3867', 'for batch', 7)
('GAN loss 0.6841 ', 'GAN acc 0.5586', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4805', 'Total loss: 1.3849', 'for batch', 8)
('GAN loss 0.6832 ', 'GAN acc 0.5703', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4883', 'Total loss: 1.3833', 'for batch', 9)
('GAN loss 0.6987 ', 'GAN acc 0.5469', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4902', 'Total loss: 1.3969', 'for batch', 10)
('GAN loss 0.6861 ', 'GAN acc 0.5664', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5059', 'Total loss: 1.3812', 'for batch', 11)
('GAN loss 0.6882 ', 'GAN acc 0.5898', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5098', 'Total loss: 1.3817', 'for batch', 12)
('GAN loss 0.6885 ', 'GAN acc 0.5664', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5371', 'Total loss: 1.3800', 'for batch', 13)
('GAN loss 0.6908 ', 'GAN acc 0.5469', 'Discriminator loss 0.7015', 'Discriminator accuracy 0.4648', 'Total loss: 1.3923', 'for batch', 14)
('GAN loss 0.7072 ', 'GAN acc 0.4727', 'Discriminator loss 0.7052', 'Discriminator accuracy 0.4551', 'Total loss: 1.4124', 'for batch', 15)
('GAN loss 0.6931 ', 'GAN acc 0.5078', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5000', 'Total loss: 1.3891', 'for batch', 16)
('GAN loss 0.6934 ', 'GAN acc 0.5000', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4766', 'Total loss: 1.3919', 'for batch', 17)
('GAN loss 0.6873 ', 'GAN acc 0.5664', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4941', 'Total loss: 1.3848', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56951147)
('DISCRIMINATOR_Imagem FAKE=', 0.57128799)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.861864')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6959 ', 'GAN acc 0.5430', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4844', 'Total loss: 1.3963', 'for batch', 0)
('GAN loss 0.6942 ', 'GAN acc 0.5000', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5000', 'Total loss: 1.3909', 'for batch', 1)
('GAN loss 0.6953 ', 'GAN acc 0.5117', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5020', 'Total loss: 1.3923', 'for batch', 2)
('GAN loss 0.6998 ', 'GAN acc 0.5078', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4805', 'Total loss: 1.4034', 'for batch', 3)
('GAN loss 0.7102 ', 'GAN acc 0.4531', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4922', 'Total loss: 1.4069', 'for batch', 4)
('GAN loss 0.7020 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4980', 'Total loss: 1.3975', 'for batch', 5)
('GAN loss 0.7058 ', 'GAN acc 0.4805', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5039', 'Total loss: 1.4018', 'for batch', 6)
('GAN loss 0.7077 ', 'GAN acc 0.4180', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5059', 'Total loss: 1.4057', 'for batch', 7)
('GAN loss 0.7029 ', 'GAN acc 0.4727', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4902', 'Total loss: 1.4033', 'for batch', 8)
('GAN loss 0.6886 ', 'GAN acc 0.5352', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.4824', 'Total loss: 1.3903', 'for batch', 9)
('GAN loss 0.6889 ', 'GAN acc 0.5781', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5195', 'Total loss: 1.3808', 'for batch', 10)
('GAN loss 0.6763 ', 'GAN acc 0.5898', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4707', 'Total loss: 1.3770', 'for batch', 11)
('GAN loss 0.6789 ', 'GAN acc 0.5859', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5000', 'Total loss: 1.3737', 'for batch', 12)
('GAN loss 0.6834 ', 'GAN acc 0.5391', 'Discriminator loss 0.6872', 'Discriminator accuracy 0.5449', 'Total loss: 1.3706', 'for batch', 13)
('GAN loss 0.7019 ', 'GAN acc 0.5156', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4922', 'Total loss: 1.3978', 'for batch', 14)
('GAN loss 0.6770 ', 'GAN acc 0.5977', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4863', 'Total loss: 1.3778', 'for batch', 15)
('GAN loss 0.6956 ', 'GAN acc 0.5234', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4922', 'Total loss: 1.3951', 'for batch', 16)
('GAN loss 0.6911 ', 'GAN acc 0.5547', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4727', 'Total loss: 1.3922', 'for batch', 17)
('GAN loss 0.6975 ', 'GAN acc 0.5312', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5195', 'Total loss: 1.3942', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.55865777)
('DISCRIMINATOR_Imagem FAKE=', 0.5596841)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.888181')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6898 ', 'GAN acc 0.5039', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5059', 'Total loss: 1.3908', 'for batch', 0)
('GAN loss 0.6942 ', 'GAN acc 0.5234', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4961', 'Total loss: 1.3894', 'for batch', 1)
('GAN loss 0.6906 ', 'GAN acc 0.5312', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4785', 'Total loss: 1.3861', 'for batch', 2)
('GAN loss 0.6878 ', 'GAN acc 0.5156', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4727', 'Total loss: 1.3914', 'for batch', 3)
('GAN loss 0.7038 ', 'GAN acc 0.5078', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4961', 'Total loss: 1.4039', 'for batch', 4)
('GAN loss 0.6976 ', 'GAN acc 0.5156', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4766', 'Total loss: 1.3934', 'for batch', 5)
('GAN loss 0.7028 ', 'GAN acc 0.4844', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5000', 'Total loss: 1.3992', 'for batch', 6)
('GAN loss 0.6999 ', 'GAN acc 0.5000', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4941', 'Total loss: 1.3947', 'for batch', 7)
('GAN loss 0.6976 ', 'GAN acc 0.4766', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4824', 'Total loss: 1.3986', 'for batch', 8)
('GAN loss 0.6950 ', 'GAN acc 0.5195', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5195', 'Total loss: 1.3875', 'for batch', 9)
('GAN loss 0.6949 ', 'GAN acc 0.4883', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.4824', 'Total loss: 1.3944', 'for batch', 10)
('GAN loss 0.6888 ', 'GAN acc 0.5391', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5039', 'Total loss: 1.3845', 'for batch', 11)
('GAN loss 0.6831 ', 'GAN acc 0.5898', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5195', 'Total loss: 1.3770', 'for batch', 12)
('GAN loss 0.6888 ', 'GAN acc 0.5586', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.4785', 'Total loss: 1.3910', 'for batch', 13)
('GAN loss 0.7005 ', 'GAN acc 0.5078', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5098', 'Total loss: 1.3953', 'for batch', 14)
('GAN loss 0.7034 ', 'GAN acc 0.4922', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4941', 'Total loss: 1.4018', 'for batch', 15)
('GAN loss 0.6939 ', 'GAN acc 0.5547', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4688', 'Total loss: 1.3970', 'for batch', 16)
('GAN loss 0.6901 ', 'GAN acc 0.5312', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.5137', 'Total loss: 1.3877', 'for batch', 17)
('GAN loss 0.6890 ', 'GAN acc 0.5703', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5039', 'Total loss: 1.3850', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54737306)
('DISCRIMINATOR_Imagem FAKE=', 0.54770994)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.425556')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6957 ', 'GAN acc 0.4883', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4648', 'Total loss: 1.3962', 'for batch', 0)
('GAN loss 0.6922 ', 'GAN acc 0.4961', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4805', 'Total loss: 1.3908', 'for batch', 1)
('GAN loss 0.6933 ', 'GAN acc 0.5273', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5156', 'Total loss: 1.3832', 'for batch', 2)
('GAN loss 0.6834 ', 'GAN acc 0.5469', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5059', 'Total loss: 1.3793', 'for batch', 3)
('GAN loss 0.6920 ', 'GAN acc 0.5312', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4922', 'Total loss: 1.3902', 'for batch', 4)
('GAN loss 0.6955 ', 'GAN acc 0.5039', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4980', 'Total loss: 1.3904', 'for batch', 5)
('GAN loss 0.6886 ', 'GAN acc 0.5625', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5195', 'Total loss: 1.3829', 'for batch', 6)
('GAN loss 0.6900 ', 'GAN acc 0.5273', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5156', 'Total loss: 1.3839', 'for batch', 7)
('GAN loss 0.6874 ', 'GAN acc 0.5586', 'Discriminator loss 0.6875', 'Discriminator accuracy 0.5625', 'Total loss: 1.3749', 'for batch', 8)
('GAN loss 0.6911 ', 'GAN acc 0.5312', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4902', 'Total loss: 1.3879', 'for batch', 9)
('GAN loss 0.6819 ', 'GAN acc 0.5898', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4941', 'Total loss: 1.3777', 'for batch', 10)
('GAN loss 0.6863 ', 'GAN acc 0.5586', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5000', 'Total loss: 1.3832', 'for batch', 11)
('GAN loss 0.6877 ', 'GAN acc 0.5703', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4746', 'Total loss: 1.3817', 'for batch', 12)
('GAN loss 0.6867 ', 'GAN acc 0.5430', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4922', 'Total loss: 1.3817', 'for batch', 13)
('GAN loss 0.6867 ', 'GAN acc 0.5547', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5156', 'Total loss: 1.3836', 'for batch', 14)
('GAN loss 0.6894 ', 'GAN acc 0.5469', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5020', 'Total loss: 1.3849', 'for batch', 15)
('GAN loss 0.6929 ', 'GAN acc 0.4961', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4863', 'Total loss: 1.3919', 'for batch', 16)
('GAN loss 0.6967 ', 'GAN acc 0.4922', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4980', 'Total loss: 1.3925', 'for batch', 17)
('GAN loss 0.7004 ', 'GAN acc 0.5000', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5137', 'Total loss: 1.3947', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54551244)
('DISCRIMINATOR_Imagem FAKE=', 0.54589939)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.836934')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5273', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5215', 'Total loss: 1.3918', 'for batch', 0)
('GAN loss 0.6950 ', 'GAN acc 0.5234', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5195', 'Total loss: 1.3870', 'for batch', 1)
('GAN loss 0.7053 ', 'GAN acc 0.4102', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4883', 'Total loss: 1.4034', 'for batch', 2)
('GAN loss 0.6953 ', 'GAN acc 0.5117', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5039', 'Total loss: 1.3928', 'for batch', 3)
('GAN loss 0.6948 ', 'GAN acc 0.5156', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4863', 'Total loss: 1.3935', 'for batch', 4)
('GAN loss 0.6968 ', 'GAN acc 0.4648', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4922', 'Total loss: 1.3926', 'for batch', 5)
('GAN loss 0.6910 ', 'GAN acc 0.5586', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5312', 'Total loss: 1.3837', 'for batch', 6)
('GAN loss 0.6905 ', 'GAN acc 0.5156', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5000', 'Total loss: 1.3862', 'for batch', 7)
('GAN loss 0.6867 ', 'GAN acc 0.5273', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5059', 'Total loss: 1.3843', 'for batch', 8)
('GAN loss 0.6860 ', 'GAN acc 0.5078', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4688', 'Total loss: 1.3891', 'for batch', 9)
('GAN loss 0.6830 ', 'GAN acc 0.5938', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4688', 'Total loss: 1.3812', 'for batch', 10)
('GAN loss 0.6853 ', 'GAN acc 0.5820', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3801', 'for batch', 11)
('GAN loss 0.6958 ', 'GAN acc 0.5000', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4883', 'Total loss: 1.3903', 'for batch', 12)
('GAN loss 0.6969 ', 'GAN acc 0.5039', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4980', 'Total loss: 1.3946', 'for batch', 13)
('GAN loss 0.6923 ', 'GAN acc 0.5039', 'Discriminator loss 0.7042', 'Discriminator accuracy 0.4434', 'Total loss: 1.3965', 'for batch', 14)
('GAN loss 0.6820 ', 'GAN acc 0.5898', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5020', 'Total loss: 1.3744', 'for batch', 15)
('GAN loss 0.6934 ', 'GAN acc 0.5273', 'Discriminator loss 0.7014', 'Discriminator accuracy 0.4688', 'Total loss: 1.3948', 'for batch', 16)
('GAN loss 0.7028 ', 'GAN acc 0.4727', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5293', 'Total loss: 1.3945', 'for batch', 17)
('GAN loss 0.6962 ', 'GAN acc 0.4766', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4551', 'Total loss: 1.3959', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53872621)
('DISCRIMINATOR_Imagem FAKE=', 0.53918236)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.378203')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6969 ', 'GAN acc 0.5195', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5020', 'Total loss: 1.3930', 'for batch', 0)
('GAN loss 0.6999 ', 'GAN acc 0.4844', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5020', 'Total loss: 1.3958', 'for batch', 1)
('GAN loss 0.7049 ', 'GAN acc 0.4688', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5332', 'Total loss: 1.3974', 'for batch', 2)
('GAN loss 0.6917 ', 'GAN acc 0.5273', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4727', 'Total loss: 1.3925', 'for batch', 3)
('GAN loss 0.6965 ', 'GAN acc 0.5039', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4824', 'Total loss: 1.3952', 'for batch', 4)
('GAN loss 0.7012 ', 'GAN acc 0.4922', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5273', 'Total loss: 1.3923', 'for batch', 5)
('GAN loss 0.6991 ', 'GAN acc 0.4688', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5234', 'Total loss: 1.3910', 'for batch', 6)
('GAN loss 0.6900 ', 'GAN acc 0.5586', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4531', 'Total loss: 1.3906', 'for batch', 7)
('GAN loss 0.6901 ', 'GAN acc 0.5664', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5020', 'Total loss: 1.3859', 'for batch', 8)
('GAN loss 0.6894 ', 'GAN acc 0.5039', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5059', 'Total loss: 1.3839', 'for batch', 9)
('GAN loss 0.6941 ', 'GAN acc 0.5352', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5039', 'Total loss: 1.3868', 'for batch', 10)
('GAN loss 0.6815 ', 'GAN acc 0.6133', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3756', 'for batch', 11)
('GAN loss 0.6852 ', 'GAN acc 0.5508', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4902', 'Total loss: 1.3812', 'for batch', 12)
('GAN loss 0.6824 ', 'GAN acc 0.5938', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5059', 'Total loss: 1.3779', 'for batch', 13)
('GAN loss 0.6853 ', 'GAN acc 0.5859', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4941', 'Total loss: 1.3815', 'for batch', 14)
('GAN loss 0.6949 ', 'GAN acc 0.5078', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4961', 'Total loss: 1.3921', 'for batch', 15)
('GAN loss 0.7047 ', 'GAN acc 0.4492', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5254', 'Total loss: 1.3964', 'for batch', 16)
('GAN loss 0.6965 ', 'GAN acc 0.5078', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4824', 'Total loss: 1.3939', 'for batch', 17)
('GAN loss 0.6901 ', 'GAN acc 0.5312', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5195', 'Total loss: 1.3873', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53639978)
('DISCRIMINATOR_Imagem FAKE=', 0.53711492)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.825937')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6964 ', 'GAN acc 0.5312', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5059', 'Total loss: 1.3927', 'for batch', 0)
('GAN loss 0.6960 ', 'GAN acc 0.4961', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4980', 'Total loss: 1.3910', 'for batch', 1)
('GAN loss 0.6989 ', 'GAN acc 0.4844', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4551', 'Total loss: 1.3966', 'for batch', 2)
('GAN loss 0.7001 ', 'GAN acc 0.4844', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5195', 'Total loss: 1.3945', 'for batch', 3)
('GAN loss 0.6951 ', 'GAN acc 0.4883', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4746', 'Total loss: 1.3943', 'for batch', 4)
('GAN loss 0.7028 ', 'GAN acc 0.4648', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4355', 'Total loss: 1.4046', 'for batch', 5)
('GAN loss 0.6950 ', 'GAN acc 0.5078', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5156', 'Total loss: 1.3901', 'for batch', 6)
('GAN loss 0.6987 ', 'GAN acc 0.4766', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5176', 'Total loss: 1.3929', 'for batch', 7)
('GAN loss 0.6946 ', 'GAN acc 0.5391', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5078', 'Total loss: 1.3870', 'for batch', 8)
('GAN loss 0.6944 ', 'GAN acc 0.4922', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4883', 'Total loss: 1.3869', 'for batch', 9)
('GAN loss 0.6918 ', 'GAN acc 0.5586', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5156', 'Total loss: 1.3830', 'for batch', 10)
('GAN loss 0.6908 ', 'GAN acc 0.5508', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4922', 'Total loss: 1.3885', 'for batch', 11)
('GAN loss 0.6901 ', 'GAN acc 0.5273', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5117', 'Total loss: 1.3831', 'for batch', 12)
('GAN loss 0.6881 ', 'GAN acc 0.5312', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4824', 'Total loss: 1.3873', 'for batch', 13)
('GAN loss 0.6905 ', 'GAN acc 0.5273', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4609', 'Total loss: 1.3893', 'for batch', 14)
('GAN loss 0.6967 ', 'GAN acc 0.4961', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4844', 'Total loss: 1.3924', 'for batch', 15)
('GAN loss 0.6913 ', 'GAN acc 0.5469', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5020', 'Total loss: 1.3865', 'for batch', 16)
('GAN loss 0.6994 ', 'GAN acc 0.4805', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4648', 'Total loss: 1.3996', 'for batch', 17)
('GAN loss 0.6902 ', 'GAN acc 0.5312', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4961', 'Total loss: 1.3890', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53429908)
('DISCRIMINATOR_Imagem FAKE=', 0.53568453)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.398482')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6895 ', 'GAN acc 0.5352', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4883', 'Total loss: 1.3849', 'for batch', 0)
('GAN loss 0.6967 ', 'GAN acc 0.5117', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5020', 'Total loss: 1.3924', 'for batch', 1)
('GAN loss 0.6958 ', 'GAN acc 0.4688', 'Discriminator loss 0.6877', 'Discriminator accuracy 0.5488', 'Total loss: 1.3835', 'for batch', 2)
('GAN loss 0.6935 ', 'GAN acc 0.5312', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4902', 'Total loss: 1.3898', 'for batch', 3)
('GAN loss 0.6942 ', 'GAN acc 0.4961', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5078', 'Total loss: 1.3896', 'for batch', 4)
('GAN loss 0.6971 ', 'GAN acc 0.5156', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3921', 'for batch', 5)
('GAN loss 0.6966 ', 'GAN acc 0.4805', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4492', 'Total loss: 1.3966', 'for batch', 6)
('GAN loss 0.6976 ', 'GAN acc 0.4531', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4785', 'Total loss: 1.3962', 'for batch', 7)
('GAN loss 0.6921 ', 'GAN acc 0.5000', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.5098', 'Total loss: 1.3909', 'for batch', 8)
('GAN loss 0.6946 ', 'GAN acc 0.5078', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4902', 'Total loss: 1.3918', 'for batch', 9)
('GAN loss 0.6915 ', 'GAN acc 0.5039', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4883', 'Total loss: 1.3903', 'for batch', 10)
('GAN loss 0.6955 ', 'GAN acc 0.5156', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5234', 'Total loss: 1.3895', 'for batch', 11)
('GAN loss 0.6891 ', 'GAN acc 0.5234', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5176', 'Total loss: 1.3832', 'for batch', 12)
('GAN loss 0.6986 ', 'GAN acc 0.4648', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5137', 'Total loss: 1.3925', 'for batch', 13)
('GAN loss 0.6942 ', 'GAN acc 0.5039', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4980', 'Total loss: 1.3905', 'for batch', 14)
('GAN loss 0.6960 ', 'GAN acc 0.5430', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5156', 'Total loss: 1.3911', 'for batch', 15)
('GAN loss 0.6977 ', 'GAN acc 0.5039', 'Discriminator loss 0.7018', 'Discriminator accuracy 0.4629', 'Total loss: 1.3995', 'for batch', 16)
('GAN loss 0.6953 ', 'GAN acc 0.4922', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4746', 'Total loss: 1.3935', 'for batch', 17)
('GAN loss 0.6869 ', 'GAN acc 0.5469', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4746', 'Total loss: 1.3862', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53119814)
('DISCRIMINATOR_Imagem FAKE=', 0.53052932)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.847660')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6918 ', 'GAN acc 0.5352', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5254', 'Total loss: 1.3826', 'for batch', 0)
('GAN loss 0.6966 ', 'GAN acc 0.5039', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4922', 'Total loss: 1.3929', 'for batch', 1)
('GAN loss 0.6919 ', 'GAN acc 0.5156', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4824', 'Total loss: 1.3893', 'for batch', 2)
('GAN loss 0.6993 ', 'GAN acc 0.4844', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4922', 'Total loss: 1.3947', 'for batch', 3)
('GAN loss 0.6875 ', 'GAN acc 0.5273', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4922', 'Total loss: 1.3841', 'for batch', 4)
('GAN loss 0.7039 ', 'GAN acc 0.4375', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4590', 'Total loss: 1.3998', 'for batch', 5)
('GAN loss 0.6987 ', 'GAN acc 0.4375', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4844', 'Total loss: 1.3955', 'for batch', 6)
('GAN loss 0.6876 ', 'GAN acc 0.6055', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5156', 'Total loss: 1.3842', 'for batch', 7)
('GAN loss 0.6906 ', 'GAN acc 0.5156', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5156', 'Total loss: 1.3818', 'for batch', 8)
('GAN loss 0.6893 ', 'GAN acc 0.5352', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5020', 'Total loss: 1.3833', 'for batch', 9)
('GAN loss 0.6789 ', 'GAN acc 0.6211', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5117', 'Total loss: 1.3728', 'for batch', 10)
('GAN loss 0.6837 ', 'GAN acc 0.6016', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4727', 'Total loss: 1.3784', 'for batch', 11)
('GAN loss 0.6796 ', 'GAN acc 0.5977', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5215', 'Total loss: 1.3723', 'for batch', 12)
('GAN loss 0.6862 ', 'GAN acc 0.5977', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4766', 'Total loss: 1.3850', 'for batch', 13)
('GAN loss 0.6898 ', 'GAN acc 0.5273', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4922', 'Total loss: 1.3852', 'for batch', 14)
('GAN loss 0.6946 ', 'GAN acc 0.5156', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5449', 'Total loss: 1.3848', 'for batch', 15)
('GAN loss 0.6957 ', 'GAN acc 0.4922', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5059', 'Total loss: 1.3893', 'for batch', 16)
('GAN loss 0.6996 ', 'GAN acc 0.5156', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5195', 'Total loss: 1.3909', 'for batch', 17)
('GAN loss 0.6974 ', 'GAN acc 0.4844', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4668', 'Total loss: 1.3959', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52283692)
('DISCRIMINATOR_Imagem FAKE=', 0.52310586)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.407210')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6897 ', 'GAN acc 0.5117', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5000', 'Total loss: 1.3855', 'for batch', 0)
('GAN loss 0.7041 ', 'GAN acc 0.4609', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4609', 'Total loss: 1.4020', 'for batch', 1)
('GAN loss 0.6976 ', 'GAN acc 0.4609', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4707', 'Total loss: 1.3967', 'for batch', 2)
('GAN loss 0.6969 ', 'GAN acc 0.5273', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5059', 'Total loss: 1.3919', 'for batch', 3)
('GAN loss 0.7023 ', 'GAN acc 0.4883', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5020', 'Total loss: 1.3955', 'for batch', 4)
('GAN loss 0.7014 ', 'GAN acc 0.4727', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4961', 'Total loss: 1.3973', 'for batch', 5)
('GAN loss 0.6961 ', 'GAN acc 0.5117', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4824', 'Total loss: 1.3954', 'for batch', 6)
('GAN loss 0.6876 ', 'GAN acc 0.5078', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5020', 'Total loss: 1.3840', 'for batch', 7)
('GAN loss 0.6898 ', 'GAN acc 0.5117', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5078', 'Total loss: 1.3847', 'for batch', 8)
('GAN loss 0.6880 ', 'GAN acc 0.5508', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5312', 'Total loss: 1.3815', 'for batch', 9)
('GAN loss 0.6820 ', 'GAN acc 0.6055', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.4512', 'Total loss: 1.3855', 'for batch', 10)
('GAN loss 0.6832 ', 'GAN acc 0.5820', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5156', 'Total loss: 1.3741', 'for batch', 11)
('GAN loss 0.6861 ', 'GAN acc 0.5664', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5000', 'Total loss: 1.3777', 'for batch', 12)
('GAN loss 0.6882 ', 'GAN acc 0.5625', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5234', 'Total loss: 1.3812', 'for batch', 13)
('GAN loss 0.6974 ', 'GAN acc 0.5039', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5137', 'Total loss: 1.3913', 'for batch', 14)
('GAN loss 0.7006 ', 'GAN acc 0.5000', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5273', 'Total loss: 1.3949', 'for batch', 15)
('GAN loss 0.6911 ', 'GAN acc 0.5391', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5059', 'Total loss: 1.3870', 'for batch', 16)
('GAN loss 0.6922 ', 'GAN acc 0.4883', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4941', 'Total loss: 1.3885', 'for batch', 17)
('GAN loss 0.6921 ', 'GAN acc 0.5352', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4961', 'Total loss: 1.3869', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52726132)
('DISCRIMINATOR_Imagem FAKE=', 0.52700359)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.982770')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6887 ', 'GAN acc 0.5391', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5156', 'Total loss: 1.3810', 'for batch', 0)
('GAN loss 0.6906 ', 'GAN acc 0.5234', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5137', 'Total loss: 1.3864', 'for batch', 1)
('GAN loss 0.6951 ', 'GAN acc 0.5000', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5215', 'Total loss: 1.3879', 'for batch', 2)
('GAN loss 0.6962 ', 'GAN acc 0.5078', 'Discriminator loss 0.6901', 'Discriminator accuracy 0.5410', 'Total loss: 1.3863', 'for batch', 3)
('GAN loss 0.6942 ', 'GAN acc 0.5430', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4844', 'Total loss: 1.3907', 'for batch', 4)
('GAN loss 0.6975 ', 'GAN acc 0.5117', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5039', 'Total loss: 1.3928', 'for batch', 5)
('GAN loss 0.6962 ', 'GAN acc 0.5156', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4668', 'Total loss: 1.3931', 'for batch', 6)
('GAN loss 0.6879 ', 'GAN acc 0.5156', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5254', 'Total loss: 1.3801', 'for batch', 7)
('GAN loss 0.6915 ', 'GAN acc 0.5352', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5020', 'Total loss: 1.3840', 'for batch', 8)
('GAN loss 0.6948 ', 'GAN acc 0.4961', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4961', 'Total loss: 1.3915', 'for batch', 9)
('GAN loss 0.6817 ', 'GAN acc 0.6055', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3777', 'for batch', 10)
('GAN loss 0.6846 ', 'GAN acc 0.5703', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5020', 'Total loss: 1.3791', 'for batch', 11)
('GAN loss 0.6886 ', 'GAN acc 0.5508', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4902', 'Total loss: 1.3867', 'for batch', 12)
('GAN loss 0.6878 ', 'GAN acc 0.5469', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5117', 'Total loss: 1.3832', 'for batch', 13)
('GAN loss 0.6877 ', 'GAN acc 0.5352', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5117', 'Total loss: 1.3801', 'for batch', 14)
('GAN loss 0.6943 ', 'GAN acc 0.4922', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4961', 'Total loss: 1.3871', 'for batch', 15)
('GAN loss 0.6936 ', 'GAN acc 0.5000', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5254', 'Total loss: 1.3872', 'for batch', 16)
('GAN loss 0.6962 ', 'GAN acc 0.4883', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4531', 'Total loss: 1.3967', 'for batch', 17)
('GAN loss 0.6947 ', 'GAN acc 0.5039', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4883', 'Total loss: 1.3880', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52580553)
('DISCRIMINATOR_Imagem FAKE=', 0.52660036)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.429583')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6980 ', 'GAN acc 0.5156', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3935', 'for batch', 0)
('GAN loss 0.7003 ', 'GAN acc 0.4922', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5098', 'Total loss: 1.3949', 'for batch', 1)
('GAN loss 0.7051 ', 'GAN acc 0.4102', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4824', 'Total loss: 1.3994', 'for batch', 2)
('GAN loss 0.7002 ', 'GAN acc 0.4219', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4902', 'Total loss: 1.3942', 'for batch', 3)
('GAN loss 0.7050 ', 'GAN acc 0.4609', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4727', 'Total loss: 1.3999', 'for batch', 4)
('GAN loss 0.6924 ', 'GAN acc 0.4883', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4766', 'Total loss: 1.3902', 'for batch', 5)
('GAN loss 0.6976 ', 'GAN acc 0.4844', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5020', 'Total loss: 1.3916', 'for batch', 6)
('GAN loss 0.6969 ', 'GAN acc 0.5117', 'Discriminator loss 0.6861', 'Discriminator accuracy 0.5469', 'Total loss: 1.3830', 'for batch', 7)
('GAN loss 0.6985 ', 'GAN acc 0.4805', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4941', 'Total loss: 1.3953', 'for batch', 8)
('GAN loss 0.6954 ', 'GAN acc 0.4844', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4922', 'Total loss: 1.3937', 'for batch', 9)
('GAN loss 0.6919 ', 'GAN acc 0.5156', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4863', 'Total loss: 1.3886', 'for batch', 10)
('GAN loss 0.6863 ', 'GAN acc 0.5664', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.3819', 'for batch', 11)
('GAN loss 0.6873 ', 'GAN acc 0.5312', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5117', 'Total loss: 1.3821', 'for batch', 12)
('GAN loss 0.6918 ', 'GAN acc 0.5430', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4746', 'Total loss: 1.3877', 'for batch', 13)
('GAN loss 0.6902 ', 'GAN acc 0.5469', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5195', 'Total loss: 1.3825', 'for batch', 14)
('GAN loss 0.6956 ', 'GAN acc 0.4805', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4766', 'Total loss: 1.3927', 'for batch', 15)
('GAN loss 0.6953 ', 'GAN acc 0.5156', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4961', 'Total loss: 1.3912', 'for batch', 16)
('GAN loss 0.6914 ', 'GAN acc 0.5234', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4980', 'Total loss: 1.3883', 'for batch', 17)
('GAN loss 0.6907 ', 'GAN acc 0.5234', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3852', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52122486)
('DISCRIMINATOR_Imagem FAKE=', 0.52181613)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.806883')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6920 ', 'GAN acc 0.5156', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5078', 'Total loss: 1.3874', 'for batch', 0)
('GAN loss 0.6902 ', 'GAN acc 0.5352', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5137', 'Total loss: 1.3822', 'for batch', 1)
('GAN loss 0.6941 ', 'GAN acc 0.5352', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4590', 'Total loss: 1.3917', 'for batch', 2)
('GAN loss 0.6907 ', 'GAN acc 0.5234', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4941', 'Total loss: 1.3861', 'for batch', 3)
('GAN loss 0.6919 ', 'GAN acc 0.5078', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4883', 'Total loss: 1.3857', 'for batch', 4)
('GAN loss 0.6903 ', 'GAN acc 0.5625', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4668', 'Total loss: 1.3888', 'for batch', 5)
('GAN loss 0.6952 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5039', 'Total loss: 1.3907', 'for batch', 6)
('GAN loss 0.6910 ', 'GAN acc 0.5391', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5312', 'Total loss: 1.3834', 'for batch', 7)
('GAN loss 0.6930 ', 'GAN acc 0.5469', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5039', 'Total loss: 1.3889', 'for batch', 8)
('GAN loss 0.6986 ', 'GAN acc 0.4609', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4980', 'Total loss: 1.3952', 'for batch', 9)
('GAN loss 0.6942 ', 'GAN acc 0.5078', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3880', 'for batch', 10)
('GAN loss 0.6939 ', 'GAN acc 0.5430', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5039', 'Total loss: 1.3875', 'for batch', 11)
('GAN loss 0.6951 ', 'GAN acc 0.4961', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4727', 'Total loss: 1.3922', 'for batch', 12)
('GAN loss 0.6892 ', 'GAN acc 0.5430', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5098', 'Total loss: 1.3815', 'for batch', 13)
('GAN loss 0.6948 ', 'GAN acc 0.4844', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5195', 'Total loss: 1.3875', 'for batch', 14)
('GAN loss 0.6944 ', 'GAN acc 0.5000', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.5117', 'Total loss: 1.3912', 'for batch', 15)
('GAN loss 0.6996 ', 'GAN acc 0.4609', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4863', 'Total loss: 1.3958', 'for batch', 16)
('GAN loss 0.6982 ', 'GAN acc 0.4688', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4629', 'Total loss: 1.3938', 'for batch', 17)
('GAN loss 0.6929 ', 'GAN acc 0.5391', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5195', 'Total loss: 1.3833', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52173036)
('DISCRIMINATOR_Imagem FAKE=', 0.52191734)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.378946')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6923 ', 'GAN acc 0.5312', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4961', 'Total loss: 1.3850', 'for batch', 0)
('GAN loss 0.6924 ', 'GAN acc 0.5156', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4492', 'Total loss: 1.3920', 'for batch', 1)
('GAN loss 0.6967 ', 'GAN acc 0.5117', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5117', 'Total loss: 1.3926', 'for batch', 2)
('GAN loss 0.7023 ', 'GAN acc 0.4648', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4766', 'Total loss: 1.3983', 'for batch', 3)
('GAN loss 0.6970 ', 'GAN acc 0.4688', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5117', 'Total loss: 1.3911', 'for batch', 4)
('GAN loss 0.6946 ', 'GAN acc 0.5273', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5312', 'Total loss: 1.3850', 'for batch', 5)
('GAN loss 0.6937 ', 'GAN acc 0.4883', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4805', 'Total loss: 1.3915', 'for batch', 6)
('GAN loss 0.6948 ', 'GAN acc 0.5117', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5469', 'Total loss: 1.3843', 'for batch', 7)
('GAN loss 0.6921 ', 'GAN acc 0.5430', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4805', 'Total loss: 1.3880', 'for batch', 8)
('GAN loss 0.6836 ', 'GAN acc 0.5703', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5215', 'Total loss: 1.3752', 'for batch', 9)
('GAN loss 0.6853 ', 'GAN acc 0.5781', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4785', 'Total loss: 1.3829', 'for batch', 10)
('GAN loss 0.6844 ', 'GAN acc 0.5938', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4883', 'Total loss: 1.3807', 'for batch', 11)
('GAN loss 0.6852 ', 'GAN acc 0.5820', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4883', 'Total loss: 1.3834', 'for batch', 12)
('GAN loss 0.6860 ', 'GAN acc 0.5586', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4688', 'Total loss: 1.3845', 'for batch', 13)
('GAN loss 0.6901 ', 'GAN acc 0.5039', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4883', 'Total loss: 1.3862', 'for batch', 14)
('GAN loss 0.6945 ', 'GAN acc 0.5195', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4648', 'Total loss: 1.3921', 'for batch', 15)
('GAN loss 0.6957 ', 'GAN acc 0.4766', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4980', 'Total loss: 1.3910', 'for batch', 16)
('GAN loss 0.6978 ', 'GAN acc 0.4805', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.3927', 'for batch', 17)
('GAN loss 0.6979 ', 'GAN acc 0.4883', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4824', 'Total loss: 1.3928', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52159548)
('DISCRIMINATOR_Imagem FAKE=', 0.52166945)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.840528')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6956 ', 'GAN acc 0.5352', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5215', 'Total loss: 1.3894', 'for batch', 0)
('GAN loss 0.6935 ', 'GAN acc 0.5352', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4980', 'Total loss: 1.3905', 'for batch', 1)
('GAN loss 0.6964 ', 'GAN acc 0.4805', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5391', 'Total loss: 1.3890', 'for batch', 2)
('GAN loss 0.6932 ', 'GAN acc 0.5234', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5449', 'Total loss: 1.3849', 'for batch', 3)
('GAN loss 0.6996 ', 'GAN acc 0.4609', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4961', 'Total loss: 1.3933', 'for batch', 4)
('GAN loss 0.6925 ', 'GAN acc 0.5508', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4922', 'Total loss: 1.3880', 'for batch', 5)
('GAN loss 0.6924 ', 'GAN acc 0.5430', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5254', 'Total loss: 1.3842', 'for batch', 6)
('GAN loss 0.6887 ', 'GAN acc 0.5508', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4844', 'Total loss: 1.3825', 'for batch', 7)
('GAN loss 0.6897 ', 'GAN acc 0.5430', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5195', 'Total loss: 1.3819', 'for batch', 8)
('GAN loss 0.6966 ', 'GAN acc 0.5039', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4629', 'Total loss: 1.3946', 'for batch', 9)
('GAN loss 0.6946 ', 'GAN acc 0.5312', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5195', 'Total loss: 1.3895', 'for batch', 10)
('GAN loss 0.7006 ', 'GAN acc 0.4844', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5000', 'Total loss: 1.3946', 'for batch', 11)
('GAN loss 0.7008 ', 'GAN acc 0.4297', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4844', 'Total loss: 1.3963', 'for batch', 12)
('GAN loss 0.6886 ', 'GAN acc 0.5547', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5195', 'Total loss: 1.3813', 'for batch', 13)
('GAN loss 0.6900 ', 'GAN acc 0.5781', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4922', 'Total loss: 1.3866', 'for batch', 14)
('GAN loss 0.6881 ', 'GAN acc 0.5586', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5430', 'Total loss: 1.3793', 'for batch', 15)
('GAN loss 0.6984 ', 'GAN acc 0.4844', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4746', 'Total loss: 1.3943', 'for batch', 16)
('GAN loss 0.6936 ', 'GAN acc 0.5195', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5059', 'Total loss: 1.3877', 'for batch', 17)
('GAN loss 0.6888 ', 'GAN acc 0.5625', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5312', 'Total loss: 1.3795', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52269268)
('DISCRIMINATOR_Imagem FAKE=', 0.52308238)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.439173')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6858 ', 'GAN acc 0.5938', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5059', 'Total loss: 1.3811', 'for batch', 0)
('GAN loss 0.6888 ', 'GAN acc 0.5352', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4648', 'Total loss: 1.3876', 'for batch', 1)
('GAN loss 0.6946 ', 'GAN acc 0.5312', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5332', 'Total loss: 1.3863', 'for batch', 2)
('GAN loss 0.6997 ', 'GAN acc 0.4883', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5469', 'Total loss: 1.3924', 'for batch', 3)
('GAN loss 0.7000 ', 'GAN acc 0.4375', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5293', 'Total loss: 1.3932', 'for batch', 4)
('GAN loss 0.6961 ', 'GAN acc 0.5039', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4844', 'Total loss: 1.3908', 'for batch', 5)
('GAN loss 0.6956 ', 'GAN acc 0.5000', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5234', 'Total loss: 1.3896', 'for batch', 6)
('GAN loss 0.6956 ', 'GAN acc 0.5078', 'Discriminator loss 0.6900', 'Discriminator accuracy 0.5410', 'Total loss: 1.3856', 'for batch', 7)
('GAN loss 0.6915 ', 'GAN acc 0.5352', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5293', 'Total loss: 1.3832', 'for batch', 8)
('GAN loss 0.6905 ', 'GAN acc 0.5273', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4824', 'Total loss: 1.3876', 'for batch', 9)
('GAN loss 0.6921 ', 'GAN acc 0.5312', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3876', 'for batch', 10)
('GAN loss 0.6900 ', 'GAN acc 0.5273', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5215', 'Total loss: 1.3822', 'for batch', 11)
('GAN loss 0.6941 ', 'GAN acc 0.5234', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4824', 'Total loss: 1.3896', 'for batch', 12)
('GAN loss 0.6907 ', 'GAN acc 0.4883', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4766', 'Total loss: 1.3856', 'for batch', 13)
('GAN loss 0.6914 ', 'GAN acc 0.5430', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5508', 'Total loss: 1.3836', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.5156', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5430', 'Total loss: 1.3835', 'for batch', 15)
('GAN loss 0.6890 ', 'GAN acc 0.5547', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4531', 'Total loss: 1.3878', 'for batch', 16)
('GAN loss 0.6979 ', 'GAN acc 0.4414', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5312', 'Total loss: 1.3875', 'for batch', 17)
('GAN loss 0.6868 ', 'GAN acc 0.5234', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5254', 'Total loss: 1.3804', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5195685)
('DISCRIMINATOR_Imagem FAKE=', 0.51932096)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.908010')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6893 ', 'GAN acc 0.5391', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.4707', 'Total loss: 1.3896', 'for batch', 0)
('GAN loss 0.6934 ', 'GAN acc 0.5156', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5234', 'Total loss: 1.3849', 'for batch', 1)
('GAN loss 0.6954 ', 'GAN acc 0.4922', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5039', 'Total loss: 1.3885', 'for batch', 2)
('GAN loss 0.6962 ', 'GAN acc 0.4883', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4531', 'Total loss: 1.3937', 'for batch', 3)
('GAN loss 0.6941 ', 'GAN acc 0.4805', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4727', 'Total loss: 1.3884', 'for batch', 4)
('GAN loss 0.6951 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5059', 'Total loss: 1.3912', 'for batch', 5)
('GAN loss 0.6992 ', 'GAN acc 0.4453', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5332', 'Total loss: 1.3932', 'for batch', 6)
('GAN loss 0.7023 ', 'GAN acc 0.4258', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4648', 'Total loss: 1.4007', 'for batch', 7)
('GAN loss 0.6936 ', 'GAN acc 0.4961', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4727', 'Total loss: 1.3893', 'for batch', 8)
('GAN loss 0.6959 ', 'GAN acc 0.5078', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5195', 'Total loss: 1.3882', 'for batch', 9)
('GAN loss 0.6941 ', 'GAN acc 0.4805', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4766', 'Total loss: 1.3901', 'for batch', 10)
('GAN loss 0.6909 ', 'GAN acc 0.5469', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4824', 'Total loss: 1.3879', 'for batch', 11)
('GAN loss 0.6908 ', 'GAN acc 0.5312', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5410', 'Total loss: 1.3826', 'for batch', 12)
('GAN loss 0.6899 ', 'GAN acc 0.5664', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5098', 'Total loss: 1.3819', 'for batch', 13)
('GAN loss 0.6904 ', 'GAN acc 0.5352', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4629', 'Total loss: 1.3885', 'for batch', 14)
('GAN loss 0.6912 ', 'GAN acc 0.5352', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3867', 'for batch', 15)
('GAN loss 0.6967 ', 'GAN acc 0.4531', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5215', 'Total loss: 1.3879', 'for batch', 16)
('GAN loss 0.6922 ', 'GAN acc 0.5078', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5176', 'Total loss: 1.3845', 'for batch', 17)
('GAN loss 0.6923 ', 'GAN acc 0.5664', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4727', 'Total loss: 1.3917', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51772255)
('DISCRIMINATOR_Imagem FAKE=', 0.51765788)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.429799')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6953 ', 'GAN acc 0.5234', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4844', 'Total loss: 1.3914', 'for batch', 0)
('GAN loss 0.6863 ', 'GAN acc 0.5547', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5059', 'Total loss: 1.3810', 'for batch', 1)
('GAN loss 0.7011 ', 'GAN acc 0.4336', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4805', 'Total loss: 1.3980', 'for batch', 2)
('GAN loss 0.6918 ', 'GAN acc 0.5430', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4746', 'Total loss: 1.3881', 'for batch', 3)
('GAN loss 0.6958 ', 'GAN acc 0.5000', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5254', 'Total loss: 1.3867', 'for batch', 4)
('GAN loss 0.6956 ', 'GAN acc 0.5039', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5176', 'Total loss: 1.3865', 'for batch', 5)
('GAN loss 0.6967 ', 'GAN acc 0.4805', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5117', 'Total loss: 1.3908', 'for batch', 6)
('GAN loss 0.6944 ', 'GAN acc 0.5430', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4902', 'Total loss: 1.3911', 'for batch', 7)
('GAN loss 0.6959 ', 'GAN acc 0.4570', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4727', 'Total loss: 1.3939', 'for batch', 8)
('GAN loss 0.6944 ', 'GAN acc 0.5273', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5176', 'Total loss: 1.3871', 'for batch', 9)
('GAN loss 0.6960 ', 'GAN acc 0.5117', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4668', 'Total loss: 1.3937', 'for batch', 10)
('GAN loss 0.6963 ', 'GAN acc 0.4961', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4941', 'Total loss: 1.3907', 'for batch', 11)
('GAN loss 0.6993 ', 'GAN acc 0.4609', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5391', 'Total loss: 1.3926', 'for batch', 12)
('GAN loss 0.6958 ', 'GAN acc 0.4922', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4785', 'Total loss: 1.3898', 'for batch', 13)
('GAN loss 0.6991 ', 'GAN acc 0.4844', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5117', 'Total loss: 1.3922', 'for batch', 14)
('GAN loss 0.6933 ', 'GAN acc 0.5234', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5391', 'Total loss: 1.3855', 'for batch', 15)
('GAN loss 0.6916 ', 'GAN acc 0.5586', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4961', 'Total loss: 1.3852', 'for batch', 16)
('GAN loss 0.6844 ', 'GAN acc 0.5938', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4902', 'Total loss: 1.3793', 'for batch', 17)
('GAN loss 0.6836 ', 'GAN acc 0.6094', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4805', 'Total loss: 1.3806', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51991516)
('DISCRIMINATOR_Imagem FAKE=', 0.51947594)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.812874')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6841 ', 'GAN acc 0.6250', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5137', 'Total loss: 1.3794', 'for batch', 0)
('GAN loss 0.6808 ', 'GAN acc 0.6094', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5176', 'Total loss: 1.3761', 'for batch', 1)
('GAN loss 0.6867 ', 'GAN acc 0.5898', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5195', 'Total loss: 1.3816', 'for batch', 2)
('GAN loss 0.6957 ', 'GAN acc 0.5117', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4922', 'Total loss: 1.3897', 'for batch', 3)
('GAN loss 0.6883 ', 'GAN acc 0.5430', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5195', 'Total loss: 1.3798', 'for batch', 4)
('GAN loss 0.6898 ', 'GAN acc 0.5312', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5000', 'Total loss: 1.3842', 'for batch', 5)
('GAN loss 0.6912 ', 'GAN acc 0.5195', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5254', 'Total loss: 1.3817', 'for batch', 6)
('GAN loss 0.6853 ', 'GAN acc 0.5898', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5117', 'Total loss: 1.3775', 'for batch', 7)
('GAN loss 0.6959 ', 'GAN acc 0.4688', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4941', 'Total loss: 1.3920', 'for batch', 8)
('GAN loss 0.6915 ', 'GAN acc 0.5430', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4922', 'Total loss: 1.3859', 'for batch', 9)
('GAN loss 0.6864 ', 'GAN acc 0.5938', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5000', 'Total loss: 1.3813', 'for batch', 10)
('GAN loss 0.6946 ', 'GAN acc 0.4844', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3884', 'for batch', 11)
('GAN loss 0.6973 ', 'GAN acc 0.4727', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5176', 'Total loss: 1.3910', 'for batch', 12)
('GAN loss 0.6982 ', 'GAN acc 0.4766', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5215', 'Total loss: 1.3903', 'for batch', 13)
('GAN loss 0.7041 ', 'GAN acc 0.4609', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.4961', 'Total loss: 1.3965', 'for batch', 14)
('GAN loss 0.7009 ', 'GAN acc 0.4336', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5078', 'Total loss: 1.3935', 'for batch', 15)
('GAN loss 0.6982 ', 'GAN acc 0.5156', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5020', 'Total loss: 1.3926', 'for batch', 16)
('GAN loss 0.6967 ', 'GAN acc 0.4648', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4863', 'Total loss: 1.3937', 'for batch', 17)
('GAN loss 0.6986 ', 'GAN acc 0.4766', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5234', 'Total loss: 1.3911', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51788688)
('DISCRIMINATOR_Imagem FAKE=', 0.51769567)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.462437')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6948 ', 'GAN acc 0.5156', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5176', 'Total loss: 1.3869', 'for batch', 0)
('GAN loss 0.6908 ', 'GAN acc 0.5547', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4902', 'Total loss: 1.3855', 'for batch', 1)
('GAN loss 0.6892 ', 'GAN acc 0.5352', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5000', 'Total loss: 1.3825', 'for batch', 2)
('GAN loss 0.6869 ', 'GAN acc 0.5469', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3809', 'for batch', 3)
('GAN loss 0.6961 ', 'GAN acc 0.5039', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4766', 'Total loss: 1.3921', 'for batch', 4)
('GAN loss 0.6950 ', 'GAN acc 0.5156', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4863', 'Total loss: 1.3906', 'for batch', 5)
('GAN loss 0.6875 ', 'GAN acc 0.5820', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4902', 'Total loss: 1.3824', 'for batch', 6)
('GAN loss 0.6926 ', 'GAN acc 0.5039', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4863', 'Total loss: 1.3880', 'for batch', 7)
('GAN loss 0.6910 ', 'GAN acc 0.5234', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4727', 'Total loss: 1.3859', 'for batch', 8)
('GAN loss 0.6882 ', 'GAN acc 0.5430', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4961', 'Total loss: 1.3803', 'for batch', 9)
('GAN loss 0.6934 ', 'GAN acc 0.5078', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5078', 'Total loss: 1.3852', 'for batch', 10)
('GAN loss 0.6913 ', 'GAN acc 0.5469', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4863', 'Total loss: 1.3858', 'for batch', 11)
('GAN loss 0.6930 ', 'GAN acc 0.5195', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4941', 'Total loss: 1.3874', 'for batch', 12)
('GAN loss 0.6923 ', 'GAN acc 0.5078', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5293', 'Total loss: 1.3861', 'for batch', 13)
('GAN loss 0.6938 ', 'GAN acc 0.5273', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4629', 'Total loss: 1.3901', 'for batch', 14)
('GAN loss 0.6981 ', 'GAN acc 0.4648', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4824', 'Total loss: 1.3933', 'for batch', 15)
('GAN loss 0.6951 ', 'GAN acc 0.4922', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4902', 'Total loss: 1.3903', 'for batch', 16)
('GAN loss 0.7007 ', 'GAN acc 0.4688', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5117', 'Total loss: 1.3976', 'for batch', 17)
('GAN loss 0.6910 ', 'GAN acc 0.5273', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5156', 'Total loss: 1.3831', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51559818)
('DISCRIMINATOR_Imagem FAKE=', 0.51597816)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.888180')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7024 ', 'GAN acc 0.4531', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4980', 'Total loss: 1.3959', 'for batch', 0)
('GAN loss 0.7037 ', 'GAN acc 0.4102', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4707', 'Total loss: 1.4009', 'for batch', 1)
('GAN loss 0.7084 ', 'GAN acc 0.3828', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5273', 'Total loss: 1.4012', 'for batch', 2)
('GAN loss 0.7107 ', 'GAN acc 0.3789', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4980', 'Total loss: 1.4035', 'for batch', 3)
('GAN loss 0.7063 ', 'GAN acc 0.3828', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4824', 'Total loss: 1.4020', 'for batch', 4)
('GAN loss 0.7028 ', 'GAN acc 0.4453', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5098', 'Total loss: 1.3950', 'for batch', 5)
('GAN loss 0.6964 ', 'GAN acc 0.5117', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5234', 'Total loss: 1.3879', 'for batch', 6)
('GAN loss 0.6933 ', 'GAN acc 0.4844', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4961', 'Total loss: 1.3890', 'for batch', 7)
('GAN loss 0.6919 ', 'GAN acc 0.4961', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5391', 'Total loss: 1.3856', 'for batch', 8)
('GAN loss 0.6885 ', 'GAN acc 0.5469', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5039', 'Total loss: 1.3829', 'for batch', 9)
('GAN loss 0.6942 ', 'GAN acc 0.4883', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5117', 'Total loss: 1.3897', 'for batch', 10)
('GAN loss 0.6926 ', 'GAN acc 0.5195', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4961', 'Total loss: 1.3847', 'for batch', 11)
('GAN loss 0.6884 ', 'GAN acc 0.5547', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5020', 'Total loss: 1.3819', 'for batch', 12)
('GAN loss 0.6878 ', 'GAN acc 0.5664', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4883', 'Total loss: 1.3808', 'for batch', 13)
('GAN loss 0.6978 ', 'GAN acc 0.5078', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.5059', 'Total loss: 1.3941', 'for batch', 14)
('GAN loss 0.6921 ', 'GAN acc 0.5156', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4785', 'Total loss: 1.3888', 'for batch', 15)
('GAN loss 0.6952 ', 'GAN acc 0.5039', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5000', 'Total loss: 1.3906', 'for batch', 16)
('GAN loss 0.6949 ', 'GAN acc 0.4883', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5000', 'Total loss: 1.3885', 'for batch', 17)
('GAN loss 0.6973 ', 'GAN acc 0.4609', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4844', 'Total loss: 1.3935', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.517555)
('DISCRIMINATOR_Imagem FAKE=', 0.51708263)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.441675')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6984 ', 'GAN acc 0.4570', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5059', 'Total loss: 1.3941', 'for batch', 0)
('GAN loss 0.6926 ', 'GAN acc 0.5352', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5000', 'Total loss: 1.3866', 'for batch', 1)
('GAN loss 0.6948 ', 'GAN acc 0.4805', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5273', 'Total loss: 1.3871', 'for batch', 2)
('GAN loss 0.6949 ', 'GAN acc 0.5078', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5332', 'Total loss: 1.3868', 'for batch', 3)
('GAN loss 0.6965 ', 'GAN acc 0.4961', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5527', 'Total loss: 1.3880', 'for batch', 4)
('GAN loss 0.6908 ', 'GAN acc 0.5430', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4727', 'Total loss: 1.3857', 'for batch', 5)
('GAN loss 0.6883 ', 'GAN acc 0.5625', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4844', 'Total loss: 1.3832', 'for batch', 6)
('GAN loss 0.6879 ', 'GAN acc 0.5547', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5078', 'Total loss: 1.3816', 'for batch', 7)
('GAN loss 0.6848 ', 'GAN acc 0.6211', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5156', 'Total loss: 1.3777', 'for batch', 8)
('GAN loss 0.6926 ', 'GAN acc 0.5156', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4863', 'Total loss: 1.3880', 'for batch', 9)
('GAN loss 0.6873 ', 'GAN acc 0.5312', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4727', 'Total loss: 1.3837', 'for batch', 10)
('GAN loss 0.6915 ', 'GAN acc 0.5156', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4805', 'Total loss: 1.3858', 'for batch', 11)
('GAN loss 0.6931 ', 'GAN acc 0.5195', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4746', 'Total loss: 1.3898', 'for batch', 12)
('GAN loss 0.6982 ', 'GAN acc 0.4883', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4863', 'Total loss: 1.3929', 'for batch', 13)
('GAN loss 0.7025 ', 'GAN acc 0.4453', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4941', 'Total loss: 1.3971', 'for batch', 14)
('GAN loss 0.7033 ', 'GAN acc 0.4336', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4863', 'Total loss: 1.3996', 'for batch', 15)
('GAN loss 0.7011 ', 'GAN acc 0.4805', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4785', 'Total loss: 1.3982', 'for batch', 16)
('GAN loss 0.6960 ', 'GAN acc 0.5039', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5000', 'Total loss: 1.3910', 'for batch', 17)
('GAN loss 0.7001 ', 'GAN acc 0.4570', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4980', 'Total loss: 1.3927', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51512921)
('DISCRIMINATOR_Imagem FAKE=', 0.51523131)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.888865')
----------------------------------
('Epoch', 32, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7054 ', 'GAN acc 0.4102', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5371', 'Total loss: 1.3975', 'for batch', 0)
('GAN loss 0.7012 ', 'GAN acc 0.4648', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4883', 'Total loss: 1.3965', 'for batch', 1)
('GAN loss 0.6973 ', 'GAN acc 0.4727', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5137', 'Total loss: 1.3906', 'for batch', 2)
('GAN loss 0.7036 ', 'GAN acc 0.4297', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5215', 'Total loss: 1.3947', 'for batch', 3)
('GAN loss 0.6969 ', 'GAN acc 0.4609', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.4883', 'Total loss: 1.3897', 'for batch', 4)
('GAN loss 0.6939 ', 'GAN acc 0.5117', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5020', 'Total loss: 1.3878', 'for batch', 5)
('GAN loss 0.6923 ', 'GAN acc 0.5352', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5176', 'Total loss: 1.3873', 'for batch', 6)
('GAN loss 0.6907 ', 'GAN acc 0.5469', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5156', 'Total loss: 1.3827', 'for batch', 7)
('GAN loss 0.6824 ', 'GAN acc 0.6133', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5312', 'Total loss: 1.3736', 'for batch', 8)
('GAN loss 0.6837 ', 'GAN acc 0.6445', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4941', 'Total loss: 1.3779', 'for batch', 9)
('GAN loss 0.6860 ', 'GAN acc 0.6016', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4668', 'Total loss: 1.3821', 'for batch', 10)
('GAN loss 0.6810 ', 'GAN acc 0.6094', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5137', 'Total loss: 1.3723', 'for batch', 11)
('GAN loss 0.6776 ', 'GAN acc 0.6523', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4883', 'Total loss: 1.3757', 'for batch', 12)
('GAN loss 0.6868 ', 'GAN acc 0.5781', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4766', 'Total loss: 1.3842', 'for batch', 13)
('GAN loss 0.6896 ', 'GAN acc 0.5352', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5137', 'Total loss: 1.3825', 'for batch', 14)
('GAN loss 0.6904 ', 'GAN acc 0.5195', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5098', 'Total loss: 1.3820', 'for batch', 15)
('GAN loss 0.7020 ', 'GAN acc 0.4375', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4922', 'Total loss: 1.3964', 'for batch', 16)
('GAN loss 0.7005 ', 'GAN acc 0.4375', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4883', 'Total loss: 1.3944', 'for batch', 17)
('GAN loss 0.7019 ', 'GAN acc 0.4648', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3977', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51517808)
('DISCRIMINATOR_Imagem FAKE=', 0.51562524)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.978714')
----------------------------------
('Epoch', 33, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7004 ', 'GAN acc 0.4453', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5254', 'Total loss: 1.3921', 'for batch', 0)
('GAN loss 0.7053 ', 'GAN acc 0.4180', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5098', 'Total loss: 1.3997', 'for batch', 1)
('GAN loss 0.7008 ', 'GAN acc 0.4570', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5020', 'Total loss: 1.3940', 'for batch', 2)
('GAN loss 0.6903 ', 'GAN acc 0.5469', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4824', 'Total loss: 1.3853', 'for batch', 3)
('GAN loss 0.6954 ', 'GAN acc 0.5078', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4492', 'Total loss: 1.3912', 'for batch', 4)
('GAN loss 0.6962 ', 'GAN acc 0.4531', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4785', 'Total loss: 1.3910', 'for batch', 5)
('GAN loss 0.6954 ', 'GAN acc 0.5039', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5059', 'Total loss: 1.3894', 'for batch', 6)
('GAN loss 0.6894 ', 'GAN acc 0.5547', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5078', 'Total loss: 1.3845', 'for batch', 7)
('GAN loss 0.6901 ', 'GAN acc 0.5273', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5000', 'Total loss: 1.3861', 'for batch', 8)
('GAN loss 0.6875 ', 'GAN acc 0.5781', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.5000', 'Total loss: 1.3836', 'for batch', 9)
('GAN loss 0.6864 ', 'GAN acc 0.5820', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5039', 'Total loss: 1.3817', 'for batch', 10)
('GAN loss 0.6832 ', 'GAN acc 0.5977', 'Discriminator loss 0.6891', 'Discriminator accuracy 0.5762', 'Total loss: 1.3722', 'for batch', 11)
('GAN loss 0.6804 ', 'GAN acc 0.6211', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4902', 'Total loss: 1.3737', 'for batch', 12)
('GAN loss 0.6876 ', 'GAN acc 0.6016', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5176', 'Total loss: 1.3806', 'for batch', 13)
('GAN loss 0.6877 ', 'GAN acc 0.5664', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5117', 'Total loss: 1.3795', 'for batch', 14)
('GAN loss 0.6939 ', 'GAN acc 0.4961', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4902', 'Total loss: 1.3892', 'for batch', 15)
('GAN loss 0.6964 ', 'GAN acc 0.4805', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5059', 'Total loss: 1.3889', 'for batch', 16)
('GAN loss 0.6988 ', 'GAN acc 0.4375', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4746', 'Total loss: 1.3939', 'for batch', 17)
('GAN loss 0.7037 ', 'GAN acc 0.4023', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4863', 'Total loss: 1.4002', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51352209)
('DISCRIMINATOR_Imagem FAKE=', 0.51399952)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.410463')
----------------------------------
('Epoch', 34, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7080 ', 'GAN acc 0.3750', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5117', 'Total loss: 1.4017', 'for batch', 0)
('GAN loss 0.7071 ', 'GAN acc 0.4102', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4961', 'Total loss: 1.4018', 'for batch', 1)
('GAN loss 0.7055 ', 'GAN acc 0.3672', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5273', 'Total loss: 1.3976', 'for batch', 2)
('GAN loss 0.7003 ', 'GAN acc 0.4180', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4961', 'Total loss: 1.3960', 'for batch', 3)
('GAN loss 0.6947 ', 'GAN acc 0.5000', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5293', 'Total loss: 1.3862', 'for batch', 4)
('GAN loss 0.7009 ', 'GAN acc 0.4258', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3957', 'for batch', 5)
('GAN loss 0.6941 ', 'GAN acc 0.5312', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5039', 'Total loss: 1.3889', 'for batch', 6)
('GAN loss 0.6903 ', 'GAN acc 0.5508', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4961', 'Total loss: 1.3838', 'for batch', 7)
('GAN loss 0.6909 ', 'GAN acc 0.5742', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5488', 'Total loss: 1.3823', 'for batch', 8)
('GAN loss 0.6905 ', 'GAN acc 0.5273', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4727', 'Total loss: 1.3861', 'for batch', 9)
('GAN loss 0.6906 ', 'GAN acc 0.5547', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5391', 'Total loss: 1.3836', 'for batch', 10)
('GAN loss 0.6886 ', 'GAN acc 0.5781', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4980', 'Total loss: 1.3845', 'for batch', 11)
('GAN loss 0.6808 ', 'GAN acc 0.6328', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3750', 'for batch', 12)
('GAN loss 0.6857 ', 'GAN acc 0.5586', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4805', 'Total loss: 1.3807', 'for batch', 13)
('GAN loss 0.6865 ', 'GAN acc 0.5781', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4902', 'Total loss: 1.3820', 'for batch', 14)
('GAN loss 0.6858 ', 'GAN acc 0.5664', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5078', 'Total loss: 1.3804', 'for batch', 15)
('GAN loss 0.6911 ', 'GAN acc 0.5195', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5371', 'Total loss: 1.3841', 'for batch', 16)
('GAN loss 0.6878 ', 'GAN acc 0.5469', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4824', 'Total loss: 1.3834', 'for batch', 17)
('GAN loss 0.6957 ', 'GAN acc 0.4922', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.3906', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51560968)
('DISCRIMINATOR_Imagem FAKE=', 0.51611191)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.806454')
----------------------------------
('Epoch', 35, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6914 ', 'GAN acc 0.5195', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5078', 'Total loss: 1.3837', 'for batch', 0)
('GAN loss 0.7022 ', 'GAN acc 0.3867', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5215', 'Total loss: 1.3948', 'for batch', 1)
('GAN loss 0.7007 ', 'GAN acc 0.4180', 'Discriminator loss 0.6896', 'Discriminator accuracy 0.5332', 'Total loss: 1.3902', 'for batch', 2)
('GAN loss 0.7052 ', 'GAN acc 0.4375', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4980', 'Total loss: 1.4008', 'for batch', 3)
('GAN loss 0.7046 ', 'GAN acc 0.4180', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4648', 'Total loss: 1.4014', 'for batch', 4)
('GAN loss 0.7054 ', 'GAN acc 0.3555', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4668', 'Total loss: 1.3998', 'for batch', 5)
('GAN loss 0.7040 ', 'GAN acc 0.4102', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4668', 'Total loss: 1.3998', 'for batch', 6)
('GAN loss 0.6986 ', 'GAN acc 0.4453', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4785', 'Total loss: 1.3948', 'for batch', 7)
('GAN loss 0.6972 ', 'GAN acc 0.4961', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4551', 'Total loss: 1.3952', 'for batch', 8)
('GAN loss 0.6976 ', 'GAN acc 0.4453', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4883', 'Total loss: 1.3918', 'for batch', 9)
('GAN loss 0.6921 ', 'GAN acc 0.5195', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5215', 'Total loss: 1.3832', 'for batch', 10)
('GAN loss 0.6928 ', 'GAN acc 0.5469', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4883', 'Total loss: 1.3888', 'for batch', 11)
('GAN loss 0.6937 ', 'GAN acc 0.5078', 'Discriminator loss 0.6892', 'Discriminator accuracy 0.5410', 'Total loss: 1.3829', 'for batch', 12)
('GAN loss 0.6910 ', 'GAN acc 0.5547', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4746', 'Total loss: 1.3872', 'for batch', 13)
('GAN loss 0.6898 ', 'GAN acc 0.5977', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4844', 'Total loss: 1.3859', 'for batch', 14)
('GAN loss 0.6888 ', 'GAN acc 0.5625', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4961', 'Total loss: 1.3831', 'for batch', 15)
('GAN loss 0.6855 ', 'GAN acc 0.5781', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3796', 'for batch', 16)
('GAN loss 0.6842 ', 'GAN acc 0.6094', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5078', 'Total loss: 1.3792', 'for batch', 17)
('GAN loss 0.6851 ', 'GAN acc 0.5820', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5488', 'Total loss: 1.3757', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51675576)
('DISCRIMINATOR_Imagem FAKE=', 0.51674217)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.402820')
----------------------------------
('Epoch', 36, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6831 ', 'GAN acc 0.5898', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4707', 'Total loss: 1.3803', 'for batch', 0)
('GAN loss 0.6873 ', 'GAN acc 0.5742', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4805', 'Total loss: 1.3847', 'for batch', 1)
('GAN loss 0.6850 ', 'GAN acc 0.6016', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5254', 'Total loss: 1.3776', 'for batch', 2)
('GAN loss 0.6878 ', 'GAN acc 0.6016', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4512', 'Total loss: 1.3875', 'for batch', 3)
('GAN loss 0.6900 ', 'GAN acc 0.5586', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4727', 'Total loss: 1.3857', 'for batch', 4)
('GAN loss 0.6942 ', 'GAN acc 0.4688', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4883', 'Total loss: 1.3898', 'for batch', 5)
('GAN loss 0.6919 ', 'GAN acc 0.5312', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4961', 'Total loss: 1.3849', 'for batch', 6)
('GAN loss 0.6938 ', 'GAN acc 0.5000', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4922', 'Total loss: 1.3898', 'for batch', 7)
('GAN loss 0.6978 ', 'GAN acc 0.4688', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5020', 'Total loss: 1.3924', 'for batch', 8)
('GAN loss 0.6958 ', 'GAN acc 0.4961', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5039', 'Total loss: 1.3891', 'for batch', 9)
('GAN loss 0.6939 ', 'GAN acc 0.4844', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5312', 'Total loss: 1.3877', 'for batch', 10)
('GAN loss 0.6957 ', 'GAN acc 0.4570', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5078', 'Total loss: 1.3903', 'for batch', 11)
('GAN loss 0.7004 ', 'GAN acc 0.4375', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5000', 'Total loss: 1.3923', 'for batch', 12)
('GAN loss 0.6954 ', 'GAN acc 0.4844', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5215', 'Total loss: 1.3879', 'for batch', 13)
('GAN loss 0.6949 ', 'GAN acc 0.5000', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5195', 'Total loss: 1.3863', 'for batch', 14)
('GAN loss 0.6957 ', 'GAN acc 0.4727', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4922', 'Total loss: 1.3925', 'for batch', 15)
('GAN loss 0.6972 ', 'GAN acc 0.4805', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4941', 'Total loss: 1.3911', 'for batch', 16)
('GAN loss 0.6930 ', 'GAN acc 0.5117', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4922', 'Total loss: 1.3864', 'for batch', 17)
('GAN loss 0.6924 ', 'GAN acc 0.5273', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5312', 'Total loss: 1.3848', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51254708)
('DISCRIMINATOR_Imagem FAKE=', 0.51218688)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.828987')
----------------------------------
('Epoch', 37, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6927 ', 'GAN acc 0.5195', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3891', 'for batch', 0)
('GAN loss 0.6948 ', 'GAN acc 0.5078', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4863', 'Total loss: 1.3901', 'for batch', 1)
('GAN loss 0.6873 ', 'GAN acc 0.5664', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4961', 'Total loss: 1.3817', 'for batch', 2)
('GAN loss 0.6899 ', 'GAN acc 0.5508', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4785', 'Total loss: 1.3840', 'for batch', 3)
('GAN loss 0.6901 ', 'GAN acc 0.5078', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4648', 'Total loss: 1.3869', 'for batch', 4)
('GAN loss 0.6941 ', 'GAN acc 0.5352', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4609', 'Total loss: 1.3912', 'for batch', 5)
('GAN loss 0.6938 ', 'GAN acc 0.5078', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5156', 'Total loss: 1.3871', 'for batch', 6)
('GAN loss 0.6919 ', 'GAN acc 0.5430', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5410', 'Total loss: 1.3829', 'for batch', 7)
('GAN loss 0.6979 ', 'GAN acc 0.4727', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5371', 'Total loss: 1.3898', 'for batch', 8)
('GAN loss 0.6990 ', 'GAN acc 0.4336', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4961', 'Total loss: 1.3950', 'for batch', 9)
('GAN loss 0.6993 ', 'GAN acc 0.4688', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4590', 'Total loss: 1.3950', 'for batch', 10)
('GAN loss 0.6951 ', 'GAN acc 0.4805', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4609', 'Total loss: 1.3917', 'for batch', 11)
('GAN loss 0.7008 ', 'GAN acc 0.4727', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4844', 'Total loss: 1.3934', 'for batch', 12)
('GAN loss 0.6985 ', 'GAN acc 0.4531', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5020', 'Total loss: 1.3940', 'for batch', 13)
('GAN loss 0.6978 ', 'GAN acc 0.4219', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4785', 'Total loss: 1.3932', 'for batch', 14)
('GAN loss 0.7036 ', 'GAN acc 0.3789', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5059', 'Total loss: 1.3959', 'for batch', 15)
('GAN loss 0.6963 ', 'GAN acc 0.4883', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4883', 'Total loss: 1.3932', 'for batch', 16)
('GAN loss 0.6979 ', 'GAN acc 0.4570', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5000', 'Total loss: 1.3910', 'for batch', 17)
('GAN loss 0.6954 ', 'GAN acc 0.4961', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4941', 'Total loss: 1.3893', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50997639)
('DISCRIMINATOR_Imagem FAKE=', 0.51008773)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.424633')
----------------------------------
('Epoch', 38, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6929 ', 'GAN acc 0.4883', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4922', 'Total loss: 1.3877', 'for batch', 0)
('GAN loss 0.6914 ', 'GAN acc 0.5234', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5254', 'Total loss: 1.3857', 'for batch', 1)
('GAN loss 0.6932 ', 'GAN acc 0.4922', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4805', 'Total loss: 1.3891', 'for batch', 2)
('GAN loss 0.6890 ', 'GAN acc 0.5781', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5059', 'Total loss: 1.3808', 'for batch', 3)
('GAN loss 0.6907 ', 'GAN acc 0.5039', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4844', 'Total loss: 1.3873', 'for batch', 4)
('GAN loss 0.6895 ', 'GAN acc 0.5508', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4688', 'Total loss: 1.3852', 'for batch', 5)
('GAN loss 0.6880 ', 'GAN acc 0.5469', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4824', 'Total loss: 1.3821', 'for batch', 6)
('GAN loss 0.6862 ', 'GAN acc 0.6055', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5000', 'Total loss: 1.3811', 'for batch', 7)
('GAN loss 0.6895 ', 'GAN acc 0.5352', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5137', 'Total loss: 1.3835', 'for batch', 8)
('GAN loss 0.6902 ', 'GAN acc 0.5430', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4961', 'Total loss: 1.3837', 'for batch', 9)
('GAN loss 0.6864 ', 'GAN acc 0.5820', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5156', 'Total loss: 1.3771', 'for batch', 10)
('GAN loss 0.6911 ', 'GAN acc 0.5469', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4941', 'Total loss: 1.3863', 'for batch', 11)
('GAN loss 0.6864 ', 'GAN acc 0.5781', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5371', 'Total loss: 1.3773', 'for batch', 12)
('GAN loss 0.6919 ', 'GAN acc 0.5547', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5195', 'Total loss: 1.3833', 'for batch', 13)
('GAN loss 0.6974 ', 'GAN acc 0.4336', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5039', 'Total loss: 1.3911', 'for batch', 14)
('GAN loss 0.6981 ', 'GAN acc 0.4727', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4941', 'Total loss: 1.3913', 'for batch', 15)
('GAN loss 0.6968 ', 'GAN acc 0.5078', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5176', 'Total loss: 1.3877', 'for batch', 16)
('GAN loss 0.6949 ', 'GAN acc 0.4766', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4727', 'Total loss: 1.3917', 'for batch', 17)
('GAN loss 0.6943 ', 'GAN acc 0.4805', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4902', 'Total loss: 1.3877', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50987375)
('DISCRIMINATOR_Imagem FAKE=', 0.50993901)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.038749')
----------------------------------
('Epoch', 39, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6951 ', 'GAN acc 0.5195', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4824', 'Total loss: 1.3916', 'for batch', 0)
('GAN loss 0.6975 ', 'GAN acc 0.4492', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4902', 'Total loss: 1.3924', 'for batch', 1)
('GAN loss 0.6949 ', 'GAN acc 0.5117', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5234', 'Total loss: 1.3861', 'for batch', 2)
('GAN loss 0.6961 ', 'GAN acc 0.4414', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5020', 'Total loss: 1.3898', 'for batch', 3)
('GAN loss 0.6913 ', 'GAN acc 0.5469', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4785', 'Total loss: 1.3865', 'for batch', 4)
('GAN loss 0.6916 ', 'GAN acc 0.5430', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4727', 'Total loss: 1.3892', 'for batch', 5)
('GAN loss 0.6954 ', 'GAN acc 0.4727', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5273', 'Total loss: 1.3885', 'for batch', 6)
('GAN loss 0.6905 ', 'GAN acc 0.5703', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5059', 'Total loss: 1.3846', 'for batch', 7)
('GAN loss 0.6918 ', 'GAN acc 0.5273', 'Discriminator loss 0.6894', 'Discriminator accuracy 0.5469', 'Total loss: 1.3812', 'for batch', 8)
('GAN loss 0.6847 ', 'GAN acc 0.6484', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5195', 'Total loss: 1.3774', 'for batch', 9)
('GAN loss 0.6852 ', 'GAN acc 0.5898', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4824', 'Total loss: 1.3797', 'for batch', 10)
('GAN loss 0.6850 ', 'GAN acc 0.6172', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4941', 'Total loss: 1.3800', 'for batch', 11)
('GAN loss 0.6847 ', 'GAN acc 0.6406', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4922', 'Total loss: 1.3806', 'for batch', 12)
('GAN loss 0.6935 ', 'GAN acc 0.5273', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4746', 'Total loss: 1.3906', 'for batch', 13)
('GAN loss 0.6963 ', 'GAN acc 0.4844', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4570', 'Total loss: 1.3929', 'for batch', 14)
('GAN loss 0.6950 ', 'GAN acc 0.4648', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5273', 'Total loss: 1.3884', 'for batch', 15)
('GAN loss 0.6978 ', 'GAN acc 0.4766', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5176', 'Total loss: 1.3899', 'for batch', 16)
('GAN loss 0.6994 ', 'GAN acc 0.4336', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4766', 'Total loss: 1.3941', 'for batch', 17)
('GAN loss 0.6995 ', 'GAN acc 0.4336', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5215', 'Total loss: 1.3918', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.50859839)
('DISCRIMINATOR_Imagem FAKE=', 0.5089522)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.352592')
----------------------------------
('Epoch', 40, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6978 ', 'GAN acc 0.4766', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4941', 'Total loss: 1.3924', 'for batch', 0)
('GAN loss 0.6985 ', 'GAN acc 0.4297', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.4922', 'Total loss: 1.3911', 'for batch', 1)
('GAN loss 0.6998 ', 'GAN acc 0.4258', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5039', 'Total loss: 1.3942', 'for batch', 2)
('GAN loss 0.7007 ', 'GAN acc 0.4219', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5059', 'Total loss: 1.3944', 'for batch', 3)
('GAN loss 0.6953 ', 'GAN acc 0.4766', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4746', 'Total loss: 1.3925', 'for batch', 4)
('GAN loss 0.6976 ', 'GAN acc 0.4648', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5605', 'Total loss: 1.3886', 'for batch', 5)
('GAN loss 0.6941 ', 'GAN acc 0.5039', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4570', 'Total loss: 1.3886', 'for batch', 6)
('GAN loss 0.6862 ', 'GAN acc 0.6016', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4707', 'Total loss: 1.3837', 'for batch', 7)
('GAN loss 0.6924 ', 'GAN acc 0.4961', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4746', 'Total loss: 1.3888', 'for batch', 8)
('GAN loss 0.6922 ', 'GAN acc 0.5430', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4961', 'Total loss: 1.3869', 'for batch', 9)
('GAN loss 0.6892 ', 'GAN acc 0.5547', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3856', 'for batch', 10)
('GAN loss 0.6906 ', 'GAN acc 0.5312', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4844', 'Total loss: 1.3855', 'for batch', 11)
('GAN loss 0.6935 ', 'GAN acc 0.4844', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5000', 'Total loss: 1.3872', 'for batch', 12)
('GAN loss 0.6905 ', 'GAN acc 0.5508', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4863', 'Total loss: 1.3863', 'for batch', 13)
('GAN loss 0.6888 ', 'GAN acc 0.5703', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5000', 'Total loss: 1.3820', 'for batch', 14)
('GAN loss 0.6881 ', 'GAN acc 0.5312', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5117', 'Total loss: 1.3802', 'for batch', 15)
('GAN loss 0.6908 ', 'GAN acc 0.5312', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4922', 'Total loss: 1.3841', 'for batch', 16)
('GAN loss 0.6906 ', 'GAN acc 0.5430', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5273', 'Total loss: 1.3846', 'for batch', 17)
('GAN loss 0.6887 ', 'GAN acc 0.5547', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5039', 'Total loss: 1.3800', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51267129)
('DISCRIMINATOR_Imagem FAKE=', 0.51301396)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.819664')
----------------------------------
('Epoch', 41, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6907 ', 'GAN acc 0.5391', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.4902', 'Total loss: 1.3840', 'for batch', 0)
('GAN loss 0.6907 ', 'GAN acc 0.5352', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4863', 'Total loss: 1.3855', 'for batch', 1)
('GAN loss 0.6971 ', 'GAN acc 0.4805', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4570', 'Total loss: 1.3943', 'for batch', 2)
('GAN loss 0.6995 ', 'GAN acc 0.3867', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5234', 'Total loss: 1.3926', 'for batch', 3)
('GAN loss 0.6968 ', 'GAN acc 0.4648', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4688', 'Total loss: 1.3923', 'for batch', 4)
('GAN loss 0.6994 ', 'GAN acc 0.4141', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4746', 'Total loss: 1.3965', 'for batch', 5)
('GAN loss 0.6943 ', 'GAN acc 0.5234', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5039', 'Total loss: 1.3877', 'for batch', 6)
('GAN loss 0.6983 ', 'GAN acc 0.4453', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5000', 'Total loss: 1.3909', 'for batch', 7)
('GAN loss 0.7006 ', 'GAN acc 0.4570', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4668', 'Total loss: 1.3963', 'for batch', 8)
('GAN loss 0.6900 ', 'GAN acc 0.5469', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5137', 'Total loss: 1.3826', 'for batch', 9)
('GAN loss 0.6946 ', 'GAN acc 0.5156', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4883', 'Total loss: 1.3881', 'for batch', 10)
('GAN loss 0.6931 ', 'GAN acc 0.5312', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5156', 'Total loss: 1.3854', 'for batch', 11)
('GAN loss 0.6917 ', 'GAN acc 0.5391', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5137', 'Total loss: 1.3840', 'for batch', 12)
('GAN loss 0.6887 ', 'GAN acc 0.5742', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5488', 'Total loss: 1.3780', 'for batch', 13)
('GAN loss 0.6926 ', 'GAN acc 0.5156', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5449', 'Total loss: 1.3853', 'for batch', 14)
('GAN loss 0.6933 ', 'GAN acc 0.4961', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4766', 'Total loss: 1.3888', 'for batch', 15)
('GAN loss 0.6949 ', 'GAN acc 0.5273', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5059', 'Total loss: 1.3879', 'for batch', 16)
('GAN loss 0.6953 ', 'GAN acc 0.4648', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4863', 'Total loss: 1.3908', 'for batch', 17)
('GAN loss 0.6952 ', 'GAN acc 0.4922', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5176', 'Total loss: 1.3885', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51053888)
('DISCRIMINATOR_Imagem FAKE=', 0.51086289)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.428807')
----------------------------------
('Epoch', 42, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6981 ', 'GAN acc 0.4688', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5234', 'Total loss: 1.3908', 'for batch', 0)
('GAN loss 0.6951 ', 'GAN acc 0.4922', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5039', 'Total loss: 1.3886', 'for batch', 1)
('GAN loss 0.6958 ', 'GAN acc 0.5039', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5176', 'Total loss: 1.3910', 'for batch', 2)
('GAN loss 0.7020 ', 'GAN acc 0.4062', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5059', 'Total loss: 1.3952', 'for batch', 3)
('GAN loss 0.6952 ', 'GAN acc 0.4727', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5508', 'Total loss: 1.3852', 'for batch', 4)
('GAN loss 0.6983 ', 'GAN acc 0.4570', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5215', 'Total loss: 1.3913', 'for batch', 5)
('GAN loss 0.6908 ', 'GAN acc 0.5430', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5137', 'Total loss: 1.3841', 'for batch', 6)
('GAN loss 0.6988 ', 'GAN acc 0.4609', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5137', 'Total loss: 1.3921', 'for batch', 7)
('GAN loss 0.6953 ', 'GAN acc 0.4922', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5020', 'Total loss: 1.3873', 'for batch', 8)
('GAN loss 0.6947 ', 'GAN acc 0.4766', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.4941', 'Total loss: 1.3883', 'for batch', 9)
('GAN loss 0.6911 ', 'GAN acc 0.5078', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4961', 'Total loss: 1.3863', 'for batch', 10)
('GAN loss 0.6895 ', 'GAN acc 0.5430', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5176', 'Total loss: 1.3828', 'for batch', 11)
('GAN loss 0.6918 ', 'GAN acc 0.5352', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4961', 'Total loss: 1.3852', 'for batch', 12)
('GAN loss 0.6861 ', 'GAN acc 0.6016', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5039', 'Total loss: 1.3802', 'for batch', 13)
('GAN loss 0.6849 ', 'GAN acc 0.6133', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4863', 'Total loss: 1.3790', 'for batch', 14)
('GAN loss 0.6934 ', 'GAN acc 0.5117', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5020', 'Total loss: 1.3870', 'for batch', 15)
('GAN loss 0.6915 ', 'GAN acc 0.5352', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5000', 'Total loss: 1.3850', 'for batch', 16)
('GAN loss 0.6870 ', 'GAN acc 0.6172', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5078', 'Total loss: 1.3812', 'for batch', 17)
('GAN loss 0.6852 ', 'GAN acc 0.6094', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4453', 'Total loss: 1.3815', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51284921)
('DISCRIMINATOR_Imagem FAKE=', 0.51319039)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.877592')
----------------------------------
('Epoch', 43, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6890 ', 'GAN acc 0.5664', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5098', 'Total loss: 1.3808', 'for batch', 0)
('GAN loss 0.6944 ', 'GAN acc 0.4570', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4902', 'Total loss: 1.3879', 'for batch', 1)
('GAN loss 0.6968 ', 'GAN acc 0.4844', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5156', 'Total loss: 1.3914', 'for batch', 2)
('GAN loss 0.6928 ', 'GAN acc 0.5078', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4492', 'Total loss: 1.3889', 'for batch', 3)
('GAN loss 0.6964 ', 'GAN acc 0.4922', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5273', 'Total loss: 1.3881', 'for batch', 4)
('GAN loss 0.6992 ', 'GAN acc 0.4141', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5117', 'Total loss: 1.3933', 'for batch', 5)
('GAN loss 0.6918 ', 'GAN acc 0.5312', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4824', 'Total loss: 1.3869', 'for batch', 6)
('GAN loss 0.6995 ', 'GAN acc 0.4414', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5137', 'Total loss: 1.3937', 'for batch', 7)
('GAN loss 0.6921 ', 'GAN acc 0.5039', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5176', 'Total loss: 1.3839', 'for batch', 8)
('GAN loss 0.6936 ', 'GAN acc 0.5000', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4980', 'Total loss: 1.3887', 'for batch', 9)
('GAN loss 0.6951 ', 'GAN acc 0.4766', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5000', 'Total loss: 1.3867', 'for batch', 10)
('GAN loss 0.6910 ', 'GAN acc 0.5352', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5156', 'Total loss: 1.3839', 'for batch', 11)
('GAN loss 0.6929 ', 'GAN acc 0.5312', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.4980', 'Total loss: 1.3851', 'for batch', 12)
('GAN loss 0.6995 ', 'GAN acc 0.4453', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4766', 'Total loss: 1.3947', 'for batch', 13)
('GAN loss 0.6997 ', 'GAN acc 0.4805', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.4805', 'Total loss: 1.3937', 'for batch', 14)
('GAN loss 0.6993 ', 'GAN acc 0.4609', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4805', 'Total loss: 1.3942', 'for batch', 15)
('GAN loss 0.6991 ', 'GAN acc 0.4258', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4824', 'Total loss: 1.3939', 'for batch', 16)
('GAN loss 0.6993 ', 'GAN acc 0.4453', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4980', 'Total loss: 1.3950', 'for batch', 17)
('GAN loss 0.6971 ', 'GAN acc 0.4648', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5195', 'Total loss: 1.3904', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51044267)
('DISCRIMINATOR_Imagem FAKE=', 0.51104498)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.433146')
----------------------------------
('Epoch', 44, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6981 ', 'GAN acc 0.4492', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4902', 'Total loss: 1.3921', 'for batch', 0)
('GAN loss 0.7048 ', 'GAN acc 0.4141', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4883', 'Total loss: 1.3993', 'for batch', 1)
('GAN loss 0.7031 ', 'GAN acc 0.4141', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5039', 'Total loss: 1.3938', 'for batch', 2)
('GAN loss 0.7034 ', 'GAN acc 0.3789', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5020', 'Total loss: 1.3959', 'for batch', 3)
('GAN loss 0.6948 ', 'GAN acc 0.4727', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5078', 'Total loss: 1.3879', 'for batch', 4)
('GAN loss 0.6927 ', 'GAN acc 0.5039', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4844', 'Total loss: 1.3877', 'for batch', 5)
('GAN loss 0.6892 ', 'GAN acc 0.5625', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4316', 'Total loss: 1.3863', 'for batch', 6)
('GAN loss 0.6908 ', 'GAN acc 0.5586', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4863', 'Total loss: 1.3855', 'for batch', 7)
('GAN loss 0.6898 ', 'GAN acc 0.5664', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4883', 'Total loss: 1.3840', 'for batch', 8)
('GAN loss 0.6866 ', 'GAN acc 0.5938', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5059', 'Total loss: 1.3794', 'for batch', 9)
('GAN loss 0.6879 ', 'GAN acc 0.5664', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5078', 'Total loss: 1.3812', 'for batch', 10)
('GAN loss 0.6873 ', 'GAN acc 0.5820', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5254', 'Total loss: 1.3803', 'for batch', 11)
('GAN loss 0.6861 ', 'GAN acc 0.6445', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4727', 'Total loss: 1.3799', 'for batch', 12)
('GAN loss 0.6891 ', 'GAN acc 0.5625', 'Discriminator loss 0.6933', 'Discriminator accuracy 0.5156', 'Total loss: 1.3825', 'for batch', 13)
('GAN loss 0.6905 ', 'GAN acc 0.5195', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5059', 'Total loss: 1.3836', 'for batch', 14)
('GAN loss 0.6948 ', 'GAN acc 0.5195', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4707', 'Total loss: 1.3901', 'for batch', 15)
('GAN loss 0.6901 ', 'GAN acc 0.5703', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4629', 'Total loss: 1.3850', 'for batch', 16)
('GAN loss 0.6929 ', 'GAN acc 0.5117', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4863', 'Total loss: 1.3860', 'for batch', 17)
('GAN loss 0.6936 ', 'GAN acc 0.4688', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.4961', 'Total loss: 1.3875', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51332265)
('DISCRIMINATOR_Imagem FAKE=', 0.51316482)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.841523')
----------------------------------
('Epoch', 45, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6904 ', 'GAN acc 0.5312', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4863', 'Total loss: 1.3856', 'for batch', 0)
('GAN loss 0.6965 ', 'GAN acc 0.4492', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4922', 'Total loss: 1.3913', 'for batch', 1)
('GAN loss 0.6984 ', 'GAN acc 0.4766', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5215', 'Total loss: 1.3909', 'for batch', 2)
('GAN loss 0.6935 ', 'GAN acc 0.5039', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5137', 'Total loss: 1.3856', 'for batch', 3)
('GAN loss 0.6964 ', 'GAN acc 0.4805', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4922', 'Total loss: 1.3910', 'for batch', 4)
('GAN loss 0.6910 ', 'GAN acc 0.5703', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4883', 'Total loss: 1.3862', 'for batch', 5)
('GAN loss 0.6932 ', 'GAN acc 0.5039', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4902', 'Total loss: 1.3901', 'for batch', 6)
('GAN loss 0.6918 ', 'GAN acc 0.5586', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5078', 'Total loss: 1.3861', 'for batch', 7)
('GAN loss 0.6954 ', 'GAN acc 0.5195', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4922', 'Total loss: 1.3905', 'for batch', 8)
('GAN loss 0.6939 ', 'GAN acc 0.5156', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4570', 'Total loss: 1.3907', 'for batch', 9)
('GAN loss 0.6966 ', 'GAN acc 0.4688', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4961', 'Total loss: 1.3917', 'for batch', 10)
('GAN loss 0.6968 ', 'GAN acc 0.4648', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4551', 'Total loss: 1.3926', 'for batch', 11)
('GAN loss 0.6990 ', 'GAN acc 0.4453', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5352', 'Total loss: 1.3903', 'for batch', 12)
('GAN loss 0.7005 ', 'GAN acc 0.4414', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4512', 'Total loss: 1.3977', 'for batch', 13)
('GAN loss 0.6965 ', 'GAN acc 0.4727', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4766', 'Total loss: 1.3911', 'for batch', 14)
('GAN loss 0.7005 ', 'GAN acc 0.4492', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5332', 'Total loss: 1.3930', 'for batch', 15)
('GAN loss 0.7011 ', 'GAN acc 0.4336', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5117', 'Total loss: 1.3943', 'for batch', 16)
('GAN loss 0.7025 ', 'GAN acc 0.3867', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4766', 'Total loss: 1.3983', 'for batch', 17)
('GAN loss 0.7020 ', 'GAN acc 0.3828', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4785', 'Total loss: 1.3961', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51187199)
('DISCRIMINATOR_Imagem FAKE=', 0.51143563)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.488292')
----------------------------------
('Epoch', 46, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6976 ', 'GAN acc 0.4141', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4883', 'Total loss: 1.3909', 'for batch', 0)
('GAN loss 0.6942 ', 'GAN acc 0.4922', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5078', 'Total loss: 1.3868', 'for batch', 1)
('GAN loss 0.6943 ', 'GAN acc 0.5312', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5312', 'Total loss: 1.3846', 'for batch', 2)
('GAN loss 0.6972 ', 'GAN acc 0.4570', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5195', 'Total loss: 1.3894', 'for batch', 3)
('GAN loss 0.6945 ', 'GAN acc 0.5273', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5234', 'Total loss: 1.3854', 'for batch', 4)
('GAN loss 0.6932 ', 'GAN acc 0.5156', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4668', 'Total loss: 1.3877', 'for batch', 5)
('GAN loss 0.6919 ', 'GAN acc 0.5156', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5215', 'Total loss: 1.3845', 'for batch', 6)
('GAN loss 0.6873 ', 'GAN acc 0.5859', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5195', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6883 ', 'GAN acc 0.5977', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4941', 'Total loss: 1.3834', 'for batch', 8)
('GAN loss 0.6839 ', 'GAN acc 0.5742', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4941', 'Total loss: 1.3782', 'for batch', 9)
('GAN loss 0.6831 ', 'GAN acc 0.6250', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5293', 'Total loss: 1.3750', 'for batch', 10)
('GAN loss 0.6867 ', 'GAN acc 0.5938', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5059', 'Total loss: 1.3805', 'for batch', 11)
('GAN loss 0.6857 ', 'GAN acc 0.6055', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5059', 'Total loss: 1.3789', 'for batch', 12)
('GAN loss 0.6897 ', 'GAN acc 0.5430', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4668', 'Total loss: 1.3865', 'for batch', 13)
('GAN loss 0.6929 ', 'GAN acc 0.4883', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4727', 'Total loss: 1.3874', 'for batch', 14)
('GAN loss 0.6947 ', 'GAN acc 0.5078', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5195', 'Total loss: 1.3877', 'for batch', 15)
('GAN loss 0.6913 ', 'GAN acc 0.5547', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5254', 'Total loss: 1.3816', 'for batch', 16)
('GAN loss 0.6928 ', 'GAN acc 0.5195', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5332', 'Total loss: 1.3854', 'for batch', 17)
('GAN loss 0.6946 ', 'GAN acc 0.4727', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5059', 'Total loss: 1.3877', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51412451)
('DISCRIMINATOR_Imagem FAKE=', 0.51414925)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.857467')
----------------------------------
('Epoch', 47, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6990 ', 'GAN acc 0.4219', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5469', 'Total loss: 1.3905', 'for batch', 0)
('GAN loss 0.6996 ', 'GAN acc 0.4414', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4961', 'Total loss: 1.3928', 'for batch', 1)
('GAN loss 0.6978 ', 'GAN acc 0.4766', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4609', 'Total loss: 1.3938', 'for batch', 2)
('GAN loss 0.7004 ', 'GAN acc 0.4414', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5059', 'Total loss: 1.3941', 'for batch', 3)
('GAN loss 0.6962 ', 'GAN acc 0.5156', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4805', 'Total loss: 1.3917', 'for batch', 4)
('GAN loss 0.7008 ', 'GAN acc 0.4141', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.4805', 'Total loss: 1.3959', 'for batch', 5)
('GAN loss 0.7037 ', 'GAN acc 0.4023', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4883', 'Total loss: 1.3980', 'for batch', 6)
('GAN loss 0.7005 ', 'GAN acc 0.4180', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5156', 'Total loss: 1.3933', 'for batch', 7)
('GAN loss 0.7042 ', 'GAN acc 0.3711', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5469', 'Total loss: 1.3963', 'for batch', 8)
('GAN loss 0.6996 ', 'GAN acc 0.4102', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5020', 'Total loss: 1.3936', 'for batch', 9)
('GAN loss 0.6979 ', 'GAN acc 0.4688', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4844', 'Total loss: 1.3909', 'for batch', 10)
('GAN loss 0.7008 ', 'GAN acc 0.4453', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5137', 'Total loss: 1.3947', 'for batch', 11)
('GAN loss 0.6945 ', 'GAN acc 0.5352', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4961', 'Total loss: 1.3877', 'for batch', 12)
('GAN loss 0.6965 ', 'GAN acc 0.4766', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4824', 'Total loss: 1.3925', 'for batch', 13)
('GAN loss 0.6948 ', 'GAN acc 0.4922', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4941', 'Total loss: 1.3902', 'for batch', 14)
('GAN loss 0.6922 ', 'GAN acc 0.5586', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5059', 'Total loss: 1.3852', 'for batch', 15)
('GAN loss 0.6909 ', 'GAN acc 0.5352', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4805', 'Total loss: 1.3855', 'for batch', 16)
('GAN loss 0.6885 ', 'GAN acc 0.5586', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5312', 'Total loss: 1.3804', 'for batch', 17)
('GAN loss 0.6869 ', 'GAN acc 0.5898', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5410', 'Total loss: 1.3779', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5142858)
('DISCRIMINATOR_Imagem FAKE=', 0.51446426)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.401431')
----------------------------------
('Epoch', 48, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6864 ', 'GAN acc 0.5742', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3828', 'for batch', 0)
('GAN loss 0.6871 ', 'GAN acc 0.5977', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5039', 'Total loss: 1.3808', 'for batch', 1)
('GAN loss 0.6908 ', 'GAN acc 0.5156', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.4941', 'Total loss: 1.3833', 'for batch', 2)
('GAN loss 0.6864 ', 'GAN acc 0.5938', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5332', 'Total loss: 1.3782', 'for batch', 3)
('GAN loss 0.6914 ', 'GAN acc 0.5273', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4551', 'Total loss: 1.3893', 'for batch', 4)
('GAN loss 0.6896 ', 'GAN acc 0.5625', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4609', 'Total loss: 1.3866', 'for batch', 5)
('GAN loss 0.6882 ', 'GAN acc 0.5742', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.4922', 'Total loss: 1.3812', 'for batch', 6)
('GAN loss 0.6929 ', 'GAN acc 0.5039', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3866', 'for batch', 7)
('GAN loss 0.6880 ', 'GAN acc 0.6133', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.4922', 'Total loss: 1.3798', 'for batch', 8)
('GAN loss 0.6907 ', 'GAN acc 0.5469', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.4961', 'Total loss: 1.3831', 'for batch', 9)
('GAN loss 0.6920 ', 'GAN acc 0.5234', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5000', 'Total loss: 1.3866', 'for batch', 10)
('GAN loss 0.6924 ', 'GAN acc 0.5391', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5000', 'Total loss: 1.3852', 'for batch', 11)
('GAN loss 0.6935 ', 'GAN acc 0.5000', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5488', 'Total loss: 1.3853', 'for batch', 12)
('GAN loss 0.6925 ', 'GAN acc 0.4922', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5156', 'Total loss: 1.3862', 'for batch', 13)
('GAN loss 0.6976 ', 'GAN acc 0.4531', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4883', 'Total loss: 1.3919', 'for batch', 14)
('GAN loss 0.7000 ', 'GAN acc 0.4219', 'Discriminator loss 0.6926', 'Discriminator accuracy 0.5000', 'Total loss: 1.3926', 'for batch', 15)
('GAN loss 0.7015 ', 'GAN acc 0.3984', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5195', 'Total loss: 1.3932', 'for batch', 16)
('GAN loss 0.7004 ', 'GAN acc 0.4258', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5098', 'Total loss: 1.3938', 'for batch', 17)
('GAN loss 0.7029 ', 'GAN acc 0.4102', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4746', 'Total loss: 1.3975', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51000053)
('DISCRIMINATOR_Imagem FAKE=', 0.51113987)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.869474')
----------------------------------
('Epoch', 49, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7047 ', 'GAN acc 0.4062', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.4902', 'Total loss: 1.3993', 'for batch', 0)
('GAN loss 0.7065 ', 'GAN acc 0.3672', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4492', 'Total loss: 1.4035', 'for batch', 1)
('GAN loss 0.7069 ', 'GAN acc 0.3320', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5020', 'Total loss: 1.4000', 'for batch', 2)
('GAN loss 0.7052 ', 'GAN acc 0.3633', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4824', 'Total loss: 1.4003', 'for batch', 3)
('GAN loss 0.7017 ', 'GAN acc 0.4219', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5000', 'Total loss: 1.3969', 'for batch', 4)
('GAN loss 0.6997 ', 'GAN acc 0.4062', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5176', 'Total loss: 1.3917', 'for batch', 5)
('GAN loss 0.6947 ', 'GAN acc 0.4805', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5371', 'Total loss: 1.3893', 'for batch', 6)
('GAN loss 0.6928 ', 'GAN acc 0.5156', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5156', 'Total loss: 1.3870', 'for batch', 7)
('GAN loss 0.6913 ', 'GAN acc 0.5508', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.4941', 'Total loss: 1.3848', 'for batch', 8)
('GAN loss 0.6855 ', 'GAN acc 0.5977', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4941', 'Total loss: 1.3797', 'for batch', 9)
('GAN loss 0.6852 ', 'GAN acc 0.5938', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4805', 'Total loss: 1.3801', 'for batch', 10)
('GAN loss 0.6820 ', 'GAN acc 0.6680', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4863', 'Total loss: 1.3764', 'for batch', 11)
('GAN loss 0.6802 ', 'GAN acc 0.6523', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4824', 'Total loss: 1.3750', 'for batch', 12)
('GAN loss 0.6805 ', 'GAN acc 0.6562', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5156', 'Total loss: 1.3734', 'for batch', 13)
('GAN loss 0.6793 ', 'GAN acc 0.6680', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.4785', 'Total loss: 1.3750', 'for batch', 14)
('GAN loss 0.6784 ', 'GAN acc 0.6914', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.4941', 'Total loss: 1.3725', 'for batch', 15)
('GAN loss 0.6802 ', 'GAN acc 0.6836', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5117', 'Total loss: 1.3717', 'for batch', 16)
('GAN loss 0.6766 ', 'GAN acc 0.7266', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5117', 'Total loss: 1.3712', 'for batch', 17)
('GAN loss 0.6809 ', 'GAN acc 0.6758', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4824', 'Total loss: 1.3764', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51711649)
('DISCRIMINATOR_Imagem FAKE=', 0.51766217)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.431176')
----------------------------------
('Epoch', 50, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6813 ', 'GAN acc 0.6602', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5273', 'Total loss: 1.3737', 'for batch', 0)
('GAN loss 0.6840 ', 'GAN acc 0.5859', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5137', 'Total loss: 1.3785', 'for batch', 1)
('GAN loss 0.6904 ', 'GAN acc 0.5273', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4883', 'Total loss: 1.3848', 'for batch', 2)
('GAN loss 0.6914 ', 'GAN acc 0.4961', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5078', 'Total loss: 1.3834', 'for batch', 3)
('GAN loss 0.6945 ', 'GAN acc 0.5078', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4980', 'Total loss: 1.3895', 'for batch', 4)
('GAN loss 0.7042 ', 'GAN acc 0.3633', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5215', 'Total loss: 1.3981', 'for batch', 5)
('GAN loss 0.7073 ', 'GAN acc 0.3594', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.4883', 'Total loss: 1.4024', 'for batch', 6)
('GAN loss 0.7059 ', 'GAN acc 0.3633', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5195', 'Total loss: 1.3991', 'for batch', 7)
('GAN loss 0.7060 ', 'GAN acc 0.3789', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5312', 'Total loss: 1.3967', 'for batch', 8)
('GAN loss 0.7088 ', 'GAN acc 0.3398', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.4037', 'for batch', 9)
('GAN loss 0.7059 ', 'GAN acc 0.3672', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4531', 'Total loss: 1.4036', 'for batch', 10)
('GAN loss 0.7064 ', 'GAN acc 0.3203', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5078', 'Total loss: 1.4000', 'for batch', 11)
('GAN loss 0.6990 ', 'GAN acc 0.4453', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5000', 'Total loss: 1.3937', 'for batch', 12)
('GAN loss 0.6979 ', 'GAN acc 0.4727', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5137', 'Total loss: 1.3904', 'for batch', 13)
('GAN loss 0.6916 ', 'GAN acc 0.5547', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4824', 'Total loss: 1.3869', 'for batch', 14)
('GAN loss 0.6906 ', 'GAN acc 0.5781', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3843', 'for batch', 15)
('GAN loss 0.6906 ', 'GAN acc 0.5547', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4746', 'Total loss: 1.3861', 'for batch', 16)
('GAN loss 0.6901 ', 'GAN acc 0.5156', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3838', 'for batch', 17)
('GAN loss 0.6900 ', 'GAN acc 0.5742', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4922', 'Total loss: 1.3838', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5135349)
('DISCRIMINATOR_Imagem FAKE=', 0.5135386)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.906450')
----------------------------------
End of training
Saving histograms
----------------------------------
('Total samples = ', 5000, ' Batch size =', 256, ' Epochs = ', 50)
('Generator loss 0.6900 ', 'Discriminator loss 0.6937', 'Total: 1.3838')
----------------------------------
---DISCRIMINATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_14 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_3[0][0]      
____________________________________________________________________________________________________
leakyrelu_14 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_14[0][0]           
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 16, 16, 16)    0           leakyrelu_14[0][0]               
____________________________________________________________________________________________________
convolution2d_15 (Convolution2D) (None, 32, 8, 8)      4640        dropout_6[0][0]                  
____________________________________________________________________________________________________
leakyrelu_15 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_15[0][0]           
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 32, 8, 8)      0           leakyrelu_15[0][0]               
____________________________________________________________________________________________________
convolution2d_16 (Convolution2D) (None, 64, 4, 4)      18496       dropout_7[0][0]                  
____________________________________________________________________________________________________
leakyrelu_16 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_16[0][0]           
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 64, 4, 4)      0           leakyrelu_16[0][0]               
____________________________________________________________________________________________________
convolution2d_17 (Convolution2D) (None, 128, 2, 2)     73856       dropout_8[0][0]                  
____________________________________________________________________________________________________
leakyrelu_17 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_17[0][0]           
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 128, 2, 2)     0           leakyrelu_17[0][0]               
____________________________________________________________________________________________________
flatten_2 (Flatten)              (None, 512)           0           dropout_9[0][0]                  
____________________________________________________________________________________________________
dense_3 (Dense)                  (None, 256)           131328      flatten_2[0][0]                  
____________________________________________________________________________________________________
leakyrelu_18 (LeakyReLU)         (None, 256)           0           dense_3[0][0]                    
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 256)           0           leakyrelu_18[0][0]               
____________________________________________________________________________________________________
dense_4 (Dense)                  (None, 1)             257         dropout_10[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
None
----------------------------------
---GENERATOR---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_18 (Convolution2D) (None, 32, 32, 32)    320         convolution2d_input_4[0][0]      
____________________________________________________________________________________________________
leakyrelu_19 (LeakyReLU)         (None, 32, 32, 32)    0           convolution2d_18[0][0]           
____________________________________________________________________________________________________
convolution2d_19 (Convolution2D) (None, 64, 32, 32)    18496       leakyrelu_19[0][0]               
____________________________________________________________________________________________________
batchnormalization_8 (BatchNormal(None, 64, 32, 32)    128         convolution2d_19[0][0]           
____________________________________________________________________________________________________
leakyrelu_20 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_8[0][0]       
____________________________________________________________________________________________________
convolution2d_20 (Convolution2D) (None, 128, 32, 32)   73856       leakyrelu_20[0][0]               
____________________________________________________________________________________________________
batchnormalization_9 (BatchNormal(None, 128, 32, 32)   256         convolution2d_20[0][0]           
____________________________________________________________________________________________________
leakyrelu_21 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_9[0][0]       
____________________________________________________________________________________________________
convolution2d_21 (Convolution2D) (None, 256, 32, 32)   295168      leakyrelu_21[0][0]               
____________________________________________________________________________________________________
batchnormalization_10 (BatchNorma(None, 256, 32, 32)   512         convolution2d_21[0][0]           
____________________________________________________________________________________________________
leakyrelu_22 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_10[0][0]      
____________________________________________________________________________________________________
convolution2d_22 (Convolution2D) (None, 256, 32, 32)   590080      leakyrelu_22[0][0]               
____________________________________________________________________________________________________
batchnormalization_11 (BatchNorma(None, 256, 32, 32)   512         convolution2d_22[0][0]           
____________________________________________________________________________________________________
leakyrelu_23 (LeakyReLU)         (None, 256, 32, 32)   0           batchnormalization_11[0][0]      
____________________________________________________________________________________________________
convolution2d_23 (Convolution2D) (None, 128, 32, 32)   295040      leakyrelu_23[0][0]               
____________________________________________________________________________________________________
batchnormalization_12 (BatchNorma(None, 128, 32, 32)   256         convolution2d_23[0][0]           
____________________________________________________________________________________________________
leakyrelu_24 (LeakyReLU)         (None, 128, 32, 32)   0           batchnormalization_12[0][0]      
____________________________________________________________________________________________________
convolution2d_24 (Convolution2D) (None, 64, 32, 32)    73792       leakyrelu_24[0][0]               
____________________________________________________________________________________________________
batchnormalization_13 (BatchNorma(None, 64, 32, 32)    128         convolution2d_24[0][0]           
____________________________________________________________________________________________________
leakyrelu_25 (LeakyReLU)         (None, 64, 32, 32)    0           batchnormalization_13[0][0]      
____________________________________________________________________________________________________
convolution2d_25 (Convolution2D) (None, 32, 32, 32)    18464       leakyrelu_25[0][0]               
____________________________________________________________________________________________________
batchnormalization_14 (BatchNorma(None, 32, 32, 32)    64          convolution2d_25[0][0]           
____________________________________________________________________________________________________
leakyrelu_26 (LeakyReLU)         (None, 32, 32, 32)    0           batchnormalization_14[0][0]      
____________________________________________________________________________________________________
convolution2d_26 (Convolution2D) (None, 2, 32, 32)     578         leakyrelu_26[0][0]               
____________________________________________________________________________________________________
lambda_2 (Lambda)                (None, 2, 32, 32)     0           convolution2d_26[0][0]           
====================================================================================================
Total params: 1367650
____________________________________________________________________________________________________
None
----------------------------------
---GAN---
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_5 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_4 (Sequential)        (None, 1)             228881      lambda_2[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
None
----------------------------------
('Training with dataset based on class - ', 'bird', 'with', 5000, 'samples')
----------------------------------
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
sequential_8 (Sequential)        (None, 2, 32, 32)     1367650                                      
____________________________________________________________________________________________________
sequential_7 (Sequential)        (None, 1)             0           lambda_3[0][0]                   
====================================================================================================
Total params: 1596531
____________________________________________________________________________________________________
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
convolution2d_27 (Convolution2D) (None, 16, 16, 16)    304         convolution2d_input_5[0][0]      
____________________________________________________________________________________________________
leakyrelu_27 (LeakyReLU)         (None, 16, 16, 16)    0           convolution2d_27[0][0]           
____________________________________________________________________________________________________
dropout_11 (Dropout)             (None, 16, 16, 16)    0           leakyrelu_27[0][0]               
____________________________________________________________________________________________________
convolution2d_28 (Convolution2D) (None, 32, 8, 8)      4640        dropout_11[0][0]                 
____________________________________________________________________________________________________
leakyrelu_28 (LeakyReLU)         (None, 32, 8, 8)      0           convolution2d_28[0][0]           
____________________________________________________________________________________________________
dropout_12 (Dropout)             (None, 32, 8, 8)      0           leakyrelu_28[0][0]               
____________________________________________________________________________________________________
convolution2d_29 (Convolution2D) (None, 64, 4, 4)      18496       dropout_12[0][0]                 
____________________________________________________________________________________________________
leakyrelu_29 (LeakyReLU)         (None, 64, 4, 4)      0           convolution2d_29[0][0]           
____________________________________________________________________________________________________
dropout_13 (Dropout)             (None, 64, 4, 4)      0           leakyrelu_29[0][0]               
____________________________________________________________________________________________________
convolution2d_30 (Convolution2D) (None, 128, 2, 2)     73856       dropout_13[0][0]                 
____________________________________________________________________________________________________
leakyrelu_30 (LeakyReLU)         (None, 128, 2, 2)     0           convolution2d_30[0][0]           
____________________________________________________________________________________________________
dropout_14 (Dropout)             (None, 128, 2, 2)     0           leakyrelu_30[0][0]               
____________________________________________________________________________________________________
flatten_3 (Flatten)              (None, 512)           0           dropout_14[0][0]                 
____________________________________________________________________________________________________
dense_5 (Dense)                  (None, 256)           131328      flatten_3[0][0]                  
____________________________________________________________________________________________________
leakyrelu_31 (LeakyReLU)         (None, 256)           0           dense_5[0][0]                    
____________________________________________________________________________________________________
dropout_15 (Dropout)             (None, 256)           0           leakyrelu_31[0][0]               
____________________________________________________________________________________________________
dense_6 (Dense)                  (None, 1)             257         dropout_15[0][0]                 
====================================================================================================
Total params: 228881
____________________________________________________________________________________________________
('Epoch', 1, 'of', 50)
('Number of batches', 19)
('GAN loss 0.4910 ', 'GAN acc 0.7812', 'Discriminator loss 0.9038', 'Discriminator accuracy 0.5137', 'Total loss: 1.3948', 'for batch', 0)
('GAN loss 0.5390 ', 'GAN acc 0.7344', 'Discriminator loss 0.9399', 'Discriminator accuracy 0.4883', 'Total loss: 1.4789', 'for batch', 1)
('GAN loss 0.6524 ', 'GAN acc 0.6328', 'Discriminator loss 0.9382', 'Discriminator accuracy 0.4023', 'Total loss: 1.5906', 'for batch', 2)
('GAN loss 0.8006 ', 'GAN acc 0.5039', 'Discriminator loss 0.9588', 'Discriminator accuracy 0.3594', 'Total loss: 1.7594', 'for batch', 3)
('GAN loss 0.8064 ', 'GAN acc 0.4727', 'Discriminator loss 0.8089', 'Discriminator accuracy 0.4551', 'Total loss: 1.6153', 'for batch', 4)
('GAN loss 0.8482 ', 'GAN acc 0.4180', 'Discriminator loss 0.8396', 'Discriminator accuracy 0.4297', 'Total loss: 1.6879', 'for batch', 5)
('GAN loss 0.8218 ', 'GAN acc 0.4414', 'Discriminator loss 0.7373', 'Discriminator accuracy 0.5117', 'Total loss: 1.5591', 'for batch', 6)
('GAN loss 0.9088 ', 'GAN acc 0.3828', 'Discriminator loss 0.7376', 'Discriminator accuracy 0.5371', 'Total loss: 1.6464', 'for batch', 7)
('GAN loss 1.1018 ', 'GAN acc 0.2539', 'Discriminator loss 0.7081', 'Discriminator accuracy 0.5898', 'Total loss: 1.8099', 'for batch', 8)
('GAN loss 1.1991 ', 'GAN acc 0.2188', 'Discriminator loss 0.6657', 'Discriminator accuracy 0.6113', 'Total loss: 1.8648', 'for batch', 9)
('GAN loss 1.2874 ', 'GAN acc 0.1797', 'Discriminator loss 0.6161', 'Discriminator accuracy 0.6582', 'Total loss: 1.9035', 'for batch', 10)
('GAN loss 1.0790 ', 'GAN acc 0.2500', 'Discriminator loss 0.6203', 'Discriminator accuracy 0.6660', 'Total loss: 1.6994', 'for batch', 11)
('GAN loss 1.1353 ', 'GAN acc 0.2266', 'Discriminator loss 0.6006', 'Discriminator accuracy 0.6641', 'Total loss: 1.7358', 'for batch', 12)
('GAN loss 1.1722 ', 'GAN acc 0.2109', 'Discriminator loss 0.6115', 'Discriminator accuracy 0.6758', 'Total loss: 1.7836', 'for batch', 13)
('GAN loss 1.1158 ', 'GAN acc 0.2266', 'Discriminator loss 0.6520', 'Discriminator accuracy 0.6582', 'Total loss: 1.7678', 'for batch', 14)
('GAN loss 0.9993 ', 'GAN acc 0.2539', 'Discriminator loss 0.7178', 'Discriminator accuracy 0.5488', 'Total loss: 1.7171', 'for batch', 15)
('GAN loss 1.0688 ', 'GAN acc 0.2578', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.5566', 'Total loss: 1.7747', 'for batch', 16)
('GAN loss 1.1067 ', 'GAN acc 0.2422', 'Discriminator loss 0.7017', 'Discriminator accuracy 0.5547', 'Total loss: 1.8084', 'for batch', 17)
('GAN loss 1.1099 ', 'GAN acc 0.2344', 'Discriminator loss 0.6721', 'Discriminator accuracy 0.5996', 'Total loss: 1.7820', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.84892017)
('DISCRIMINATOR_Imagem FAKE=', 0.73481214)
('Discriminator trained', 14, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:46.870213')
----------------------------------
('Epoch', 2, 'of', 50)
('Number of batches', 19)
('GAN loss 1.0714 ', 'GAN acc 0.2969', 'Discriminator loss 0.6086', 'Discriminator accuracy 0.6621', 'Total loss: 1.6801', 'for batch', 0)
('GAN loss 1.1885 ', 'GAN acc 0.2383', 'Discriminator loss 0.6094', 'Discriminator accuracy 0.6836', 'Total loss: 1.7979', 'for batch', 1)
('GAN loss 1.2786 ', 'GAN acc 0.1406', 'Discriminator loss 0.6058', 'Discriminator accuracy 0.6660', 'Total loss: 1.8844', 'for batch', 2)
('GAN loss 1.1905 ', 'GAN acc 0.2148', 'Discriminator loss 0.6013', 'Discriminator accuracy 0.6855', 'Total loss: 1.7919', 'for batch', 3)
('GAN loss 1.0514 ', 'GAN acc 0.2539', 'Discriminator loss 0.5903', 'Discriminator accuracy 0.6934', 'Total loss: 1.6417', 'for batch', 4)
('GAN loss 1.2000 ', 'GAN acc 0.1836', 'Discriminator loss 0.6103', 'Discriminator accuracy 0.6660', 'Total loss: 1.8103', 'for batch', 5)
('GAN loss 1.2446 ', 'GAN acc 0.1602', 'Discriminator loss 0.6278', 'Discriminator accuracy 0.6348', 'Total loss: 1.8725', 'for batch', 6)
('GAN loss 1.0854 ', 'GAN acc 0.2422', 'Discriminator loss 0.5712', 'Discriminator accuracy 0.6973', 'Total loss: 1.6566', 'for batch', 7)
('GAN loss 0.9850 ', 'GAN acc 0.3242', 'Discriminator loss 0.5975', 'Discriminator accuracy 0.6719', 'Total loss: 1.5825', 'for batch', 8)
('GAN loss 1.0207 ', 'GAN acc 0.3203', 'Discriminator loss 0.6307', 'Discriminator accuracy 0.6484', 'Total loss: 1.6514', 'for batch', 9)
('GAN loss 1.0900 ', 'GAN acc 0.2578', 'Discriminator loss 0.6451', 'Discriminator accuracy 0.6211', 'Total loss: 1.7351', 'for batch', 10)
('GAN loss 1.0612 ', 'GAN acc 0.2969', 'Discriminator loss 0.6407', 'Discriminator accuracy 0.6367', 'Total loss: 1.7020', 'for batch', 11)
('GAN loss 1.0587 ', 'GAN acc 0.2656', 'Discriminator loss 0.6778', 'Discriminator accuracy 0.5820', 'Total loss: 1.7365', 'for batch', 12)
('GAN loss 0.9490 ', 'GAN acc 0.3633', 'Discriminator loss 0.6881', 'Discriminator accuracy 0.5762', 'Total loss: 1.6371', 'for batch', 13)
('GAN loss 1.0683 ', 'GAN acc 0.2578', 'Discriminator loss 0.7047', 'Discriminator accuracy 0.5430', 'Total loss: 1.7730', 'for batch', 14)
('GAN loss 0.8980 ', 'GAN acc 0.3516', 'Discriminator loss 0.7173', 'Discriminator accuracy 0.5527', 'Total loss: 1.6153', 'for batch', 15)
('GAN loss 0.7949 ', 'GAN acc 0.4883', 'Discriminator loss 0.7233', 'Discriminator accuracy 0.5234', 'Total loss: 1.5182', 'for batch', 16)
('GAN loss 0.8651 ', 'GAN acc 0.3906', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5781', 'Total loss: 1.5581', 'for batch', 17)
('GAN loss 0.9859 ', 'GAN acc 0.3125', 'Discriminator loss 0.6683', 'Discriminator accuracy 0.5977', 'Total loss: 1.6542', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.89541453)
('DISCRIMINATOR_Imagem FAKE=', 0.85317767)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.646809')
----------------------------------
('Epoch', 3, 'of', 50)
('Number of batches', 19)
('GAN loss 0.9754 ', 'GAN acc 0.2812', 'Discriminator loss 0.6528', 'Discriminator accuracy 0.6074', 'Total loss: 1.6282', 'for batch', 0)
('GAN loss 0.9717 ', 'GAN acc 0.3086', 'Discriminator loss 0.6690', 'Discriminator accuracy 0.6055', 'Total loss: 1.6407', 'for batch', 1)
('GAN loss 0.8737 ', 'GAN acc 0.3594', 'Discriminator loss 0.6501', 'Discriminator accuracy 0.6035', 'Total loss: 1.5238', 'for batch', 2)
('GAN loss 1.0520 ', 'GAN acc 0.2422', 'Discriminator loss 0.6718', 'Discriminator accuracy 0.5781', 'Total loss: 1.7239', 'for batch', 3)
('GAN loss 1.0776 ', 'GAN acc 0.2383', 'Discriminator loss 0.6592', 'Discriminator accuracy 0.6250', 'Total loss: 1.7368', 'for batch', 4)
('GAN loss 1.0679 ', 'GAN acc 0.2539', 'Discriminator loss 0.6738', 'Discriminator accuracy 0.5820', 'Total loss: 1.7417', 'for batch', 5)
('GAN loss 0.8776 ', 'GAN acc 0.3750', 'Discriminator loss 0.6837', 'Discriminator accuracy 0.5547', 'Total loss: 1.5612', 'for batch', 6)
('GAN loss 0.7875 ', 'GAN acc 0.4570', 'Discriminator loss 0.6605', 'Discriminator accuracy 0.6074', 'Total loss: 1.4480', 'for batch', 7)
('GAN loss 0.7810 ', 'GAN acc 0.4531', 'Discriminator loss 0.6839', 'Discriminator accuracy 0.5664', 'Total loss: 1.4649', 'for batch', 8)
('GAN loss 0.8482 ', 'GAN acc 0.3867', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5488', 'Total loss: 1.5462', 'for batch', 9)
('GAN loss 0.7832 ', 'GAN acc 0.4219', 'Discriminator loss 0.7092', 'Discriminator accuracy 0.5293', 'Total loss: 1.4924', 'for batch', 10)
('GAN loss 0.7617 ', 'GAN acc 0.4648', 'Discriminator loss 0.7239', 'Discriminator accuracy 0.5234', 'Total loss: 1.4856', 'for batch', 11)
('GAN loss 0.8057 ', 'GAN acc 0.4727', 'Discriminator loss 0.7041', 'Discriminator accuracy 0.5566', 'Total loss: 1.5098', 'for batch', 12)
('GAN loss 0.8296 ', 'GAN acc 0.4062', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5566', 'Total loss: 1.5191', 'for batch', 13)
('GAN loss 0.8743 ', 'GAN acc 0.3164', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5586', 'Total loss: 1.5682', 'for batch', 14)
('GAN loss 0.8342 ', 'GAN acc 0.4062', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5488', 'Total loss: 1.5254', 'for batch', 15)
('GAN loss 0.9126 ', 'GAN acc 0.3203', 'Discriminator loss 0.7208', 'Discriminator accuracy 0.5352', 'Total loss: 1.6333', 'for batch', 16)
('GAN loss 0.8438 ', 'GAN acc 0.3945', 'Discriminator loss 0.7316', 'Discriminator accuracy 0.4707', 'Total loss: 1.5753', 'for batch', 17)
('GAN loss 0.8565 ', 'GAN acc 0.3164', 'Discriminator loss 0.7220', 'Discriminator accuracy 0.5000', 'Total loss: 1.5785', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.85091329)
('DISCRIMINATOR_Imagem FAKE=', 0.8435238)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.234142')
----------------------------------
('Epoch', 4, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8294 ', 'GAN acc 0.4180', 'Discriminator loss 0.7140', 'Discriminator accuracy 0.5059', 'Total loss: 1.5434', 'for batch', 0)
('GAN loss 0.7883 ', 'GAN acc 0.4375', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5273', 'Total loss: 1.4866', 'for batch', 1)
('GAN loss 0.7746 ', 'GAN acc 0.4570', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5488', 'Total loss: 1.4712', 'for batch', 2)
('GAN loss 0.8417 ', 'GAN acc 0.3203', 'Discriminator loss 0.6863', 'Discriminator accuracy 0.5762', 'Total loss: 1.5280', 'for batch', 3)
('GAN loss 0.8381 ', 'GAN acc 0.3477', 'Discriminator loss 0.6838', 'Discriminator accuracy 0.5547', 'Total loss: 1.5218', 'for batch', 4)
('GAN loss 0.8293 ', 'GAN acc 0.3828', 'Discriminator loss 0.7055', 'Discriminator accuracy 0.5547', 'Total loss: 1.5348', 'for batch', 5)
('GAN loss 0.8303 ', 'GAN acc 0.3477', 'Discriminator loss 0.6778', 'Discriminator accuracy 0.5742', 'Total loss: 1.5081', 'for batch', 6)
('GAN loss 0.7856 ', 'GAN acc 0.4180', 'Discriminator loss 0.7058', 'Discriminator accuracy 0.5430', 'Total loss: 1.4914', 'for batch', 7)
('GAN loss 0.8101 ', 'GAN acc 0.4102', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5449', 'Total loss: 1.5025', 'for batch', 8)
('GAN loss 0.8232 ', 'GAN acc 0.3789', 'Discriminator loss 0.6687', 'Discriminator accuracy 0.5801', 'Total loss: 1.4918', 'for batch', 9)
('GAN loss 0.8071 ', 'GAN acc 0.4023', 'Discriminator loss 0.6890', 'Discriminator accuracy 0.5684', 'Total loss: 1.4962', 'for batch', 10)
('GAN loss 0.8208 ', 'GAN acc 0.3398', 'Discriminator loss 0.6774', 'Discriminator accuracy 0.5645', 'Total loss: 1.4982', 'for batch', 11)
('GAN loss 0.8177 ', 'GAN acc 0.3438', 'Discriminator loss 0.6852', 'Discriminator accuracy 0.5547', 'Total loss: 1.5029', 'for batch', 12)
('GAN loss 0.7893 ', 'GAN acc 0.3750', 'Discriminator loss 0.7126', 'Discriminator accuracy 0.5293', 'Total loss: 1.5019', 'for batch', 13)
('GAN loss 0.7377 ', 'GAN acc 0.4648', 'Discriminator loss 0.7244', 'Discriminator accuracy 0.4883', 'Total loss: 1.4621', 'for batch', 14)
('GAN loss 0.7010 ', 'GAN acc 0.5430', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.5078', 'Total loss: 1.4029', 'for batch', 15)
('GAN loss 0.7459 ', 'GAN acc 0.4492', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.5371', 'Total loss: 1.4445', 'for batch', 16)
('GAN loss 0.7281 ', 'GAN acc 0.4531', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.5156', 'Total loss: 1.4283', 'for batch', 17)
('GAN loss 0.7174 ', 'GAN acc 0.5117', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.5117', 'Total loss: 1.4176', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.82104355)
('DISCRIMINATOR_Imagem FAKE=', 0.78837383)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.784607')
----------------------------------
('Epoch', 5, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6576 ', 'GAN acc 0.6133', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5371', 'Total loss: 1.3570', 'for batch', 0)
('GAN loss 0.6646 ', 'GAN acc 0.6445', 'Discriminator loss 0.7056', 'Discriminator accuracy 0.5234', 'Total loss: 1.3702', 'for batch', 1)
('GAN loss 0.7006 ', 'GAN acc 0.5234', 'Discriminator loss 0.6888', 'Discriminator accuracy 0.5547', 'Total loss: 1.3894', 'for batch', 2)
('GAN loss 0.7604 ', 'GAN acc 0.4297', 'Discriminator loss 0.6878', 'Discriminator accuracy 0.5664', 'Total loss: 1.4482', 'for batch', 3)
('GAN loss 0.7429 ', 'GAN acc 0.4492', 'Discriminator loss 0.6729', 'Discriminator accuracy 0.5977', 'Total loss: 1.4158', 'for batch', 4)
('GAN loss 0.6974 ', 'GAN acc 0.4805', 'Discriminator loss 0.6807', 'Discriminator accuracy 0.5840', 'Total loss: 1.3780', 'for batch', 5)
('GAN loss 0.6769 ', 'GAN acc 0.5586', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5371', 'Total loss: 1.3718', 'for batch', 6)
('GAN loss 0.6893 ', 'GAN acc 0.5586', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5293', 'Total loss: 1.3818', 'for batch', 7)
('GAN loss 0.6735 ', 'GAN acc 0.5742', 'Discriminator loss 0.6817', 'Discriminator accuracy 0.5684', 'Total loss: 1.3552', 'for batch', 8)
('GAN loss 0.7183 ', 'GAN acc 0.4805', 'Discriminator loss 0.6677', 'Discriminator accuracy 0.5859', 'Total loss: 1.3860', 'for batch', 9)
('GAN loss 0.7719 ', 'GAN acc 0.3750', 'Discriminator loss 0.6608', 'Discriminator accuracy 0.5898', 'Total loss: 1.4327', 'for batch', 10)
('GAN loss 0.7311 ', 'GAN acc 0.4844', 'Discriminator loss 0.6686', 'Discriminator accuracy 0.5879', 'Total loss: 1.3998', 'for batch', 11)
('GAN loss 0.7511 ', 'GAN acc 0.4805', 'Discriminator loss 0.6717', 'Discriminator accuracy 0.5586', 'Total loss: 1.4228', 'for batch', 12)
('GAN loss 0.7493 ', 'GAN acc 0.4375', 'Discriminator loss 0.6797', 'Discriminator accuracy 0.5703', 'Total loss: 1.4289', 'for batch', 13)
('GAN loss 0.7702 ', 'GAN acc 0.4023', 'Discriminator loss 0.6801', 'Discriminator accuracy 0.5508', 'Total loss: 1.4502', 'for batch', 14)
('GAN loss 0.7456 ', 'GAN acc 0.4414', 'Discriminator loss 0.6799', 'Discriminator accuracy 0.5918', 'Total loss: 1.4255', 'for batch', 15)
('GAN loss 0.7386 ', 'GAN acc 0.4961', 'Discriminator loss 0.6666', 'Discriminator accuracy 0.5820', 'Total loss: 1.4052', 'for batch', 16)
('GAN loss 0.7353 ', 'GAN acc 0.5234', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5547', 'Total loss: 1.4295', 'for batch', 17)
('GAN loss 0.7836 ', 'GAN acc 0.3789', 'Discriminator loss 0.6847', 'Discriminator accuracy 0.5488', 'Total loss: 1.4683', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.79906797)
('DISCRIMINATOR_Imagem FAKE=', 0.76723588)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.484290')
----------------------------------
('Epoch', 6, 'of', 50)
('Number of batches', 19)
('GAN loss 0.8004 ', 'GAN acc 0.3477', 'Discriminator loss 0.6570', 'Discriminator accuracy 0.6113', 'Total loss: 1.4575', 'for batch', 0)
('GAN loss 0.7637 ', 'GAN acc 0.4609', 'Discriminator loss 0.6756', 'Discriminator accuracy 0.5879', 'Total loss: 1.4393', 'for batch', 1)
('GAN loss 0.7386 ', 'GAN acc 0.4453', 'Discriminator loss 0.6782', 'Discriminator accuracy 0.5703', 'Total loss: 1.4168', 'for batch', 2)
('GAN loss 0.7737 ', 'GAN acc 0.3906', 'Discriminator loss 0.7035', 'Discriminator accuracy 0.5391', 'Total loss: 1.4772', 'for batch', 3)
('GAN loss 0.8159 ', 'GAN acc 0.3047', 'Discriminator loss 0.6716', 'Discriminator accuracy 0.5879', 'Total loss: 1.4876', 'for batch', 4)
('GAN loss 0.7891 ', 'GAN acc 0.3789', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5312', 'Total loss: 1.4810', 'for batch', 5)
('GAN loss 0.7978 ', 'GAN acc 0.3672', 'Discriminator loss 0.6672', 'Discriminator accuracy 0.5469', 'Total loss: 1.4650', 'for batch', 6)
('GAN loss 0.7509 ', 'GAN acc 0.4492', 'Discriminator loss 0.6876', 'Discriminator accuracy 0.5352', 'Total loss: 1.4385', 'for batch', 7)
('GAN loss 0.7716 ', 'GAN acc 0.4258', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5391', 'Total loss: 1.4630', 'for batch', 8)
('GAN loss 0.7667 ', 'GAN acc 0.4180', 'Discriminator loss 0.6756', 'Discriminator accuracy 0.5957', 'Total loss: 1.4423', 'for batch', 9)
('GAN loss 0.7642 ', 'GAN acc 0.4062', 'Discriminator loss 0.6869', 'Discriminator accuracy 0.5488', 'Total loss: 1.4512', 'for batch', 10)
('GAN loss 0.7650 ', 'GAN acc 0.4531', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5605', 'Total loss: 1.4559', 'for batch', 11)
('GAN loss 0.7311 ', 'GAN acc 0.4844', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5195', 'Total loss: 1.4241', 'for batch', 12)
('GAN loss 0.7841 ', 'GAN acc 0.4062', 'Discriminator loss 0.6878', 'Discriminator accuracy 0.5527', 'Total loss: 1.4719', 'for batch', 13)
('GAN loss 0.7689 ', 'GAN acc 0.4023', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.5137', 'Total loss: 1.4696', 'for batch', 14)
('GAN loss 0.7695 ', 'GAN acc 0.4219', 'Discriminator loss 0.6827', 'Discriminator accuracy 0.5605', 'Total loss: 1.4522', 'for batch', 15)
('GAN loss 0.7737 ', 'GAN acc 0.3906', 'Discriminator loss 0.6731', 'Discriminator accuracy 0.5781', 'Total loss: 1.4468', 'for batch', 16)
('GAN loss 0.8096 ', 'GAN acc 0.3516', 'Discriminator loss 0.6633', 'Discriminator accuracy 0.5996', 'Total loss: 1.4729', 'for batch', 17)
('GAN loss 0.7692 ', 'GAN acc 0.4141', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.5156', 'Total loss: 1.4668', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.76902354)
('DISCRIMINATOR_Imagem FAKE=', 0.76908982)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.880650')
----------------------------------
('Epoch', 7, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7566 ', 'GAN acc 0.4141', 'Discriminator loss 0.6995', 'Discriminator accuracy 0.5254', 'Total loss: 1.4560', 'for batch', 0)
('GAN loss 0.7697 ', 'GAN acc 0.4297', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.5312', 'Total loss: 1.4741', 'for batch', 1)
('GAN loss 0.7829 ', 'GAN acc 0.3828', 'Discriminator loss 0.7043', 'Discriminator accuracy 0.5312', 'Total loss: 1.4872', 'for batch', 2)
('GAN loss 0.7956 ', 'GAN acc 0.3242', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5586', 'Total loss: 1.4873', 'for batch', 3)
('GAN loss 0.7440 ', 'GAN acc 0.4375', 'Discriminator loss 0.7044', 'Discriminator accuracy 0.5117', 'Total loss: 1.4484', 'for batch', 4)
('GAN loss 0.7554 ', 'GAN acc 0.4414', 'Discriminator loss 0.7069', 'Discriminator accuracy 0.5234', 'Total loss: 1.4622', 'for batch', 5)
('GAN loss 0.7454 ', 'GAN acc 0.4766', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.5117', 'Total loss: 1.4505', 'for batch', 6)
('GAN loss 0.7481 ', 'GAN acc 0.4375', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5254', 'Total loss: 1.4442', 'for batch', 7)
('GAN loss 0.7360 ', 'GAN acc 0.4609', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.5059', 'Total loss: 1.4354', 'for batch', 8)
('GAN loss 0.7541 ', 'GAN acc 0.4414', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5352', 'Total loss: 1.4473', 'for batch', 9)
('GAN loss 0.7709 ', 'GAN acc 0.3672', 'Discriminator loss 0.7103', 'Discriminator accuracy 0.4785', 'Total loss: 1.4812', 'for batch', 10)
('GAN loss 0.7805 ', 'GAN acc 0.3672', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.5117', 'Total loss: 1.4795', 'for batch', 11)
('GAN loss 0.7853 ', 'GAN acc 0.3594', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5078', 'Total loss: 1.4864', 'for batch', 12)
('GAN loss 0.7678 ', 'GAN acc 0.4062', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5371', 'Total loss: 1.4598', 'for batch', 13)
('GAN loss 0.7871 ', 'GAN acc 0.3555', 'Discriminator loss 0.6819', 'Discriminator accuracy 0.5645', 'Total loss: 1.4691', 'for batch', 14)
('GAN loss 0.8036 ', 'GAN acc 0.3281', 'Discriminator loss 0.6841', 'Discriminator accuracy 0.5625', 'Total loss: 1.4876', 'for batch', 15)
('GAN loss 0.7789 ', 'GAN acc 0.3633', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5195', 'Total loss: 1.4737', 'for batch', 16)
('GAN loss 0.7862 ', 'GAN acc 0.3672', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5254', 'Total loss: 1.4817', 'for batch', 17)
('GAN loss 0.8019 ', 'GAN acc 0.3555', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5449', 'Total loss: 1.4970', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.71414274)
('DISCRIMINATOR_Imagem FAKE=', 0.72273678)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.497877')
----------------------------------
('Epoch', 8, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7610 ', 'GAN acc 0.3984', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5449', 'Total loss: 1.4561', 'for batch', 0)
('GAN loss 0.8112 ', 'GAN acc 0.3086', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5312', 'Total loss: 1.5015', 'for batch', 1)
('GAN loss 0.7983 ', 'GAN acc 0.3242', 'Discriminator loss 0.6863', 'Discriminator accuracy 0.5645', 'Total loss: 1.4846', 'for batch', 2)
('GAN loss 0.7734 ', 'GAN acc 0.3633', 'Discriminator loss 0.6919', 'Discriminator accuracy 0.5312', 'Total loss: 1.4653', 'for batch', 3)
('GAN loss 0.7735 ', 'GAN acc 0.3594', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5273', 'Total loss: 1.4629', 'for batch', 4)
('GAN loss 0.7492 ', 'GAN acc 0.4375', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5234', 'Total loss: 1.4421', 'for batch', 5)
('GAN loss 0.7688 ', 'GAN acc 0.3672', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5469', 'Total loss: 1.4639', 'for batch', 6)
('GAN loss 0.7794 ', 'GAN acc 0.3750', 'Discriminator loss 0.6867', 'Discriminator accuracy 0.5586', 'Total loss: 1.4660', 'for batch', 7)
('GAN loss 0.7723 ', 'GAN acc 0.4023', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5508', 'Total loss: 1.4632', 'for batch', 8)
('GAN loss 0.8061 ', 'GAN acc 0.3555', 'Discriminator loss 0.6784', 'Discriminator accuracy 0.5742', 'Total loss: 1.4845', 'for batch', 9)
('GAN loss 0.7952 ', 'GAN acc 0.3477', 'Discriminator loss 0.6755', 'Discriminator accuracy 0.5820', 'Total loss: 1.4707', 'for batch', 10)
('GAN loss 0.7630 ', 'GAN acc 0.3984', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.5117', 'Total loss: 1.4641', 'for batch', 11)
('GAN loss 0.7625 ', 'GAN acc 0.4141', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5430', 'Total loss: 1.4556', 'for batch', 12)
('GAN loss 0.7717 ', 'GAN acc 0.3672', 'Discriminator loss 0.6777', 'Discriminator accuracy 0.5703', 'Total loss: 1.4494', 'for batch', 13)
('GAN loss 0.7618 ', 'GAN acc 0.3984', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5371', 'Total loss: 1.4511', 'for batch', 14)
('GAN loss 0.7533 ', 'GAN acc 0.4141', 'Discriminator loss 0.7055', 'Discriminator accuracy 0.5137', 'Total loss: 1.4588', 'for batch', 15)
('GAN loss 0.7499 ', 'GAN acc 0.4141', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.5215', 'Total loss: 1.4538', 'for batch', 16)
('GAN loss 0.7359 ', 'GAN acc 0.4609', 'Discriminator loss 0.7085', 'Discriminator accuracy 0.4824', 'Total loss: 1.4444', 'for batch', 17)
('GAN loss 0.7274 ', 'GAN acc 0.4414', 'Discriminator loss 0.7056', 'Discriminator accuracy 0.5137', 'Total loss: 1.4330', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.69792348)
('DISCRIMINATOR_Imagem FAKE=', 0.70832556)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.885276')
----------------------------------
('Epoch', 9, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7431 ', 'GAN acc 0.4023', 'Discriminator loss 0.7002', 'Discriminator accuracy 0.4961', 'Total loss: 1.4433', 'for batch', 0)
('GAN loss 0.7152 ', 'GAN acc 0.4883', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.5332', 'Total loss: 1.4151', 'for batch', 1)
('GAN loss 0.7613 ', 'GAN acc 0.3672', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5332', 'Total loss: 1.4505', 'for batch', 2)
('GAN loss 0.7577 ', 'GAN acc 0.3672', 'Discriminator loss 0.6867', 'Discriminator accuracy 0.5312', 'Total loss: 1.4444', 'for batch', 3)
('GAN loss 0.7445 ', 'GAN acc 0.4531', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.5156', 'Total loss: 1.4424', 'for batch', 4)
('GAN loss 0.7450 ', 'GAN acc 0.4375', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5176', 'Total loss: 1.4387', 'for batch', 5)
('GAN loss 0.7277 ', 'GAN acc 0.4453', 'Discriminator loss 0.7054', 'Discriminator accuracy 0.5039', 'Total loss: 1.4331', 'for batch', 6)
('GAN loss 0.7232 ', 'GAN acc 0.4492', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5410', 'Total loss: 1.4142', 'for batch', 7)
('GAN loss 0.7357 ', 'GAN acc 0.4336', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5312', 'Total loss: 1.4259', 'for batch', 8)
('GAN loss 0.7349 ', 'GAN acc 0.4609', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4961', 'Total loss: 1.4356', 'for batch', 9)
('GAN loss 0.7389 ', 'GAN acc 0.4531', 'Discriminator loss 0.7012', 'Discriminator accuracy 0.5195', 'Total loss: 1.4401', 'for batch', 10)
('GAN loss 0.7166 ', 'GAN acc 0.4531', 'Discriminator loss 0.7019', 'Discriminator accuracy 0.5254', 'Total loss: 1.4185', 'for batch', 11)
('GAN loss 0.7029 ', 'GAN acc 0.5078', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.5312', 'Total loss: 1.4039', 'for batch', 12)
('GAN loss 0.6837 ', 'GAN acc 0.5586', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5469', 'Total loss: 1.3829', 'for batch', 13)
('GAN loss 0.6873 ', 'GAN acc 0.5742', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.5215', 'Total loss: 1.3902', 'for batch', 14)
('GAN loss 0.7137 ', 'GAN acc 0.5156', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.5215', 'Total loss: 1.4144', 'for batch', 15)
('GAN loss 0.7213 ', 'GAN acc 0.4336', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5273', 'Total loss: 1.4196', 'for batch', 16)
('GAN loss 0.7050 ', 'GAN acc 0.4961', 'Discriminator loss 0.7048', 'Discriminator accuracy 0.5020', 'Total loss: 1.4099', 'for batch', 17)
('GAN loss 0.7377 ', 'GAN acc 0.4141', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5410', 'Total loss: 1.4318', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.66564512)
('DISCRIMINATOR_Imagem FAKE=', 0.65386188)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.456862')
----------------------------------
('Epoch', 10, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7542 ', 'GAN acc 0.3867', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5410', 'Total loss: 1.4477', 'for batch', 0)
('GAN loss 0.7220 ', 'GAN acc 0.4844', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5469', 'Total loss: 1.4115', 'for batch', 1)
('GAN loss 0.7167 ', 'GAN acc 0.4531', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5156', 'Total loss: 1.4094', 'for batch', 2)
('GAN loss 0.6999 ', 'GAN acc 0.5352', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.5059', 'Total loss: 1.4028', 'for batch', 3)
('GAN loss 0.7105 ', 'GAN acc 0.4570', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5527', 'Total loss: 1.4007', 'for batch', 4)
('GAN loss 0.7152 ', 'GAN acc 0.4648', 'Discriminator loss 0.6939', 'Discriminator accuracy 0.5449', 'Total loss: 1.4091', 'for batch', 5)
('GAN loss 0.7039 ', 'GAN acc 0.4570', 'Discriminator loss 0.7077', 'Discriminator accuracy 0.4980', 'Total loss: 1.4115', 'for batch', 6)
('GAN loss 0.7135 ', 'GAN acc 0.4688', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5410', 'Total loss: 1.4028', 'for batch', 7)
('GAN loss 0.7067 ', 'GAN acc 0.5000', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5176', 'Total loss: 1.4039', 'for batch', 8)
('GAN loss 0.6980 ', 'GAN acc 0.5117', 'Discriminator loss 0.6859', 'Discriminator accuracy 0.5684', 'Total loss: 1.3839', 'for batch', 9)
('GAN loss 0.7098 ', 'GAN acc 0.4727', 'Discriminator loss 0.6823', 'Discriminator accuracy 0.5469', 'Total loss: 1.3921', 'for batch', 10)
('GAN loss 0.7142 ', 'GAN acc 0.4922', 'Discriminator loss 0.6808', 'Discriminator accuracy 0.5488', 'Total loss: 1.3950', 'for batch', 11)
('GAN loss 0.7074 ', 'GAN acc 0.4805', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5312', 'Total loss: 1.3986', 'for batch', 12)
('GAN loss 0.6820 ', 'GAN acc 0.5820', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5332', 'Total loss: 1.3765', 'for batch', 13)
('GAN loss 0.7098 ', 'GAN acc 0.5000', 'Discriminator loss 0.6850', 'Discriminator accuracy 0.5352', 'Total loss: 1.3948', 'for batch', 14)
('GAN loss 0.6887 ', 'GAN acc 0.5781', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.5273', 'Total loss: 1.3841', 'for batch', 15)
('GAN loss 0.6847 ', 'GAN acc 0.5664', 'Discriminator loss 0.7038', 'Discriminator accuracy 0.5195', 'Total loss: 1.3885', 'for batch', 16)
('GAN loss 0.7085 ', 'GAN acc 0.5000', 'Discriminator loss 0.6831', 'Discriminator accuracy 0.5488', 'Total loss: 1.3917', 'for batch', 17)
('GAN loss 0.7149 ', 'GAN acc 0.4531', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.5020', 'Total loss: 1.4132', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.66119629)
('DISCRIMINATOR_Imagem FAKE=', 0.65238851)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.943506')
----------------------------------
('Epoch', 11, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7162 ', 'GAN acc 0.4766', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5098', 'Total loss: 1.4112', 'for batch', 0)
('GAN loss 0.7153 ', 'GAN acc 0.4844', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5293', 'Total loss: 1.4133', 'for batch', 1)
('GAN loss 0.6879 ', 'GAN acc 0.5586', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5273', 'Total loss: 1.3843', 'for batch', 2)
('GAN loss 0.6817 ', 'GAN acc 0.6055', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5195', 'Total loss: 1.3754', 'for batch', 3)
('GAN loss 0.6862 ', 'GAN acc 0.5859', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.5195', 'Total loss: 1.3858', 'for batch', 4)
('GAN loss 0.6911 ', 'GAN acc 0.5742', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5078', 'Total loss: 1.3904', 'for batch', 5)
('GAN loss 0.6998 ', 'GAN acc 0.4961', 'Discriminator loss 0.6876', 'Discriminator accuracy 0.5391', 'Total loss: 1.3874', 'for batch', 6)
('GAN loss 0.7076 ', 'GAN acc 0.5000', 'Discriminator loss 0.6907', 'Discriminator accuracy 0.5645', 'Total loss: 1.3983', 'for batch', 7)
('GAN loss 0.6970 ', 'GAN acc 0.5430', 'Discriminator loss 0.7039', 'Discriminator accuracy 0.4902', 'Total loss: 1.4010', 'for batch', 8)
('GAN loss 0.6852 ', 'GAN acc 0.5547', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4961', 'Total loss: 1.3844', 'for batch', 9)
('GAN loss 0.7136 ', 'GAN acc 0.4922', 'Discriminator loss 0.6902', 'Discriminator accuracy 0.5566', 'Total loss: 1.4038', 'for batch', 10)
('GAN loss 0.7108 ', 'GAN acc 0.4883', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5078', 'Total loss: 1.4039', 'for batch', 11)
('GAN loss 0.7025 ', 'GAN acc 0.5273', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5332', 'Total loss: 1.3936', 'for batch', 12)
('GAN loss 0.6919 ', 'GAN acc 0.4805', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5352', 'Total loss: 1.3855', 'for batch', 13)
('GAN loss 0.6874 ', 'GAN acc 0.5391', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5273', 'Total loss: 1.3804', 'for batch', 14)
('GAN loss 0.7071 ', 'GAN acc 0.5273', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5293', 'Total loss: 1.3992', 'for batch', 15)
('GAN loss 0.7131 ', 'GAN acc 0.5117', 'Discriminator loss 0.6797', 'Discriminator accuracy 0.5605', 'Total loss: 1.3927', 'for batch', 16)
('GAN loss 0.7152 ', 'GAN acc 0.4922', 'Discriminator loss 0.6882', 'Discriminator accuracy 0.5410', 'Total loss: 1.4033', 'for batch', 17)
('GAN loss 0.6998 ', 'GAN acc 0.5195', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5273', 'Total loss: 1.3929', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.64549905)
('DISCRIMINATOR_Imagem FAKE=', 0.64031798)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.479624')
----------------------------------
('Epoch', 12, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6993 ', 'GAN acc 0.5234', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5547', 'Total loss: 1.3891', 'for batch', 0)
('GAN loss 0.6871 ', 'GAN acc 0.5391', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4746', 'Total loss: 1.3900', 'for batch', 1)
('GAN loss 0.6899 ', 'GAN acc 0.5508', 'Discriminator loss 0.7001', 'Discriminator accuracy 0.4941', 'Total loss: 1.3900', 'for batch', 2)
('GAN loss 0.7019 ', 'GAN acc 0.4766', 'Discriminator loss 0.7097', 'Discriminator accuracy 0.4668', 'Total loss: 1.4117', 'for batch', 3)
('GAN loss 0.6918 ', 'GAN acc 0.5430', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4941', 'Total loss: 1.3907', 'for batch', 4)
('GAN loss 0.6883 ', 'GAN acc 0.5508', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5391', 'Total loss: 1.3804', 'for batch', 5)
('GAN loss 0.6876 ', 'GAN acc 0.5508', 'Discriminator loss 0.6857', 'Discriminator accuracy 0.5605', 'Total loss: 1.3732', 'for batch', 6)
('GAN loss 0.6819 ', 'GAN acc 0.5391', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5020', 'Total loss: 1.3786', 'for batch', 7)
('GAN loss 0.7050 ', 'GAN acc 0.5273', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5391', 'Total loss: 1.3949', 'for batch', 8)
('GAN loss 0.7115 ', 'GAN acc 0.4883', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5234', 'Total loss: 1.4076', 'for batch', 9)
('GAN loss 0.7052 ', 'GAN acc 0.4844', 'Discriminator loss 0.7003', 'Discriminator accuracy 0.5215', 'Total loss: 1.4055', 'for batch', 10)
('GAN loss 0.7145 ', 'GAN acc 0.4492', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5156', 'Total loss: 1.4083', 'for batch', 11)
('GAN loss 0.7175 ', 'GAN acc 0.4727', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5039', 'Total loss: 1.4146', 'for batch', 12)
('GAN loss 0.7127 ', 'GAN acc 0.4648', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.5117', 'Total loss: 1.4109', 'for batch', 13)
('GAN loss 0.7048 ', 'GAN acc 0.4922', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.5059', 'Total loss: 1.4020', 'for batch', 14)
('GAN loss 0.6885 ', 'GAN acc 0.5508', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.5254', 'Total loss: 1.3884', 'for batch', 15)
('GAN loss 0.6819 ', 'GAN acc 0.5781', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.5156', 'Total loss: 1.3790', 'for batch', 16)
('GAN loss 0.6923 ', 'GAN acc 0.5234', 'Discriminator loss 0.7045', 'Discriminator accuracy 0.4648', 'Total loss: 1.3968', 'for batch', 17)
('GAN loss 0.6898 ', 'GAN acc 0.5703', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.5078', 'Total loss: 1.3892', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.62915015)
('DISCRIMINATOR_Imagem FAKE=', 0.62628621)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.856718')
----------------------------------
('Epoch', 13, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6900 ', 'GAN acc 0.5117', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5332', 'Total loss: 1.3815', 'for batch', 0)
('GAN loss 0.7000 ', 'GAN acc 0.5234', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4805', 'Total loss: 1.4037', 'for batch', 1)
('GAN loss 0.7022 ', 'GAN acc 0.4961', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5020', 'Total loss: 1.4002', 'for batch', 2)
('GAN loss 0.7108 ', 'GAN acc 0.4766', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4980', 'Total loss: 1.4099', 'for batch', 3)
('GAN loss 0.7106 ', 'GAN acc 0.4453', 'Discriminator loss 0.6860', 'Discriminator accuracy 0.5215', 'Total loss: 1.3966', 'for batch', 4)
('GAN loss 0.7095 ', 'GAN acc 0.4961', 'Discriminator loss 0.6872', 'Discriminator accuracy 0.5312', 'Total loss: 1.3967', 'for batch', 5)
('GAN loss 0.7005 ', 'GAN acc 0.4844', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4941', 'Total loss: 1.3985', 'for batch', 6)
('GAN loss 0.6929 ', 'GAN acc 0.5391', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4844', 'Total loss: 1.3912', 'for batch', 7)
('GAN loss 0.6977 ', 'GAN acc 0.5469', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.4883', 'Total loss: 1.3991', 'for batch', 8)
('GAN loss 0.6978 ', 'GAN acc 0.4883', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.5156', 'Total loss: 1.3956', 'for batch', 9)
('GAN loss 0.6961 ', 'GAN acc 0.5312', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5352', 'Total loss: 1.3914', 'for batch', 10)
('GAN loss 0.6945 ', 'GAN acc 0.5273', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5000', 'Total loss: 1.3857', 'for batch', 11)
('GAN loss 0.6935 ', 'GAN acc 0.5195', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5195', 'Total loss: 1.3841', 'for batch', 12)
('GAN loss 0.6964 ', 'GAN acc 0.5234', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.5039', 'Total loss: 1.3945', 'for batch', 13)
('GAN loss 0.7061 ', 'GAN acc 0.4805', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5039', 'Total loss: 1.3954', 'for batch', 14)
('GAN loss 0.6929 ', 'GAN acc 0.5273', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.5078', 'Total loss: 1.3980', 'for batch', 15)
('GAN loss 0.7038 ', 'GAN acc 0.4531', 'Discriminator loss 0.6870', 'Discriminator accuracy 0.5430', 'Total loss: 1.3908', 'for batch', 16)
('GAN loss 0.7036 ', 'GAN acc 0.5234', 'Discriminator loss 0.6873', 'Discriminator accuracy 0.5527', 'Total loss: 1.3909', 'for batch', 17)
('GAN loss 0.6887 ', 'GAN acc 0.5469', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5508', 'Total loss: 1.3862', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.6085372)
('DISCRIMINATOR_Imagem FAKE=', 0.60770714)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.476314')
----------------------------------
('Epoch', 14, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6974 ', 'GAN acc 0.5430', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5137', 'Total loss: 1.3932', 'for batch', 0)
('GAN loss 0.6868 ', 'GAN acc 0.5469', 'Discriminator loss 0.7051', 'Discriminator accuracy 0.4629', 'Total loss: 1.3919', 'for batch', 1)
('GAN loss 0.7109 ', 'GAN acc 0.4844', 'Discriminator loss 0.6992', 'Discriminator accuracy 0.4883', 'Total loss: 1.4101', 'for batch', 2)
('GAN loss 0.6894 ', 'GAN acc 0.5742', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4785', 'Total loss: 1.3894', 'for batch', 3)
('GAN loss 0.6991 ', 'GAN acc 0.5156', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.4902', 'Total loss: 1.3997', 'for batch', 4)
('GAN loss 0.6949 ', 'GAN acc 0.5352', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4883', 'Total loss: 1.3948', 'for batch', 5)
('GAN loss 0.6832 ', 'GAN acc 0.5195', 'Discriminator loss 0.7081', 'Discriminator accuracy 0.4922', 'Total loss: 1.3912', 'for batch', 6)
('GAN loss 0.6994 ', 'GAN acc 0.5117', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5059', 'Total loss: 1.3930', 'for batch', 7)
('GAN loss 0.7093 ', 'GAN acc 0.4844', 'Discriminator loss 0.6893', 'Discriminator accuracy 0.5430', 'Total loss: 1.3985', 'for batch', 8)
('GAN loss 0.6933 ', 'GAN acc 0.5547', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.5195', 'Total loss: 1.3937', 'for batch', 9)
('GAN loss 0.6837 ', 'GAN acc 0.5547', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5117', 'Total loss: 1.3762', 'for batch', 10)
('GAN loss 0.6919 ', 'GAN acc 0.5547', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5254', 'Total loss: 1.3822', 'for batch', 11)
('GAN loss 0.6922 ', 'GAN acc 0.5234', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.5547', 'Total loss: 1.3852', 'for batch', 12)
('GAN loss 0.6866 ', 'GAN acc 0.5625', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.5293', 'Total loss: 1.3862', 'for batch', 13)
('GAN loss 0.6978 ', 'GAN acc 0.5195', 'Discriminator loss 0.6912', 'Discriminator accuracy 0.5215', 'Total loss: 1.3891', 'for batch', 14)
('GAN loss 0.6891 ', 'GAN acc 0.5430', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5156', 'Total loss: 1.3856', 'for batch', 15)
('GAN loss 0.6870 ', 'GAN acc 0.5625', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5059', 'Total loss: 1.3850', 'for batch', 16)
('GAN loss 0.6953 ', 'GAN acc 0.5273', 'Discriminator loss 0.7013', 'Discriminator accuracy 0.5352', 'Total loss: 1.3966', 'for batch', 17)
('GAN loss 0.6964 ', 'GAN acc 0.4883', 'Discriminator loss 0.7040', 'Discriminator accuracy 0.5059', 'Total loss: 1.4004', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.58868736)
('DISCRIMINATOR_Imagem FAKE=', 0.58944911)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.860739')
----------------------------------
('Epoch', 15, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6965 ', 'GAN acc 0.4961', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4980', 'Total loss: 1.3973', 'for batch', 0)
('GAN loss 0.7016 ', 'GAN acc 0.5117', 'Discriminator loss 0.7007', 'Discriminator accuracy 0.4922', 'Total loss: 1.4023', 'for batch', 1)
('GAN loss 0.6897 ', 'GAN acc 0.5508', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5039', 'Total loss: 1.3863', 'for batch', 2)
('GAN loss 0.6882 ', 'GAN acc 0.5508', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4941', 'Total loss: 1.3914', 'for batch', 3)
('GAN loss 0.6935 ', 'GAN acc 0.5312', 'Discriminator loss 0.7037', 'Discriminator accuracy 0.4941', 'Total loss: 1.3972', 'for batch', 4)
('GAN loss 0.6957 ', 'GAN acc 0.5156', 'Discriminator loss 0.7006', 'Discriminator accuracy 0.5000', 'Total loss: 1.3963', 'for batch', 5)
('GAN loss 0.6977 ', 'GAN acc 0.4883', 'Discriminator loss 0.7016', 'Discriminator accuracy 0.4961', 'Total loss: 1.3993', 'for batch', 6)
('GAN loss 0.6871 ', 'GAN acc 0.5273', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5098', 'Total loss: 1.3824', 'for batch', 7)
('GAN loss 0.7057 ', 'GAN acc 0.4492', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4941', 'Total loss: 1.4039', 'for batch', 8)
('GAN loss 0.7015 ', 'GAN acc 0.5000', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5293', 'Total loss: 1.3930', 'for batch', 9)
('GAN loss 0.6922 ', 'GAN acc 0.4961', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.5020', 'Total loss: 1.3908', 'for batch', 10)
('GAN loss 0.7168 ', 'GAN acc 0.4102', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5039', 'Total loss: 1.4127', 'for batch', 11)
('GAN loss 0.6988 ', 'GAN acc 0.4922', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5449', 'Total loss: 1.3908', 'for batch', 12)
('GAN loss 0.6905 ', 'GAN acc 0.5273', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5059', 'Total loss: 1.3872', 'for batch', 13)
('GAN loss 0.6854 ', 'GAN acc 0.5391', 'Discriminator loss 0.7030', 'Discriminator accuracy 0.4922', 'Total loss: 1.3884', 'for batch', 14)
('GAN loss 0.6832 ', 'GAN acc 0.5508', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4805', 'Total loss: 1.3787', 'for batch', 15)
('GAN loss 0.6976 ', 'GAN acc 0.4922', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.5117', 'Total loss: 1.3952', 'for batch', 16)
('GAN loss 0.6924 ', 'GAN acc 0.5430', 'Discriminator loss 0.7059', 'Discriminator accuracy 0.4590', 'Total loss: 1.3983', 'for batch', 17)
('GAN loss 0.6974 ', 'GAN acc 0.5117', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4961', 'Total loss: 1.3963', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.57609314)
('DISCRIMINATOR_Imagem FAKE=', 0.57555383)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.460859')
----------------------------------
('Epoch', 16, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6907 ', 'GAN acc 0.5195', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4863', 'Total loss: 1.3885', 'for batch', 0)
('GAN loss 0.7049 ', 'GAN acc 0.4531', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5078', 'Total loss: 1.3993', 'for batch', 1)
('GAN loss 0.7008 ', 'GAN acc 0.4727', 'Discriminator loss 0.7080', 'Discriminator accuracy 0.4316', 'Total loss: 1.4088', 'for batch', 2)
('GAN loss 0.6856 ', 'GAN acc 0.5625', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4902', 'Total loss: 1.3827', 'for batch', 3)
('GAN loss 0.6889 ', 'GAN acc 0.5508', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4688', 'Total loss: 1.3879', 'for batch', 4)
('GAN loss 0.7058 ', 'GAN acc 0.4492', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.5156', 'Total loss: 1.4046', 'for batch', 5)
('GAN loss 0.6911 ', 'GAN acc 0.5234', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5234', 'Total loss: 1.3848', 'for batch', 6)
('GAN loss 0.7126 ', 'GAN acc 0.4492', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5078', 'Total loss: 1.4040', 'for batch', 7)
('GAN loss 0.7029 ', 'GAN acc 0.5156', 'Discriminator loss 0.7082', 'Discriminator accuracy 0.4336', 'Total loss: 1.4111', 'for batch', 8)
('GAN loss 0.7057 ', 'GAN acc 0.4766', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4727', 'Total loss: 1.4041', 'for batch', 9)
('GAN loss 0.6903 ', 'GAN acc 0.5078', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5293', 'Total loss: 1.3840', 'for batch', 10)
('GAN loss 0.6917 ', 'GAN acc 0.5156', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.5254', 'Total loss: 1.3860', 'for batch', 11)
('GAN loss 0.6861 ', 'GAN acc 0.5664', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5039', 'Total loss: 1.3810', 'for batch', 12)
('GAN loss 0.6976 ', 'GAN acc 0.5117', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4941', 'Total loss: 1.3948', 'for batch', 13)
('GAN loss 0.6837 ', 'GAN acc 0.5391', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5195', 'Total loss: 1.3819', 'for batch', 14)
('GAN loss 0.6991 ', 'GAN acc 0.5234', 'Discriminator loss 0.7022', 'Discriminator accuracy 0.4766', 'Total loss: 1.4013', 'for batch', 15)
('GAN loss 0.6943 ', 'GAN acc 0.5234', 'Discriminator loss 0.7032', 'Discriminator accuracy 0.4609', 'Total loss: 1.3975', 'for batch', 16)
('GAN loss 0.7003 ', 'GAN acc 0.4688', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.5020', 'Total loss: 1.4014', 'for batch', 17)
('GAN loss 0.6996 ', 'GAN acc 0.4883', 'Discriminator loss 0.6822', 'Discriminator accuracy 0.5566', 'Total loss: 1.3818', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5657472)
('DISCRIMINATOR_Imagem FAKE=', 0.5653758)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.869689')
----------------------------------
('Epoch', 17, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7026 ', 'GAN acc 0.4883', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5293', 'Total loss: 1.3982', 'for batch', 0)
('GAN loss 0.6891 ', 'GAN acc 0.5547', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.4941', 'Total loss: 1.3865', 'for batch', 1)
('GAN loss 0.7056 ', 'GAN acc 0.4570', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5312', 'Total loss: 1.3985', 'for batch', 2)
('GAN loss 0.7009 ', 'GAN acc 0.4961', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5059', 'Total loss: 1.3955', 'for batch', 3)
('GAN loss 0.7076 ', 'GAN acc 0.4219', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5215', 'Total loss: 1.4038', 'for batch', 4)
('GAN loss 0.7079 ', 'GAN acc 0.4414', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5410', 'Total loss: 1.3982', 'for batch', 5)
('GAN loss 0.6940 ', 'GAN acc 0.5273', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4883', 'Total loss: 1.3909', 'for batch', 6)
('GAN loss 0.6989 ', 'GAN acc 0.5078', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.4746', 'Total loss: 1.3949', 'for batch', 7)
('GAN loss 0.6982 ', 'GAN acc 0.4883', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4980', 'Total loss: 1.3954', 'for batch', 8)
('GAN loss 0.6928 ', 'GAN acc 0.5195', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5117', 'Total loss: 1.3880', 'for batch', 9)
('GAN loss 0.7027 ', 'GAN acc 0.4922', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.5000', 'Total loss: 1.4015', 'for batch', 10)
('GAN loss 0.7018 ', 'GAN acc 0.4648', 'Discriminator loss 0.7029', 'Discriminator accuracy 0.4922', 'Total loss: 1.4047', 'for batch', 11)
('GAN loss 0.6964 ', 'GAN acc 0.5078', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4980', 'Total loss: 1.3944', 'for batch', 12)
('GAN loss 0.6890 ', 'GAN acc 0.5547', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5273', 'Total loss: 1.3836', 'for batch', 13)
('GAN loss 0.7048 ', 'GAN acc 0.4766', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5117', 'Total loss: 1.4016', 'for batch', 14)
('GAN loss 0.6924 ', 'GAN acc 0.5430', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5156', 'Total loss: 1.3856', 'for batch', 15)
('GAN loss 0.6890 ', 'GAN acc 0.5508', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5000', 'Total loss: 1.3821', 'for batch', 16)
('GAN loss 0.6800 ', 'GAN acc 0.5938', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5312', 'Total loss: 1.3754', 'for batch', 17)
('GAN loss 0.6850 ', 'GAN acc 0.5156', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4668', 'Total loss: 1.3849', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.56386167)
('DISCRIMINATOR_Imagem FAKE=', 0.5627414)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.476209')
----------------------------------
('Epoch', 18, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6807 ', 'GAN acc 0.5781', 'Discriminator loss 0.7009', 'Discriminator accuracy 0.4805', 'Total loss: 1.3816', 'for batch', 0)
('GAN loss 0.6846 ', 'GAN acc 0.5859', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5020', 'Total loss: 1.3813', 'for batch', 1)
('GAN loss 0.6945 ', 'GAN acc 0.5625', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4766', 'Total loss: 1.3955', 'for batch', 2)
('GAN loss 0.6978 ', 'GAN acc 0.5156', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.5098', 'Total loss: 1.3930', 'for batch', 3)
('GAN loss 0.6957 ', 'GAN acc 0.5117', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4766', 'Total loss: 1.3980', 'for batch', 4)
('GAN loss 0.6935 ', 'GAN acc 0.5156', 'Discriminator loss 0.6973', 'Discriminator accuracy 0.4844', 'Total loss: 1.3909', 'for batch', 5)
('GAN loss 0.7078 ', 'GAN acc 0.5117', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.5000', 'Total loss: 1.4049', 'for batch', 6)
('GAN loss 0.6937 ', 'GAN acc 0.5312', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5137', 'Total loss: 1.3887', 'for batch', 7)
('GAN loss 0.7013 ', 'GAN acc 0.5078', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5117', 'Total loss: 1.3980', 'for batch', 8)
('GAN loss 0.6922 ', 'GAN acc 0.5000', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4980', 'Total loss: 1.3872', 'for batch', 9)
('GAN loss 0.7036 ', 'GAN acc 0.4648', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4746', 'Total loss: 1.4022', 'for batch', 10)
('GAN loss 0.7033 ', 'GAN acc 0.4727', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5000', 'Total loss: 1.3964', 'for batch', 11)
('GAN loss 0.7020 ', 'GAN acc 0.4805', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4941', 'Total loss: 1.3998', 'for batch', 12)
('GAN loss 0.6945 ', 'GAN acc 0.4922', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5156', 'Total loss: 1.3909', 'for batch', 13)
('GAN loss 0.6931 ', 'GAN acc 0.5586', 'Discriminator loss 0.6942', 'Discriminator accuracy 0.5020', 'Total loss: 1.3873', 'for batch', 14)
('GAN loss 0.7005 ', 'GAN acc 0.5000', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5020', 'Total loss: 1.3934', 'for batch', 15)
('GAN loss 0.6896 ', 'GAN acc 0.5273', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.5098', 'Total loss: 1.3863', 'for batch', 16)
('GAN loss 0.6943 ', 'GAN acc 0.4922', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4824', 'Total loss: 1.3920', 'for batch', 17)
('GAN loss 0.6909 ', 'GAN acc 0.5547', 'Discriminator loss 0.7023', 'Discriminator accuracy 0.4902', 'Total loss: 1.3932', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5543257)
('DISCRIMINATOR_Imagem FAKE=', 0.55409789)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.006667')
----------------------------------
('Epoch', 19, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6881 ', 'GAN acc 0.5625', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4941', 'Total loss: 1.3859', 'for batch', 0)
('GAN loss 0.6853 ', 'GAN acc 0.5430', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5195', 'Total loss: 1.3809', 'for batch', 1)
('GAN loss 0.6891 ', 'GAN acc 0.5508', 'Discriminator loss 0.7011', 'Discriminator accuracy 0.4922', 'Total loss: 1.3902', 'for batch', 2)
('GAN loss 0.6853 ', 'GAN acc 0.5703', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4902', 'Total loss: 1.3844', 'for batch', 3)
('GAN loss 0.6815 ', 'GAN acc 0.5508', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4883', 'Total loss: 1.3802', 'for batch', 4)
('GAN loss 0.6945 ', 'GAN acc 0.5430', 'Discriminator loss 0.6899', 'Discriminator accuracy 0.5547', 'Total loss: 1.3843', 'for batch', 5)
('GAN loss 0.6944 ', 'GAN acc 0.5117', 'Discriminator loss 0.7027', 'Discriminator accuracy 0.4805', 'Total loss: 1.3971', 'for batch', 6)
('GAN loss 0.6880 ', 'GAN acc 0.5586', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5195', 'Total loss: 1.3802', 'for batch', 7)
('GAN loss 0.6995 ', 'GAN acc 0.4805', 'Discriminator loss 0.7010', 'Discriminator accuracy 0.4785', 'Total loss: 1.4005', 'for batch', 8)
('GAN loss 0.7029 ', 'GAN acc 0.4961', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.4961', 'Total loss: 1.3939', 'for batch', 9)
('GAN loss 0.7019 ', 'GAN acc 0.4844', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.5000', 'Total loss: 1.4012', 'for batch', 10)
('GAN loss 0.6992 ', 'GAN acc 0.4688', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5117', 'Total loss: 1.3910', 'for batch', 11)
('GAN loss 0.6990 ', 'GAN acc 0.4648', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5176', 'Total loss: 1.3948', 'for batch', 12)
('GAN loss 0.7007 ', 'GAN acc 0.4766', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4883', 'Total loss: 1.3962', 'for batch', 13)
('GAN loss 0.7068 ', 'GAN acc 0.4570', 'Discriminator loss 0.7053', 'Discriminator accuracy 0.4648', 'Total loss: 1.4122', 'for batch', 14)
('GAN loss 0.6980 ', 'GAN acc 0.4492', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5078', 'Total loss: 1.3921', 'for batch', 15)
('GAN loss 0.7068 ', 'GAN acc 0.4531', 'Discriminator loss 0.7020', 'Discriminator accuracy 0.4844', 'Total loss: 1.4088', 'for batch', 16)
('GAN loss 0.7057 ', 'GAN acc 0.4609', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5059', 'Total loss: 1.4023', 'for batch', 17)
('GAN loss 0.7018 ', 'GAN acc 0.4609', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.5059', 'Total loss: 1.4005', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.54415041)
('DISCRIMINATOR_Imagem FAKE=', 0.54457235)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.957496')
----------------------------------
('Epoch', 20, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6997 ', 'GAN acc 0.5156', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4531', 'Total loss: 1.3991', 'for batch', 0)
('GAN loss 0.6926 ', 'GAN acc 0.5078', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5098', 'Total loss: 1.3891', 'for batch', 1)
('GAN loss 0.6873 ', 'GAN acc 0.5508', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4902', 'Total loss: 1.3860', 'for batch', 2)
('GAN loss 0.6891 ', 'GAN acc 0.5117', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4805', 'Total loss: 1.3860', 'for batch', 3)
('GAN loss 0.6890 ', 'GAN acc 0.5273', 'Discriminator loss 0.6931', 'Discriminator accuracy 0.5195', 'Total loss: 1.3821', 'for batch', 4)
('GAN loss 0.6848 ', 'GAN acc 0.5508', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5156', 'Total loss: 1.3790', 'for batch', 5)
('GAN loss 0.6934 ', 'GAN acc 0.5586', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4863', 'Total loss: 1.3911', 'for batch', 6)
('GAN loss 0.6890 ', 'GAN acc 0.5391', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4805', 'Total loss: 1.3867', 'for batch', 7)
('GAN loss 0.6910 ', 'GAN acc 0.5000', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4883', 'Total loss: 1.3914', 'for batch', 8)
('GAN loss 0.6951 ', 'GAN acc 0.5078', 'Discriminator loss 0.6975', 'Discriminator accuracy 0.5000', 'Total loss: 1.3926', 'for batch', 9)
('GAN loss 0.6966 ', 'GAN acc 0.5117', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5215', 'Total loss: 1.3902', 'for batch', 10)
('GAN loss 0.7001 ', 'GAN acc 0.5156', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4805', 'Total loss: 1.3989', 'for batch', 11)
('GAN loss 0.6801 ', 'GAN acc 0.5820', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3759', 'for batch', 12)
('GAN loss 0.6896 ', 'GAN acc 0.5547', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5312', 'Total loss: 1.3804', 'for batch', 13)
('GAN loss 0.6857 ', 'GAN acc 0.5234', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4883', 'Total loss: 1.3811', 'for batch', 14)
('GAN loss 0.6894 ', 'GAN acc 0.5430', 'Discriminator loss 0.6999', 'Discriminator accuracy 0.4863', 'Total loss: 1.3894', 'for batch', 15)
('GAN loss 0.6917 ', 'GAN acc 0.5391', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.5039', 'Total loss: 1.3870', 'for batch', 16)
('GAN loss 0.6951 ', 'GAN acc 0.5195', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5391', 'Total loss: 1.3878', 'for batch', 17)
('GAN loss 0.7010 ', 'GAN acc 0.4648', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5098', 'Total loss: 1.3969', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53976291)
('DISCRIMINATOR_Imagem FAKE=', 0.53995925)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.455636')
----------------------------------
('Epoch', 21, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6929 ', 'GAN acc 0.5117', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4883', 'Total loss: 1.3903', 'for batch', 0)
('GAN loss 0.6970 ', 'GAN acc 0.4727', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5312', 'Total loss: 1.3903', 'for batch', 1)
('GAN loss 0.6916 ', 'GAN acc 0.5039', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5273', 'Total loss: 1.3844', 'for batch', 2)
('GAN loss 0.7030 ', 'GAN acc 0.4609', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5156', 'Total loss: 1.3939', 'for batch', 3)
('GAN loss 0.6841 ', 'GAN acc 0.5352', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5195', 'Total loss: 1.3791', 'for batch', 4)
('GAN loss 0.6935 ', 'GAN acc 0.5078', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5234', 'Total loss: 1.3859', 'for batch', 5)
('GAN loss 0.6941 ', 'GAN acc 0.4922', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4980', 'Total loss: 1.3905', 'for batch', 6)
('GAN loss 0.6940 ', 'GAN acc 0.5156', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5078', 'Total loss: 1.3880', 'for batch', 7)
('GAN loss 0.6936 ', 'GAN acc 0.5156', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5137', 'Total loss: 1.3880', 'for batch', 8)
('GAN loss 0.7014 ', 'GAN acc 0.4102', 'Discriminator loss 0.6935', 'Discriminator accuracy 0.5293', 'Total loss: 1.3949', 'for batch', 9)
('GAN loss 0.6994 ', 'GAN acc 0.4883', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4844', 'Total loss: 1.3988', 'for batch', 10)
('GAN loss 0.6934 ', 'GAN acc 0.5586', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4883', 'Total loss: 1.3896', 'for batch', 11)
('GAN loss 0.6946 ', 'GAN acc 0.5117', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.5117', 'Total loss: 1.3893', 'for batch', 12)
('GAN loss 0.6859 ', 'GAN acc 0.5664', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4922', 'Total loss: 1.3818', 'for batch', 13)
('GAN loss 0.6916 ', 'GAN acc 0.5391', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5156', 'Total loss: 1.3862', 'for batch', 14)
('GAN loss 0.6949 ', 'GAN acc 0.5156', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4863', 'Total loss: 1.3936', 'for batch', 15)
('GAN loss 0.6971 ', 'GAN acc 0.5039', 'Discriminator loss 0.6903', 'Discriminator accuracy 0.5254', 'Total loss: 1.3874', 'for batch', 16)
('GAN loss 0.6901 ', 'GAN acc 0.5195', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4902', 'Total loss: 1.3865', 'for batch', 17)
('GAN loss 0.6933 ', 'GAN acc 0.5156', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4941', 'Total loss: 1.3877', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53545058)
('DISCRIMINATOR_Imagem FAKE=', 0.53626138)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.900567')
----------------------------------
('Epoch', 22, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6924 ', 'GAN acc 0.5391', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.5039', 'Total loss: 1.3891', 'for batch', 0)
('GAN loss 0.6918 ', 'GAN acc 0.5391', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.4922', 'Total loss: 1.3842', 'for batch', 1)
('GAN loss 0.6969 ', 'GAN acc 0.4766', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4414', 'Total loss: 1.3947', 'for batch', 2)
('GAN loss 0.6840 ', 'GAN acc 0.5430', 'Discriminator loss 0.6972', 'Discriminator accuracy 0.4980', 'Total loss: 1.3813', 'for batch', 3)
('GAN loss 0.6885 ', 'GAN acc 0.5234', 'Discriminator loss 0.6905', 'Discriminator accuracy 0.5488', 'Total loss: 1.3790', 'for batch', 4)
('GAN loss 0.7008 ', 'GAN acc 0.4531', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.5078', 'Total loss: 1.3967', 'for batch', 5)
('GAN loss 0.6827 ', 'GAN acc 0.5977', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4902', 'Total loss: 1.3809', 'for batch', 6)
('GAN loss 0.6973 ', 'GAN acc 0.4961', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4805', 'Total loss: 1.3937', 'for batch', 7)
('GAN loss 0.6902 ', 'GAN acc 0.5156', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.5039', 'Total loss: 1.3851', 'for batch', 8)
('GAN loss 0.6952 ', 'GAN acc 0.4844', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5312', 'Total loss: 1.3876', 'for batch', 9)
('GAN loss 0.6958 ', 'GAN acc 0.5117', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5332', 'Total loss: 1.3902', 'for batch', 10)
('GAN loss 0.6909 ', 'GAN acc 0.5195', 'Discriminator loss 0.6920', 'Discriminator accuracy 0.5430', 'Total loss: 1.3830', 'for batch', 11)
('GAN loss 0.7020 ', 'GAN acc 0.4102', 'Discriminator loss 0.6915', 'Discriminator accuracy 0.5020', 'Total loss: 1.3935', 'for batch', 12)
('GAN loss 0.6987 ', 'GAN acc 0.4844', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5293', 'Total loss: 1.3931', 'for batch', 13)
('GAN loss 0.6927 ', 'GAN acc 0.5352', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5137', 'Total loss: 1.3833', 'for batch', 14)
('GAN loss 0.6991 ', 'GAN acc 0.4688', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4922', 'Total loss: 1.3954', 'for batch', 15)
('GAN loss 0.6950 ', 'GAN acc 0.5273', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.5059', 'Total loss: 1.3934', 'for batch', 16)
('GAN loss 0.6911 ', 'GAN acc 0.5273', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4863', 'Total loss: 1.3889', 'for batch', 17)
('GAN loss 0.6944 ', 'GAN acc 0.4922', 'Discriminator loss 0.7033', 'Discriminator accuracy 0.4492', 'Total loss: 1.3977', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53168458)
('DISCRIMINATOR_Imagem FAKE=', 0.53404629)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.449576')
----------------------------------
('Epoch', 23, 'of', 50)
('Number of batches', 19)
('GAN loss 0.7002 ', 'GAN acc 0.4844', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4980', 'Total loss: 1.3976', 'for batch', 0)
('GAN loss 0.6985 ', 'GAN acc 0.4844', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5410', 'Total loss: 1.3942', 'for batch', 1)
('GAN loss 0.6933 ', 'GAN acc 0.5117', 'Discriminator loss 0.6970', 'Discriminator accuracy 0.4863', 'Total loss: 1.3902', 'for batch', 2)
('GAN loss 0.6967 ', 'GAN acc 0.4727', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4961', 'Total loss: 1.3905', 'for batch', 3)
('GAN loss 0.7029 ', 'GAN acc 0.4492', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5117', 'Total loss: 1.3994', 'for batch', 4)
('GAN loss 0.6920 ', 'GAN acc 0.5430', 'Discriminator loss 0.6996', 'Discriminator accuracy 0.4805', 'Total loss: 1.3916', 'for batch', 5)
('GAN loss 0.6999 ', 'GAN acc 0.4922', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4648', 'Total loss: 1.3967', 'for batch', 6)
('GAN loss 0.6922 ', 'GAN acc 0.5352', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4863', 'Total loss: 1.3904', 'for batch', 7)
('GAN loss 0.6964 ', 'GAN acc 0.4766', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4727', 'Total loss: 1.3948', 'for batch', 8)
('GAN loss 0.7023 ', 'GAN acc 0.4648', 'Discriminator loss 0.6961', 'Discriminator accuracy 0.4922', 'Total loss: 1.3984', 'for batch', 9)
('GAN loss 0.6905 ', 'GAN acc 0.5352', 'Discriminator loss 0.6974', 'Discriminator accuracy 0.4648', 'Total loss: 1.3879', 'for batch', 10)
('GAN loss 0.6947 ', 'GAN acc 0.4805', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.4902', 'Total loss: 1.3888', 'for batch', 11)
('GAN loss 0.6866 ', 'GAN acc 0.5625', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4688', 'Total loss: 1.3835', 'for batch', 12)
('GAN loss 0.6834 ', 'GAN acc 0.5547', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5156', 'Total loss: 1.3745', 'for batch', 13)
('GAN loss 0.6808 ', 'GAN acc 0.5586', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4727', 'Total loss: 1.3789', 'for batch', 14)
('GAN loss 0.6885 ', 'GAN acc 0.5820', 'Discriminator loss 0.6990', 'Discriminator accuracy 0.4902', 'Total loss: 1.3875', 'for batch', 15)
('GAN loss 0.6857 ', 'GAN acc 0.5664', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5039', 'Total loss: 1.3781', 'for batch', 16)
('GAN loss 0.6884 ', 'GAN acc 0.5742', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4863', 'Total loss: 1.3854', 'for batch', 17)
('GAN loss 0.6968 ', 'GAN acc 0.5039', 'Discriminator loss 0.6960', 'Discriminator accuracy 0.4844', 'Total loss: 1.3929', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.53096676)
('DISCRIMINATOR_Imagem FAKE=', 0.53064543)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.867239')
----------------------------------
('Epoch', 24, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6890 ', 'GAN acc 0.5352', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5156', 'Total loss: 1.3811', 'for batch', 0)
('GAN loss 0.6946 ', 'GAN acc 0.5273', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5078', 'Total loss: 1.3901', 'for batch', 1)
('GAN loss 0.6995 ', 'GAN acc 0.4961', 'Discriminator loss 0.7025', 'Discriminator accuracy 0.4590', 'Total loss: 1.4020', 'for batch', 2)
('GAN loss 0.7054 ', 'GAN acc 0.4414', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.5020', 'Total loss: 1.4036', 'for batch', 3)
('GAN loss 0.6960 ', 'GAN acc 0.5117', 'Discriminator loss 0.6925', 'Discriminator accuracy 0.5176', 'Total loss: 1.3885', 'for batch', 4)
('GAN loss 0.7012 ', 'GAN acc 0.4727', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5137', 'Total loss: 1.3948', 'for batch', 5)
('GAN loss 0.6982 ', 'GAN acc 0.4922', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4766', 'Total loss: 1.3975', 'for batch', 6)
('GAN loss 0.6949 ', 'GAN acc 0.4805', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4961', 'Total loss: 1.3911', 'for batch', 7)
('GAN loss 0.6930 ', 'GAN acc 0.5039', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4902', 'Total loss: 1.3878', 'for batch', 8)
('GAN loss 0.6953 ', 'GAN acc 0.5469', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.4766', 'Total loss: 1.3896', 'for batch', 9)
('GAN loss 0.6961 ', 'GAN acc 0.5234', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4863', 'Total loss: 1.3919', 'for batch', 10)
('GAN loss 0.6999 ', 'GAN acc 0.4336', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4766', 'Total loss: 1.3986', 'for batch', 11)
('GAN loss 0.6954 ', 'GAN acc 0.5039', 'Discriminator loss 0.7005', 'Discriminator accuracy 0.4785', 'Total loss: 1.3959', 'for batch', 12)
('GAN loss 0.6947 ', 'GAN acc 0.5078', 'Discriminator loss 0.6985', 'Discriminator accuracy 0.4570', 'Total loss: 1.3932', 'for batch', 13)
('GAN loss 0.6968 ', 'GAN acc 0.4961', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5117', 'Total loss: 1.3906', 'for batch', 14)
('GAN loss 0.6944 ', 'GAN acc 0.4922', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5000', 'Total loss: 1.3895', 'for batch', 15)
('GAN loss 0.6987 ', 'GAN acc 0.5117', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5039', 'Total loss: 1.3938', 'for batch', 16)
('GAN loss 0.6992 ', 'GAN acc 0.5039', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.5176', 'Total loss: 1.3937', 'for batch', 17)
('GAN loss 0.6902 ', 'GAN acc 0.5273', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4824', 'Total loss: 1.3885', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52543414)
('DISCRIMINATOR_Imagem FAKE=', 0.525141)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.540470')
----------------------------------
('Epoch', 25, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6909 ', 'GAN acc 0.5469', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4844', 'Total loss: 1.3856', 'for batch', 0)
('GAN loss 0.6932 ', 'GAN acc 0.5469', 'Discriminator loss 0.6898', 'Discriminator accuracy 0.5547', 'Total loss: 1.3830', 'for batch', 1)
('GAN loss 0.6958 ', 'GAN acc 0.5312', 'Discriminator loss 0.6924', 'Discriminator accuracy 0.5215', 'Total loss: 1.3882', 'for batch', 2)
('GAN loss 0.6907 ', 'GAN acc 0.5312', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5117', 'Total loss: 1.3835', 'for batch', 3)
('GAN loss 0.6878 ', 'GAN acc 0.5625', 'Discriminator loss 0.6997', 'Discriminator accuracy 0.4648', 'Total loss: 1.3875', 'for batch', 4)
('GAN loss 0.6907 ', 'GAN acc 0.5234', 'Discriminator loss 0.6936', 'Discriminator accuracy 0.5137', 'Total loss: 1.3843', 'for batch', 5)
('GAN loss 0.6944 ', 'GAN acc 0.5117', 'Discriminator loss 0.6998', 'Discriminator accuracy 0.4805', 'Total loss: 1.3942', 'for batch', 6)
('GAN loss 0.6868 ', 'GAN acc 0.5508', 'Discriminator loss 0.7000', 'Discriminator accuracy 0.4590', 'Total loss: 1.3868', 'for batch', 7)
('GAN loss 0.6938 ', 'GAN acc 0.4883', 'Discriminator loss 0.6906', 'Discriminator accuracy 0.5176', 'Total loss: 1.3843', 'for batch', 8)
('GAN loss 0.6963 ', 'GAN acc 0.4805', 'Discriminator loss 0.6981', 'Discriminator accuracy 0.4609', 'Total loss: 1.3944', 'for batch', 9)
('GAN loss 0.6918 ', 'GAN acc 0.5312', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.4980', 'Total loss: 1.3855', 'for batch', 10)
('GAN loss 0.7005 ', 'GAN acc 0.4727', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.5020', 'Total loss: 1.3960', 'for batch', 11)
('GAN loss 0.7055 ', 'GAN acc 0.4258', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.4746', 'Total loss: 1.4002', 'for batch', 12)
('GAN loss 0.6877 ', 'GAN acc 0.5586', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5098', 'Total loss: 1.3818', 'for batch', 13)
('GAN loss 0.6938 ', 'GAN acc 0.5312', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5371', 'Total loss: 1.3852', 'for batch', 14)
('GAN loss 0.6963 ', 'GAN acc 0.4922', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4961', 'Total loss: 1.3918', 'for batch', 15)
('GAN loss 0.7054 ', 'GAN acc 0.4492', 'Discriminator loss 0.6913', 'Discriminator accuracy 0.5156', 'Total loss: 1.3967', 'for batch', 16)
('GAN loss 0.6878 ', 'GAN acc 0.5078', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4824', 'Total loss: 1.3846', 'for batch', 17)
('GAN loss 0.6897 ', 'GAN acc 0.5586', 'Discriminator loss 0.6918', 'Discriminator accuracy 0.5312', 'Total loss: 1.3815', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.5245443)
('DISCRIMINATOR_Imagem FAKE=', 0.52475607)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.842194')
----------------------------------
('Epoch', 26, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6870 ', 'GAN acc 0.5625', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.4883', 'Total loss: 1.3808', 'for batch', 0)
('GAN loss 0.6968 ', 'GAN acc 0.4609', 'Discriminator loss 0.6922', 'Discriminator accuracy 0.5332', 'Total loss: 1.3891', 'for batch', 1)
('GAN loss 0.6932 ', 'GAN acc 0.5195', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.4922', 'Total loss: 1.3864', 'for batch', 2)
('GAN loss 0.6963 ', 'GAN acc 0.4727', 'Discriminator loss 0.6957', 'Discriminator accuracy 0.5000', 'Total loss: 1.3920', 'for batch', 3)
('GAN loss 0.6929 ', 'GAN acc 0.5195', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.5059', 'Total loss: 1.3884', 'for batch', 4)
('GAN loss 0.6902 ', 'GAN acc 0.4844', 'Discriminator loss 0.6941', 'Discriminator accuracy 0.5176', 'Total loss: 1.3842', 'for batch', 5)
('GAN loss 0.6949 ', 'GAN acc 0.5117', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.5176', 'Total loss: 1.3877', 'for batch', 6)
('GAN loss 0.7048 ', 'GAN acc 0.4492', 'Discriminator loss 0.6932', 'Discriminator accuracy 0.5156', 'Total loss: 1.3981', 'for batch', 7)
('GAN loss 0.7003 ', 'GAN acc 0.4648', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4551', 'Total loss: 1.3957', 'for batch', 8)
('GAN loss 0.7021 ', 'GAN acc 0.4336', 'Discriminator loss 0.6983', 'Discriminator accuracy 0.4805', 'Total loss: 1.4005', 'for batch', 9)
('GAN loss 0.7041 ', 'GAN acc 0.4570', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5332', 'Total loss: 1.3970', 'for batch', 10)
('GAN loss 0.6962 ', 'GAN acc 0.4766', 'Discriminator loss 0.6909', 'Discriminator accuracy 0.5117', 'Total loss: 1.3871', 'for batch', 11)
('GAN loss 0.7079 ', 'GAN acc 0.4219', 'Discriminator loss 0.6940', 'Discriminator accuracy 0.5137', 'Total loss: 1.4019', 'for batch', 12)
('GAN loss 0.7030 ', 'GAN acc 0.4531', 'Discriminator loss 0.6959', 'Discriminator accuracy 0.5195', 'Total loss: 1.3988', 'for batch', 13)
('GAN loss 0.6968 ', 'GAN acc 0.4961', 'Discriminator loss 0.6956', 'Discriminator accuracy 0.4824', 'Total loss: 1.3924', 'for batch', 14)
('GAN loss 0.6909 ', 'GAN acc 0.5391', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.5117', 'Total loss: 1.3873', 'for batch', 15)
('GAN loss 0.7003 ', 'GAN acc 0.4609', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4785', 'Total loss: 1.3987', 'for batch', 16)
('GAN loss 0.6869 ', 'GAN acc 0.5469', 'Discriminator loss 0.6950', 'Discriminator accuracy 0.5176', 'Total loss: 1.3819', 'for batch', 17)
('GAN loss 0.6933 ', 'GAN acc 0.5156', 'Discriminator loss 0.7021', 'Discriminator accuracy 0.4707', 'Total loss: 1.3954', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52401853)
('DISCRIMINATOR_Imagem FAKE=', 0.52360362)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.456955')
----------------------------------
('Epoch', 27, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6859 ', 'GAN acc 0.5703', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4609', 'Total loss: 1.3830', 'for batch', 0)
('GAN loss 0.6908 ', 'GAN acc 0.5000', 'Discriminator loss 0.6952', 'Discriminator accuracy 0.5039', 'Total loss: 1.3860', 'for batch', 1)
('GAN loss 0.6854 ', 'GAN acc 0.5781', 'Discriminator loss 0.6944', 'Discriminator accuracy 0.5254', 'Total loss: 1.3797', 'for batch', 2)
('GAN loss 0.6920 ', 'GAN acc 0.5273', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5391', 'Total loss: 1.3836', 'for batch', 3)
('GAN loss 0.6901 ', 'GAN acc 0.5273', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5273', 'Total loss: 1.3859', 'for batch', 4)
('GAN loss 0.6902 ', 'GAN acc 0.5781', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.5312', 'Total loss: 1.3819', 'for batch', 5)
('GAN loss 0.6992 ', 'GAN acc 0.4688', 'Discriminator loss 0.6917', 'Discriminator accuracy 0.4980', 'Total loss: 1.3909', 'for batch', 6)
('GAN loss 0.6917 ', 'GAN acc 0.5117', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4922', 'Total loss: 1.3871', 'for batch', 7)
('GAN loss 0.6990 ', 'GAN acc 0.5117', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5098', 'Total loss: 1.3952', 'for batch', 8)
('GAN loss 0.6991 ', 'GAN acc 0.5156', 'Discriminator loss 0.6977', 'Discriminator accuracy 0.4805', 'Total loss: 1.3968', 'for batch', 9)
('GAN loss 0.6991 ', 'GAN acc 0.4883', 'Discriminator loss 0.6914', 'Discriminator accuracy 0.5273', 'Total loss: 1.3905', 'for batch', 10)
('GAN loss 0.7051 ', 'GAN acc 0.4219', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4707', 'Total loss: 1.4014', 'for batch', 11)
('GAN loss 0.7031 ', 'GAN acc 0.4375', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5254', 'Total loss: 1.3979', 'for batch', 12)
('GAN loss 0.6973 ', 'GAN acc 0.5156', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5176', 'Total loss: 1.3908', 'for batch', 13)
('GAN loss 0.6953 ', 'GAN acc 0.4844', 'Discriminator loss 0.6984', 'Discriminator accuracy 0.4844', 'Total loss: 1.3937', 'for batch', 14)
('GAN loss 0.6942 ', 'GAN acc 0.4844', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4941', 'Total loss: 1.3910', 'for batch', 15)
('GAN loss 0.6905 ', 'GAN acc 0.5352', 'Discriminator loss 0.6930', 'Discriminator accuracy 0.4961', 'Total loss: 1.3835', 'for batch', 16)
('GAN loss 0.6950 ', 'GAN acc 0.5312', 'Discriminator loss 0.6937', 'Discriminator accuracy 0.5000', 'Total loss: 1.3887', 'for batch', 17)
('GAN loss 0.6920 ', 'GAN acc 0.5195', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.4785', 'Total loss: 1.3900', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.52170384)
('DISCRIMINATOR_Imagem FAKE=', 0.52221751)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.862736')
----------------------------------
('Epoch', 28, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6927 ', 'GAN acc 0.5117', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.5020', 'Total loss: 1.3892', 'for batch', 0)
('GAN loss 0.6912 ', 'GAN acc 0.5273', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4570', 'Total loss: 1.3878', 'for batch', 1)
('GAN loss 0.6890 ', 'GAN acc 0.5391', 'Discriminator loss 0.6955', 'Discriminator accuracy 0.4961', 'Total loss: 1.3845', 'for batch', 2)
('GAN loss 0.6925 ', 'GAN acc 0.5586', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4844', 'Total loss: 1.3859', 'for batch', 3)
('GAN loss 0.6904 ', 'GAN acc 0.5273', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4844', 'Total loss: 1.3854', 'for batch', 4)
('GAN loss 0.6953 ', 'GAN acc 0.5195', 'Discriminator loss 0.6904', 'Discriminator accuracy 0.5293', 'Total loss: 1.3857', 'for batch', 5)
('GAN loss 0.6902 ', 'GAN acc 0.5664', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5098', 'Total loss: 1.3825', 'for batch', 6)
('GAN loss 0.6943 ', 'GAN acc 0.5156', 'Discriminator loss 0.6989', 'Discriminator accuracy 0.4766', 'Total loss: 1.3931', 'for batch', 7)
('GAN loss 0.7027 ', 'GAN acc 0.4336', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5059', 'Total loss: 1.3961', 'for batch', 8)
('GAN loss 0.6995 ', 'GAN acc 0.4844', 'Discriminator loss 0.6986', 'Discriminator accuracy 0.4785', 'Total loss: 1.3981', 'for batch', 9)
('GAN loss 0.6976 ', 'GAN acc 0.4805', 'Discriminator loss 0.6994', 'Discriminator accuracy 0.4727', 'Total loss: 1.3970', 'for batch', 10)
('GAN loss 0.6901 ', 'GAN acc 0.5469', 'Discriminator loss 0.6971', 'Discriminator accuracy 0.4746', 'Total loss: 1.3872', 'for batch', 11)
('GAN loss 0.6923 ', 'GAN acc 0.5195', 'Discriminator loss 0.6987', 'Discriminator accuracy 0.4668', 'Total loss: 1.3910', 'for batch', 12)
('GAN loss 0.6946 ', 'GAN acc 0.5117', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.5273', 'Total loss: 1.3880', 'for batch', 13)
('GAN loss 0.6983 ', 'GAN acc 0.4766', 'Discriminator loss 0.6921', 'Discriminator accuracy 0.5254', 'Total loss: 1.3904', 'for batch', 14)
('GAN loss 0.6925 ', 'GAN acc 0.5586', 'Discriminator loss 0.6943', 'Discriminator accuracy 0.4902', 'Total loss: 1.3868', 'for batch', 15)
('GAN loss 0.6947 ', 'GAN acc 0.5195', 'Discriminator loss 0.6969', 'Discriminator accuracy 0.4844', 'Total loss: 1.3916', 'for batch', 16)
('GAN loss 0.6980 ', 'GAN acc 0.4766', 'Discriminator loss 0.6978', 'Discriminator accuracy 0.4902', 'Total loss: 1.3959', 'for batch', 17)
('GAN loss 0.6953 ', 'GAN acc 0.5234', 'Discriminator loss 0.6928', 'Discriminator accuracy 0.5000', 'Total loss: 1.3881', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51963592)
('DISCRIMINATOR_Imagem FAKE=', 0.52074671)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.514348')
----------------------------------
('Epoch', 29, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6914 ', 'GAN acc 0.5469', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4922', 'Total loss: 1.3876', 'for batch', 0)
('GAN loss 0.6926 ', 'GAN acc 0.5078', 'Discriminator loss 0.6976', 'Discriminator accuracy 0.4902', 'Total loss: 1.3902', 'for batch', 1)
('GAN loss 0.6938 ', 'GAN acc 0.4883', 'Discriminator loss 0.6993', 'Discriminator accuracy 0.4570', 'Total loss: 1.3931', 'for batch', 2)
('GAN loss 0.6928 ', 'GAN acc 0.5352', 'Discriminator loss 0.6980', 'Discriminator accuracy 0.5039', 'Total loss: 1.3907', 'for batch', 3)
('GAN loss 0.7000 ', 'GAN acc 0.4883', 'Discriminator loss 0.6916', 'Discriminator accuracy 0.5391', 'Total loss: 1.3915', 'for batch', 4)
('GAN loss 0.6918 ', 'GAN acc 0.5430', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4863', 'Total loss: 1.3882', 'for batch', 5)
('GAN loss 0.6940 ', 'GAN acc 0.5195', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5117', 'Total loss: 1.3878', 'for batch', 6)
('GAN loss 0.6936 ', 'GAN acc 0.5508', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4805', 'Total loss: 1.3900', 'for batch', 7)
('GAN loss 0.6949 ', 'GAN acc 0.4922', 'Discriminator loss 0.6979', 'Discriminator accuracy 0.4883', 'Total loss: 1.3928', 'for batch', 8)
('GAN loss 0.6967 ', 'GAN acc 0.4727', 'Discriminator loss 0.7004', 'Discriminator accuracy 0.4648', 'Total loss: 1.3971', 'for batch', 9)
('GAN loss 0.7012 ', 'GAN acc 0.4648', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5156', 'Total loss: 1.3951', 'for batch', 10)
('GAN loss 0.6984 ', 'GAN acc 0.5117', 'Discriminator loss 0.6965', 'Discriminator accuracy 0.4883', 'Total loss: 1.3949', 'for batch', 11)
('GAN loss 0.6948 ', 'GAN acc 0.5312', 'Discriminator loss 0.6948', 'Discriminator accuracy 0.5098', 'Total loss: 1.3896', 'for batch', 12)
('GAN loss 0.6934 ', 'GAN acc 0.5000', 'Discriminator loss 0.6910', 'Discriminator accuracy 0.5371', 'Total loss: 1.3844', 'for batch', 13)
('GAN loss 0.6945 ', 'GAN acc 0.5039', 'Discriminator loss 0.6911', 'Discriminator accuracy 0.5469', 'Total loss: 1.3856', 'for batch', 14)
('GAN loss 0.6881 ', 'GAN acc 0.5352', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4902', 'Total loss: 1.3847', 'for batch', 15)
('GAN loss 0.6956 ', 'GAN acc 0.5039', 'Discriminator loss 0.6964', 'Discriminator accuracy 0.4766', 'Total loss: 1.3920', 'for batch', 16)
('GAN loss 0.6962 ', 'GAN acc 0.4805', 'Discriminator loss 0.6966', 'Discriminator accuracy 0.4766', 'Total loss: 1.3928', 'for batch', 17)
('GAN loss 0.6972 ', 'GAN acc 0.4883', 'Discriminator loss 0.6946', 'Discriminator accuracy 0.5059', 'Total loss: 1.3918', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51755178)
('DISCRIMINATOR_Imagem FAKE=', 0.51788467)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:27.907062')
----------------------------------
('Epoch', 30, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6947 ', 'GAN acc 0.5234', 'Discriminator loss 0.6947', 'Discriminator accuracy 0.4941', 'Total loss: 1.3895', 'for batch', 0)
('GAN loss 0.6913 ', 'GAN acc 0.5039', 'Discriminator loss 0.6949', 'Discriminator accuracy 0.4922', 'Total loss: 1.3862', 'for batch', 1)
('GAN loss 0.6879 ', 'GAN acc 0.5469', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.4844', 'Total loss: 1.3838', 'for batch', 2)
('GAN loss 0.6904 ', 'GAN acc 0.5195', 'Discriminator loss 0.6953', 'Discriminator accuracy 0.4863', 'Total loss: 1.3857', 'for batch', 3)
('GAN loss 0.6889 ', 'GAN acc 0.5508', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.4980', 'Total loss: 1.3851', 'for batch', 4)
('GAN loss 0.6849 ', 'GAN acc 0.5664', 'Discriminator loss 0.6988', 'Discriminator accuracy 0.4746', 'Total loss: 1.3837', 'for batch', 5)
('GAN loss 0.6864 ', 'GAN acc 0.5781', 'Discriminator loss 0.6962', 'Discriminator accuracy 0.5000', 'Total loss: 1.3825', 'for batch', 6)
('GAN loss 0.6903 ', 'GAN acc 0.5352', 'Discriminator loss 0.7008', 'Discriminator accuracy 0.4551', 'Total loss: 1.3910', 'for batch', 7)
('GAN loss 0.6997 ', 'GAN acc 0.4922', 'Discriminator loss 0.6982', 'Discriminator accuracy 0.4961', 'Total loss: 1.3980', 'for batch', 8)
('GAN loss 0.6940 ', 'GAN acc 0.5000', 'Discriminator loss 0.6934', 'Discriminator accuracy 0.4785', 'Total loss: 1.3874', 'for batch', 9)
('GAN loss 0.7010 ', 'GAN acc 0.4805', 'Discriminator loss 0.6927', 'Discriminator accuracy 0.4922', 'Total loss: 1.3937', 'for batch', 10)
('GAN loss 0.6981 ', 'GAN acc 0.4727', 'Discriminator loss 0.6945', 'Discriminator accuracy 0.4824', 'Total loss: 1.3926', 'for batch', 11)
('GAN loss 0.6848 ', 'GAN acc 0.5703', 'Discriminator loss 0.6938', 'Discriminator accuracy 0.5098', 'Total loss: 1.3787', 'for batch', 12)
('GAN loss 0.6905 ', 'GAN acc 0.5586', 'Discriminator loss 0.6954', 'Discriminator accuracy 0.4844', 'Total loss: 1.3859', 'for batch', 13)
('GAN loss 0.6847 ', 'GAN acc 0.5625', 'Discriminator loss 0.6923', 'Discriminator accuracy 0.5293', 'Total loss: 1.3771', 'for batch', 14)
('GAN loss 0.6978 ', 'GAN acc 0.4727', 'Discriminator loss 0.6908', 'Discriminator accuracy 0.5312', 'Total loss: 1.3886', 'for batch', 15)
('GAN loss 0.6938 ', 'GAN acc 0.4883', 'Discriminator loss 0.6895', 'Discriminator accuracy 0.5293', 'Total loss: 1.3832', 'for batch', 16)
('GAN loss 0.6959 ', 'GAN acc 0.5039', 'Discriminator loss 0.6958', 'Discriminator accuracy 0.5059', 'Total loss: 1.3918', 'for batch', 17)
('GAN loss 0.6973 ', 'GAN acc 0.5039', 'Discriminator loss 0.6963', 'Discriminator accuracy 0.4844', 'Total loss: 1.3936', 'for batch', 18)
('DISCRIMINATOR_Imagem REAL=', 0.51808947)
('DISCRIMINATOR_Imagem FAKE=', 0.51831466)
('Discriminator trained', 19, 'times of', 19, 'batchs')
Saving weights...
Saving sample images...
('Elapsed time in epoch = ', '0:00:28.416133')
----------------------------------
('Epoch', 31, 'of', 50)
('Number of batches', 19)
('GAN loss 0.6904 ', 'GAN acc 0.5039', 'Discriminator loss 0.6968', 'Discriminator accuracy 0.4746', 'Total loss: 1.3871', 'for batch', 0)
('GAN loss 0.6958 ', 'GAN acc 0.5078', 'Discriminator loss 0.6929', 'Discriminator accuracy 0.5039', 'Total loss: 1.3887', 'for batch', 1)
('GAN loss 0.6953 ', 'GAN acc 0.5000', 'Discriminator loss 0.6967', 'Discriminator accuracy 0.4688', 'Total loss: 1.3920', 'for batch', 2)
('GAN loss 0.6927 ', 'GAN acc 0.5391', 'Discriminator loss 0.6951', 'Discriminator accuracy 0.4941', 'Total loss: 1.3878', 'for batch', 3)
('GAN loss 0.6974 ', 'GAN acc 0.4766', 'Discriminator loss 0.6991', 'Discriminator accuracy 0.4961', 'Total loss: 1.3965', 'for batch', 4)
('GAN loss 0.6932 '